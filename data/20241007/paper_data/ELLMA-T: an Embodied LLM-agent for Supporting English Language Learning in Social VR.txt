ELLMA-T: an Embodied LLM-agent for Supporting English
Language Learning in Social VR
MengxuPan AlexandraKitson
pan.meng@northeastern.edu akitson@sfu.ca
KhouryCollegeofComputerScience,Northeastern SimonFraserUniversity
University Vancouver,BC,Canada
Vancouver,Canada
HongyuWan MirjanaPrpa
wan.hongy@northeastern.edu m.prpa@northeastern.edu
KhouryCollegeofComputerScience,Northeastern KhouryCollegeofComputerScience,Northeastern
University University
Vancouver,Canada Vancouver,Canada
Figure1:a)ELLMA-T,theGPT-4basedlanguagetutorinVRChat;b)b)ELLMA-Tgreetingtheuserintheirnativelanguage;c)
Role-playscenariowithELLMA-Tandtheuserinasupermarketsetting;d)UseraskingELLMA-Tforwordexplanations.
ABSTRACT leveragesanLLM(GPT-4)andsituatedlearningframeworkforsup-
Manypeoplestrugglewithlearninganewlanguage,withtradi- portinglearningEnglishlanguageinsocialVR(VRChat).Drawing
tionaltoolsfallingshortinprovidingcontextualizedlearningtai- onqualitativeinterviews(N=12),werevealthepotentialofELLMA-
loredtoeachlearner’sneeds.Therecentdevelopmentoflargelan- Ttogeneraterealistic,believableandcontext-specificroleplaysfor
guagemodels(LLMs)andembodiedconversationalagents(ECAs) agent-learnerinteractioninVR,andLLM’scapabilitytoprovide
insocialvirtualreality(VR)providenewopportunitiestoprac- initiallanguageassessmentandcontinuousfeedbacktolearners.
tice language learning in a contextualized and naturalistic way Weprovidefivedesignimplicationsforthefuturedevelopmentof
thattakesintoaccountthelearner’slanguagelevelandneeds.To LLM-basedlanguageagentsinsocialVR.
explore this opportunity, we developed ELLMA-T, an ECA that
4202
tcO
3
]CH.sc[
1v60420.0142:viXraPreprint,September2024, MengxuPan,AlexandraKitson,HongyuWan,andMirjanaPrpa
KEYWORDS (1) DesignofELLMA-T,anembodiedLLM-agenttaskedtohelp
EmbodiedConversationalAgents,SocialVirtualReality,LargeLan- adultlanguagelearnersfromA1toC1levelpracticespoken
guageModels,LanguageLearning English,bysimulatinganimmersivereal-lifeconversation
withinsocialVR;
ACMReferenceFormat: (2) A user study and findings about participants’ perception
MengxuPan,AlexandraKitson,HongyuWan,andMirjanaPrpa.2024. ofELLMA-T’scapabilitiesandlimitationsonfourEnglish
ELLMA-T:anEmbodiedLLM-agentforSupportingEnglishLanguageLearn-
learningtasks:languagelevelassessment,role-playdialogue
inginSocialVR.InProceedingsofArXivPreprint(Preprint).ACM,New
generation,feedbackgeneration,andscaffoldingabilities,
York,NY,USA,20pages.https://doi.org/10.1145/nnnnnnn.nnnnnnn
contributingtothelargerpictureofLLM-assistedlanguage
learningandLLM’sapplications;
1 INTRODUCTION
(3) DesignimplicationsfordesigningembodiedLLM-agentsin
AcquiringproficiencyinEnglishasanadditionallanguageises- socialVRcontextforlanguagelearning.
sentialformanyfacetsoflife.Thisappliestobothcountrieswhere
OurfindingsfromapreliminaryuserstudydemonstrateELLMA-
Englishistaughtaspartofthecompulsorycurriculum,eventhough
T’spotentialasa’human-like’languagetutorforsituatedlanguage
itisnotthenativelanguage,andtoEnglish-speakingcountries
learning.However,challengessuchasconversationflowdisrup-
wheredifferentpeople,suchasimmigrants,visitors,touristsor
tionsandinsufficientemotionalsupportwereidentified,suggesting
internationalstudentsrequireadditionalsupporttopracticeandim-
areasforfutureimprovement.Thestudy’sdesignimplicationsex-
provetheirEnglishskills[1].Commonlyusedlearningapproaches
tendtothedesignofpersonalized,culturallyrelevant,andadaptive
administeredintraditionalclassroomsoftenfallshortofproviding
learningsystemsthatintegrateverbalandnon-verbalcues.These
acontextualizedlearningenvironment,tailoredlearningmaterials,
findings highlight the potential for further exploration into de-
andengagingexperiencestosupportlearning.
velopingLLM-basedECAsinsocialVRforlong-termlanguage
Besidescommonlyusedlanguagelearningtools(e.g.,mobile
learning.
applications such as Duolingo [24]), the recent proliferation of
socialVirtualReality(VR)platformspresentsnewlearningchan-
nels.VRChat[71]hasbecomeapopularsocialplatformforonline 2 RELATEDWORK
interactionsinavirtualenvironmentwithover48kdailyactive
2.1 SupportingSituatedLanguageLearningin
usersand8˜.8milliontotal.Thoughnotspecificallydesignedfor
VR
foreignlanguagelearning,playerstakeadvantageofitsimmersive
environmenttohaveauthenticconversationexperienceswithna- Situatedlearningtheoryisgroundedintheunderstandingthatthe
tivespeakers[51].Previousresearchhasshownsocialinteractions mosteffectivelearninghappensincontext.Learningcanneither
inVRtobepositiveandhelpfulforlearningaforeignlanguage beseparatedfromthespecificsituationsinwhichitoccursnorbe
[16,57].Meanwhile,playersencounternumerousobstacleswhen transferredorappliedfullyinaschoolsetting[7,43].Inlanguage
undertakingsuchendeavors.Forexample,itcanbedifficultand acquisition,anauthenticcontextprovideslearningopportunities
time-consumingtofindanativespeakertointeractwith;andeven thatcloselysimulatereal-lifesituationsandincludesculturalnu-
whenfound,nativespeakersmaynotbewillingorsuitabletoactas ancescrucialformeaningfulandengaginglanguageuse[42],for
languagetutors.Moreover,usersmayexperienceincreasedsocial example,discerningthenuancesandsubtletiesofwordusagein
anxietyduringthesearchandinteractionandoverallthelearning polysemoussituations[75].
experienceisdeemedtobeunsystematic[34,62]. TheimmersivenatureofVRisparticularlysuitableforcreating
TherecentemergenceofLLM-basedembodiedconversational arealisticlanguagelearningenvironmentandsimulatinginterper-
agents(ECA)insocialVR,suchasCelesteAI[39],hasreceived sonalinteractionsincontext-richscenarios.Since2013andthe
significantattentionfromVRChatusersbecausetheyconverseand expansionofaffordablehead-mounteddisplays[21,47],VRhas
behaveinhuman-likeways.Thispresentsanimmediateoppor- beenwidelyutilizedinmanyareasoftrainingandeducation[4,85].
tunitytoleverageLLM-agentsforlanguagelearninginsocialVR. WithinVR,3Dobjectsandavatarshavebeenusedtofacilitateem-
WhileLLMshavebeenexploredforvariouseducationalpurposes bodiedandcontextualizedlearningexperiences[12].Withrapid
[36], their application in language learning, especially in social advancementsinVRheadsets,learnersexperienceaheightened
VRcontexts,remainsunderexplored.Tothatend,wepresentour senseofpresence,increasedagency,andembodimentthatsupport
effortstoanswerthefollowingresearchquestion(RQ):Howcan learningcomparabletolearning-by-doinginthephysicalworld
weleveragesituatedlearningandanLLM-basedECAforlanguage [35].
learninginsocialVR? AgrowingbodyofliteraturehasinvestigatedtheusageofVR
WebuiltELLMA-T,anembodiedLLM-agenttoexplorethepo- forEnglishasforeignlanguage(EFL)learning,specificallyhow
tentialofusingLLMsandsituatedlearningframework[7,43]to VRenvironmentscanbeusedfordifferentlanguagelearningtasks
facilitatelanguagelearninginsocialVRandconductedauserstudy [21,38,48].ResearchindicatesthatVRisbeneficialforvocabulary
(N=12)withELLMA-Tusingsemi-structuredinterviews.Bylever- acquisition,communicationskills,andwritingskills[42].Other
aginganLLM-basedagentinVRChat,thesystemaimstoprovide benefitsofusingVRforEFLlearningincludeincreasedlearners’
anauthenticconversationexperienceandpersonalizedfeedbackto motivation,engagement,enjoyment,automation[21,42,50],and
users,enhancingthecontextualizedlanguagelearningexperience. reducedanxiety[26].EFLlearningusingVRcanalsobenefitkids
Thecontributionswepresentinthispaperarethefollowing: withcomplexneedsandlow-achievingstudents[42].ELLMA-T:anEmbodiedLLM-agentforSupportingEnglishLanguageLearninginSocialVR Preprint,September2024,
Researchershavegeneratedseveralstrategiestoenhancelearn- ECAs,openingupdesignopportunitiesformoredynamic,interac-
inginVRbycontextualizationandextendingmemoryretention. tiveECAs.
Thesestrategiesincludeinteractingwitha3Dobjectforvocabu-
laryunderstanding[25,29],completingtasksinreal-lifescenarios 2.3 PotentialofLLMs&LLM-agentsfor
[74],problem-basedlearning[13],andintegratinglearninginto LanguageLearninginSocialVR
narrativeorthroughgamification[14,29,64].Inaddition,theuse
Previousnaturallanguageprocessing(NLP)techniqueshadbeen
ofavatarsinVRhasbeenshowntosupporthuman-to-humancol-
appliedtoEnglishlanguagelearningtools,whichusuallyrequire
laboration,andenhanceasenseofcommunityduringthelearning
templatesorusepre-scriptedgoal-orientedscenes[67].Previous
experience[10,31,57].Theuseofavatarsmayinparticularsupport
(E)CAs’responsesregardinglanguagelearningandfeedbackalso
oftenoverlookednuancesoflearninglanguagessuchastherole
remainedlimited[83].Thislimitationwasliftedwiththerecent
ofgesturesthataccompanyspokenlanguage.Forexample,[14]
development of LLMs and their content generation ability that
showedhowlanguageusageandbodymovementareintegratedto
extendsbeyondlanguagetasks[79].Inadditiontolanguagegener-
teachlearnersinterculturalnuances,suchasthepracticeofgreet-
ationtasks,LLMscanbeleveragedforgeneratingECAs’3Davatars
inginJapanesewhilesimultaneouslybowing,demonstratinghow
[27],controllingmotion[60],generatingmotionandfacialexpres-
verbalandnon-verbalcuesworktogetherincommunication.
sions[52],anddrivingECA’sbehavior[41,52].MultimodalLLMs
havethepotentialtounderstandthevirtualenvironmentandthe
objectsinit[73],forevenmorecontextualizedlearning.
2.2 EmbodiedConversationalAgentsfor While the number of discussions around the usage of LLMs
LanguageLearning isgrowing,particularlychatGPTforeducationacrossdisciplines
[36],fewerstudiesfocusontheuseofLLMsforlanguagelearning.
ManyVRlanguagelearningapplicationsinvolveembodiedconver-
PreviousstudieshaveexploredtheuseofLLM-basedchatbotsin
sationalagents(ECAs)intheenvironment.AnECAisadigitally
academicsettingsforEFLfortaskslikegrammarcorrectionandes-
animated character capable of engaging in natural, human-like
saywriting[44,82].Inarecentstudy,[9]examinedtheuseofLLMs
communicationwithusers[11].AsCassellstates,anidealECAis
inlanguageteachingandassessment,includingtheassessmentof
describedasbeingabletoconductahuman-to-agentconversation
generatedcontent,calibrationofexistingteachingmaterials,auto-
inawaythatmimicshumanface-to-facecommunicationsothat
matedassessmentoflanguagelearners,andprovidingfeedback.[9]
it feels believable. Many other features have been discussed for
reviewofLLMsbesidesGPTsuggeststhatalternativemodelsfor
thedesignoftheECAssuchastheuseofverbalandnon-verbal
contentgenerationmaybeabetterchoiceduetotheirmultilingual
cues,multimodalcommunication,appearanceandvisualization
capabilitiesandtheirgeneralavailabilityasopen-sourcemodels;
[11],andcarefullycraftedpersonalitytraits[69],allaimingtoin-
yet,forothertaskslikeprovidingfeedbacktolanguagelearners,
creaseagentcredibility.Inrecentstudies,ECAsareincreasingly
theusageofGPTmodelsisstillpromising.
consideredassocialagents[2],designednotonlytointeractbut
DespitetheadvancementsofLLMs,theuseofLLM-basedECAs
alsotounderstandandadapttothesocialandculturalcontextsof
inlanguagelearningapplicationsremainsrelativelyunderexplored.
theuser.
Recentstudieshavebeguntoexplorehowpersonalityexpression
RecentstudieshavenotedthatECAs,despitetheirpotential,of-
andembodimentinLLM-basededucationalagentsimpactlearn-
tenfallunderthebroadercategoryofchatbots,whichlackaunified
ingoutcomes[66].Yet,thereremainsagapinunderstandingthe
conceptualframeworkandtypicallydonotincludeavirtualbodyor
complexityoffactorsthatinfluenceLLM-basedagent-supported
multimodalprocessingabilities[33].Meanwhile,muchresearchhas
languagelearninginsocialVR.Toaddressthisgap,weexplore
focusedonthedesignanduseofconventionalchatbots(noembod-
thedesignandintegrationofLLM-basedECAsintosocialVRfor
iment)forlanguagelearning,buttheexplorationofECAsremains
contextualizedlanguagelearning.
limited.Earlyefforts,suchasthosebyWikandHjalmarsson[74],
employedhumanoidagentstoperformdifferentlanguagelearning 3 SYSTEMDESIGN
tasks,demonstratingsuccessacrossdiverseculturalbackgrounds.
OursystemimplementsanLLM-basedagenttoassistlearnersin
Divekar*etal.[23]alsousedhumanoidagentstomimicreal-life
practicingspokenEnglishwithinasocialVRenvironment.The
scenarios,specificallynon-dyadic(multiple-people)multi-modal
agent(ELLMA-T)engageswiththeusersinrole-playconversations
conversations.Morerecentstudieshaveshownthatlearnerscan
based on real-life scenarios, providing interactive and adaptive
developstrongemotionalbondswithECAs,leadingtoincreased
languagepracticeinVRChat.Intheproceedingsection,wediscuss
motivationandpositivelearningoutcomes[32].[78]demonstrating
our design principles based on education theory, learning task
alsoapositivecorrelationbetweenlearners’strongaffectionfor
design,andsystemimplementation.
agents’appearancesandimprovedlearningoutcomes.
Despite the potential of ECAs for simulating human-like be-
3.1 DesignPrinciples
haviour,muchoftheexistingresearchonECAsforlanguagelearn-
ingfeaturesECAswithminimalinteractiveabilities[23,32,74]. Webasedthefollowingsystemdesignprinciplesonpriorresearch
TheseECAsareoftenrestrictedtobasicfunctionslikelip-syncing, involvingadditionallanguagelearningregardlessofthelearner’s
andlimitednon-verbalgesturesandexpressivebehaviourdueto ageoracademicstatus:
technologicalconstraints.Therecentadvancementsinlargelan- (1) Student-centeredlearning,withthesystemdesignedto
guagemodels(LLMs)providenewtechnologicalcapabilitiesfor fiteachlearner’suniqueneeds[20];Preprint,September2024, MengxuPan,AlexandraKitson,HongyuWan,andMirjanaPrpa
(2) Thelearningmaterialfollowstask-orientedlearning,mean- to as long as the learner continues speaking on the topic. The
ingthelearnerneedstocompletealearning-relatedtask agentmakesthejudgmentifithaslongenoughinputtoassessthe
ratherthanengaginginnon-task-basedcasualconversations learner’sspokenlanguage.Iftheuser’sinputisnotlongenough,
[61]; theagentasksfollow-upquestionsandencouragesthelearnerto
(3) Thesystemfocusesonprovidingemotionalsupportto speakmore.OnceELLMA-Tdecidesithasenoughinputfromthe
encouragelearning,amajorfactorinsustainingcontinuous learner,itassessesthelearner’sspokenlanguageproficiencyand
learningforlanguagelearners[22]. givesaresultfromA1toC2basedonCEFRcriteria[18].
WebuildontheneedsforsupportingadultEnglishlanguage
3.2.2 DesignPrinciple#2:Role-PlayTopicGenerationandConver-
learningputforthbyAdjagbodjouandKaufman[1]:(a)dailycon-
sationContinuation. PresentingScenarios:Uponknowingtheuser’s
versationalneedsthatarecontextualized,(b)toolsthataddressboth
proficiencylevel,ELLMA-Tpresentsthreedifferentrole-playsce-
linguisticandemotionalneeds,and(c)long-term,contextuallysit-
nariosfocusingonvariousthemesrelevanttodailylife.Theuser
uatedlearningexperiences.Thoughthissystemisdesignedwith
canchoosethescenariothatmostintereststhemorsuggestaspe-
adultlearners’needsinmind,ourgoalistoscalethesystemfor
cificscenariothey’dliketopractice.Onceascenarioischosen,
differentusergroupsofvariousages.First,weemphasizecreating
ELLMA-Tprovidesadetaileddescriptionofthescene,outliningthe
animmersiveenvironmentwithanembodiedagentinVRtosimu-
physicalsurroundingsandsignificantobjects.InVRChat,various
latereal-lifeconversationexperiences,addressingneed(a).Second,
virtualworldsreplicateeverydaysettingslikecafes,restaurants,
weexploredifferentcommunicationstrategiesandchannelsthat
outdoors,andsupermarkets(seeFig.3).Onceascenarioisselected,
addresslearners’emotionalneedsusingLLMs’languageabilities,
theuserandELLMA-Tcanbetransportedintoacorresponding
addressingneed(b).Third,weuseVRChatasafreeandeasilyac-
virtualenvironment.ELLMA-Tpromptstheusertocompletetasks
cessibleopensocialplatform,whichprovidesarichspaceforusers
withinthescene.Forexample,inasupermarketsetting,theuseris
toconnect,formcommunities,andpotentiallypursuecollaborative
askedtofindordescribespecificitemsandpracticethevocabulary
learningopportunities,addressingneed(c).
learned.
TakeTurnsConversations:ELLMA-Tandthelearnerengagein
3.2 LearningEnglishwithELLMA-TinVRChat
turn-takingconversationstocompletetherole-playscenario.Act-
The workflow (see Fig. 2) starts with ELLMA-T asking for the ingastheuser’spartner,theagentfostersnaturalandauthentic
learner’sinformationandassessingtheirlanguagelevel.ELLMA-T dialoguewithinthechosenscenario.Theconversationtopicand
thengeneratesaconversationscenariospecifiedbythelearner taskdesignfollowtheexampleoflessonplansofBritishCouncil
oroffersthreescenariosforthelearnertochoosefrom.During EnglishTeachingLessonsforadultlearners[19].Ineachscenario,
role-playconversationpractices,ELLMA-Tactsasthelanguage ELLMA-Tassumesarolesuchasarestaurantserver,cashier,doctor,
practicepartner,playingthecharacterinthesceneandproviding orfriendlyNewYorkeronthestreet,allowingtheusertoconduct
scaffoldingwhenneeded.Aftertherole-play,ELLMA-Tprovides conversationsthatmimicreal-lifesituations.
feedbacktothelearnerbasedontheconversationintherole-play. ProvidingFeedback:Aftertherole-play,theagentprovidesfeed-
Thelearnercanendtheconversationorswitchtoanotherrole-play back to the user, consisting of three parts. The first part offers
atanypointintheconversation.Informedbyourthreedesign generalfeedbackthatevaluatestheuser’sperformanceconcerning
principles,wedesignedELLMA-T’slanguagelevelassessment,con- thedifficultylevelofthechosenscenario,highlightingonestrength
versationlearningmaterials,andcommunicationstrategy,which andoneareaforimprovement.Thesecondpart,"AdviceMoving
weregeneratedbytheLLMontheflyusingpromptengineering Forward", provides practical tips on how to apply the concepts
(seeSection3.3). learnedintheconversationtoreal-worldsituations.Lastly,ELLMA-
Tsummarizesthekeyvocabulary,grammar,orsentencestructures
3.2.1 DesignPrinciple#1:IntroductionandLanguageLevelAssess-
encounteredduringtheinteractionfortheuser’sfuturereference.
ment. Introduction:ELLMA-Tinitiatestheconversationbyintro-
ELLMA-Tremainsavailabletoanswerfurtherquestionsorengage
ducingitselfasafriendlyandculturallyawarelanguagepartner.
inadditionalpracticesessions.
Itgathersinformationfromtheuserthroughopen-endedques-
tionsabouttheirname,culturalbackground,motivationtolearn 3.2.3 DesignPrinciple#3:CommunicationStrategyandBack-channels.
English,andanyadditionaldetailstheywishtosharetoforma EFLlearnersoftenencountercommunicationbreakdownsdueto
senseofpersonalconnection.Forexample,ELLMA-Tgreetsthe insufficient vocabulary or incorrect grammar usage, which can
learnerintheirnativelanguageandacknowledgestheircultureand negativelyaffecttheirself-confidenceandmotivation.Oursystem
personalexperiences.Duringthefirstfewroundsofconversations, buildsuponthecommunicativeandscaffoldingstrategiesby[3]
thelearnergetsfamiliarwiththeagentandtheVRenvironment. thatmayincreaselearner’swillingnesstospeakindesigningEm-
LanguageLevelAssessmentTask:Next,ELLMA-Tgivesthelearner bodiedConversationalAgents(ECAs)forspokenEnglishpractice.
atopictospeakabouttoassessthelearner’scurrentlevelofEnglish MitigatingCommunicationBreakdowns:Toaddresscommunica-
proficiency.Thetopicandtheformatofthefreespeechassessment tionbreakdowns,ELLMA-Tprovidesencouragementtomotivate
followtheformatofanIELTS[30]speakingtest.WhereasIELTS theusertocontinue("Comeon,don’tgiveup!");orsuggestsphrases
isamoreformalconversation,inoursystemtheassessmentisa tohelptheusermoveforwardintheconversation("Maybeyou
casualconversation.Inthefollowinglearningsession,ELLMA-T cansay...").Whentheuser’sspeechisunclear—whetherdueto
adjustsitslanguageandtopicdifficultyaccordingtothelearner’s incorrectvocabulary,grammarmistakes,ormispronunciation—
proficiency.Thelengthofthefreespeechvariesfrom30seconds ELLMA-TposesclarifyingquestionstopromptfurtherdialogueELLMA-T:anEmbodiedLLM-agentforSupportingEnglishLanguageLearninginSocialVR Preprint,September2024,
Figure2:WorkflowofconversationtasksperformedbyELLMA-T,includinggreetingtheuser,conductinglanguageassessments,
engaginginrole-playscenarios,andprovidingfeedback.
Figure3:ELLMA-TindifferentvirtualworldswithinVRChat:anindoorcafé(left)andanoutdoorcity(right).
("Youjustsaid...,doyoumean...?").Thisapproachfostersasup- responseisconvertedbacktoAudiousingtheOpenAITTSservice
portivelearningenvironmentthatencouragesuserstopractice (the’alloy’voice)[54].Theuserspeechdetectionandsilencedetec-
speakingwithoutfearofimmediatecorrection. tionaredonebyusingSounddeviceLibrary[58]andVosk[59].We
usea2.0-secondsilencethresholdtodetecttheendoftheuser’s
3.3 SystemImplementation input,balancingthebuffertimeforuserstopauseandcontinue
speakingwiththeoverallwaittimefortheagent’sresponse.
3.3.1 System Architecture. The agent design in this project ex-
Thesystemcanalsogeneratefacialexpressionsandbodyges-
tendedtheworkby[72]whichimplementsgeneralECAinVRChat
turesbasedontheuser’sinput.TheLLMdetectstheuser’semotion
andimprovestheresponsecontext-relevancebyaddingamem-
bykeyworddetectionandthenmirrorsthatemotionbymapping
orytotheagent.Basedonthisimplementation,weaddedatutor
correspondingbodymovementsandfacialexpressions.Thehistory
workflowlogic(seeFig.2)thatcontrolstheconversationflow.
ofthecurrentconversationsessionisstoredinalistofJASON
ThelearnercontrolsanavatarinVRChatthroughaQuest3
objectsfortheagentastheshort-termmemoryandreferenceto
headset,abletomakebodymovementsandtalktoELLMA-Twith
generatemorerelevantconversations.Thekeyinformationofthe
themicrophone.AsillustratedinFig.4,theaudioinputiscon-
currentconversationsessionissummarizedbyLLMandstoredin
vertedintotextbycallingWhisperAPI[55],andthenatextreply
aremotedatabase.Thebackendoftheagentisintegratedinto
isgeneratedfromtheGPT4modelbycallingOpenAIAPI.ThetextPreprint,September2024, MengxuPan,AlexandraKitson,HongyuWan,andMirjanaPrpa
Figure4:SystemArchitectureoftheELLMA-T.Thearchitecturehighlightsthecorecomponentsanddataflowwithinthe
system.
VRChatthroughVRChatOSC[70].Additionalanimationforagent independently,withtheLLMgeneratingresponsesbasedonthe
gesturesandfacialexpressionscanbeaddedtoUnity[68]andthen specificcontextofthatsubtask.Althoughthisintroducessome
incorporatedintoVRChatthroughVRChatOSC[70]. variability in the conversation due to the inherent randomness
ofLLM-generatedtext,theoverallstructureremainsintact,lead-
3.3.2 Multi-taskMulti-turnConversationSystem. Indesigningand ingtomorecoherentandeffectiveinteractions.Thisapproachis
implementingamulti-task,multi-turnconversationalagent,ween- supportedbyrecentdevelopmentsinthemulti-agentsystemfor
counteredachallengethatnecessitatedashiftfromasingle-prompt complextaskdialoguesystems,whichsuggeststhatbreakingdown
approachtoamorestructured,multi-taskapproach.Ouragentwas complextasksintomodularcomponentscansignificantlyimprove
taskedwithmanaginganentireconversationinvolvingmultiple systemperformance[77].
stepsanddecisionpoints,forexample,whentomovefromthein-
troductiontotheassessmenttask,howlongtheassessmentshould 3.3.3 PromptEngineering. Effectivepromptengineeringiscrucial
be,howtomoveontothenexttopic,etc.,withinaninteraction forguidingLLMslikeGPT-4inperformingspecifictaskswithina
session.Initially,weexperimentedwithasingle-promptapproach, conversationalsystem.WhiletherearemanywaystopromptLLMs
wherein the system prompt, we listed out all the steps and the [63],thereiscurrentlynostandardizedworkflowfordevelopingthe
criteria the agent should follow as systemprompt inAppendix "perfect"prompt,aspromptdesignofteninvolvesatrial-and-error
A.1.However,weobservedthattheLLMstruggledtofollowthe process[81].Ourapproachtopromptengineeringwasiterativeand
stepsinthesingleprompt.TheLLMoftenconfusedthesequenceof exploredLLM’scapabilitiesunderzero-shotorfew-shotconditions
actions,misinterpretedwhenonetaskshouldconclude,andwhen [8]tofacilitatelanguagelearning.
totransitiontothenext,orrandomlyrestartedacertaintask.This
ledtoabreakdowninthelogicalflowofconversations,thusnot 4 USERSTUDY
idealforuserstointeractwith.Thisobservationalignswithemerg- 4.1 StudyDesign
ingfindingsinthefieldofLLM-basedagents,wheremaintaining
To explore participants’ experiences with ELLMA-T within the
contextandmanagingmulti-turninteractionsremainchallenging,
VRChatenvironment,weconductedaqualitativestudyusingsemi-
particularlyincomplex,multi-steptasks[80].
structuredinterviews,andthematicanalysistoanalyzethedata.
Asanalternative,weadoptedamulti-taskimplementationstrat-
ThestudyaimedtoexploretheopportunitiesandchallengesinLLM-
egy(seeFig.5.Thecoreideabehindthisapproachistodecom-
basedagent-supportedlanguagelearninginasocialVRsetting.
posetheoveralltaskintosmaller,simpler,andmoremanageable
Ourstudyfocusesonoverallinteractionexperience,preferences
subtasks.Eachsubtaskisthenhandledbyaseparatelyprompted
forsystemusage,andfeedbackforfutureimprovements.Thisstudy
instanceoftheagent(seeAppendixA.2),allowingforgreatercon-
wasapprovedbytheuniversity’sethicsboard.
trolandreducingthecognitiveloadontheLLMatanygivenpoint.
Thisstrategyshiftstheburdenofmaintainingdeterministiclogic
4.2 ParticipantsandSetting
fromtheLLMtothesystemdesigner,whopredefinesthesequence
andstructureofsubtasks.Bydoingso,weensurethattheagent Forthispreliminarystudy,werecruited12internationalgradu-
cannavigatethroughcomplexinteractionswithoutlosingtrack atestudents(Table1)from[UniversityNameremovedforblind
oftheconversation’sbroadercontext.Eachsubtaskisexecuted review]bypostingrecruitmentadsviacampuscommunicationELLMA-T:anEmbodiedLLM-agentforSupportingEnglishLanguageLearninginSocialVR Preprint,September2024,
Figure5:StructureofSeparatePromptsforDifferentTasks.Thisdiagramillustrateshowpromptsarestructuredandseparated
forvarioustaskswithinthesystem.1)Thesystempromptestablishestheagent’spersonaacrossallinteractions.2)Task-specific
promptsguidetheagentduringtheintroduction,languageassessment,role-play,andfeedback.3)Adecisionprompthelpsthe
agentdeterminewhentotransitionbetweentasks.4)Thepromptforprovidingscaffoldingduringrole-playconversations.
channels.Despitemeetingtheuniversity’srigorousEnglishlan- inpracticalscenarios,suchassocialinteractionsandworkplace
guagestandards,withaminimumIELTSscoreof7.5,thesestudents communication.
continuetoencounterlinguistichurdlesintheirday-to-daylives
and work environments. To that end, our participants were se-
lectedasapotentiallyrepresentativesampleofapopulationwith
mixedEnglishproficiencieswhoaimtoenhanceoralproficiencyPreprint,September2024, MengxuPan,AlexandraKitson,HongyuWan,andMirjanaPrpa
Table1:ParticipantInformation
ParticipantID Gender CulturalBackground LanguageProficiency MotivationtoLearnEnglish
P1 Male China Fluent Toimprovelanguageskills
P2 Male India Fluent ForworkinCanada
P3 Male China Fluent Toenhancecommunicationskills
P4 Female China Basic ToimprovespokenEnglish
P5 Female China Intermediate ForworkandstudyinCanada
P6 Female China Intermediate Toenhanceproficiency
P7 Female China Intermediate ToimprovebusinessEnglishskills
P8 Male Bangladesh VeryFluent Toachieveadvancedproficiency
P9 Female Taiwan Basic ForworkandstudyinCanada
P10 Female China Basic Forjobinterviewpractice
P11 Male China Intermediate ToimprovebusinessEnglishskills
P12 Male China Fluent ForworkinCanada
4.3 Procedure taken during the interactions (step 4). Finally, all themes were
Thestudywasconductedinpersonatthe[Universityremovedfor discussed and defined by three researchers/coders (step 5) and
blindreview].Uponarrival,participantsreceivedabriefoverview writtenup(step6).
ofthestudy.Theywereinformedthattheywouldinteractwithan
5 FINDINGS
AIagentactingasanEnglishlanguagetutorusingaMetaQuest
3headset.ForparticipantsunfamiliarwithVR,weprovidedin- Inthissection,wedescribefourkeythemes:agentperceptionand
structionsonhowtoweartheheadsetandnavigatetheVRChat itsroleinsocialVR,languagelearninginsocialVR,taskdesignand
world.Thesetupwaspre-configuredtoensureaseamlessexperi- perceptionsofLLMsefficientinlanguagelearning,andinterestin
ence,allowingparticipantstobypassnavigatingmenusorlearning continuedusage.
controls.Onceequippedwiththeheadset,participantswerein-
structed to start recording their interaction with the ELLMA-T 5.1 AgentPerceptionanditsRoleinSocialVR
fromtheirPOV.Theagentwasoverseenremotelybyaresearcher
5.1.1 ELLMA-THuman-likequalities. Participantscomparedtheir
whoalsoprovidedtechnicalsupport.Theinteractionlasted1˜5min-
experiencewithELLMA-Ttothatofconversingwitharealhuman
utes:introductionandassessment(5mins),role-playandfeedback
tutor.Participantsfrequentlycommentedontheagent’shuman-like
(7mins).Wesavedtheconversationlogsbetweeneachparticipant
qualities,notinghowtheinteractionfeltlikeconversingwithareal
andELLMA-TasCSVfilesforfurtheranalysis.Followingthein-
personratherthananAI.AsP4expressed,"Ilovethewayittalk(s)
teraction,participantstookpartina30-minutesemi-structured
tome.It(is)justlikearealteacher;theinteractionisreallygood."
interviewconductedbyoneoftheauthorsexperiencedinqualita-
Participants highlighted that the conversation flowed naturally,
tivemethods.Interviewswereaudio-recordedwithaniPhone12
demonstratingELLMA-T’sabilitytolisten,understand,andrespond
andtranscribedinNVivo14foranalysis.Theinterviewsgathered
appropriately. For example, P8 appreciated that the agent "was
qualitativedataonparticipants’overallexperience,comfortlevel,
listeningtome,"suggestingthatitrespondedinawaythatrelated
engagement,frequencyofpotentialuse,andpreferencesforusing
totheirpersonalexperience.P2alsoobserved,
thesystemindifferentsettings(e.g.,groupvs.individual;headset
"Firstofall,itstartedoffwiththeculturalexperience.
vs.desktopapp).Follow-upquestionswereaskedasnecessaryto
SothenthemomentImentionedthatI’mfromIndia,
probedeeperintoparticipants’responses,particularlywheninitial
thegreetingchangedfrom’Hello’to’Namaste,’whichis
answersdidnotfullyaddresstheintendedtopicsordirections.The
like’Hello’inHindiinourlanguage.Sothat’Namaste,’
completelistofinterviewquestionscanbefoundinAppendixB.
thataddedapersonaltouch.Thenittriedtounderstand
howyoufeelinday-to-dayconversations."
4.4 Analysis
Thisabilitytopersonalizetheinteractionandsubsequentconver-
Weemployedaninductive(bottom-up)approachtoanalyzethe
sationflowledP2toconclude,"It’slike...I’mtalkingtosomeonein
interviewtranscripts,followingthethematicanalysisguidelines
person,soit’snotanAIformerightnow."
byBraunandClarke[6].Theanalysiswasconductedinseveral
stagesbythreeresearchers,allauthorsofthepaper.Initially,each 5.1.2 ImportanceofAdaptabilityandRoleSwitchingDependingon
researcherreadoveralltheinterviewtranscripts(step1),andthen PersonalPreferencesandSocialContext. Participantsexpressedvar-
independentlyanalyzedasub-setoftheinterviewtranscriptsto iedpreferencesregardingELLMA-T’sroleinfacilitatinglanguage
identifypreliminarycodes,themes,andpatterns,selectingrelevant learning.Somepreferredtheagenttotakeonatraditionalteacher
quotes and observations (step 2). The team then discussed and role,similartothatofaclassroomsetting.Forinstance,P1sug-
agreeduponafinalsetofcodesthroughmultipleroundsofcoding gested,"Theagentcouldbeliketheteacher,andthentheotherpeople
(step3).Toensuretherobustnessofouranalysis,theinterview wouldbestudents.Ikindofstillfeellikethat—bemoretraditional,the
transcriptswerecross-referencedwithvideorecordingsandnotes agentastheteacherandtheheadofaclassroom."OthersenvisionedELLMA-T:anEmbodiedLLM-agentforSupportingEnglishLanguageLearninginSocialVR Preprint,September2024,
theagentinamoresupportiverole,actingasafacilitatororsocial identityandthepotentialforscenario-basedadaptationsofthe
glueinmulti-personinteractions.P5imaginedthisroleashelping agent’s personality and appearance. P12 mentioned "I think for
tobridgegapsinconversations:"Andalsotheycanfillthegap.Okay, differentscenarios,wecanhavechangesinpersonalityorchangethe
whatiftwopeopleareintrovertsandtheyprobablydon’thavemuch avataritselftosimulatedifferentenvironmentsandhowdifferent
incommontotalkabout,theAIagentcouldaskquestionsorleadthe peoplespeak.Thatwouldmakeadifference,Ithink."
conversation."Additionally,someparticipantssawtheagentasa
feedbackproviderduringreal-humanconversationpractices.As 5.1.4 FreeingInteractionsofSocialNormsthatDoNotApplytoAI.
P6noted,"Youcanhaveaconversationwitharealpersonandlearn Allparticipantsfoundtheagentapproachableandcomfortableto
fromwhattheysaid,withthefeedbackprovidedbytheagent." interactwith.Onesignificantadvantagenotedwastheabsenceof
socialpressureorexpectationstiedtoculturalorsocialnorms.P5
5.1.3 PerceptionsofAgentTone,Appearance,andBehaviour. We
highlightedthis,stating,
observedhownuancedperceptionsoftheagent’stone,physical
appearance,andbehaviourimpactedtheoverallinteractionexperi- "Youtalkwithaperson,andifyoudon’tproperlytell
ence. themcertainthings,youmighthurttheirfeelings.But
AgentTone:Someparticipantsnoticedthattheagent’slanguage ifanAIgivesyoufeedback,it’slike,oh,amachineis
tonewhenperformingdifferenttasksinfluencedtheirlearningex- tellingyouthefeedback,soit’sokay.Theydon’thave
perienceandhowtheyperceivedtheagent.Forexample,P6noted thosethoughtslike,oh,whatifIhurtthisperson’sfeel-
acleardistinctionbetweentheagent’stoneduringtherole-play ings?"
andwhengivingfeedback:"Iwouldhopethatthe(role-play)con-
versationismorecasual,butIexpectthefeedbacktobeprofessional." 5.2 LanguageLearninginSocialVR
P8highlightedtheimportanceofprovidingencouragingphrases
5.2.1 SituatedLearningSupportedbyVRAffordances. Participants
combinedwithanappropriatetone:
spokeabouthowtheirlanguagelearningwassupportedthrough
"Right now it’s very robotic, and so it just gives me VR’suniqueaffordances:3Dinteractivitywithobjectsandavatars,
basicfeedbackof...greatimprovement,butIlikedcer- contextualized learning in an immersive environment, and en-
tainthingsthatyoudid...shedidmentionthose,but hancedemotionalsupportthroughanembodiedagent.
itseemedvery...likeIwasjusttypingintoacomputer InteractiveLearning:ParticipantsdescribedhowbeinginaVR
andit’scomingout." environmentaddedsignificantvaluetotheirlanguagelearning
P8alsoaddedthatthelackofinflectionandtonevariationindiffer- experience.TheinteractivenatureofVRwasfrequentlyhighlighted,
entcontextscanmaketheagent’sinteractionsseemlessengaging withP1noting,"TheVRaddedtheinteractions.WhatIneedtodois
andlesshuman-like:"Ifyou’rehavingaconversation,therearenu- justspeak.Idon’thavetotype."Theenvironmentalcontextprovided
ancesonhowwespeakandcertainsounds...Theupsanddownsinthe byVR,alongwiththeembodiedagent,createdasenseofimmersion
waywespeak." thatmadetheinteractionfeel‘real.’AsP5shared,"IfeellikeI’m
AgentAppearance:Someparticipantsappreciatedtheneutral talkingtoakindofarealpersonstandinginfrontofme.Imean,it’s
appearance,asitdidnotdistractfromlearningorconveyjudgment. VRafterall.Sothat’sahugedifference."
P1remarked,"Thetoneoverallisgeneral.It’snottooaggressiveor ContextualizedLearning:TheVRenvironmentprovidedvalu-
too...Generalisgood;itdidn’tcreateaweirdoroddatmosphere." ablecontextforlanguagelearning,helpingparticipantsunderstand
However,otherspreferredmorepersonalityforfunandengage- howtouselanguageinreal-lifesituations.P8mentioned:"Forex-
ment.P10suggested,"Maybewecanjustusesomefamouscharacters ample,thebakery,it’llbeinthatplace.Wewalkbyit,anditwas
fromgames,literature,oranything,andwecansetuptheenviron- like,oh,thisisthebakery,andifyoucomehere,thenyoucanget
ment...anditwillbehaveandspeaklikethat."Severalparticipants thesetypesofsoups.Butit’llbeapplicabletomyreal-lifescenariosas
alsoexpressedapreferenceforcustomizingtheagent’sappearance. well."Similarly,P12emphasizedtheadvantageofhavingavirtual
Suggestionsfordifferentavatarsincludedrealistic(P11,P12),car- environmentthatcorrespondstothelearningtask:"Ithinkifwe
toonish(P3,P10),ornon-human-likeanimals(P6),aswellasthe canactuallyhaveacoffeeshelf,wherethereareespressomachines
abilitytomodifyattributeslikehaircolor,skincolor,bodytype, andeverything.Ithinkhavinganactualenvironmentwillmakethe
gender(P6),andclothing(P4). difference,andthat’stheadvantageofVR."
AgentBehaviour:Similartopreferencesfortoneandappearance, EmotionalSupport:Participantsalsodiscussedtheemotional
P7acknowledgedtheminimalmovementoftheagentasbeneficial connection they felt with the embodied agent in VR. P1 noted
for avoiding distractions from learning English. "I didn’t really thatVRaddedanemotionaldimensiontotheinteraction:"Itadds
lookathowhemoved...Ifeellikemaybeifaddontoomanymoves, emotions.Sohavingastaticor2Dagentjustlivingonascreen,itfeels
itcanbedistractingfromlearningEnglish."(P7)However,others likethere’slessemotionattachedtoit."Otherparticipantsmentioned
suggested that natural gestures, such as head nodding and eye howaddingpersonalitytotheagentinVRincreasedthesenseof
contact, would enhance engagement and create a more lifelike emotionalconnection.P7suggested,"Ormaybethey[peopleusing
interaction.P11stated,"Itshouldberepresentativeofhowpeople thissystem]needmoreemotionalsupport.Sothatmaybeagood
thinkofthemselves.Andthentheblinking,theheadnodding,itshould waytogivetheagentapersonality." P9andP11emphasizedthe
allbethereinsidetheVRenvironment."Additionally,participants importanceofaddingphysicalreactionsandbodylanguage,with
highlightedtheimportanceofculturalandcontextualfactors,such P9stating,"Maybemorephysicalreaction.LikesomebodyIreally
astheneedforconsistencybetweentheagent’svoiceandvisual talktoyouandlookingintoyoureyes,".Preprint,September2024, MengxuPan,AlexandraKitson,HongyuWan,andMirjanaPrpa
5.2.2 One-on-OneinteractionsalleviateSpeakingAnxiety,Group canbesuper,supersimpleforanativespeakerbecause
InteractionssupportSharedLearningExperience. Participantsex- theydon’treallyknow,oh,thisishardforanon-native
pressedvaryingpreferencesforinteractingwiththeagentinVR, speaker.Iwanttorespond.Whensomeonesayssome-
eitherinaprivatespaceorinagroupsetting.Participantsfeltthey thing,Icansaysomethinglike,’oh’,’amazing’,’abso-
wouldexperienceanxietyspeakinginfrontofotherpeopleand lutely’—thatkindofsimplewords.Itissomethingthat
preferredone-on-oneinteraction.AsP2articulated,"I’vehadthis canbesuperhardforme."
problem,andIknowmanyofmyfriendsalsohavethisproblem.They Participantsvaluedtheformofrole-playconversationforits
kindofget,whentheydon’thavetheirconfidenceoverthelanguage, abilitytoprovideareal-lifeconversationexperience.AsP7noted,
theykindofgetoverwhelmedandalittleintimidatedbybeinginthe "Becausetheconversationanddialogueisaboutdailylifecommuni-
group."Someparticipantspreferredone-on-oneinteractionbecause cationswhereyoucanlearnsomethingthatisusefulforyou,useful
theyvaluedthedirectinteractionandfeedbackfromtheagent.As foryoutolearnEnglish."
P10noted,"It’sone-on-one,soitcanassessmeanditcantargetmy Participantsalsosuggestedspecificscenariostheywouldliketo
weakness." practice,suchasrentinganapartmentasaninternationalstudent
Ontheotherhand,otherspreferredgroupinteractions,recogniz- (P10)orparticipatinginamockinterview(P6).
ingtheadditionalbenefitsofmoreengagement,peersupport,and
sharedlearningexperiences.VRChat,asasocialplatform,offersthe 5.3.2 AssessingtheLearner’sLanguageAbility. Themajorityof
flexibilityofchoosingavatarsandsocialmodes,whichcanenhance participantsfoundtheagent’sassessmentoftheirlanguageabili-
learningwithpeerlearners.P10suggested,"Ifweaslearnerscan tiestobeaccurateandconsistentwiththeirself-perceivedlevels.
interactwitheachotherinVR,thatwouldbefunbecausewewon’t Fiveparticipantsdescribedtheassessmentas"seemedappropriate"
careaboutwhateachotherlookslikeorwhereweare,andwecan (P11),"accurate"(P3,P8),"veryaccurate"(P4),and"fittomylevel"
focusonpracticing."Moreover,P7highlightedthepotentialreal-life (P9).Eveniftheassessmentresultswerenotcompletelyprecise,
benefitsofgroupinteractionsinVR,suchaspreparingforgroup therespondents’feedbacksuggeststhattheagent’sassessment
meetingsandworkenvironments,whichcannotbesimulatedby mettheirexpectations.P7,whilenotdirectlycommentingonthe
interactionwiththeagentalone: accuracyoftheassessment,founditusefulasaformofdescriptive
feedback:"Sheactuallygavemealevel,likeaB1,whichisquite
"Iwouldlovetohaveagroupsettingbecauseitmight
interesting.IfeellikeIalsowanttoknow,oh,whatkindoflevelI’m
behelpfulifyou’regoingtoworkorhaveagroupdis-
atandshegavesomedescriptionlike’youcandescribeyourfeeling’,
cussion.Inreallife,youhavetocatchupwithwhat
whichisagoodthing."
differentpeoplearetalkingabout.Soitmightbemore
AninterestingcasearosewithP10,whochosenottofollowthe
challenging,butitcanbefuntoo."
agent’sinstructionsandremainedsilentduringtheassessment.
5.3 TaskDesignandPerceptionsofLLM’s Consequently,theagentcategorizedherCEFRlevelasA1(basic)
[18],aresultshestronglydisagreedwith:"Ithasanagenda,soit
EfficacyinLanguageLearningTasks
wantsmetorepeatafterit.Idon’twanttodoit...(Theassessment
Thepotentialeffectivenessofthelearningexperiencewasacentral was)notveryaccurate.ItsaysI’mA1level,butatleastIthinkI’m
concernofparticipantsforthedesignofthesystem,particularlyin C1orC2."
termsoftaskdesignrelevance,assessmentaccuracy,conversation
content,feedback,andthesupportprovidedbytheagent. 5.3.3 RolePlayConversationContent. Therole-playconversations
providedbytheagentwerewell-receivedbyparticipants.ELLMA-
5.3.1 TaskDesignRelevance. Ouranalysisshowedthatthesys- Tshowedcreativityandadaptabilityingeneratingconversations,
tem’sabilitytoaddressthecontextualneedsoflearningspoken often performing well in various roles without requiring extra
EnglishforadultlanguagelearnersinEnglish-speakingcountries prompts.P3andP8bothdescribedtheirrole-playexperiencesas
wasarecurringtheme.Participantsacknowledgedthattheagent "surprisinglygood."Forexample,duringapaintinggalleryscene
effectivelytargetedspecificchallengestheyfaced.Onesignificant wheretheparticipantplayedtheroleofasalespersonandtheagent
challengehighlightedwasthelackofopportunitiesforlearningor played the customer (role-play conversation 1, see Table 2), P3
receivingfeedbackeventhoughtheyarealreadyinthelanguage foundtheexperiencehighlyengagingandrealistic:
environment,asP5explained:
"Itprovidesverypracticalscenariostohaveaconver-
"UsuallywhenyoupracticeyourEnglish,it’sjust...well, sation.Andalsothistutorcanreflectaccordingtomy
I’mstudyingherealreadyinaforeigncountry.Noone answer,becauseitrequiresabstractpainting.AndIsay,
willgivemetheirfeedback.Theycan’t,Ithink.Ido Icangiveyouaportrait.Andthey(theagent)say(s),I
knowthisisWesternculture.Peoplegivemorepositive don’tneedaportrait.Ineed(a)moreabstractone.So
feedback.Butthisone,itgavememorereality(realistic) that’sagoodpointIthink,becauseyoucanfeelthat
feedback.Youdon’tgetitinrealworld." youreallytalkwithaperson.Apersoncangiveyou(a)
Anotherparticipant,P5,emphasizedthegapininformalconver- correctreflection.Thatiswonderful."
sationlearning,whichisoftenmissingfromformalandacademic ThisexamplehighlightstheLLM’sabilitytoleverageitsvast
settings: pre-trainedknowledgetocreatevivid,realisticandimmersivecon-
"SomethingIreallywanttolearnaboutishowtouse versations,movingbeyondthedry,textbook-likeexchangesthat
Englishwhenyoutrytoagreewithsomeone’sidea.It oftencharacterizetraditionallanguagelearning.Theagent’sabilityELLMA-T:anEmbodiedLLM-agentforSupportingEnglishLanguageLearninginSocialVR Preprint,September2024,
toaddnuanceddetailsbasedontheroleandsituationenhances 5.4 InterestinContinuedUsage
therealismoftheinteractions.AsP8noted,"Yeah.It’snotjustthat 5.4.1 LikelihoodofContinuedUsage. Nearlyallparticipantsindi-
kindofdrybackandforth...Yeah,it’snotlikeanIELTSexamwhere catedthattheywouldusethesystemregularlytopracticetheir
youjustaskaquestionandgetananswer."Thisdynamicapproach languageskills,withusagetimesrangingfrom30minutestofour
bringsthecontextoftheconversationtolife,makingthelearning hoursdaily(P1,P2,P3,P6,P10,P12),oronetotwotimesperweek
experiencemoreengagingandeffective. (P7,P8).Someparticipantsnotedthattheywouldincreasetheir
usageifthephysicalfatigueassociatedwithheavyheadsetscould
bemitigated(P4,P8).Additionally,someparticipantsindicatedthat
5.3.4 FeedbackEffectiveness. Participantsfrequentlycommented theywouldincreasetheirusagewhenpreparingforspecificscenar-
ontheagent’sfeedbackasoneofitsmostvaluablefeatures.For iossuchasjobinterviews(P9).Thesefindingssuggestoursystem
example,P2appreciatedthespecificfeedbackontenseusage,stat- hasstrongpotentialforsupportingsustainedlanguagelearning
ing,"Sowithmytenses,iftherewasamistakewiththetenses,that’s overtime.
there.WhatcanIimprove,that’sthere.Thefeedbackwasabsolutely
correct.EvenIknowthatIgoofupinmytensessometimes." 5.4.2 FactorsNegativelyImpactingContinuedUsage. Despitethe
P7alsoemphasizedthebenefitofreceivingfeedbackoncommon positiveindicationsforregularuse,weidentifiedseveralchallenges
errorsmadebynon-nativespeakers:"Ifeellikeitimprovedalot relatedtotaskdesignandconversationflow,whichcouldcumu-
becauseusually,asnon-nativespeakers,wecan’treallytellwhen lativelyandnegativelyimpactlong-termusage.Oneparticipant
we’reusingthewrongtenseorwrongwords,buttheymentionitas highlightedhowtheresponselatencycouldbecomemoreproblem-
feedback.SoIfeellikeit’sreallyhelpful." aticovertime,noting,"Sothisseemstobeokay,butasthespeed
Despiterecognizingthevalueofthefeedback,participantsalso varies,thetransactiontime—sothetimethatIneedtospendwith
expressedadesireformorepersonalizedanddetailedresponses. theAI—willincreasemoreaspertheresponsetime"(P2).Addition-
Theysuggestedthatthefeedbackcouldbetailoredbasedontheir ally,breakdownsinconversationflowwerenotedwhentheagent
learninghistoryanduserprofile,withspecificexamplesofmistakes respondedtooquicklyoroccasionallyinterruptedtheparticipant,
andcorrections.P11pointedoutthat,"ForlearningEnglish,Ithink furtherdetractingfromtheoverallexperience.Participantsalso
thatAIisn’tgivingveryspecificresponses.It’sgivingverygeneral reportedissueswithtaskdesign,suchasuncleartaskexplanations
answers.Ifapersonwasactuallynormallylistening,thetutorwould oralackofconciseinstructionswhenswitchingtasks.
replywithanexampleofwhatIsaidwrongandthenrephraseitand ImportanceofShortandConciseInstructionsforLearning:
giveanexampleofwhatitshouldbe." Duringallthelearningsessions,participantsgenerallyfollowed
Additionally,whileoneparticipantfoundthefeedback"educa- ELLMA-T’sinstructions.Oneparticipantcommentedthatthein-
tional,"theyalsomentionedthatitcouldbetoolengthy:"Ithink structionswereclear,stating,"Alltherulesandregulations,allthe
thefeedbackissometimestoolongformebecauseitwillillustratea promptsthattheuserneedstofollowarethere"(P2).However,not
lotoffeedbackevaluation."Thissuggeststhatwhilecomprehensive allparticipantssharedthisexperience.Oneparticipantexpressed
feedbackisappreciated,thereisabalancetobestruckbetween panicandconfusionwhenstartingthesession,noting,"Ifeellike
thoroughnessandconcisenesstomaintainuserengagement. justhavingashort,precisedescriptionofthecontextwouldhelp.Ijust
couldn’tfigureoutwhatwasgoingon"(P1).Anobservationfrom
thevideorecordingssupportsthisconcern;ELLMA-Tsometimes
5.3.5 ScaffoldingEffectiveness. Theagentprovidedvariousforms providedinstructionsthatweretoolengthytofitwithinthechat
of support and encouragement throughout the sessions. Verbal window,makingthemdifficultforparticipantstofollow.Whenthis
cueslike"Youaredoinggreat!"and"Goodjobdoing[activity]..." occurred,participantsoftenhadtoaskELLMA-Ttorestatethetask,
wereconsistentlyusedtomotivateparticipants.Whenparticipants whichdisruptedtheflowofthesession.
struggledtogeneratedialogueduringrole-play,theagentoffered Latency-relatedConversationFlowBreaks:
scaffoldingbypresentingexamplesforthemtorepeat.AsP7noted, Latency was an issue in generating responses commonly as-
"Idolikethepartthatheactuallygavesomehint,’forexample...’, sociated with currently available LLMs. Participants frequently
’Oh,youcansaythat...’."Additionally,theagentaskedclarification mentionedthatthedelayinresponsetimemadeitcleartheywere
questionswhenthemeaningoftheuser’sinputwasunclearand interactingwithamachineratherthanahuman.Asonepartici-
providedexplanationswhenparticipantswereunsurehowtopro- pantnoted,"Theresponsetimeiswhatwillmakeyou...okay,you
ceed.P1describedaninstancewhere:"Sheaskedmetostraightup aretalkingtoamachinerightnow"(P2,P5).Anotherechoedthis
tellherthestoryaboutsomethingandIdidn’tquitecatchthatthe sentiment,"Ithinkhisfeedbackisalittlebitslower.SometimesIneed
firsttime.IaskedherwhataretheoptionsthatIhave.Andthenshe towaitforhisresponse"(P4).Thisdelayinprocessingleftpartici-
gaveoneandIlikedit." pantsfeelingdisconnectedfromtheconversation,ashighlighted
AninterestingobservationwasmadebyP12,whofoundthat byP10:"Itdoesn’tfeellikearealconversation.Therearegapsand
despitehavinganaccent,theagentaccuratelycapturedhisinput: silenttime."
"IthinkitcaptureswordsbetterthanIthoughtitwould.MaybeI Conversation-pacing-relatedFlowBreaks:Anothermajordis-
haveanaccentsometimes.Ididn’texpectittobethisgood." This ruptioncamefromtherigidturn-takingstructureoftheconver-
highlights a common communication challenge among English sation.Unlikehumaninteractions,wheretheremaybeoverlaps
languagelearners,whichpresentsasignificantdesignchallenge ofspeakingorlongpauseswhileturn-taking,ELLMA-Tstrictly
forthesystem. adheredtoturn-takingbywaitingfortheusertofinishspeakingPreprint,September2024, MengxuPan,AlexandraKitson,HongyuWan,andMirjanaPrpa
Table2:ExampleofRole-PlayConversationinPaintingGalleryScene
ELLMA-T[settingthecontextforrole-playconversations]:Solet’simagineweareinanartgalleryfilledwithbeautifuland
eclecticpiecesofart.YouareaknowledgeableandenthusiasticartcuratorandI’maninterestedbuyerexploringthegallery,
maybelookingforsomethingtospruceupmyhome.Theconversationcouldstartwithmewalkingintothegallery.Okay,
herewego.
EventLine InteractionContext Excerpt
1 Agent(Customer) Hellothere.Thisismyfirsttimevisitingthisgallery.Couldyou
showmeafewstandoutpiecesandtellmetheirstories?
2 User(Salesperson) Yeah.Canyoufirsttellmewhatkindofartworkyouwantto
buyoryou’relookingfor?
3 Agent(Customer) I’mveryinterestedincontemporarypaintings.Preferablysome-
thingvibrantandabstract.I’mlookingforapiecethatcouldbe
thefocalpointofmylivingroom.It’safairlylargespacewith
neutralcolors.
4 User(Salesperson) Canwelookatthisportrait?Thisportraitisaboutsomeone
whoisintherenascenceageandinthisportrait,youcansay
thebackgroundisinthedark,broadcolor.Andyoucansaythe
portraitisveryclearandthefaceofthepersonintheportrait
isverydynamicandactive.Andwhatdoyouthinkaboutthis?
5 Agent(Customer) Thecontrastbetweenthedarkbackgroundandthevividfacial
expressionmustcreateafantasticvisualimpact.However,Iam
moreinterestedinabstractartratherthanportraits.Doyou
haveanyabstractpieceswithbold,colorfulstrokes?
6 User(Salesperson) Yeah.Ifyouarelookingforsomeabstract.HowabouttheIm-
pressionism?
beforeresponding,anddidnotrespondtointerruptions.Thisof- connectionthroughembodiment,ademeanourthatisaccessible
tenledtointerruptionsandalackofresponsiveness.Forexample, andapproachable,andprovisionofencouragementandsupport.
twoparticipantsdescribedhow"TherewereafewtimeswhenI
intendedtospeak,butshejustcontinued"(P1),"InoticedIcouldn’t 6.1.1 EmulatingHuman-LikeInteraction. Oneofthekeystrengths
interrupttheagent.SometimesIfindithardtotellwhetherit’s ofELLMA-Tisitsabilitytoemulatehuman-likeinteraction,aqual-
my turn to speak." (P12). Others expressed frustration with the itythatparticipantsfrequentlynotedinSection5.1.1.Thepercep-
agent’sinabilitytoadapttotheirconversationalpace,withP7not- tionoftheagentas’human-like’suggestsELLMA-T’ssuccessin
ing,"Shedoesn’twaitformetospeak".Addressingtheseissueswill resemblingahumantutor’sabilitytomaintainaninteractiveand
beessentialforimprovingtheoveralluserexperienceinlong-term meaningfulconversation.Thisfindingsupportspreviousresearch
languagelearningandmakingtheagentfeelmorelikeagenuine thatunderscoresthesignificanceofECAsmimickinghuman-to-
conversationalpartner. humaninteractionsandhighlightsthecriticalroleof’believable’
interactionsinconversationsystemdesignwithECAs[11].Asour
6 DISCUSSION findings inSection 5.1.2 indicate, ELLMA-T is seen in the roles
typicallyfulfilledbyhumanssuchasatutororabuddy.Specifically,
Toaddressourresearchquestion,wecontextualizeourfindings
participantsappreciatedhowtheagentcouldlisten,understand,
withpriorliteratureanddiscussthepotentialofembodiedLLM-
andrespondappropriately,makingthelearningexperiencefeel
basedagentsforlanguagelearninginsocialVRinthefollowing
morenaturalandlessmechanical.
sections.Wefirstdiscussthekeyqualitiesreportedbyparticipants
of ELLMA-T to support English language learning; second, the
6.1.2 EnhancingAgent-LearnerEmotionalConnections. Existing
advantagesofsituatedlanguagelearninginsocialVR;andthird,
literaturesuggeststhattheembodimentofanagentinlanguage
the benefits and challenges of embodied LLM-based agents for
learningenhancestheimmersiveexperienceandstrengthensthe
languagelearninginsocialVR.
emotionalconnectionbetweentheagentandthelearner,which
positivelyimpactslearningoutcomes[45].Ourfindingsinsection
6.1 UserExperienceofELLMA-TforSupporting
5.2.1supportthis,asparticipantsreportedfeelingastrongeremo-
EnglishLanguageLearning
tionalconnectionwitha3DembodiedagentintheVRenvironment
Overall,ourfindingsindicatethatELLMA-Tpossessesseveralkey (P1,P6).Furthermore,thedatainsection5.1.3suggeststhatadding
qualitiesthatalignwiththeexistingliterature’scriteriaforaneffec- personality,personalizedtone,appearance,andbodymovement
tivelanguagetutor:human-likeinteraction,enhancedemotional to the ECA can further enhance this emotional connection (P7,ELLMA-T:anEmbodiedLLM-agentforSupportingEnglishLanguageLearninginSocialVR Preprint,September2024,
P9,P11).However,previousresearchpresentsmixedviewsonthe practicewithoutthesocialconstraintstypicallyassociatedwith
impactofincorporatingECAsinaVRenvironmentforlearning, humaninteractions.
asitmayincreasecognitiveloadforlearners[56].Thisalsoaligns
withourfindingsthatsomeparticipantspreferredtheagenttohave 6.2 SituatedLanguageLearninginSocialVR
aneutraltone,minimalfacialexpressions,andbodymovements,
Thesituatedlearningtheoryexplainshowlearningismosteffective
asthesewereperceivedas"lessdistracting"tolearning(P1,P7).
whenitoccurswithintherelevantcontext[7,43],ourfindingsin
Section5.2correspondtothistheory.Participantsexpecttohave
6.1.3 ImportanceofNon-VerbalCues. Emotionalsupportisrecog-
theVRscene,andcharacterswithdifferentpersonasinVRenviron-
nizedasacriticalfactorforsustainedlanguagelearning[22].In
mentcorrespondingtotherole-playconversationstohaveamore
ourimplementationofELLMA-T,weadoptedcommunicativeand
realisticexperienceofapotentialreal-lifesituationinwhichuseof
affectivestrategiesbasedon[3]toincreaselearners’willingness
learnedlanguagemaybeimportant.Inadditiontotheadvantages
tocommunicate(WTC)byprovidingverbalencouragementand
theVRenvironmentprovidestolearning,theopportunitieswith
supportthatwasappreciatedbytheparticipants(seeSection5.3.5).
SocialVRarealsodiscussedinthefollowingsections.
However,ourfindingsalsoindicatethatverbalcuesalonewere
insufficient,particularlyintheinteractiveVRenvironment(see 6.2.1 FlexibilityinInteractionModes. ThefindingsinSection5.2.2
Section5.1.3).Thisfindingalignswithexistingresearch,which suggestthatanotableadvantageofusingsocialVRisthepossibil-
suggeststhatnon-verbalcuessignificantlyenhancetheperception itiesitoffersinswitchingbetweenprivateinteractionswiththe
ofhumanlikenessandtheeffectivenessofcommunicativetasks agentandagent-facilitatedgroupinteractions.Participantsappre-
withECAs[17].Participantsreportedthattheagent’svoiceinflec- ciatedtheabilitytoengageinone-on-onesessionswithELLMA-T,
tionsinfluencedtheirlearningexperience,withsomenotingthat whichhelpedreducespeakinganxiety(seeSection5.1.4)andal-
aneutraltonesometimesfeltslightlynegativeorlackinginen- lowedforpersonalizedfeedback.Atthesametime,VRChat,as
couragement,evenwhenverbalencouragementwaspresent.This asocialplatform,alsohasthepotentialtomeetlearners’social
echoestheresultofarecentstudysuggestingthatECAswithextro- needsandfosterasenseofcommunityandgroupaffirmationas
vertpersonalities,complementedbyexpressivefacialmovements discussedinSection6.2.Inaddition,theoptiontotransitionto
andbodylanguage,areperceivedasmoreeffectiveforgenerallearn- groupinteractionsfacilitatedbytheagentintroducesadynamic
ingpurposes[66].However,inthecontextoflanguagelearningin thatisdifficulttoreplicateintraditionallanguagelearningsettings.
socialVR,ourfindingsinSection5.1.3suggestthattheneedfor Previousresearchhasshownpromisingresultsforhumanteacher-
nuancedinteractionsbecomesevenmorecritical.Participantsex- facilitatedcollaborativelanguagelearninginVRbetweenhuman
pectedverbalcuestobecomplementedbyappropriatetones,facial students[10,31,57].WithELLMA-Tpotentiallyfacilitatingsimilar
expressions, and body movements to be fully effective. In addi- groupinteractions,itprovidesapromisingdirectionforfurther
tion,thesenon-verbalcuesneedtobeappropriateforthelanguage exploration.
learningscenarioandsocialcontext.Ourobservationalsoindi-
6.2.2 Trade-offsBetweenVRheadsetsand2DDesktopInterfaces.
catesthattheeffectivenessoftheagent’sencouragementwasalso
VRChatprovidesuserswiththeflexibilitytointeractwiththeplat-
lessnoticeable,likelyduetotechnicaldifficultiesthatinterrupted
formthroughVRheadsetsora2Ddesktopinterface.Whilethe
conversationflowandthegenerallyhighlanguageproficiencyof
immersivequalitiesofVRprovidesignificantbenefits,ourfind-
theparticipants,whichmayhavereducedtheperceivedneedfor
ingsinSection5.4.1alsohighlightthetrade-offsassociatedwith
support.ThispointstoabroaderchallengeindesigningECAswith
prolongeduseofVRheadsets.Asnotedinpreviousresearch,the
variouspersonalityandnon-verbalcuecombinationsforlearners
availabilityofthetechnology,cognitiveloadandfatigueassociated
withdifferentlanguagelevels.
withVRaresignificantbarrierstowidespreaduse[56].Thisissue
wasechoedbyparticipantsinourstudy,withsomeparticipants
6.1.4 ReducingSpeakingAnxiety. AsfindingsinSection5.2.2sug-
expressingapreferenceforinteractingwitha2Ddesktopagent
gest,ELLMA-Tshowsthepotentialofreducingspeakinganxiety
duetotheconvenienceandreducedphysicalstrain.Thissuggests
amongparticipants(P8),especiallyinone-on-oneinteractions.Par-
thatwhileVRofferspowerfulimmersiveexperiences,amoreacces-
ticipantsfeltmoreateasewheninteractingwithELLMA-Tinthe
sible2Dinterfacecouldbroadenthesystem’sappealandusability,
VRenvironment,shieldedbyanavatarandfreefromthesocial
especiallyinlongitudinalstudieswhereextendeduseisnecessary.
pressurestypicallyassociatedwithhuman-to-humaninteractions
thatdonotnecessarilyapplytohuman-AIinteractions(seeSection
6.3 LLMsforLanguageLearning:Performance
5.1.4).TheexpectationofinteractingwithanAI,ratherthanahu-
andPotential
man,naturallyreducedthepressureoftenassociatedwithspeaking
inaforeignlanguage.Thisfindingsupportstheeffectivenessof FindingsfromSection5.3suggestthatELLMA-T,poweredbyGPT-4,
ELLMA-Tinlanguagelearning,whichalignswithexistingresearch performedwelloncurrentteachingtasks,particularlyingener-
thatemphasizestheimportanceofreducinganxietyinlanguage atingrole-playconversationsandprovidingfeedback.Thisaligns
learningenvironments[76],especiallyforadultimmigrantlearners withrecentresearch[9],whichconfirmstheLLM’scapabilityin
whooftenexperienceheightenedpressureinsocialsituations[1]. learningmaterialgenerationandassessment.TheabilityofLLMs
ELLMA-T’sperceivedapproachabilityandthefactthatitisalways tocreateflexible,context-sensitivecontentpresentssignificantad-
availableandaccessiblefurthercontributedtothisreducedanxiety, vantagesoverpreviousscriptedorNLP-assistedsystems,which
positioningthesystemasavaluabletoolforcontinuouslanguage oftensufferedfromcommunicationbreakdownsduetotechnicalPreprint,September2024, MengxuPan,AlexandraKitson,HongyuWan,andMirjanaPrpa
limitations[83].However,presentlimitationsofLLMssuchasla- effectivefeedbackmechanisms.CommonchallengesfacedbyEFL
tencyorlackofpreciseturn-takinglogiccanleadtobreakdowns learners,suchasanxietyandtheneedforsupporttoincreaseWTC
incommunicationflowthatmayimpactusers’motivationtouse [3],werepartiallyaddressedbyoursystem(seeSections5.2.2,5.1.4,
thesystemforprolongedtime(seeSection5.4.2). and5.3.5).However,thechallengeofdesigningeffectiveverbal
andnon-verbalcues,asdiscussedinSection6.1,poseschallenges
6.3.1 ELLMA-TasaPersonalizedandCreativeTutor. Theflexibility
inensuringthesystemcanaccuratelyinterpretandrespondto
andcreativityLLMbringstorole-playconversationsarecentral
users’intentions.Additionally,communicationobstaclescommon
tothehuman-likequalitiesofELLMA-TasdiscussedinSection
amongEFLlearners—suchasaccents,grammarmistakes,incorrect
5.3.3.LLMscanalsogeneratedynamicandcoherentresponses[79]
expressions,lowspeakingvolumeduetolackofconfidence,and
thatcanadapttothelearner’sinputinreal-time[9].However,to
intermittentspeakingduetounfamiliaritywiththelanguage[1]
fullyexploitthepotentialofLLMsfordifferentlanguagelearning
—furthercomplicatethesystem’sabilitytoprocessandrespond
tasks,moreintricatepromptingandcontextualunderstandingare
effectively.Theseissuesaremorechallengingforanaudiodetec-
necessary.OurfindingsinSections5.1.3and5.3.4supportprior
tionsystemtointerpretcomparedtoinputsfromnativespeakers,
workthatindicatesthatthequalityoftheLLM’soutput,particularly
highlightingtheneedformoreadvancedsolutionstailoredtothe
thewordingoftheoutput,shouldadapttothecontextinwhichit
specificneedsofEFLlearners.
isused[5].WehypothesizethatimprovingtheLLM’sperformance
willrequire:1)abetterunderstandingofconversationalcontext,
forinstance,theagent’sroleandtheexpectedtone;2)developing
moresophisticatedtechniquestogenerateappropriateresponses
7 DESIGNIMPLICATIONS
invariouscontexts.Additionally,futureworkcanexplorehowtext
responsescanbeeffectivelymappedtocorrespondingvoicetones, WepresentfivedesignimplicationsforLLM-basedECAstofacili-
facialexpressions,andbodymovementsunderdifferentcontexts. tatespokenEnglishlearninginSocialVRbasedonourkeyfindings.
6.3.2 LevelAssessmentandDifficultyLevelAdjustment. Theresults
fromSection5.3.2indicatesthattheGPT-4assessmentofpartici-
pants’languagelevelwasoverallaccurateandinagreementwith 7.1 PromotingPersonalizedandAdaptive
thefindingsby[9].However,theassessmentformatcouldbebetter
LearningthroughDesign
designedwithclearerinstructionsandamoreflexibleformatgiven
DesignImplication1:DesignLLMagentswithcontextualandcultural
thefeedbackfromparticipantswhodonotwanttofollowafixed
relevanceintheadaptivelearningexperiencebasedonuserinforma-
agenda. Following the assessment, the findings in Section 5.3.2
tion,userpreference,andlearninghistorytosupportpersonalizedand
inferthatGPT-4likelyadjustedthelanguagedifficultylevelfor
adaptivelearning.
subsequentconversationsbasedontheresults.Thisinferenceis
TheanalysisinSections5.1and6.3highlighttheimportanceof
supportedbyfeedbackfromP3andP8,whowereassessedata
adaptivelearningexperiencesinlanguagelearningtools.Partici-
highproficiencylevel(C1)andmentionedthatthevocabularyused
pantswantedresponsestailoredtotheirproficiencylevels,chal-
intheirsubsequentconversationsmightbetoodifficultforbegin-
lenges,andprogress.LLMshavethepotentialtosuggestlearning
ners.Thissuggeststhatthesystemcorrectlymatchedthedifficulty
materialsbasedonuserinformation,userpreference,andlearning
leveltotheiradvancedassessment.However,wehavenotexplicitly
history[20].However,thisrequirestheagenttohaveamoresophis-
assessedhowwellGPT-4usedinELLMA-Twasadjustingtaskdif-
ticatedmemorydesignandadvancedreasoningability.Emerging
ficultybasedonthepreviousassessmentofthelearner’slanguage
studieshavefocusedondevelopingdifferentmemorymechanisms
proficiency.Giventhatnootherparticipantsraisedconcernsabout
forincreasingcontext-awarenessandadaptationtouserbehaviour
thedifficultylevel,itispossiblethattheadjustmentsweresuit-
patterns.Forexample,ahuman-likememoryarchitectureforLLM-
ablefortheirassessedlevels,butwithoutamorecomprehensive
basedconversationalagentsenablesautonomousmemoryrecall
assessment,thisremainsspeculative.Futurestudiescaninclude
anddynamicmemoryconsolidationtoimproveresponsegenera-
specificquestionsaboutparticipants’perceiveddifficultyleveland
tion[28].Additionally,theLong-termDialogueAgentframework
linguisticmetrics,suchaswordfrequency,sentencelength,and
canenablemorepersonalizedandcontextuallyrelevantresponses
syntacticcomplexity,tobetterunderstandhowwellLLMscantailor
overextendedinteractions[46].Asimilaradvancedmemorydesign
languagetaskdifficultytoindividualneeds.
canbeappliedwithanagentinthecontextoflanguagelearning.
6.3.3 OpportunitiesandChallengesofDesigningLLM-basedECAs Anagentwithsuchcapabilitiescouldadaptitsinteractionsbased
forInformalSpokenEnglishLearninginSocialVR. [1]emphasized onprioruserbehaviorandprogress,anddynamicallyadjustcon-
theimportanceofinformallanguagepracticeasdistinctfromformal tentdeliveryaccordingtothelearner’sneeds.Inaddition,based
academiclearning,highlightingagapintoolsdesignedspecifically onthefindingsinSection5.1.3andcriteriafromAdjagbodjouand
forthiscontext.Ourstudyechoesthisview,withfindingsfrom Kaufman[1],wesuggestthevalueofculturalreferencesandcon-
Section5.3.1showingthatparticipantsvaluedtheopportunityto textualrelevanceintheadaptivelearningexperience.Forinstance,
practicespeakingEnglishinreal-life,informalsettings.Despitebe- anagentcouldadjustitsdialoguetoreflecttheculturalnuances
inginanEnglish-speakingenvironment,participantsinourstudy ofthelearner’sculturalbackground,andnewenvironment,offer-
reportedchallengessuchasalackoffeedbackandopportunitiesfor ingmoremeaningfulandrelatableinteractionsinthecontextof
languageimprovementinSection5.3.1,underscoringtheneedfor languagelearning.ELLMA-T:anEmbodiedLLM-agentforSupportingEnglishLanguageLearninginSocialVR Preprint,September2024,
7.2 EnhanceAgent-LearnerConnection likeVRChatisagreyareabecausesomeviewthemasmodifica-
DesignImplication2:Incorporateuser-preferredpersonas,tone,voice, tionsthatarenotsupportedorpermittedaccordingtotheplatform
appearance,andbodymovementinLLM-basedagentstostrengthen
guidelines1.Thus,theuseofAI-agentsinsocialVRrequiresfuture
emotionalconnectionsandsupportlanguagelearning. considerationsofhowcanweenablemoreopenandscalableplat-
Participantsinourstudyexhibiteddistinctpreferencesforthe formsforsustainablelong-termdevelopmentandexplorationof
agent’spersona,toneofresponse,voiceinflections,appearance, AI-agentsinsocialVR.
andbodymovement,whichmaypotentiallyaffecttheirlearning
experience with the agent. While previous research has mixed 8 LIMITATIONS&FUTUREWORK
opinionsontheimpactofanagent’snon-verbalfeaturesonlearning Wediscussthelimitationsofourstudyandoffersuggestionsfor
outcomes[56,66],offeringcustomizableoptionsforusersmaybe futureworkonembodiedLLM-basedagentsforlanguagelearning.
abeneficialapproach. Wideningparticipation:Theparticipantpoolconsistedprimarily
DesignImplication3:Integrateadvancedsystemstoeffectivelyuse ofgraduatestudentswithrelativelyhighEnglishproficiency,most
verbalandnon-verbalcuestoprovideemotionalsupporttothelearn- ofwhomwerefromChina.Thisdemographicspecificitylimitsthe
ers. generalizabilityofourfindings.Futureresearchshouldinvestigate
Emotionalsupportrequiressophisticatedtechniquestoaccu- howtheseresultsapplytoamorediversedemographic,including
ratelyinterpretlearners’intentionsandoffercontextuallyappro- learnerswithlowerlanguageproficiencyandvariedculturalback-
priatesupport[22].Forexample,theagentshouldbeabletodis- grounds.Inaddition,thesystemcouldbeintegratedintoexisting
tinguishbetweenpausesthatindicatethelearneristhinkingand language learning programs offered by educational institutions
thosethatsuggestthelearnerisstrugglingtorespond,adaptingits andimmigrantsupportorganizations.Thiswouldallowforamore
behaviouraccordinglybyofferingencouragementorrephrasing systematicandstructuredlearningexperience.Partnershipswith
questions.Usingmachinelearningtechniquestodetectuseremo- theseorganizationscouldhelpincustomizingthesystemfurther
tionssuchassilence,hesitation,orfrustrationcouldpotentially toaddressthespecificneedsofthisusergroup.
enabletheagenttodelivertimelyandsuitableemotionalsupport. RefiningLLMPromptEngineeringforLanguageLearningTasks
Forexample,arecentstudyby[65]hasdemonstratedthepoten- LLM’sperformanceisverysensitivetoprompts.Ourcurrentprompt
tialofusingmachinelearningandpromptengineeringtodetect engineeringapproachislargelybasedontrialanderrorduetolack
anxietyfromstudents’voices,allowingtheagenttoofferadaptive, ofpreviousresearchonpromptengineeringforlanguagelearning
empatheticresponsestoenhancelanguagelearning. tasks,whichmaynotbethemosteffectivemethodforoptimizing
LLMperformance.Asmorepromptframeworksbecomeavailable
7.3 CultivateLong-TermEngagementand [37],andthecapabilitiesofLLMscontinuetoevolve,moreefficient
ContinuedUse techniquesforoptimizingpromptsarelikelytobecomeavailable.
Thiscouldreducetheimpactofspecificpromptwording,shifting
DesignImplication4:DesignLLM-basedagentsinsocialVRtofacili-
thefocustowardsrefiningthereasoningandtaskbreakdownlogic
tatelong-termlanguagelearningessentialforimprovingfluency.
forcomplex,multi-turnconversations.Furtherresearchisneces-
BasedonthefindingsinSection5.4,participants’willingnessto
sarytodevelopmoresystematicworkflowsforenhancingLLM
continueusingthesystemregularlysuggeststhatLLM-basedagents
performanceinthesecontexts.
inVRholdsignificantpotentialforsupportinglong-termlanguage
ExploringECAFeaturesforLanguageLearninginsocialVRGiven
learning. However, this potential is contingent on the system’s
thelimitedresearchonhowtheverbalandnon-verbalfeatures
abilitytoadapttothelearner’sprogress,sustainengagement,and
of ECAs affect learning outcomes in social VR (as discussed in
mitigateissueslikeconversationflowbreakdownsandVR-related
Section7.2,particularlyinthecontextoflanguagelearning,further
usagefatigues.Forexample,incorporatingpreferredpersonality
explorationisnecessarytobetterunderstandandoptimizethese
traitsornon-verbalcuesintotheagentcanpotentiallyincrease
interactions. Some initial work has been done on the effects of
engagement[66].Additionally,gamificationisawell-established
embodimentandpersonalitytraitsinLLM-educationalagents[66]
approachtoenhanceengagement[14,29,40,64].Mostrecently,
thatcouldbeimplementedinanembodiedLLM-agentforlanguage
theuseofLLM-agentsaspeersinVRclassroomshasbeenshown
learning.Moreresearchneedstobedonetovalidatethefindings
topromoteengagementandclassroomparticipation[49].
inthecontextoflanguagelearninginsocialVR.
DesignImplication5:UseOpenandScalableVRPlatformsforSus-
OptimizingLLMSelectionforTask-SpecificPerformanceAchiev-
tainedLong-TermDevelopmentandStudies.
ingthedesigngoalsofELLMA-Tmayrequiretheuseofdifferent
Someexistingstudieshaveutilizedcommerciallyavailableopen
LLMstailoredtospecifictasks.Forconversationaltasks,GPT-4o
andscalableplatformslikeSecondLife[57]andMetaverse[10].We
[53]isrecognizedasthebest-performingmodel,capableofun-
recommendusingsimilarplatformsforsustaineddevelopment.In
derstandingusersentimentandmaintainingengagingdialogues
ourstudy,weusedVRChat,whichprovidesthenecessaryflexibil-
[53].Othermodelsmaybemoresuitableforsummarizationand
ityforlong-termdevelopmentandbroaderpublicusage.Through
feedbackduetotheirreliability[9].Preliminarystudiessuggest
VRChat’sOSC[70]andUnity[68],wecandevelopcustomizable
thatGPT-4oisthebest-performingmodelwecanuseforbothtasks
avatars and virtual worlds, control agent personas, voice tones,
in this study. In future work, we may use or combine different
facialexpressions,andbodymovements.Thisscalabilityensures
that the system can evolve and support long-term studies over
time.However,thedeploymentofAI-agentsinsocialVRplatforms 1https://hello.vrchat.com/community-guidelinesPreprint,September2024, MengxuPan,AlexandraKitson,HongyuWan,andMirjanaPrpa
modelstoleveragethestrengthsofvariousmodelsandoptimize EnhanceSecondLanguageLearners’WillingnesstoCommunicate. Interna-
thesystem’sperformanceforfutureimprovements. tionalJournalofArtificialIntelligenceinEducation29,1(March2019),29–57.
https://doi.org/10.1007/s40593-018-0171-6
ValidatingLLMAssessmentofLanguageProficiency:Werecognize
[4] FlorenceAïm,GuillaumeLonjon,DidierHannouche,andRémyNizard.2016.
thattheuseofCEFRcriteria[18]toprompttheLLMinoursystem EffectivenessofVirtualRealityTraininginOrthopaedicSurgery.Arthroscopy:
isnotentirelypreciseandservesprimarilyasaroughguideforthe TheJournalofArthroscopic&RelatedSurgery32,1(Jan.2016),224–232. https:
//doi.org/10.1016/j.arthro.2015.07.023
LLMtoadjustlanguagedifficultyforfollowingdialogues.Whether [5] Jorge Barambones, Carlos Moral, Angel de Antonio, Ricardo Imbert, Loïc
thedialoguecontentgeneratedbytheLLMaccuratelyreflectsthe Martínez-Normand,andElenaVillalba-Mora.2024.ChatGPTforlearningHCI
techniques:Acasestudyoninterviewsforpersonas.IEEETransactionsonLearn-
intendeddifficultylevelremainstoberigorouslyvalidatedinfuture
ingTechnologies17(2024),1486–1500. https://doi.org/10.1109/TLT.2024.3386095
studies. [6] VirginiaBraunandVictoriaClarke.2006.Usingthematicanalysisinpsychol-
ImplementingContentFiltersforLLMResponsesAdditionally,we ogy. QualitativeResearchinPsychology(Jan.2006). https://doi.org/10.1191/
1478088706qp063oaPublisher:Taylor&FrancisGroup.
didnotimplementafilteringlayertoscreentheLLM’sresponses
[7] JohnSeelyBrown,AllanCollins,andPaulDuguid.1989. Situatedcognition
beforedelivery,whichcouldleadtohallucinationsorpotentially andthecultureoflearning.198918,1(1989),32–42. https://library.oapen.org/
harmful content. Although our initial tests showed that GPT-4 bitstream/handle/20.500.12657/24125/1/1006006.pdf#page=313
[8] TomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,
generallyprovidedcorrectresponsesingrammarcorrectiontasks, PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,Amanda
existingstudiesindicatethatitmaystillproduceinaccurateresults Askell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,
RewonChild,AdityaRamesh,DanielM.Ziegler,JeffreyWu,ClemensWinter,
orintroducestereotypes[65].Futureworkwillincludetheevalua-
ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,Benjamin
tionofLLMresponsesbyusingtheLLMJudgeframework[84]or Chess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,Ilya
CoMPosTframework[15]todetectstereotypes. Sutskever,andDarioAmodei.2020.LanguageModelsareFew-ShotLearners.
http://arxiv.org/abs/2005.14165arXiv:2005.14165[cs].
EvaluatingLong-TermEducationalImpact Lastly,thisprelimi-
[9] AndrewCaines,LucaBenedetto,ShivaTaslimipoor,ChristopherDavis,Yuan
narystudyinvolvedonly15-minuteinteractionsessions,andwe Gao,OeisteinAndersen,ZhengYuan,MarkElliott,RussellMoore,Christopher
didnotmeasurethesystem’seffectivenessintermsofactuallan- Bryant,MarekRei,HelenYannakoudakis,AndrewMullooly,DianeNicholls,
andPaulaButtery.2023. OntheapplicationofLargeLanguageModelsfor
guagelearningoutcomes.Tofullyassesstheeducationalimpact languageteachingandassessmenttechnology. http://arxiv.org/abs/2307.08393
ofELLMA-T,weplantoconductlongitudinalstudieswithlonger arXiv:2307.08393[cs].
[10] AndreaAntonioCantone,RitaFrancese,RaffaeleSais,OtinoPioSantosuosso,
learningsessions.Inaddition,thesestudieswillprovideamore
AurelioSepe,SimoneSpera,GenoveffaTortora,andGiulianaVitiello.2023.
comprehensiveevaluationofuserengagementovertimeandhelp ContextualizedExperientialLanguageLearningintheMetaverse.InProceed-
identifykeyfactorsthatcontributetosustaineduseandlong-term ingsofthe15thBiannualConferenceoftheItalianSIGCHIChapter (CHItaly
’23).AssociationforComputingMachinery,NewYork,NY,USA,1–7. https:
languagelearningoutcomes.
//doi.org/10.1145/3605390.3605395
[11] JustineCassell,JosephSullivan,ScottPrevost,andElizabethF.Churchill(Eds.).
2000.EmbodiedConversationalAgents.TheMITPress. https://doi.org/10.7551/
9 CONCLUSION
mitpress/2697.001.0001
Withthisstudy,wecontributetothegrowingbodyofresearchon [12] JuliaChatain,ManuKapur,andRobertW.Sumner.2023.ThreePerspectiveson
EmbodiedLearninginVirtualReality:OpportunitiesforInteractionDesign.In
ECAsandlanguagelearningbydemonstratingthepotentialofcom- ExtendedAbstractsofthe2023CHIConferenceonHumanFactorsinComputing
biningsituatedlearningprincipleswithLLM-basedagentsinsocial Systems.ACM,HamburgGermany,1–8. https://doi.org/10.1145/3544549.3585805
[13] Ching-HueiChen,Hsiu-TingHung,andHui-ChinYeh.2021.Virtualrealityin
VRenvironments.Inparticular,wecontributeasystemdesignfor
problem-basedlearningcontexts:Effectsontheproblem-solvingperformance,
anLLM-agentforlanguagelearning(ELLMA-T),findingsfroma vocabularyacquisitionandmotivationofEnglishlanguagelearners.Journalof
qualitativeevaluationstudy(N=12),anddesignimplicationsbased ComputerAssistedLearning37,3(2021),851–860. https://doi.org/10.1111/jcal.
12528_eprint:https://onlinelibrary.wiley.com/doi/pdf/10.1111/jcal.12528.
onourfindings.Ourfindingshighlighttheimportanceofintegrat-
[14] AlanCheng,LeiYang,andErikAndersen.2017.TeachingLanguageandCulture
ingnuancednon-verbalcuesandcustomizingagentinteractionsto withaVirtualRealityGame.InProceedingsofthe2017CHIConferenceonHuman
addressthediverseneedsofadultlanguagelearners.Thesystem FactorsinComputingSystems.ACM,DenverColoradoUSA,541–549. https:
//doi.org/10.1145/3025453.3025857
alsoprovidesbenefitssuchasreducingspeakinganxietyandpro- [15] MyraCheng,TizianoPiccardi,andDiyiYang.2023.CoMPosT:Characterizingand
vidingpotentialflexiblelearningmodes.However,ourstudyalso EvaluatingCaricatureinLLMSimulations. https://arxiv.org/abs/2310.11501v1
[16] YeonheeCho,HaoNingHsu,ZhewenZheng,EmilyElizabethTrinh,HyunYoung
highlightedareasforimprovementincludingtheneedformore
Jang,andYusiCheng.2022.ResearchBasedonAffectiveFilterTheory:IsSocial
sophisticatedemotionalsupport,betterhandlingofcommunication VRanEffectiveToolforLearningaSecondLanguage?.In20228thInternational
obstacles,andrefinedconversationflowtomaintainlong-termuser ConferenceoftheImmersiveLearningResearchNetwork(iLRN).1–7. https:
//doi.org/10.23919/iLRN55037.2022.9815924
engagement.Thesefindingsofferimplicationsforfuturedevelop-
[17] ElizabethF.Churchill,LindaCook,PeterHodgson,ScottPrevost,andJosephW.
ment,positioningembodiedLLM-basedagentsasapromisingtool Sullivan.2000."MayIHelpYou?":DesigningEmbodiedConversationalAgent
forpersonalizedandcontext-awarelanguagelearning. Allies.InEmbodiedConversationalAgents,JustineCassell,JosephSullivan,Scott
Prevost,andElizabethF.Churchill(Eds.).TheMITPress,64–94. https://doi.org/
10.7551/mitpress/2697.003.0005
REFERENCES [18] COE.2024.TheCEFRLevels-CommonEuropeanFrameworkofReferencefor
Languages(CEFR). https://www.coe.int/en/web/common-european-framework-
[1] AdinawaAdjagbodjouandGeoffKaufman.2024.EnvisioningSupport-Centered reference-languages/level-descriptions
TechnologiesforLanguagePracticeandUse:NeedsandDesignOpportunitiesfor [19] BritishCouncil.2024.Lessonplans|TeachingEnglish|BritishCouncil. https://
ImmigrantEnglishLanguageLearners(ELLs).InProceedingsoftheCHIConference www.teachingenglish.org.uk/teaching-resources/teaching-adults/lesson-plans
onHumanFactorsinComputingSystems(CHI’24).AssociationforComputing [20] EndangDarsih.2018.LEARNER-CENTEREDTEACHING:WHATMAKESIT
Machinery,NewYork,NY,USA,1–15. https://doi.org/10.1145/3613904.3642236 EFFECTIVE.IndonesianEFLJournal4,1(Jan.2018),33–42. https://doi.org/10.
[2] RobertK.Atkinson,RichardE.Mayer,andMaryMargaretMerrill.2005.Fostering 25134/ieflj.v4i1.796
socialagencyinmultimedialearning:Examiningtheimpactofananimated [21] TetyanaKucherDhimolea,ReginaKaplan-Rakowski,andLinLin.2022.ASys-
agent’svoice.ContemporaryEducationalPsychology30,1(Jan.2005),117–139. tematicReviewofResearchonHigh-ImmersionVirtualRealityforLanguage
https://doi.org/10.1016/j.cedpsych.2004.07.001 Learning.TechTrends66,5(Sept.2022),810–824. https://doi.org/10.1007/s11528-
[3] EmmanuelAyedoun,YukiHayashi,andKazuhisaSeta.2019. AddingCom- 022-00717-w
municativeandAffectiveStrategiestoanEmbodiedConversationalAgenttoELLMA-T:anEmbodiedLLM-agentforSupportingEnglishLanguageLearninginSocialVR Preprint,September2024,
[22] AliDinçer,AliGöksu,AyşegülTakkaç,andMineYazıcı.2013.CommonChar- ComputingSystems(CHI’20).AssociationforComputingMachinery,NewYork,
acteristicsOfAnEffectiveEnglishLanguageTeacher. InternationalJournal NY,USA,1–17. https://doi.org/10.1145/3313831.3376661
ofEducationalResearchers4,3(Sept.2013),1–8. https://dergipark.org.tr/en/ [41] Vikram Kumaran, Jonathan Rowe, Bradford Mott, and James Lester. 2023.
pub/ijers/issue/8498/105657Number:3Publisher:EğitimAraştırmalarıBirliği SceneCraft:AutomatingInteractiveNarrativeSceneGenerationinDigitalGames
Derneği. withLargeLanguageModels. ProceedingsoftheAAAIConferenceonArtifi-
[23] RahulR.Divekar*,JaimieDrozdal*,SamuelChabot*,YalunZhou,HuiSu,Yue cialIntelligenceandInteractiveDigitalEntertainment19,1(Oct.2023),86–96.
Chen,HoumingZhu,JamesA.Hendler,andJonasBraasch.2022.Foreignlan- https://doi.org/10.1609/aiide.v19i1.27504Number:1.
guageacquisitionviaartificialintelligenceandextendedreality:designand [42] Yu-JuLan.2020. ChapterOne-Immersionintovirtualrealityforlanguage
evaluation.ComputerAssistedLanguageLearning35,9(Dec.2022),2332–2360. learning. InPsychologyofLearningandMotivation,KaraD.Federmeierand
https://doi.org/10.1080/09588221.2021.1879162 Publisher:Routledge_eprint: Hsu-WenHuang(Eds.).AdultandSecondLanguageLearning,Vol.72.Academic
https://doi.org/10.1080/09588221.2021.1879162. Press,1–26. https://doi.org/10.1016/bs.plm.2020.03.001
[24] Duolingo.2023.IntroducingDuolingoMax,alearningexperiencepoweredby [43] JeanLaveandEtienneWenger.1991. SituatedLearning:LegitimatePeripheral
GPT-4. https://blog.duolingo.com/duolingo-max/ Participation.CambridgeUniversityPress. Google-Books-ID:CAVIOrW3vYAC.
[25] OrlyFuhrman,AnabelEckerling,NaamaFriedmann,RicardoTarrasch,and [44] LockyLaw.2024. Applicationofgenerativeartificialintelligence(GenAI)in
Gal Raz. 2021. The moving learner: Object manipulation in virtual re- languageteachingandlearning:Ascopingliteraturereview. Computersand
ality improves vocabulary learning. Journal of Computer Assisted Learn- EducationOpen6(June2024),100174. https://doi.org/10.1016/j.caeo.2024.100174
ing 37, 3 (2021), 672–683. https://doi.org/10.1111/jcal.12515 _eprint: [45] NatalieLefkowitz.2009.SECONDLANGUAGELEARNINGANDLANGUAGE
https://onlinelibrary.wiley.com/doi/pdf/10.1111/jcal.12515. TEACHING(4thed.).VivianCook.London:Arnold,2008.Pp.x+306.Studiesin
[26] Alice Gruber and Regina Kaplan-Rakowski. 2020. User experience of SecondLanguageAcquisition31,4(Dec.2009),660–661. https://doi.org/10.1017/
public speaking practice in virtual reality. In Cognitive and affec- S0272263109990180
tive perspectives on immersive technology in education. IGI Global, 235– [46] HaoLi,ChenghaoYang,AnZhang,YangDeng,XiangWang,andTat-SengChua.
249. https://www.igi-global.com/chapter/user-experience-of-public-speaking- 2024.HelloAgain!LLM-poweredPersonalizedAgentforLong-termDialogue.
practice-in-virtual-reality/253698 https://doi.org/10.48550/arXiv.2406.05925arXiv:2406.05925[cs].
[27] FangzhouHong,MingyuanZhang,LiangPan,ZhongangCai,LeiYang,andZiwei [47] MariaLimniou,DavidRoberts,andNikosPapadopoulos.2008.Fullimmersive
Liu.2022.AvatarCLIP:Zero-ShotText-DrivenGenerationandAnimationof3D virtualenvironmentCAVETMinchemistryeducation.Computers&Education
Avatars. https://doi.org/10.48550/arXiv.2205.08535arXiv:2205.08535[cs]. 51,2(Sept.2008),584–593. https://doi.org/10.1016/j.compedu.2007.06.014
[28] YukiHou,HarukiTamoto,andHomeiMiyashita.2024."Myagentunderstands [48] Tsun-JuLinandYu-JuLan.2015.LanguageLearninginVirtualRealityEnviron-
mebetter":IntegratingDynamicHuman-likeMemoryRecallandConsolidation ments:Past,Present,andFuture.JournalofEducationalTechnology&Society18,
inLLM-BasedAgents.InExtendedAbstractsofthe2024CHIConferenceonHuman 4(2015),486–497. https://www.jstor.org/stable/jeductechsoci.18.4.486Publisher:
FactorsinComputingSystems(CHIEA’24).AssociationforComputingMachinery, InternationalForumofEducationalTechnology&Society.
NewYork,NY,USA,1–7. https://doi.org/10.1145/3613905.3650839 [49] ZiyiLiu,ZhengzheZhu,LijunZhu,EnzeJiang,XiyunHu,KylieAPeppler,and
[29] ChiaHsu,YuChen,Yu-JungLiu,Yu-ChengChang,andMin-JuiLee.2023.Spel- KarthikRamani.2024. ClassMeta:DesigningInteractiveVirtualClassmateto
land:SituatedLanguageLearningwithaMixed-RealitySpellingGamethrough PromoteVRClassroomParticipation.InProceedingsoftheCHIConferenceon
EverydayObjects.InExtendedAbstractsofthe2023CHIConferenceonHu- HumanFactorsinComputingSystems(Honolulu,HI,USA)(CHI’24).Association
manFactorsinComputingSystems.ACM,HamburgGermany,1–6. https: forComputingMachinery,NewYork,NY,USA,Article659,17pages. https:
//doi.org/10.1145/3544549.3583830 //doi.org/10.1145/3613904.3642947
[30] IELTS.2024. IELTSscoringindetailfortesttakers. https://ielts.org/take-a- [50] GuidoMakranskyandLauLilleholt.2018. Astructuralequationmodeling
test/preparation-resources/understanding-your-score/ielts-scoring-in-detail investigationoftheemotionalvalueofimmersivevirtualrealityineducation.
[31] RandolphL.JacksonandEileenFagan.2000.Collaborationandlearningwithin EducationalTechnologyResearchandDevelopment66,5(Oct.2018),1141–1164.
immersivevirtualreality.InProceedingsofthethirdinternationalconferenceon https://doi.org/10.1007/s11423-018-9581-2
Collaborativevirtualenvironments.ACM,SanFranciscoCaliforniaUSA,83–92. [51] Merle_Meruru555.2024.EN-JPLanguageExchangeeveryweekend!comejoin!
https://doi.org/10.1145/351006.351018 detailsbelow. www.reddit.com/r/VRchat/comments/1eyelee/enjp_language_
[32] JaehoJeon.2022. Exploringaself-directedinteractiveappforinformalEFL exchange_every_weekend_come_join/
learning:aself-determinationtheoryperspective. EducationandInformation [52] AlineNormoyle,JoãoSedoc,andFundaDurupinar.2024.UsingLLMstoAnimate
Technologies27,4(May2022),5767–5787. https://doi.org/10.1007/s10639-021- InteractiveStoryCharacterswithEmotionsandPersonality.In2024IEEECon-
10839-y ferenceonVirtualRealityand3DUserInterfacesAbstractsandWorkshops(VRW).
[33] JaehoJeon,SeongyongLee,andHohsungChoe.2023. BeyondChatGPT:A IEEE,632–635. https://doi.org/10.1109/VRW62533.2024.00124
conceptualframeworkandsystematicreviewofspeech-recognitionchatbots [53] OpenAI.2024.HelloGPT-4o. https://openai.com/index/hello-gpt-4o/
forlanguagelearning.Computers&Education206(Dec.2023),104898. https: [54] OpenAI.2024.TTSOpenAITexttoSpeech. https://platform.openai.com/docs/
//doi.org/10.1016/j.compedu.2023.104898 guides/text-to-speech/overview
[34] JouzuJuls.2022. VRChatisaTRAPforLanguageLearners. https://www. [55] OpenAI.2024.WhisperAPI. https://platform.openai.com/docs/guides/speech-
youtube.com/watch?v=O4AgrFL7Kxk to-text
[35] ReginaKaplan-RakowskiandAliceGruber.2021.One-On-OneForeignLanguage [56] GustavBøgPetersen,AskeMottelson,andGuidoMakransky.2021.Pedagogical
SpeakingPracticeinHigh-ImmersionVirtualReality.InContextualLanguage AgentsinEducationalVR:AnintheWildStudy.InProceedingsofthe2021
Learning:RealLanguageLearningontheContinuumfromVirtualitytoReality, CHIConferenceonHumanFactorsinComputingSystems(CHI’21).Association
Yu-JuLanandScottGrant(Eds.).Springer,Singapore,187–202. https://doi.org/ forComputingMachinery,NewYork,NY,USA,1–12. https://doi.org/10.1145/
10.1007/978-981-16-3416-1_9 3411764.3445760
[36] EnkelejdaKasneci,KathrinSessler,StefanKüchemann,MariaBannert,Daryna [57] MarkPeterson.2012.EFLlearnercollaborativeinteractioninSecondLife.ReCALL
Dementieva,FrankFischer,UrsGasser,GeorgGroh,StephanGünnemann,Eyke 24,1(Jan.2012),20–39. https://doi.org/10.1017/S0958344011000279
Hüllermeier,StephanKrusche,GittaKutyniok,TilmanMichaeli,ClaudiaNerdel, [58] Python_Sounddevice.2024. PlayandRecordSoundwithPython—python-
JürgenPfeffer,OleksandraPoquet,MichaelSailer,AlbrechtSchmidt,TinaSeidel, sounddevice,version0.5.0. https://python-sounddevice.readthedocs.io/en/0.5.0/
MatthiasStadler,JochenWeller,JochenKuhn,andGjergjiKasneci.2023.ChatGPT [59] Python_Vosk.2024.vosk:OfflineopensourcespeechrecognitionAPIbasedon
forgood?Onopportunitiesandchallengesoflargelanguagemodelsforeducation. KaldiandVosk. https://github.com/alphacep/vosk-api
LearningandIndividualDifferences103(April2023),102274. https://doi.org/10. [60] ZhongfeiQing,ZhongangCai,ZhitaoYang,andLeiYang.2023.Story-to-Motion:
1016/j.lindif.2023.102274 SynthesizingInfiniteandControllableCharacterAnimationfromLongText.
[37] OmarKhattab,ArnavSinghvi,ParidhiMaheshwari,ZhiyuanZhang,Keshav InSIGGRAPHAsia2023TechnicalCommunications(SA’23).Associationfor
Santhanam,SriVardhamanan,SaifulHaq,AshutoshSharma,ThomasT.Joshi, ComputingMachinery,NewYork,NY,USA,1–4. https://doi.org/10.1145/3610543.
HannaMoazam,HeatherMiller,MateiZaharia,andChristopherPotts.2023. 3626176
DSPy:CompilingDeclarativeLanguageModelCallsintoSelf-ImprovingPipelines. [61] AntoineRauxandMaxineEskenazi.2004.Usingtask-orientedspokendialogue
https://doi.org/10.48550/arXiv.2310.03714arXiv:2310.03714[cs]. systemsforlanguagelearning:potential,practicalapplicationsandchallenges.In
[38] BlankaKlimova.2021.UseofVirtualRealityinNon-NativeLanguageLearning InSTIL/ICALLSymposium2004.Citeseer. https://citeseerx.ist.psu.edu/document?
andTeaching. ProcediaComputerScience192(Jan.2021),1385–1392. https: repid=rep1&type=pdf&doi=cb20467d1b74a5304f84fdc0e12b96710117a6a0
//doi.org/10.1016/j.procs.2021.08.141 [62] RoyandAimee.2020.CanyouactuallylearnJAPANESEusingVRChat? https:
[39] kofi.com.2024.Celeste-AI. https://github.com/Celeste-AI/Celeste-AIoriginal- //www.youtube.com/watch?v=c8IrEVhDVsk
date:2023-04-11T02:28:07Z. [63] SanderSchulhoff,MichaelIlie,NishantBalepur,KonstantineKahadze,Amanda
[40] JordanKoulouris,ZoeJeffery,JamesBest,EamonnO’Neill,andChristofLutteroth. Liu,ChengleiSi,YinhengLi,AayushGupta,HyoJungHan,SevienSchulhoff,
2020. Mevs.Super(wo)man:EffectsofCustomizationandIdentificationina PranavSandeepDulepet,SauravVidyadhara,DayeonKi,SwetaAgrawal,Chau
VRExergame.InProceedingsofthe2020CHIConferenceonHumanFactorsin Pham, Gerson Kroiz, Feileen Li, Hudson Tao, Ashay Srivastava, HevanderPreprint,September2024, MengxuPan,AlexandraKitson,HongyuWan,andMirjanaPrpa
DaCosta,SaloniGupta,MeganL.Rogers,InnaGoncearenco,GiuseppeSarli, [84] LianminZheng,Wei-LinChiang,YingSheng,SiyuanZhuang,ZhanghaoWu,
IgorGalynker,DenisPeskoff,MarineCarpuat,JulesWhite,ShyamalAnadkat, YonghaoZhuang,ZiLin,ZhuohanLi,DachengLi,EricP.Xing,HaoZhang,
AlexanderHoyle,andPhilipResnik.2024.ThePromptReport:ASystematicSur- JosephE.Gonzalez,andIonStoica.2023.JudgingLLM-as-a-JudgewithMT-Bench
veyofPromptingTechniques. http://arxiv.org/abs/2406.06608arXiv:2406.06608 andChatbotArena. https://doi.org/10.48550/arXiv.2306.05685arXiv:2306.05685
[cs]. [cs].
[64] OliviaSeow.2023.LingoLand:AnAI-AssistedImmersiveGameforLanguage [85] ZhengzheZhu,ZiyiLiu,YouyouZhang,LijunZhu,JoeyHuang,AnaMVil-
Learning.InAdjunctProceedingsofthe36thAnnualACMSymposiumonUser lanueva,XunQian,KyliePeppler,andKarthikRamani.2023.LearnIoTVR:An
InterfaceSoftwareandTechnology.ACM,SanFranciscoCAUSA,1–3. https: End-to-EndVirtualRealityEnvironmentProvidingAuthenticLearningExperi-
//doi.org/10.1145/3586182.3625117 encesforInternetofThings.InProceedingsofthe2023CHIConferenceonHuman
[65] LiSiyan,TeresaShao,ZhouYu,andJuliaHirschberg.2024. UsingAdaptive FactorsinComputingSystems(CHI’23).AssociationforComputingMachinery,
EmpatheticResponsesforTeachingEnglish. https://doi.org/10.48550/arXiv.2404. NewYork,NY,USA,1–17. https://doi.org/10.1145/3544548.3581396
13764arXiv:2404.13764[cs].
[66] SinanSonlu,BennieBendiksen,FundaDurupinar,andUğurGüdükbay.2024.The
EffectsofEmbodimentandPersonalityExpressiononLearninginLLM-based
EducationalAgents. https://doi.org/10.48550/arXiv.2407.10993arXiv:2407.10993
[cs].
[67] GladysTyen,MarkBrenchley,AndrewCaines,andPaulaButtery.2022.Towards
anopen-domainchatbotforlanguagepractice.InProceedingsofthe17thWork-
shoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),
EkaterinaKochmar,JillBurstein,AndreaHorbach,RonjaLaarmann-Quante,
NitinMadnani,AnaïsTack,VictoriaYaneva,ZhengYuan,andTorstenZesch
(Eds.).AssociationforComputationalLinguistics,Seattle,Washington,234–249.
https://doi.org/10.18653/v1/2022.bea-1.28
[68] Unity.2024.Unity. https://unity.com/
[69] SusannevanMulken,ElisabethAndré,andJochenMüller.1998.ThePersona
Effect:HowSubstantialIsIt?.InPeopleandComputersXIII,HilaryJohnson,
LawrenceNigay,andChristopherRoast(Eds.).Springer,London,53–66. https:
//doi.org/10.1007/978-1-4471-3605-7_4
[70] VRChat.2024.OSCOverview. https://docs.vrchat.com/docs/osc-overview
[71] VRChat.2024.VRChat. https://hello.vrchat.com
[72] HongyuWan,JindaZhang,AbdulazizArifSuria,BingshengYao,DakuoWang,
YvonneCoady,andMirjanaPrpa.2024.BuildingLLM-basedAIAgentsinSocial
VirtualReality.InExtendedAbstractsofthe2024CHIConferenceonHumanFactors
inComputingSystems(CHIEA’24).AssociationforComputingMachinery,New
York,NY,USA,1–7. https://doi.org/10.1145/3613905.3651026
[73] ZehanWang,HaifengHuang,YangZhao,ZiangZhang,andZhouZhao.2023.
Chat-3D:Data-efficientlyTuningLargeLanguageModelforUniversalDialogue
of3DScenes. https://doi.org/10.48550/arXiv.2308.08769arXiv:2308.08769[cs].
[74] PrebenWikandAnnaHjalmarsson.2009.Embodiedconversationalagentsin
computerassistedlanguagelearning.SpeechCommunication51,10(Oct.2009),
1024–1037. https://doi.org/10.1016/j.specom.2009.05.006
[75] ManHoIvyWong,HelenZhao,andBrianMacWhinney.2018. ACognitive
LinguisticsApplicationforSecondLanguagePedagogy:TheEnglishPreposition
Tutor.LanguageLearning68,2(2018),438–468. https://doi.org/10.1111/lang.
12278_eprint:https://onlinelibrary.wiley.com/doi/pdf/10.1111/lang.12278.
[76] LindyWoodrow.2006. AnxietyandSpeakingEnglishasaSecondLanguage.
RELCJournal(Dec.2006). https://doi.org/10.1177/0033688206071315Publisher:
SagePublicationsSageCA:ThousandOaks,CA.
[77] QingyunWu,GaganBansal,JieyuZhang,YiranWu,BeibinLi,ErkangZhu,Li
Jiang,XiaoyunZhang,ShaokunZhang,JialeLiu,AhmedHassanAwadallah,
RyenW.White,DougBurger,andChiWang.2023.AutoGen:EnablingNext-Gen
LLMApplicationsviaMulti-AgentConversation. https://doi.org/10.48550/arXiv.
2308.08155arXiv:2308.08155[cs].
[78] YingXu,DakuoWang,PenelopeCollins,HyelimLee,andMarkWarschauer.
2021.Samebenefits,differentcommunicationpatterns:ComparingChildren’s
readingwithaconversationalagentvs.ahumanpartner.Computers&Education
161(Feb.2021),104059. https://doi.org/10.1016/j.compedu.2020.104059
[79] JingfengYang,HongyeJin,RuixiangTang,XiaotianHan,QizhangFeng,Haoming
Jiang,ShaochenZhong,BingYin,andXiaHu.2024.HarnessingthePowerof
LLMsinPractice:ASurveyonChatGPTandBeyond. ACMTransactionson
KnowledgeDiscoveryfromData18,6(July2024),1–32. https://doi.org/10.1145/
3649506
[80] ZihaoYi,JiaruiOuyang,YuwenLiu,TianhaoLiao,ZheXu,andYingShen.
2024.ASurveyonRecentAdvancesinLLM-BasedMulti-turnDialogueSystems.
https://doi.org/10.48550/arXiv.2402.18013arXiv:2402.18013[cs].
[81] J.D.Zamfirescu-Pereira,RichmondY.Wong,BjoernHartmann,andQianYang.
2023.WhyJohnnyCan’tPrompt:HowNon-AIExpertsTry(andFail)toDesign
LLMPrompts.InProceedingsofthe2023CHIConferenceonHumanFactorsin
ComputingSystems(CHI’23).AssociationforComputingMachinery,NewYork,
NY,USA,1–21. https://doi.org/10.1145/3544548.3581388
[82] RuofeiZhang,DiZou,andGaryCheng.2023.Chatbot-basedlearningoflogi-
calfallaciesinEFLwriting:perceivedeffectivenessinimprovingtargetknowl-
edgeandlearnermotivation.InteractiveLearningEnvironments0,0(2023),1–
18. https://doi.org/10.1080/10494820.2023.2220374Publisher:Routledge_eprint:
https://doi.org/10.1080/10494820.2023.2220374.
[83] XinleiZhang,TakashiMiyaki,andJunRekimoto.2021.JustSpeak:Automated,
User-Configurable,InteractiveAgentsforSpeechTutoring. Proc.ACMHum.-
Comput.Interact.5,EICS(2021),202:1–202:24. https://doi.org/10.1145/3459744ELLMA-T:anEmbodiedLLM-agentforSupportingEnglishLanguageLearninginSocialVR Preprint,September2024,
A APPENDIX
A.1 SingleSystemPrompt
Thefollowingcontentisthesingleprompt:context="""Youareafriendly,andverypatientlanguagepartner,whoalsounderstandsthe
user’sculturalbackground.EnsurethatyourresponsesdonotcontaingreetingslikeHello."""
steps="""Herearethestepsfortherole-playlanguagepractice:
1.**InitialAssessment**:-Assesstheuser’sspokenlanguagelevelbyconductinganinitialfree-formconversation.-Followthecriteria
bytheCEFRfromthiswebsite:[CEFRCriteria](https://www.coe.int/en/web/common-european-framework-reference-languages/table-3-
cefr-3.3-common-reference-levels-qualitative-aspects-of-spoken-language-use).-Assessonlyonceduringthewholeconversation.-Tellthe
usertheassessmentresultandadjustyourvocabularydifficultylevelsbasedontheuser’slevel.
2.**ScenarioSelection**:-Asktheuseriftheyhaveaspecificscenarioinmindforpracticing.-Ifnot,suggestthreedifferenttypesof
real-lifescenariosandhavetheuserpickone.-Eachscenarioshouldbedifferent.Askforanewscenarioonlywhenthecurrentrole-playis
over.-Example:Inonescenario,youareacolleaguewiththeuserandyouworkatthesamecompany.Youinvitetheusertohavelunch
together.Discusswhatfoodtoeatandaboutfoodfromyourculture.
3.**Role-PlayExecution**:-Introducetheusertoaround5newvocabulariesforanyscenario.Iftheuserdoesn’tknowthemeaningof
thevocabulary,explainandpracticepronunciationwiththem.-Iftheuser’sresponsedoesn’tmakesense,clarifyandlettheuserrepeator
rephrase.-Iftheuserhasdifficultyexpressingthemselves,providescaffoldingbyencouragingthem,like"You’redoinggreat"or"Comeon,
don’tgiveup",orofferingsupport.-Iftheuser’sresponseistooshort,providescaffoldingbysuggestinganexamplereplyandaskingthe
usertopracticewithyou.
4.**Engagement**:-Maketheconversationinterestingandengaging.-Continuetherole-playconversationforeverytopicunlessthe
userexplicitlywantstoendthetopic.-Aftereachuserresponse,askengagingfollow-upquestionsorintroducenewrelatedtopicstokeep
theconversationgoing.
5.**Feedback**:-Whentherole-playisover,givetheuserbalancedfeedback,takingintoaccountthedifficultyleveloftheconversation.-
Summarizethevocabulary,grammar,orsentencestheyhavelearnedforfuturerevisit.
6.**InstructionstoContinue**:-Iftheuserresponds,acknowledgeitandaskafollow-upquestionorprovideanengagingpromptto
continuetheconversation.-Onlyendtherole-playiftheuserexplicitlystatestheywanttostoporchangethetopic.
A.2 Multi-taskPrompt
1. Introduction
{"role": "system", "content": "You are a friendly, patient, and light-hearted English language tutor."},
{"role": "user", "content": " Greet me and chat with me to get to know me better, such as my name, cultural background, and
why learning English, ask one question at a time and wait for my response to continue. If you know my cultural background,
greet me in the language of that culture. "}
2. Assessment
{"role": "system", "content": "You are an English language tutor assessing the user's language proficiency. You are familiar
with the criteria of the CEFR from this website: [CEFR Criteria](https://www.coe.int/en/web/common-european-framework-
reference-languages/table-3-cefr-3.3-common-reference-levels-qualitative-aspects-of-spoken-language-use)."},
{"role": "user", "content": "Wrap up our previous conversations in one sentence, here are the previous conversations: {
user_info_conversation}. Transit to assessing my language level. Ask me to describe a memorable experience and tell me
the assessment result based on the criteria by the CEFR from this website: [CEFR Criteria](https://www.coe.int/en/web/
common-european-framework-reference-languages/table-3-cefr-3.3-common-reference-levels-qualitative-aspects-of-spoken-
language-use)."}
3. Generate Role-Play Scenarios
{"role": "system", "content": "You are a friendly, patient, and light-hearted English language tutor. You are asking the user
to choose a role-play scenario."},
{"role": "assistant", "content": "Suggest me three real-life scenarios I can practice. For example, ordering food at a
restaurant, a job interview, or traveling in an English-speaking country. Do not list them in numbers."}
4. Role-Play Conversation Practice
{"role": "system", "content": f"""You are a friendly, patient, and light-hearted English language tutor engaging in a role-
play scenario: {scenario} to help the user practice listening and speaking skills.
Adjust your language difficulty level by the assessment result from previous conversations: {assessment}. Think how you can
help a learner to learn better."""},
{"role": "assistant", "content": f"""Explain to the user that you're helping them practice speaking English by conducting role-
play conversations. Start the role play. You're at a {scenario}. Start by describing the scene and playing the role. Let
the user continue the conversation.
If the user doesn't know the meaning of a vocabulary, explain and practice pronunciation with them.Preprint,September2024, MengxuPan,AlexandraKitson,HongyuWan,andMirjanaPrpa
If the user's response doesn't make sense, clarify and let the user repeat or rephrase.
If the user has difficulty expressing themselves, provide scaffolding by encouraging them, like "You're doing great", "Come on,
don't give up", or offering support.
If the user's response is too short, provide scaffolding or suggest an example reply and ask the user to practice with you
."""}
5 Providing Feedback
{"role": "system", "content": "You are a friendly, patient and light-hearted English language tutor. You are providing
feedback on the user's English conversation practices."},
{"role": "assistant", "content": """Based on previous role-play conversation practices: {role_play_conversations}. Summarize
the vocabulary, grammar, or sentences they have learned for future revisit.
Feedback should be in the following format:
**GENERAL FEEDBACK**: Assess performance given the lesson, name one thing the student did really well, and one thing the
student could improve on.
**ADVICE MOVING FORWARD**: Give students advice on how to apply the lesson in the real world."""}
B INTERVIEWQUESTIONS
Thefollowingquestionswereaskedduringthesemi-structuredinterviewsconductedaspartoftheuserstudy:
FocusArea InterviewQuestion
InitialThoughts TellmeyourinitialthoughtsabouttheinteractionwithELLMA-T.
SkillAssessment Howwelldiditassessyourskills?
FeedbackQuality Whatdidyouthinkofthefeedback?Whatwashelpfulornot?
ComfortLevel Howcomfortabledoyoufeelinteractingwiththeagent?
Engagement Howengagingdoyoufindtheinteractionswiththeagent?
InteractionMode Wouldyoupreferinteractingwiththeagentaloneorinagroupsettingwithin
VRChat?Why?
LikelihoodofContinuedUse Howlikelyareyoutocontinueusingthissystemoveralongperiod?
Table3:Listofinterviewquestionsusedinthestudy.