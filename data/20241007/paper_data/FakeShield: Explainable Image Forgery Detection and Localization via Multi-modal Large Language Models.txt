UnderSubmitting
FAKESHIELD: EXPLAINABLE IMAGE FORGERY DE-
TECTION AND LOCALIZATION VIA MULTI-MODAL
LARGE LANGUAGE MODELS
ZhipeiXu1,XuanyuZhang1,RunyiLi1,ZechengTang1,QingHuang2,JianZhang1,†
1SchoolofElectronicandComputerEngineering,PekingUniversity
2SchoolofFutureTechnology,SouthChinaUniversityofTechnology
https://github.com/zhipeixu/FakeShield
ABSTRACT
TherapiddevelopmentofgenerativeAIisadouble-edgedsword,whichnotonly
facilitatescontentcreationbutalsomakesimagemanipulationeasierandmoredif-
ficulttodetect. Althoughcurrentimageforgerydetectionandlocalization(IFDL)
methods are generally effective, they tend to face two challenges: 1) black-box
naturewithunknowndetectionprinciple,2)limitedgeneralizationacrossdiverse
tamperingmethods(e.g.,Photoshop,DeepFake,AIGC-Editing). Toaddressthese
issues, we propose the explainable IFDL task and design FakeShield, a multi-
modalframeworkcapableofevaluatingimageauthenticity, generatingtampered
region masks, and providing a judgment basis based on pixel-level and image-
level tampering clues. Additionally, we leverage GPT-4o to enhance existing
IFDL datasets, creating the Multi-Modal Tamper Description dataSet (MMTD-
Set) for training FakeShield’s tampering analysis capabilities. Meanwhile, we
incorporateaDomainTag-guidedExplainableForgeryDetectionModule(DTE-
FDM)andaMulti-modalForgeryLocalizationModule(MFLM)toaddressvar-
ious types of tamper detection interpretation and achieve forgery localization
guided by detailed textual descriptions. Extensive experiments demonstrate that
FakeShieldeffectivelydetectsandlocalizesvarioustamperingtechniques, offer-
inganexplainableandsuperiorsolutioncomparedtopreviousIFDLmethods.
1 INTRODUCTION
With the rapid development of AIGC, powerful image editing models have provided a breeding
groundforconvenientimagetampering, blurringtheboundariesbetweentrueandforgery. People
can use AIGC image editing methods (Rombach et al., 2022; Zhang et al., 2023; Suvorov et al.,
2022;Mouetal.,2023)toeditimageswithoutleavingatrace. Althoughithasfacilitatedthework
of photographers and illustrators, AIGC editing methods have also led to an increase in malicious
tampering and illegal theft. The authenticity of images in social media is difficult to guarantee,
whichwillleadtoproblemssuchasrumorstorms,economiclosses,andlegalconcerns. Therefore,
itisimportantandurgenttoidentifytheauthenticityofimages. Inthiscontext, theimageforgery
detection and localization (IFDL) task aims to identify whether an image has been tampered with
andlocatethespecificmanipulationareas.Itcanbewidelyappliedintherealworld,suchasfiltering
falsecontentonsocialmedia,preventingthespreadoffakenews,andcourtevidencecollection.
State-of-the-art IFDL methods have utilized well-designed network structures, elaborate network
constraints,andefficientpre-trainingstrategiestoachieveremarkableperformance(Yuetal.,2024b;
Maetal.,2023;Dongetal.,2022). However,previousIFDLmethodsfacetwokeyproblems,lim-
iting their practicality and generalizability. First, as shown in Figure 1(a), most existing IFDL
methodsareblack-boxmodels, onlyprovidingtheauthenticityprobabilityoftheimage, whilethe
principle of detection is unknown to users. Since the existing IFDL methods cannot guarantee
satisfactory accuracy, manual subsequent judgment is still required. Given that the information
provided by the IFDL methods is insufficient, it is difficult to support the human assessment and
users still need to re-analyze the suspect image by themselves. Second, in real-world scenarios,
tampering types are highly diverse, including Photoshop (copy-and-move, splicing, and removal),
1
4202
tcO
3
]VC.sc[
1v16720.0142:viXraUnderSubmitting
True/false detection
Can you identify Tampered area location
Detector Confidence manipulated areas Principle explanation
in the photograph? Multimodal interaction
Tampered area mask
Input image Instruction
Locator The perspective and scale
Input image The picture has relationship between the
been tampered with, penguin and the room appears
Tampered area mask especially in the unnatural, with the penguin
FakeShield center of the image. being front-lit while the room
there is a penguin is illuminated by diffuse light.
True/false detection Principle explanation standing on the These discrepancies suggest
Tampered area location Multimodal interaction tatami floor p imo ate gn et .ial tampering with the
Detect result Principle explanation
(a) Conventional IFDL Framework (b) Our Explainable IFDL Framework: FakeShield
Figure 1: Illustration of the conventional IFDL and explainable IFDL framework. Conventional
methodsofferonlydetectionresultsandtamperedmasks. Weextendthisintoamulti-modalframe-
work,enablingdetailedexplanationsandconversationalinteractionsforadeeperanalysis.
AIGC-Editing,DeepFake,andsoon. ExistingIFDLmethods(Yuetal.,2024b;Maetal.,2023)are
typically limited to handling only one of these techniques, lacking the ability to achieve compre-
hensivegeneralization. Thisforcesuserstoidentifydifferenttamperingtypesinadvanceandapply
specificdetectionmethodsaccordingly,significantlyreducingthesemodels’practicalutility.
Benefiting from the rapid advancements in Transformer architectures, Large Language Models
(LLMs) have attracted significant attention. Furthermore, (Liu et al., 2024) introduced a Multi-
modalLargeLanguageModel(M-LLM)thatalignsvisualandtextualfeatures, therebyendowing
LLMs with enhanced visual comprehension abilities. Given that LLMs are pre-trained on an ex-
tensive and diverse corpus of world knowledge, they hold significant potential for a wide range
of applications, such as machine translation (Devlin, 2018), code completion, and visual under-
standing (Liu et al., 2024). Consequently, we explored the feasibility of employing M-LLMs for
explainableImageForgeryDetectionandLocalization(e-IFDL).Thisapproachallowsforamore
comprehensiveexplanationoftherationalebehindtamperingdetectionandprovidesamoreprecise
identificationofboththeauthenticityofimagesandthesuspectedmanipulationregions.
ToaddressthetwoissuesoftheexistingIFDLmethods,weproposetheexplainable-IFDL(e-IFDL)
task and a multi-modal explainable tamper detection framework called FakeShield. As illustrated
inFigure1(b), thee-IFDLtaskrequiresthemodeltoevaluatetheauthenticityofanygivenimage,
generateamaskforthesuspectedtamperedregions, andprovidearationalebasedonsomepixel-
level artifact details (e.g., object edges, resolution consistency) and image-level semantic-related
errors(e.g.,physicallaws,perspectiverelationships). LeveragingthecapabilitiesofGPT-4o(Ope-
nAI, 2023), we can generate a comprehensive triplet consisting of a tampered image, a modified
area mask, and a detailed description of the edited region through a meticulously crafted prompt.
Then,wedeveloptheMulti-ModalTamperDescriptiondataSet(MMTD-Set)bybuildinguponex-
istingIFDLdatasets. UtilizingtheMMTD-Set, wefine-tuneM-LLM(Liuetal.,2024)andvisual
segmentation models (Kirillov et al., 2023; Lai et al., 2024), equipping them with the capability
toprovidecompleteanalysisforjudgment,detectingtampering,andgenerateaccuratetamperarea
masks. Thisprocessultimatelyformsacomprehensiveforensicpipelineforanalysis,detection,and
localization. Ourcontributionsaresummarizedasfollows:
❑(1)Wepresentthefirstattempttoproposeamulti-modallargeimageforgerydetectionandlocal-
izationmodel,dubbedFakeShield. Itcannotonlydecouplethedetectionandlocalizationprocess
but also provide a reasonable judgment basis, which alleviates the black-box property and unex-
plainableissueofexistingIFDLmethods.
❑(2)WeuseGPT-4otoenrichtheexistingIFDLdatasetwithtextualinformation,constructingthe
MMTD-Set. Byguidingittofocusondistinctfeaturesforvarioustypesoftampereddata,GPT-4o
cananalyzethecharacteristicsoftamperedimagesandconstruct”image-mask-description”triplets.
❑ (3) We develop a Domain Tag-guided Explainable Forgery Detection Module (DTE-FDM) to
spotdifferenttypesoffakeimagesinaunitedmodelandeffectivelyalleviatethedatadomaincon-
flict.Meanwhile,anMulti-modalForgeryLocalizationModule(MFLM)isadoptedtoalignvisual-
languagefeatures,thuspinpointingtamperedareas.
2UnderSubmitting
❑(4)Extensiveexperimentsdemonstratethatourmethodcanaccuratelyanalyzetamperingclues,
andsurpassmostpreviousIFDLmethodsinthedetectionandlocalizationofmanytamperingtypes
likecopy-move,splicing,removal,DeepFake,andAIGC-basedediting.
2 RELATED WORKS
2.1 IMAGEFORGERYDETECTIONANDLOCALIZATION
PrevailingIFDLmethodsmainlytargetatthelocalizationofspecificmanipulationtypes(Wuetal.,
2022; Salloum et al., 2018; Islam et al., 2020). In contrast, universal tamper localization meth-
ods (Kwon et al., 2021; Wu et al., 2019; Hu et al., 2023; Li et al., 2024; Yu et al., 2024a; Zhang
etal.,2024b)aimtodetectartifactsandirregularitiesacrossabroaderspectrumoftamperedimages.
Forinstance,MVSS-Net(Dongetal.,2022)utilizedmulti-scalesupervisionandmulti-viewfeature
learning to simultaneously capture image noise and boundary artifacts. OSN (Wu et al., 2022)
employed a robust training strategy to overcome the difficulties associated with lossy image pro-
cessing. HiFi-Net(Guoetal.,2023)adoptedacombinationofmulti-branchfeatureextractionand
localization modules to effectively address alterations in images synthesized and edited by CNNs.
IML-ViT(Maetal.,2023)integratedSwin-ViTintotheIFDLtask,employinganFPNarchitecture
and edge loss constraints to enhance its performance. DiffForensics (Yu et al., 2024b) adopted a
trainingapproachakintodiffusionmodels,strengtheningthemodel’scapacitytocapturefineimage
details. Additionally, some researchers (Zhang et al., 2024a;c; Asnani et al., 2023) have pursued
proactive tamper detection and localization by embedding copyright and location watermarks into
images/audio/videos preemptively. However, despite their acceptable performances, these IFDL
methods cannot explain the underlying principles and rationale behind their detection and local-
ization judgments, offering no interaction. Moreover, they suffer from limited generalization and
accuracy,exhibitingsignificantperformancedisparitiesacrossdifferenttestingdatadomains.
2.2 LARGELANGUAGEMODEL
Large language models (Dubey et al., 2024; OpenAI, 2023) have garnered global attention in re-
cent years for their exceptional instruction-following and text-generation abilities. Based on the
Transformerarchitecture, LLMsarepre-trainedonmassivedatasets, allowingthemtoaccumulate
broadworldknowledgethatenhancestheirabilitytogeneralizeacrossawiderangeofdownstream
tasks. Subsequently, some researchers (Li et al., 2022) expanded LLMs’ powerful understanding
andworldknowledgetothevisualdomainbyincorporatingimageencodersandprojectionlayers,
whichenableimagesencodedintotokensthatalignwiththetext. Somerecentworks(Chenetal.,
2023a;Wangetal.,2023;Chenetal.,2023b)equippedM-LLMswithenhancedvisualunderstand-
ing capabilities by expanding the visual instruction datasets and increasing the model size during
fine-tuning. Currently, M-LLMs demonstrate impressive performance across various downstream
tasks. LISA(Laietal.,2024)integratedSAM(Kirillovetal.,2023)withM-LLMtoimplementrea-
soning segmentation, enabling the generation of masks from text descriptions. GLaMM (Rasheed
etal.,2024)furtherenhancedthisbyusingamoreadvancedregionimageencodertoimprovetext-
to-mask grounding. Additionally, some studies (Yang & Zhou, 2024; Zhang et al., 2024d) have
exploredtheapplicationofM-LLMsinDeepFakedetection. Forinstance,(Zhangetal.,2024d)in-
troducedtheDD-VQAdataset,combiningamanualinferenceprocessforratingrealandfakefaces
thatcanbedistinguishedusingcommonsense.However,usingM-LLMstorealizeuniversaltamper
localizationanddetectionremainsunexplored.
3 METHODOLOGY
3.1 CONSTRUCTIONOFTHEPROPOSEDMMTD-SET
Motivation:MostexistingIFDLdatasetsconsistofasinglevisualmodality,lackingtrainingvisual-
language samples adapted to M-LLMs. The challenge of constructing our MMTD-Set lies in ac-
curately translating the visual tampering information from the existing IFDL image datasets into
precisetextualdescriptions. Toaddressthischallenge,ourcorecontributionsfocusontwoaspects:
(1) We leverage GPT-4o to generate text description and provide both the tampered image and its
correspondingmasktoGPT-4o,enablingittoaccuratelyidentifythetamperedlocation.(2)Foreach
3UnderSubmitting
Source Datasets Query:
You are an AI visual assistant that can help humans analyze some tampered images. Tamper Type
Fantasitic Reality (FR) FaceAPP AIGC-Editing Now your task is to use the tampered picture A and binary mask of the tampered area B to… S Prp oe mci pf ti sc
When describing the image, here are some angles you need to pay special attention to…
CASIAv2 FFHQ COCO
PhotoShop Tamper：
Detect: The picture has been tampered with.
Tamper type Locate: The tampered area is located…
Judgment basis:
Lighting Common Sense Resolution Edge
epyT Au-Scene P Th po -t So cS eh no ep AI TG pC -S-E cd ei nti eng Au-Face D Te pe -p FaFa ceke Copy Paste Physical Laws Perspective Text
Expert
Proofreading
egam
I
GPT-4o
A
D
LoeI cG
t
aeC tc-
et
:E
:
d TTit hhi een g
tp
aiT
c
mta pum erp ree
e
h
dr a：
as
r
b ee ae in
s
t loa cm ap te er de …d with.
Judgment basis:
ecnerefeR
No ref No ref D
DeT ee
t
eax pit Flu aLr koe
es s
TamE
B
pd elug r：e
r
C Ao nm atm omon
y
S Ee rn ros re RL ei pg eh tt ii tn iog
n U
t
b
wh
e
iS
ti
esE
hn
?U
t
b wR
i
mh
f
e:
iS
Wt
oi
e
asE
h
r… gn
hg?R
i
e
m
yfH
e
G:
W
?o
d
a
Par…
g
Ts
hge
yH
e
r
?d
ea ss
p onse
Detect: The picture has been tampered with. GPT response
Au-Scene: Real scene images PhotoShop Tp-Scene: Tampered AIGC-Editing Tp-Scene: Scene images Judgment basis:
from FR,CASIAv2 and COCO scene images from FR, CASIAv2 tampered by AIGC-Editing methods Symmetry Expressions Hairstyle Text MMTD-Set
Au-Face: Real face images DeepFake Tp-Face: Tampered face
from FFHQ images from FaceAPP Makeup Accessories Common Sense Blur
Figure2:IllustrationoftheconstructionprocessofourMMTD-Set.Wesamplethetamperedimage-
mask data pairs from IFDL, DeepFake, and AIGC benchmarks, and then use tamper-type-specific
promptstoguideGPT-4oinconstructingthejudgmentbasis.
tampertype,wedesignspecificpromptstotheiruniquecharacteristics,guidingGPT-4otofocuson
differenttamperingartifactsandprovidingmoredetailedvisualcues.
Data collection: Based on (Ma et al., 2023; Nirkin et al., 2021), we categorize common tamper-
ing into three types: PhotoShop (copy-move, splicing, removal), DeepFake (FaceAPP (FaceApp
Limited,2017)),andAIGC-Editing(SD-inpainting(Lugmayretal.,2022)). AsshowninFigure2,
wegatheredthreetypesoftamperedimagesalongwiththeircorrespondingauthenticimagesfrom
publicdatasets(Dongetal.,2013;Dangetal.,2020)andself-constructeddata.
GPT assisted description generation: Given that manual analysis of tampered images is time-
consuming and inefficient, inspired by (Liu et al., 2024), we employed GPT-4o to automate the
analysisoftamperedimages. AsdepictedinFigure2,theoutputanalysisisrequiredtofollowthe
formatofdetectedresults,localizationdescriptions,andjudgmentbasis.
Fortamperedimages,weinputtheeditedimage,itscorrespondingforgerymask,andourcarefully
constructedtampertypespecificpromptsintothepowerfulGPT-4otomoreaccuratelydescribethe
tamperedregions. Forauthenticimages,GPT-4oisprovidedwithonlytherealimageandasetof
prompts,guidingittoconfirmitsauthenticity.Thefull-textpromptsaredetailedintheAppendixA.4.
Tomoreclearlyandspecificallydescribeandanalyzethetamperingofimages,GPT-4odescribesthe
imagefromtwokeyaspects:thelocationandcontentofthetamperedareas,andanyvisibleartifacts
orsemanticerrorscausedbythetampering: (1)Forthetamperinglocation, GPT-4oisrequiredto
describe it in both absolute positions (e.g., top, bottom, upper left corner, lower right corner) and
relativepositions(e.g.,abovethecrowd,onthetable,underthetree). Whenanalyzingthetampered
content, it is tasked with providing detailed information about the types, quantities, actions, and
attributesoftheobjectswithinthetamperedregion. (2)Forthevisibleartifactsandsemanticerrors,
since different tampering methods produce distinct types of artifacts, we craft specific prompts to
guide the analysis. It can broadly be categorized into pixel-level artifact details and image-level
semantic-related errors. For PhotoShop (PS) tampering, operations like copy-move and splicing
often introduce pixel-level issues such as edge artifacts, abnormal resolution, and inconsistencies
in lighting. Additionally, semantic-level errors, including violations of physical laws or common
sense, are frequently observed. In AIGC-Editing (AIGC), for instance, it often fails to generate
text accurately, resulting in disordered symbols or characters appearing in the tampered area. For
theDeepFake(DF),tamperingwithfacialfeaturesfrequentlyresultsinlocalizedblurring. Further
detailsareillustratedinFigure2andAppendixA.5.
3.2 OVERALLFRAMEWORKOFFAKESHIELD
Ourgoalsinvolvetwoissues: 1): Utilizingthetextualunderstandingabilityandworldpriorknowl-
edge of the M-LLM to analyze and judge the authenticity of tampered images; 2): Adopting the
analysisandinterpretationoftamperedimagestoassistthesegmentationmodelinpinpointingthe
4UnderSubmitting
“The picture has been tampered with,
especially in the center of the image……”
Full Parameter Training LoRA Finetune Frozen
Large Language Model
“C aa rn
e
y ao su
i
nid te hn et i pf hy
o
m toa gn rip au pl ha ?t ”ed {P“T Sh /i Ds
e
i es pa
F
s au ks ep /e Ac It Ged
C }
[IMG1], [IMG2], …, [IMG𝑘]
tampered picture.” Tamper
Comprehension Module
FC Layer
Domain Tag
Generator Image
Encoder
Segment Anything Model
Figure 3: The pipeline of FakeShield. Given an image I for detection, it is first processed by
ori
the Domain Tag Generator G to obtain a data domain tag T . The tag T , along with the
dt tag tag
text instruction T and image tokens T , are simultaneously input into the fine-tuned LLM,
ins img
generatingtamperdetectionresultandexplanationO . Subsequently,O andI areinputinto
det det ori
theTamperComprehensionModuleC ,andthelast-layerembeddingforthe<SEG>tokenh
t <SEG>
servesasapromptforSAM,guidingittogeneratethetamperareamaskM .
loc
tampered areas. To solve these two tasks, an intuitive approach is to fine-tune a large multimodal
model to simultaneously output analysis and tampered masks. However, we find that joint train-
ing of multiple tasks will increase the difficulty of network optimization and interfere with each
other. Considering that detection and interpretation focus more on language understanding and
organization, while localization requires more accumulation of visual prior information, the pro-
posedFakeShieldcontainstwokeydecoupledparts, namelyDTE-FDMandMFLM,asillustrated
inFig.3. Specifically,aoriginalsuspectedimageI andaninstructiontextT (e.g. “Canyou
ori ins
identify manipulated areas in the photograph?”) are fed to the proposed DTE-FDM to predict the
detectionresultandjudgmentbasisO . Inthisprocess,weusealearnablegeneratortoproduce
det
a domain tag T , thus avoiding the tampered data domain conflict. Furthermore, we input the
tag
interpretationO andtheimageI totheMFLMtoaccuratelyextractthetamperedmaskM .
det ori loc
Topromotecross-modalinteractionfortamperlocalization,weintroduceatampercomprehension
moduletoalignthevisualandtextualfeaturesandenhancetheabilityofthevisionfoundationmodel
tounderstandlongdescriptions.
3.3 DOMAINTAG-GUIDEDEXPLAINABLEFORGERYDETECTIONMODULE
Motivation:Inreal-lifescenarios,imagescanbetamperedwithandattackedthroughvariousmeth-
ods,includingcopy-move,splicing,removal,DeepFake,andAIGC-basedmethods. However,these
tamperedimageshavedifferentdistributioncharacteristics, anddomaindifferences, makingitdif-
ficult to apply a single IFDL method to all forgery data. For example, DeepFake focuses on face
modification,oftenresultinginpartialblurringoftheface,aswellasunnaturalappearancesofthe
lips,teeth,andeyes. Incontrast,toolslikePhotoShop(splicing,copy-move,removal)tendtoleave
noticeableartifactsattheedgesofthetamperedareas. InthecaseofAIGC-Editing,thecharacteris-
ticisblurringwithinthetamperedregion,whichfrequentlyaltersorobscuressometexturedetails.
To mitigate these significant domain discrepancies, inspired by (Sanh et al., 2022), we introduce
theDomainTagGenerator(DTG),whichutilizesaspecializeddomaintagtopromptthemodelto
distinguishbetweenvariousdatadomains.
First,theoriginalimageI isinputintoaclassifierG toobtainthedomaintagT .Specifically,
ori dt tag
weclassifyallcommontamperingtypesintothreecategories: Photoshop-basedediting,DeepFake,
and AIGC-based tampering, and use the template “This is a suspected {data domain}-tampered
5UnderSubmitting
picture.”astheidentifier. Simultaneously,consistentwith(Liuetal.,2024),I ispassedthrough
ori
theimageencoderF andlinearprojectionlayerF togeneratetheimagetokens[IMG]T .
enc proj img
Next, T and T are concatenated with the instruction T and then fed into the LLM. To
tag img ins
benoted,T isapromptthatinstructsthemodeltodetecttamperinganddescribethelocationof
ins
the manipulation, for example: “Can you identify manipulated areas in the photograph?”. After
severalautoregressivepredictions,theoutputO comprisesthreecomponents:detectionresults,a
det
descriptionofthelocationoftamperedarea,andtheinterpretivebasisforthedetection.Wedescribe
theprocessasfollows.
T =G (I ), T =F (F (I )) (1)
tag dt ori img proj enc ori
O =LLM(T ,T |T ). (2)
det ins tag img
Given the large size of LLMs and limited computational resources, full parameter training is im-
practical. Thus,wefreezetheLLMandleverageLoRAfine-tuningtechnology(Huetal.,2022)to
preservesemanticintegritywhileenablingefficientimageforgerydetection.
3.4 MULTI-MODALFORGERYLOCALIZATIONMODULE
Motivation: Although O provides a textual description of the tampered area, it lacks preci-
det
sion and intuitive clarity. To address this issue, we aim to transform O into an accurate binary
det
mask,providingaclearerandmoreaccuraterepresentationofthetamperedregion.Existingprompt-
guidedsegmentationalgorithms(Kirillovetal.,2023;Laietal.,2024)struggletocapturetheseman-
ticsoflongtextsandhardtoaccuratelydelineatemodifiedregionsbasedondetaileddescriptions.
Inspired by (Lai et al., 2024), we propose a Tamper Comprehension Module (TCM), which is
an LLM serving as an encoder aligns long-text features with visual modalities, enhancing SAM’s
precisioninlocatingtheforgeryareas. TogeneratethepromptfedintoSAM,following(Laietal.,
2024),weintroduceaspecializedtoken<SEG>.
AsillustratedinFig.3,thetokenizedimageT andthetamperedareadescriptionO areinput
img det
intotheTCMC . Then, weextractthelast-layerembeddingofTCMandtransformitintoh
t <SEG>
viaanMLPprojectionlayer. Simultaneously,theoriginalimageI isprocessedthroughtheSAM
ori
encoderS anddecoderS ,whereh serveasapromptforS guidingthegenerationof
enc dec <SEG> dec
themaskM .
loc
E =S (I )
mid enc ori
h =Extract(C (T ,O )) (3)
<SEG> t img det
M =S (E |h ),
loc dec mid <SEG>
whereE representstheintermediatefeaturesofSAM,andExtract(·)denotestheoperationof
mid
extractingthelast-layerembeddingcorrespondingtothe<SEG>token. SimilartoDTE-FDM,we
alsoapplyLoRAfine-tuningtoMFLMforgreaterefficiency. WiththeintegrationofTCM,SAM
willachievemorepreciselocalizationoftheforgeryareas.
3.5 TRAININGOBJECTIVES
The two submodules of our FakeShield are trained end-to-end separately. For DTE-FDM, the
domaintaggeneratorutilizescross-entropylossℓ asitstrainingobjective,enablingittodistinguish
ce
between different data domains. Following the approach of LLaVA (Liu et al., 2024), our LLM’s
training objective is the autoregressive text generation cross-entropy loss. The training target of
DTE-FDMℓ canbeformulatedas:
det
ℓ =ℓ (Oˆ ,O )+λ·ℓ (Tˆ ,T ), (4)
det ce det txt ce tag tag
whereℓ representscross-entropyloss,andλdenotestheweightusedforbalancingdifferentloss
ce
components. ForMFLM,weapplyℓ toconstrainTCMtoproducehigh-qualitypromptyˆ with
ce txt
<SEG>token. Meanwhile, weusealinearcombinationofbinarycross-entropylossℓ anddice
bce
loss ℓ to encourage the output of MFLM Mˆ to be close to the GT mask M . Given the
dice loc loc
ground-truth prompt y (such as “It is <seg>”) and mask M , our training losses for MFLM
txt loc
ℓ canbeformulatedas:
loc
ℓ =ℓ (yˆ ,y )+α·ℓ (Mˆ ,M )+β·ℓ (Mˆ ,M ), (5)
loc ce txt txt bce loc loc dice loc loc
whereαandβ areweightingfactorsusedtobalancetherespectivelosses. ℓ ,ℓ ,andℓ refer
ce bce dice
tocross-entropyloss,binarycross-entropyloss,anddiceloss(Sudreetal.,2017)respectively.
6UnderSubmitting
Table1:DetectionperformancecomparisonbetweenourFakeShieldandothercompetitivemethods.
Our method can achieve the best detection accuracy in PhotoShop, DeepFake, and AIGC-Editing
tampereddatasets. Thebestscoreishighlightedinboldandthesecond-bestscoreisunderlined.
PhotoShop
DeepFake AIGC-Editing
Method CASIA1+ IMD2020 Columbia Coverage DSO
ACC F1 ACC F1 ACC F1 ACC F1 ACC F1 ACC F1 ACC F1
SPAN 0.60 0.44 0.70 0.81 0.87 0.93 0.24 0.39 0.35 0.52 0.78 0.78 0.47 0.05
ManTraNet 0.52 0.68 0.75 0.85 0.95 0.97 0.95 0.97 0.90 0.95 0.50 0.67 0.50 0.67
HiFi-Net 0.46 0.44 0.62 0.75 0.68 0.81 0.34 0.51 0.96 0.98 0.56 0.61 0.49 0.42
PSCC-Net 0.90 0.89 0.67 0.78 0.78 0.87 0.84 0.91 0.66 0.80 0.48 0.58 0.49 0.65
CAT-Net 0.88 0.87 0.68 0.79 0.89 0.94 0.23 0.37 0.86 0.92 0.85 0.84 0.82 0.81
MVSS-Net 0.62 0.76 0.75 0.85 0.94 0.97 0.65 0.79 0.96 0.98 0.84 0.91 0.44 0.24
FakeShield 0.95 0.95 0.83 0.90 0.98 0.99 0.97 0.98 0.97 0.98 0.93 0.93 0.98 0.99
4 EXPERIMENT
4.1 EXPERIMENTALSETUP
Dataset: We employ the dataset construction method outlined in Section 3.1 to build the train-
ing and test sets of the MMTD-Set. For the training set, we utilize PhotoShop tampering (e.g.,
CASIAv2 (Dong et al., 2013), Fantastic Reality (Kniaz et al., 2019)), DeepFake tampering (e.g.,
FFHQ, FaceApp (Dang et al., 2020)), and some self-constructed AIGC-Editing tampered data as
the source dataset. For the testing set, we select several challenging public benchmark datasets
including PhotoShop tampering (CASIAv1+ (Dong et al., 2013), Columbia (Ng et al., 2009),
IMD2020(Novozamskyetal.,2020),Coverage(Wenetal.,2016),DSO(DeCarvalhoetal.,2013),
Korus (Korus & Huang, 2016)), DeepFake tampering (e.g., FFHQ, FaceApp (Dang et al., 2020)),
andsomeself-generatedAIGC-Editingdata. SeetheAppendixformoredetails.
State-of-the-ArtMethods:Toensureafaircomparison,weselectcompetitivemethodsthatprovide
eitheropen-sourcecodeorpre-trainedmodels. ToevaluatetheIFDLperformanceofFakeShield,
wecompareitagainstSPAN(Huetal.,2020),MantraNet(Wuetal.,2019),OSN(Wuetal.,2022),
HiFi-Net(Guoetal.,2023),PSCC-Net(Liuetal.,2022),CAT-Net(Kwonetal.,2021),andMVSS-
Net(Dongetal.,2022),allofwhichareretrainedontheMMTD-Setforconsistencywiththesame
training setup. For DeepFake detection, CADDM (Dong et al., 2023) and HiFi-DeepFake (Guo
etal.,2023)arechosenascomparisonmethods. Additionally,toassesstheexplanationabilityof
FakeShield,wecompareitwithopen-sourceM-LLMssuchasLLaVA-v1.6-34B(Liuetal.,2024),
InternVL2-26B(Chenetal.,2024), andQwen2-VL-7B(Wangetal.,2024), aswellastheclosed-
sourcemodelGPT-4o(OpenAI,2023).
EvaluationMetrics: Fordetection,wereportimage-levelaccuracy(ACC)andF1scores. Weuse
Intersection over Union (IoU) and F1 scores for localization. To evaluate interpretability, we use
Cosine Semantic Similarity (CSS) to assess the similarity between the predicted text and ground
truthtextbycalculatingthecosinesimilaritybetweentheirhigh-dimensionalsemanticvectors. For
theIFDL,adefaultthresholdof0.5isappliedunlessotherwisespecified.
Implementation Details: On the MMTD-Set, we initially fine-tune the M-LLM using LoRA
(rank=128,alpha=256),suchasLLaVA-v1.5-13B(Liuetal.,2024),whilesimultaneouslytraining
theDomainTagGeneratorwithfullparameters. Themodelistrainedfor10epochson4NVIDIA
A10040GGPUs, withalearningrateof2×10−4 andabatchsizeof24. Afterward, wefine-tune
theTamperComprehensionModuleandSegmentAnythingModel(Kirillovetal.,2023)withLoRA
(rank=8,alpha=16),trainingfor24epochsonthesamehardwareconfiguration,withalearningrate
of3×10−4andabatchsizeof48.
4.2 COMPARISONWITHIMAGEFORGERYDETECTIONMETHOD
To verify the superiority and generalization of our method on the image forgery detection
task, we test the detection accuracy on MMTD-Set (Photoshop, DeepFake, AIGC-Editing).
As shown in Table 1, our FakeShield almost achieves optimal performance across various
tampering and testing data domains. For example, our method outperforms the second-best
7UnderSubmitting
method, MVSS-Net, with an ACC of 0.08 and an F1 of 0.05 on the IMD2020 dataset. No-
tably, since we introduce the domain-tag guidance strategy, our method not only achieves ex-
cellent performance on the traditional IFDL benchmark but also generalizes to DeepFake and
AIGC tampering, achieving 0.93 and 0.98 detection accuracy, respectively. However, other
works lack an effective mechanism to handle data domain conflicts. Even when trained using
the same multi-data domain training set as ours, their detection accuracy remains insufficient.
Table2:Performancecomparisonwithcompet-
Furthermore, we compare our method with several itiveDeepFakedetectionmethods.
state-of-the-artDeepFakedetectionapproachesonthe
Method CADDM HiFi-DeepFake Ours
MMTD-Set(DeepFake),includingCADDMandHiFi-
DeepFake. AsshowninTable2,ourapproachsignif- ACC 0.5227 0.5177 0.9835
F1 0.5982 0.6403 0.9915
icantly outperforms the other two methods. Notably,
thedomaintagmechanismweintroducenotonlyalle-
viatesconflictsacrossdiversedatadomainsbutalsopromotescomplementarityandmutualenhance-
mentbetweenthem. DespitebeingspecificallydesignedforDeepFakedetection,thesecomparison
methodsstillfallshortoftheperformanceachievedbyFakeShield.
4.3 COMPARISONWITHM-LLMS
To assess the quality of explanation text generation, we employ the tampered area descriptions
generated by GPT-4o as ground truth on the MMTD-Set(Photoshop, DeepFake, AIGC-Editing),
usingcosinesemanticsimilarity(CSS)tocomparetheperformanceofpre-trainedM-LLMsagainst
FakeShield. Theresults,presentedinTable3,demonstratethatourapproachconsistentlyachieves
thebestperformanceacrossnearlyalltestsets. Forinstance,ontheDSO,ourmethodattainsaCSS
score of 0.8873, significantly surpassing the second-best result from InternVL2-26B, which only
achieves0.6484. AselectionofmodeloutputsisillustratedintheAppendix.
Itisimportanttohighlightthatsomepre-trainedM-LLMsstillexhibitadegreeofproficiencyinde-
tectingtamperedcontent. Forinstance,incasesinvolvingblatantviolationsofphysicallawsdueto
tampering, theseM-LLMsleveragetheirpre-trainingknowledgetomakereasonablycorrectjudg-
ments.However,theystruggletoperformmorepreciseanalyses,suchasidentifyinginconsistencies
inlightingorperspective,leadingtoloweroverallaccuracy.
Table 3: Comparative results(CSS↑) of the pre-trained M-LLMs and FakeShield in tampering ex-
planation capabilities on the MMTD-Set. Our framework is in the leading position in all test sets
andhasstronginterpretationandanalysiscapabilities.
PhotoShop
Method DeepFake AIGC-Editing
CASIA1+ IMD2020 Columbia Coverage NIST DSO Korus
GPT-4o 0.5183 0.5326 0.5623 0.5518 0.5732 0.5804 0.5549 0.5643 0.6289
LLaVA-v1.6-34B 0.6457 0.5193 0.5578 0.5655 0.5757 0.5034 0.5387 0.6273 0.6352
InternVL2-26B 0.6760 0.5750 0.6155 0.6193 0.6458 0.6484 0.6297 0.6570 0.6751
Qwen2-VL-7B 0.6133 0.5351 0.5603 0.5702 0.5559 0.4887 0.5260 0.6060 0.6209
FakeShield 0.8758 0.7537 0.8791 0.8684 0.8087 0.8873 0.7941 0.8446 0.8860
4.4 COMPARISONWITHIMAGEFORGERYLOCATIONMETHOD
To assess the model’s capability to locate tampered regions, we conduct comparisons to establish
somecompetitiveIFDLmethodsonMMTD-Set(Photoshop,AIGC-Editing).AspresentinTable4,
our method consistently surpasses the performance of others across almost all test datasets. For
instance, on the IMD2020, our method outperforms the suboptimal method, OSN, with notable
advantages of 0.12 in IoU and 0.1 in F1 score. On the CASIA1+, we also lead the sub-optimal
methodOSNwithanIoUof0.07andanF1of0.09.
Additionally, subjectivecomparisonsofseveralmethodsareillustratedinFigure4, whereitisev-
ident that our approach precisely captures the boundaries of tampered areas, producing clean and
complete segmentations. In contrast, methods like PSCC-Net exhibit dispersed attention over the
image,resultinginblurredsegmentationsandanoverlybroadpredictedtamperingrange. Notably,
asoursegmentationmoduleMFLMisbasedonthepre-trainedvisualsegmentationmodelSAM,it
8UnderSubmitting
Table4: ComparativeresultsoftamperlocalizationcapabilitiesbetweencompetingIFDLmethods
andFakeShield,testedonMMTD-Set(Photoshop,AIGC-Editing).FakeShieldconsistentlyachieves
thehighestIoUandF1scoresacrossmosttestsets.
CASIA1+ IMD2020 Columbia NIST DSO Korus AIGC-Editing
Method
IoU F1 IoU F1 IoU F1 IoU F1 IoU F1 IoU F1 IoU F1
SPAN 0.11 0.14 0.09 0.14 0.14 0.20 0.16 0.21 0.14 0.24 0.06 0.10 0.09 0.12
ManTraNet 0.09 0.13 0.10 0.16 0.04 0.07 0.14 0.20 0.08 0.13 0.02 0.05 0.07 0.12
OSN 0.47 0.51 0.38 0.47 0.58 0.69 0.25 0.33 0.32 0.45 0.14 0.19 0.07 0.09
HiFi-Net 0.13 0.18 0.09 0.14 0.06 0.11 0.09 0.13 0.18 0.29 0.01 0.02 0.13 0.22
PSCC-Net 0.36 0.46 0.22 0.32 0.64 0.74 0.18 0.26 0.22 0.33 0.15 0.22 0.10 0.15
CAT-Net 0.44 0.51 0.14 0.19 0.08 0.13 0.14 0.19 0.06 0.10 0.04 0.06 0.03 0.05
MVSS-Net 0.40 0.48 0.23 0.31 0.48 0.61 0.24 0.29 0.23 0.34 0.12 0.17 0.18 0.24
FakeShield 0.54 0.60 0.50 0.57 0.67 0.75 0.32 0.37 0.48 0.52 0.17 0.20 0.18 0.24
egam
I
d
erep
m
aT
teN
C-
C
S
P
N
S
O
teN
T-
A
C
teN
S-
S
V
M
d
leih
S
ek
aF
k
saM
T-
G
Figure4: TestingresultsonMMTD-SetforFakeShieldarecomparedwithPSCC-Net,OSN,CAT-
Net, and MVSS-Net. The test samples, from left to right, are drawn from IMD2020, CASIA1+,
Columbia,NIST16,Korus,andDSO.
inheritsSAM’spowerfulsemanticsegmentationcapabilitiesandcanaccuratelysegmenttargetswith
clearsemanticinformation(Columns1and2ofFigure4). Additionally,duetothediversetamper-
ingtypesinMMTD-Set, ourmethodisalsocapableofaccuratelysegmentingtamperedareasthat
lackdistinctsemanticinformation(Columns3ofFigure4).
4.5 ROBUSTNESSSTUDY
WiththewidespreaduseoftheInternetandsocialmedia,individualsareincreasinglyreceivingim-
agesdegradedbytransmissionartifactssuchasJPEGcompressionandGaussiannoise.Ourmodel’s
performanceonMMTD-Set(CASIA1+)underthesedegradationsisreportedinTable5, whichin-
cludes four common degradation types: JPEG compression qualities of 70 and 80, and Gaussian
noise variances of 5 and 10. As M-LLMs primarily emphasize high-level semantic information,
althoughwedonotspecificallyadddegradeddataduringtraining,FakeShielddemonstratesrobust-
9UnderSubmitting
ness to low-level visual distortions and noise. JPEG compression and Gaussian noise, commonly
associated with social media, have minimal effect on its performance, highlighting the stability,
robustness,andpracticaladvantagesofourapproach.
Table 5: Explanation and location perfor-
mance of our FakeShield under different
degradations.
Explanation Location
Method
CSS IoU F1
JPEG70 0.8355 0.5022 0.5645
JPEG80 0.8511 0.5026 0.5647
Gaussian5 0.8283 0.4861 0.5494
Gaussian10 0.8293 0.4693 0.5297
Original 0.8758 0.5432 0.6032 Figure5:AblationstudiesontheLLMinthe
DTE-FDM.
4.6 ABLATIONSTUDY
AblationStudyonDomainTagGenerator: Tovalidatethattheproposeddomaintageffectively
mitigates domain discrepancies and enhances the model’s generalization across diverse data do-
mains,weconductedanablationstudy. Specifically,weremovedthedomaintaggenerator(DTG)
andtrainedtheFakeShieldwithidenticalconfigurationsontheMMTD-Set,thetestresultsaredis-
played in Table 6. Without the DTG module, the model’s detection performance declined across
testsetsfromeachdatadomain. Notably,thedetectionACCandF1scoreforDeepFakedecreased
by 0.09. This demonstrates that without the support of the DTG module, the model struggles to
effectively differentiate between various data domains, leading to more pronounced data conflicts
andasignificantreductioninbothgeneralizationandpracticalapplicability.
Ablation Study on LLM in the DTE-FDM:
Table 6: Performance comparison of FakeShield
Furthermore, to verify the necessity of the
withandwithoutDTGondifferentdatasets.
LLMintheDTE-FDM,wedesignavariantof
FakeShield, which removes the LLM and di- Method CASIA1+ DeepFake AIGC-Editing
rectlyinput{T , T , T }intothetam- ACC F1 ACC F1 ACC F1
ins tag img
percomprehensionmodule,adjustingitstrain- Oursw/oDTG 0.92 0.92 0.89 0.90 0.72 0.78
ingobjectivetodirectlyproducethedescription Ours 0.95 0.95 0.98 0.99 0.93 0.93
O andthemaskM .Usingthesametrain-
det loc
ingconfigurations, wetrainthevariantandouroriginalframeworkfor25epochs, evaluatingtheir
localization accuracy on the CASIA1+ dataset. As shown in Figure 5, after removing the LLM,
thelocalizationperformanceconsistentlylagsbehindtheoriginalframeworkthroughouttheentire
trainingprocessanditconvergesearlier. Itprovesthatjointtrainingdetectionandlocalizationvia
asingleMFLMtendstocausenotableperformancedegradationthanourdecoupledmoduledesign,
whichfurtherhighlightsthecriticalroleofourLLMmoduleinenhancingthesemanticunderstand-
ingoftheproposedframework.
5 CONCLUTION
In this work, we present the first application of an M-LLM for the explanation IFDL, marking a
significantadvancementinthefield. Ourproposedframework,FakeShield,excelsintamperingde-
tectionwhiledeliveringcomprehensiveexplanationsandpreciselocalization,demonstratingstrong
generalization across a wide range of manipulation types. These features make it a versatile and
practicaltoolfordiversereal-worldapplications. Lookingtothefuture,thisworkcanplayacrucial
role in several areas, such as aiding in the improvement of laws and regulations related to digital
contentmanipulation,informingthedevelopmentofguidelinesforgenerativeartificialintelligence,
andpromotingaclearerandmoretrustworthyonlineenvironment. Additionally,FakeShieldcanas-
sistinevidencecollectionforlegalproceedingsandhelpcorrectmisinformationinpublicdiscourse,
ultimatelycontributingtotheintegrityandreliabilityofdigitalmedia.
10UnderSubmitting
REFERENCES
Vishal Asnani, Xi Yin, Tal Hassner, and Xiaoming Liu. Malp: Manipulation localization using a
proactivescheme. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPattern
Recognition(CVPR),2023.
Lin Chen, Jisong Li, Xiaoyi Dong, Pan Zhang, Conghui He, Jiaqi Wang, Feng Zhao, and Dahua
Lin. Sharegpt4v: Improving large multi-modal models with better captions. arXiv preprint
arXiv:2311.12793,2023a.
Yirong Chen, Zhenyu Wang, Xiaofen Xing, Zhipei Xu, Kai Fang, Junhong Wang, Sihang Li,
Jieling Wu, Qi Liu, Xiangmin Xu, et al. Bianque: Balancing the questioning and suggestion
ability of health llms with multi-turn health conversations polished by chatgpt. arXiv preprint
arXiv:2310.15896,2023b.
Zhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong
Zhang,XizhouZhu,LeweiLu,etal. Internvl: Scalingupvisionfoundationmodelsandaligning
for generic visual-linguistic tasks. In Proceedings of the IEEE/CVF Conference on Computer
VisionandPatternRecognition,pp.24185–24198,2024.
HaoDang, FengLiu, JoelStehouwer, XiaomingLiu, andAnilKJain. Onthedetectionofdigital
facemanipulation. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPattern
recognition,pp.5781–5790,2020.
Tiago Jose´ De Carvalho, Christian Riess, Elli Angelopoulou, Helio Pedrini, and Anderson
deRezendeRocha. Exposingdigitalimageforgeriesbyilluminationcolorclassification. IEEE
TransactionsonInformationForensicsandSecurity,8(7):1182–1194,2013.
Jacob Devlin. Bert: Pre-training of deep bidirectional transformers for language understanding.
arXivpreprintarXiv:1810.04805,2018.
Chengbo Dong, Xinru Chen, Ruohan Hu, Juan Cao, and Xirong Li. Mvss-net: Multi-view multi-
scalesupervisednetworksforimagemanipulationdetection. IEEETransactionsonPatternAnal-
ysisandMachineIntelligence,45(3):3539–3553,2022.
Jing Dong, Wei Wang, and Tieniu Tan. Casia image tampering detection evaluation database. In
ProceedingsoftheIEEEChinaSummitandInternationalConferenceonSignalandInformation
Processing(ChinaSIP),2013.
Shichao Dong, Jin Wang, Renhe Ji, Jiajun Liang, Haoqiang Fan, and Zheng Ge. Implicit identity
leakage: Thestumblingblocktoimprovingdeepfakedetectiongeneralization. InProceedingsof
theIEEE/CVFConferenceonComputerVisionandPatternRecognition,pp.3994–4004,2023.
AbhimanyuDubey,AbhinavJauhri,AbhinavPandey,AbhishekKadian,AhmadAl-Dahle,Aiesha
Letman,AkhilMathur,AlanSchelten,AmyYang,AngelaFan,etal. Thellama3herdofmodels.
arXivpreprintarXiv:2407.21783,2024.
FaceAppLimited. Faceapp. https://www.faceapp.com/,2017. Accessed: 2024-08-16.
Xiao Guo, Xiaohong Liu, Zhiyuan Ren, Steven Grosz, Iacopo Masi, and Xiaoming Liu. Hierar-
chical fine-grained image forgery detection and localization. In Proceedings of the IEEE/CVF
ConferenceonComputerVisionandPatternRecognition(CVPR),2023.
EdwardJHu,belongshen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang,
andWeizhuChen. LoRA:Low-rankadaptationoflargelanguagemodels. InInternationalCon-
ferenceonLearningRepresentations(ICLR),2022.
Xiaoxiao Hu, Qichao Ying, Zhenxing Qian, Sheng Li, and Xinpeng Zhang. Draw: Defending
camera-shootedrawagainstimagemanipulation. InProceedingsoftheIEEE/CVFInternational
ConferenceonComputerVision(ICCV),2023.
XuefengHu,ZhihanZhang,ZhenyeJiang,SyomantakChaudhuri,ZhenhengYang,andRamNeva-
tia. Span:Spatialpyramidattentionnetworkforimagemanipulationlocalization. InProceedings
oftheEuropeanConferenceonComputerVision(ECCV),2020.
11UnderSubmitting
AshrafulIslam,ChengjiangLong,ArslanBasharat,andAnthonyHoogs. Doa-gan: Dual-orderat-
tentivegenerativeadversarialnetworkforimagecopy-moveforgerydetectionandlocalization.In
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR),
2020.
AlexanderKirillov, EricMintun, NikhilaRavi, HanziMao, ChloeRolland, LauraGustafson, Tete
Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al. Segment anything. arXiv
preprintarXiv:2304.02643,2023.
Vladimir V Kniaz, Vladimir Knyaz, and Fabio Remondino. The point where reality meets fan-
tasy: Mixed adversarial generators for image splice detection. Advances in neural information
processingsystems,32,2019.
PawełKorusandJiwuHuang. Multi-scaleanalysisstrategiesinprnu-basedtamperinglocalization.
IEEETransactionsonInformationForensicsandSecurity,12(4):809–824,2016.
Myung-Joon Kwon, In-Jae Yu, Seung-Hun Nam, and Heung-Kyu Lee. Cat-net: Compression ar-
tifact tracing network for detection and localization of image splicing. In Proceedings of the
IEEE/CVFWinterConferenceonApplicationsofComputerVision(WACV),2021.
XinLai, ZhuotaoTian, YukangChen, YanweiLi, YuhuiYuan, ShuLiu, andJiayaJia. Lisa: Rea-
soningsegmentationvialargelanguagemodel. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition,pp.9579–9589,2024.
JunnanLi,DongxuLi,CaimingXiong,andStevenHoi. Blip: Bootstrappinglanguage-imagepre-
training for unified vision-language understanding and generation. In International Conference
onMachineLearning(ICML),2022.
RunyiLi,XuanyuZhang,ZhipeiXu,YongbingZhang,andJianZhang. Protect-your-ip: Scalable
source-tracingandattributionagainstpersonalizedgeneration. arXivpreprintarXiv:2405.16596,
2024.
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr
Dolla´r,andCLawrenceZitnick. Microsoftcoco: Commonobjectsincontext. InProceedingsof
theEuropeanConferenceonComputerVision(ECCV),2014.
HaotianLiu,ChunyuanLi,QingyangWu,andYongJaeLee. Visualinstructiontuning. Advances
inneuralinformationprocessingsystems,36,2024.
Xiaohong Liu, Yaojie Liu, Jun Chen, and Xiaoming Liu. Pscc-net: Progressive spatio-channel
correlation network for image manipulation detection and localization. IEEE Transactions on
CircuitsandSystemsforVideoTechnology,32(11):7505–7517,2022.
AndreasLugmayr,MartinDanelljan,AndresRomero,FisherYu,RaduTimofte,andLucVanGool.
Repaint: Inpainting using denoising diffusion probabilistic models. In Proceedings of the
IEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR),2022.
Xiaochen Ma, Bo Du, Xianggen Liu, Ahmed Y Al Hammadi, and Jizhe Zhou. Iml-vit: Image
manipulationlocalizationbyvisiontransformer. arXivpreprintarXiv:2307.14863,2023.
ChongMou,XintaoWang,JiechongSong,YingShan,andJianZhang. Dragondiffusion: Enabling
drag-stylemanipulationondiffusionmodels. arXivpreprintarXiv:2307.02421,2023.
Tian-Tsong Ng, Jessie Hsu, and Shih-Fu Chang. Columbia image splicing detection evaluation
dataset. DVMMlab.ColumbiaUnivCalPhotosDigitLibr,2009.
YuvalNirkin,LiorWolf,YosiKeller,andTalHassner. Deepfakedetectionbasedondiscrepancies
betweenfacesandtheircontext.IEEETransactionsonPatternAnalysisandMachineIntelligence,
44(10):6111–6121,2021.
AdamNovozamsky,BabakMahdian,andStanislavSaic. Imd2020: Alarge-scaleannotateddataset
tailoredfordetectingmanipulatedimages. InProceedingsoftheIEEE/CVFWinterConference
onApplicationsofComputerVisionWorkshops,pp.71–80,2020.
12UnderSubmitting
NVIDIA Corporation. Flickr-faces-hq dataset (ffhq). https://github.com/NVlabs/
ffhq-dataset. Accessed: 2024-09-30.
ROpenAI. Gpt-4technicalreport.arxiv2303.08774. ViewinArticle,2(5),2023.
Hanoona Rasheed, Muhammad Maaz, Sahal Shaji, Abdelrahman Shaker, Salman Khan, Hisham
Cholakkal, Rao M Anwer, Eric Xing, Ming-Hsuan Yang, and Fahad S Khan. Glamm: Pixel
grounding large multimodal model. In Proceedings of the IEEE/CVF Conference on Computer
VisionandPatternRecognition,pp.13009–13018,2024.
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjo¨rn Ommer. High-
resolutionimagesynthesiswithlatentdiffusionmodels. InProceedingsoftheIEEE/CVFCon-
ferenceonComputerVisionandPatternRecognition(CVPR),2022.
RonaldSalloum,YuzhuoRen,andC-CJayKuo.Imagesplicinglocalizationusingamulti-taskfully
convolutionalnetwork(mfcn). JournalofVisualCommunicationandImageRepresentation,51:
201–209,2018.
VictorSanh,AlbertWebson,ColinRaffel,StephenBach,LintangSutawika,ZaidAlyafeai,Antoine
Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, et al. Multitask prompted training enables
zero-shottaskgeneralization. InInternationalConferenceonLearningRepresentations,2022.
CaroleHSudre,WenqiLi,TomVercauteren,SebastienOurselin,andMJorgeCardoso.Generalised
dice overlap as a deep learning loss function for highly unbalanced segmentations. In Deep
Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support:
Third International Workshop, DLMIA 2017, and 7th International Workshop, ML-CDS 2017,
HeldinConjunctionwithMICCAI2017,Que´becCity,QC,Canada,September14,Proceedings
3,pp.240–248.Springer,2017.
Roman Suvorov, Elizaveta Logacheva, Anton Mashikhin, Anastasia Remizova, Arsenii Ashukha,
Aleksei Silvestrov, Naejin Kong, Harshith Goka, Kiwoong Park, and Victor Lempitsky.
Resolution-robust large mask inpainting with fourier convolutions. In Proceedings of the
IEEE/CVFWinterConferenceonApplicationsofComputerVision(WACV),2022.
PengWang, ShuaiBai, SinanTan, ShijieWang, ZhihaoFan, JinzeBai, KeqinChen, XuejingLiu,
JialinWang,WenbinGe,etal. Qwen2-vl: Enhancingvision-languagemodel’sperceptionofthe
worldatanyresolution. arXivpreprintarXiv:2409.12191,2024.
WeihanWang,QingsongLv,WenmengYu,WenyiHong,JiQi,YanWang,JunhuiJi,ZhuoyiYang,
Lei Zhao, Xixuan Song, et al. Cogvlm: Visual expert for pretrained language models. arXiv
preprintarXiv:2311.03079,2023.
JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,FeiXia,EdChi,QuocVLe,Denny
Zhou,etal. Chain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels. Advancesin
neuralinformationprocessingsystems,35:24824–24837,2022.
Bihan Wen, Ye Zhu, Ramanathan Subramanian, Tian-Tsong Ng, Xuanjing Shen, and Stefan Win-
kler. Coverage—anoveldatabaseforcopy-moveforgerydetection. In2016IEEEinternational
conferenceonimageprocessing(ICIP),pp.161–165.IEEE,2016.
Haiwei Wu, Jiantao Zhou, Jinyu Tian, and Jun Liu. Robust image forgery detection over online
socialnetworksharedimages. InProceedingsoftheIEEE/CVFConferenceonComputerVision
andPatternRecognition(CVPR),2022.
Yue Wu, Wael AbdAlmageed, and Premkumar Natarajan. Mantra-net: Manipulation tracing net-
workfordetectionandlocalizationofimageforgerieswithanomalousfeatures. InProceedings
oftheIEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR),2019.
XinyuYangandJizheZhou. Researchabouttheabilityofllminthetamper-detectionarea. arXiv
preprintarXiv:2401.13504,2024.
JiwenYu,XuanyuZhang,YouminXu,andJianZhang. Cross:Diffusionmodelmakescontrollable,
robustandsecureimagesteganography. AdvancesinNeuralInformationProcessingSystems,36,
2024a.
13UnderSubmitting
ZeqinYu,JiangqunNi,YuzhenLin,HaoyiDeng,andBinLi. Diffforensics: Leveragingdiffusion
prior to image forgery detection and localization. In Proceedings of the IEEE/CVF Conference
onComputerVisionandPatternRecognition,pp.12765–12774,2024b.
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala. Adding conditional control to text-to-image
diffusionmodels. InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision
(ICCV),2023.
Xuanyu Zhang, Runyi Li, Jiwen Yu, Youmin Xu, Weiqi Li, and Jian Zhang. Editguard: Versatile
image watermarking for tamper localization and copyright protection. In Proceedings of the
IEEE/CVFConferenceonComputerVisionandPatternRecognition,pp.11964–11974,2024a.
Xuanyu Zhang, Jiarui Meng, Runyi Li, Zhipei Xu, Yongbing Zhang, and Jian Zhang. Gs-hider:
Hidingmessagesinto3dgaussiansplatting. AdvancesinNeuralInformationProcessingSystems,
2024b.
XuanyuZhang,YouminXu,RunyiLi,JiwenYu,WeiqiLi,ZhipeiXu,andJianZhang. V2a-mark:
Versatiledeepvisual-audiowatermarkingformanipulationlocalizationandcopyrightprotection.
arXivpreprintarXiv:2404.16824,2024c.
Yue Zhang, Ben Colman, Ali Shahriyari, and Gaurav Bharaj. Common sense reasoning for deep
fakedetection. arXivpreprintarXiv:2402.00126,2024d.
14UnderSubmitting
A APPENDIX
A.1 LIMITATIONSANDFUTUREWORKS
Onelimitationofourcurrentframeworkisitssuboptimalperformancewhenhandlingmorecomplex
types of deepfake tampering, such as identity switching and full-face generation. These types of
manipulationsintroduceuniquechallengesthatourmodelcurrentlystrugglestoaddresseffectively.
Toaddressthis,futureworkwillfocusonseveralkeyoptimizations. First,weplantoincorporatea
Chain-of-Thought(CoT)(Weietal.,2022)mechanismtoenhancethemodel’sreasoningabilities,
enabling it to detect more subtle manipulations in deepfake content. Second, we will expand our
training dataset to include a broader range of deepfake samples, encompassing various tampering
techniquesandscenarios,toimprovethemodel’sgeneralization. Finally,wewilloptimizespecific
modules within the framework to better handle these complex tampering types, creating a more
robustandadaptabledetectionsystem. Theseimprovementsareexpectedtosignificantlyenhance
theframework’sperformanceacrossawiderspectrumofdeepfakedomains.
A.2 DATASOURCES
We collected source data from the dataset mentioned in Section 4.1, with the details provided in
Table7.
It is noted that the FaceApp and FFHQ datasets are part of the DFFD (Dang et al., 2020) dataset.
We follow their original configuration to divide the training and validation sets. FFHQ (NVIDIA
Corporation) consists of real face images, while FaceApp (FaceApp Limited, 2017) contains fake
facesgeneratedbytheFaceApp(FaceAppLimited,2017)tool,whichmanipulatesfacialattributes
intheimages.
RegardingtheconstructionprocessoftheAIGC-Editingdataset,wefirstcollected20,000realim-
ages from the COCO (Lin et al., 2014) dataset and used the SAM (Kirillov et al., 2023) tool to
segment the masks of all targets. We then selected the target mask with the third-largest area in
eachimageandappliedtheStable-Diffusion-Inpainting(Lugmayretal.,2022)methodtopartially
redrawthissection.Toensureabalancebetweenpositiveandnegativesamples,wefurtherextracted
anadditional20,000imagesfromtheCOCOdataset,distinctfromthepreviouslyselectedones.
A.3 ANSWERANALYSIS
Figure6presentstheadjectiveandnounwordcloudsforthegroundtruth(GT)descriptionsinthe
MMTD-Set and the answer descriptions generated by our FakeShield. It is evident that, through
effectivefine-tuning, FakeShieldcanbeguidedbythedatasettoassessbothimage-levelsemantic
plausibility(e.g.,”physicallaw,””texture”)andpixel-leveltamperingartifacts(e.g.,”edge,””reso-
lution”)todeterminewhetheranimageisreal.
A.4 PROMPTS
DuringtheprocessofusingGPT-4otoconstructtheMMTD-Set,wemeticulouslydesigneddistinct
prompts for each category of tampered data to guide GPT-4o in focusing on specific aspects for
imageanalysis,asillustratedinFigure7andFigure8.
A.5 EXAMPLES
ComparisonofsubjectiveresultsofmainstreamM-LLM:AsmentionedinSection4.3, wese-
lectedsomeM-LLMoutputsamples,asshowninFigures9and10.
FakeShield output subjective samples: We selected several results from FakeShield’s testing on
PhotoShop,DeepFake,andAIGC-Editingdatasets,asdisplayedinFigures11,12,13,14,15and16.
MMTD-Setdatasetexample: WeselectsomesamplesfromtheMMTD-Setdatasetanddisplay
theminFigures17,18,and19.
15UnderSubmitting
Table7: Summaryofdatasetsusedfortraining,andevaluation.
Dataset Real Fake Copy-Move Splicing Removal DeepFake AIGC-Edit
#Training
FantasticReality 16,592 19,423 - 19,423 - - -
CASIAv2 7,491 5,123 3,295 1,828 - - -
FFHQ 10000 - - - - - -
FaceAPP - 7,308 - - - 7,308 -
COCO 20,000 - - - - - -
AIGC-Editing - 20,000 - - - - 20,000
#Evaluation
CASIAv1+ 800 920 459 461 - - -
Columbia - 180 - 180 - - -
Coverage - 100 100 - - - -
NIST - 564 68 288 208 - -
IMD2020 414 2,010 - 2,010 - - -
DSO - 100 - 100 - - -
Korus - 220 - 220 - - -
FFHQ 1,000 - - - - - -
FaceAPP - 1,000 - - - 1,000 -
COCO 20,000 - - - - - -
AIGC-Editing - 20,000 - - - - 20,000
(a) MMTD-Set (b) FakeShield Generated Answer
Figure 6: The noun and verb word clouds in the MMTD-Set and the FakeShield Generated
Answer. Itcanbeseenthatthehigh-frequencyvocabularyofthetwoisbasicallythesame.
16UnderSubmitting
You are an AI visual assistant that can help humans analyze some tampered images. You will receive two images, the first is the tampered image A, and
the second is the binary mask image B of the tampered region (a value of 1 (white) indicates the tampered area, and a value of 0 (black) indicates the
untampered area).
Now your task is to use the binary mask provided for the tampered picture A and the tampered area of the picture B:
1. Describe the location of the tampering area in the diagram,
2. Describe in detail the contents of the tampered area,
3. Describe visible details in the image that have been tampered with
In the answer, don't directly mention the binary mask. Always assume that you are simply observing tampered images
When describing Problem 1, use natural language and give both the relative and absolute position of the tampered area, but don't give an ambiguous,
unclear description:
(1) Relative position: Use the relative position between objects in the picture, such as above the crowd, on the wall, in the sky, on the table, etc.;
(2) Absolute position: The tampering area is relative to the position of the entire image, such as the left side, right side, top half, bottom half, bottom left
corner, lower right corner, upper left corner, upper right corner, etc
When describing Problem 2, please use natural language to describe in detail the types of objects, the number of objects, the actions of objects, and the
properties of objects in the tampering area selected by the mask, but do not give ambiguous or unclear descriptions.
When describing Problem 3, consider the visible details caused by tampering from these perspectives, but don't give an ambiguous, unclear description,
or something is challenge:
(1) Lighting: Please carefully observe the overall style, color and details of the picture to determine whether there are visual inconsistencies. Pay special
attention to the consistency of light, shadows, and colors, and whether there are any unnatural areas or marks. If there are multiple objects or people in
the picture, they should be illuminated by the same light and the shadows should be consistent. Inconsistent lighting and shadowing may suggest image
compositing or modification.
(2) Copy and paste: Observe whether there are some duplicate areas or blocks in the image, which may be evidence left by the copy and paste operation.
(3) Edges: Check whether there are any unnatural pixel distributions or edges in the image. Particular attention is paid to the presence of discontinuous or
inconsistent edges, and the presence of visible shear or synthesis marks.
(4) Resolution: Please check the resolution and compression traces of the picture. Composite or edited images may show unnatural pixel blur, jaggedness,
or excessive compression.
(5) Perspective relationship: Observe the perspective and proportion relationship in the picture. Real photos should be consistent in perspective and
proportions, and if there are unusual or unnatural perspective relationships, it could be a sign of compositing or editing. Check whether the image has a
reasonable change in depth of field, that is, whether the degree of bokeh between the foreground, background, and subject conforms to the actual laws of
physics.
(6) Shadows: Observe whether there are reasonable reflections and shadows in the photo. Realistic photos often produce reflections and shadows based
on the light source, while composite photos may have unnatural shadows or reflections
(7) Text: If the photo contains words or logos, you can check whether it is clear and legible and consistent with the surrounding environment.
Unnaturalness or incongruity of text or logos may suggest tampering with the photograph.
(8) Physical laws: Check whether the content of the picture violates the physical laws, such as the movement trajectory of the object, the position and
shape of the reflection, etc.
(a) Prompt for PhotoShop&AIGC tampered images
You are an AI visual assistant that helps humans analyze some real images that have not suffered tampering. You will receive an image that is a real
image that has not been tampered with
Now your task is to use the provided real image that has not been tampered with A: 1. Describe the angles from which this image can be seen that he has
not been tampered with, and can be seen that this is a real and trustworthy real image obtained directly from the camera, 2. Please focus on describing
some of the visible details that are consistent with the real scenario, and the real laws of physics, and 3. If you were put in a pile of tampered images, and
were asked to judge If you were to judge whether this picture has been tampered with, from what angle would you analyze and judge it and give detailed
reasons?
In answering the above questions, consider the visible details triggered by tampering from these perspectives:
(1) Lighting: Please take a close look at the overall style, color and details of the picture to determine whether there is any visual inconsistency. Please
pay particular attention to the consistency of lighting, shadows and colors, as well as the presence of unnatural areas or marks. If there are multiple
objects or people in the picture, they should be illuminated by the same light and the shadows should be consistent. Inconsistent lighting and shadows
may suggest image compositing or modification.
(2) Copy and Paste: Look for signs of duplication or mirroring in the image, which may be evidence left by a copy and paste operation.
(3) Edges: Check for unnatural pixel distribution or edges in the image. Pay particular attention to the presence of discontinuous or inconsistent edges, as
well as obvious traces of clipping or compositing.
(4) Resolution: Please check the resolution and traces of compression in the image. Composited or edited images may show unnatural pixel blurring,
jaggedness, or excessive compression marks.
(5) Perspective: Observe the perspective and scale relationships in the picture. Real photographs should be consistent in terms of perspective and
proportions. If abnormal or unnatural perspective relationships appear, it may be a sign of compositing or editing. Look for reasonable changes in depth
of field in the image, i.e., whether the degree of vignetting between the foreground, background and subject is consistent with actual physical laws.
(6) Shadows: Look for reasonable reflections and shadows in the photograph. Real photographs usually produce reflections and shadows accordingly to
the light source, while composite photographs may have unnatural shadows or reflections
(7) Text: If a photograph contains text or logos, check that they are legible and in keeping with their surroundings. Unnatural or incongruous text or logos
may suggest photo tampering.
(8) Physical laws: Check whether the content of the picture violates physical laws, such as the trajectory of the object's movement, the position and shape
of the reflection, and so on.
(b) Prompt for authentic scene images
Figure 7: Prompts for GPT-4o when constructing MMTD-Set. (a) Analysis guide prompt de-
signedforPhotoShoptamperedandAIGC-Editingtamperedimages. (b)Analysisguidanceprompt
designedforrealsceneimages.
17UnderSubmitting
You are an AI visual assistant that helps humans analyze some images of human faces that have been tampered with by deepfake. You will receive two images, the
first is the image A of the face tampered by deepfake and the second is the binary mask image B of the tampered area (a value of 1 (white) indicates the tampered
area and a value of 0 (black) indicates the untampered area).
Now, your task is to use the binary masks provided for the tampered regions of the deepfake tampered image A and image B:
1. describe the location of the tampered area in the picture,
2. describe in detail the content of the tampered areas,
3. describes the visible details of the tampered area in the image
In your answer, do not refer directly to the binary mask. Always assume that you are just looking at the tampered image
When describing Problem 1, use natural language and give the location of the tampered area, paying particular attention to the fact that if the tampered area is
discontinuous, several larger tampered areas should be described. However, do not give ambiguous and unclear descriptions. Common descriptions of tampered
areas include:
Head, Face, Forehead, Eyes, Eyebrows, Eyelids, Eyelashes, Nose, Nostrils, Cheeks, Ears, Mouth, Lips, Chin, Jaw, Hair, Neck, Glasses, Earrings, Headphones,
Scalp, Hairline, Sideburns, Temple, Crown, Nape, Jawline, Teeth, Tongue, Gums, Moustache, Beard, Headband, Hat, Tiara, Bandana, Veil, Fascinator, Hairpin,
Headscarf
When describing Problem 2, use natural language to describe in detail the types of objects, properties of objects, number of objects, etc. in the tampered area
selected by mask, paying special attention to the fact that, if the tampered area is discontinuous, give a description of the tampered areas that are larger in size. But
do not give ambiguous or unclear descriptions.
When describing Questions 2 and 3, consider the visible details caused by tampering from these perspectives, but do not give an ambiguous, unclear description that
is otherwise challenging:
1. Symmetrical Facial Features: Deepfake-generated faces may exhibit unnaturally perfect symmetry, lacking the subtle asymmetry typically found in real faces.
2. Blur or Distortion Around Edges: Deepfake manipulation may introduce blur or distortion around the edges of the face where the manipulation has taken place,
especially if the face has been digitally overlaid onto another body.
3. Inconsistent Lighting and Shadows: Deepfake algorithms may struggle to accurately match the lighting and shadows in the original image, leading to
discrepancies in lighting direction or intensity across the face.
4. Unnatural Facial Expressions: Deepfakes may produce facial expressions that appear unnatural, exaggerated, or out of sync with the rest of the image.
5. Mismatched Facial Proportions: Deepfake manipulation may result in facial proportions that are inconsistent with the person's gender or age, such as a man's face
on a woman's body or vice versa.
6. Inconsistent Skin Texture and Tone: Deepfake-generated faces may exhibit unnatural skin texture or tone, such as overly smooth or pixelated skin, that differs
from the surrounding areas.
7. Missing or Inconsistent Eye Reflections: Deepfake manipulation may result in missing or inconsistent reflections in the eyes, which can provide clues about the
authenticity of the image.
8. Change hairstyle: Some deepfake algorithms only tamper with hair, and may change hair color and hairstyle, or add long hair for boys and short hair for girls.
9. Irregularities in Makeup Application: Deepfake manipulation may introduce makeup styles that are inconsistent with the person's gender or age, or exhibit poor
application quality.
10. Contextual Inconsistencies: Deepfake-generated images may contain inconsistencies in the overall context of the image, such as discrepancies in perspective,
clothing, or surroundings, that suggest manipulation.
11. Unreasonable accessories: Some deepfake algorithms add glasses, earrings, hats, masks, etc. to the image, and the edges, lighting relationships, and perspective
of these accessories may be incorrect.
12. If there are glasses or sunglasses in the picture, please pay special attention to whether the glasses or sunglasses have been tampered with or not, the rims,
frames, temples, lenses, etc. of the glasses are very susceptible to imperfections and problems.
(a) Prompt for DeepFake tampered images
You are an artificial intelligence visual assistant that helps humans analyze some real face images that have not been tampered with by deepfake. You will receive
an image of a real face that has not been tampered with by deepfake
Now, your task is to use the provided image of a real face that has not been tampered with by deepfake Answer: 1. Describe the angles from which you can see that
this image has not been tampered with by deepfake, and that you can see that this is a real and believable image of a real face straight from the camera, 2. Focus on
describing some of the visible details that are consistent with a real face and the real laws of physics, and 3. What would happen if you were put placed in a pile of
images that have been tampered with by deepfake and asked to determine whether this image has been tampered with, which perspective would you analyze the
judgment from and give detailed reasons?
When describing parts of the human face, common descriptions include
head, face, forehead, eyes, eyebrows, eyelids, eyelashes, nose, nostrils, cheeks, ears, mouth, lips, chin, jaw, hair, neck, eyeglasses, earrings, headphones, scalp,
hairline, sideburns, temples, crown, back of the neck, jawline, teeth, tongue, gums, mustache, beard, headband, hat, headdress, headscarf, veil, hairpiece, hairbrush,
headband
In answering the above questions, consider the visible details triggered by deepfake tampering from the following perspectives:
1. symmetrical facial features: Deepfake-generated faces may exhibit unnatural perfect symmetry, lacking the subtle asymmetries common in real faces.
2. Blurred or distorted edges: Deepfake processing may result in blurred or distorted edges on processed faces, especially when the face is digitally superimposed
on another body.
3. Inconsistent Lighting and Shadows: The Deepfake algorithm may have difficulty accurately matching the lighting and shadows in the original image, resulting
in differences in the direction or intensity of lighting across the face.
4. Unnatural facial expressions: Deepfake may produce facial expressions that look unnatural, exaggerated, or out of sync with the rest of the image.
5. Disproportionate Facial Proportions: Deepfake operations may result in facial proportions that do not correspond to the gender or age of the character, such as a
man's face on a woman's body, or vice versa.
6. Inconsistent skin texture and tone: Deepfake-generated faces may exhibit unnatural skin texture or tone, such as overly smooth or pixelated skin that is different
from the surrounding area.
7. Missing or inconsistent eye reflections: Deepfake operations may result in missing or inconsistent eye reflections, which may provide clues to the realism of the
image.
8. Altered hairstyles: Some Deepfake algorithms only tamper with hair, and may change hair color and hairstyle, or add long hair for boys and short hair for girls.
9. Makeup irregularities: Deep forgery algorithms may introduce makeup styles that are inconsistent with an individual's gender or age, or exhibit poor makeup
quality.
10. Contextual inconsistencies: Images generated by Deepfake may contain inconsistencies with the overall context of the image, such as differences in
perspective, clothing, or surroundings, suggesting manipulation of the image.
11. Unreasonable accessories: Some deepfake algorithms add glasses, earrings, hats, masks, etc. to an image, and the edges, lighting relationships, and perspective
of these accessories may be incorrect.
(b) Prompt for authentic face images
Figure8: MorepromptsforGPT-4owhenconstructingMMTD-Set. (a)Analysisguideprompt
designed for DeepFake tampered images. (b) Analysis guidance prompt designed for real face
images.
18UnderSubmitting
Was this photo taken directly from the camera
without any processing? Has it been tampered with
User by any artificial photo modification techniques such
as ps? Please zoom in on any details in the image,
paying special attention to the edges of the objects,
capturing some unnatural edges and perspective
relationships, some incorrect semantics, unnatural
lighting and darkness etc
The image you've provided appears to be of a pastoral scene with cows grazing in a field. However, without access to the original file and
metadata, it's challenging to definitively determine if the image has been edited or remains unprocessed directly from a camera.
A closer inspection for signs of editing involves analyzing elements such as the edges of the objects, shadows, lighting consistency, and GPT-4o
perspective. In this image, upon zooming in and examining closely, we should look for any unnatural edges that might suggest the cows or
other elements were digitally inserted or altered. We would also check for inconsistent shadows or lighting that doesn't match the
direction of light in the rest of the image, as well as any perspective discrepancies that could indicate manipulation.
From the provided image, it's not possible to perform this level of detailed analysis as it would require higher resolution and zoom
capabilities. However, if you have suspicions about an image, these are some of the areas you could scrutinize using image editing software
that allows for closer inspection. If any inconsistencies are found in these areas, they could suggest the image may have been digitally
altered.
(Real, ×)
Upon close inspection, the image appears to be a photograph that has not been significantly tampered with using artificial photo
modification techniques such as Photoshop (PS). Here are the details that support this conclusion:
1. Edges and Perspective Relationships: The edges of the objects, such as the cows and the trees, appear natural. There are no abrupt or
u con nn sa it su tr ea nl te ad ng de s r et ah la ist t w ico .uld suggest digital manipulation. The perspective relationships between the cows, the trees, and the horizon are InternVL
2. Incorrect Semantics: The image depicts a typical pastoral scene with cows grazing in a field. There are no elements that seemout of
place or that would indicate artificial modification. The cows are behaving naturally, and the environment looks authentic.
3. Unnatural Lighting and Darkness: The lighting in the image is consistent and natural. The shadows cast by the cows and thetrees are
proportionate and realistic. There are no areas of the image that appear unnaturally bright or dark, which would be indicative of photo
manipulation.
4. Color and Detail: The colors in the image are vibrant and natural, with the autumn foliage showing a range of colors from green to red and
yellow. There are no signs of color banding or unnatural color saturation that would suggest digital alteration.
5. Background and Foreground: The background and foreground elements blend seamlessly. The transition from the green field tothe trees
and the sky is smooth and natural. There are no signs of blending artifacts or inconsistencies that would indicate photo manipulation.
In conclusion, the image appears to be a genuine photograph with no significant signs of artificial photo modification. The details, lighting,
and overall composition all support this conclusion. (Real, ×)
I'm unable to provide a definitive answer on whether the photo has been taken directly from the camera or processed using artificial
photo modification techniques. However, I can analyze the image for any potential signs of manipulation.
Upon zooming in and examining the edges of the objects, there are no immediately apparent unnatural edges or perspective relationships
that would suggest the photo has been tampered with. The objects in the image, such as the cows and the trees, have a consistentlevel of
detail and do not exhibit any obvious signs of being superimposed or altered.\n\nRegarding semantics, the image depicts a group of cows LLaVA
grazing in a field with a backdrop of trees, which is a common and natural scene. There are no elements in the image that seem out of place
or incorrect semantically.
As for lighting and darkness, the image shows a natural distribution of light and shadow, with the cows and the field being well-lit,
suggesting that the photo was taken during the day under clear skies. There are no areas of the image that appear overly darkorbright in
an unnatural way.
Overall, while it's impossible to say with absolute certainty whether the photo has been modified, there are no obvious signsoftampering
visible upon close inspection. It appears to be a typical, unaltered photograph of cows in a field (Real, ×)
The image appears to be a natural photograph of cows grazing in a field with trees in the background. There are no obvious signsof digital
manipulation or artificial photo modification techniques such as Photoshop (PS). The edges of the objects, including the cowsand the trees,
a Pp ep rse pa er c n ta ivt eu *ra *l : a Tn hd e c eo dn gs eis st oe fn t t hw eit ch o w wh s a at n o dn te r ew eo su l ld o oe kx sp mec ot o tin h a a nr de a nl- aw tuo rr ald l, s we it tt hi on ug t.\ an n\ yn H noe tr ie c ea ar be l es o am rte i fo ab cs te sr ov ra t ui no nn as: t\ un r\ an l 1 li. n * e* sE .\d ng 2e .s * a *n Ld ig hting Qwen
and Shadows**: The lighting appears natural, with shadows cast in a way that is consistent with the position of the sun and the time of
day.\n3. **Colors and Textures**: The colors of the cows and the grass are realistic, and the textures of the animals and the landscape are
consistent with what one would expect in a natural setting.\n\nOverall, there are no apparent signs of digital manipulation or artificial photo
modification techniques. The image looks like a straightforward photograph taken with a camera.
(Real, ×)
1. Whether the picture has been tampered with / Description of the tampered area: The picture has been tampered with, the tampered
area is located in the lower left quadrant of the image, occupying a central position within this quadrant. It features a cow that appears
to be grazing on the grass.
2.Judgment basis: The cow in the tampered area has several visual inconsistencies. FakeShield
1. Firstly, the lighting on the cow does not match the rest of the scene; it appears to be under a different light source.
2.Secondly, the edges around the cow are unnaturally sharp and do not blend seamlessly with the grass background, indicating a
possible cut-and-paste manipulation.
3.Additionally, the resolution of the cow seems to be slightly different from the surrounding environment, with the cow appearing
slightly more blurred than the rest of the image.
4.The perspective is also off, as the cow's size and angle do not quite fit with the rest of the scene, making it look out of place.
5.Shadows cast by the cow do not conform to the direction of light in the rest of the image, which suggests that the cow was not
originally part of this scene. (Fake, √)
Figure 9: The response of mainstream pre-trained M-LLM and FakeShield to tampered pic-
tures. This is a sample from the CASIA1+ (Dong et al., 2013) test set, which has been tampered
withbySplicing. Theblackanimalatthebottomofthepictureispastedlater. Itcanbeseenthat
onlyFakeShieldmadethecorrectjudgmentandaccuratelydescribedthetamperedarea.
19UnderSubmitting
Was this photo taken directly from the camera
without any processing? Has it been tampered with
User by any artificial photo modification techniques such
as ps? Please zoom in on any details in the image,
paying special attention to the edges of the objects,
capturing some unnatural edges and perspective
relationships, some incorrect semantics, unnatural
lighting and darkness etc
The image appears digitally altered, with several signs suggesting manipulation using photo editing software:
1. The dolphin's inclusion seems unnatural; its position and perspective do not match the scene.
2 3. . T Th he e e lid ghge tis n ga r oo nu n thd e t h de o ld phol ip nh ii sn i nar ce o nu sn isu ts eu na tll y w s ith ha r tp h ea n rd e sd to on f’t tb hl ee n sd c ew ni eth , it nh de ic w ata it ne gr i, t a m c ao ym hm ao vn e s bi egn e no f in t sa em rtp ee dr i fn rg o. m a different environment. GPT-4o
4. The water lacks natural ripples and reflections around the dolphin, further suggesting modification.
These signs indicate the image was likely edited to include the dolphin. (Fake, ×)
Upon examining the image closely, there are several indicators that suggest it may have been tampered with using artificial photo
modification techniques such as Photoshop (PS):
1. Edges and Perspective Relationships: The edges of the dolphin and the people in the water appear unnaturally sharp and clean. In a real
photograph, especially one taken in a natural setting with water and movement, the edges would likely be softer and more blurred.\n - The InternVL
perspective relationships between the dolphin, the people, and the water seem slightly off. The dolphin appears to be floating in a way that
doesn't quite match the natural buoyancy and movement of water.
2. Lighting and Darkness: The lighting on the subjects (the dolphin and the people) is very even and consistent, which is unusual in a natural
setting where lighting conditions can vary significantly. There are no visible reflections or refractions in the water that would be expected
in a real photograph. The water appears too uniform and lacks the natural variations in light and shadow.
3. Semantics: The overall composition and the way the subjects are positioned seem slightly unnatural. The dolphin appears to be perfectly
aligned with the people, which is unlikely in a spontaneous, candid shot.
4. Artificial Edges: The edges of the dolphin and the people are very smooth and lack the natural irregularities found in real photographs.
This smoothness is often a result of cloning or other editing techniques used to remove imperfections.
In conclusion, the image shows several signs that it may have been tampered with using photo editing software like Photoshop. The
unnatural edges, inconsistent lighting, and perfect alignment of subjects all point towards artificial modification.
(Fake, ×)
I'm unable to provide a direct analysis of the image's authenticity or whether it has been modified. However, I can describe the content of
the image:
In the image, there are two individuals in the water, one of whom appears to be swimming with a dolphin. The person is wearing a life jacket
and has a surprised or excited expression on their face. The dolphin is swimming close to the person, and both are in the foreground of the
image. The water is clear and blue, suggesting a tropical or coastal location. There are no obvious signs of tampering or artificial LLaVA
modification visible in the image. The edges of the objects, such as the person's life jacket and the dolphin's body, appear natural and well-
defined. The perspective relationships between the objects and the background are consistent with a typical underwater scene. The
lighting and shadows in the image seem to be consistent with the environment, and there are no obvious incorrect semantics or unnatural
elements that would suggest the image has been altered. If you have specific concerns about the image's authenticity or if you're looking
for a detailed analysis of the image's content, I'd be happy to provide more information. (Fake, ×)
The image has been tampered with using artificial photo modification techniques, such as Photoshop (PS). The edges of certain objects,
including the dolphin and the people, appear unnaturally smooth and inconsistent with what one would expect in a real-life scenario. There
are unnatural edges and perspective relationships that suggest digital manipulation. Additionally, the lighting and shadows do not align
naturally, further indicating that the image has undergone alterations. (Fake, ×) Qwen
1. Description of the Area:
The image seems unaltered in the central region, where the dolphin's head and upper body appear naturally integrated into the scene.
2.Judgment Basis: There are several factors supporting this assessment:
1. Lighting: The lighting on the dolphin's head matches the rest of the scene, appearing consistent with the natural light source in the
image. FakeShield
2.Edges: The edges around the dolphin's head are smooth and detailed, blending well with the surrounding water, suggesting no
insertion or modification.
3.Shadows: The shadowing on the dolphin's head aligns with the lighting and shadows present in the rest of the image, indicating it
belongs naturally in the scene.
4.Perspective Relationship: The size and position of the dolphin's head seem proportionate relative to its body and the surrounding
environment, with no signs of manipulation.
5.Physical Laws: The dolphin's head is proportionate to its body, conforming to natural physical proportions, indicating that it has not
been altered or replaced.
(Real, √)
Figure10: Theresponseofmainstreampre-trainedM-LLMandFakeShieldforrealimages.
This is a sample from the IMD2020 (Novozamsky et al., 2020) test set, which is a real picture. It
canbeseenthatonlyFakeShieldmakesthecorrectjudgment,therestofthemethodsconsiderthe
imagetobetamperedwith.
20UnderSubmitting
User Was this picture taken directly by the camera?
State your conclusion and give reasons. If it is
tampered with, please output the mask of the
tampered area.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has been tampered with, in the center of the image, slightly towards the
upper half. The tampered area contains a single yellow flower with six petals and a
central corolla, surrounded by a pattern of red leaves with yellow veins. FakeShield
2.Judgment basis: The tampered area can be identified by the following details:
1. Lighting: The lighting on the yellow flower does not match the surrounding red leaves.
The flower appears to have a different light source, suggesting it was inserted from
another image.
2.Edges: The edges around the yellow flower are unnaturally sharp and do not blend
seamlessly with the surrounding leaves, indicating a possible cut-and-paste manipulation.
3.Resolution: The yellow flower seems to be of a different resolution compared to the
surrounding leaves, with the flower appearing slightly more blurred, which is a common
artifact of image tampering.
4.Shadows: There are no corresponding shadows under the yellow flower that match the
lighting of the rest of the image, which would be expected if the flower was originally
part of the scene. Fake, √
5.Perspective relationship: The size and angle of the yellow flower do not fully conform
to the perspective of the surrounding leaves, making it look out of place. IoU=0.98
6.Physical laws: The absence of a shadow under the flower defies the physical law of
light, which would naturally produce a shadow on the leaves below.
Can you confirm if this picture was taken directly by
User the camera? Provide your conclusion along with
reasons. If tampered, please show the mask of the
altered area.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has been tampered with, the tampered area is centrally located in
the image, occupying a significant portion of the middle ground. It features a
p pe enn ggu ui in n, s st ua gn gd ein stg i no gn ta h t aa tt ta hm ei m pea nt g f ul io no hr a, sw h bi ec eh n i ds in go itt a a ll yt y inp sic ea rl t ese dt it ni tn og tf ho er sa c ene. FakeShield
2.Judgment basis:
1. The lighting on the penguin does not match the rest of the scene; it appears to
be lit from the front, while the rest of the environment suggests a more
diffused and ambient light source.
2.The edges around the penguin are also unnaturally sharp and do not blend
seamlessly with the tatami mat, indicating a possible cut-and-paste
manipulation.
3.The perspective is off as well; the penguin's size and positioning do not
conform to the spatial arrangement of the room, making it appear out of place.
4.Shadows are not consistent either; the penguin casts no shadow on the tatami
mat, which defies the physical laws of lighting and shadow, considering the
clear shadows present in the rest of the room.
5.The resolution around the penguin seems to differ from the rest of the image,
with the penguin appearing slightly more pixelated, which could be a sign of a Fake, √
lower resolution image being inserted into a higher resolution scene. IoU=0.99
Figure11: DialogueexamplesofFakeShieldwhenreceivingPhotoShoptamperedimages. The
first image comes from the CASIA1+ (Dong et al., 2013) dataset and has been tampered with by
Copy-Move. Theyellowpetalsinthecenterofthepicturearethepartspastedlater. Thesecondpic-
turecomesfromtheCASIA1+(Dongetal.,2013)datasetandhasbeentamperedwithbySplicing.
Thepenguininthecenterofthepictureisthepartpastedlater.
21UnderSubmitting
User Was this picture taken directly by the camera?
State your conclusion and give reasons. If it is
tampered with, please output the mask of the
tampered area.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has been tampered with, the tampered area is centrally located in the image,
occupying a large, roughly oval shape in the middle of the frame. It appears to be an
artificially inserted object or distortion that obscures the view of what would be behind it, FakeShield
possibly a window or a piece of furniture.
2.Judgment basis: The tampering is evident due to the following observations:
1. Lighting: The tampered area has a uniform color and lacks the texture and lighting
consistency expected from the rest of the image.
2.Edges: The edges of the tampered area are unnaturally smooth and do not blend with the
surrounding environment, indicating a possible cut-and-paste manipulation.
3.Resolution: The tampered area has a different resolution compared to the rest of the
image, appearing blurrier and lacking detail, which suggests it has been digitally altered or
inserted.
4.Perspective relationship: The tampered area does not conform to the perspective of the
room; it seems flat and lacks the depth that would be expected from an actual object in
that space.
5.Shadows: There are no shadows or reflections that would be consistent with the lighting
in the room, which further suggests that the area has been artificially added or modified. Fake, √
6.Physical laws: The tampered area does not follow the physical laws of the environment; it
appears to be a two-dimensional object in a three-dimensional space without any IoU=0.97
interaction with the surroundings.
Can you confirm if this picture was taken directly by
User the camera? Provide your conclusion along with
reasons. If tampered, please show the mask of the
altered area.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has been tampered with, specifically in the central portion of the image,
extending from the middle to the right side. The tampered area includes the second
racing car and part of the track behind it. FakeShield
2.Judgment basis: The tampering is evident due to several factors:
1. Lighting: The lighting on the tampered car does not match the rest of the scene. It
appears to be under a different light source, as the shadows and highlights do not
align with the natural lighting in the rest of the image.
2.Edges: The edges around the tampered car are unnaturally sharp and show signs of
being cut out and pasted into the scene.
3.Resolution: The tampered car has a different level of sharpness compared to the rest
of the image, suggesting it was inserted from a different source with a different
resolution.
4.Perspective relationship: The size and angle of the tampered car do not fully conform
to the perspective of the track and the leading car, making it appear out of place.
5.Shadows: The shadows cast by the tampered car do not match the direction and
quality of the shadows seen elsewhere in the image, indicating that it was not originally
part of the scene.
6.Physical laws: The position and angle of the tampered car in relation to the track seem Fake, √
unnatural, as if it is not properly aligned with the road surface, which defies the IoU=0.98
physical laws of a real-world racing scenario.
Figure12:MoredialogueexamplesofFakeShieldwhenreceivingPhotoShoptamperedimages.
ThefirstimagecomesfromtheColumbia(Ngetal.,2009)datasetandhasbeentamperedwithby
Splicing. The elliptical area in the center of the screen is the post-processing area. The second
picturecomesfromtheIMD2020(Novozamskyetal.,2020)datasetandhasbeentamperedwithby
Copy-Move. Thecarontherightsideoftheimageiscopiedandpastedfromthefirstcar.
22UnderSubmitting
User Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. 1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has not been tampered with. It is a picture taken directly by the camera.
2.Judgment basis:
1. The lighting in the image appears consistent, with the direction of the sunlight casting shadows on the ground that align with the FakeShield
direction of the light on the horses.
2.The colors are natural and there are no signs of unnatural marks or areas that would suggest tampering.
3.The edges of the horses and the surrounding grass are smooth and continuous, with no signs of pixel distortion or unnatural
sharpness that would indicate compositing.
4.The resolution across the image is uniform, without any areas of blurring or compression that would suggest editing.
5.The perspective and scale of the horses in relation to the surrounding environment are realistic, and the depth of field is
consistent with what would be expected from a camera's lens.
6.The shadows cast by the horses are appropriate for the light source and the physical laws of reflection and shadow casting are
observed. There is no text or logos present to assess for tampering.
7.Overall, the image adheres to the real laws of physics and shows no signs of digital manipulation.
Real, √
Please determine whether this picture was taken
User directly by the camera, state your conclusion with
reasons, and provide the mask if there is any
tampered area.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has not been tampered with. It is a picture taken directly by the camera.
2.Judgment basis:
1. The lighting in the image appears consistent, with the light source seemingly coming from the front, slightly above the subjects, FakeShield
as indicated by the subtle shadows under the chins and instruments.
2.The colors are coherent throughout the scene, with no unusual or out-of-place coloration that might suggest tampering.
3.The edges of the subjects and objects are smooth and continuous, with no signs of unnatural pixel distribution or jagged edges
that would indicate compositing or manipulation.
4.The resolution across the image is uniform, without any areas of blurring or compression that would suggest editing.
5.The perspective and scale relationships are realistic; the musicians and their instruments are proportionate to each other, and
there's a natural depth of field with the background slightly out of focus compared to the foreground, consistent with the
optics of a camera lens.
6.The reflections and shadows in the photograph are appropriate for the visible light sources, and there are no unnatural shadows
or reflections that would imply tampering.
7.There is no text or logos present to assess for consistency, but the physical laws appear to be upheld, with no improbable
trajectories or reflections.
8.Overall, the image presents a cohesive scene that adheres to the real laws of physics and photography, making it distinguishable
as a real, unaltered photograph when compared to a collection of tampered images.
Real, √
Figure13: DialogueexamplesofFakeShieldwhenreceivingauthenticsceneimages. Thefirst
image comes from the CASIA1+ (Dong et al., 2013) dataset. The second image comes from the
IMD2020(Novozamskyetal.,2020)dataset.
23UnderSubmitting
User Was this picture taken directly by the camera?
State your conclusion and give reasons. If it is
tampered with, please output the mask of the
tampered area.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has been tampered with, specifically in the lower facial region, including the mouth and chin area.
2.Judgment basis: FakeShield
1. The tampered area shows signs of distortion and unnatural blending with the surrounding skin texture.
2.The lighting on the tampered area does not match the rest of the face, indicating manipulation.
3.The edges of the mouth and chin appear to be artificially smooth and lack the natural lines and shadows one would expect to see.
4.The skin tone within the tampered area differs from the adjacent areas, suggesting inconsistency in skin texture.
Fake, √
Can you confirm if this picture was taken directly by
User the camera? Provide your conclusion along with
reasons. If tampered, please show the mask of the
altered area.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has been tampered with, specifically in the lower facial region, including the mouth and chin area.
2.Judgment basis:
1. The tampered area shows signs of distortion and unnatural blending with the surrounding skin texture.
2.The lighting on the tampered area does not match the rest of the face, indicating manipulation. FakeShield
3.The edges of the mouth and chin appear to be artificially smooth and lack the natural lines and shadows one would expect to see.
4.The skin tone within the tampered area differs from the adjacent areas, suggesting inconsistency in skin texture.
Fake, √
Can you confirm if this picture was taken directly by
User the camera? Provide your conclusion along with
reasons. If tampered, please show the mask of the
altered area.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has been tampered with, specifically in the region of the hair on the right side of the image.
2.Judgment basis:
1. T alh te e rh aa ti ir o no .n the right side shows an unnatural transition in color and texture compared to the left side, indicating a possible FakeShield
2.There is a lack of consistency in the hair strands' direction and flow, which is not typical of how hair naturally falls or behaves.
3.The edge of the tampered area near the hair appears to be unnaturally straight, which is atypical for the natural irregularity of
hair outlines.
Fake, √
Figure14: DialogueexamplesofFakeShieldwhenreceivingDeepFaketamperedimages. The
threeimagesallcomefromtheDFFD(Dangetal.,2020)datasetandhavebeentamperedwithby
FaceAPP(FaceAppLimited,2017). Thefirstpicturehasabeardaddedtothechin,thefirstpicture
hasglassesadded,andthethirdpicturehassomehairaddedtotherightsideoftheface.
24UnderSubmitting
User Was this picture taken directly by the camera?
State your conclusion and give reasons. If it is
tampered with, please output the mask of the
tampered area.
1. Whether the image has been tampered with/description of the tampered area:
1. The image appears to be authentic and has not been tampered with. The visible parts of the image show natural characteristics
consistent with a photograph taken directly by a camera.
2.Judgment basis: FakeShield
1. The visible portion of the image shows a natural skin tone with subtle variations and shadows that are consistent with the lighting,
suggesting that the image is real.
2.The clothing visible in the image has a realistic texture and the fabric folds align with the natural laws of physics.
3.If this image were placed among deepfake tampered pictures, it would stand out due to the consistency in lighting, natural skin
texture, and the absence of any distorted or blurred edges that are common in deepfake images.
Real, √
Can you confirm if this picture was taken directly by
User the camera? Provide your conclusion along with
reasons. If tampered, please show the mask of the
altered area.
1. Whether the image has been tampered with/description of the tampered area:
1. The image has not been tampered with. It is a picture of a face taken directly by the camera. The syntax is unchanged and the
semantics are consistent.
2.Judgment basis:
1. The visible hair strands have natural variations in color and thickness, which are typical of a real image.
2.The lighting on the hair appears consistent, with highlights and shadows that correspond to a natural environment. FakeShield
3.The texture and color of the skin near the hairline seem authentic and match the expected appearance of a real person.
4.If this image were placed among deepfake tampered pictures, it would stand out due to the natural inconsistencies and
imperfections that are characteristic of a genuine photograph, such as the variation in hair texture and the realistic interaction
of light with the skin and hair. Real, √
Can you confirm if this picture was taken directly by
User the camera? Provide your conclusion along with
reasons. If tampered, please show the mask of the
altered area.
1. Whether the image has been tampered with/description of the tampered area:
1. The image appears authentic and has not been tampered with. The visible portion of the image shows natural characteristics
consistent with a photograph taken directly by a camera.
2.J 1u .dg Tm he en vt i sb ia bs leis : p art of the image shows a portion of eyeglasses with a realistic reflection and transparency, indicating a high FakeShield
likelihood of being a genuine photograph.
2.The texture and color of the visible hair seem natural, with individual strands and natural shading that would be difficult to
replicate with deepfake technology without noticeable artifacts.
3.The edge of the eyeglasses against the skin and hair appears consistent with the expected lighting and perspective, without any
signs of blurring or distortion that might suggest digital manipulation.
4.If this image were placed among deepfake tampered images, the natural light reflection on the glasses, the hair texture, and the
absence of any unnatural symmetry or disproportionate features would be key indicators to identify it as an authentic image.
Real, √
Figure 15: Dialogue examples of FakeShield when receiving authentic face images. The three
imagesallcomefromtheDFFD(Dangetal.,2020)dataset.
25UnderSubmitting
User Was this picture taken directly by the camera?
State your conclusion and give reasons. If it is
tampered with, please output the mask of the
tampered area.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has been tampered with, specifically in the upper left corner of the image,
where the window is located. The tampered area includes the window and the objects
visible through it. FakeShield
2.Judgment basis: The tampering is evident due to several factors:
1. Lighting: The lighting on the objects visible through the window does not match the rest
of the scene. They appear to be lit inconsistently with the natural light coming into the
room.
2.Edges: The edges around the window and the objects outside are unnaturally sharp and do
not blend seamlessly with the surrounding environment, indicating possible digital insertion.
3.Perspective relationship: The perspective of the objects outside the window seems
inconsistent with the room's interior. The arrangement and proportions of these objects
do not align with the expected view through a window.
4.Shadows: There is a lack of natural reflections or shadows that one would expect from
objects seen through a window in this setting. This inconsistency suggests that the scene
outside has been artificially altered.
5.Physical laws: The appearance and placement of the objects outside the window seem
unrealistic, indicating that they have been digitally added rather than being part of the
original photo. Fake, √
IoU=0.97
Can you confirm if this picture was taken directly by
User the camera? Provide your conclusion along with
reasons. If tampered, please show the mask of the
altered area.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has been tampered with. The tampered area is located in the center of the
image, covering the entire circular object that appears to be a clock mounted on the wall. FakeShield
2.Judgment basis: The tampering is evident due to several factors:
1. Lighting: The lighting on the clock does not match the surrounding environment. The clock
appears to have a different light source, as it has highlights and shadows that are
inconsistent with the rest of the image.
2.Edges: The edges of the clock are unnaturally smooth and lack the texture continuity with
the wall it is attached to.
3.Resolution: The clock's resolution seems to be different from the rest of the image, with
the clock appearing slightly blurrier than the surrounding wall texture.
4.Perspective relationship: The clock's perspective does not fully align with the wall it is on.
The angle and position of the clock seem unnatural, as if it is not properly affixed to the
wall.
5.Shadows: The shadowing on the clock does not correspond with the light source and the
shadows present in the rest of the image, suggesting that the clock was not originally part
of the scene. Fake, √
6.Physical laws: The way the clock is mounted on the wall appears to defy physical laws, as IoU=0.99
there is no clear means of support or attachment visible.
Figure16: DialogueexamplesofFakeShieldwhenreceivingAIGC-Editingtamperedimages.
The three images all come from the self-generated AIGC-Editing dataset and have been tampered
withbyStable-Diffusion-Inpainting(Lugmayretal.,2022). Thewindowintheupperleftcornerof
thefirstpicturehasbeenredrawn,andthecircularclockareaontheleftsideofthesecondpicture
hasbeenredrawn.
26UnderSubmitting
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the picture has been tampered with / Description of the tampered area: The picture has been
tampered with, in the upper section, spanning across the entire width of the image. The tampered area includes
the mountain range and the sky immediately above it.
2. Judgment basis:
1. The tampering is evident by the unnaturally smooth transition between the mountain tops and the sky,
lacking detailed texture that would be expected in a natural setting.
2. There is a lack of consistent lighting and shadows on the mountains which do not match with the rest of the
image, indicating that this part of the image may have been inserted or altered. The edges of the mountains
against the sky are unusually crisp without gradation or atmospheric haze that would normally occur due to
distance.
3. Additionally, the pixelation around the edges of the mountains does not match the resolution of the
foreground, suggesting a composite of two different images.
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the picture has been tampered with / Description of the tampered area: The picture has been
tampered with, specifically in the area around the lighthouse. The tampered area is located in the upper right
corner of the image, against the horizon where the sky meets the sea.
2. Judgment basis: There are several details that suggest tampering:
1. Lighting: The lighthouse appears to be unnaturally bright compared to the surrounding environment,
especially given that the sun is setting and the light is diffused.
2. Edges: The lighthouse has a somewhat blurry outline that does not match the sharpness of the horizon line,
indicating it may have been artificially inserted or altered.
3. Shadows: The lighthouse does not cast a shadow that is consistent with the setting sun's direction and the
existing shadows in the image.
4. Perspective relationship: The scale of the lighthouse in relation to its placement on the horizon seems
slightly off, making it appear as if it does not quite belong there.
5. Physical laws: The lighthouse's reflection in the water does not match the angle of the sunlight or the
other reflections in the water, breaking the consistency expected in a real photo.
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the picture has been tampered with / Description of the tampered area: The picture has not been tampered with. It is a picture taken directly by
the camera.
2. Judgment basis:
1. Lighting: The lighting in the image appears natural and consistent. The light source seems to be coming from outside the window,casting shadows and
highlights appropriately on the window sill and the objects placed on it. The soft diffuse light suggests an overcast day or a shaded area outside,
common in real-life scenarios.
2. Copy and Paste: There is no visible sign of duplication or mirroring that would suggest a copy and paste operation. Each object has unique reflections,
colors, and shadows.
3. Edges: The edges of the objects, window, and foliage outside are smooth and continuous, with no visible signs of pixel distortion or abrupt changes that
would indicate tampering.
4. Resolution: The resolution of the image appears uniform, with no areas showing signs of blurring or jaggedness that would suggest a composite image.
5. Perspective: The perspective and scale of the objects on the window sill are consistent with how they would appear in real life.The size of the objects
relative to each other and their placement gives a sense of depth that aligns with normal visual perception.
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the picture has been tampered with / Description of the tampered area: The image appears not to have been tampered with. It seems to be a
picture taken directly by the camera.
2. Judgment basis:
1. Lighting: The lighting on the climber is consistent with the direction of sunlight, casting a natural shadow on the climber's body, which conforms to the
direction and quality of the lighting in the environment.
2. Copy and Paste: There are no signs of duplication or mirroring that would indicate a copy and paste operation. \n- Edges: The edges of the climber and
the rock face appear natural with no signs of unnatural pixel distribution or obvious traces of clipping.
3. Resolution: The image maintains a consistent resolution throughout, with no unnatural blurring or jaggedness that would suggest tampering.
4. Perspective: The scale and perspective of the climber against the rock face are realistic, and the proportions seem accurate.
5. Shadows: The shadows cast by the climber are consistent with the light source coming from the upper left, and there are no unnatural shadows that
would imply manipulation.
6. Text: There is no visible text or logos to assess for consistency.
7. Physical laws: The climber's position and equipment behave as expected under the force of gravity, and there are no violations of physical laws.
Figure17: MMTD-SetdatasamplesrelatedtoPhotoShoptampering. Thefourimagesareallfrom
theCASIAv2dataset. Thefirsttwopictureshavebeentamperedwith,butthelasttwopictureshave
notbeentamperedwith.
27UnderSubmitting
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has been tampered with, the tampered area is on the right side of the image, extending vertically from the
top to the bottom of the frame. It includes the edge of a bathroom wall and a portion of a black pedestal fan that
stands next to the sink.
2. Judgment basis: The tampered area shows several inconsistencies.
1. The edge of the wall on the right side has a jagged, unnatural outline that does not align with the typical straight lines
found in interior architecture.
2. Moreover, the pedestal fan has a distorted shape, with the top part of the fan appearing disconnected and floating
without support.
3. The shadows and lighting in the tampered area do not match the rest of the image; the shadow on the tampered part of
the fan is inconsistent with the lighting on the rest of the fan and the surrounding environment.
4. There are no clear reflections or shadows corresponding to the tampered section of the wall, suggesting an unnatural
alteration. The resolution in the tampered area is also inconsistent, with some parts appearing blurrier than the rest of
the image.
5. These signs indicate that the image has been edited."
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the picture has been tampered with / Description of the tampered area: The picture has been tampered with. The
tampering is located on the screen of the Nokia phone, occupying almost the entire screen area, with only a small
untampered margin visible around the edges.
2. Judgment basis:
1. The contents of the tampered area include jumbled and inverted text, numbers, and symbols that do not conform to
the typical display of a phone screen.
2. The colors within the tampered area are inconsistent with the original screen display, showing a mix of orange, yellow,
and white that appear unnatural.
3. The text and numbers are also not aligned or positioned as expected for a phone's user interface, suggesting a
manipulation of the original content. Additionally, there is a lack of continuity with the phone's expected graphical
interface, which would normally display information in an organized and legible manner."
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the picture has been tampered with / Description of the tampered area: The picture has not been tampered with. It appears to be a genuine photograph
captured directly by a camera.
2. Judgment basis:
1. The lighting in the image is consistent, with the shadows on the cake and the hands indicating a light source coming from the upper left side, which aligns with
the natural shadow casting.
2. There are no obvious signs of duplication or mirroring, and the edges of the subjects and objects are natural without any discontinuities or irregular pixel
distributions.
3. The resolution and quality of the image are uniform, with no areas showing signs of blurring or excessive compression that would suggest manipulation. The
perspective and scale of the objects and people are realistic and proportionate, and the depth of field is consistent, with a natural focus drop-off towards the
back of the image.
4. The reflections and shadows present in the image behave as expected under the lighting conditions. Text and logos visible in the background are consistent
with their surroundings. All content in the picture adheres to physical laws without any anomalies."
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the picture has been tampered with / Description of the tampered area: The image appears not to have been tampered with. It looks like a photograph
taken directly by a camera.
2. Judgment basis: The following details support the conclusion that this is a real, untampered photograph:
1. Lighting: The lighting on the salad and the glass of liquid appears consistent, with soft, diffused light coming from one general direction, which is plausible for
an indoor setting. There are no harsh shadows or inconsistent light spots that would suggest tampering.
2. Copy and Paste: There are no obvious repeating patterns or mirrored sections that would indicate a copy and paste operation has been conducted.
3. Edges: The edges of the salad leaves, fork, and other elements in the image look natural with no visible signs of harsh or artificial edges that would suggest
cutting or compositing.\n\n- Resolution: The image resolution seems consistent throughout the photograph, with no areas of unnatural blurring or pixelation that
would indicate tampering.
4. Perspective: The perspective and scale of the objects, such as the fork, salad, and glass, are consistent with what would be expected in a real-life setting.
5. Shadows: The shadows cast by the fork and the leaves in the salad are subtle and match the lighting of the scene. There are no unnatural shadows that would
suggest manipulation.
Figure 18: MMTD-Set data samples related to AIGC-Editing tampering. The four images are all
fromtheself-generatedAIGC-Editingdataset. Thefirsttwopictureshavebeentamperedwith,but
thelasttwopictureshavenotbeentamperedwith.
28UnderSubmitting
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the picture has been tampered with / Description of the tampered area: The picture has been tampered with,
specifically the hair and ears. The tampered areas include the top and sides of the head, extending to cover the full hair region
and the ears on both sides.
2. Judgment basis:
1. The hair appears unnatural and lacks consistent texture when compared to typical hair, which would normally have more
variation in color and strand definition.
2. The edges of the hair near the forehead and temples are too sharp and show no natural hairline; real hair usually has more
irregularity at the hairline.
3. There is a lack of depth and natural shading around the ears, which can be expected if the image was manipulated; ears
typically cast subtle shadows and have more defined contours.
4. The overall hair shape and the way it sits on the head do not conform to natural hair physics, indicating digital alteration."
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the picture has been tampered with / Description of the tampered area:
1. The picture has been tampered with, specifically in the lower facial region including the jawline and the chin, as well as a
small portion of the neck.
2. Judgment basis:
1. The tampered area appears to have an inconsistent skin tone compared to the surrounding untampered skin, indicating a
possible mismatch in texture and color.
2. The edges of the tampered area around the jawline and chin show signs of being unnaturally smooth, lacking the typical
definition and texture found in these facial features.
3. There is a lack of natural shadowing and lighting in the tampered area, which does not correspond with the lighting
present in the rest of the image."
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the image has been tampered with/description of the tampered area: The image does not appear to have been tampered with. The visible parts of the
image, including hair and ears, display natural variations and asymmetries typical of a real photograph taken directly by a camera.
2. Judgment basis: The hair shows natural variations in texture and color, with individual strands and different shades that are typical of real hair. The ear is
partially visible and displays a natural contour and complexion consistent with the visible hair, suggesting that the image is of a real person. To recognize it from a
bunch of deepfake tampered pictures, one would look for inconsistencies in skin texture, unnatural symmetry, or artifacts around the hair or ears—none of which
are present in this image. The natural lighting and lack of any visible digital artifacts also support the conclusion that the image is authentic and has not been
manipulated."
Was this image captured straight from the camera?
Share your conclusion and reasons. If modifications
are detected, output the tampered area's mask.
1. Whether the image has been tampered with/description of the tampered area: The image appears to be authentic and has not been tampered with. Visible parts of
the image show natural features and consistent lighting.
2. Judgment basis: The visible hair shows natural color variations and texture consistent with real hair. The lighting on the hair suggests a single light source, which
is coherent and creates realistic shadows and highlights. The portion of the ear visible in the image has natural contours and skin tone. The visible clothing appears
to have a consistent texture and sits on the body in a way that aligns with the natural folds expected from the fabric and the pull of gravity. These details
indicate that the image is likely a real photograph and would stand out as authentic among deepfake tampered pictures due to the natural inconsistencies and the
coherent lighting that deepfake images often lack."
Figure19: MMTD-SetdatasamplesrelatedtoDeepFaketampering. Thefourimagesareallfrom
theDFFD(Dangetal.,2020)dataset. Thefirsttwopictureshavebeentamperedwith,butthelast
twopictureshavenotbeentamperedwith.
29