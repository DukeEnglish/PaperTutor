CriSPO: Multi-Aspect Critique-Suggestion-guided
Automatic Prompt Optimization for Text Generation
HanHe*,QianchuLiu*,LeiXu*,ChaitanyaShivade,
YiZhang,SundararajanSrinivasan,KatrinKirchhoff
*EqualContribution
AmazonAWSAILabs
{hankcs, liufqian, leixx, shivadc,
yizhngn, sundarsr, katrinki}@amazon.com
Abstract metricimprovesovernumerousiterations.However,apply-
ingthesemethodsdirectlytotextgenerationtasks,suchas
Existingautomaticpromptengineeringmethodsaretypically
summarization,issub-optimalduetochallengesinobtain-
designedfordiscriminativetasks,wherenewtaskprompts
ingeffectiveoptimizationsignals.Unlikeclassificationtasks,
are iteratively refined with limited feedback from a single
wheremetricsarestraightforward(eg.accuracy),automatic metricreflectingasingleaspect.However,theseapproaches
metricsfortextgeneration,likeROUGE(Lin2004),provides
aresuboptimalforgenerativetasks,whichrequiremorenu-
ancedguidancebeyondasinglenumericmetrictoimprove limitedguidanceforpromptrefinement.Forexample,alower
thepromptandoptimizemultipleaspectsofthegeneratedtext. ROUGEscoremayresultfromaspectssuchasmismatched
Toaddressthesechallenges,weproposeanovelmulti-aspect length,differencesinwordchoiceduetoformality,orvary-
Critique-Suggestion-guidedautomaticPromptOptimization ing writing formats, making it difficult to guide LLMs in
(CriSPO)approach.CriSPOintroducesacritique-suggestion promptmodificationwithoutfine-grainedfeedbacktargeting
moduleasitscorecomponent.Thismodulespontaneously theseindividualaspects.Furthermore,evaluatingtextgenera-
discoversaspects,andcomparesgeneratedandreferencetexts
tioninvolvesmultiplemetrics(Fabbrietal.2021;Gaoand
acrosstheseaspects,providingspecificsuggestionsforprompt
Wan2022;Elangovanetal.2024).Inadditiontoreference
modification.Theseclearcritiquesandactionablesuggestions
similarity,othermetricssuchasfactualconsistency,which
guideareceptiveoptimizermoduletomakemoresubstantial
can be assessed using metrics like AlignScore (Zha et al.
changes,exploringabroaderandmoreeffectivesearchspace.
TofurtherimproveCriSPOwithmulti-metricoptimization, 2023),isalsoimportant.Balancingorutilizingthesemultiple
weintroduceanAutomaticSuffixTuning(AST)extension metricsisnotfullyaddressedbyexistingpromptengineering
toenhancetheperformanceoftaskpromptsacrossmultiple methodsthatfocusonoptimizingasinglemetric.
metrics.WeevaluateCriSPOon4state-of-the-artLargeLan-
To address these challenges, we introduce CriSPO, a
guageModels(LLMs)across4summarizationand5Question
multi-aspectCritique-Suggestion-guidedautomaticPrompt
Answering(QA)datasets.Extensiveexperimentsshow3-4%
ROUGEscoreimprovementonsummarizationandsubstantial Optimization(CriSPO)approach.Overall,ourapproachem-
improvementofvariousmetricsonQA. ploysLLMstoautomaticallyidentifiesmulti-aspectprompt
revisionsuggestions,basedonwhichpromptsareautomat-
ically designed and refined (Table 8 in Appendix shows a
1 Introduction
workingexampleofhowapromptgetsrevisedinCriSPO).
LLMs have emerged as powerful tools for various natural Inspiredbyrecentself-reflectionstudies,whereLLMsgen-
languageprocessingtasks,includingtextgeneration(Brown erateverbalfeedbacktoaidinself-improvement(Geroetal.
etal.2020).Tofullyleveragetheircapabilities,acriticalstep 2023;Shinnetal.2023;Madaanetal.2024),wedesignedthe
istodesignaprecisetaskpromptwhichspecifiesthedesired firstkeycomponentofCriSPO:themulti-aspectcritique-
behavioroftheLLMtosolveatask.Manualpromptengi- suggestionmeta-prompt.Itautomaticallydiscoversproper
neering is often laborious, skill-intensive and sub-optimal, aspectstocomparegeneratedtextwithreference,writecri-
motivatingtheneedforautomaticpromptengineeringtech- tiquesofflaws(Pryzantetal.2023)andsuggestionstoim-
niqueswhichautomaticallytunethetaskprompt. provethetaskprompt(Figure2showsawordcloudofas-
Recentresearchhasmadenotableprogressinautomatic pectsidentifiedbyCriSPO,includingnumberofwords,style,
prompt engineering for discriminative tasks, such as text and precision). Both critiques and suggestions, written in
classification (Zhou et al. 2022; Yang et al. 2023; Pryzant naturallanguage,aremorehelpfulforpromptimprovement
et al. 2023; Sordoni et al. 2024). These methods focus on than a single ROUGE score. We then create a receptive
optimizingtaskpromptsforasinglemetriconasingleaspect. optimizermeta-promptthatgeneratesnewprompts.Inad-
TheprocesstypicallyinvolvesinstructinganLLMoptimizer ditiontoconditioningonprevioushigh-scoretaskprompts
withameta-prompttogeneratenewtaskpromptsbasedon andscores,thisoptimizeralsoreviewsthepastcritiquesand
previously sampled task prompts and their corresponding suggestions.Itthengeneratesanoverallsuggestionandanim-
scores.Byiterativelyexploringcandidatesandselectingthe provedtaskpromptcandidateinaChain-of-Thought(CoT)
taskpromptwiththehighestscore,performanceonthetarget (Weietal.2022)manner.Ourapproachiterativelyoptimizes
4202
tcO
3
]LC.sc[
1v84720.0142:viXrathetaskpromptusingLLMssimilartopreviousworklike promptswithvariationalinferencebyconsideringtheirout-
OptimizationbyPROmpting(OPRO)(Yangetal.2023),but putsaslatentvariables.Lateron,Yangetal.(2023)propose
itenrichesthetrainingsignalwithmulti-aspectcritiquesand OPROtoimproveoverthembyincorporatingthehistoryof
suggestionstobetteroptimizeatextgenerationmetric.Tofur- pastpromptswiththeirscoreswhichstabilizesoptimization.
therenhanceperformancebyallowingtheprompttoaccess Morestructuredpromptshavealsobeenexploredbyimpos-
externaldata,wedesignthetaskprompttemplatethatcon- ing expert-level planning (Wang et al. 2023). In a parallel
tainsplaceholdersforIn-ContextLearning(ICL)examples thread, Fernando et al. (2023) and Guo et al. (2023) were
orretrievedcontexts.Thereceptiveoptimizermeta-prompt inspiredbyevolutionaryalgorithmstoperformmutationop-
generates these templates directly, so it can flexibly move erationsforpromptgeneration.Alloftheexistingapproaches
componentsintaskpromptforbetterorganization. havemostlybeendesignedtotargetclassificationtasksus-
WhileCriSPOoffersmulti-aspectguidanceforoptimiz- ingasinglemetric.Comparingtotheexistingstudies,our
ing text generation through critiques and suggestions, we proposedmethodspecificallytargetstheuniquechallenges
furtherenhancethisguidancebyincorporatingmultiplemet- intextgenerationandapproachesthepromptoptimization
ricsasadditionalteachingsignals.Tothisend,wepropose probleminamulti-aspectandmulti-metricfashion.Forprac-
a novel Automatic Suffix Tuning (AST) extension which titioners,Khattabetal.(2023)designDSPyframeworkto
divides prompts into chunks conquering different metrics. build and optimize complex LLM pipelines in a program-
Throughmulti-objectivelearning,weimproveeachnewmet- maticfashion.TextGrad(Yuksekgonuletal.2024)further
ricwithlittletonodropinexistingmetrics. generalizesoptimizationtotextbeyondprompt.OurCriSPO
We test CriSPO on state-of-the-art LLMs, including canbeusedasapowerfuloptimizerintheseframeworks.
Claude(Anthropic2023,2024),Mistral(Jiangetal.2023) Ourapproachisalsoinspiredbyrecentstudiesonusing
andLlama3(MetaAI2024),across9heterogeneousdatasets. LLMs to automatically correct its output (Pan et al. 2023;
Theseinclude4summarizationdatasetsspanningvariousab- Madaanetal.2024).Geroetal.(2023)applymultipleself-
stractiveness,formats,anddomains,aswellas5QAdatasets. reflectionstepstoimprovetheperformanceofinformation
ExtensiveexperimentsdemonstratethatCriSPOsignificantly extraction.Yanetal.(2024)useCoTtogeneratestructured
improvespromptqualityandtaskperformanceoverstrong comparisonand preferencesfortwo modeloutputs.Shinn
baselinesasverifiedbyhumanevaluation.Wealsoconduct etal.(2023)arguetheimportanceoftheself-reflectionhistory
ablationstudytoassesstheeffectivenessofkeyingredients. andproposereflexionagenttoprovideverbalfeedbackon
Ourcontributionsaresummarizedbelow: pasttrialsforbetterdecisioninthenexttrials.Itisimportant
(1)WeproposeCriSPO,anautomaticpromptengineering tonoticethattheseself-reflectionstudiesarestrictlyspeaking
approachtailoredforgenerativetasks.Itdiscoversaspects notautomaticpromptengineeringapproachesasthesestudies
to critique generated text and write suggestions for more optimizeoutputrevisionratherthandirectlyontheprompts.
effectivepromptrevision. CriSPO,however,automaticallyreflectsonthedesignofthe
(2)Weconductcomprehensiveexperimentsacrossmulti- promptandusesthesepastreflectionstorevisetheprompts.
pleLLMsanddatasets,demonstratingtheeffectivenessand
robustnessofourmethod.Weshowanoverall3-4%improve- 3 Method
ment on ROUGE scores with qualitative verification from
ProblemFormulation:Inatextgenerationtask,letD =
humanevaluation.CriSPOalsoobtainedconsistentimprove- trn
{(x ,y )} bethetrainingset,withadevelopmentset
mentsonvariousQAtasks. i i i=1...n
D andatestsetD .Here,xrepresentstheinputdata,
3)WeproposeASTthatenablesprompttuningformul- dev tst
and y is the corresponding ground truth reference. A task
tiple metrics. We show that CriSPO with AST can jointly
promptpcomprisesinstructionsthat,whenfilledwithinput
optimizeAlignScore(Zhaetal.2023)forfaithfulnessand
x,arefedtoablack-boxAPILLM 1togenerateacomple-
ROUGEforreferencesimilarity. task
tionyˆ=LLM (p,x).ThegoalistooptimizepusingD
task trn
andD toidentifyanoptimalpromptp∗ thatmaximizes
dev
2 RelatedWork
performanceononeormoreevaluationmetricsonD .
tst
There is an increasing effort in the literature to explore CriSPOOverview:CriSPOisanautomaticpromptoptimiza-
gradient-free automatic prompt engineering methods with tionalgorithmdesignedtoiterativelyrefineataskpromptp
off-the-shelfLLMs.Thefocusoftheseapproachesistofind fromaninitialseedpromptp 0totheoptimum:p∗ ←F(p 0).
agoodsearchalgorithmforbetterpromptcandidatestosolve Ineachiterationt,weconductthefollowingsteps:
discriminitivetasks.Earlierstudieshaveemployedconven-
• EvaluateonD : Apply the candidate prompt p on
trn t
tionalparaphrasingmethodsforpromptgenerationthrough
D ,callLLM togenerateoutputs{yˆt} and
editingphrases(Prasadetal.2023)orbacktranslation(Xu trn task i i=1...n
computeaprimarymetrics ,whichcanbeasinglemetric
etal.2022).Morerecently,LLMsthemselveshavebeenused t
oranaggregationofmultiplemetrics.
tosamplepromptcandidates.Zhouetal.(2022)proposedAu-
tomaticPromptEngineering(APE)whichiterativelyprompts • GenerateCritiquesandSuggestions: Apply the multi-
an LLM to generate semantically similar variations of the aspect critique-suggestion meta-prompt M and call
c
locally best prompt. Pryzant et al. (2023) add verbal feed-
backbasedonerrorexamplestoproposebetterpromptsin 1WeusenotationsLLM ,LLM ,LLM forclarity.Though
task crit opti
termsofaccuracy.Concurrently,Sordonietal.(2024)learn theysharethesameunderlyingLLMunlessspecifiedotherwise.Multi-Aspect Critique- Candidate Task Prompt Receptive Optimizer
Suggestion Meta-Prompt Here are some summarization examples: Meta-Prompt
INSERT_EXAMPLES_HERE.
Now you have to summarize an article:
Candidate task prompt INSERT_INPUT_HERE. Task Description
Try to write a short summary in a similar style.
Input Reference Generation Top-K task Scores Critiques and
prompts suggestions
Step 4: Sample new
Instructions: Step 1: Inference candidate prompt Instructions:
1. Identify aspects to critique. on 1. Synthesize all suggestions, and write
2. Compare generation with reference LLMtask ideas to improve tasks prompt.
and write critique along these aspects 2. Follow the ideas, and write a task
3. Write suggestions on task prompt. Multi-Aspect Receptive prompt using placeholders.
Critique-Suggestion Optimizer
Response LLM
crit
LLMopti Response
Multiple Aspects Ideas on how to improve
the task prompt
Critiques
Step 2: Generate Previous task Step 3: Pick top-K Candidate task prompt
prompts, scores,
Suggestions critiques and task prompts
critiques and
suggestions suggestions for next iteration
Figure1:TheCriSPOworkflowfortextgenerationtasks.Ineachiteration,acandidatetaskpromptp isappliedtoD (step1)
t trn
andevaluatedusingamulti-aspectcritique-suggestionmeta-promptM (step2).Weselecttop-K previouslysampledtask
c
prompts(step3)anduseareceptiveoptimizerM togeneratethenextcandidatep (step4).Theautomaticoptimizationloop
o t+1
runsmultipleiterations,whilethebesttaskpromptisselectedbasedonperformanceonD .
dev
LLM tocompare{yˆt} and{yt} andgen-
crit i i=1...n i i=1...n
eratecritiquesandsuggestionsc (seeSection3.1).
t
• GenerateaCandidateTaskPrompt:Selectthetop-Ktask
prompts from previous iterations based on the pri-
mary metric, and insert the corresponding K triples
{(p ,s ,c )}intothereceptiveoptimizermeta-prompt
k k k
M . Then call LLM to generate the next candidate
o opti
promptp (seeSection3.2).
t+1
We evaluate the current prompt p on D and select p∗ Figure2:Awordcloudshowingthedifferentaspectsidenti-
t dev
basedontheprimarymetric.Uponreachingthemaximum fiedbyCriSPOwhencomparinggenerationsandreferences.
numberofiterations,weapplyanoptionalASTtoenhance
performanceonsecondarymetricsonp∗ (seeSection3.3).
suggestionmodulefromthenewpromptgenerationprocess.
Figure1demonstratestheworkflowofCriSPOonsumma-
Ratherthangeneratinganewpromptwitheachsuggestion,
rizationtasks.Table8(inAppendix)showsaconcretework-
wepackahistoryofcritiquesandsuggestionsintotherecep-
ingexampleofCriSPO.
tiveoptimizerforgeneratingthenextprompt,enablingmore
3.1 Multi-AspectCritiquesandSuggestions stableoptimizationovertheinfinitesearchspace.
Our M is implemented in a single CoT meta-prompt
Givenapromptp anditsoutputs{yˆt}onD ,wedesigna c
t i trn which generates, dimensions, critiques and suggestions in
multi-aspectcritique-suggestionmeta-promptM toidentify
c onesingleLLMcall,specifically
critiques – flaws of the generated outputs across multiple
aspects,andsuggestions–specificeditsonthetaskprompt c t =LLM crit(cid:0) M c,p t,(x i,y i,yˆ it) i=1...n(cid:1) .
torectifyeachflaw. M fordifferentLLMsandtasksareshowninAppendixG.
c
Constructivecritiqueswithspontaneousdimensiondis-
3.2 ReceptivePromptOptimizer
covery: InM ,wefirstinstructLLM togeneratesev-
c crit
eral task-specific and iteration-specific aspects for a given Ourreceptivepromptoptimizermeta-promptM oimproves
batchofoutputsfromthecurrentp .Thisapproachensures over the OPRO optimizer meta-prompt (Yang et al. 2023)
t
that as task prompts evolve across iterations, the focus re- byenrichingitsoptimizationtrajectory{(p k,s k)}withpast
mains on relevant aspects, addressing specific issues that critiquesandsuggestionsc k.Thus,ourssamplescandidate
arise.Figure2illustratestheaspectsdiscoveredduringopti- prompts for the next iteration conditioned on an enriched
mization.Foreachaspect,M instructsLLM togener- optimizationtrajectory:
c crit
atesacritiquehighlightingpotentialproblemsoftheoutputs p =LLM (M ,{(p ,s ,c )}).
t+1 opti o k k k
generatedwithp onthebatch.
t Specifically,weenhancetheOPROoptimizermodulewith
Multi-aspect suggestions: In line with each critique, a thefollowingthreeimprovementstobetterutilizecritiques
corresponding suggestion is made by LLM to edit p . andsuggestionsforachievingstrongerguidanceandbetter
crit t
AsopposedtoPryzantetal.(2023),wedecoupledtheedit exploration.SeeAppendixHforallM byLLMsandtasks.
oManual AutomaticPromptEngineering
0-shot 3-shot* OPRO CriSPO CriSPO3-shot*
Dataset LLM R1 R2 RL R1 R2 RL R1 R2 RL R1 R2 RL R1 R2 RL
CNN ClaudeIn. 37.5 12.5 22.6 40.4 14.8 24.8 39.5 14.3 24.5 40.1 15.7 26.1 42.1 17.0 27.4
Claude3 38.8 14.4 24.0 40.3 15.4 25.2 39.7 15.1 5.1 42.2 17.3 27.9 41.6 16.3 27.1
Mistral7B 30.9 11.0 20.4 30.7 10.6 20.1 36.5 14.4 23.0 38.5 14.3 23.9 38.5 14.3 24.1
Llama38B 37.9 14.4 23.8 39.1 15.2 24.6# 41.5 16.3 26.5#
MBank ClaudeIn. 30.7 11.6 20.5 34.2 17.3 25.5 39.0 20.3 29.7 41.4 23.7 33.1 50.1 35.4 44.4
Claude3 31.2 14.2 22.3 37.5 22.0 29.5 41.5 21.8 32.0 47.4 32.5 40.9 58.5 46.5 54.1
Mistral7B 26.0 11.5 18.5 31.3 14.8 22.7 33.9 15.4 24.2 39.1 19.5 29.3 35.2 16.7 26.1
Llama38B 31.4 14.6 22.6 40.2 22.3 31.5# 44.7 27.6 36.8#
SAMSum ClaudeIn. 33.9 11.7 25.6 37.8 14.3 28.8 38.1 13.4 28.7 44.4 16.9 34.3 45.7 18.7 36.2
Claude3 35.8 12.7 27.0 41.1 16.6 31.3 39.0 14.7 30.1 43.4 17.1 34.3 47.2 20.8 38.2
Mistral7B 32.0 10.2 24.1 39.5 14.1 30.3 37.9 13.6 29.0 37.6 12.4 28.4 40.0 14.2 30.8
Llama38B 35.7 12.3 27.1 39.3 14.7 30.0# 44.8 18.8 35.4#
D2Note ClaudeIn. 43.8 16.9 26.1 51.5 23.6 33.5 45.2 16.3 25.5 53.0 19.7 26.8 58.2 26.7 35.3
Claude3 47.3 20.3 29.3 59.1 30.1 38.6 48.8 20.1 29.5 54.0 21.4 30.3 63.1 32.5 41.0
Mistral7B 47.8 17.7 25.4 48.4 19.2 28.1 45.1 17.0 25.2 50.2 18.2 25.6 50.3 18.7 26.2
Llama38B 50.5 19.8 27.7 54.2 22.0 29.3# 56.2 22.8 29.9#
Average ClaudeIn. 36.5 13.2 23.7 41.0 17.5 28.2 40.4 16.1 27.1 44.7 19.0 30.1 49.0 24.4 35.8
Claude3 38.3 15.4 25.6 44.5 21.0 31.2 42.2 17.9 29.2 46.8 22.1 33.3 52.6 29.0 40.1
Mistral7B 34.2 12.6 22.1 37.5 14.7 25.3 38.4 15.1 25.4 41.4 16.1 26.8 41.0 16.0 26.8
Llama38B 38.9 15.3 25.3 43.2 18.6 28.8 46.8 21.4 32.2
Table1:ComparingCriSPOwithmanualpromptsandOPROonrepresentativesummarizationbenchmarks.AveragedR1/R2/RL
(i.e.ROUGE-1/2/L)arereportedacross3runs.3-shot*:3-shotICLwithexampleselection.Claude3:Claude3Sonnet.Claude
In.:ClaudeInstant.Llama3resultsmarkedwith(#)areusingClaude3Sonnetastheoptimizer.3-shot*resultsareemptyfor
Llama3duetoitslimitedcontextwindow.StandarddeviationandSOTAresultsareinAppendixL.Claude3Sonnetachieves
newSOTAROUGE-1performanceonD2Note.MBank:MeetingBank;D2Note:Dialogue2Note.
Enrichedoptimizationtrajectory: Thecritiquesandsug- holder INSERT EXAMPLES HERE to indicate the posi-
gestions generated in Section 3.1 are used in an enriched tion of ICL examples. In Retrieval-Augmented Genera-
optimizationtrajectorytoproposenewpromptsviaanOPRO- tion (RAG) settings, we introduce a context placeholder
styleoptimizer.Specifically,ourenrichedoptimizationtrajec- INSERT CONTEXT HERE which will be replaced by the
toryincludesthetop-K best-performingpastprompts{p }, retrieved context for each question. When filled the place-
k
theirscores{s },critiquesandsuggestions{c },sortedin holderswithproperdata,thetaskpromptclearlyorganized
k k
theascendingorderbyscores.Includingcritiquesandsug- alltheinformationtohelpLLM bettersolvethetask.
task
gestions in the optimization trajectory allows the LLM to
avoid common limitations and identify common strengths 3.3 Multi-MetricAutomaticSuffixTuning
fromthepastpromptsforstableoptimization.
UsingcomponentsinSection3.1and3.2,CriSPOisready
Chain-of-thought: Afterenrichingtheoptimizationtrajec- tooptimizeaprimarymetric.Tobenefitfrommoreteaching
tory,wealsoapplyCoTtotheoptimizationprocess.Specifi- signals,e.g.,completenessandfaithfulness,hereweextend
cally,LLM isexplicitlyaskedtofirstcomparehigh-score CriSPOtomulti-metricoptimizationbyproposinganovel
opti
promptstolow-scoreones,andthenelicitgeneralideasand multi-metriclearningextensionnamedasAST.
learnings,andfinallydraftanewandbetterprompt.CoTfur- InAST,weproposetooptimizeasuffixpostscriptσ ap-
therensurestheoptimizertoharnesscollectivestrengthfrom pended to p∗, which has already been trained on certain
thehistoryandidentifyapromisingpaththroughcomparing metrics. p∗ will remain fixed throughout the whole tuning
thedivergentpastprompts. processforanewmetrictopreservemostofitsperformance
on existing metrics. p∗ is extended with an additional suf-
Flexible task prompt template: Instead of only tuning fix σ∗ ← F(σ ), which serves as a postscript to steer the
0
instruction text and fixing the input position as in exist- LLM toward the new metric and remedy any potential re-
ingapproachessuchasOPRO,CriSPOoptimizesthetask gressioninperformanceonexistingmetrics.Specifically,we
prompt structure using a template that can freely and nat- provideboththemainpromptp∗ andeachsuffixσ inthe
t
urally move around input and instruction in the prompt. meta-prompts while asking the LLM to critique or refine
It uses placeholders for the input and any external data. onlythesuffix.Toensurewemaintainexistingmetricswhile
For example, we instruct LLM to generate example place- improvingontheadditionalmetric,wetakeinspirationsfromthebalancetermsoflossfunctionsinmulti-tasklearning(He w/oICLcanmatchorevenoutperformmanualpromptwith
andChoi2021)andcomputeanaggregatedscoreacrossthe 3-shotinmostdatasetsandsetups,reducinglatencyandcost.
multiplemetrics.Sincethescoreofeachmetricisondiffer-
entscalesandhardtoestimatebeforetraining,weproposeto 4.3 AblatingKeyIngredients
usetheaveragerankingofeachmetricastheultimatebasis
Table 2 shows the ablation results of CriSPO with Claude
toscorepromptcandidatesinthemeta-prompt.
InstantonSAMSumdataset.Weobservedthatthethreekey
components in our approach, including flexible template,
4 MainExperiments
critique and step-by-step CoT optimization, are essential
4.1 ExperimentSetup forachievingoptimalperformance.Removinganyofthese
componentsleadstoadecreaseinperformance.Removing
Datasets We select a diverse range of 4 summarization critique-suggestionmoduleandCoToptimizationaltogether
tasksincludingconventionaldocumentsummarizationtasks leadstoa5pointdecrease,similartoOPROperformance.
suchasCNNdailymail(Hermannetal.2015)(newsheadline Thisindicatesthesetwoelementsareessentialtothesuccess
summarization),andalsoconversationsummarizationtasks ofCriSPOandflexibletemplateisonlyeffectivewhenbeing
such as SAMSum (Gliwa et al. 2019), MeetingBank (Hu addedontopofthesetwoelements.
etal.2023).Inaddition,wetestonamedical-domainclinical
notesummarizationtask,Dialogue2Note(Yimetal.2023).
Method Crit-Sugg CoT Template avg std
DetaileddatasetupcanbefoundinAppendixC.Thesetasks
covervariouslengths,domainsandstylesassummarizedin CriSPO ✓ ✓ ✓ 44.4 1.9
Table9.WereportROUGE-1/2/LF-measure(Lin2004)2to ✗ ✓ ✓ 42.8 0.8
measureoutputsimilaritytothereferences. ✓ ✗ ✓ 43.9 0.3
✓ ✓ ✗ 42.2 1.6
LLMsandBaselines Wetestourapproachonstate-of-the- ✗ ✗ ✓ 37.4 3.4
artLLMsincludingproprietarymodels:ClaudeInstant(An- OPRO ✗ ✗ ✗ 38.1 1.3
thropic2023),Claude3Sonnet(Anthropic2024),andopen-
Method Changingmulti-aspect
sourceLLMs:Mistral7B(Jiangetal.2023)andLlama38B
(MetaAI2024).WeusethesameLLMforallthe3CriSPO CriSPO freemulti-aspects 44.4 1.9
modules: task inference, critique-suggestion and receptive nomulti-aspects 41.1 0.9
pre-definedmulti-aspects 44.5 0.7
optimization,apartfromtheLlama3setup.Specifichyper-
parameterswithablationsaredetailedinAppendixD.
Table2:AblationstudiesofCriSPOontheSAMSumdataset
Our baseline methods include manual prompts with
withClaudeInstant.Wereportaverageandstddeviationof
zero/few-shotICL.Thesemanualpromptsarecarefullytuned
theROUGE-1Fresultsacross3runs.
foreachtasktoincorporatelengthconstraintsandtaskguide-
lines,andthereforeestablishahighbarofperformancefrom
manualpromptengineering(AppendixI).Giventhereareno Thekeynoveltyinourproposednovelcritique-suggestion
existingautomaticpromptingresultsfortextgeneration,we strategyinCriSPOisthatithasmulti-aspect:i.e.theLLM
adaptedOPRO(Yangetal.2023),acompetitiveestablished willgeneratemulti-aspectcomparisonwithoutenforcingpre-
approach, on our selected tasks. We use the same hyper- definedaspects.Tounderstandtheeffectofthemulti-aspect
parametersetupinOPROandCriSPOforfaircomparison. critique-suggestion,weprovidetwoalternativebaselines:1.
nomulti-aspect:weaskLLMtocomparepredictionsandref-
4.2 MainResults erencesingeneralwithnoexplicitrequirementforgenerating
critiqueandsuggestionsalongmultipledimensions/aspects.
AsshowninTable1,acrossallthetasksandLLMs,CriSPO
This is in line with the approach adopted by Pryzant et al.
consistentlyimprovesover0-shotmanualpromptandOPRO
(2023).2.predefinedaspects:wecarefullydesigndimensions
baselines.Overall,thereareapproximately3-4pointimprove-
potentiallyhelpfulforthesummarizationtaskandinclude
mentsforallLLMs.Eventhestrongstate-of-the-artClaude3
verbosity,comprehensiveness,precisionandstylealongwith
SonnetmodelcanstillgreatlybenefitfromCriSPO.Thecon-
theirdefinitions(AppendixK).Thenomulti-aspectcritique-
sistentimprovementshowsCriSPOisamoreeffectivesearch
suggestion baseline performs significantly worse, lacking
methodthanexistingmethod(OPRO)tounlockthefullpo-
criticalandtargetedsuggestionsduetoitstendencytobetoo
tentialoftheseLLMs,andoffersanalternativesolutionto
general.Thepredefinedmulti-aspectapproachisaseffective
themorelabour-intensivemanualpromptengineering.
asCriSPObutweseenosignificantimprovementfromex-
Additionally,wefoundexamplestobehelpfulasadding
plicitdefinitionsofdimensions.Thisisbecausethecritique
3-shotICLsignificantlyimprovestheperformance.Owning
LLMinCriSPOisalreadyabletoidentifyrelevantdimen-
totheversatiletemplateinCriSPO,wecaneasilyintegrate
sions(suchascompleteness,verbosityetc.asinTable8)for
examplesandweshowCriSPO3-shotcanfurtherboostper-
eachiterationwithoutexplicitguidance.
formanceoverCriSPOandachievesthebestperformancein
mostsetups.ItisalsoworthnoticingthatthevanillaCriSPO
4.4 QualitativeAnalysisandHumanEvaluation
2WereportadditionalmetricsincludingAlignScore(Zhaetal. ToqualitativelycompareCriSPOoutputswiththebaselines,
2023)andBertScore(Zhangetal.2019)inAppendixL. we conducted human evaluation on 20 examples from theSAMSum testset. We follow the procedure from Liu et al. (Reimers and Gurevych 2019) to obtain their embeddings
(2023)wherethereferencesummariesaresplitintoatomic andcosinedistances.
contentunitsandannotatorsmarkthemaseitherpresentor AsshowninTable5,CriSPOpromptsdemonstratelarger
missing in the prediction summary. In total, we collected variationsinlengthandvocabularywhilebeinglesssimilar
300 annotations (100 annotations × 3 annotators). A final inlexiconsandsemantics,indicatingitsstrengthinexploring
normalizedrecallscoreiscomputedwithalengthpenalty, alargerspace.Wealsoprovideavisualizationoftheprompts
whichindicateshowsimilarthepredictionsummaryistothe foundbyOPROandCriSPOinAppendixF.
referencesummary.Inourexperiment,weaskedthreeanno-
tatorswithpostgraduatedegreestoindependentlyannotate
thesummarieswithblindedsetup.Theinter-annotatoragree-
Dataset Length↑ Vocab↑ ROUGE-L↓ Cosine↓
mentis“almostperfect”(0.8679Fleisskappa).Wethentook CNN
themajorityvote,andcalculatedthefinalnormalizedrecall OPRO 41±6 36±5 57.5 0.93
score(humanrating)usingade-correlatedlengthpenalty. CriSPO 149±24 96±12 50.3 0.90
AsshowninTable3,CriSPOachievesthehighestrating
MeetingBank
accordingtoourhumanevaluation.Table4showsqualitative OPRO 31±5 28±4 44.9 0.84
exampleswherepromptsfoundbyCriSPObettercapturethe CriSPO 216±41 135±19 39.7 0.80
style of the reference summaries in terms of length, what
SAMSum
tofocusonandwhattoskip.CriSPOoutputsalsolookthe
OPRO 34±6 30±5 57.0 0.94
mostsimilartothereferences,especiallyintermsofbeingas CriSPO 172±22 112±12 46.0 0.88
conciseasthereferencewhilecoveringallthekeydetails.
D2Note
OPRO 58±11 46±8 62.7 0.95
Manual OPRO CriSPO CriSPO 247±40 117±13 54.3 0.93
HumanRating 0.58 0.59 0.63
Table5:Promptdiversityon4summarizationdatasets.
Table3:HumanevaluationonsampledSAMSumtest.
5 ExtensionwithMulti-MetricOptimization
OPRO[BestPrompt]:Generateaonetotwosentencesum-
marywithinthe 〈summary〉 tagsthatconcisely describesthe ASTSetup Inthisexperiment,weextendCriSPOwithour
keydetailsoftheconversationandanyconclusionsreached. proposedASTtooptimizemultiplemetricssimultaneously.
INPUT DOC Specifically,wetakethebestpromptsoptimizedforROUGE-
CriSPO[BestPrompt]:Thetextbelowcontainsadiscussionex- 1F-measurefromCriSPOwithClaudeInstantastheseed
pressingseveralkeyfactsandevents.Yourconcise1-sentence main prompt p∗. We employ AST to optimize AlignScore
summary should relate only the 2 most important pieces of (Zhaetal.2023)startingfromasimpleseedsuffixσ :“Every
0
informationstated,withoutassumptionsorextracontext.IN-
wordofyoursummarymustbefaithfultotheinput/conversa-
PUT DOCWritethesummarywithin〈summary〉tags.
tion”acrossalldatasets.TheAlignScorebetweentheinput
OPRO[ExampleOutput]:RalphaskedAndrewifhehearda textandtheoutputsummaryisusedasasignalreflectingthe
Polishjoke,thentoldajokeaboutsinkingaPolishbattleshipby
faithfulness.Withregardtobaselines,wereporttheinitial
puttingitinwater.Andrewrespondedthatthejokewasterrible
performanceinROUGE-1F-measureandAlignScoreofthe
andsounfunnythatitmadehismouthdry,requiringasipof
seedmainpromptw/andw/otheseedsuffix.Wealsoprovide
water.
astrongbaselinetotuneboththemainpromptanditssuffix
CriSPO[ExampleOutput]:RalphtellsAndrewaPolishbat-
tleshipjokethatAndrewfindsunfunny. together(fulltuning)ratherthanonlythesuffixinAST.
[Reference]:RalphtoldAndrewajoke.
Results Theresultsformulti-metricoptimizationarepre-
Table4:QualitativelycomparingpromptsfoundbyOPRO sentedinTable6.Onalldatasets,ourASTisabletooptimize
andCriSPOonSAMSum.CriSPOisabletofindapromptto thenewmetricAlignScorewithanegligibleorzeroregres-
generateoutputmoresimilartothereference’sconcisestyle. sionontheexistingmetricROUGE,meaningthatASTcan
reduce LLM hallucination while maintaining relevancy in
theoutput.Inparticular,ASTdramaticallyimprovesAlign-
4.5 QuantitativeAnalysisofPromptDiversity
Scoreby11.7pointsonCNN.Acrosstasks,ASTisthemost
ToverifythatourdesigninSection3leadstoabetterexplo- effectiveapproachtoimproveAlignScorewhilemaintaining
rationofthesolutionspace,wequantitativelyanalyzethedi- ROUGE.Amongallmethods,ASTistheonlyonethatbrings
versityofpromptsfoundbyCriSPOandOPRO(samehyper- consistentimprovementonAlignScoreforeverytask,and
parameters, Section 4.1) on the summarization datasets. achievesthebestaverageoverallimprovement(by4.3).The
We measure 4 aggregated properties on all task prompts mainpromptw/suffixseedpromptslightlyimprovesAlign-
exploredbyeachmethodduringoptimization:length(num- Score(by1.2)andthefull-tuningbaselineonlymeaningfully
ber of words), vocabulary size (number of unique words improvesAlignScoreonCNNandtheoverallimprovement
used),andpairwiseROUGE-L/semanticsimilarity.Forpair- ismarginal(by0.7).ThesuperiorityofASTshowsthatitcan
wisesemanticsimilarity,weemploySentenceTransformers robustlyoptimizemultiplemetricsacrossvariousdomains.Seed CriSPO:F(·) ing consistent improvement over the manual prompt and
OPRO. Surprisingly, CriSPO even outperforms OPRO on
main w/suffix full w/AST
MedMCQAdespiteitisnotdesignedforclassificationtasks.
Dataset p∗ p∗+σ F(p∗+σ ) p∗+F(σ )
0 0 0
CNN
ROUGE-1 40.7 40.6 40.6 40.4 Manual AutomaticPromptEngineering
AlignScore 66.5 69.5(↑3.0) 69.6(↑3.1) 78.1(↑11.7) Task Claude 0-shot 64* OPRO CriSPO CriSPO64*
NQ Instant 34.0 33.4 8.0 36.5 37.8
MeetingBank
Sonnet 26.6 32.0 6.7 38.3 38.7
ROUGE-1 39.6 39.9 39.4 39.7
AlignScore 43.6 43.7 43.8 44.4(↑0.9)
T-QA Instant 58.6 59.2 53.7 66.3 67.5
SAMSum Sonnet 58.4 65.0 41.8 70.6 72.1
ROUGE-1 45.5 45.9 45.8 45.1 0-shot 5* OPRO CriSPO CriSPO5*
AlignScore 87.2 86.6(↓0.6) 86.6(↓0.6) 88.6(↑1.4)
Squad Instant 79.5 82.5 78.5 87.8 89.4
D2Note Sonnet 76.1 83.2 76.4 85.3 87.9
ROUGE-1 54.4 55.2(↑0.8) 54.5 54.3
NarQA Instant 64.2 67.0 59.4 75.1 76.1
AlignScore 66.7 69.0(↑2.3) 66.5 70.0(↑3.4)
Sonnet 64.0 66.7 58.6 76.2 75.2
Average
Med- Instant 49.2 53.8 50.5 52.3 54.4
ROUGE-1 45.1 45.4 45.1 44.9
MCQA Sonnet 49.8 54.4 57.7 57.9 57.4
AlignScore 66.0 67.2(↑1.2) 66.7(↑0.7) 70.3(↑4.3)
Table7:ComparingCriSPOwithmanualpromptsandcom-
Table6:ClaudeInstantmulti-metricresultsonsummariza-
petitive automatic prompt engineering baseline OPRO on
tion tasks. In seed block, main and w/ suffix refers to the
representativeQAbenchmarks.WereportExactmatching
ROUGE-1-optimizedpromptp∗anditsconcatenationwith
forNQ(NaturalQuestions)andTQA(TrivialQA).Wereport
themanualsuffixσ respectively.InCriSPOblock,fulland
0 F1forSquad,Rouge-LforNarQA(NarrativeQA),andaccu-
w/ASTreferstothefull-prompttuningbaselineandAST
racyforMedMCQA.k*:k-shotICLwithexampleselection.
inSection3.3respectively.Weshowintheparenthesesthe
StandarddeviationscanbefoundinTable16.
absolutedifferenceswithmainp∗onlywhen>0.5.Herewe
useCriSPOF(·)tooptimizeanaggregationoftwometrics.
7 Conclusion
6 GeneralizationtoOtherTasks
In this paper, we tackle the challenging problem of auto-
To confirm its generalizability, in this section, we apply maticpromptengineeringfortextgeneration.Wepropose
CriSPOtoextractive,abstractiveandmulti-choiceQAtasks. CriSPO,amulti-aspectcritique-suggestionguidedoptimizer
augmentedwithenrichedtrajectory,CoTandflexibletem-
Datasets WebenchmarkCriSPOon5commonlyusedQA
plate.Ourexperimentsshowmulti-aspectcritique-suggestion
datasets,including1)Wikipedia-basedQA:NaturalQues-
is critical for finding good task prompts. Overall, CriSPO
tions(Kwiatkowskietal.2019),TriviaQA(Joshietal.2017),
achieves3-4%ROUGEscoreimprovementand4-5%human
Squad(Rajpurkaretal.2016)2)story-basedabstractiveread-
ratingincreasecomparedtobaselinemethodsforsummariza-
ingcomprehension:NarrativeQA(Kocˇisky` etal.2018)and
tion,andsignificantimprovementforQA.Wealsoshowthat
3) medical domain multiple-choice QA: MedMCQA (Pal,
CriSPO can effectively optimize multiple metrics through
Umapathi,andSankarasubbu2022).ForNaturalQuestions
a novel suffix tuning extension AST, and incorporate ICL
andTrivialQA,wealsoincorporatetheRAGsetuptoopti-
andRAGwithflexibleprompttemplates.Ablationstudies
mize the prompt template with inserted pre-retrieved con-
confirmtheeffectivenessofallCriSPOcomponents.Human
textsfromeachdataset.WeretrievedtheWikipediapages
evaluationandquantitativeanalysisshowCriSPOencourages
followingIzacardandGrave(2021).ForNarrativeQA,we
moreeffectivepromptexplorationandtheoptimizedprompts
usesummariesascontexts.ForMedMCQA,wecastittotext
canbettercapturetaskrequirements.
generationbyelicitingreasoningbeforethefinalanswer.Fol-
lowingtheconventions,wereportExactMatchforNatural
QuestionsandTriviaQA,F1forSquad,ROUGE-LforNar- Limitations
rativeQA,accuracyforMedMCQA.Forefficiency,weonly
ThelistofLLMsinourexperimentsismeanttoberepresen-
usedasmallfractionofthetrainanddevsetfortheexperi-
tativeratherthanexhaustive.Werecognizethatsupervised
ments.ThespecificdatasettingsarelistedinAppendixC.
fine-tuning can outperform prompt engineering on certain
Results Similar to summarization tasks, we observe metrics.Wealsoacknowledgetheongoingresearchonthe
CriSPO significantly outperforms the manual prompt and limitationsofautomaticevaluationmetricsfortextgenera-
OPRObaselineinvariousQAdatasetsasshowninTable7. tion.Inaddition,CriSPOcouldbecostlyinLLMAPItokens
ForNarrativeQA,CriSPObringsmassiveimprovement(+10 especially with long input. Finally, while our experiments
ROUGE-L) compared with baselines, achieving the new focusonsummarizationandQA,CriSPOcanbeadaptable
SOTAperformance.ForNaturalQuestionsandTrivialQA, toothertextgenerationtasks,whichweleaveforfuturere-
CriSPOhasnoissueincorporatingtheRAGsetupandachiev- search.SeeAppendixBforadetailedlimitationsdiscussion.References He, H.; and Choi, J. D. 2021. The Stem Cell Hypothesis:
DilemmabehindMulti-TaskLearningwithTransformerEn-
Anthropic.2023. Claudeinstantmodel1.2. Accessed:2024-
coders. InMoens,M.-F.;Huang,X.;Specia,L.;andYih,S.
06-13.
W.-t.,eds.,Proceedingsofthe2021ConferenceonEmpirical
Anthropic,A.2024. Theclaude3modelfamily:Opus,son-
MethodsinNaturalLanguageProcessing,5555–5577.On-
net,haiku. Claude-3ModelCard.
lineandPuntaCana,DominicanRepublic:Associationfor
Augenstein, I.; Baldwin, T.; Cha, M.; Chakraborty, T.; ComputationalLinguistics.
Ciampaglia,G.L.;Corney,D.;DiResta,R.;Ferrara,E.;Hale,
Hermann,K.M.;Kocisky,T.;Grefenstette,E.;Espeholt,L.;
S.;Halevy,A.;etal.2023. Factualitychallengesintheeraof
Kay, W.; Suleyman, M.; and Blunsom, P. 2015. Teaching
largelanguagemodels. arXivpreprintarXiv:2310.05189.
machinestoreadandcomprehend. Advancesinneuralinfor-
Brown,T.;Mann,B.;Ryder,N.;Subbiah,M.;Kaplan,J.D.; mationprocessingsystems,28.
Dhariwal,P.;Neelakantan,A.;Shyam,P.;Sastry,G.;Askell,
Hu, Y.; Ganter, T.; Deilamsalehy, H.; Dernoncourt, F.;
A.; et al. 2020. Language models are few-shot learners.
Foroosh, H.; and Liu, F. 2023. MeetingBank: A Bench-
Advancesinneuralinformationprocessingsystems,33:1877–
mark Dataset for Meeting Summarization. In Rogers, A.;
1901.
Boyd-Graber,J.;andOkazaki,N.,eds.,Proceedingsofthe
Devlin,J.;Chang,M.-W.;Lee,K.;andToutanova,K.2019. 61stAnnualMeetingoftheAssociationforComputational
BERT:Pre-trainingofDeepBidirectionalTransformersfor Linguistics(Volume1:LongPapers),16409–16423.Toronto,
Language Understanding. In Burstein, J.; Doran, C.; and Canada:AssociationforComputationalLinguistics.
Solorio,T.,eds.,Proceedingsofthe2019Conferenceofthe
Izacard, G.; and Grave, E. 2021. Leveraging Passage Re-
North American Chapter of the Association for Computa-
trievalwithGenerativeModelsforOpenDomainQuestion
tionalLinguistics:HumanLanguageTechnologies,Volume
Answering. In Merlo, P.; Tiedemann, J.; and Tsarfaty, R.,
1(LongandShortPapers),4171–4186.Minneapolis,Min-
eds., Proceedings of the 16th Conference of the European
nesota:AssociationforComputationalLinguistics.
Chapter of the Association for Computational Linguistics:
Elangovan, A.; Liu,L.; Xu, L.; Bodapati, S.; and Roth, D. MainVolume,874–880.Online:AssociationforComputa-
2024. ConSiDERS-The-HumanEvaluationFramework:Re- tionalLinguistics.
thinkingHumanEvaluationforGenerativeLargeLanguage
Izacard,G.;Lewis,P.;Lomeli,M.;Hosseini,L.;Petroni,F.;
Models. arXivpreprintarXiv:2405.18638.
Schick,T.;Dwivedi-Yu,J.;Joulin,A.;Riedel,S.;andGrave,
Fabbri,A.R.;Krys´cin´ski,W.;McCann,B.;Xiong,C.;Socher, E.2023. Atlas:Few-shotlearningwithretrievalaugmented
R.; and Radev, D. 2021. SummEval: Re-evaluating Sum- languagemodels. JournalofMachineLearningResearch,
marizationEvaluation. TransactionsoftheAssociationfor 24(251):1–43.
ComputationalLinguistics,9:391–409.
Jiang, A. Q.; Sablayrolles, A.; Mensch, A.; Bamford, C.;
Fernando,C.;Banarse,D.;Michalewski,H.;Osindero,S.; SinghChaplot,D.;delasCasas,D.;Bressand,F.;Lengyel,
andRockta¨schel,T.2023. Promptbreeder:Self-referential G.;Lample,G.;Saulnier,L.;etal.2023. Mistral7B. arXiv
self-improvement via prompt evolution. arXiv preprint e-prints,arXiv–2310.
arXiv:2309.16797.
Joshi, M.; Choi, E.; Weld, D.; and Zettlemoyer, L. 2017.
Gao, M.; and Wan, X. 2022. DialSummEval: Revisiting TriviaQA: A Large Scale Distantly Supervised Challenge
Summarization Evaluation for Dialogues. In Carpuat,M.; Dataset for Reading Comprehension. In Barzilay, R.; and
deMarneffe,M.-C.;andMezaRuiz,I.V.,eds.,Proceedings Kan,M.-Y.,eds.,Proceedingsofthe55thAnnualMeeting
ofthe2022ConferenceoftheNorthAmericanChapterofthe oftheAssociationforComputationalLinguistics(Volume1:
AssociationforComputationalLinguistics:HumanLanguage LongPapers),1601–1611.Vancouver,Canada:Association
Technologies,5693–5709.Seattle,UnitedStates:Association forComputationalLinguistics.
forComputationalLinguistics.
Khattab, O.; Singhvi, A.; Maheshwari, P.; Zhang, Z.; San-
Gero, Z.; Singh, C.; Cheng, H.; Naumann, T.; Galley, M.; thanam, K.; Vardhamanan, S.; Haq, S.; Sharma, A.; Joshi,
Gao,J.;andPoon,H.2023. Self-verificationimprovesfew- T.T.;Moazam,H.;Miller,H.;Zaharia,M.;andPotts,C.2023.
shotclinicalinformationextraction. InICML3rdWorkshop DSPy: Compiling Declarative Language Model Calls into
onInterpretableMachineLearninginHealthcare(IMLH). Self-ImprovingPipelines. arXivpreprintarXiv:2310.03714.
Gliwa, B.; Mochol, I.; Biesek, M.; and Wawer, A. 2019. Kocˇisky`,T.;Schwarz,J.;Blunsom,P.;Dyer,C.;Hermann,
SAMSum Corpus: A Human-annotated Dialogue Dataset K.M.;Melis,G.;andGrefenstette,E.2018. Thenarrativeqa
for Abstractive Summarization. In Wang, L.; Cheung, J. readingcomprehensionchallenge. TransactionsoftheAsso-
C.K.;Carenini,G.;andLiu,F.,eds.,Proceedingsofthe2nd ciationforComputationalLinguistics,6:317–328.
WorkshoponNewFrontiersinSummarization,70–79.Hong
Kwiatkowski, T.; Palomaki, J.; Redfield, O.; Collins, M.;
Kong,China:AssociationforComputationalLinguistics. Parikh,A.;Alberti,C.;Epstein,D.;Polosukhin,I.;Devlin,
Guo,Q.;Wang,R.;Guo,J.;Li,B.;Song,K.;Tan,X.;Liu, J.; Lee, K.; Toutanova, K.; Jones, L.; Kelcey, M.; Chang,
G.; Bian, J.; and Yang, Y. 2023. Connecting Large Lan- M.-W.;Dai,A.M.;Uszkoreit,J.;Le,Q.;andPetrov,S.2019.
guageModelswithEvolutionaryAlgorithmsYieldsPowerful NaturalQuestions:ABenchmarkforQuestionAnswering
PromptOptimizers. InTheTwelfthInternationalConference Research. TransactionsoftheAssociationforComputational
onLearningRepresentations. Linguistics,7:452–466.Li,X.;Sun,X.;Meng,Y.;Liang,J.;Wu,F.;andLi,J.2020. LargeLanguageModels. InVlachos,A.;andAugenstein,
DiceLossforData-imbalancedNLPTasks. InJurafsky,D.; I.,eds.,Proceedingsofthe17thConferenceoftheEuropean
Chai,J.;Schluter,N.;andTetreault,J.,eds.,Proceedingsof Chapter of the Association for Computational Linguistics,
the 58th Annual Meeting of the Association for Computa- 3845–3864.Dubrovnik,Croatia:AssociationforComputa-
tionalLinguistics,465–476.Online:AssociationforCompu- tionalLinguistics.
tationalLinguistics. Pryzant,R.;Iter,D.;Li,J.;Lee,Y.;Zhu,C.;andZeng,M.
Lin,C.-Y.2004. ROUGE:APackageforAutomaticEvalu- 2023. AutomaticPromptOptimizationwith“GradientDe-
ationofSummaries. InTextSummarizationBranchesOut, scent”andBeamSearch. InBouamor,H.;Pino,J.;andBali,
74–81.Barcelona,Spain:AssociationforComputationalLin- K., eds., Proceedings of the 2023 Conference on Empiri-
guistics. calMethodsinNaturalLanguageProcessing,7957–7968.
Liu,J.;Shen,D.;Zhang,Y.;Dolan,B.;Carin,L.;andChen, Singapore:AssociationforComputationalLinguistics.
W.2022. WhatMakesGoodIn-ContextExamplesforGPT- Rajpurkar, P.; Zhang, J.; Lopyrev, K.; and Liang, P. 2016.
3? In Agirre, E.; Apidianaki, M.; and Vulic´, I., eds., Pro- SQuAD:100,000+QuestionsforMachineComprehension
ceedingsofDeepLearningInsideOut(DeeLIO2022):The of Text. In Su, J.; Duh, K.; and Carreras, X., eds., Pro-
3rdWorkshoponKnowledgeExtractionandIntegrationfor ceedingsofthe2016ConferenceonEmpiricalMethodsin
DeepLearningArchitectures,100–114.Dublin,Irelandand Natural Language Processing, 2383–2392. Austin, Texas:
Online:AssociationforComputationalLinguistics. AssociationforComputationalLinguistics.
Liu, Y.; Fabbri, A.; Liu, P.; Zhao, Y.; Nan, L.; Han, R.; Reimers,N.;andGurevych,I.2019. Sentence-BERT:Sen-
Han,S.;Joty,S.;Wu,C.-S.;Xiong,C.;andRadev,D.2023. tenceEmbeddingsusingSiameseBERT-Networks. InPro-
Revisiting the Gold Standard: Grounding Summarization ceedingsofthe2019ConferenceonEmpiricalMethodsin
EvaluationwithRobustHumanEvaluation. InRogers,A.; Natural Language Processing. Association for Computa-
Boyd-Graber,J.;andOkazaki,N.,eds.,Proceedingsofthe tionalLinguistics.
61stAnnualMeetingoftheAssociationforComputational Shinn,N.;Cassano,F.;Gopinath,A.;Narasimhan,K.;and
Linguistics(Volume1:LongPapers),4140–4170.Toronto, Yao,S.2023. Reflexion:languageagentswithverbalrein-
Canada:AssociationforComputationalLinguistics. forcementlearning. InOh,A.;Naumann,T.;Globerson,A.;
Madaan, A.; Tandon, N.; Gupta, P.; Hallinan, S.; Gao, L.; Saenko,K.;Hardt,M.;andLevine,S.,eds.,AdvancesinNeu-
Wiegreffe, S.; Alon, U.; Dziri, N.; Prabhumoye, S.; Yang, ralInformationProcessingSystems,volume36,8634–8652.
Y.; et al. 2024. Self-refine: Iterative refinement with self- CurranAssociates,Inc.
feedback. AdvancesinNeuralInformationProcessingSys- Sordoni,A.;Yuan,E.;Coˆte´,M.-A.;Pereira,M.;Trischler,
tems,36. A.; Xiao, Z.; Hosseini, A.; Niedtner, F.; and Le Roux, N.
MetaAI.2024. LLaMA3Model. Accessed:2024-06-13. 2024. Jointpromptoptimizationofstackedllmsusingvaria-
Mu,W.;andLim,K.H.2022. UniversalEvasionAttacks tionalinference. AdvancesinNeuralInformationProcessing
on Summarization Scoring. In Bastings, J.; Belinkov, Y.; Systems,36.
Elazar,Y.;Hupkes,D.;Saphra,N.;andWiegreffe,S.,eds., Touvron,H.;Martin,L.;Stone,K.;Albert,P.;Almahairi,A.;
Proceedings of the Fifth BlackboxNLP Workshop on Ana- Babaei,Y.;Bashlykov,N.;Batra,S.;Bhargava,P.;Bhosale,
lyzingandInterpretingNeuralNetworksforNLP,104–118. S.;etal.2023. Llama2:Openfoundationandfine-tunedchat
AbuDhabi,UnitedArabEmirates(Hybrid):Associationfor models. arXivpreprintarXiv:2307.09288.
ComputationalLinguistics. VanderMaaten,L.;andHinton,G.2008. Visualizingdata
Nishida,K.;Saito,I.;Nishida,K.;Shinoda,K.;Otsuka,A.; usingt-SNE. Journalofmachinelearningresearch,9(11).
Asano, H.; and Tomita, J. 2019. Multi-style Generative Wang,B.;Liu,Z.;andChen,N.2023. InstructiveDialogue
ReadingComprehension. InKorhonen,A.;Traum,D.;and SummarizationwithQueryAggregations. InBouamor,H.;
Ma`rquez,L.,eds.,Proceedingsofthe57thAnnualMeeting Pino,J.;andBali,K.,eds.,Proceedingsofthe2023Confer-
oftheAssociationforComputationalLinguistics,2273–2284. enceonEmpiricalMethodsinNaturalLanguageProcessing,
Florence,Italy:AssociationforComputationalLinguistics. 7630–7653.Singapore:AssociationforComputationalLin-
Nori, H.; King, N.; McKinney, S. M.; Carignan, D.; and guistics.
Horvitz,E.2023. Capabilitiesofgpt-4onmedicalchallenge Wang,X.;Li,C.;Wang,Z.;Bai,F.;Luo,H.;Zhang,J.;Jojic,
problems. arXivpreprintarXiv:2303.13375. N.;Xing,E.;andHu,Z.2023. PromptAgent:StrategicPlan-
Pal,A.;Umapathi,L.K.;andSankarasubbu,M.2022.Medm- ning with Language Models Enables Expert-level Prompt
cqa:Alarge-scalemulti-subjectmulti-choicedatasetformed- Optimization. InTheTwelfthInternationalConferenceon
ical domain question answering. In Conference on health, LearningRepresentations.
inference,andlearning,248–260.PMLR. Wei,J.;Wang,X.;Schuurmans,D.;Bosma,M.;Xia,F.;Chi,
Pan, L.; Saxon, M.; Xu, W.; Nathani, D.; Wang, X.; and E.;Le,Q.V.;Zhou,D.;etal.2022.Chain-of-thoughtprompt-
Wang,W.Y.2023. Automaticallycorrectinglargelanguage ingelicitsreasoninginlargelanguagemodels. Advancesin
models:Surveyingthelandscapeofdiverseself-correction neuralinformationprocessingsystems,35:24824–24837.
strategies. arXivpreprintarXiv:2308.03188. Xu,H.;Chen,Y.;Du,Y.;Shao,N.;Yanggang,W.;Li,H.;
Prasad,A.;Hase,P.;Zhou,X.;andBansal,M.2023. GrIPS: and Yang, Z. 2022. GPS: Genetic Prompt Search for Ef-
Gradient-free,Edit-basedInstructionSearchforPrompting ficientFew-ShotLearning. InGoldberg,Y.;Kozareva,Z.;andZhang,Y.,eds.,Proceedingsofthe2022Conferenceon
EmpiricalMethodsinNaturalLanguageProcessing,8162–
8171. Abu Dhabi, United Arab Emirates: Association for
ComputationalLinguistics.
Yan,J.N.;Liu,T.;Chiu,J.;Shen,J.;Qin,Z.;Yu,Y.;Lak-
shmanan,C.;Kurzion,Y.;Rush,A.;Liu,J.;andBendersky,
M.2024. PredictingTextPreferenceViaStructuredCompar-
ativeReasoning. InKu,L.-W.;Martins,A.;andSrikumar,
V.,eds.,Proceedingsofthe62ndAnnualMeetingoftheAs-
sociation for Computational Linguistics (Volume 1: Long
Papers),10040–10060.Bangkok,Thailand:Associationfor
ComputationalLinguistics.
Yang, C.; Wang, X.; Lu, Y.; Liu, H.; Le, Q. V.; Zhou, D.;
and Chen, X. 2023. Large Language Models as Optimiz-
ers. InTheTwelfthInternationalConferenceonLearning
Representations.
Yim, W.-w.; Fu, Y.; Ben Abacha, A.; Snider, N.; Lin, T.;
andYetisgen,M.2023. Aci-bench:anovelambientclinical
intelligencedatasetforbenchmarkingautomaticvisitnote
generation. ScientificData,10(1):586.
Yuksekgonul,M.;Bianchi,F.;Boen,J.;Liu,S.;Huang,Z.;
Guestrin,C.;andZou,J.2024. TextGrad:Automatic”Differ-
entiation”viaText.
Zha, Y.; Yang, Y.; Li, R.; and Hu, Z. 2023. AlignScore:
EvaluatingFactualConsistencywithAUnifiedAlignment
Function. InRogers,A.;Boyd-Graber,J.;andOkazaki,N.,
eds.,Proceedingsofthe61stAnnualMeetingoftheAssocia-
tionforComputationalLinguistics(Volume1:LongPapers),
11328–11348.Toronto,Canada:AssociationforComputa-
tionalLinguistics.
Zhang,T.;Kishore,V.;Wu,F.;Weinberger,K.Q.;andArtzi,
Y.2019.BERTScore:EvaluatingTextGenerationwithBERT.
InInternationalConferenceonLearningRepresentations.
Zhou,Y.;Muresanu,A.I.;Han,Z.;Paster,K.;Pitis,S.;Chan,
H.; and Ba, J. 2022. Large Language Models are Human-
LevelPromptEngineers. InTheEleventhInternationalCon-
ferenceonLearningRepresentations.Appendix
Flow Component Text
Hereisaninput:
Promptv1 INSERTINPUTHERE
Writeasummarywithin〈summary〉tagsforit.
Output TegantellsValentiathatPaul’sbrothersentherafriendrequestonsocialmedia.Sheisunsurehowtorespondtotherequest.ValentiaadvisesTeganto
score:33.3 ignorethefriendrequest,asshedoesnotwantTegantogodownthesamedifficultroadshehadwithPaul.TeganagreeswithValentia’sperspective.
-Numberofwords:Thepredictedsummariestendedtobelongerwithmoredetailswhilethereferencesummarieswereshorterandmoreconcise.
-Numberofsentences:Thepredictedsummariesusedmoresentencestodescribetheinputswhilethereferencesummariesweremoresuccinctwith
Critique fewersentences.
-Precision:Somedetailsinthepredictedsummarieswerenotimportantandnotmentionedinthereferencesummaries.
-Recall:Somekeydetailshighlightedinthereferencesummariesweremissingfromthepredictedsummaries.
-Specifyingtheexpectedlengthofthesummary(e.g.1-2sentences)
Suggestion -Emphasizingtoonlyincludethemostimportant/keydetails
-Indicatingwhichdetailsshouldbeprioritizedoromitted
Forthegiventext,writea1-2sentencesummarywithin〈summary〉tagsthathighlightsthemostimportantdetails.Focusonincludingwhothekey
Promptv2 peopleareandwhathappenedbetweenthem.
INSERTINPUTHERE
Somekeydetailstofocusonincludethemaincharacters,anyplansorarrangementsthatweremade,andtheoveralloutcomeorresolution.
Output TegantellsValentiathatPaul’sbrothersentherafriendrequestonsocialmedia,thoughsheandPaulhadpreviouslybrokenup.Valentiaadvises
score:42.1 Tegantoignoretherequest,notwantingTegantorevisitherpastrelationshipwithPaul.
-Numberofwords:Predictedsummariestendtobelongerthanreferencesummaries.
Critique -Numberofsentences:Predictedsummariesusemultiplesentenceswhilereferencesuse1-2sentences.
-Precision:Predictedsummariesincludemorecontextualdetailswhilereferencesfocusonlyonkeypeopleandevents.
-Recall:Predictedsummariescovermoreinformationfromtheinputwhilereferencesonlyhighlightthemostimportantdetails.
-Suggestusinglessthan10wordswherepossible
Suggestion -Emphasizeconcise1-2sentenceformatoverdetail
-Specifytofocusonlyonkeyevents/outcomes,notcontext
Comparingthehigh-scoreandlow-scoreinstructions,herearesomesuggestionsthatcouldimprovethem:
CoT 〈suggestion〉Specifythedesiredlengthorrangeforthesummaries(e.g.,10wordsand1-2sentences).〈/suggestions〉
Suggestion 〈suggestion〉Specifytofocusonkeyeventsandspecifywhichdetails〈/suggestion〉
〈suggestion〉Specifytheoutputshouldnotcontainunnessarycontext〈/suggestion〉
I Pm rop mro pv ted R sue mad mt ah re yd wi ia tl ho ig nu 〈e sup mro mvi ad re yd 〉i tn agI sN tS haE tR cT onI cN isP eU lyT caH pE tuR reE sta hn ed seid imen pti of ry tat nh te pk loe ty pe ov ie nn tst ,s sb ue ct hw ae sen whch oa wra ic llte br os rra on wd aou dt rc eo sm soe rs. wT hh oe hn aw sari nte ina te1 r- v2 ies we ,n wte hn ic le
e
keepingwithin10wordswherepossible.Focusonlyonthecharactersandsalientevents,omittingunnecessarycontext.
Improved
Output TeganreceivesafriendrequestfromPaul’sbrotherandValentiaadviseshertoignoreitduetopastissues.
score:75.6
Reference TeganhasreceivedafriendrequestfromPaul’sbrother.Valentiaadvisedhernottoacceptit.
Table8:AworkingexamplefortheCriSPOframeworkforSAMSumsummarizationwithClaude3Sonnetononetraindata
point.Yellowhighlightsthegenerationfromthemulti-aspectcritique-suggestionmodule.Greenhighlightsthegenerationfrom
thereceptiveoptimizermodule.ThescoreisROUGE-1Fforthedatapoint.A ACompleteWorkingExample theoptimizationrunsfor100iterations.Especiallywhenthe
Table8showsafullworkingexampleofCriSPO. inputsinvolvelongcontexts(e.g.,RAG)and/orthetraining
setislarge.InourRAGsettings,theoptimizationtakesupto
B Limitations 2daystofinish.
MinorpromptadaptationfordifferentLLMs. Different
C DatasetSetting
LLMshavevaryingcontextlengthlimits,preferredinput/out-
putformats,etc.Therefore,ourapproachstillrequiressome ForCNN,SAMSum,MeetingBank,MedMCQA,Narrative
manual adaptation to different LLMs. However, the man- QAandSQUAD,weusetheHuggingFacedatasetsrepository.
ualeffortissignificantlylesscomparedtomanuallytuning For Dialogue2Note, we use the data from Task B at ACL
task-specificprompts,because:1)oncetuned,thecritand
ClinicalNLP MEDIQAChat shared task 2023 in the Aci-
optipromptscanbereusedfordifferenttasks,and2)the benchdataset3(Yimetal.2023).ForNaturalQuestions,we
tuningshouldmainlyfocusonformattinginput/output,and followthedatapreparationinFiD4(IzacardandGrave2021).
adjustingthenumberofexamplestofitthecontextlength,
Our experiments are conducted with sampled train and
whicharestraightforwardfollowingtheLLMdocumentation.
devset.ForDialogue2Note,weusedthefulltraining(67),
Evaluationmetrics. Evaluatingtextgenerationisachal- development(20)andtestset(40).Forothersummarization
lengingprobleminitself.Forsummarization,ourworkfo- tasks,werandomlyselected500samplesfromthefulltest
cusesonROUGEscorestoquantifythesimilaritybetween setasourtestset.Toshowtheefficiencyofourapproach,we
generatedandreferencetexts,andAlignScoretoevaluatethe usedasmallfractionofthetrainanddevelopmentset.For
factualityofthegeneratedtext.Wealsoconductedhuman CNN,wesampled100trainingsamplesasourtrainingset,
evaluation to verify our findings. (Augenstein et al. 2023) and100developmentsamplesasourdevelopmentset.For
callsoutthatcurrentfactualityevaluationsarenotreliable. othertasks,werandomlysampled50trainingsamplesasour
(Elangovanetal.2024)highlightsthechallengesofconduct- trainingset,and50developmentsamplesasourdevelopment
inghumanevaluationinLLMera.However,weacknowledge set.
thattheseevaluationsarestilllimited,whiledesigningbetter ForNQandTQA,werandomlysample200/200/500exam-
evaluationmetricsisbeyondthescopeofthispaper. plesfortraining/development/testset.Eachexamplehas100
contextparagraphsfromWikipediaandeachparagraphhas
ComparingtoSOTASFTmodels. Wewouldliketoem-
100wordsfollowingIzacardandGrave(2021).Weuseonly
phasizethatCriSPOisnotdesignedtooutperformthestate-
thetop20contextparagraphsinourexperimentsbecauseof
of-the-artgradient-basedsupervisedfine-tuning(SFT)mod-
thehighinferencecostforlongtext.
els. For some datasets, our approach still falls short com-
ForNarrativeQAandMedMCQA,werandomlysample
pared to SOTA SFT models. Prompt tuning is a discrete
100/100/500 for training/development/test set respectively.
optimizationprocesswithnoisydirectionalsignalsontopof
ForSquad,wesample50/50/500fortraining/developmen-
alimitednumberofprompttokens,comparedtosupervised
t/testsetrespectively.
fine-tuning,whichusescontinuousgradientdescentonmuch
largerdatasetstooptimizemuchmoreparameters.Therefore,
D CriSPOSettingsforDifferentLLMs
itisusuallyhardertomatchtheperformanceofSFT.
ComparisonbetweenLLMs. Ourbenchmarkonvarious Claude Settings: In suggestion-critique meta-prompt, we
LLMs is designed to demonstrate that CriSPO is compati- pass10randomlyselectedexamplesfortheLLMtoprovide
blewithawiderangeofbothproprietaryandopen-weight critique.Inoptimizermeta-prompt,weuse10historytask
(lightweight)LLMs.ThelistofLLMsismeanttoberepresen- promptswiththeircritiques,suggestionsandscores.Weadd
tativeinsteadofexhaustive.Weacknowledgetheexistence 2input/outputexamplesintheoptimizerprompt.
ofmorepowerfulLLMsfromeachfamilythatmaypushthe Mistral Settings: Mistral has a shorter context window.
performanceevenhigher,whichweleaveforfuturework. Therefore,weadjustthesettings.Wereducethetaskprompt
history to 1 in optimizer meta-prompt. On MeetingBank
GeneralizationbeyondsummarizationandQA. Inour
dataset,wetruncatetheinputdocumentto3500words,and
experiments,wemainlyfocusedonsummarizationandques-
donotprovidetheinput(onlyusegeneratedtextandrefer-
tion answering tasks. However, our proposed approach is
ence)inthecritique-suggestionmeta-prompt.
generalandcanadapttovarioustextgenerationtasks,since
Llama3 Settings: The context window of Llama3 is in-
theLLM-basedcritique-suggestionmodelonlytakesgener-
sufficient to fit a few examples and generate meaningful
atedtextandreferencetextasinputandcanspontaneously
critique-suggestions.Therefore,weuseClaude3Sonnetas
comparethemalongrelevantdimensions.Ourframeworkcan
the critique-suggestion LLM and the receptive optimizer
potentiallybenefitclassificationtasksotherthanMedMCQA
LLM.Llama3isusedonlyasthetaskLLM.
iftheyprovide“explanation”or“reasoning”toeachlabel.
Forallexperiments,wesetthetemperatureofthemeta-
Cost DespiteCriSPOhasbeenoptimizedtousearelatively promptLLMsusedfortheoptimizationtobe1.0toencour-
smallernumberofcandidatesthanexistingmethodspereach agediversity,andwesetthescorerLLM’stemperaturetobe
step, it still requires a full evaluation of the candidates on
the sampled training set of 50-200 examples, which costs 3https://github.com/abachaa/MEDIQA-Chat-2023
significantamountsofLLMAPItokensandtimeconsidering 4https://github.com/facebookresearch/FiDDataset Description Input Output
CNN/DailyMail Newsarticleheadlinegeneration. 773 58
MeetingBank Citycouncilmeeting(longconversation)summarization 3095 66
SAMSum Messenger-like(short)conversationsummarization 127 23
Dialogue2Note Docter-patient(long)conversationmedicalnotegeneration 1372 476
NaturalQuestions Open-domainQAusingRAGonWikipedia 20009.2 2.2
TriviaQA Open-domainQAusingRAGonWikipedia 20016.4 2.8
SQuAD ReadingcomprehensiononWikipedia 149.7 3.4
NarrativeQA Storyreadingcomprehension 653.6 5.0
MedMCQA Multiple-choiceQAinmedicaldomain 38.0 100.6
Table9:Datasetdescriptionandthenumberofwordsininputandoutput.ForQAdatasets,theinputincludesbothcontextsand
thequestion.
47 47
46 46
45 45
44 44
43 43
42 42
2 4 6 8 10 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0
Number of examples in critique Number of history prompts in the meta prompt
(a)TheeffectofnumberofexamplesintheCritique-Suggestion(b)Theeffectofnumberofthehistorypromptsinthereceptive
meta-prompt optimizermeta-prompt
45
46
44
44
43
42
42
40 41
38 40
20 40 60 80 100 100 200 300 400 500
Train and dev sample size Number of iterations
(c)Theeffectofthetrain/devsamplesize (d)Theeffectofthenumberofiterations
Figure3:AblationstudieswithClaudeInstantonSAMSum.Foreachsetup,wereportthemeanROUGE1F1andstandard
deviationacrossthreeruns.For(c),wechangetherandomseedtoselectdifferentsamplesacrossthethreeruns.
1F
1eguoR
1F
1eguoR
1F
1eguoR
1F
1eguoR(a)CNN (b)MeetingBank (c)SAMSum (d)D2Note
Figure4:Visualizationofpromptdiversityon4summarizationdatasetsforOPROinred•andCriSPOinblue×.
0whichgivesmorestableresultswhentheLLMisperform- marizationdatasetsusingtheall-MiniLM-L6-v2model
inginferencewiththetaskprompt.WeusethesameLLMas fromSentenceTransformers(ReimersandGurevych2019).
meta-promptandtaskpromptexceptfortheLlama3. Then,weperformt-SNEvisualization(VanderMaatenand
The initial prompts are generic and naive prompt. For Hinton2008)totheirembeddingsinatwo-dimensionalmap.
example,forsummarization,thestartingpromptis“Generate AsillustratedinFigure4,CriSPOproducesmorediverse
a summary for the input text”. For QA, the starting point prompts than OPRO on all of the 4 datasets. The distribu-
is “Answer the question using the context provided”. We tionofOPROpromptsismorecentralized,indicatingthat
alsofollowtheoriginalOPROpaper(Yangetal.2023)to OPROpromptsarehomogeneousinsemantics,possiblythe
samplekpromptcandidatesateachstepforCriSPO.Weset “semanticallysimilarparaphrases”(Yangetal.2023).How-
k=3inourexperiments.Forefficiency,wealsorundevset ever, CriSPO distribution is more divergent, with prompts
evaluationevery5stepsratherthanoneverystep.Weend spread outovera widerrange. This visualizationsuggests
theoptimizationprocesswhenwereach100steps. that prompts tuned by CriSPO are semantically more dis-
persedandversatile,whichexpandtheexplorationbeyond
E Hyper-parameterSearch paraphrasinganddirectionlessMonte-Carlosearch.
We conducted experiments as shown in Figure 3 to assess
G Multi-AspectCritique-Suggestion
theeffectofdifferenthyper-parameters.Weshowtheperfor-
manceincreasesasweincreasethenumberofexamplesin Meta-Prompt
thecritique-suggestionmeta-promptand10exampleshave
G.1 ClaudeforSummarization
asignificantjumpofperformancecomparedwith1or5ex-
amples in the prompt. In line with Yang et al. (2023), we
alsofoundthehistoryofpromptsishelpful,wherewesee In a summarization task, a writer is given an input text
significantimprovementwhenweincreasefrom1prompt to write a summary following an instruction.
historyto10prompthistory,butnosignificantdifferenceas
<instruction>{instruction}</instruction>
wefurtherincreasethehistoryto20.Astothesamplesize,
<examples>
theperformancegrowsatthebeginningwhenweincreasethe
<example>
sizefrom10to50,andplateausmovingfrom50to100.We
<input>
choose50sampleformostofourexperimentsasitisasuffi- {document}
cientlyrepresentativesampletoachievegoodperformance </input>
withrelativelylowerlatency.Weobservedlargervariations <predicted_summary>
andgenerallylowerperformancewhenthenumberofitera- {predicted_summary}
tionsarebelow100,butfurtheriterationsabove100alsodoes </predicted_summary>
notfurtherimproveresultsasitismostlikelythatwealready <reference_summary>
{reference_summary}
foundthebestpromptwithin100iterations.Inconclusion,
</reference_summary>
themostoptimalcombinationofthesehyper-parametersare:
</example>
10examplesinthecritiqueprompt,10or20historyprompts,
...
with50train/devset,with100iterations.
</examples>
F VisualizationofPromptDiversity Write a general and helpful critique in <critique> XML
tags to improve the instruction such that the predicted
To verify that our design in Sec. 3 leads to a better explo-
summaries are as close to references as possible.
rationofthesolutionspace,weexaminethedistributionsof
promptsfoundbyCriSPOandOPROinanembeddingspace. 1. Come up with several dimensions to compare its
WefirstencodetheirClaudeInstantpromptsonthe4sum- predicted summaries and reference summaries, e.g.,number of words, number of sentences, style, precision, </examples>
recall, etc.
2. List the difference predicted summaries and Write a general and helpful critique in <critique> XML
references on each dimension. tags to improve the instruction such that the generated
3. Identify specific phrases in the instruction that answer are the same as gold answer.
could have gotten these predicted summaries different
with references on each dimension. 1. Come up with several dimensions to compare its
4. Suggest specific action items that are general to all generated and gold answer, e.g., number of words, style,
examples and helpful to improve the instruction. precision, recall, etc.
2. List the difference between generated and gold answer
on each dimension.
G.2 MistralforSummarization
3. Identify specific phrases in the instruction that
could have gotten these generated answer different with
In a summarization task, a writer is given an input text
gold one on each dimension.
to write a summary following an instruction.
4. Suggest specific action items that are general to all
examples and helpful to improve the instruction.
INSTRUCTION:
{instruction}
H ReceptiveOptimizerMeta-Prompt
Here are a few examples using the instruction.
EXAMPLE {id} H.1 ClaudeforSummarization
INPUT:
{document}
Your task is to optimize the instruction for a
PREDICTED_SUMMARY:
summarization task, where a writer is given an input
{predicted_summary}
text to write its summary following your instruction.
REFERENCE_SUMMARY:
{reference_summary}
Below are some examples:
...
<example>
<instruction>?</instruction>
Write a general and helpful critique to improve the
<input>
instruction such that the predicted summaries are as
{article}
close to references as possible.
</input>
<summary>
1. Come up with several dimensions to compare its
{summary}
predicted summaries and reference summaries, e.g.,
</summary>
number of words, number of sentences, style, precision,
</example>
recall, etc.
...
2. List the difference predicted summaries and
references on each dimension.
Below are some previous instructions with their scores
3. Identify specific phrases in the instruction that
and critiques.
could have gotten these predicted summaries different
<rated_instruction>
with references on each dimension.
<instruction>{instruction}</instruction>
4. Suggest specific action items that are general to all
<score>{score}</score>
examples and helpful to improve the instruction.
<critique>
{critique}
G.3 ClaudeforRAG </critique>
</rated_instruction>
In a question-answering task, question and context are ...
provided and the answer needs to be generated.
Generate an instruction that is different from all the
<instruction>{instruction}</instruction> instructions above, and has a higher score than all the
<examples> instructions above.
<example> It should be concise, effective, and generally
<question> applicable to all examples above.
{question}
</question> Draft your new instruction step by step:
{context}
<generated_answer> 1. Compare high-score instructions to low-score ones,
{generated_answer} identify what suggestions could have improved them. List
</generated_answer> them in <suggestion> tags.
<gold_answer> 2. Apply the suggestions and draft a new instruction
{gold_answer} aiming for a higher score.
</gold_answer> 3. Be creative and vary the wording, paraphrase,
</example> position of INSERT_INPUT_HERE and INSERT_EXAMPLES_HERE,
... phrase order, grammar, sentence order and etc.4. Write your final new instruction in <instruction> {context}
tags. <answer>
{answer}
</answer>
H.2 MistralforSummarization
</example>
...
Your task is to optimize the instruction for a
summarization task, where a writer is given an input
Below are some previous instructions with their scores
text to write its summary following your instruction.
and critiques.
<rated_instruction>
Below are some examples:
<instruction>{instruction}</instruction>
EXAMPLE {id}
<score>{score}</score>
INPUT:
<critique>
{article}
{critique}
TARGET_SUMMARY:
</critique>
{summary}
</rated_instruction>
...
...
Below are some previous instructions with their scores
Generate an instruction that is different from all the
and critiques.
instructions above, and has a higher score than all the
INSTRUCTION:
instructions above.
{instruction}
It should be concise, effective, and generally
SCORE:
applicable to all examples above.
{score}
CRITIQUE:
Draft your new instruction step by step:
{critique}
...
1. Compare high-score instructions to low-score ones,
identify what suggestions could have improved them. List
Generate an instruction that is different from all the
them in <suggestion> tags.
instructions above, and has a higher score than all the
2. Apply the suggestions and draft a new instruction
instructions above.
aiming for a higher score.
It should be concise, effective, and generally
3. Be creative and vary the wording, paraphrase,
applicable to all examples above.
position of "{question_placeholder}", "{
context_placeholder}", phrase order, grammar, sentence
Draft your new instruction step by step:
order, which specific examples to give, etc.
4. Write your final new instruction in <instruction>
1. Compare high-score instructions to low-score ones,
tags.
identify what suggestions could have improved them.
Write down your suggestions first.
2. Apply the suggestions and draft a new instruction I ManualPrompts
aiming for a higher score.
We present the manual prompts for the summariza-
3. Be creative and vary the wording, paraphrase,
tion experiments with the Claude instant model.
position of <INSERT_INPUT_HERE> and <
INSERT INPUT HERE in each prompt indicates
INSERT_EXAMPLES_HERE>, phrase order, grammar, sentence
order and etc. the position where we will insert the input text. IN-
4. Write your final new instruction in <instruction></ SERT EXAMPLES HEREindicatesthepositionwherewe
instruction> tags. willinsertfew-shotexamples.Eachexampleisintheformat
5. In your final prompt, you must use <INSERT_INPUT_HERE of
> only once and use it in a separate line.
6. In your final prompt, you must use < <examples>
INSERT_EXAMPLES_HERE> only once and use it in a separate <input> ...<input>
line. <summary> ... <summary>
</examples>
H.3 ClaudeforRAG Forthefew-shotsetup,wefirstencodeinputswithBERT
embeddings (Devlin et al. 2019), then retrieve their most
Your task is to optimize the instruction for a question- similarexamplesfromthetrainsetaccordingtothecosine
answering task, where the question and context are similarity(Liuetal.2022).
provided.
I.1 Zero-shotCNN
Below are some examples:
<example> Here is an input CNN news document:
<instruction>?</instruction> INSERT_INPUT_HERE
<question> Please write a headline summary between around 50 to 100
{question} words within <summary> tags.
</question>I.2 Few-shotCNN Following the examples, please write a summary of the
discussion from the input conversation with around 60 to
Write a headline summary between around 50 to 100 words 150 words within <summary> tags.
for the CNN news document. Here are example input
documents and example output summaries
I.7 Zero-shotDialogue2Note
INSERT_EXAMPLES_HERE
Here is an input conversation of a clinical visit:
INSERT_INPUT_HERE
Here is an input CNN news document:
Please write a detailed clinical note summary for the
input conversation within <summary> tags.
INSERT_INPUT_HERE
Please write a headline summary between around 50 to 100 I.8 Few-shotDialogue2Note
words within <summary> tags.
Write a clinical note summary within <summary> tags for
I.3 Zero-shotSAMSum the input conversation of a clinical visit. Here are
example input conversations and example output summaries
Here is an input conversation:
INSERT_EXAMPLES_HERE
INSERT_INPUT_HERE
Please write a summary for the input conversation within
Here is the input conversation:
<summary> tags. The summary should (1) be rather short
INSERT_INPUT_HERE
with 20 to 50 words, (2) extract important pieces of
Following the examples, please write a clinical note
information, (3) include names of interlocutors, (4) be
summary for the input conversation within <summary> tags
written in the third person.
.
I.4 Few-shotSAMSum
I.9 ManualPromptTuning
Write a summary within <summary> tags for the input While it is not possible to exhaust all prompt variations
conversation. Here are example input conversations and withmanualpromptengineering,weexperimentedwithsev-
example output summaries eral iterations of manual prompts and presented the best
prompt results. Below, we show that our tuned zero-shot
INSERT_EXAMPLES_HERE
manual prompts (ours) significantly outperform zero-shot
naiveprompts(”Writeasummaryfortheinputtext”),and
Here is the input conversation:
the results from our manual prompts can be regarded as a
INSERT_INPUT_HERE
reasonablebaselinefromhumanpromptengineering.
Following the examples, please write a summary for the
input conversation within <summary> tags. The summary CNN MBank SAMSum D2note
should (1) be rather short with 20 to 50 words, (2)
extract important pieces of information, (3) include Naive 34.8 29.7 29.9 34.3
names of interlocutors, (4) be written in the third Ours 37.5 30.7 33.9 43.8
person.
Table10:Comparingourzero-shotmanuallytunedprompts
I.5 Zero-shotMeetingBank (ours) with naive prompts on summarization tasks with
Claude Instant. MBank= MeetingBank. D2Note: Dia-
Here is an input conversation from city council meeting: logue2Note
INSERT_INPUT_HERE
Please write a summary of the discussion with around 60
to 150 words within <summary> tags.
J BestQAPromptsFoundusingCriSPO
(ClaudeInstant)
I.6 Few-shotMeetingBank
J.1 NaturalQuestions
Write a summary for the input city council meeting. Here
are example input meeting conversations and example Consider INSERT_QUESTION_HERE and all provided
output summaries INSERT_CONTEXT_HERE. Write a concise answer in <answer>
tags focusing only on the single most important
INSERT_EXAMPLES_HERE attribute implied across contexts. Then compare your
answer to the gold below through reasoning: cite how
Here is an input conversation from a city council your intended meaning matches theirs on attributes like
meeting: level of precision/detail implied jointly by contexts.
It is acceptable for your answer to have less context
INSERT_INPUT_HERE than the gold if the meaning remains clear, like using a
single word versus a phrase. Explain any differencesusing specific examples from contexts. Answers should be Your task is to answer the question as concisely as
as concise as possible while still encompassing possible using only the minimum information explicitly
implications as fully as contexts allow. asked for. Carefully examine the question to understand
exactly what specific detail is being requested, then
scan the context to extract only that precise piece of
J.2 TriviaQA information to satisfy the question - no more and no
less. Avoid including any additional context,
Read the question and contexts carefully. Extract the descriptors or embellishments beyond the single term or
key detail(s) directly answering the question from the brief phrase strictly necessary to directly answer what
most relevant context(s). Write your response in <answer is asked. Refer to the examples, where "pub landlord"
> tags matching the style and level of detail of the and "French alone is the official language" are the
example gold answers. Consider using a single word, minimum possible responses. Do not exceed these examples
number, or short phrase if that fully answers the in length or level of detail. Write only the clearest,
question precisely. Compare your answer to the examples, most succinct answer in <answer> tags.
considering alternatives suggested in the contexts and
relationships between entities. Aim for consistency with K AblationStudyPrompts
the gold answers in terms of words used, precision, and
completeness of specification. Pre-definedmulti-aspectcritique-suggestionmeta-prompt:
- Verbosity and length: compare the level of details and
INSERT_CONTEXT_HERE
the length between prediction and reference summaries
- Comprehensiveness: compare whether the prediction
INSERT_QUESTION_HERE
covers all the information from the reference summaries
- Precision: compare whether the information from the
J.3 MedMCQA prediction summaries are present in the reference
summaries.
- Style: compare the formatting, formality, word choices
QUESTION_PLACEHOLDER Provide your answer, and
, sentence structures etc.
comprehensively reason through it by: referencing
authoritative medical sources, accounting for all
relevant context in the question, logically laying out L FullMetricsforSummarization
your reasoning steps, and addressing any applicable
Wereporttheaverageandstandarddeviationfrom3runsfor
exceptions or nuances. Your response should demonstrate
Rouge1(Table11),Rouge2(Table12),RougeL(Table13),
a rigorous application of established medical knowledge.
BertScore(Table14)andAlignScore(Table15).
Chose an option and write it in <answer> XML tags
M StandardDeviationforQA
Table16showsthefullresultsforQA(QuestionAnswering)
J.4 NarrativeQA
datasetswithstandarddeviationreportedoverthreeruns.
Provide a focused, concise answer in the form of a 1-3
word phrase or brief quote, enclosed in <answer> tags.
Capture all key details directly relevant to fully
addressing the question, while excluding extraneous
background information or repetition of context details.
If a short quote from the context directly and
precisely answers the question in a maximally concise
manner, use the quote verbatim. Otherwise, paraphrase
the essential information as succinctly as possible. The
goal is a clear, to-the-point response that
comprehensively answers the core of the question without
omitting crucial details or including unnecessary
information.
CONTEXT_PLACEHOLDER
QUESTION_PLACEHOLDER
J.5 Squad
INSERT_CONTEXT_HERE
INSERT_QUESTION_HEREManual AutomaticPromptEngineering
Dataset LLM z-shot 3-shot* OPRO CriSPO CriSPO3-shot*
CNN ClaudeInstant 37.5 40.4 39.5(±0.4) 40.1(±0.5) 42.1(±0.6)
SOTA:48.2 Claude3Sonnet 38.8 40.3 39.7(±0.6) 42.2(±0.9) 41.6(±1.0)
(MuandLim2022) Mistral7B 30.9 30.7 36.5(±1.8) 38.5(±1.7) 38.5(±1.0)
Llama38B 37.9 39.1(±0.3)# 41.5(±0.7)#
MeetingBank ClaudeInstant 30.7 34.2 39.0(±6.1) 41.4(±2.4) 50.1(±0.6)
SOTA:70.3 Claude3Sonnet 31.2 37.5 41.5(±2.2) 47.4(±1.7) 58.5(±1.3)
(Huetal.2023) Mistral7B 26.0 31.3 33.9(±3.7) 39.1(±4.8) 35.2(±0.7)
Llama38B 31.4 40.2(±3.0)# 44.7(±0.8)#
SAMSum ClaudeInstant 33.9 37.8 38.1(±1.3) 44.4(±1.9) 45.8(±0.4)
SOTA:55.3 Claude3Sonnet 35.8 41.1 39.0(±1.4) 43.4(±2.1) 47.2(±0.3)
(Wang,Liu,andChen2023) Mistral7B 32.0 39.5 37.9(±0.8) 37.6(±3.4) 40.0(±1.0)
Llama38B 35.7 39.3(±0.6)# 44.8(±3.4)#
D2Note ClaudeInstant 43.9 51.5 45.2(±0.2) 53.0(±0.4) 58.2(±1.8)
SOTA:53.5 Claude3Sonnet 47.3 59.1 48.8(±1.9) 54.0(±1.5) 63.1(±0.6)
(Yimetal.2023) Mistral7B 47.8 48.4 45.1(±0.6) 50.2(±3.0) 50.3(±0.5)
Llama38B 50.5 54.2(±0.8)# 56.2(±0.4)#
Table11:ComparingCriSPOwithmanualpromptsandcompetitiveautomaticpromptengineeringbaselineOPROonrepresen-
tativesummarizationbenchmarks(ROUGE-1Faveragedacross3runs).3-shot*:3-shotICLwithexampleselection.Llama3
resultsmarkedwith(#)isusingClaude-3astheoptimizer,duetolimitedcontextwindowofLlama3.
Manual AutomaticPromptEngineering
Dataset LLM z-shot 3-shot* OPRO CriSPO CriSPO3-shot*
CNN ClaudeInstant 12.5 14.8 14.3(±0.3) 15.7(±0.9) 17.0(±0.2)
Claude3Sonnet 14.4 15.4 15.1(±0.2) 17.3(±1.5) 16.3(±0.5)
Mistral7B 11.0 10.6 14.4(±0.8) 14.3(±0.6) 14.3(±0.1)
Llama38B 14.4 15.2(±0.4)# 16.3(±0.9)#
MeetingBank ClaudeInstant 11.6 17.3 20.3(±6.9) 23.7(±4.7) 35.4(±0.5)
Claude3Sonnet 14.2 22.0 21.8(±2.8) 32.5(±2.2) 46.5(±1.8)
Mistral7B 11.5 14.8 15.4(±2.5) 19.5(±6.7) 16.7(±0.9)
Llama38B 14.6 22.3(±2.7)# 27.6(±0.4)#
SAMSum ClaudeInstant 11.7 14.3 13.4(±0.9) 16.9(±2.2) 18.7(±0.8)
Claude3Sonnet 12.7 16.6 14.7(±0.1) 17.1(±1.0) 20.8(±0.3)
Mistral7B 10.2 14.1 13.6(±1.4) 12.4(±1.5) 14.2(±1.0)
Llama38B 12.3 14.7(±0.4)# 18.8(±3.8)#
D2Note ClaudeInstant 16.9 23.6 16.3(±0.4) 19.7(±0.6) 26.7(±2.3)
Claude3Sonnet 20.3 30.1 20.1(±1.4) 21.4(±0.8) 32.5(±0.9)
Mistral7B 17.7 19.2 17.0(±0.1) 18.2(±1.7) 18.7(±0.7)
Llama38B 19.8 22.0(±0.2)# 22.8(±0.2)#
Table12:ComparingCriSPOwithmanualpromptsandcompetitiveautomaticpromptengineeringbaselineOPROonrepresen-
tativesummarizationbenchmarks(ROUGE-2Faveragedacross3runs).3-shot*:3-shotICLwithexampleselection.Llama3
resultsmarkedwith(#)isusingClaude3Sonnetastheoptimizer,duetolimitedcontextwindowofLlama3.Manual AutomaticPromptEngineering
Dataset LLM z-shot 3-shot* OPRO CriSPO CriSPO3-shot*
CNN ClaudeInstant 22.6 24.8 24.5(±0.5) 26.1(±0.4) 27.4(±0.5)
Claude3Sonnet 24.0 25.2 25.1(±0.5) 27.9(±0.9) 27.1(±0.6)
Mistral7B 20.4 20.1 23.0(±1.5) 23.9(±1.3) 24.1(±0.7)
Llama38B 23.8 24.6(±0.4)# 26.5(±0.5)#
MeetingBank ClaudeInstant 20.5 25.5 29.7(±7.4) 33.1(±4.5) 44.4(±0.2)
Claude3Sonnet 22.3 29.5 32.0(±2.8) 40.9(±2.0) 54.1(±1.6)
Mistral7B 18.5 22.7 24.2(±3.4) 29.3(±6.5) 26.1(±1.0)
Llama38B 22.6 31.5(±3.3)# 36.8(±0.7)#
SAMSum ClaudeInstant 25.6 28.8 28.7(±1.2) 34.3(±2.0) 36.2(±0.2)
Claude3Sonnet 27.0 31.3 30.1(±1.1) 34.3(±2.3) 38.2(±0.5)
Mistral7B 24.1 30.3 29.0(±0.7) 28.4(±2.9) 30.8(±1.3)
Llama38B 27.1 30.0(±0.5)# 35.4(±3.4)#
D2Note ClaudeInstant 26.1 33.5 25.5(±1.0) 26.8(±1.4) 35.3(±2.3)
Claude3Sonnet 29.3 38.6 29.5(±1.1) 30.3(±0.4) 41.0(±0.6)
Mistral7B 25.4 28.1 25.2(±0.1) 25.6(±1.9) 26.2(±0.4)
Llama38B 27.7 29.3(±0.6)# 29.9(±0.5)#
Table13:ComparingCriSPOwithmanualpromptsandcompetitiveautomaticpromptengineeringbaselineOPROonrepresen-
tativesummarizationbenchmarks(ROUGE-LFaveragedacross3runs).3-shot*:3-shotICLwithexampleselection.Llama3
resultsmarkedwith(#)isusingClaude3Sonnetastheoptimizer,duetolimitedcontextwindowofLlama3.
Manual AutomaticPromptEngineering
Dataset LLM z-shot 3-shot* OPRO CriSPO CriSPO3-shot*
CNN ClaudeInstant 87.0 87.6 87.5(±0.1) 87.2(±0.4) 87.7(±0.3)
Claude3Sonnet 87.4 87.7 87.5(±0.0) 87.8(±0.0) 87.8(±0.3)
Mistral7B 85.6 85.8 87.0(±0.1) 87.3(±0.2) 87.3(±0.1)
Llama38B 87.2 87.4(±0.1)# 87.6(±0.1)#
MeetingBank ClaudeInstant 85.0 86.0 86.7(±1.2) 86.8(±0.3) 89.2(±0.1)
Claude3Sonnet 85.4 86.9 87.1(±0.4) 88.1(±0.3) 90.8(±0.3)
Mistral7B 84.3 85.3 85.8(±0.7) 86.2(±0.3) 85.9(±0.2)
Llama38B 85.4 86.7(±0.6)# 87.7(±0.2)#
SAMSum ClaudeInstant 89.2 89.8 89.8(±0.2) 90.4(±0.4) 90.7(±0.5)
Claude3Sonnet 89.5 90.3 89.8(±0.4) 90.6(±0.7) 91.3(±0.1)
Mistral7B 88.3 90.0 89.8(±0.2) 89.5(±0.6) 90.1(±0.2)
Llama38B 88.7 89.9(±0.1)# 90.7(±0.5)#
D2Note ClaudeInstant 85.5 88.1 85.1(±0.3) 85.8(±0.7) 88.1(±0.5)
Claude3Sonnet 85.7 89.1 85.7(±0.5) 86.1(±0.3) 90.0(±0.3)
Mistral7B 85.3 86.4 84.9(±0.1) 85.5(±0.8) 85.8(±0.2)
Llama38B 85.1 86.1(±0.2)# 86.6(±0.4)#
Table14:ComparingCriSPOwithmanualpromptsandcompetitiveautomaticpromptengineeringbaselineOPROonrepresen-
tativesummarizationbenchmarks(BERTScoreFaveragedacross3runs).3-shot*:3-shotICLwithexampleselection.Llama3
resultsmarkedwith(#)isusingClaude3Sonnetastheoptimizer,duetolimitedcontextwindowofLlama3.Manual AutomaticPromptEngineering
Dataset LLM z-shot 3-shot* OPRO CriSPO CriSPO3-shot*
CNN ClaudeInstant 76.1 83.1 85.5(±1.3) 73.9(±12.6) 77.8(±7.1)
(Reference:78.7) Claude3Sonnet 84.5 86.0 84.6(±1.3) 84.5(±4.9) 83.9(±5.5)
Mistral7B 84.9 85.2 84.5(±5.9) 84.4(±1.3) 86.4(±0.5)
Llama38B 83.7 85.4(±0.9)# 86.1(±1.2)#
MeetingBank ClaudeInstant 72.5 70.8 59.6(±12.8) 61.9(±6.2) 64.0(±2.1)
(Reference:51.4) Claude3Sonnet 71.9 70.8 57.5(±3.3) 49.9(±16.8) 70.5(±2.1)
Mistral7B 76.5 72.1 76.5(±6.5) 76.5(±2.1) 76.6(±0.6)
Llama38B 72.2 71.9(±14.9)# 63.7(±1.3)#
SAMSum ClaudeInstant 85.7 86.6 84.5(±0.9) 85.3(±3.6) 83.9(±1.2)
(Reference:79.9) Claude3Sonnet 87.9 87.2 89.5(±0.5) 87.0(±1.3) 84.4(±1.5)
Mistral7B 87.6 86.8 88.4(±0.8) 87.7(±0.7) 87.4(±1.3)
Llama38B 88.8 88.9(±0.7)# 87.7(±2.5)#
D2Note ClaudeInstant 66.7 66.3 62.3(±2.0) 63.3(±3.3) 65.6(±1.1)
(Reference:61.4) Claude3Sonnet 70.2 67.4 69.8(±7.8) 65.0(±3.3) 63.8(±0.6)
Mistral7B 68.0 69.0 65.6(±0.4) 67.8(±2.3) 67.2(±1.6)
Llama38B 72.5 59.4(±1.8)# 62.3(±1.2)#
Table15:ComparingCriSPOwithmanualpromptsandcompetitiveautomaticpromptengineeringbaselineOPROonrepresenta-
tivesummarizationbenchmarks(AlignScoreaveragedacross3runs).3-shot*:3-shotICLwithexampleselection.Llama3results
markedwith(#)isusingClaude3Sonnetastheoptimizer,duetolimitedcontextwindowofLlama3.AlthoughAlignScoreis
amongtheSoTAmetricsforthefactualconsistency,itisfarfromperfect.Ittendstofavorverbatimcopiesandsimpleparaphrases
ofthesourcedocumentoverhighlyabstractivesummaries.Asanevidence,thegroundtruthreferencesummaryfromthedataset
getslowerAlignScorethanLLMgeneratedsummary.
Manual AutomaticPromptEngineering
Dataset Claude z-shot 64-shot OPRO CriSPO CriSPO64-shot
NaturalQuestion(ExactMatch) Instant 34.0 33.4 8.0(±6.6) 36.5(±2.2) 37.8(±1.1)
SOTA:60.4(Izacardetal.2023) Sonnet 26.6 32.0 6.7(±5.9) 38.3(±1.6) 38.7(±3.9)
TriviaQA(ExactMatch) Instant 58.6 59.2 53.7(±3.3) 66.3(±1.1) 67.5(±1.0)
SOTA:86.1(Touvronetal.2023) Sonnet 58.4 65.0 41.8(±23.9) 70.6(±0.2) 72.1(±0.3)
z-shot 5-shot OPRO CriSPO CriSPO5-shot
Squad(F1) Instant 79.5 82.5 78.5(±4.1) 87.8(±0.5) 89.4(±0.2)
SOTA:95.8(Lietal.2020) Sonnet 76.1 83.2 76.4(±7.4) 85.3(±3.8) 87.9(±2.5)
NarrativeQA(Rouge-L) Instant 64.2 67.0 59.4(±13.2) 75.1(±0.4) 76.1(±0.5)
SOTA:59.87(Nishidaetal.2019) Sonnet 64.0 66.7 58.6(±09.9) 76.2(±1.6) 75.2(±1.0)
MedMCQA(Accuracy) Instant 49.2 53.8 50.5(±0.9) 52.3(±2.9) 54.4(±2.1)
SOTA:73.7(Norietal.2023) Sonnet 49.8 54.4 57.7(±2.1) 57.9(±0.9) 57.4(±0.3)
Table16:ComparingCriSPOwithmanualpromptsandcompetitiveautomaticpromptengineeringbaselineOPROonrepresen-
tativequestionansweringbenchmarks.*-shot:few-shotICLwithexampleselection.