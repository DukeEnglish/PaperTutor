[
    {
        "title": "CinePile: A Long Video Question Answering Dataset and Benchmark",
        "authors": "Ruchit RawalKhalid SaifullahRonen BasriDavid JacobsGowthami SomepalliTom Goldstein",
        "links": "http://arxiv.org/abs/2405.08813v1",
        "entry_id": "http://arxiv.org/abs/2405.08813v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08813v1",
        "summary": "Current datasets for long-form video understanding often fall short of\nproviding genuine long-form comprehension challenges, as many tasks derived\nfrom these datasets can be successfully tackled by analyzing just one or a few\nrandom frames from a video. To address this issue, we present a novel dataset\nand benchmark, CinePile, specifically designed for authentic long-form video\nunderstanding. This paper details our innovative approach for creating a\nquestion-answer dataset, utilizing advanced LLMs with human-in-the-loop and\nbuilding upon human-generated raw data. Our comprehensive dataset comprises\n305,000 multiple-choice questions (MCQs), covering various visual and\nmultimodal aspects, including temporal comprehension, understanding\nhuman-object interactions, and reasoning about events or actions within a\nscene. Additionally, we evaluate recent video-centric LLMs, both open-source\nand proprietary, on the test split of our dataset. The findings reveal that\neven state-of-the-art video-centric LLMs significantly lag behind human\nperformance in these tasks, highlighting the complexity and challenge inherent\nin video understanding. The dataset is available at\nhttps://hf.co/datasets/tomg-group-umd/cinepile",
        "updated": "2024-05-14 17:59:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08813v1"
    },
    {
        "title": "Prospects of Privacy Advantage in Quantum Machine Learning",
        "authors": "Jamie HeredgeNiraj KumarDylan HermanShouvanik ChakrabartiRomina YalovetzkyShree Hari SureshbabuMarco Pistoia",
        "links": "http://arxiv.org/abs/2405.08801v1",
        "entry_id": "http://arxiv.org/abs/2405.08801v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08801v1",
        "summary": "Ensuring data privacy in machine learning models is critical, particularly in\ndistributed settings where model gradients are typically shared among multiple\nparties to allow collaborative learning. Motivated by the increasing success of\nrecovering input data from the gradients of classical models, this study\naddresses a central question: How hard is it to recover the input data from the\ngradients of quantum machine learning models? Focusing on variational quantum\ncircuits (VQC) as learning models, we uncover the crucial role played by the\ndynamical Lie algebra (DLA) of the VQC ansatz in determining privacy\nvulnerabilities. While the DLA has previously been linked to the classical\nsimulatability and trainability of VQC models, this work, for the first time,\nestablishes its connection to the privacy of VQC models. In particular, we show\nthat properties conducive to the trainability of VQCs, such as a\npolynomial-sized DLA, also facilitate the extraction of detailed snapshots of\nthe input. We term this a weak privacy breach, as the snapshots enable training\nVQC models for distinct learning tasks without direct access to the original\ninput. Further, we investigate the conditions for a strong privacy breach where\nthe original input data can be recovered from these snapshots by classical or\nquantum-assisted polynomial time methods. We establish conditions on the\nencoding map such as classical simulatability, overlap with DLA basis, and its\nFourier frequency characteristics that enable such a privacy breach of VQC\nmodels. Our findings thus play a crucial role in detailing the prospects of\nquantum privacy advantage by guiding the requirements for designing quantum\nmachine learning models that balance trainability with robust privacy\nprotection.",
        "updated": "2024-05-14 17:49:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08801v1"
    },
    {
        "title": "A Brief Introduction to Causal Inference in Machine Learning",
        "authors": "Kyunghyun Cho",
        "links": "http://arxiv.org/abs/2405.08793v1",
        "entry_id": "http://arxiv.org/abs/2405.08793v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08793v1",
        "summary": "This is a lecture note produced for DS-GA 3001.003 \"Special Topics in DS -\nCausal Inference in Machine Learning\" at the Center for Data Science, New York\nUniversity in Spring, 2024. This course was created to target master's and PhD\nlevel students with basic background in machine learning but who were not\nexposed to causal inference or causal reasoning in general previously. In\nparticular, this course focuses on introducing such students to expand their\nview and knowledge of machine learning to incorporate causal reasoning, as this\naspect is at the core of so-called out-of-distribution generalization (or lack\nthereof.)",
        "updated": "2024-05-14 17:41:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08793v1"
    },
    {
        "title": "Towards Enhanced RAC Accessibility: Leveraging Datasets and LLMs",
        "authors": "Edison Jair Bejarano SepulvedaNicolai Potes HectorSantiago Pineda MontoyaFelipe Ivan RodriguezJaime Enrique OrduyAlec Rosales CabezasDanny Traslaviña NavarreteSergio Madrid Farfan",
        "links": "http://arxiv.org/abs/2405.08792v1",
        "entry_id": "http://arxiv.org/abs/2405.08792v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08792v1",
        "summary": "This paper explores the potential of large language models (LLMs) to make the\nAeronautical Regulations of Colombia (RAC) more accessible. Given the\ncomplexity and extensive technicality of the RAC, this study introduces a novel\napproach to simplifying these regulations for broader understanding. By\ndeveloping the first-ever RAC database, which contains 24,478 expertly labeled\nquestion-and-answer pairs, and fine-tuning LLMs specifically for RAC\napplications, the paper outlines the methodology for dataset assembly,\nexpert-led annotation, and model training. Utilizing the Gemma1.1 2b model\nalong with advanced techniques like Unsloth for efficient VRAM usage and flash\nattention mechanisms, the research aims to expedite training processes. This\ninitiative establishes a foundation to enhance the comprehensibility and\naccessibility of RAC, potentially benefiting novices and reducing dependence on\nexpert consultations for navigating the aviation industry's regulatory\nlandscape.\n  You can visit the dataset\n(https://huggingface.co/somosnlp/gemma-1.1-2b-it_ColombiaRAC_FullyCurated_format_chatML_V1)\nand the model\n(https://huggingface.co/datasets/somosnlp/ColombiaRAC_FullyCurated) here.",
        "updated": "2024-05-14 17:41:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08792v1"
    },
    {
        "title": "Kolmogorov-Arnold Networks (KANs) for Time Series Analysis",
        "authors": "Cristian J. Vaca-RubioLuis BlancoRoberto PereiraMàrius Caus",
        "links": "http://arxiv.org/abs/2405.08790v1",
        "entry_id": "http://arxiv.org/abs/2405.08790v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08790v1",
        "summary": "This paper introduces a novel application of Kolmogorov-Arnold Networks\n(KANs) to time series forecasting, leveraging their adaptive activation\nfunctions for enhanced predictive modeling. Inspired by the Kolmogorov-Arnold\nrepresentation theorem, KANs replace traditional linear weights with\nspline-parametrized univariate functions, allowing them to learn activation\npatterns dynamically. We demonstrate that KANs outperforms conventional\nMulti-Layer Perceptrons (MLPs) in a real-world satellite traffic forecasting\ntask, providing more accurate results with considerably fewer number of\nlearnable parameters. We also provide an ablation study of KAN-specific\nparameters impact on performance. The proposed approach opens new avenues for\nadaptive forecasting models, emphasizing the potential of KANs as a powerful\ntool in predictive analytics.",
        "updated": "2024-05-14 17:38:17 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08790v1"
    }
]