[
    {
        "title": "Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram",
        "authors": "Aehong MinXuan WangRion Brattig CorreiaJordan RozumWendy R. MillerLuis M. Rocha",
        "links": "http://arxiv.org/abs/2405.08784v1",
        "entry_id": "http://arxiv.org/abs/2405.08784v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08784v1",
        "summary": "We used a dictionary built from biomedical terminology extracted from various\nsources such as DrugBank, MedDRA, MedlinePlus, TCMGeneDIT, to tag more than 8\nmillion Instagram posts by users who have mentioned an epilepsy-relevant drug\nat least once, between 2010 and early 2016. A random sample of 1,771 posts with\n2,947 term matches was evaluated by human annotators to identify\nfalse-positives. OpenAI's GPT series models were compared against human\nannotation. Frequent terms with a high false-positive rate were removed from\nthe dictionary. Analysis of the estimated false-positive rates of the annotated\nterms revealed 8 ambiguous terms (plus synonyms) used in Instagram posts, which\nwere removed from the original dictionary. To study the effect of removing\nthose terms, we constructed knowledge networks using the refined and the\noriginal dictionaries and performed an eigenvector-centrality analysis on both\nnetworks. We show that the refined dictionary thus produced leads to a\nsignificantly different rank of important terms, as measured by their\neigenvector-centrality of the knowledge networks. Furthermore, the most\nimportant terms obtained after refinement are of greater medical relevance. In\naddition, we show that OpenAI's GPT series models fare worse than human\nannotators in this task.",
        "updated": "2024-05-14 17:27:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08784v1"
    },
    {
        "title": "Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs",
        "authors": "Akhila YerukolaSaujas VaduguruDaniel FriedMaarten Sap",
        "links": "http://arxiv.org/abs/2405.08760v1",
        "entry_id": "http://arxiv.org/abs/2405.08760v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08760v1",
        "summary": "Humans often express their communicative intents indirectly or non-literally,\nwhich requires their interlocutors -- human or AI -- to understand beyond the\nliteral meaning of words. While most existing work has focused on\ndiscriminative evaluations, we present a new approach to generatively evaluate\nlarge language models' (LLMs') intention understanding by examining their\nresponses to non-literal utterances. Ideally, an LLM should respond in line\nwith the true intention of a non-literal utterance, not its literal\ninterpretation. Our findings show that LLMs struggle to generate pragmatically\nrelevant responses to non-literal language, achieving only 50-55% accuracy on\naverage. While explicitly providing oracle intentions significantly improves\nperformance (e.g., 75% for Mistral-Instruct), this still indicates challenges\nin leveraging given intentions to produce appropriate responses. Using\nchain-of-thought to make models spell out intentions yields much smaller gains\n(60% for Mistral-Instruct). These findings suggest that LLMs are not yet\neffective pragmatic interlocutors, highlighting the need for better approaches\nfor modeling intentions and utilizing them for pragmatic generation.",
        "updated": "2024-05-14 16:48:56 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08760v1"
    },
    {
        "title": "From Text to Context: An Entailment Approach for News Stakeholder Classification",
        "authors": "Alapan KuilaSudeshna Sarkar",
        "links": "http://arxiv.org/abs/2405.08751v1",
        "entry_id": "http://arxiv.org/abs/2405.08751v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08751v1",
        "summary": "Navigating the complex landscape of news articles involves understanding the\nvarious actors or entities involved, referred to as news stakeholders. These\nstakeholders, ranging from policymakers to opposition figures, citizens, and\nmore, play pivotal roles in shaping news narratives. Recognizing their\nstakeholder types, reflecting their roles, political alignments, social\nstanding, and more, is paramount for a nuanced comprehension of news content.\nDespite existing works focusing on salient entity extraction, coverage\nvariations, and political affiliations through social media data, the automated\ndetection of stakeholder roles within news content remains an underexplored\ndomain. In this paper, we bridge this gap by introducing an effective approach\nto classify stakeholder types in news articles. Our method involves\ntransforming the stakeholder classification problem into a natural language\ninference task, utilizing contextual information from news articles and\nexternal knowledge to enhance the accuracy of stakeholder type detection.\nMoreover, our proposed model showcases efficacy in zero-shot settings, further\nextending its applicability to diverse news contexts.",
        "updated": "2024-05-14 16:35:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08751v1"
    },
    {
        "title": "Targeted Augmentation for Low-Resource Event Extraction",
        "authors": "Sijia WangLifu Huang",
        "links": "http://arxiv.org/abs/2405.08729v1",
        "entry_id": "http://arxiv.org/abs/2405.08729v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08729v1",
        "summary": "Addressing the challenge of low-resource information extraction remains an\nongoing issue due to the inherent information scarcity within limited training\nexamples. Existing data augmentation methods, considered potential solutions,\nstruggle to strike a balance between weak augmentation (e.g., synonym\naugmentation) and drastic augmentation (e.g., conditional generation without\nproper guidance). This paper introduces a novel paradigm that employs targeted\naugmentation and back validation to produce augmented examples with enhanced\ndiversity, polarity, accuracy, and coherence. Extensive experimental results\ndemonstrate the effectiveness of the proposed paradigm. Furthermore, identified\nlimitations are discussed, shedding light on areas for future improvement.",
        "updated": "2024-05-14 16:15:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08729v1"
    },
    {
        "title": "Thinking Tokens for Language Modeling",
        "authors": "David HerelTomas Mikolov",
        "links": "http://arxiv.org/abs/2405.08644v1",
        "entry_id": "http://arxiv.org/abs/2405.08644v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08644v1",
        "summary": "How much is 56 times 37? Language models often make mistakes in these types\nof difficult calculations. This is usually explained by their inability to\nperform complex reasoning. Since language models rely on large training sets\nand great memorization capability, naturally they are not equipped to run\ncomplex calculations. However, one can argue that humans also cannot perform\nthis calculation immediately and require a considerable amount of time to\nconstruct the solution. In order to enhance the generalization capability of\nlanguage models, and as a parallel to human behavior, we propose to use special\n'thinking tokens' which allow the model to perform much more calculations\nwhenever a complex problem is encountered.",
        "updated": "2024-05-14 14:21:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08644v1"
    }
]