[
    {
        "title": "ViSTooth: A Visualization Framework for Tooth Segmentation on Panoramic Radiograph",
        "authors": "Shenji ZhuMiaoxin HuTianya PanYue HongBin LiZhiguang ZhouTing Xu",
        "links": "http://arxiv.org/abs/2405.08573v1",
        "entry_id": "http://arxiv.org/abs/2405.08573v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08573v1",
        "summary": "Tooth segmentation is a key step for computer aided diagnosis of dental\ndiseases. Numerous machine learning models have been employed for tooth\nsegmentation on dental panoramic radiograph. However, it is a difficult task to\nachieve accurate tooth segmentation due to complex tooth shapes, diverse tooth\ncategories and incomplete sample set for machine learning. In this paper, we\npropose ViSTooth, a visualization framework for tooth segmentation on dental\npanoramic radiograph. First, we employ Mask R-CNN to conduct preliminary tooth\nsegmentation, and a set of domain metrics are proposed to estimate the accuracy\nof the segmented teeth, including tooth shape, tooth position and tooth angle.\nThen, we represent the teeth with high-dimensional vectors and visualize their\ndistribution in a low-dimensional space, in which experts can easily observe\nthose teeth with specific metrics. Further, we expand the sample set with the\nexpert-specified teeth and train the tooth segmentation model iteratively.\nFinally, we conduct case study and expert study to demonstrate the\neffectiveness and usability of our ViSTooth, in aiding experts to implement\naccurate tooth segmentation guided by expert knowledge.",
        "updated": "2024-05-14 13:10:54 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08573v1"
    },
    {
        "title": "EEG-Features for Generalized Deepfake Detection",
        "authors": "Arian BeckmannTilman StephaniFelix KlotzscheYonghao ChenSimon M. HofmannArno VillringerMichael GaeblerVadim NikulinSebastian BossePeter EisertAnna Hilsmann",
        "links": "http://arxiv.org/abs/2405.08527v1",
        "entry_id": "http://arxiv.org/abs/2405.08527v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08527v1",
        "summary": "Since the advent of Deepfakes in digital media, the development of robust and\nreliable detection mechanism is urgently called for. In this study, we explore\na novel approach to Deepfake detection by utilizing electroencephalography\n(EEG) measured from the neural processing of a human participant who viewed and\ncategorized Deepfake stimuli from the FaceForensics++ datset. These\nmeasurements serve as input features to a binary support vector classifier,\ntrained to discriminate between real and manipulated facial images. We examine\nwhether EEG data can inform Deepfake detection and also if it can provide a\ngeneralized representation capable of identifying Deepfakes beyond the training\ndomain. Our preliminary results indicate that human neural processing signals\ncan be successfully integrated into Deepfake detection frameworks and hint at\nthe potential for a generalized neural representation of artifacts in computer\ngenerated faces. Moreover, our study provides next steps towards the\nunderstanding of how digital realism is embedded in the human cognitive system,\npossibly enabling the development of more realistic digital avatars in the\nfuture.",
        "updated": "2024-05-14 12:06:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08527v1"
    },
    {
        "title": "Why Larp?! A Synthesis Paper on Live Action Roleplay in Relation to HCI Research and Practice",
        "authors": "Karin JohanssonRaquel Breejon RobinsonJon BackSarah Lynne BowmanJames FeyElena Márquez SeguraAnnika WaernKatherine Isbister",
        "links": "http://arxiv.org/abs/2405.08526v1",
        "entry_id": "http://arxiv.org/abs/2405.08526v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08526v1",
        "summary": "Live action roleplay (larp) has a wide range of applications, and can be\nrelevant in relation to HCI. While there has been research about larp in\nrelation to topics such as embodied interaction, playfulness and futuring\npublished in HCI venues since the early 2000s, there is not yet a compilation\nof this knowledge. In this paper, we synthesise knowledge about larp and\nlarp-adjacent work within the domain of HCI. We present a practitioner overview\nfrom an expert group of larp researchers, the results of a literature review,\nand highlight particular larp research exemplars which all work together to\nshowcase the diverse set of ways that larp can be utilised in relation to HCI\ntopics and research. This paper identifies the need for further discussions\ntoward establishing best practices for utilising larp in relation to HCI\nresearch, as well as advocating for increased engagement with larps outside\nacademia.",
        "updated": "2024-05-14 12:06:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08526v1"
    },
    {
        "title": "Precarious Experiences: Citizens' Frustrations, Anxieties and Burdens of an Online Welfare Benefit System",
        "authors": "Colin WatsonAdam W ParnabyAhmed Kharrufa",
        "links": "http://arxiv.org/abs/2405.08515v1",
        "entry_id": "http://arxiv.org/abs/2405.08515v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08515v1",
        "summary": "There is a significant overlap between people who are supported by\nincome-related social welfare benefits, often in precarious situations, and\nthose who experience greater digital exclusion. We report on a study of\nclaimants using the UK's Universal Credit online welfare benefit system\ndesigned as, and still, \"digital by default\". Through data collection involving\nremote interviews (n=11) and online surveys (n=66), we expose claimants' own\nlived experiences interacting with this system. The claimants explain how\ndigital channels can contribute to an imbalance of power and agency, at a time\nwhen their own circumstances mean they have reduced abilities, resources and\ncapacities, and where design choices can adversely affect people's utility to\nleverage help from their own wider socio-technical ecosystems. We contribute\neight recommendations from these accounts to inform the future design and\ndevelopment of digital welfare benefit systems for this population, to reduce\ndigital barriers and harms.",
        "updated": "2024-05-14 11:37:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08515v1"
    },
    {
        "title": "AI-Resilient Interfaces",
        "authors": "Elena L. GlassmanZiwei GuJonathan K. Kummerfeld",
        "links": "http://arxiv.org/abs/2405.08447v1",
        "entry_id": "http://arxiv.org/abs/2405.08447v1",
        "pdf_url": "http://arxiv.org/pdf/2405.08447v1",
        "summary": "AI is powerful, but it can make choices that result in objective errors,\ncontextually inappropriate outputs, and disliked options. We need AI-resilient\ninterfaces that help people be resilient to the AI choices that are not right,\nor not right for them. To support this goal, interfaces need to help users\nnotice and have the context to appropriately judge those AI choices. Existing\nhuman-AI interaction guidelines recommend efficient user dismissal,\nmodification, or otherwise efficient recovery from AI choices that a user does\nnot like. However, in order to recover from AI choices, the user must notice\nthem first. This can be difficult. For example, when generating summaries of\nlong documents, a system's exclusion of a detail that is critically important\nto the user is hard for the user to notice. That detail can be hiding in a wall\nof text in the original document, and the existence of a summary may tempt the\nuser not to read the original document as carefully. Once noticed, judging AI\nchoices well can also be challenging. The interface may provide very little\ninformation that contextualizes the choices, and the user may fall back on\nassumptions when deciding whether to dismiss, modify, or otherwise recover from\nan AI choice. Building on prior work, this paper defines key aspects of\nAI-resilient interfaces, illustrated with examples. Designing interfaces for\nincreased AI-resilience of users will improve AI safety, usability, and\nutility. This is especially critical where AI-powered systems are used for\ncontext- and preference-dominated open-ended AI-assisted tasks, like ideating,\nsummarizing, searching, sensemaking, and the reading and writing of text or\ncode.",
        "updated": "2024-05-14 09:12:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.08447v1"
    }
]