Is the Pope Catholic? Yes, the Pope is Catholic.
Generative Evaluation of Intent Resolution in LLMs
AkhilaYerukola♡ SaujasVaduguru♡ DanielFried♡ MaartenSap♡♣
♡LanguageTechnologiesInstitute,CarnegieMellonUniversity
♣AllenInstituteforAI
#ayerukol@andrew.cmu.edu
Abstract mustalsodeveloppragmaticunderstandingtofacil-
itateeffectiveandnuancedhuman-AIinteractions.
Humansoftenexpresstheircommunicativein-
Inthiswork,weintroduceanewgenerativeeval-
tentsindirectlyornon-literally,whichrequires
uation framework designed to evaluate the abil-
their interlocutors—human or AI—to under-
ityofLLMstounderstandandresolveintentions
stand beyond the literal meaning of words.
Whilemostexistingworkhasfocusedondis- throughpragmaticresponsegeneration. InFigure
criminativeevaluations,wepresentanewap- 1, Kelly uses hyperbole to express her desire to
proachtogenerativelyevaluatelargelanguage readnumerousbooks. Acontextuallyappropriate
models’ (LLMs’) intention understanding by responsewouldbetoideallyechosentimentslike
examiningtheirresponsestonon-literalutter-
“That sounds like a great plan” rather than inter-
ances. Ideally,anLLMshouldrespondinline
preting “a million” literally, as seen in responses
with the true intention of a non-literal utter-
like“That’squiteanambitiousreadinglist”. Our
ance, not its literal interpretation. Our find-
framework uses this intuition to compare LLMs’
ingsshowthatLLMsstruggletogenerateprag-
maticallyrelevantresponsestonon-literallan- responsestohuman-likeexpectations,enablinga
guage,achievingonly50-55%accuracyonav- nuancedassessmentoftheirpragmaticunderstand-
erage. While explicitly providing oracle in- ingandresponseaccuracy.
tentions significantly improves performance
Ourprimaryfocusonpragmaticresponsegen-
(e.g., 75% for Mistral-Instruct), this still
erationmarksadeparturefrompriorwork(Zheng
indicateschallengesinleveraginggiveninten-
etal.,2021;Huetal.,2022;Srivastavaetal.,2023;
tionstoproduceappropriateresponses. Using
chain-of-thoughttomakemodelsspelloutin- Ruisetal.,2023),whichhaspredominantlymea-
tentions yields much smaller gains (60% for suredintentionunderstandingthroughadiscrimina-
Mistral-Instruct). These findings suggest tivecontrastivemultiple-choiceclassification. We
thatLLMsarenotyeteffectivepragmaticin- showthatthissettingdoesnotnecessarilyreflect
terlocutors,highlightingtheneedforbetterap-
LLMs’abilitiesingeneratingpragmaticresponses,
proachesformodelingintentionsandutilizing
nordoesitcorrespondtotheuseofLLMsascon-
themforpragmaticgeneration.1
versationalagents(Westetal.,2023).
1 Introduction Weevaluatethepragmaticunderstandingofsev-
eralstate-of-the-artopen-sourceLLMsonvarious
Humans possess the ability to communicate and
typesofnon-literallanguagefromHuetal.(2022).
understandeachothereventhroughnon-literalut-
WeobservethatLLMsoftenstrugglewithgenerat-
terancesandconversationalimplicatures(Roberts
ingcontextuallyappropriateresponsesandtendto
andKreuz,1994;DewsandWinner,1999;Glucks-
interpretnon-literallanguageliterally,withanaccu-
bergandMcGlone,2001;DewsandWinner,1999).
racyof50-55%. Furthermore,wefindthatLLMs’
Thisisattributedtotheirabilitytomakepragmatic
abilityindetectingintentionsdoesnottranslateto
inferencesarisingfromcontextualfactorsandcon-
theirpragmaticresponsegeneration,highlightinga
ventionsinconversation,ratherthanspecificwords
keydistinctionbetweenmerelydetectingintentions
or phrases (Grice, 1975; Davis and Davis, 2016).
andpragmaticallyactingontheminagenerative
Since humans often use non-literal language in
setting. Finally, we explored approaches to im-
communication, large language models (LLMs)
proveLLMs’pragmaticresponseabilities. Using
chain-of-thoughtpromptingtomakemodelsexplic-
1Codeanddataareavailableat: https://github.com/
Akhila-Yerukola/generative-intention-resolution. itlyspelloutintentionsbeforegenerationhasmini-
4202
yaM
41
]LC.sc[
1v06780.5042:viXraAnnieandKellyarediscussingtheirplansforsummer.AnnieasksKelly:“Howmanybooksdoyouplantoreadthissummer?”
Incorrectliteral True
intentIL Amillion. intentIT
Kelly UN
1
Iplantodevotealotoftime
Ihavealistofamillionbooks toreadingthissummer
I b’v oe oc ko sm Ipp li ale nd toa rli es at do ,f Ao nn ne iem .illion U 1L I o’v fe md ye tc imide ed reto ads ip ne gn td hia sg sr ue mat md ee ra .l U 1T
Wow,that’sambitious!
UL That’squiteanambitious UN I’maimingforonlya UT Thatsoundslikeagreat
2 readinglist,Kelly. 2 2 plan,Kelly!
dozen
sim(UN,UL) > sim(UN,UT)
2 2 2 2
Figure1: FrameworktoevaluatewhetheranLLMcangenerateanappropriateresponsetonon-literallanguage
use. GivenacontextC andanon-literalutteranceUN,themodelrespondswithUN. Ourproposedframework
1 2
comparesUN againstresponses(ULandUT)fromtwocounterfactualdialogchainsbasedonconveyingincorrect
2 2 2
literalmeaningI anddirecttrueintentI . WethencomparethesimilarityofthemodelgeneratedresponseUN to
L T 2
thesereferenceresponses,underthecontextC,todeterminewhetheritisappropriate.
maleffectsinaddressingtheselimitations. While conveyintentionsI asUT andI asUL. The
T 1 L 1
providingtheoracletrueintentionsyieldedbetter listener responds accordingly to UT and UL,
1 1
performance,modelsstillsignificantlystruggleto withUT andUL respectively. SeeFigure1.
2 2
effectivelyutilizetheseintentionsinresponsegen-
Evaluating Pragmatic Understanding Our
eration.
framework evaluates the extent to which LLMs’
Overall,ourfindingsindicateasignificantgapin
generatedresponsesreflectanunderstandingofthe
currentLLMs’abilityinpragmaticunderstanding.
underlyingspeaker’sintention. Weoperationalize
Thisemphasizestheneedforbettermechanismsto
this into an automatic metric by using similarity
infercommunicativeintentionsand theireffective
measurements. Ideally, if LLMs can accurately
usage,toenhancepragmaticcommunication.
infer and use the intent to generate cooperative
2 PragmaticResponseGeneration responses using direct language, they should re-
spond as if the non-literal utterance was instead
We introduce a new framework to evaluate prag-
communicated literally. Thus, if an LLM gener-
maticgenerativeabilityofmodels—tounderstand
atespragmaticcooperativeresponses,theresponse
andinferimplicitintentions,anduseittogenerate
shouldbecloserinsimilaritytoresponsegenerated
pragmaticresponsestonon-literalutterances.
under the true intention than to one based on the
literalinterpretationi.e.,therelationsim(UN,UT)
Setup Our evaluation setup (pictured in Figure 2 2
>sim(UN,UL)shouldholdunderthecontextC.
1)measuresLLMs’pragmaticresponsegeneration 2 2
by comparing it to reference dialog chains under Data Huetal.(2022)evaluateintentiondetection
theintendedtruemeaningandunderaliteralmis- withacontextC,asinglenon-literalutteranceUN,
1
interpretation. Specifically,itrequires:
andverbalizedintentsthatincludealiteralintent
I andtrueintentI . Toinstantiateourframework,
• Context C: A short narrative involving 2 or L T
weaugmentthisdatawithdialogchains(UL,UL)
morecharacters. 1 2
conditionedontheliteralintentI and(UT,UT)
L 1 2
• Non-literal Utterance UN: A speaker- conditionedonthetrueintentI . WeuseGPT-4to
1 T
generatedutteranceusingnon-literallanguage. getreferencechains(SeeAppendixA.2).
Weconsiderfournon-literallanguagephenom-
• TrueIntentionI : Theactualintendedmean-
T enafromHuetal.(2022):2
ingofthespeaker.
1. INDIRECT SPEECH. Speakers phrase requests
• Incorrect Literal Intention I : An incorrect
L indirectly,suchasquestions(“Canyoupassthe
literalinterpretationofthespeaker’sintention.
salt?”) orstatements(“Itiscoldinhere”).
• ReferenceDialogChainsbasedonI andI :
T L 2Huetal.(2022)haveothertasksbutwedonotinclude
Speaker alternatively uses direct language to them(e.g.,Deceitsistoonon-cooperative).Generative Discriminative
0.9
0.7
LLaMa-2-7b-chat
LLaMa-2-13b-chat
0.5 LLaMa-2-70b-chat
Mistral-7b-instruct
0.3 Zephyr-7b-
0.1
In dire ct Iro n y M a xim s
M
eta p h or
A g
gre g ate In dire ct Iro n y M a xim s
M
eta p h or
A g
gre g ate
Figure2: ComparisonbetweenintentionresolutioninresponsegenerationvsintentiondetectionbyLLMs. On
average,LLMsfinethegenerativesettingharderthanthediscriminativesettingfornon-literallanguageuse.
2. IRONY. Speakersuseironytomeantheopposite etal.,2023)andissimilarinperformancetoLlama-
ofwhattheysay. Ironyisnotexplicitlydefined 2-70B-chat(Zhengetal.,2023). Wefindthatour
inthecontextC,butC mayincludeinformation annotatorshaveagoodagreement.3
aboutcharacters’emotionalstates.
GPT-4ContextualSimilarity Separately,we
3. MAXIMS OF CONVERSATION. In this task, tasked GPT-4 with a contextual similarity eval-
speakersfloutoneofGrice’smaxims. uation (cf. Section 2): Given the context C,
4. METAPHOR. In this task, the speaker uses the speaker’s true intended meaning I T, and the
metaphors to draw comparisons between enti- Mistral-Instruct generated response U 2N, GPT-4
tiesinanon-literalsense. uses all the information to identify whether U 2N
ismoresimilartothereferenceresponseconveying
Models Weevaluatefivestate-of-the-artLLMs: thetrueintention(UT)ortheonewiththeincorrect
2
Llama2-7B-chat,Llama2-13B-chat,Llama2-70B- literal intention (UL). We find that GPT-4 agrees
2
chat,Mistral-7B-Instruct-v0.2andZephyr-7B-β in- wellwithhumanannotators.4
structionfinetunedmodels. Wegeneratecandidate
Non-ContextualEmbeddingSimilaritywith
listener responses UN using these models, given
2 Llama-3-8B-Instruct Wealsomeasurethenon-
the preceding context C and the speaker’s non-
contextual cosine similarity of UN embeddings
literal utterance UN. We exclude closed-source 2
1
withreferenceresponseconveyingthetrueinten-
APImodels(GPT-3.5/4/variants)fromourevalua-
tion(UT)versustheincorrectliteralintention(UL).
tionsuite,sincewefollow(Huetal.,2022)’sdis- 2 2
UsingLLM2Vec(BehnamGhaderetal.,2024),we
criminativesetupwhichrequiresaccesstomodels’
obtaintextembeddingsfromLlama-3-8B-Instruct.
inputtokenprobabilities. PleaserefertoAppendix
The similarity measured using Llama-3 embed-
A.3forgenerationdetails.
dings generally aligns with human annotations,
Evaluators thoughitagreeslessthanGPT-4’scontextualsim-
ilarity evaluation.5 Additionally, we experiment
HumanEvaluation SinceLLMresponsesare with contextual embedding similarity variations
intended for human conversational partners, we (Yerukola et al., 2023), where the context C′ can
solicit human judgments to check whether un- be I , I , or turn-1 responses UT or UL. How-
T L 1 1
derstanding of the true intent is reflected in the ever,thissettingperformedworse. Wehypothesize
generated response. We employ 9 students from
ourinstitutiontoevaluatewhetherMistral-Instruct
3pairwiseagreement=0.8,Krippendorff’sα=0.6
4Weaverageacrossindividualpairwiseagreementsofeach
responses successfully capture the true intended
annotatorwithGPT-4(pairwiseagreement=0.77,σ=0.05;
intention I T behind the speaker’s non-literal ut- Krippendorff’sα=0.54,σ=0.1)
terance UN, within the given context C. We 5SimilartoGPT-4,weaverageacrossindividualpairwise
1 agreements of each annotator with Llama-3-embeddings
choose Mistral-Instruct arbitrarily, since it is re-
(pairwise agreement = 0.74, σ = 0.005; Krippendorff’s
portedtosurpassLlama-2-13B-chatmodel(Jiang α=0.46,σ=0.01)
ycaruccAthatnon-literallanguagenuancesarehardertobe free-form,requiringconsistencyandminimalcom-
capturedbyembeddingsalone. poundingerrors. Thisunderscorestheimportance
Thus,weusethebetterperformingGPT-4con- ofevaluatingmodelperformanceinbothdiscrim-
textualsimilarityevaluationasaproxyforoureval- inative and generative settings to obtain a better
uationparadigminalloursubsequentexperiments. understandingofLLMs’pragmaticunderstanding.
3 ResultsonPragmaticResponse 4 Chain-of-ThoughtPromptingfor
Generation PragmaticResponseGeneration
MotivatedbytheabilityofLLMstodetectinten-
Inthissection,weanalyzehowwellLLMscangen-
tionsinsomephenomena,weexplorewaystoim-
eratecontextuallyrelevantresponses. Wecompare
provetheirunderstandingofimplicitintentionsand,
ourproposedgenerativeapproach,whichevaluates
implicitunderstandinginresponsestoUN,against therebyenhancingtheircapabilitytogenerateprag-
1
maticresponsesusingchain-of-thoughtprompting
a discriminative multiple-choice setup as in Hu
(CoT)(Camburuetal.,2018;Weietal.,2022).
etal.(2022),whichevaluatesintentiondetectionin
UN utterances.
1 Experiments using Chain-of-Thought In our
experimentswithCoT,wefirstgenerateaninferred
Results Figure 2 indicates that LLMs exhibit
intention and then a response (unless otherwise
better performance in responding to INDIRECT
specified). Weexaminehowresponsegeneration
SPEECH amongvariousnon-literallanguagetypes,
performance is affected by introducing varying
potentiallyduetoconventionalizationofresponses,
levelsoforaclecuesattheinferredintentiongen-
orexplicitdescriptionsofrequestscompletedseen
eration step, organized by increasing amounts of
duringtraining(Huetal.,2022). Modelsperform
“hand-holding”:
the worst at responding to flouted MAXIMS, per-
forming worse than chance. For instance, mod- (0) Nooracleinformation(Naive)
elsfailtodetecttheattempttochangethesubject
(1) Counterfactual reasoning to clarify the non-
in “Oh, it’s such a pleasant day today” amidst a
literalutterances(noinferredintentionhere)
discussion about a “bad date”. Llama-2 models
(2) Questioningaspecificphenomenon(e.g.,’is
exhibit marginally better metaphorical language
Kellybeingironic’)
understanding(METAPHORS)comparedtoMistral
andZephyrmodels. IntheLlama-2family,wesee (3) Merelyindicatingnon-literallanguageuse
thatmodelsperformbetterwithincreasingsize. In (4) Identifying the phenomenon (e.g., ’Kelly is
aggregate, we see that LLMs perform at or near beingironic’)
chanceingeneratinganappropriateresponsethat
(5) ProvidingthetrueintentionasCoT(nomodel-
reflectshavinginferredthetrueintent.
generatedinferredintentionhere)
Comparison against Discriminative Intention (6) Providingtrueintentionand phenomenonin-
Detection Wefollowthemultiple-choicesetup formation(e.g.,“Kellywantstoreadalotand
asinHuetal.(2022)(detailsinAppendixB).In isusingironytoconveyit”)
Figure2,weconsistentlyseethatmodelsfinditeas-
iertodetecttrueintentionsinsocialsituationsthat Results Figure 3 illustrates that specifying the
involvefloutingconversationalnorms(MAXIMS) type of non-literal language used along with the
inamultiple-choicesetup. However,theystruggle speaker’strueintent(Prompt 6)significantlyim-
withusingthispotentiallyinferredunderstanding proves the model’s ability to generate appropri-
inpragmaticresponsegeneration. ateresponses,withtop-performingMistral-Instruct
We see that trends do not remain consistent achieving 75%accuracy. Evenprovidingsubsets
acrossdifferentmodelsandphenomena,andthat ofthis,suchasjustthetrueintention(Prompt 5),
onaverage,modelsstrugglemoreinthegenerative generally improves performance. In these cases,
setting. We hypothesise that in a discriminative the task essentially becomes leveraging the pro-
setup, the model can access all options, thus it videdoracletrueintentioninresponsegeneration.
knowstheanswerforminadvanceandhastheabil- However, despitethissimplification, thereisstill
itytoevaluatetheanswerscontrastively. However, roomforsignificantimprovementinpragmaticre-
in a generative setup, the model’s generation is sponsegeneration.LLaMa-2-7b-chat LLaMa-2-70b-chat Zephyr-7b- thoughthelpsimproveamodel’sabilitytointerpret
LLaMa-2-13b-chat Mistral-7b-instruct
theuseofimplicatures. Thesetaskshavefocused
0.75 onevaluatingmodels’abilitytointerpretthetrue
0.70 intentunderlyinganutterance,butnotrespond to
0.65 itaswedointhiswork. Anotherlineofworkhas
0.60 consideredLLMs’mentalizingabilitiesusingfalse
0.55 belief tasks (Shapira et al., 2023) or question an-
0.50 swering(Leetal.,2019;Kimetal.,2023a). Zhou
0.45 et al. (2023a) consider a task that evaluates how
Base prompt Prompt 0 Prompt 1 Prompt 2 Prompt 3 Prompt 4 Prompt 5 Prompt 6 modelsrespondusingknowledgeofotheragents’
Increasing oracle information mentalstates.
Figure3:ResultsfromexperimentswithCoTprompting
showthatperformanceishighestwhenprovidingoracle Generatingresponsesbasedoninferredintents
trueintention,andlowestwithnooracleinformation. Some work has presented resources for intent or
emotion-conditioned response generation, where
a conversational agent must respond conditioned
Intuitively,ifmodelscanaccuratelyinferthese
onaparticularintentoremotion. Lietal.(2017b)
intention cues themselves, they could generate
and Rashkin et al. (2019) present datasets of dia-
pragmaticresponses. Weobservetaslightimprove-
logues annotated with discrete emotion or intent
ment in performance (on average) when no ora-
labels. Zhang and Zhang (2019) and Chen et al.
cle information is provided (Prompt 0) or when
(2022) present approaches to modeling intent ex-
prompted for counterfactual reasoning regarding
plicitly. Guetal.(2022a)generateexplicitscene
thenon-literalexpression(Prompt 1). Providing
elaborationstoimprovefigurativelanguageunder-
explicit cues about the phenomenon (e.g.,‘Kelly
standing. Whiletheseworksconsiderconditioning
is being ironic’ vs. ‘Is Kelly being ironic?’) help
onintent,theydonotexplicitlyfocusongenerating
slightly (Prompts 2-4), although not as signifi-
orevaluatingresponsestonon-literallanguageuse.
cantlyasprovidingthetrueintention.
These findings highlight the importance of ex- 6 Summary
plicitly modeling intention in LLMs, indicating
Weproposeanewframeworktoevaluatehowwell
thatresponseaccuracytonon-literallanguagecan
LLMs understand intentions and respond to non-
improvewithsuchapproaches. Overall,thereisa
literal language, moving beyond previously em-
clearneedfor: (a)betterlearningmechanismsto
ployedmultiple-choicesettings. Ourresultsshow
helpmodelseffectivelydisentanglethelinguistic
thatLLMsoftenstruggletogeneratecontextually
strategiesusedandcommunicativeintent(e.g.,rec-
relevantresponses. Whilechain-of-thoughtprompt-
ognizinghowexaggerationcancreateironytohigh-
ingtospelloutinferredintentionsoffersmarginal
lightdisagreement),and(b)effectiveutilizationof
improvements, explicitly providing oracle inten-
learnedintentionsduringresponsegeneration.
tionsandcues,suchasforirony,significantlyen-
5 RelatedWork hancesperformance. Thesefindingshighlightthe
current limitations of LLMs in pragmatic under-
Non-literal language understanding in LLMs standing,suggestingthatimprovedlearningmech-
Recent work has proposed several ways to eval- anismstoexplicitlymodelintentionsandlinguis-
uate LLMs’ ability to interpret non-literal lan- ticstrategiescouldsignificantlyenhanceconversa-
guage, including implicature (Ruis et al., 2023; tionalabilities.
Kim et al., 2023b), figurative language use (Liu
etal.,2022a;Chakrabartyetal.,2022b;Guetal., 7 Limitations&EthicalConsiderations
2022b;Chakrabartyetal.,2022a;Wachowiakand
Despite taking the first step towards proposing a
Gromann, 2023; Lai and Nissim, 2024), detect-
newgenerativeframeworkforevaluatingintention
ingprofundity(Herrera-Bergetal.,2023),broader
resolution in LLMs, there are several limitations
benchmarks for social language understanding
andethicalconcerns,whichwelistbelow.
(Choietal.,2023)andvariouspragmaticphenom-
ena(Lietal.,2017a;Zhengetal.,2021;Huetal., Limited Context Scope In this study, our pri-
2022). Kimetal.(2023b)alsofindthatchain-of- mary focus is the evaluation of intention under-
ycarucca
noitareneg
esnopseRstandingandusingitinpragmaticresponsegenera- findings,andconclusionsorrecommendationsex-
tion. Futureworkshouldexploreintroducingother pressed in this material are those of the author(s)
forms of context into the pragmatic generation anddonotreflecttheviewsofAmazon.
pipeline, such as richer social and power dynam-
ics(Antoniaketal.,2023),emotionalstates(Zhou
References
etal.,2023b),andexternalknowledge(Ghazvinine-
jadetal.,2018),allofwhichcansignificantlycon- Maria Antoniak, Anjalie Field, Ji Min Mun, Melanie
tributetovariedlevelsofpragmaticunderstanding. Walsh,LaurenF.Klein,andMaartenSap.2023. Riv-
eter: Measuringpowerandsocialdynamicsbetween
entities. InACLdemonstrations.
Amountofcontext Inourexperiments,weopted
toincludeshort1-3sentencestories. Futurework Parishad BehnamGhader, Vaibhav Adlakha, Marius
canexplorelongerstoriesandincludemorepreced- Mosbach, Dzmitry Bahdanau, Nicolas Chapados,
andSivaReddy.2024. LLM2Vec: Largelanguage
ingdialogturns. Wehypothesizethatmorecontext
models are secretly powerful text encoders. arXiv
willmakethistaskmorechallenging,andwewould
preprint.
neednuancedwaysofunderstandingintentionsat
differentturns. Oana-Maria Camburu, Tim Rocktäschel, Thomas
Lukasiewicz,andPhilBlunsom.2018. e-snli: Natu-
rallanguageinferencewithnaturallanguageexpla-
Limited number of non-literal phenomenon
nations. AdvancesinNeuralInformationProcessing
We explore the evaluation of only four phenom-
Systems,31.
ena: INDIRECT SPEECH, IRONY, MAXIMS, and
Tuhin Chakrabarty, Yejin Choi, and Vered Shwartz.
METAPHORS. Futureworkshouldconsiderother
2022a. It’snotrocketscience: Interpretingfigurative
types of figurative language, such as cultural
languageinnarratives. TransactionsoftheAssocia-
metaphors(Kabraetal.,2023),visualmetaphors tionforComputationalLinguistics,10:589–606.
(Liu et al., 2022b), idioms, proverbs, etc. Ex-
TuhinChakrabarty,ArkadiySaakyan,DebanjanGhosh,
pandingthescopetoincludetheseelementswould
and Smaranda Muresan. 2022b. Flute: Figurative
provide a more comprehensive understanding of
languageunderstandingthroughtextualexplanations.
LLMs’ capabilities in interpreting nuanced lan- In Proceedings of the 2022 Conference on Empiri-
guage. calMethodsinNaturalLanguageProcessing,pages
7139–7159.
PotentiallyInconsistentHumanEvaluation In
MaoYanChen,SihengLi,andYujiuYang.2022. Em-
our work, we employ only 9 expert human anno- pHi: Generatingempatheticresponseswithhuman-
tators and assume human judgments as the gold likeintents. InProceedingsofthe2022Conference
standard. Concurrentworkhasshownthathuman oftheNorthAmericanChapteroftheAssociationfor
ComputationalLinguistics: HumanLanguageTech-
evaluation might not always be consistent (Clark
nologies, pages 1063–1074, Seattle, United States.
et al., 2021; Karpinska et al., 2021); however hu-
AssociationforComputationalLinguistics.
manjudgmentscontinuetobethegoldstandardfor
MinjeChoi,JiaxinPei,SagarKumar,ChangShu,and
evaluatingopen-endedtextgeneration.
David Jurgens. 2023. Do LLMs understand social
knowledge? evaluatingthesociabilityoflargelan-
PotentialeffectsonFactuality Inourwork,we
guagemodelswithSocKETbenchmark. InProceed-
showthatLLMsstrugglewithrespondingpragmat- ingsofthe2023ConferenceonEmpiricalMethodsin
icallytonon-literallanguage. Trainingapproaches NaturalLanguageProcessing,pages11370–11403,
Singapore.AssociationforComputationalLinguis-
whichmighthelpwithbetterintentionmodelingto
tics.
handlenon-literallanguagemaypotentiallyaffect
faithfulnessorfactualityofLLMsresponses. Elizabeth Clark, Tal August, Sofia Serrano, Nikita
Haduong, Suchin Gururangan, and Noah A Smith.
2021. Allthat’s‘human’isnotgold: Evaluatinghu-
8 Acknowledgements
man evaluation of generated text. In Proceedings
of the 59th Annual Meeting of the Association for
Wewouldliketothankourstudentannotatorsfor
ComputationalLinguisticsandthe11thInternational
helping us with intention resolution annotations. JointConferenceonNaturalLanguageProcessing
WethankOpenAIforprovidingresearchercredits (Volume1: LongPapers),pages7282–7296.
toaccessGPT-4. Thisprojectisfundedinpartby
WayneADavisandWayneADavis.2016. Implicature.
DSO National Laboratories and an Amazon Re-
IrregularNegatives,Implicatures,andIdioms,pages
search Award, Spring 2023 CFP. Any opinions, 51–84.ShellyDewsandEllenWinner.1999. Obligatorypro- HyunwooKim,MelanieSclar,XuhuiZhou,RonanBras,
cessingofliteralandnonliteralmeaningsinverbal GunheeKim,YejinChoi,andMaartenSap.2023a.
irony. Journalofpragmatics,31(12):1579–1599. FANToM:Abenchmarkforstress-testingmachine
theoryofmindininteractions. InProceedingsofthe
Marjan Ghazvininejad, Chris Brockett, Ming-Wei 2023ConferenceonEmpiricalMethodsinNatural
Chang,BillDolan,JianfengGao,Wen-tauYih,and Language Processing, pages 14397–14413, Singa-
MichelGalley.2018. Aknowledge-groundedneu- pore.AssociationforComputationalLinguistics.
ralconversationmodel. InProceedingsoftheAAAI
ConferenceonArtificialIntelligence,volume32. ZaeMyungKim,DavidE.Taylor,andDongyeopKang.
2023b. "is the pope catholic?" applying chain-of-
SamGlucksbergandMatthewSMcGlone.2001. Un- thought reasoning to understanding conversational
derstandingfigurativelanguage: Frommetaphorto implicatures.
idioms. 36.OxfordUniversityPress.
HuiyuanLaiandMalvinaNissim.2024. Asurveyon
Herbert P Grice. 1975. Logic and conversation. In automaticgenerationoffigurativelanguage: From
Speechacts,pages41–58.Brill. rule-basedsystemstolargelanguagemodels. ACM
ComputingSurveys.
Yuling Gu, Yao Fu, Valentina Pyatkin, Ian Magnus-
MatthewLe,Y-LanBoureau,andMaximilianNickel.
son,BhavanaDalviMishra,andPeterClark.2022a.
2019. Revisiting the evaluation of theory of mind
Just-DREAM-about-it: Figurative language under-
throughquestionanswering. InProceedingsofthe
standingwithDREAM-FLUTE. InProceedingsof
2019 Conference on Empirical Methods in Natu-
the3rdWorkshoponFigurativeLanguageProcess-
ralLanguageProcessingandthe9thInternational
ing (FLP), pages 84–93, Abu Dhabi, United Arab
JointConferenceonNaturalLanguageProcessing
Emirates (Hybrid). Association for Computational
(EMNLP-IJCNLP),pages5872–5877,HongKong,
Linguistics.
China.AssociationforComputationalLinguistics.
YulingGu,YaoFu,ValentinaPyatkin,IanMagnusson,
Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang
BhavanaDalviMishra,andPeterClark.2022b. Just-
Cao,andShuziNiu.2017a. Dailydialog:Amanually
dream-about-it: Figurativelanguageunderstanding
labelledmulti-turndialoguedataset. InProceedings
withdream-flute. FLP2022,page84.
oftheEighthInternationalJointConferenceonNat-
uralLanguageProcessing(Volume1: LongPapers),
Eugenio Herrera-Berg, Tomás Browne, Pablo León-
pages986–995.
Villagrá, Marc-Lluís Vives, and Cristian Calderon.
2023. Largelanguagemodelsarebiasedtooveresti-
Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang
mateprofoundness. InProceedingsofthe2023Con-
Cao,andShuziNiu.2017b. DailyDialog: Amanu-
ferenceonEmpiricalMethodsinNaturalLanguage
allylabelledmulti-turndialoguedataset. InProceed-
Processing,pages9653–9661,Singapore.Associa-
ings of the Eighth International Joint Conference
tionforComputationalLinguistics.
onNaturalLanguageProcessing(Volume1: Long
Papers),pages986–995,Taipei,Taiwan.AsianFed-
JenniferHu,SammyFloyd,OlessiaJouravlev,Evelina
erationofNaturalLanguageProcessing.
Fedorenko, and Edward Gibson. 2022. A fine-
grained comparison of pragmatic language under- EmmyLiu,ChenxuanCui,KennethZheng,andGraham
standing in humans and language models. arXiv Neubig.2022a. Testingtheabilityoflanguagemod-
preprintarXiv:2212.06801. elstointerpretfigurativelanguage. InProceedings
ofthe2022ConferenceoftheNorthAmericanChap-
Albert Q Jiang, Alexandre Sablayrolles, Arthur Men- teroftheAssociationforComputationalLinguistics:
sch,ChrisBamford,DevendraSinghChaplot,Diego HumanLanguageTechnologies,pages4437–4452,
delasCasas,FlorianBressand,GiannaLengyel,Guil- Seattle,UnitedStates.AssociationforComputational
laumeLample,LucileSaulnier,etal.2023. Mistral Linguistics.
7b. arXivpreprintarXiv:2310.06825.
EmmyLiu,ChenxuanCui,KennethZheng,andGraham
Anubha Kabra, Emmy Liu, Simran Khanuja, Al- Neubig.2022b. Testingtheabilityoflanguagemod-
hamFikriAji,GentaWinata,SamuelCahyawijaya, elstointerpretfigurativelanguage. InProceedings
AnuoluwapoAremu,PerezOgayo,andGrahamNeu- ofthe2022ConferenceoftheNorthAmericanChap-
big.2023. Multi-lingualandmulti-culturalfigurative teroftheAssociationforComputationalLinguistics:
languageunderstanding. InFindingsoftheAssocia- HumanLanguageTechnologies.
tionforComputationalLinguistics:ACL2023,pages
8269–8284. HannahRashkin,EricMichaelSmith,MargaretLi,and
Y-Lan Boureau. 2019. Towards empathetic open-
Marzena Karpinska, Nader Akoury, and Mohit Iyyer. domainconversationmodels: Anewbenchmarkand
2021. Theperilsofusingmechanicalturktoevaluate dataset. In Proceedings of the 57th Annual Meet-
open-ended text generation. In Proceedings of the ingoftheAssociationforComputationalLinguistics,
2021ConferenceonEmpiricalMethodsinNatural pages 5370–5381, Florence, Italy. Association for
LanguageProcessing,pages1265–1285. ComputationalLinguistics.Richard M Roberts and Roger J Kreuz. 1994. Why ZilongZheng,ShuwenQiu,LifengFan,YixinZhu,and
do people use figurative language? Psychological Song-Chun Zhu. 2021. Grice: A grammar-based
science,5(3):159–163. datasetforrecoveringimplicatureandconversational
reasoning. InFindingsoftheAssociationforCom-
LauraElineRuis,AkbirKhan,StellaBiderman,Sara putational Linguistics: ACL-IJCNLP 2021, pages
Hooker,TimRocktäschel,andEdwardGrefenstette. 2074–2085.
2023. The goldilocks of pragmatic understanding:
Fine-tuningstrategymattersforimplicatureresolu-
tionbyllms. InThirty-seventhConferenceonNeural
InformationProcessingSystems.
Natalie Shapira, Mosh Levy, Seyed Hossein Alavi,
Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten
Sap,andVeredShwartz.2023. Cleverhansorneural
theory of mind? stress testing social reasoning in
largelanguagemodels.
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,
AbuAwalMdShoeb,AbubakarAbid,AdamFisch,
AdamRBrown,AdamSantoro,AdityaGupta,Adrià
Garriga-Alonso, et al. 2023. Beyond the imitation
game: Quantifying and extrapolating the capabili-
tiesoflanguagemodels. TransactionsonMachine
LearningResearch. PeiZhou,AmanMadaan,SrividyaPranaviPotharaju,
Aditya Gupta, Kevin R. McKee, Ari Holtzman,
LennartWachowiakandDagmarGromann.2023. Does JayPujara, XiangRen, SwaroopMishra, AidaNe-
GPT-3graspmetaphors? identifyingmetaphormap- matzadeh, Shyam Upadhyay, and Manaal Faruqui.
pingswithgenerativelanguagemodels. InProceed- 2023a. How far are large language models from
ingsofthe61stAnnualMeetingoftheAssociationfor agentswiththeory-of-mind?
ComputationalLinguistics(Volume1: LongPapers),
pages1018–1032,Toronto,Canada.Associationfor
ComputationalLinguistics.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
etal.2022. Chain-of-thoughtpromptingelicitsrea-
soninginlargelanguagemodels. AdvancesinNeural
InformationProcessingSystems,35:24824–24837.
PeterWest,XimingLu,NouhaDziri,FaezeBrahman,
LinjieLi,JenaDHwang,LiweiJiang,JillianFisher,
AbhilashaRavichander,KhyathiChandu,etal.2023.
Thegenerativeaiparadox:"whatitcancreate,itmay
notunderstand". arXivpreprintarXiv:2311.00059.
Akhila Yerukola, Xuhui Zhou, Elizabeth Clark, and
MaartenSap.2023. Don’ttakethisoutofcontext!: XuhuiZhou,HaoZhu,AkhilaYerukola,ThomasDavid-
Ontheneedforcontextualmodelsandevaluations son, Jena D. Hwang, Swabha Swayamdipta, and
for stylistic rewriting. In Proceedings of the 2023 MaartenSap.2023b. Cobraframes: Contextualrea-
Conference on Empirical Methods in Natural Lan- soning about effects and harms of offensive state-
guageProcessing,pages11419–11444. ments. InFindingsofACL.
Bo Zhang and Xiaoming Zhang. 2019. Hierarchy re-
sponselearningforneuralconversationgeneration.
InProceedingsofthe2019ConferenceonEmpirical
Methods in Natural Language Processing and the
9thInternationalJointConferenceonNaturalLan-
guageProcessing(EMNLP-IJCNLP),pages1772–
1781,HongKong,China.AssociationforComputa-
tionalLinguistics.
LianminZheng,Wei-LinChiang,YingSheng,Siyuan
Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,
ZhuohanLi,DachengLi,Eric.PXing,HaoZhang,
JosephE.Gonzalez,andIonStoica.2023. Judging
llm-as-a-judgewithmt-benchandchatbotarena.A PragmaticResponseGeneration Task: You will read a short story. The story
will be followed by a question. Your
A.1 Data
task is to decide which response option is
Weconsiderfournon-literallanguagephenomenon closest to the 'Generated Response'.
fromHuetal.(2022): The answer options are 1 or 2.
1. INDIRECT SPEECH-20examples
Scenario: {Context}
2. IRONY-25examples
{speaker's non-literal utterance U_1^N}
3. MAXIMS OF CONVERSATION20examples
Intention: {True intention}
4. METAPHOR-20examples
These examples were were manually curated by Generated Response:
expert researchers to cover a broad range of non- {Person2} replies, {U_2^N from model}
literalphenomenaandelicitindividualdifferences
amonghumans. Compare the below utterances to the
Generated Response. Which of the
A.2 GoldDialogChainsbasedonI andI
T L
below utterances is closest to the
Inourexperiments,weuseGPT-4togeneratecoun-
above Generated Response?
terfactual gold dialog chains based on I and I .
T L Options:
WefirstgenerateUL byprovidingGPT-4withonly
1 1. {U_2^T from true intention dialog chain}
theincorrectliteralintentionI topreventanypos-
L 2. {U_2^L from incorrect literal intention
sible contextual inference from C from being re-
dialog chain}
flectedinUL. Next,wegenerateUT byproviding
1 1
GPT-4 with the context C and true intention I ,
T Answer (option number 1 or 2): {number}
mimicking an ideal direct cooperative utterance
generationsetting. Wefollowthesamesettingto Werandomlyshuffleintentionsprovidedasoptions
generate UL and UT from UL and UT, respec- 1 and 2. We set the temperature=0 to ensure the
2 2 1 1
tively. stabilityoftheevaluation.
Forhumanevaluation,weprovidethefollowing
A.3 Models
prompt:
Weusethefollowingprompttogenerateresponses Task: You will be provided a short story,
usingLLMs: an utterance by one of the characters
Generate a short, concise single sentence in the story (person1). Person1 uses
response. non-literal language (like irony).
Context: {context} Person2 from the story responds to person1's
{speaker's non-literal utterance} utterance. The task is to identify if
the "true intention" (provided) is
Generate a co-operative response without resolved/understood in person2's response
any non-literal language as or not.
{listener character name}.
Make a binary yes/no choice.
{listener character name} replies,
We employ 9 students from our institution – 6
Weusetemperaturesamplingwithtemperaturesof
women, 3 men (20-30 age group) living in the
0.3 and 0.5 to generate responses, averaging the
UnitedStatesofAmerica.
results from both settings. We find that a lower
temperature= 0 results in incoherent, uninterest- B DiscriminativeSetup
ingresponses,whileatemperature> 0.5leadsto
veryverboseresponsesthatdigressfromthemain WefollowsetupinHuetal.(2022)forourdiscrim-
contextandextrapolateexcessively. inativesetupcomparison. Theyuseathemultiple-
choicesetup. Theycomputetheprobabilityofan-
A.4 Evaluators
sweroptions–trueintentionI andliteralmisin-
T
ForGPT-4asanevaluator,weprovidethefollow- terpretationI –giventhecontextC,thespeaker’s
L
ingprompt: non-literalutteranceUN,andtaskinstructions. We
10.7
0.6
0.5 Prompt
naive CoT
non-literal lang + CoT
0.4 phenomenon + CoT
counterfactual + CoT
0.3
0.2
0.45 0.50 0.55 0.60 0.65
inferred_intention_acc
Figure4:Positivecorrelationbetweeninferredintention
accuracyandpragmaticresponseaccuracy.
measureaccuracyasassigningthehighestproba-
bility to the correct answer token (e.g., “1”, “2”).
We follow the same prompt template as Hu et al.
(2022):
Task: You will read short stories that
describe everyday situations. Each
story will be followed by a multiple-
choice question. Read each story and
choose the best answer. Your task is
to decide what the character in the
story is trying to convey. The answer
options are 1 or 2.
Scenario: {context} {dialog}.
What might {person1} be trying to convey?
Options:
1) {option1}
2) {option2}
Answer:
C Chain-of-thoughtPrompting
Pleaserefertoforthechain-of-thoughtprompting
templatesusedforallthemodels
C.1 InferredIntentionvsResponseAccuracy
We evaluate similarity of CoT generated intents
withthetrueintentandtheincorrectliteralintent
usingGPT-4. WefollowasimilarpromptasGPT-4
evaluatorinAppendixA.4. WeobserveinFigure
4 that a model that is able to correctly infer the
underlyingtrueintentionisalsobetteratgenerating
contextuallyrelevantresponses,corroboratingour
findingfrom PROMPT 5-6 inSection4.
cca_esnopserFigure5:Chain-of-thoughtPromptingtemplatesusedinSection4.Orangehighlightedtextistheexplicitlyprovided
oracleinformation.