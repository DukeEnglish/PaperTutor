ViSTooth: A Visualization Framework for Tooth Segmentation on
Panoramic Radiograph
ShenjiZhu* MiaoxinHu† TianyaPan‡
HangzhouDianziUniversity HangzhouDianziUniversity HangzhouDianziUniversity
YueHong§ BinLi¶
DepartmentofStomatology,FirstAffiliatedHospital,ZhejiangUniversity. DepartmentofStomatology,ShengzhouPeople’sHospital.
SchoolofMedicine,ZhejiangUniversity.
ZhiguangZhou|| TingXu**
HangzhouDianziUniversity DepartmentofStomatology,FirstAffiliatedHospital,ZhejiangUniversity.
Figure 1: The visualization interface for tooth segmentation on panoramic radiograph. (A)Model Explorer: The dataset panel
displaysthebasicinformationoftheunlabeledpanoramicradiographandthecontrolpanelcontrolsthevaluesofparametersin
themodelsuchastrainingtimes,learningrateandsoon.(A1)Thelinecharttodisplaytheprocessofmodeloptimization.(A2)The
barcharttoshowthetimeofmanuallycorrectionperimage. (B)RadiographicFeatureExplorer: (B1)ThePanoramicViewtoshow
thesegmentationmasksonpanoramicradiograph.(B2)TheGlyphViewtorevealthefeaturesoftoothsegmentation.(C)Extracted
FeatureExplorer: (C1)TheScatterplotViewtoprovideanoverviewofrelationshipsamongthetoothsamples. (C2)TheZoomed
Viewtodisplayamoredetailedexplorationofextractedfeatures. (C3)TheReferenceSampleViewtoillustratetheattributesof
similarinstances.
ABSTRACT incompletesamplesetformachinelearning. Inthispaper,wepro-
pose ViSTooth, a visualization framework for tooth segmentation
Toothsegmentationisakeystepforcomputeraideddiagnosisof
ondentalpanoramicradiograph.First,weemployMaskR-CNNto
dental diseases. Numerous machine learning models have been
conductpreliminarytoothsegmentation,andasetofdomainmet-
employedfortoothsegmentationondentalpanoramicradiograph.
ricsareproposedtoestimatetheaccuracyofthesegmentedteeth,
However, it is a difficult task to achieve accurate tooth segmen-
includingtoothshape,toothpositionandtoothangle.Then,werep-
tation due to complex tooth shapes, diverse tooth categories and
resent the teeth with high-dimensional vectors and visualize their
distributioninalow-dimensionalspace,inwhichexpertscaneas-
*e-mail:231330018@hdu.edu.cn
†e-mail:miaoxinhu@outlook.com ily observe those teeth with specific metrics. Further, we expand
‡e-mail:cbpantianya@163.com the sample set with the expert-specified teeth and train the tooth
§e-mail:hy984500@163.com segmentationmodeliteratively.Finally,weconductcasestudyand
¶e-mail:libin330624@163.com expert study to demonstrate the effectiveness and usability of our
||e-mail:zhgzhou@hdu.edu.cn ViSTooth,inaidingexpertstoimplementaccuratetoothsegmenta-
**e-mail:xut@zju.edu.cn tionguidedbyexpertknowledge.
IndexTerms: Toothsegmentation,panoramicradiograph,visual-
ization,visualanalytics,humancomputercollaboration.
4202
yaM
41
]CH.sc[
1v37580.5042:viXra1 INTRODUCTION 2 RELATEDWORK
Panoramicradiographisawidely-usedimagingmodalityfordental 2.1 ToothSegmentation
examinationinstomatology,whichprovidesavisualrepresentation
Toothsegmentationonpanoramicradiographisacriticaltask,ad-
ofallteethwithinthedentalcavity, andhelpsdoctorstoexamine
dressedthroughtwoprimarymethodologies:unsupervisedandsu-
the pathological conditions, such as dental calculus, dental mal-
pervisedapproaches. Intheunsupervisedcategory,variousstrate-
formationsandcaries[1]. Toothsegmentationisapivotalstepfor
gieshavebeendeveloped.Modietal.[21]proposedaregion-based
computeraideddiagnosisoftooth-relateddisorders[2]. However,
methodtoidentifyregionsofinterestforgapvalleyandtoothisola-
manual annotation is a laborious and time-consuming task, espe-
tionusingbinaryedgeintensityintegralcurves.Indraswarietal.[6]
ciallywhenthereareoverlappingshadowsorlowcontrast.
employedathree-stepprocessinvolvingdirectionalimageforma-
In recent years, numerous machine learning models have been
tionusingDDFBT,enhancementforedgereinforcementandnoise
proposedfortoothsegmentationondentalpanoramicradiograph[3,
removal, andMATwithSauvolaLocalThresholdingforsegmen-
4, 5], encompassing both unsupervised and supervised methods.
tation. Alsmad et al.[22] utilized a cluster-based approach, while
Unsupervisedmethodsincludethreshold-basedsegmentation[6,7],
Hasanetal.[23]focusedonjawsegmentationusinggradientinfor-
edgedetection[8,9],andgraphtheory[10],whilesupervisedmeth-
mationinafour-stepmethodcomprisingk-meansclustering,point
ods rely on labeled data for training[11]. Deep learning-based
detection around the jaw, gradient vector flow snakes, and shape
approaches, such as U-Net[12, 13], Faster R-CNN[14, 15] and
correctionforthesegmentedarea. Lietal.[24]introducedanew
PANet[16], fall under the category of supervised methods. How-
watershed algorithm based on mathematical morphology, specifi-
ever,duetothesubstantialvariationsintoothshapeandtypes,such
callytailoredfordentalX-rayimagesegmentation.Farizaetal.[25]
astrategyisstillunabletofundamentallysolvetheproblemofac-
employedamethodtoextractdifferentdentalstructuresusingcon-
curacyandrobustnessofautomaticsegmentationalgorithms,which
ditionalspatialfuzzyC-meansclustering.
bringsuncertaintytothesubsequentdiagnosis[17,11,18].
Incontrast, supervisedmethodsleveragedeeplearningmodels
Extensivediscussionswithprofessionaldentalexpertsandcom-
trained on annotated data to improve segmentation accuracy and
puter experts have led to the consensus that traditional AI seg-
stability. Jaderetal. [26]arecreditedforbeingthepioneerswho
mentationmethodsexhibitsignificantlimitationswhenappliedto
detectedandsegmentedeachtoothonpanoramicradiographs. Al-
toothsegmentationonpanoramicradiograph. Twoprimaryques-
malki et al.[27] applied two self-supervised learning methods to
tionshavebeenidentified. Q1. Themodelhasaprimaryfocuson
SwinTransformerondentalpanoramicradiographs: SimMIMand
pixelfeaturesbutlacksessentialdentalexpertiseliketoothshape
UM-MAE. Zhang et al.[28] proposed a novel method that using
andangle,hinderingitscontextualunderstandingandabilitytodis-
label tree with cascade network structure combining several key
cernintricatedetailsandnuancesspecifictodentalconditions.This
strategiesforteethrecognition,whichcandealwithmanycomplex
limitation becomes particularly evident when the training sample
cases.Hellietal.[29]employedatwo-stepmethodwheretheyem-
is unable to cover the full spectrum of dental conditions, causing
ployed a U-Net to create prediction followed by post-processing
themodeltostruggleinaccuratelysegmentingcomplexorspecial
operations to achieve segmentation. Leite et al.[18] proposed a
teeth.Q2.Intheprocessofsegmentation,completedependenceon
CNN-basedsolutionfordeterminingtoothcontoursusingseman-
automated algorithmsmay lead tosuboptimal tooth segmentation
ticsegmentation,furtherrefinedbyaFullyConvolutionalNetwork
results in certain cases, as the model lacks the ability to dynami-
(FCN). These methods were evaluated using metrics such as av-
cally adapt and refine its segmentation outputs in response to the
erageIntersectionoverUnion(IoU)andHausdorffdistance,com-
nuancesofindividualcases.
paredagainstmanualannotationsandmedicalsoftware. Tuzoffet
As such, we develop a human-machine collaboration frame- al.[30] applied the Faster R-CNN object detection model to gen-
work,VisTooth(Figure1),comprehensivelyconsideringtoothfea- eratetoothborders,enhancingtheoutputthroughintegrationwith
turesandintroducingexpertiseinthesegmentationprocesstoopti- the VGG16 classification network and heuristic rules of dentition
mizethemodeloutcomes.Firstly,weusethefine-adjustedMaskR- arrangement. Additionally, Mask R-CNN[19], a deep learning-
CNNmodel[19]toachievepreliminarytoothsegmentation,which based method, offers simultaneous object detection and segmen-
focuses on the features involving dental expertise. A glyph rep- tation,incorporatingROIAlignforimprovedaccuracy.Despitethe
resentationisgeneratedtovisualizethesefeatures(Q1). Forcases higherprecisionofsupervisedmethods, challengespersistinsce-
suchasstructuralabnormalitiesorblurredtoothcontours, human nariosofinsufficientorinaccuratelyannotatedtrainingdata,under-
expert judgment and intervention are needed to improve segmen- scoringtheongoingneedforaccuratesegmentationonpanoramic
tationquality[20]. Toaddressthis, wedevelopaninteractivetool radiograph[31].
toallowexpertstocorrecttheoutcomesoftheinitialsegmentation.
In this paper, we select appropriate neural network and incor-
Further,differentlevelsofdetailinformationviewsareincorporated
porate a consideration for dental expertise when using Mask R-
to assist experts in screening out high-quality segmentation , and
CNNfortoothsegmentation. Further, weprposeanovelhuman-
expert-specified teeth will be piped into the model for interactive
computerinteractionsystemthatallowsexpertstointeractivelyre-
optimization (Q2). Finally, in order to demonstrate the effective-
finesegmentationoutputs,therebyenhancingtheaccuracyandre-
nessandusabilityofourVisToothinaddressingtheissueoftooth
liabilityofthefinalresults.
segmentation,weconductcasestudyandexpertstudy.
Themajorcontributionsofthispaperarelistedasfollows:
2.2 VisualizationforArtificialIntelligence
• Asetoffeaturemetricsareproposedtoassessthesegmenta- Inthedomainofartificialintelligence,theburgeoningcomplexity
tionaccordingtodentalexpertise. of models necessitates advanced methods for elucidation of their
inner workings. Visualization tools play an instrumental role in
• Anovelvisualanalyticssystemisimplementedtosummarize
this context, aiding in the comprehension of training data, model
and compare the tooth segmentation with different levels of
architecture, and output[32, 33]. A notable contribution in this
details.
field is the OoDAnalyzer[34] by Chen et al., which presents an
• Anewhuman-machinecollaborationworkflowleveragingad- interactivevisualmethodfortheidentificationandexplanationof
vanced machine learning algorithms and human expertise is Out-of-Distribution (OoD) samples. Kandel et al.[35] proposed
implementedtoguaranteetheaccuracyandefficiencyoftooth Profiler, a tool designed to assess quality issues in tabular data.
segmentation. Anomalydetectionmethodsareemployedtodetectandcategorizeddata anomalies. And visual summaries aids evaluation of poten- T2.AssessmentofAutomaticToothSegmentationAccuracy.
tial anomalies and their causes. Liu et al.[36] developed a visual Onceobtainingpreliminaryautomatedoutputs,thesubsequentstep
analyticsapproachusingtimeseriesdatatorepresenttrainingdy- istoexamandmodifypotentiallyincorrectsegmentationmasks.In
namics of Deep Generative Models (DGMs). It includes a novel ordertofacilitatethiscorrectionprocess,itisnecessarytopropose
bluenoiselinesamplingschemeandacreditassignmentalgorithm quantifiablemetricstoassesstheaccuracyofautomatictoothseg-
for improved understanding and diagnosis of DGM training pro- mentation results. Additionally, a clear visual cue should also be
cesses. Cao et al.[37] presented a visual analysis tool AEVis to displayedtoguidetheexpertstoreviewandmanuallycorrect.
explainwhyadversarialexamplesaremisclassified. Thecontribu- T3. Model Optimization through Valuable Instance Sam-
tionanalysisandrichinteractionsfurtherenableuserstotracethe pling. The diversity in different types of teeth presents a chal-
rootcauseofthemisclassificationofadversarialexamples. Wang lenge for the machine learning model. However, manual correc-
et al.[38] presented CNN EXPLAINER, an interactive visualiza- tionscaptureexpertexpertiseontheaccuratedelineationoftooth
tion tool designed for non-experts to learn and examine convolu- boundarieswhichcanserveashigh-qualitylabeleddatatoretrain
tional neural networks. Through smooth transitions across levels theML-model.Thus,itbecomesnecessarytoincorporatevaluable
of abstraction, users can inspect the interplay between operations expertcorrectionsasacomplementtothetrainingsettooptimize
andoutcomes. Mahendranetal.[39]introducedtheDeepVisual- themodelespeciallywhentheinitialsamplesetishardtoencom-
izationToolbox(DeepVis)tovisualizeandinterpretCNNfeatures passallpossiblevariations.
bysynthesizinginputimagesthatmaximallyactivatespecificneu- T4.DevelopmentofanInteractiveToothSegmentationTool.
rons. Selvarajuetal.[40]introducedGrad-CAM,whichhassince Toensuretheeffectivenessofsubsequentwork,itisdeemedcrucial
beenwidelyadoptedforinterpretingCNN-basedmodelsinvarious todevelopaninteractivetoolthatcanimplementaccuratetoothseg-
domains,includingmedicalimagingandnaturallanguageprocess- mentationandwithcontinuousiterativeoptimization. Tothebest
ing. Chenetal.[41]introducedUni-Evaluator,anopen-sourcevi- ofourknowledge,ourworkisthefirstattempttoprovideacombi-
sualanalytictoolformodelevaluationtasksliketargetdetection.It nationofman-machinetoothsegmentationtool.
representspredictionsasprobabilitydistributionsacrosstasks,us-
ingmatrices,tables,andgridsforcomprehensiveevaluationfroma 3.2 SystemOverview
globaltosamplelevel. Humanscanalsomonitorthelearningpro-
Motivatedbytheidentifiedtasks,weproposeavisualizationframe-
cessandevaluatetheeffectivenessofAImodelsatanytimethrough
workenablingexpertstoefficientlyachievehigh-qualitytoothseg-
visualization[32]. Ahnetal.[42]proposedavisualanalyticsystem
mentation on panoramic radiograph. The system pipeline is de-
FairSighttocaptureboththeglobalandinstancelevelfairnesswith
picted in Figure 2. Initially, the Mask R-CNN model is trained
evidenceofpotentialunfairoutcomes.
with a certain amount of manual labeled data, categorizing teeth
Collectively, thesedevelopmentsunderscorethepivotalroleof
intofiveclasses: incisor,canine,1st,2nd,and3rdmolar. Toesti-
visualanalyticsintheinterpretation,evaluation,andrefinementof
matetheoutputsofthemodel,weproposeseveralquantifiablemet-
complex AI models within the scientific community. In contrast,
ricsincludingtoothshape,toothpositionandtoothangle. Concur-
weapplyinteractivevisualanalyticstothedetectionandcorrection
rently, wedeviseaglyph-basedvisualizationschemetorepresent
ofmaskerrorsintheprocessofautomaticsegmentation,aimingto
theseinformation,therebyofferingexpertsacomprehensivesetof
facilitatethehigh-qualityofoutputs.
evaluation criteria(T1). We develop a scatterplot view to provide
anoverviewofrelationshipsamongthetoothsamples,sothatthe
3 TASKANALYSISANDSYSTEMOVERVIEW
possibleinaccurateresultscanbeidentifiedbytheabnormaldistri-
In this section, we provide a summary of analysis tasks(T1-T4) bution(T2). We provide experts with visual interface to show the
identifiedthroughinterviewswithdomainexpertsandsubsequently initialsegmentationofthemodelandinteractivetoolsforerrorcor-
presentthepipelineoftheproposedvisualanalysissystem. rection.Thenthecorrectedhigh-qualitytoothsamples,selectedby
experts,arefedbackintothemodelforadaptiveiterativeoptimiza-
3.1 TaskAnalysis tion(T3). Ultimately,ahuman-machinecollaborativevisualtoolis
Oursystemwasdevelopedthroughacollaborativeeffortinvolving developedforthesegmentationofteeth(T4).
expertsindentalexamination(E1andE2)andanexpertingraph-
icsandvisualization(E3). E1andE2arehighlyexperiencedoral 4 VISTOOTH
andmaxillofacialradiologistseachpossessingover5yearsofex-
We propose a visualization framework, ViSTooth, that integrates
tensive expertise. E3 is a seasoned professor specializing in data
automatic technologies and interactive visualization to support
visual analysis. In the early stages of our collaboration, weekly
human-machine collaboration for accurate tooth segmentation.
meetingswereconductedwiththesethreeexpertstoseekopportu-
Thissectionintroducesfourkeycomponents: datalabeling,tooth
nitiestooptimizetheprocessoftoothsegmentationthroughliter-
segmentationmodel,visualizationdesignandmodeloptimization.
aturereview. Accordingtoexperts,thediversityofteethpresents
significant challenges to current AutoML approaches. To ensure
4.1 DataLabeling
the accuracy of tooth segmentation, further expert judgment and
correctionaredeemednecessary.Consequently,wedelvedintothe Thepanoramicradiographsusedinthisstudywereselectedfrom
designrequirementsofahuman-machinecollaboratesystem.From a patient image database at the hospital. The patients gave their
thesediscussions,wederivedfourkeyanalyticaltasks,summarized informed consent before any panoramic radiographs were taken,
asfollows: and their privacy was protected when using the data for medical
T1. Integration of dental expertise into the segmentation research. The datasetcomprises 521 panoramic radiographs. We
process. General segmentation method only considers the pixel selected300imagesforexpertstomarkgroundtruthsegmentation
features[43]. However, dental expertise like the regularity in the labels randomly, while the remaining 221 images were used as a
physiologicalstructureandarrangementcharacteristicsofteethcan testset. Thisprocesswasunderasupervisionoftwodentists(E1
provide valuable information for segmentation. Hence, the em- andE2)usingataggingtooldevelopedwiththePythonprogram-
ployedfeatureextractionnetworkofmodelshouldbeadeptatiden- minglanguage.Weattendedweeklymeetingswhererelatedissues
tifyingtheintricatestructuresonpanoramicimages[31]. Andthe werediscussedandthelabelswerereviewedtoassurequality. In
workflowshouldalsoincorporateaconsiderationforarrangement theend,the300labeledimageswithgroundtruthsegmentationla-
featureswhendeterminingtoothlabels. bels was divided into a training set(240 images) and a validationFigure2:ThepipelineofVisToothfortoothsegmentationonpanoramicradiograph.
set(60images). The study was approved by the Ethics Commit-
teeofTheFirstAffiliatedHospital,ZhejiangUniversitySchoolof
Medicine.(approvalno.20230785)
4.2 ToothSegmentationModel
Inthispaper,weemloytheMaskR-CNNmodelforteethsegmen-
tation on panoramic radiograph. Mask R-CNN is a two-stage in-
stance segmentation framework, as depicted in Figure 3. Specif-
ically, thefirststageproposescandidatetoothboundingboxesre-
gardlessofcategories. Fistly,thepanoramicradiographisfedinto
thebackbonetoextractfeatures.Thenthefeaturescomposeapyra-
midnetwork(FPN)togeneratecandidateregionswiththepotential
tocontaintoothstructures.SinceMaskR-CNNisaflexibleframe-
work,wetriedtochangethefeatureextractionnetworkinbackbone
tomakethemodelmoresuitableforpanoramicsegmentationtasks, Figure3:TheillustrationofMaskR-CNN.
including ResNet networks with 50, 101 and 152 layers[44] and
VGG16network[45]. AsshowninTable1,WefindthatResNet50
istheoptimalchoiceforpanoramicradiographduetoitsfewerlay- terface of our system, which comprises a control panel and five
ers, which can refrain from overfitting, and its overall IoU score maimviews.
reaches75.14%.
ThesecondstageistermedastheR-CNNstage,whichextracts 4.3.1 SegmentationExplorerComponent
features using RoIAlign[19] for each proposal and performs pro-
Theradiographicfeatureexplorationcomponentcontainstwosub-
posalclassification,boundingboxregressionandmaskpredicting.
views:apanoramicviewandaglyphview.
Thisinvolvescorrespondingeachpixelontheoriginalpanoramic
As shown in Figure 1(B1), the panoramic view visualizes the
radiographwiththefeaturemapandmatchingitwithpresetfixed
toothsegmentationoutcomesgeneratedbythesystem.Itfacilitates
features. Subsequently,themodelconductsmulti-classificationon
adirectcomparativeanalysisforexpertstoassessthecongruence
thesecandidateregions,generatingmaskstocompletethesegmen-
betweenthesegmentedcontoursandgroundtruth.Expertscanad-
tation task. During the training stage, we classified sample teeth
justtheinitialsegmentationmaskbydraggingcontourpoints,en-
intofivecategories: incisors,cuspids,1stand2ndmolars,and3rd
suringacloseralignmentwiththeactualtargets.
molar. Intheprocessofclassification, weguidethemodeltonot
onlyconsidertheimagefeaturesofthesegmentedtargetsbutalso Theglyphviewrepresentsthedetailedfeaturesofsegmentation
introduceheuristicrulesbasedontheorderoftootharrangement. outputs. Inthispaper,weproposethreeessentialmetricsoftooth
Whenimagefeaturesareblurredanddifficulttodiscern,priorityis segmentation including shape, coordinates and center-line angle.
giventothesegmentationcategorydeterminedbythearrangement Subsequently,weemployavisualpromptingapproachtoguideex-
order. pertsinmakingmorenuancedjudgmentsandcorrectionstothese
results.
Firstly, weusetheHUmoment[46,47]astheshapefeatureof
4.3 VisualizationforToothSegmentation
the segmentation mask to characterize individual teeth, which is
Due to the above AutoML segmentaion approach not always be- calculatedasfollows:
ingaccurate, inthissection, wedesignthevisualizationinterface
topresentthesegmentationresultsfromthemodelandtosupport mp,q=∑∑xpyqf(x,y) p,q=0,1,2...... (1)
moredetailedfeatureexploration. Figure1,displaysthevisualin-
x yTable1:Comparisonofevaluationmetricswithdifferentbackbones.
Model Backbone IoU(%) Precision(%) Recall(%) F1-score(%)
MaskR-CNN ResNet-50 75.1 75.7 83.5 79.4
MaskR-CNN ResNet-101 65.3 65.9 73.7 69.6
MaskR-CNN ResNet-152 53.4 53.9 58.1 55.9
MaskR-CNN VGG16 71.2 71.8 81.1 76.2
wheref(x,y)isthepixelintensityvalueatthe(x,y)-coordinate.
Giventhesymmetricalarrangementoftoothsequences,theposi-
tionalattributeisdefinedasthetwo-dimensionalcoordinatesofthe
segmentation mask’s center point subtracted by the absolute val-
uesofthecoordinatesoftheoverallpanoramicradiograph’scenter
point. Andthecenterlineangleofthesegmentationmaskisdeter-
minedbycalculatingtheanglebetweenthemidlineofthemaskand
theverticaldirection.
Wedesigntheglyphtovisualizethemulti-dimensionalfeatures
ofthesegmentationmask(Figure4(B)).ThevaluesofHUmoments
are encoded with a radial bar chart(Figure 4(B-b)). Within the
glyph, we use the metaphor of a dashboard to encode the tooth’s
two-dimensionalcoordinates(Figure4(B-c,B-d))andcenterlinean-
gle(Figure4(B-e)). Tovisuallydemonstratethedifferencesoffea-
tures between the segmentation results and conventional training
samples,wecalculatetheaveragevalueforeachfeature. Thenwe
encodefeaturesclosetotheaveragevalueingray,featuressignif-
icantlyabovetheaveragevalueinblue, andfeaturessignificantly
belowtheaveragevalueinred(Figure4(B-a)).Thedentallegendat
Figure4: Theextractedfeatureexplorationcomponent. Theexpert
thecenteroftheglyphispopulatedwithdistinctcolorsaccording
canstartanalysisfrom(A)theoverviewofthedataset.The(B)feature
totheidentifiedcategories,facilitatingaclearerobservationofthe
glyph,the(C)zoomedviewandthe(D)similarityviewprovidedetailed
toothcategorization(Figure4(B-f)). Expertscaneffortlesslymod- informationforfeatureexploration.
ifytheassignedcategorylabelsbyclickingonthedentallegend.
4.3.2 FeatureExplorerComponent
panoramaslicemapandtheglyphwillbepresentedinpairsinthe
Forthereasonthatautomaticsegmentationalgorithmsrelyonthe
similaritylistandarrangedinorderofdistance.
matching between prior features and image characteristics, satis-
factory segmentation results may not be achieved when there is
4.4 ModelOptimization
prominent variation. In this section, we employ dimensionality
The process begins with loading panoramic radiograph data for
reduction and mapping to obtain the standard range and distribu-
toothsegmentation. Firstly, themodeloutputareprojectedinthe
tion of multi-dimensional features for each category of teeth. By
scatterplot view, enabling experts to quickly discover the abnor-
contrasting newly generated segmentation masks with the sample
malsegmentationmasks.Thezoomedviewandthereferenceview
setdistribution,weidentifysegmentationresultsthatdeviatefrom
show different levels of detail, helping experts to do precise cor-
conventionalpatternsaswhichhasahighprobabilityoferror.
rectionsmanually. Theseexpertcorrections, functioningashigh-
Eachpointinthescatterplotviewrepresentsatoothsample,with
quality labeled data, capture expert input on the accurate delin-
distinctcolorsindicatingdifferentcategories. Themanuallyanno-
eation of tooth boundaries. Once the necessary corrections are
tated training and test sets are represented by points with higher
made, the projection view will update to show the new overview
transparency, whilenewlyloadedtoothsamplesaredifferentiated
ofthecorrectedresults. Thentheexperthastheabilitytochoose
by larger radii and lower transparency. To lay out the points in
several high-quality tooth samples and click ‘train’ in the control
the scatterplot with respect to the feature similarities of the sam-
paneltofeedthecorrectedhigh-qualitylabeleddatabackintothe
ples, we firstly employ the HU moments matrix to extract shape
segmentationmodel. Thisstephelpsthemodellearnfromthecor-
features from individual tooth slices, incorporating positional in-
rected data and improve its performance over time. The evalua-
formationwithintheoriginalpanoramicradiographandcenterline
tion view provides a graphical representation of the optimization
angularofthetoothtoformulateasetofhigh-dimensionalfeature
process,offeringanintuitiveinsightintothemodel’sperformance
vectors. Then, we employ LDA[48] to project the vectors into a
throughout training. And the feedback loop continues as experts
two-dimensionalplane,generatingascatterplot,suchthatthesam-
repeatedlyloaddata, correctmodeloutputs, andcontributetothe
plessharethesimilarfeaturesarecloser. Ingeneraluse,trainsam-
ongoingrefinementofthesegmentationmodel.
plesareshownassolidcircles, newloadedsamplesareshownas
circleswithblackoutlinesandexpert-specifiedsamplesareshown
ascrosses.
5 SYSTEMINTERFACE
Thesimilarityview(Figure4(D))isdesignedtoshowhistorical Wedevelopasetofinteractionstointegrateintelligentmodeland
labeleddatawithhighsimilarity, providinganessentialreference expert knowledge into the process of tooth segmentation. Ini-
forwhethermasksaresuccessfullyidentifiedornot. Whentheex- tially,expertcangainautomatictoothsegmentationbyloadingthe
pertclicksonatoothinthescatterplot,wecalculatethehistorical panoramic radiograph in the control panel. Scatterplot view pro-
labeleddataadjacenttoitsprojectionposition. Subsequently, the vides a compact overview for the standard range and distributionof multi-dimensional features for each tooth category. For more initialsegmentation,andevenaftermanualcorrection,cleardiffer-
detailed features, expert can observe the glyph in zoomed view entiationwasnotachieved. E2explainedtousthatthedistinction
andsimilarsamplesinsimilarityviewbyclickingthecorrespond- betweenindividualteethisnotparticularlyclearduringactualread-
ingscatter. Bycomparingthedissimilarity,expertscanassessthe ing,andtheremaybeconfusionbetweenthecuspidand1stmolar
consistencyoffeaturedistributioninthesegmentationresultswith labels (yellow and red) for the model. Therefore, E2 marked the
realstructures. Whentheresultsofautomaticsegmentationdevi- mixed regions between these two patterns and added them to the
ate significantly from the normal range, further expert judgment training samples in the hope of strengthening the model’s learn-
andcorrectionarenecessary. Expertscanmakecorrectionstothe ing. Cluster B, on the other hand, consistently differentiated into
delineation of tooth boundaries by clicking the anchor points on five major distribution patterns. Figure 6 illustrates examples of
tooth. Whenthecorrectedsegmentationissatisfactory,thescatter- S3segmentationverificationthroughReferenceViewexamination.
plotviewwillupdatetoshowthecorrectedresultsoverview. Then Fromthis,wecanseethatS3hasadouble-rootstructuresimilarto
expertshavetheabilitytoselecthigh-qualitylabeleddatawhichis thereferenceview,butthesignificantcrownlossdeviatesitsshape
consideredexpertfeedbackandcontributestoimprovingtheaccu- featuresfromthenormalcluster. Asthenumberofannotationsin-
racyofthesegmentationresults.Thisiterativefeedbackloophelps creased, we observed the gradual aggregation of similar residual
improvethemodel’sperformanceovertimeasitadaptstothecor- tooth clusters along the edge of S3. This feature is distinct from
rectionsmadebyexperts. thetrainingsamplesetand, therefore, E2waseagertolabelitas
anewsampletoimprovethemodel’srecognitionrateforresidual
6 EVALUATION teeth during segmentation. During the labeling process, E2 com-
Weconductedtwocasestudiesandanexpertstudytodemonstrate mented, ”Using labeled samples to further enhance the model is
theeffectivenessandusabilityofViSToothintoothsegmentation. veryinnovative.Theimprovementininitialsegmentationaccuracy
means we can reduce manual correction.” He also praised the vi-
6.1 CaseStudy sual attractiveness design of the projection view, noting that this
distributionvieweffectivelyconveysthedistributionpatternofseg-
6.1.1 Case1. InteractiveCorrectionInsights
mentation masks and facilitates batch sample selection. Figure 6
WeinvitedE1toutilizeVisToothfordetailedhuman-machinecol- showstheevaluationresultsofthreeretrainingsessions, allowing
laborative segmentation of teeth on 10 panoramic X-ray images, expertstoadd100teethsliceswithcorrectionlabelstothetraining
and asked him to follow the system’s visual cues during the pro- seteachtime.Thelinegraphillustratesthechangeinsegmentation
cess. In the process of the segmentation task, all corrections and resultsbeforeandaftereachretraining,demonstratingtheeffective-
feedbackwererecorded.Initially,thesegmentationmodelachieved nessofoursysteminhigh-qualitytoothsegmentation.Initially,the
anaccuracyof74.91%,whichwasunsatisfactory. ThusE1would IoUscorewas75.14%. Afterthreeroundsoftraining,significant
liketousethesystemtoinspectandrefinethemodeloutputs. Im- improvementwasobserved,withtheIoUscorereaching80.11%.
mediately, E1 identified some abnormal outliers from the scatter
plot view(Figure 5). He first clicked on an outlier to locate the
6.2 ExpertStudy
tooth represented by it, concurrently the similarity view was up-
datedtodisplaydetailedglyphandshowsamplessimilarinheight ViSToothwasdesignedtobeanexpressiveandtaskefficienttool.
totheselectedsample. Uponobservation,E1foundthatonecase Tofurtherevaluatetheeffectivenessofoursystem, weconducted
oftheoutliermightbeattributedtoincompletesegmentation,lead- an expert study involving 2 experts in dental examination and 10
ing to a significant separation between the mask and the regular graduate students (5 males and 5 females) majoring in Medicine.
distribution of that category. Figure 5(A) illustrates how E1 cor- They were all trained to use our system until they were familiar
rectedexamplesofteethS1andS2byexaminingthemorphology with the workflow and proficient in utilizing the system. There-
inthesimilarityview.Typically,thesecondmolarshavetworoots, after,theyweretaskedwiththesegmentationof60panoramicra-
butduetotheproximityofthepixelvaluesbetweentherootand diographs. During the process, we recorded their comments and
the gingival tissue in the S1 and S2 regions, the model struggles theinteractions. Further,weformulatedasetofquestions,which
toaccuratelydifferentiatetoothstructurefromothertissues. And arecloselyrelatedtotheanalyticaltasksoutlinedinSection3.The
theglyphinsimilarityviewsuggeststhatdespiteitsmaskfeatures questionnaire is displayed in Table 2, and participants’ responses
deviating from the second molar and resembling the first molar, canbeobservedinFigure7. Herearesomekeyfindingsfromthe
itscoordinateandangularfeaturescloselymatchthoseofthe2nd analysis:
molarsaspredictedbythemodel. Subsequently, E1attemptedto System Performance. The majority of participants expressed
adjustthecontrastofthepanoramicradiographusingthetoolbarto satisfaction with the accuracy and speed of the preliminary seg-
enhancethedifferentiationbetweenthetargetteethandotherstruc- mentationperformedbytheAutoMLmodel. E1commented,”The
tures,thenmanuallyadjustedthecontourpointstorestoreprecise proposedmodelcaneffectivelysupportpreliminarysegmentation,
positioning.Furthermore,E1alsofoundthatsomecasescharacter- whichalleviateslaboriousandtime-consumingmanualdetection.”
izedbyindividualdifferencescouldleadtooutliers,asdepictedin Statisticalanalysisshowedthat75%ofparticipantsratedtheaccu-
Figure5(B).Here,thepatientexhibitedincompletetoothstructures, racyassatisfactory,while83%weresatisfiedwiththespeed.Anal-
significantlydeviatingfromthetrainingsamples. Suchsituations ysisofthecollectedmetricsindicatedthattheyeffectivelyreflected
bears the potential for erroneous segmentation, requiring manual the quality of the segmentation results, with 80% of participants
assessment. E1highlypraisedtheglyphdesign,”Utilizingfeature agreeingwiththisstatement.
indicatorsasvisualcuestohelpusdetectsegmentationanomalies Visual Design. Over 90% of participants found the interface
forfurthermanualcorrectionisbeneficialintheabsenceofground designtobeintuitiveandeasytounderstand, highlightingtheef-
truthforthenewlyloadedpanoramicimage.” fectivenessofthevisualdesigninfacilitatinguserinteraction. An
overwhelmingmajority(over95%)ofparticipantsagreedthatthe
6.1.2 Case2. IterativeRetrainingOptimization colorchoicesandgraphicalelementsinthesystemcontributedto
Inthesecondcase,weintroducedmorepanoramicimages.E2was detectingsegmentationanomalies,underscoringtheimportanceof
invitedtoperformbatchpanoramicsegmentationandselectsam- visualcuesintheanalysisprocess. E2remarked,“Thevisualde-
plesforfeedbacktothemodelforretraining. Figure6showsthe signofViSToothgreatlyfacilitatestheinterpretationofsegmenta-
projectionchangesaftermanualcorrectionbyexperts. Theresults tionresults,makingiteasiertoidentifyabnormalities.”
indicatethatclusterAexhibitedamixeddistributionpatternduring Interactivity. The interactive features designed for diggingFigure5:(A)displaystheprocessofexpertcorrection.(B)capturesinstanceswhereindividualvariationsleadtoscatteredoutliers.
Table2:Thequestionnaireconsistsoffourparts:thesystemperfor-
mance(Q1-3),thevisualdesign(Q4-6),theinteractivity(Q7-8),and
theoverallsatisfaction(Q9-10).
Q1 I am satisfied with the accuracy of preliminary tooth
segmentationbytheAutoMLmodel.
Q2 Iamsatisfiedwiththespeedoftoothsegmentationby
theAutoMLmodel.
Q3 Themetricsproposedcanreflectthequalityofthetooth
segmentationresults.
Q4 Theinterfacedesignisintuitiveandeasytounderstand.
Q5 Thecolorchoicesandgraphicalelementsinthesystem
contributetodetectingsegmentationanomalies.
Figure6: ClusterAexhibitedamixeddistributionpattern. ClusterB
Q6 Thelayoutofthesystem’sinterfacecontributestomy
consistentlydifferentiatedintofivemajordistributionpatterns.
easeofunderstandingandusingitsfeatures.
Q7 Iamsatisfiedwiththeinteractivefeaturedesignfordig-
deeperandgainingmoreinsightsintothesegmentationresultswere ging deeper and gaining more insights into the tooth
well-received,with83%ofparticipantsexpressingsatisfactionwith segmentationresults.
this aspect. Similarly, the interactive feature design for adjust-
Q8 Iamsatisfiedwiththeprovidedtoolsandcontrolsfor
ingsegmentationresultsgarneredpositivefeedback, with75%of
adjustingthetoothsegmentationresults.
participants reporting satisfaction. One graduate student noted,
“The interactive features provide flexibility and control, allowing Q9 ViSToothiseasytouse.
forfine-tuningofsegmentationresultsaccordingtoindividualpref-
Q10 I am willing to continue using this system in clinical
erences.”
practice.
OverallSatisfaction.Asignificantportionofparticipantsfound
ViSToothtobeeasytouse,indicatinghighoverallsatisfactionwith
thesystem’susability. Impressively,75%ofparticipantsexpressed
willingnesstocontinueusingViSToothintheirfutureclinicalprac-
tice, reflecting a strong endorsement of the system’s utility and
effectiveness. However, aminorityofparticipantsexpressedcon-
cernsaboutmasteringViSTooth’sadvancedfeatures,suggestingthe
needforadditionaltrainingresourcesoruserguides.
Thesestatisticalfindingsproviderobustevidencesupportingthe
positivereceptionofViSToothamongusers,affirmingitseffective-
ness as an expressive and task-efficient tool for panoramic radio-
graphsegmentation.
7 DISCUSSION
Model performance. Automation of tooth segmentation is con-
sidered the first and foundational step in the development of AI
Figure7:Thefeedbackoftheexpertinterviews.
systemsforadjuvanttherapyindentistry. Therefore,thisfirststep
should be as accurate as possible. We focus on the revolutionaryimpactofLargeLanguageModels(LLMs),suchasChatGPT[49], mentationbetweenmean, medianandotsuthresholdfordentalage
SAM[50],haspermeatedvariousindustries.Webelievethatthead- assessment.pages353–356,2014.2
vancedlanguageunderstanding,contextualinterpretationandmore [8] MuhamadRizalMohamedRazali,NazatulSabariahAhmad,Rozita
nuancedfeaturerecognitionabilitiesofLLMscanenhancetheseg- Hassan, ZulkiflyMohdZaki, andWaidahIsmail. Sobelandcanny
mentationprocess. edges segmentations for the dental age assessment. In 2014 Inter-
Feature indicators. Automatic evaluation is crucial in effi- nationalConferenceonComputerAssistedSysteminHealth, pages
ciently guiding experts to improve segmentation quality. Starting 62–66.IEEE,2014.2
[9] NSenthilkumaran. Fuzzylogicapproachtoedgedetectionfordental
fromthecommoncharacteristicsofteeth,thispaperextractstooth
x-rayimagesegmentation.InternationalJournalofComputerScience
angles, positions, andshapestoscreenoutresultswithhigherer-
andInformationTechnologies,3(5):5236–5238,2012.2
rorprobabilities. However, personalizeddifferencesamongteeth,
[10] PengchengLi,YangLiu,ZhimingCui,FengYang,YueZhao,Chun-
suchastheproximitybetweenadjacentteeth,treatmentmarks,and
fengLian, andChenqiangGao. Semanticgraphattentionwithex-
developmentalstages,canaffectthisassessment. Therefore,infu-
plicit anatomical association modeling for tooth segmentation from
turework,weplantoexploremoreextensivelyhowtoutilizericher
cbctimages. IEEETransactionsonMedicalImaging,41(11):3116–
featurestocharacterizethequalityofsegmentationresults,suchas
3127,2022.2
internaldensitydistribution,texturefeatures,andedgefeaturesof [11] GilSilva,LucianoOliveira,andMatheusPithon.Automaticsegment-
teeth. ing teeth in x-ray images: Trends, a novel data set, benchmarking
Automated Diagnosis Tooth segmentation is the most widely andfutureperspectives. ExpertSystemswithApplications,107:15–
usedprocessingtechniquetoanalyzepanoramicradiographs.With 31,2018.2
preciselysegmentedtoothstructures,furtherapplicationscanbede- [12] SenbaoHou,TaoZhou,YuncanLiu,PeiDang,HuilingLu,andHong-
velopedincomputer-aideddentaldiseases,suchasdiagnosis,tooth binShi.Teethu-net:Asegmentationmodelofdentalpanoramicx-ray
alignment assessment, orthodontic optimization, etc. This work imagesforcontextsemanticsandcontrastenhancement. Computers
formsthebasisofourfurtherdevelopmentsofAI-driventoolsfor inBiologyandMedicine,152:106296,2023.2
preciseandautomateddiagnosisofvariousdentaldiseases[51,52, [13] Thorbjørn Louring Koch, Mathias Perslev, Christian Igel, and
53].Byleveragingthesedevelopments,wehopetofosterefficiency SamiSebastianBrandt. Accuratesegmentationofdentalpanoramic
andaccuracyindentalhealthcaredelivery. radiographswithu-nets.pages15–19,2019.2
[14] HuChen,KailaiZhang,PeijunLyu,HongLi,LudanZhang,JiWu,
andChin-HuiLee. Adeeplearningapproachtoautomaticteethde-
8 CONCLUSION
tectionandnumberingbasedonobjectdetectionindentalperiapical
Inthispaper,wepresentViSToothforaccuratetoothsegmentation films.Scientificreports,9(1):3840,2019.2
throughhuman-machinecollaboration.Basedondomainexpertise, [15] ChanggyunKim, DonghyunKim, HoGulJeong, Suk-JaYoon, and
themodelinViSToothautomaticallypreliminarytoothsegmenta- Sekyoung Youm. Automatic tooth detection and numbering using
tion. Then the visual interface provides various supporting infor- a combination of a cnn and heuristic algorithm. Applied Sciences,
mationtohelpexpertstolearnthesegmentationresultsanddetect 10(16):5624,2020.2
anomalies. Richhumancomputerinteractionsareintegratedtoen- [16] BernardoSilva,La´ısPinheiro,LucianoOliveira,andMatheusPithon.
ablehigherqualitycorrecteddataanditerativeoptimizationofthe Astudyontoothsegmentationandnumberingusingend-to-enddeep
segmentationmodel.Twocasestudiesandanexpertstudyhighlight neuralnetworks.pages164–171,2020.2
[17] KroisJ.ArtificialSchwendickeF,SamekW.Intelligenceindentistry:
theeffectivenessofourtoolinstreamliningthetoothsegmentation
Chancesandchallenges.JournalofDentalResearch,pages769–774,
processandminimizingthemanualeffortrequiredforaccuratere-
2020.2
sults. Inthefuturework,wehopetoimprovetheperformanceof
[18] Andre´FerreiraLeite,AdriaanVanGerven,HolgerWillems,Thomas
automaticsegmentationtofurtherreducetheeffortofmanualcor-
Beznik, Pierre Lahoud, Hugo Gaeˆta-Araujo, Myrthel Vranckx, and
rection,leveragericherfeaturesforautomaticevaluation,aswellas
ReinhildeJacobs. Artificialintelligence-drivennoveltoolfortooth
integrate tooth segmentation into disease diagnosis and treatment
detectionandsegmentationonpanoramicradiographs. Clinicaloral
applications. investigations,25:2257–2267,2021.2
[19] KaimingHe,GeorgiaGkioxari,PiotrDolla´r,andRossGirshick.Mask
REFERENCES r-cnn.pages2980–2988,2017.2,4
[1] Vanessa Machado, Lu´ıs Proenc¸a, Mariana Morgado, Jose´ Joa˜o [20] InkyuShin,Dong-JinKim,Jae-WonCho,SanghyunWoo,KwanYong
Mendes, andJoa˜oBotelho. Accuracyofpanoramicradiographfor Park,andInSoKweon. Labor:Labelingonlyifrequiredfordomain
diagnosingperiodontitiscomparingtoclinicalexamination. Journal adaptivesemanticsegmentation.CoRR,abs/2108.05570,2021.2
ofClinicalMedicine,9(7),2020.2 [21] ChintanK.ModiandNiravP.Desai. Asimpleandnovelalgorithm
[2] ShaofengWang,ShuangLiang,QiaoChang,LiZhang,BeiwenGong, forautomaticselectionofroifordentalradiographsegmentation. In
201124thCanadianConferenceonElectricalandComputerEngi-
YuxingBai,FeifeiZuo,YajieWang,XianjuXie,andYuGu.Stsn-net:
Simultaneoustoothsegmentationandnumberingmethodincrowded
neering(CCECE),pages000504–000507,2011.2
environmentswithdeeplearning.Diagnostics,14(5),2024.2 [22] MutasemKAlsmadi. Ahybridfuzzyc-meansandneutrosophicfor
[3] JieYang,YuchenXie,LinLiu,BinXia,ZhanqiangCao,andChuan-
jawlesionssegmentation.AinShamsEngineeringJournal,9(4):697–
binGuo. Automateddentalimageanalysisbydeeplearningonsmall 706,2018.2
dataset.pages492–497,2018.2 [23] Mosaddik Hasan, Waidah Binti Ismail, Rozita Hassan, and Atsuo
[4] Acomprehensivereviewofrecentadvancesinartificialintelligence Yoshitaka. Automatic segmentation of jaw from panoramic dental
fordentistrye-health.2023.2 x-ray images using gvf snakes. 2016 World Automation Congress
[5] Developingdeeplearningmethodsforclassificationofteethindental
(WAC),pages1–6,2016.2
panoramicradiography.2023.2 [24] HuiLi,GuoxiaSun,HuiqiangSun,andW.Liu.Watershedalgorithm
[6] RarasmayaIndraswari,AgusZainalArifin,DiniAdniNavastara,and based on morphology for dental x-ray images segmentation. 2012
NaserJawas.Teethsegmentationondentalpanoramicradiographsus- IEEE 11th International Conference on Signal Processing, 2:877–
ingdecimation-freedirectionalfilterbankthresholdingandmultistage 880,2012.2
adaptivethresholding. In2015InternationalConferenceonInforma- [25] ArnaFariza,AgusZainalArifin,EhaRenwiAstuti,andTakioKurita.
tion&CommunicationTechnologyandSystems(ICTS),pages49–54, Segmentingtoothcomponentsindentalx-rayimagesusinggaussian
2015.2 kernel-basedconditionalspatialfuzzyc-meansclusteringalgorithm.
[7] MuhamadRizalMohamedrazali,NazatulSabariahAhmad,Zulkifly
InternationalJournalofIntelligentEngineeringandSystems,2019.2
MohdZaki, andWaidahIsmail. Regionofadaptivethresholdseg- [26] GilJader,JeffersonFontineli,MarcoRuiz,KalyfAbdalla,MatheusPithon,andLucianoOliveira. Deepinstancesegmentationofteethin tional networks for large-scale image recognition. arXiv preprint
panoramicx-rayimages.pages400–407,2018.2 arXiv:1409.1556,2014.4
[27] A.AlmalkiandL.Latecki.Self-supervisedlearningwithmaskedim- [46] Ming-KueiHu.Visualpatternrecognitionbymomentinvariants.IRE
age modeling for teeth numbering, detection of dental restorations, transactionsoninformationtheory,8(2):179–187,1962.4
and instance segmentation in dental panoramic radiographs. pages [47] FrederikJ.S.DoerrandAlastairJ.Florence. Amicro-xrtimageanal-
5583–5592,jan2023.2 ysis and machine learning methodology for the characterisation of
[28] KailaiZhang, JiWu, HuChen, andPeijunLyu. Aneffectiveteeth multi-particulatecapsuleformulations.InternationalJournalofPhar-
recognitionmethodusinglabeltreewithcascadenetworkstructure. maceutics:X,2:100041,2020.4
Computerizedmedicalimagingandgraphics: theofficialjournalof [48] DavidMBlei,AndrewYNg,andMichaelIJordan. Latentdirichlet
theComputerizedMedicalImagingSociety,68:61–70,2018.2 allocation. JournalofmachineLearningresearch,3(Jan):993–1022,
[29] SerdarHelliandAndac¸ Hamamcı. Toothinstancesegmentationon 2003.5
panoramic dental radiographs using u-nets and morphological pro- [49] OpenAI.Introducingchatgpt.8
cessing. Du¨zceU¨niversitesiBilimveTeknolojiDergisi,10(1):39–50, [50] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe
2022.2 Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexan-
[30] Dmitry V Tuzoff, Lyudmila N Tuzova, Michael M Bornstein, derCBerg,Wan-YenLo,etal.Segmentanything.pages4015–4026,
Alexey S Krasnov, Max A Kharchenko, Sergey I Nikolenko, 2023.8
MikhailMSveshnikov, andGeorgiyBBednenko. Toothdetection [51] Andree´ FerreiraLeite,KarladeFariaVasconcelos,HolgerWillems,
andnumberinginpanoramicradiographsusingconvolutionalneural andReinhildeJacobs.Radiomicsandmachinelearninginoralhealth-
networks.DentomaxillofacialRadiology,48(4):20180051,2019.2 care.PROTEOMICS–ClinicalApplications,14(3):1900040,2020.8
[31] SuvarnaBhat,GajananKBirajdar,andMukeshDPatil. Acompre- [52] Burak Dayı, Hu¨seyin U¨zen, ˙Ipek Balıkc¸ı C¸ic¸ek, and S¸uayip Burak
hensivesurveyofdeeplearningalgorithmsandapplicationsindental Duman. Anoveldeeplearning-basedapproachforsegmentationof
radiographanalysis.HealthcareAnalytics,page100282,2023.2,3 differenttypecarieslesionsonpanoramicradiographs. Diagnostics,
[32] Xumeng Wang, Ziliang Wu, Wenqi Huang, Wei Yating, Zhaosong 13(2):202,2023.8
Huang,MingliangXu,andWeiChen. Vis+ai: integratingvisualiza- [53] EsraSivari,GulerBurcuSenirkentli,ErkanBostanci,MehmetSerdar
tionwithartificialintelligenceforefficientdataanalysis. Frontiersof Guzel,KorayAcici,andTuncAsuroglu. Deeplearningindiagnosis
ComputerScience,17,062023.2,3 ofdentalanomaliesanddiseases: Asystematicreview. Diagnostics,
[33] WenjingDai,MengWang,ZhibinNiu,andJiawanZhang. Chartde- 13(15):2512,2023.8
coder:Generatingtextualandnumericinformationfromchartimages
automatically. JournalofVisualLanguages&Computing,48:101–
109,2018.2
[34] ChangjianChen,JunYuan,YafengLu,YangLiu,HangSu,Songtao
Yuan, andShixiaLiu. Oodanalyzer: Interactiveanalysisofout-of-
distributionsamples. IEEETransactionsonVisualizationandCom-
puterGraphics,27(7):3335–3349,jul2021.2
[35] SeanKandel, RaviParikh, AndreasPaepcke, JosephMHellerstein,
andJeffreyHeer. Profiler: Integratedstatisticalanalysisandvisual-
izationfordataqualityassessment.pages547–554,2012.2
[36] MengchenLiu,JiaxinShi,KeleiCao,JunZhu,andShixiaLiu. Ana-
lyzingthetrainingprocessesofdeepgenerativemodels. IEEEtrans-
actionsonvisualizationandcomputergraphics,24(1):77–87,2017.
3
[37] KeleiCao,MengchenLiu,HangSu,JingWu,JunZhu,andShixia
Liu. Analyzingthenoiserobustnessofdeepneuralnetworks. IEEE
TransactionsonVisualizationandComputerGraphics,27(7):3289–
3304,2020.3
[38] ZijieJ.Wang,RobertTurko,OmarShaikh,HaekyuPark,NilakshDas,
FredHohman,MinsukKahng,andDuenHorngPoloChau. Cnnex-
plainer:Learningconvolutionalneuralnetworkswithinteractivevisu-
alization. IEEETransactionsonVisualizationandComputerGraph-
ics,27(2):1396–1406,2021.3
[39] AravindhMahendranandAndreaVedaldi.Understandingdeepimage
representationsbyinvertingthem.pages5188–5196,2015.3
[40] Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ra-
makrishnaVedantam,DeviParikh,andDhruvBatra. Grad-cam: Vi-
sualexplanationsfromdeepnetworksviagradient-basedlocalization.
pages618–626,2017.3
[41] Changjian Chen, Yukai Guo, Fengyuan Tian, Shilong Liu, Weikai
Yang, Zhaowei Wang, Jing Wu, Hang Su, Hanspeter Pfister, and
ShixiaLiu. Aunifiedinteractivemodelevaluationforclassification,
objectdetection,andinstancesegmentationincomputervision.IEEE
TransactionsonVisualizationandComputerGraphics,2023.3
[42] YongsuAhnandYu-RuLin. Fairsight: Visualanalyticsforfairness
indecisionmaking.IEEEtransactionsonvisualizationandcomputer
graphics,26(1):1086–1095,2019.3
[43] Maaz Ansari, Surendra Bhosale, and Archana Choudhary. Seman-
ticsegmentationusingconvolutionalneuralnetworks. 10:31–34,06
2023.3
[44] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep
residuallearningforimagerecognition.pages770–778,2016.4
[45] Karen Simonyan and Andrew Zisserman. Very deep convolu-