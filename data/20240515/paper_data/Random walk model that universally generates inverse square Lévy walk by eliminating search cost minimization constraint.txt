1
Random walk model that universally generates inverse
square Lévy walk by eliminating search cost minimization
constraint
Shuji Shinoharaa,*, Daiki Moritaa, Hayato Hiraia, Ryosuke Kuribayashia, Nobuhito Manomeb,c, Toru
Moriyamad, Hiroshi Okamotob, Yoshihiro Nakajimae, Pegio-Yukio Gunjif, and Ung-il Chungb
a School of Science and Engineering, Tokyo Denki University, Saitama, Japan
b Department of Bioengineering, Graduate School of Engineering, The University of Tokyo, Tokyo, Japan
c Department of Research and Development, SoftBank Robotics Group Corp., Tokyo, Japan
d Faculty of Textile Science, Shinshu University, Ueda, Japan
e Graduate School of Economics, Osaka City University, Osaka, Japan
f Department of Intermedia Art and Science, School of Fundamental Science and Technology, Waseda
University, Tokyo, Japan
* Corresponding author
E-mail: s.shinohara@mail.dendai.ac.jp
Postal address: School of Science and Engineering, Tokyo Denki University, Ishizaka, Hatoyama-machi,
Hiki-gun, Saitama 350-0394, Japan
Keywords
Lévy walk, Cauchy walk, Brownian walk, power-law distribution, search cost minimization2
Abstract
The Lévy walk, a type of random walk characterized by linear step lengths that follow a power-law
distribution, is observed in the migratory behaviors of various organisms, ranging from bacteria to humans.
Notably, Lévy walks with power exponents close to two are frequently observed, though their underlying
causes remain elusive. This study introduces a simplified, abstract random walk model designed to produce
inverse square Lévy walks, also known as Cauchy walks and explores the conditions that facilitate these
phenomena. In our model, agents move toward a randomly selected destination in multi-dimensional space,
and their movement strategy is parameterized by the extent to which they pursue the shortest path. When
the search cost is proportional to the distance traveled, this parameter effectively reflects the emphasis on
minimizing search costs. Our findings reveal that strict adherence to this cost minimization constraint
results in a Brownian walk pattern. However, removing this constraint transitions the movement to an
inverse square Lévy walk. Therefore, by modulating the prioritization of search costs, our model can
seamlessly alternate between Brownian and Cauchy walk dynamics. This model has the potential to be
utilized for exploring the parameter space of an optimization problem.
I. INTRODUCTION
Lévy walks have been observed in the migratory behaviors of organisms across a range of scales, from
bacteria and T cells to humans [1][2][3][4][5]. These walks, a specialized type of random walk, exhibit step
lengths l that follow a power-law distribution P(l)=al−µ,1<µ≤3 , in contrast to the exponentially
distributed step lengths of the Brownian walk (where the frequency of step length l is characterized by an
exponential distribution P(l)=λe−λl ). Lévy walks are particularly noted for their occasional very long
linear movements. Frequently, Lévy walks with exponents close to two have been documented in various
organisms, sparking interest in the reasons behind these patterns [1][6][7][8][9][10][11]. Such walks, when
the exponent is two, are also known as Cauchy walks. The Lévy flight foraging hypothesis (LFFH)3
[12][13] suggests that under conditions where food is scarce and randomly dispersed, and predators lack
any memory of food locations, Cauchy walks represent the most efficient foraging strategy and offer
evolutionary benefits [14]. Historically, it has been accepted that search efficiency peaks for inverse square
Lévy walks with an exponent of two as per the LFFH [15]. However, recent studies challenge this
assumption, showing that Cauchy walks only achieve maximum search efficiency under specific conditions
in multi-dimensional spaces [16]. Conversely, research by Guinard and Korman has demonstrated that an
intermittent Cauchy walk becomes the optimal search strategy in finite two-dimensional domains,
particularly when the objective is to quickly locate targets of any size [17]. The ongoing debates continue
to explore the natural conditions and search methodologies that render the Cauchy walk optimal.
Although Lévy walks have traditionally been linked to the execution of an optimal search strategy for
sparsely and randomly distributed resources, this interpretation has not been universally accepted
[18][19][20]. Offering a different perspective from the LFFH, Abe proposed that the functional advantages
of Lévy walks stem from the critical phenomena within the system, demonstrating that Lévy walks emerge
near a critical point between stable synchronous and unstable asynchronous states [21]. This occurrence is
significant because, near the critical point, the range of inputs from which information can be discriminated
is broader, providing organisms the flexibility to alternate between searching for nearby resources and
venturing toward new, distant locations based on the received inputs. In Abe's model, while Lévy walks
appear near the critical point, they do not conform to a Cauchy walk with an exponent of two. Conversely,
Sakiyama developed an algorithm that effectively generates Cauchy walks through the decision-making
process of a single walker [10].
As highlighted in the LFFH, Lévy walks are not universally applicable across all environments or
conditions. Humphries et al. found that Lévy behavior is associated with environments where prey is sparse,
whereas Brownian movements correlate with areas where prey is abundant [4]. Similarly, de Jager et al.
observed that Brownian motion arises from frequent interactions among organisms in densely populated
environments; they also noted that in controlled experiments adjusting for population density, the4
movement patterns of mussels transitioned from Lévy to Brownian motion as density increased [22].
Additionally, Huda et al. demonstrated that metastatic cells exhibit Lévy walks, whereas non-metastatic
cancer cells engage in simple diffusive movements [11]. Huo et al. reported that the movements of
Escherichia coli cells are super diffusive, aligning with Lévy walk behavior. In contrast, they observed that
mutant cells lacking chemotaxis signaling noise displayed normal diffusive trajectories [23]. From these
observations, they concluded that Lévy walks stem from the noise associated with chemotaxis signaling.
The primary aim of this study is to develop a straightforward, abstract random walk model that
consistently produces Cauchy walks and to identify the specific conditions under which these walks appear.
Consider an agent navigating toward a destination in two-dimensional space. While this study focuses on
models in multi-dimensional space, for simplicity, a two-dimensional model will be used in the following
description. We introduce a function z, which depends on the distance from the agent's current position to
the destination and increases in value as this distance decreases. By implementing this function, the agent's
original goal of merely approaching the destination is transformed into the objective of maximizing z. The
agent aims to shift the position (x, y) to increase z by a small amount ∆z. The task here is to obtain ∆x and
∆y such that ∆z = z(x+∆x,y+∆y)−z(x,y). The amount of movement of x required to realize the
∂x
objective can be approximated as ∆x≈∆z using partial differentiation. Similarly, the amount of
∂z
∂y
movement of y can be approximated as ∆y ≈∆z . Although only an approximation, increasing z by ∆z
∂z
can be realized by moving only one of x or y, or by moving both x and y in any allocation. In other words,
the purpose of increasing z to z+∆z can be achieved in multiple ways and the way cannot be uniquely
determined.
In this study, we analyzed the behavior of two cases: a strategy that allocates the amount of modification
∂x ∂y
by β to 1−β ratio in both the x- and y-directions as ∆x≈β∆z and ∆y ≈( 1−β)∆z , respectively,
∂z ∂z5
where 0≤β≤1, and a strategy that determines the allocation such that movement l = (∆x)2 +(∆y)2 is
minimized. The first strategy can be classified as a non-minimum displacement strategy, as it does not aim
to minimize the amount of movement. Conversely, the second strategy is a minimum displacement strategy,
focusing on reducing movement as much as possible.
Naturally, the movement length l in the non-minimum strategy is greater than in the minimum strategy.
Our analysis indicates that when the non-minimum strategy is used, the frequency distribution of
movement l follows a power-law with an exponent of two, characteristic of a Cauchy walk. In contrast,
employing the minimum strategy results in a Brownian walk. Therefore, the decision to minimize or not
minimize movement significantly influences a Brownian and Lévy walk emerges.
II. METHODS
2.1 A random walk model
D
D
R Xnext
r
2
∆X =αR
∆x
2
r ∆x
X 1 X 1
(a) (b)
Figure 1. (a) Agent tries to approach destination D from its current position X. (b) EMA is an
algorithm that moves X close to D.
This paper deals with an agent performing a random walk in a multi-dimensional space. Let us denote the
agent's current position vector as X
=(
x ,,x,,x
)T
and destination vector
asD=(
d ,,d ,,d
)T
.
1 i N 1 i N
The difference vector between D and X is denoted by6
R= D−X =( d −x ,,d −x,,d −x )T =( r,,r,,r )T . The norm of the vector is denoted by
1 1 i i N N 1 i N
r = R = ∑N ( r)2 (Fig. 1(a)).
i=1 i
D is determined randomly each time. The distance r from the agent to the destination is assumed to be
randomly sampled from some distribution P(r) prepared in advance. The position of the agent at the next
time is X , and the movement vector is X −X =∆X =(∆x ,,∆x,,∆x )T . The step length is
next next 1 i N
defined as l = ∆X = ∑N (∆x )2 .
i=1 i
The simplest random walk model would be to assume that destination D is the agent's position X at
next
the next time, i.e., X = D= X +R . In this case, the step length will necessarily be l =r , and the
next
distribution of step lengths P(l) will be the same as for P(r).
We model an agent that attempts to approach destination D rather than moves directly to it. The simplest
algorithm for approaching D is the exponential moving average (EMA), which is generally used in online
learning algorithms such as the expectation-maximization algorithm [24] and learning vector quantization
[25]. EMA is defined as follows:
X =(1−α)X +αD= X +α(D−X)= X +αR= X +∆X . (1)
next
Here, 0≤α≤1 is the discount rate.
The random walk model that directly reaches D corresponds to the case where α=1 in EMA. From the
formula (1), the step length of the EMA agent is l = ∆X =αr (Fig. 1(b)). Therefore, P(l) is the same as
P(r) in the EMA agent. For example, if P(r)=λe−λr , then l also follows the exponential distribution
P( l)=
λ e−(λ α)
l
.
α
As illustrated in Fig. 1(b), EMA employs the minimum displacement strategy. Throughout this paper,
agents utilizing this strategy, similar to EMA, will be termed Min agents, while those adopting the non-7
minimum displacement strategy will be referred to as non-Min agents.
We introduce a function z which calculates the input as the distance from the agent's current position to
the destination, outputting a higher value as this distance decreases.
 ∑N ( x −d )2   ∑N ( r)2   r2 
z =exp− i=1 i i =exp− i=1 i =exp−  (2)
 2Σ   2Σ   2Σ
   
( )
Here 0< z ≤1 and the height of the top z d ,,d ,,d is 1. Σ>0 is a parameter that represents the
1 i N
spread of z as well as the variance of the normal distribution. By introducing z, the objective of approaching
D is replaced by the objective of increasing z. In other words, z can be said to be a function that expresses
the degree of satisfaction for agents who want to get closer to D. In this paper, Σ is set so that r2 2Σ to
 r2  r2
simplify later analysis. By setting Σ in this way, it is possible to approximate that z =exp− ≈1−
 2Σ 2Σ
using the Maclaurin expansion.
Define the movement vector ∆X when the non-Min agent attempts to increase z by ∆z as follows.
∂x
∆x =β∆z i (3)
i i ∂z
β for the non-Min agent was set randomly, where β satisfies the conditions 0≤β ≤1 and ∑N β =1.
i i i i=1 i
∆z is the difference between the top and current height, defined as
∆z =1−z( x ,,x,,x ) . (4)
1 i N
The movement vector of the Min agent can be defined using the partial differential form as follows:
∂z
∆x =α . (5)
i ∂x
i
Here 0≤α≤1.
∆z can be approximated as follows.8
∂z
∆z
≈∑N
∆x
j=1 j ∂x
j
∂z ∂z
=∑N
α (6)
j=1 ∂x ∂x
j j
2
 ∂z 
=α∑N
 
j=1∂x 
 
j
∆z
That is, α≈ , and the amount of movement required to increase z by ∆z is expressed by
2
 ∂z 
∑N
 
j=1∂x 
 
j
∂z
∆x =α
i ∂x
i
≈
∆z ∂z
. (7)
∑N  ∂z 2 ∂x i
 
j=1∂x 
 
j
Compared to the non-Min agent's movement expressed in formula (3), β is expressed by
i
2
 ∂z 
 
∂x

β ≈ i . (8)
i 2
 ∂z 
∑N
 
j=1∂x 
 
j
Thus, the Min agent corresponds to the special case where β is given by formula (8) in the non-Min agent.
i
 r2  r2 ∂z r r2
When r2 2Σ, we can approximate z =exp− ≈1− , so ≈ i , ∆z =1−z ≈ .
 2Σ 2Σ ∂x Σ 2Σ
i
r2
Then, from formula (8), β ≈ i . The step length of the Min agent is expressed as follows using formula
i r2
(3).9
l = ∑N (∆x )2
i=1 i
 ∂x 2
= ∑N β∆z i

i=1 i ∂z 
(9)
2
r2 r2 Σ
≈ ∑N  i 
i=1 r2 2Σ r 
i
r
=
2
In other words, the Min agent corresponds to the EMA in the α=0.5 case.
Next, we propose the following general model that continuously connects non-Min agents and Min agents.
∂x
∆x =η∆z i (10)
i i ∂z
γ
 2
 ∂z 
β1−γ  
i ∂x  
 i 
η = (11)
i γ
 2
 ∂z 
∑N β1−γ  
j=1 j ∂x  
 
 j 
Here 0≤γ≤1, γ=1 corresponds to the Min agent and γ=0 corresponds to the non-Min agent. In other
words, γ can be regarded as the intensity of attempts to follow the shortest path. If we consider the search
cost to be proportional to the distance traveled, we can think of γ as the degree to which the search cost is
prioritized.
r2 ∂z rz r r2
By using the approximation formulas z ≈1− , = i ≈ i and ∆z =1−z ≈ , formulas (10) and (11)
2Σ ∂x Σ Σ 2Σ
i
can be specifically written down as follows.
Σ
∆x =η( 1−z)
i i rz
i
(12)
r2
≈η
i 2r
i10
β1−γ( r2)γ
η = i i (13)
i ∑d β1−γ( r2)γ
j=1 j j
The agent has the freedom to set the direction of each axis, resulting in each axis being randomly set each
time. Let us denote the N-dimensional standard basis as { e ,,e,,e }. Here e represents an N-
1 i N i
dimensional fundamental vector where the i-th element is 1 and all other elements are 0.
Initially, a new N-dimensional orthonormal system, { e' ,,e' ,,e' }, is generated using the Gram-
1 i N
Schmidt orthogonalization method. In this context, a relationship is established between the difference
vector
R=(
r,,r,,r
)T
in the standard basis and the difference vector
R'=(
r' ,r' ,,r'
)T
in the
1 i N 1 2 N
new orthonormal system.
(
e' e' e'
)(
r' ,,r' ,,r'
)T =(
e e e
)(
r,,r,,r
)T
(14)
1 i N 1 i N 1 i N 1 i N
( )
If the transformation matrix between the two orthogonal systems is A= a and
ij
( e' e' e' )=( e e e ) A, then A=( e e e )−1( e' e' e' ) .
1 i N 1 i N 1 i N 1 i N
For the standard basis, ( e e e ) and ( e e e )−1 are the identity matrices, and hence,
1 i N 1 i N
A=( e' e' e' ). From formula (14), it can be observed that the relationship between AR'= R and
1 i N
R'= A−1R can be established.
The specific procedure for calculating the movement vector is described below. Initially, a new
destination vector D and a new N-dimensional orthonormal system are generated. Next, using the
transformation matrix R'= A−1R, the difference vector in the standard basis is converted to the difference
vector in the new orthonormal system. Subsequently, formulas (12) and (13) are employed to derive the
movement vector ∆X '=(∆x' ,,∆x' ,,∆x' )T in the new orthonormal system. Next, ∆X = A∆X ' is
1 i N
utilized to return ∆X ' to the movement vector ∆X in the standard basis. Finally, the agent’s current
position is updated to X +∆X . This process is repeated iteratively.11
(a) (b)
Figure 2. Examples of destination when agent's current position is at origin. Direction of
destination is randomly determined. (a) Exponential type. Distance r to destination is sampled
from exponential distribution P(r)=e−r . (b) Uniform type. r is sampled from uniform
[ ]
distribution in range of 0,2 .
2.2 Simulation setting
This section outlines the agent simulation setup. The destination D is randomly generated for each
time step. We employ two different methods for generating D, which vary according to the distance r from
the agent to the destination. In the first type, r is sampled from the exponential distribution of P(r)=λe−λr.
We put λ=1 in this paper. This type of generative method is called the Exponential type. In the second
type, r is sampled randomly from a uniform distribution in the range of [ 0,r ]. In this paper, we put
max
r =2. This type of generative method is called the Uniform type. The average value of P(r) for both
max
types is 1. An example of destination generation for both types with the agent's current position as the
origin is shown in Fig. 2.
β for the non-Min agent was set randomly, where β satisfies the conditions 0≤β ≤1 and
i i i
∑N
β =1.
i=1 i12
Three agents with γ=0.0, γ=0.3, and γ=1.0 were prepared, corresponding to the non-Min agent when
γ=0.0 and the Min agent when γ=1.0, respectively. Simulations were conducted on these agents using
the two destination generation methods previously described. The simulation period was set to 100000
steps.
III. RESULTS
3.1 Simulation results13
(a) (b)
(c)
Figure 3. Movement trajectory of each agent in Exponential type. (a) γ=0.0, (b) γ=0.3, and (c)
γ=1.0.
For clarity, this section presents simulation results in a two-dimensional space. Figures 3 and 4 depict the
movement trajectories of the agents for Exponential and Uniform types, respectively. It is important to note
that the axis scales vary significantly between the two figures.14
(a) (b)
(c)
Figure 4. Movement trajectory of each agent in Uniform type. (a) γ=0.0, (b) γ=0.3, and (c)
γ=1.0.15
(a) (b)
Figure 5. Step length-rank plots for three agents (γ=0.0, γ=0.3,γ=1.0). Both axes are shown
on a logarithmic scale. (a) Exponential type. (b) Uniform type.
(a) (b)
Figure 6. Enlarged view of step length-rank plots. (a) Exponential type. Vertical axis is shown on
logarithmic scale. (b) Uniform type. Both axes are shown on normal scale.
Figures 5(a) and 5(b) show the step length-rank plots of the three agents (γ=0.0, γ=0.3, γ=1.0) for the16
Exponential and Uniform types, respectively. These figures display step length on the horizontal axis and
rank step lengths in descending order on the vertical axis. The rank of a step length indicates the number of
step lengths that are greater than or equal to it, thereby representing a complementary cumulative
distribution function (CCDF). Figure 6 presents a magnified view of the short step length region from Fig.
5. Figures 5 and 6 depict the power function with a dashed line, the exponential function with a dotted line,
and the linear function with a dash-dot line.
Figure 5(a) shows that the CCDF of the Min agent (γ=1.0) can be approximated by an exponential
function with exponent 2 in the Exponential type, which means the step length distribution can be
approximated by the exponential distribution P(l)=2e−2l. From Fig. 5(b), we can see that the CCDF of the
Min agent (γ=1.0) can be linearly approximated in the Uniform type, which means that P(l) is a
constant value, i.e., uniformly distributed. In other words, for both types, the Min agent step length
distribution P(l) will be of the same type as the distribution P(r) of r used for destination generation.
The CCDF of the non-Min agent (γ=0.0) can be approximated by the power function with exponent 1
−
in the long step length domain for both types. In other words, the step length distribution of the non-Min
agent can be approximated by P(l) l−2 regardless of the type of P(r). The CCDFs of the agents with
γ=0.3 are intermediate in distribution between the Min and the non-Min agents for both types. Thus, the
movement pattern of agents varies continuously from Brownian walk to Lévy walk depending on the value
of γ. The results presented above hold true for multidimensional spaces of three or more dimensions as well.
What we want to focus on here is the shape of each agent's CCDF in the short step length region; as can
be seen from Fig. 6, in the short step length region, each agent's CCDF is of the same type as P(r), as in
the Min agent case. These results indicate that agents with γ>0.0 switch modes between searching near
and far.17
Xnext
∆X D r
1
R
2
X
H
Figure 7. The agent moves onto the hyperplane H at the next time. The agent moves forward
toward the destination D but may move outside the concentric circles of radius r centered at D,
i.e., may move away from the destination D.
3.2 Lévy walk analysis
In this section, we analyze the reasons for the results presented in the previous section. When r2 2Σ we
r2 r2 ∂z r'
can approximate z ≈1− , ∆z =1−z ≈ and ≈ i . Thus, the formula (3) can be written as
2Σ 2Σ ∂x' Σ
i
r2
∆x' ≈β . (15)
i i 2r'
i
r2
From the formula (15), since β ≈r' ∆x' and
∑N
β =1 are satisfied,
i 2 i i i=1 i
r2 r2
∑N β = ≈∑N r' ∆x' =R'⋅∆X ' holds. In particular, ∆X ' is approximately a point on the
i=1 i 2 2 i=1 i i
 r2   r2
hyperplane HR', =∆X '∈N |R'⋅∆X '=  whose normal vector is R'.
 2   2 18
If the travel distance l is very long, moving away from the destination, i.e., z, may even decrease (Fig. 7).
This is due to the fact that the approximation expressed in the formula (3) is a first-order approximation
that is valid only in the vicinity of the agent's current position, and as the travel distance increases, this
∂x
approximation is not valid because the gradients of i change. Thus, the emergence of long-distance
∂z
migration is based on the fallacy that local rules (gradients) can be applied globally. In this sense, the non-
Min agent can be said to have a weaker motivation to approach D than the Min agent. In other words, γ is a
parameter that expresses the degree of attempt to approach D.
To simplify subsequent analysis, we denote β =1,β =0( j ≠ k) for the non-Min agent. This indicates
k j
that the agent moves along the k-th axis and ∆x' ≥0,∆x' =0( j ≠k). The direction of the k-axis is
k j
randomly determined each time, resulting in random movement direction.
If the angle between the i-th basis vector e' and the difference vector R' in the N-dimensional
i
orthonormal system is θ, then R'=( r' ,r' ,,r' )T =( rcosθ,,rcosθ,,rcosθ )T .
i 1 2 N 1 i N
∂θ
Consider P(l|r)∝ P(θ), which is the distribution of l when the current position X is on the
∂l
hyper-sphere of radius r centered at the destination D. Using the formula (15), the step length can be
written as follows.
2
 r2 
l ≈ ∑N β 
i=1  i 2r' 
i
2
 r 
=
∑N
β 
i=1

i 2cosθ

i . (16)
2
r  β 
= ∑N  i 
2 i=1 cosθ 
i
r
=
2 cosθ
k19
r ∂l r sinθ
Since the step length of the non-Min agent is l ≈ , it follows that ≈ k . Also
2 cosθ ∂θ 2 cos2θ
k k k
r2 4l2 −r2
cos2θ = and sinθ = 1−cos2θ = hold. Since θ is randomly determined from a uniform
k 4l2 k k 2l
distribution, we can put the probability of occurrence P(θ) of θ as a constant. Therefore, P(l|r) can be
written as
∂θ
P( l|r)∝∑N i P(θ)
i=1 ∂l i
∂θ
= k P(θ )
∂l k
2 cos2θ
= k P(θ ) . (17)
r sinθ k
k
r
= P(θ )
k
l 4l2 −r2
r
∝
l 4l2 −r2
Finally, the distribution of l can be written as follows.
P( l)∝∫ P( l|r) P( r)
dr
r
(18)
r
∝∫ P( r) dr
rl 4l2 −r2
r r
As mentioned above, for the non-Min agent, l ≥ is satisfied, and for l such as l  ,
2 2
l 4l2 −r2 ≈l 4l2 =2l2 can be approximated. P(l) can then be written as follows.
r
P( l)∝∫ P( r)
dr
rl 4l2 −r2
r
≈∫ P( r) dr
r 2l2
(19)
1
= ∫ rP( r) dr
2l2 r
1
∝
l220
Thus, we see that P(l) of the non-Min agent can approximate the Cauchy distribution regardless of P(r)
r
with respect to l such that l  . For example, in the Uniform type, r ≤r , and in this paper we set it to
2 max
r
r =2. Thus, in the region of l where l  max =1 P(l) can be approximated as a Cauchy distribution. In
max 2
r
contrast, if the non-Min agent happens to follow near the shortest path, the step length will be l ≈ as in
2
the Min agent. In other words, since P(r)=e−r for the Exponential type, P(l)=2e−2l, and since P(r) is
uniformly distributed for the Uniform type, P(l) is also uniformly distributed.
IV. DISCUSSION
In Lévy walk simulations, the Lévy or power-law distribution is predefined as the distribution of step
lengths, from which step lengths are sampled to generate Lévy walks [26]. Similarly, for the Min agent, if
P(r) is set to a power-law distribution, P(l) itself will also follow a power-law distribution, thereby
generating a Lévy walk. Conversely, to generate a Lévy walk in the Min agent, P(r) must be a power-law
distribution. A pertinent question arises regarding the preference for the power-law distribution over
exponential or uniform distribution when generating Lévy walks. In contrast, with the non-Min agent,
regardless of what P(r) is set to, it universally results in a Cauchy walk. This suggests that the lack of a
constraint to approach the destination by the shortest path is what facilitates the generation of the Cauchy
walk.
Strictly speaking, however, in long step length regions, P(l) is a Cauchy distribution, but in shorter
regions, P(l) has the same distribution form as P(r). In our model, a single random walk model gives
rise to a composite distribution composed of two distinct distributions. This phenomenon has been21
observed in the migratory behaviors of various organisms, including mussels, desert ants, E. coli, and
humans [23][27][28][29][30][31]. Notably, the movements of mussels and desert ants are effectively
approximated by a mixture of multiple exponential distributions [30][31]. Specifically, the movement of
mussels is optimally characterized by a composite Brownian walk, which consists of three modes of
movement with different characteristic scales, among which the mussels alternate [28][30].
In humans, the composite step length distribution is approximated by a combination of multiple log-normal
distributions. This variation is attributed to differences in transportation modes such as walking, biking,
driving, and rail [29].
The proposed model is abstract, and future work will be necessary to understand the biological
implications of mode switching. Additionally, we aim to explore how search efficiency for food varies
between a pure Cauchy walk and a random walk based on the composite distribution observed in the non-
Min agent.
In the model, the agent's movement behavior can be continuously adjusted from a Brownian walk to a
Cauchy walk by controlling γ. This parameter signifies the extent to which the agent insists on approaching
the destination via the shortest path and can be seen as the degree to which the agent prioritizes search costs,
which appear to increase in proportion to the distance traveled. It has been observed that in areas where
food is scarce, marine predators adopt the Lévy walk, but in regions with abundant food, they shift to the
Brownian walk [4]. If food is ubiquitous, it would be prudent to prioritize search costs and move with as
small a step length as possible. Conversely, if food is distributed over a wide area, reducing the priority of
search costs, and extending the search distance could enhance the likelihood of finding food. To
accommodate such mode switching, a model that autonomously adjusts γ in response to environmental
changes is necessary. This remains a topic for future investigation.
While the destination is randomly set each time in this model, we did not make any specific
assumptions about its representation. If we assume the destination to be the location of another agent,
agents will attempt to converge, potentially allowing for the construction of a flocking model. Additionally,22
this model, being a random walk model generating a Cauchy walk in multi-dimensional space, could
potentially be used to search the parameter space of an optimization problem [32]. These potential
applications will be explored in future work.23
Data Availability Statement
The source code used to produce the results and analyses presented in this manuscript are available from
the GitHub repository:
https://github.com/shinoharaken/CauchyWalk24
REFERENCES
[1] Harris, T. H. et al. Generalized Lévy walks and the role of chemokines in migration of effector CD8+ T cells.
Nature 486, 545-548 (2012).
[2] Ariel, G., Rabani, A., Benisty, S., Partridge, J. D., Harshey, R. M. & Be'Er, A. Swarming bacteria migrate by
Lévy Walk. Nat. Commun. 6, 8396 (2015).
[3] Shokaku, T., Moriyama, T., Murakami, H., Shinohara, S., Manome, N. & Morioka, K. Development of an
automatic turntable-type multiple T-maze device and observation of pill bug behavior. Rev. Sci. Instrum. 91,
104104 (2020).
[4] Humphries, N. E. et al. Environmental context explains Lévy and Brownian movement patterns of marine
predators. Nature 465, 1066-1069 (2010).
[5] Humphries, N. E., Weimerskirch, H., Queiroz, N., Southall, E. J. & Sims, D. W. Foraging success of
biological Lévy flights recorded in situ. Proc. Natl. Acad. Sci. USA 109, 7169-7174 (2012).
[6] Raichlen, D. A., Wood, B. M., Gordon, A. D., Mabulla, A. Z. P., Marlowe, F. W. & Pontzer, H. Evidence of
Lévy walk foraging patterns in human hunter-gatherers. Proc. Natl. Acad. Sci. USA 111, 728-733 (2014).
[7] Focardi, S., Montanaro, P. & Pecchioli, E. Adaptive Lévy walks in foraging fallow deer. PLoS One 4, e6587
(2009).
[8] Ramos-Fernández, G., Mateos, J. L., Miramontes, O., Cocho, G., Larralde, H. & Ayala-Orozco, B. Lévy walk
patterns in the foraging movements of spider monkeys (Ateles geoffroyi). Behav. Ecol. Sociobiol. 55, 223-230
(2004).
[9] Sims, D. W. et al. Scaling laws of marine predator search behaviour. Nature 451, 1098-1102 (2008).
[10] Sakiyama, T. A recipe for an optimal power law tailed walk. Chaos 31, 023128 (2021).
[11] Huda, S. et al. Lévy-like movement patterns of metastatic cancer cells revealed in microfabricated systems
and implicated in vivo. Nat. Commun. 9, 4539 (2018).
[12] Viswanathan, G. M., Raposo, E. P. & da Luz, M. G. E. Lévy flights and superdiffusion in the context of
biological encounters and random searches. Phys. Life Rev. 5, 133-150 (2008).
[13] Bartumeus, F., da Luz, M. G. E., Viswanathan, G. M. & Catalan, J. Animal search strategies: A quantitative
random-walk analysis. Ecology 86, 3078-3087 (2005).
[14] Wosniack, M. E., Santos, M. C., Raposo, E. P., Viswanathan, G. M. & da Luz, M. G. E. The evolutionary
origins of Lévy walk foraging. PLoS Comput. Biol. 13, e1005774 (2017).
[15] Viswanathan, G. M., Buldyrev, S. V., Havlin, S., Da Luz, M. G. E., Raposo, E. P. & Stanley, H. E.
Optimizing the success of random searches. Nature 401, 911-914 (1999).
[16] Levernier, N., Textor, J., Bénichou, O. & Voituriez, R. Inverse Square Lévy Walks are not Optimal Search
Strategies for d≥2. Phys. Rev. Lett. 124, 080601 (2020).
[17] Guinard, B. & Korman, A. Intermittent inverse-square Lévy walks are optimal for finding targets of all
sizes. Sci. Adv. 7, eabe8211 (2021).
[18] James, A., Plank, M. J. & Edwards, A. M. Assessing Lévy walks as models of animal foraging. J. R. Soc.
Interface 8, 1233-1247 (2011).
[19] Reynolds, A. Liberating Lévy walk research from the shackles of optimal foraging. Phys. Life Rev. 14, 59-
83 (2015).
[20] Reynolds, A., Ceccon, E., Baldauf, C., Medeiros, T. K. & Miramontes, O. Lévy foraging patterns of rural
humans. PLoS One 13, e0199099 (2018).
[21] Abe, M. S. Functional advantages of Lévy walks emerging near a critical point. Proc. Natl. Acad. Sci. USA
117, 24336-24344 (2020).25
[22] de Jager, M. et al. How superdiffusion gets arrested: ecological encounters explain shift from Lévy to
Brownian movement. Proc. R. Soc. B 281, 20132605 (2014).
[23] Huo, H., He, R., Zhang, R. & Yuan, J. Swimming Escherichia coli Cells Explore the Environment by Lévy
Walk. Appl. Environ. Microbiol. 87, e02429-20 (2021).
[24] Bishop, C. M. Pattern Recognition and Machine Learning (Springer, 2011).
[25] Manome, N. et al. Self-incremental learning vector quantization with human cognitive biases. Sci. Rep. 11,
3910 (2021).
[26] Garcia-Saura, C., Serrano, E., Rodriguez, F. B. & Varona, P. Intrinsic and environmental factors
modulating autonomous robotic search under high uncertainty. Sci. Rep. 11, 24509 (2021).
[27] de Jager, M., Weissing, F. J., Herman, P. M., Nolet, B. A. & van de Koppel, J. Lévy walks evolve through
interaction between movement and environmental complexity. Science 332, 1551-1553 (2011).
[28] Jansen, V. A., Mashanova, A. & Petrovskii, S. Comment on "Lévy walks evolve through interaction
between movement and environmental complexity". Science 335, 918 (2012).
[29] Zhao, K., Musolesi, M., Hui, P., Rao, W. & Tarkoma, S. Explaining the power-law distribution of human
mobility through transportation modality decomposition. Sci. Rep. 5, 9136 (2015).
[30] Reynolds, A. M. Mussels realize Weierstrassian Lévy walks as composite correlated random walks. Sci.
Rep. 4, 4409 (2014).
[31] Reynolds, A. M., Schultheiss, P. & Cheng, K. Does the Australian desert ant Melophorus bagoti approximate a
Lévy search by an intrinsic bi-modal walk? J. Theor. Biol. 340, 17-22 (2014).
[32] Yang, X. S. & Deb, S. Cuckoo search via Lévy flights. World Congress on Nature & Biologically Inspired
Computing (NaBIC 2009). IEEE Publications. 210–214. https://doi.org/10.48550/arXiv.1003.1594 (2009).
Acknowledgments
This work was supported by JSPS KAKENHI [grant number JP21K12009].
Author contributions
Shuji Shinohara: Conceptualization, formal analysis, methodology, software, writing, original draft
preparation, and funding acquisition. Daiki Morita: Software, reviewing, and editing. Nobuhito Manome:
Writing, reviewing, and editing. Hayato Hirai: Software, review, and editing. Ryosuke Kuribayashi:
Software, review, and editing. Toru Moriyama: Writing, reviewing, and editing. Hiroshi Okamoto:
Writing, reviewing, and editing. Yoshihiro Nakajima: Writing, reviewing, and editing. Pegio-Yukio
Gunji: Writing, reviewing, editing, and supervision. Ung-il Chung: Writing, review, editing, supervision,
and project administration.26
Figure legends
Figure 1. (a) Agent tries to approach destination D from its current position X. (b) EMA is an algorithm
that moves X close to D.
Figure 2. Examples of destination when agent's current position is at origin. Direction of destination is
randomly determined. (a) Exponential type. Distance r to destination is sampled from exponential
distribution P(r)=e−r. (b) Uniform type. r is sampled from uniform distribution in range of [ 0,2]
Figure 3. Movement trajectory of each agent in Exponential type. (a) γ=0.0, (b) γ=0.3, and (c) γ=1.0.
Figure 4. Movement trajectory of each agent in Uniform type. (a) γ=0.0, (b) γ=0.3, and (c) γ=1.0.
Figure 5. Step length-rank plots for three agents (γ=0.0, γ=0.3,γ=1.0). Both axes are shown on a
logarithmic scale. (a) Exponential type. (b) Uniform type.
Figure 6. Enlarged view of step length-rank plots. (a) Exponential type. Vertical axis is shown on
logarithmic scale. (b) Uniform type. Both axes are shown on normal scale.
Figure 7. The agent moves onto the hyperplane H at the next time. The agent moves forward toward the
destination D but may move outside the concentric circles of radius r centered at D, i.e., may move away
from the destination D.