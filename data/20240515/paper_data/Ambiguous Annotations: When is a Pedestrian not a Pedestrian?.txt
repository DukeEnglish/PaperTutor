Ambiguous Annotations: When is a Pedestrian not a Pedestrian?
LuisaSchwirten1 JannesScholz2 DanielKondermann1 JanisKeuper2
1QualityMatchGmbH,Heidelberg
2InstituteforMachineLearningandAnalytics,OffenburgUniversity
Abstract canalsoincludefurtherinformation,suchasorientation,or
whethertheobjectispartlyoccluded. Ourexperimentsfo-
Datasetslabelledbyhumanannotatorsarewidelyused cusonsupervisedlearning,wherethequalityofthelabelled
in the training and testing of machine learning models. In dataisalreadyanimportantconsiderationattrainingtime.
recentyears,researchersareincreasinglypayingattention However, even in the case of unsupervised learning, in or-
to label quality. However, it is not always possible to ob- dertomonitorandensurethetrainedmodel’sperformance,
jectivelydeterminewhetheranassignedlabeliscorrector annotated data as a ground truth is needed. For this rea-
not. Thepresentworkinvestigatesthisambiguityinthean- son,annotationqualityiscrucialforbothtrainingregimes,
notation of autonomous driving datasets as an important supervised as well as unsupervised. It is possible to syn-
dimension of data quality. Our experiments show that ex- theticallygenerateground-truthimagesforbothtestingand
cluding highly ambiguous data from the training improves training,buttheselackbehindrealstreetsceneimagesindi-
model performance of a state-of-the-art pedestrian detec- versity[18][26]. Hence,imageslabelledbyhumanannota-
torintermsofLAMR,precisionandF1score,therebysav- torsarestillconsideredthe“goldstandard”forground-truth
ing training time and annotation costs. Furthermore, we data.
demonstrate that, in order to safely remove ambiguous in- Human annotation however comes with its own chal-
stances and ensure the retained representativeness of the lenges. Ashumans, wearenotimmunetoerrors. Asmall
training data, an understanding of the properties of the percentageofthedata,evenineasycases,willthereforebe
datasetandclassunderinvestigationiscrucial. labelledincorrectlybyhumanannotators. Moreover,some
instancesareinherentlydifficulttolabel,whichoftenleads
to disagreement between different annotators. We refer to
1.Introduction
imagesandinstances,wherethecorrectlabelisnotentirely
obviousas“ambiguous”.Thefollowingsectioninvestigates
A crucial yet difficult task in computer vision for au-
thisambiguityasanimportantaspectofdataqualityforthe
tonomousdrivinganddriverassistancesystemsisthedetec-
case of vulnerable road users. The results of our experi-
tion of vulnerable road users, such as pedestrians, cyclists
ments, which are presented in Section 3, demonstrate that
or motorcyclists, and including persons with impaired vi-
improvedmodelperformancecanbeachievedbyremoving
sion, hearing or mobility. To this day, this group carries
highlyambiguousinstancesfromthetrainingset.
the highest risk of injuries and casualties in traffic acci-
dents [7]. Therefore, the development of systems ensur-
2.RelatedWork
ing and improving the protection of these road users is an
important step towards enhancing traffic safety for all par- Awarenessofissueswiththereliabilityofgroundtruthla-
ticipants. However,thedetectionofpersonsinstreetscene belshasriseninrecentyears,markedbypublicationscon-
images is challenging given the individuality and diversity cernedwiththecorrectnessoftheannotationsinlargepub-
ofhumanappearance. licdatasetsandbenchmarks,suchasImageNetandCIFAR-
In the past decade, the capabilities of computer vision 10 [3] [13] [15] [19]. At the same time, a large number
systemshaveseenremarkableprogressthroughtheemploy- of publications is concerned with how to handle noisy la-
mentofdeeplearningmodels,whichrequirevastsamounts belsinobjectclassificationanddetection,andhowtotrain
ofdatafortrainingandtesting. Thisdatacomesintwodif- networks, which are robust against noise [1] [2] [10] [14]
ferent forms: (un-annotated) raw data and annotated data. [20] [22] [23] [25]. However, the definition of label noise
Forobjectdetection,theannotationsindicatetheidentityof usedinthisfieldofresearchimpliesthatthereisanunder-
the objects through class labels, as well as their localiza- lying true label, which can be observed. Due to the chal-
tion,mostcommonlyintheformofboundingboxes. They lenges detailed in the following sections and the resulting
1
4202
yaM
41
]VC.sc[
1v49780.5042:viXrasubjectivityinthelabellingofdifficulttasks,thisisnotal- tialocclusionbyanotherobject,ortheobjectbeingfaraway
ways the case. In comparison to studies on label noise, a fromthecamera. Thisformofambiguitywillalwaysexist
muchsmallernumberofpublicationsexists, whichiscon- instreetsceneimages,whicharetakenfromavehicledriv-
cerned with incorporating ambiguity information into the ingoutsideofcontrolledconditions“inthewild”. Figure1
training data. Starting with Gao et al. (2017) [9], neu- showsexamplesofthisfortheclass“pedestrian”. Whilein
ral networks have been employed in distribution learning theimagein1athepersoniseasilyidentifiable,in1bclas-
models, to learn a label distribution instead of binary or sification of the instance is much more difficult. Image 1c
multi-classlabels. Distributionlearningapproachesdonot shows an instance which is highly ambiguous due to low
alwaysutilizethevariabilityintheannotationstoderivethe visibility. Without additional data, such as tracking of the
groundtruthdistributions,butoftentimesthesearemodeled personthroughoutanimagesequence,itisinthiscaseim-
implicitlyfromneighboringclasses[5][12], fromfeatures possibletotellwithcertainty,ifinrealitythisistheimage
extractedbyaneuralnetwork[28],ormostrecently,using ofapersonornot. However,additionalinformation,which
transformers [27]. A reason for this is that information on would help us distinguish between “real” pedestrians and
thevariabilityofannotatoranswersisnotreadilyavailable other object classes is usually not given in publicly avail-
formostdatasets[8]. abledatasets,andnotalwaysrecordedduringthecapturing
of the images. Images 1d to 1f illustrate how occlusion,
3.AmbiguityinDetectionData which is a common challenge in image annotation, causes
differentdegreesofambiguity.
3.1.Definition
Labellingvulnerableroadusersinstreetsceneimagesisnot
ClassDefinitions Inadditiontoimageproperties,another
a simple task, and therefore involves a high level of ambi-
common cause of ambiguity is that of instances falling in
guity. Thisambiguityarisesfromseveralchallenges,mak-
between the definitions of neighboring classes in the la-
ing it difficult to recognize instances as their correct class,
bellingguide,e.g.apersoncouldbeeitherlabelledapedes-
or to distinguish them from their neighboring classes. In-
trianorcyclistdependingonwhetherandhowtheyareus-
stances,whicharepartlyorevenheavilyoccludedarehard
ingabike.Tosomeextent,thiscanbemanagedbycovering
to detect for human annotators as well as machine learn-
many possibilities in the labelling instructions. However,
ing models. The same is true for objects with low visibil-
eventhemostdetailedclassdescriptionwillnotbeableto
ity, such as blurry instances or those that are far from the
coverallpossiblecases, especiallyforsuchadiverseclass
camera. The wide variety of lighting conditions found in
aspedestrians. Weillustratethisissueusingexamplesfrom
street scenes poses an additional challenge. This leads to
the neighboring classes “pedestrian” and “rider” of e.g. a
an ambiguity in the images where the true label is not al-
bike, motorbike or scooter. Very often, the distinction be-
ways observable. Even when annotated by experts and in
tweenthetwoismadesuch, thatpersonswhoarewalking
theabsenceoferrors, theassignedlabelswillthereforere-
orstanding,aretobelabelledaspedestrians,whilesomeone
tainadegreeofsubjectivity. Thisproblemhasalreadybeen
ridingabikeorscooterisclassifiedasarider. Soaperson
describedforthefieldofmedicalimagesas“inter-observer
whoisonlyholdingorpushingabike,butnotcurrentlyrid-
variability”[14].Anothertermoftenusedintheliteratureis
ing one in the image, is by this definition a pedestrian and
“labelnoise”[1],whichusuallyimpliesthatthereisacor-
notarider. Butthenwhataboutsomeonewhoissittingon
rect label observable from the data, and annotator answers
thebike(i.e.strictlyspeakingnotwalkingorstanding),but
deviatingfromitareincorrectandaddnoisetotheannota-
forexamplewaitingatatrafficlight,shouldtheybeconsid-
tion. In contrast to this, we define ambiguous data as any
ersasariderorapedestrian? Sincethisisaverycommon
instances,wheredifferentannotatorswilldisagreeonwhat
edge case, the widely adapted distinction here is that any-
labeltoassign,becausethetruelabelisnotentirelyobjec-
onewhohasatleastonefootonthegroundistobelabelled
tivelyobservable.Ontheexampleoftheclass“pedestrian”,
as “pedestrian”. However, this brings us to the next prob-
wefurtherexaminethesourcesofthisambiguityinthefol-
lem,becauseitisnotalwaysclear,whetherornotthisisthe
lowing.Thesecanbefoundinpropertiesoftheimageitself,
caseinanimage. Figure2illustratesthisonsixexamples.
or different possible interpretations of the class definitions
According to the above distinction, the person in the im-
inthelabellingguide,i.e.theinstructions,whicharegiven
agein2aisclearlyidentifiableasapedestrian,becausethey
totheannotatorswhenlabellingtheimages.
haveonefootontheground. Followingthesamerule, the
instancein2distobelabelledarider,becausebothfeetare
3.2.SourcesofAmbiguity
onthevehicle. Theremainingfourimagesexhibitdifferent
ImageProperties Ambiguitycanarisefromtheimageit- degrees of ambiguity w.r.t. this distinction. In images 2b
self, if the visibility of the instance is impaired due to ad- and2citisnotclear,whetherornotthepersonisonavehi-
verseweather,blurrinessorlowcontrastintheimage,par- cle. Inimages2eand2fitisdifficulttotellifthecriterion
2(a)Lowambiguity: Awellrecog- (b)Mediumambiguity:Thispedes- (c)HighAmbiguity:Itisveryhard
nizablepedestrianinstance. trianisalreadyhardertoidentify. toidentifythisinstance.
(d)Lowambiguitywithocclusion. (e) Medium ambiguity with high (f)Highambiguitycausedbyhigh
occlusion. occlusion.
Figure1. ImageProperties. Mediumandhighambiguityherecorrespondstoanambiguitymeasureof0.4to0.49andover0.65respec-
tively.ExamplesfromtheECPDataset[4].
(a) Low ambiguity: A pedestrian (b)Mediumtohighambiguity:This (c)Highambiguity: Itisnotpossi-
withabikeandonefootclearlyon ridercouldalsobeinterpretedasa bletotellfromtheimagewhether
theground. pedestrianpushingabike. thepersonisonabikeorscooter.
(d) Low ambiguity: A rider with (e) Medium ambiguity: The right (f)Highambiguity:Wecannottell
bothfeetonthevehicle. footoftheperson,whichisonthe fromtheimagewhetherornotthe
ground,isbarleyvisible. leftfootisontheground.
Figure2.NeighboringClasses:“Pedestrian”versus“Rider”,withthedistinctivecriterionthatapersonwithatleastonefootontheground
istobelabelledasapedestrian.ExamplesfromtheECPDataset[4].
3ofonefootbeingonthegroundismetornot,i.e.ifthisis Subset Height Occlusion Truncation
apedestrianorriderperthedefinition. Fortheseinstances,
reasonable >40px <40% <40%
wecanexpectdisagreementbetweentheannotatorswhich
small 30−60px <40% <40%
ofthetwoneighboringclassestoassign.
occluded >40px 40−80% <80%
If we include such cases in the labelling guide as well,
all >20px <80% <80%
e.g. by always deciding for one of the two classes, if the
legsarenotbothvisible,wewillbeabletocovermoresuch
Table1.ECPEvaluationSubsets[4].
instanceswiththeinstructions,butwewillneverbeableto
come up with a finite set of rules that is able to cover all
imaginable cases. Moreover, we will want to keep our in- model trained on different data, instead of reaching peak
structionsasconciseaspossible,becausethelongerthela- performance. Wecouldhoweverconfirmthat, whiletrain-
bellingguidegets,themorethisitselfcanbecomeasource ingthemodelfor100moreepochsstillleadtominorper-
ofannotationerrors. Atsomepoint,theannotatorswillnot formance gains, the comparative results between the mod-
beabletocorrectlyrememberalltheruleswehavelaidout els stayed the same. The performance of the trained mod-
forthemduringtheprocessoftheannotation. Sotherewill els was evaluated using the official evaluation measure of
always be some remaining edge cases which might be la- theECPbenchmark,LogAverageMissRate(LAMR)[4].
belled differently depending on the annotators’ interpreta- In short, the LAMR expresses the trade-off between the
tions. Awarenessofthesechallengesandpossiblepitfallsis miss rate (ratio of ground truth pedestrians that were not
crucial, whenmakingdecisionsw.r.t.thelabellinginstruc- detected) and false positives per image (other objects the
tionsandclassdefinitions. model falsely detected as pedestrians) for different thresh-
Sinceforthesereasonsacertaindegreeofambiguityis oldsofconfidencescoresreturnedbythemodel.
inevitable when annotating a dataset, should all these in-
4.2.MeasuringAmbiguity
stancesbetreatedidenticallyduringtraining, regardlessof
their different degrees of ambiguity? And how are highly
In order to analyse the effects of ambiguous data on train-
ambiguous cases to be handled during testing and evalua-
ingandtesting,weneedawaytoquantifyambiguitywithin
tionofatrainedmodel? Should,forexample,themodelre-
theannotations.Forourexperiments,wefocusedonthean-
ceiveanequallyhighpenaltyfornotfindingtheinstancein
notationquestionwhethertheinstanceunderconsideration
Figure1casitshouldfornotcorrectlydetectingtheperson
is a human being. Annotators are asked to respond to this
in 1a? As a cost-efficient measure, we investigate the ef-
questionwitheither“yes”or“no”,orindicatethattheyare
fectsofsimplyremovinghighlyambiguousinstancesfrom
unable to give a definite answer (denoted “?” in the fol-
thedata.
lowing). Thefrequenciesoftheseanswersforagiventask,
nyes,nnoandn?,arethenusedtocalculateaheuristicmea-
4. How Does Ambiguity Influence the Model
sureforambiguityfromannotatordisagreement[16],which
Performance? definestheambiguityαofaninstanceas
4.1.ModelandTraining
(cid:40)
1−γ·2| nyes − 1| ifn−n? >0
Our experiments were conducted using data from the Eu- α= n−n? 2 (1)
1 otherwise
roCity Persons Dataset (ECP) [4], which is a prominent
benchmark for pedestrian detection. Since the test dataset
with
of the benchmark is not publicly available, we used the
n=nyes+nno+n?,
published validation set as our test set. We chose Pede-
stron [11] for evaluation, the highest performing model whereγ ≡1−n? re-scalesthedistanceoftheobserveddis-
n
fromthebenchmark,forwhichthefullarchitectureaswell tributionofanswersfromauniformdistributionbytheratio
as pretrained weights are published. This is a Cascade R- of“?”-answers,suchthat,ifonly“?”-answersaregivenby
CNN model [6], originally with an HRNet [24] backbone, theannotatorsforthetask,theambiguityreachesitsmaxi-
which we replaced with MobileNetV2 [21] to achieve still mumvalueof1.
close-to benchmark performance, but at greatly reduced For ECP, only hard labels with no information on an-
training times. Each model was trained for 50 epochs, notatordisagreementexistwithinthepublishedbenchmark
whichtookapproximately4daysonasingleNVIDIARTX data. Asacost-efficientalternativetore-annotatingtheen-
4090. The reasoning for stopping the training early and tiretrainingandvalidationsetswithmultipleannotatorsfor
choosing a more light-weight backbone was to enable us the above question, we employed the approach proposed
totrainmoreiterationsofthemodelinthesametime,since by [17] to estimate the answer distributions. The model
we were interested in the comparative performance of the pretrainedontheECPDatasethasbeenproventoestimate
4Figure3. Resultsfortwotrainingsetsandthreetestsetsincludingdifferentdegreesofambiguity. “Original”denotestheoriginalECP
trainingandvalidationsets,“Amb0.65”and“Amb0.5”thesamesubsetsprunedaboveanambiguitythresholdof0.65and0.5.
annotator answers for ECP with high accuracy [17]. The for instances up to moderate occlusion, removing ambigu-
ambiguity measure was then computed from the predicted ousinstancesfromthetrainingsetimprovesprecisionatthe
answerdistributions. expense of only a small decline in recall. Precision, recall
To compare the effects of ambiguity on both, training and F1 score for the two different training regimes when
andtestset,weremovedhighlyambiguousinstancesupto testedondatawithandwithouthighambiguityaregivenin
differentambiguitythresholdsfromthedatasetandtrained Figure4. Wecanseethatthemodeltrainedwithouthighly
themodelontheentireoriginaldataaswellasonthever- ambiguous data also performs better in terms of both pre-
sionsofthedatasetwithappliedambiguitythresholds. We cision and F1 score. Visual inspection of the detection er-
thenevaluatedthetrainedmodelsontestdataincludingin- rorsconfirmedthatambiguousdatainthetrainingsetcon-
stances, again, up to different ambiguity thresholds. The tributes to the generation of false positive detections. This
resultsfortwomodels,onetrainedonalloriginaldata,and trendisobservableregardlesswhetherthemodelwastested
onetrainedwithoutinstanceswithambiguityscore≥0.65, ondataincludingorexcludingambiguousdata. Therecall
whichwerethentestedonthreedifferentversionofthetest slightly declinesin all testing scenarios whenthe model is
set (all data vs. ambiguity thresholds of 0.65 and 0.5), are trained without the ambiguous data, most notably for the
shown in Figure 3. “Reasonable”, “Small”, “Occluded”, “occluded” test subset. This might indicate that some of
and“All”aretheoriginalsubsetsoftheECPbenchmarkfor theremovedambiguousinstancesstillconveyinformation,
evaluation(seeTable1). which can help the model learn more diverse representa-
tions,especiallyinthepresenceofocclusion.
4.3.Results
Notethat,ascanbeexpected,removingambiguousdata
Removing ambiguous data from the training dataset fromthetestsetimprovesallmetricsforbothtrainedmod-
improves model performance. Figure 3 shows that the els. Nonetheless, the implication of these observations is
modeltrainedwithouthighlyambiguousinstancesachieves less obvious: You can ignore ambiguous data in both sets,
higherperformance(lowerisbetterfortheLAMR),except resulting in reduced cost through lower training times. Si-
whenheavilyoccludedinstancesareincludedintheevalu- multaneously, annotation costs can be reduced, because it
ation. Upon further investigation of the prediction results, is possible to estimate the ambiguity measure reliably for
wefoundthatthereasonforthisbetterperformanceis,that high-ambiguity instances, and thereby exclude them from
5(a)BothtrainedmodelstestedontheoriginalECPvalidationset.
(b)BothtrainedmodelstestedontheECPvalidationsetprunedbyambiguitymeasureat0.5.
Figure4.Comparisonofrecall,precisionandF1scorefortwodifferenttrainingandtestdatasets.
theannotationprocessalltogether[17]. set (see Figure 3). When removing ambiguous instances,
we disproportionately remove occluded instances. Hence,
the model which has seen more occluded data in training
Thereisastrongcorrelationbetweenambiguityandoc- performsbetteronthisspecificsubset,whileitstillexhibits
clusion. Whencomparingtheambiguitymeasurewiththe lowerperformanceonallotherdata.
occlusiontagsinthegroundtruth(seeFigure5),weobserve
that higher values of the ambiguity measure correspond to 5. Improving Model Performance at Reduced
a greater prevalence of occlusion tags within the dataset.
TrainingandAnnotationCosts
As ambiguity increases, the proportion of tags indicating
higher levels of occlusion is also elevated. This is evident Based on the findings detailed above, we propose the fol-
inFigure5,wherethepeakofthe“occluded>80”tagpro- lowing course of action for treating ambiguity in machine
portionisatanambiguitymeasurevalueof0.79. Thisex- learningdatasets,especiallyforsafety-criticalapplications:
plainswhythemodeltrainedwithappliedambiguitythresh- 1. Assess possible sources of ambiguity in the labelling
old,whichachieveshigherperformanceinallotherevalua- guide. Deriving simple rules, which are easy to commu-
tion subsets in terms of LAMR, is surpassed by the model nicate and cover the most important edge cases can help
trained on the original training set including all ambigu- reduce ambiguity during the annotation process without
ousdatawhenevaluationisperfomedontheoccludedsub- adding possible sources of errors through excess difficulty
6Figure5.Distributionofocclusionandtruncationtagsfordifferentambiguitythresholds.
fortheannotators. tend. Whendoingso,wecanidentifytwotrade-offs,which
2. Quantify the ambiguity within the data. This can be need to be considered. Firstly, the very common trade-off
donefromtherawannotatoranswersorbyestimationfrom inmachinelearningbetweenrecallandprecisionisalsoat
thelabelleddata. Chooseamethodwhichiscost-efficient, play when adding or removing ambiguous instance from
as well as a quantitative measure which is appropriate for trainingdata. Secondly,whenremovingtoomanyambigu-
youruse-caseandinterpretable,e.g.byprovidingaranking ous instances, the dataset is at risk of loosing representa-
oftheinstancesw.r.t.ambiguity. tiveness. Therefore, an understanding of ambiguity in the
3. Inspect a subset of the labelled results visually at dif- dataset is important to decide which instances to remove,
ferent ambiguity thresholds. Examine the distributions of which to keep, and which cases of hard-to-detect objects
theambiguitymeasureoverdifferentclassesandintra-class might be in need of additional treatment to prevent them
propertiestoidentifypossiblecommonsourcesofambigu- from being underrepresented in the remaining training set.
ity. Determine if certain properties are over-represented at Aswehaveshown,asimpleambiguitymeasure,whichcan
higherambiguitythresholds. Ifannotatorsdisagreeoverin- beestimatedorcalculatedfromtherawannotationanswers
stanceswherethecorrectlabelseemsobvious,thiscanpos- ofmultipleworkers,enablesustoprunethedataset,result-
siblybeamendedbyupdatingthelabellinginstructions. inginimprovedmodelperformanceatreducedcosts.
4.Prunethedatasetbyremovinghighlyambiguousdataup
toathresholddeterminedthroughtheprevioussteps. Ifthe
dataset is in danger of loosing representativeness, this can
thenbeaddressedthroughadapteddatacollectionprotocols 7.FutureWork
oraugmentationattrainingtime.
Important topics for future work are the extension of this
6.Conclusion
framework to different object classes as well as model
architectures. We employed only one heuristic measure
As we have seen, we will always encounter some degree
for ambiguity based on annotator answer frequencies for
ofambiguityinannotateddata. Additionally,thedescribed
our evaluation. In future work, different measures to
experimentsdemonstratethattheprevalenceofambiguous
calculate and estimate ambiguity, including more elabo-
datahasimplicationsforamachinelearningmodelduring ratetechniques,shouldbeinvestigatedandcomparedw.r.t.
both, training and testing. Our experiments show that we how well they reflect ambiguity and are apt to provide a
canimprovetheperformanceofastate-of-the-artdetection thresholdforimprovingmodelperformancebypruningthe
modelbysimplyremovingambiguousdatatoacertainex- dataset.
7References niquesandremediesinmedicalimageanalysis.Medicalim-
ageanalysis,65:101759,2020. 1,2
[1] Go¨rkemAlganandIlkayUlusoy.Labelnoisetypesandtheir
[15] CsabaKerte´sz. Automatedcleanupoftheimagenetdataset
effectsondeeplearning. arXivpreprintarXiv:2003.10471,
by model consensus, explainability and confident learning.
2020. 1,2
arXivpreprintarXiv:2103.16324,2021. 1
[2] Go¨rkemAlganandIlkayUlusoy. Imageclassificationwith
[16] Christopher Klugmann. A simple measure of ambiguity
deep learning in the presence of noisy labels: A survey.
incrowdsourcedbinaryanswers. Unpublishedmanuscript,
Knowledge-BasedSystems,215:106771,2021. 1
2023. 4
[3] Lucas Beyer, Olivier J He´naff, Alexander Kolesnikov, Xi-
[17] ChristopherKlugmann,DanielKondermann,etal. Noneed
aohua Zhai, and Aa¨ron van den Oord. Are we done with
to sacrifice data quality for quantity: Crowd-informed ma-
ImageNet? arXivpreprintarXiv:2006.07159,2020. 1
chine annotation for cost-effective understanding of visual
[4] Markus Braun, Sebastian Krebs, Fabian B. Flohr, and
data. Unpublishedmanuscript,2024. 4,5,6
Dariu M. Gavrila. EuroCity Persons: A novel benchmark
[18] Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu,
forpersondetectionintrafficscenes. IEEETransactionson
and Antonio Torralba. Diverse image generation via self-
PatternAnalysisandMachineIntelligence,pages1–1,2019.
conditioned gans. In Proceedings of the IEEE/CVF con-
3,4
ference on computer vision and pattern recognition, pages
[5] Morgan Buisson, Pablo Alonso-Jime´nez, and Dmitry Bog-
14286–14295,2020. 1
danov. Ambiguity modelling with label distribution learn-
[19] Curtis Northcutt, Lu Jiang, and Isaac Chuang. Confident
ingformusicclassification. InICASSP2022-2022IEEE
learning: Estimating uncertainty in dataset labels. Journal
International Conference on Acoustics, Speech and Signal
ofArtificialIntelligenceResearch,70:1373–1411,2021. 1
Processing(ICASSP),pages611–615,2022. 2
[20] Ronaldo C Prati, Julia´n Luengo, and Francisco Herrera.
[6] ZhaoweiCaiandNunoVasconcelos.CascadeR-CNN:Delv-
Emergingtopicsandchallengesoflearningfromnoisydata
ingintohighqualityobjectdetection,2017. 4
innonstandardclassification: asurveybeyondbinaryclass
[7] European Comission. ITS & Vulnerable Road
noise.KnowledgeandInformationSystems,60:63–97,2019.
Users. https://transport.ec.europa.
1
eu / transport - themes / intelligent -
[21] MarkSandler,AndrewHoward,MenglongZhu,AndreyZh-
transport-systems/road/action-plan-and-
moginov, and Liang-Chieh Chen. MobileNetV2: Inverted
directive / implementation - its - action -
residualsandlinearbottlenecks,2019. 4
plan/its-vulnerable-road-users_en, n.d.
Accessed:2024-03-10. 1 [22] HwanjunSong, MinseokKim, DongminPark, YoojuShin,
andJae-GilLee.Learningfromnoisylabelswithdeepneural
[8] DiFeng,AliHarakeh,StevenL.Waslander,andKlausDiet-
networks:Asurvey.IEEETransactionsonNeuralNetworks
mayer. Areviewandcomparativestudyonprobabilisticob-
andLearningSystems,pages1–19,2022. 1
jectdetectioninautonomousdriving. IEEETransactionson
IntelligentTransportationSystems,23(8):9961–9980,2022. [23] RyutaroTanno,ArdavanSaeedi,SwamiSankaranarayanan,
2 DanielCAlexander,andNathanSilberman. Learningfrom
noisy labels by regularized estimation of annotator confu-
[9] Bin-Bin Gao, Chao Xing, Chen-Wei Xie, Jianxin Wu, and
sion. InProceedingsoftheIEEE/CVFconferenceoncom-
XinGeng. Deeplabeldistributionlearningwithlabelambi-
guity.IEEETransactionsonImageProcessing,26(6):2825– puter vision and pattern recognition, pages 11244–11253,
2019. 1
2838,2017. 2
[10] BoHan,QuanmingYao,TongliangLiu,GangNiu,IvorW [24] Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang,
Tsang,JamesTKwok,andMasashiSugiyama. Asurveyof ChaoruiDeng,YangZhao,DongLiu,YadongMu,Mingkui
label-noiserepresentationlearning:Past,presentandfuture. Tan, Xinggang Wang, Wenyu Liu, and Bin Xiao. Deep
arXivpreprintarXiv:2011.04406,2020. 1 high-resolution representation learning for visual recogni-
tion,2020. 4
[11] IrtizaHasan,ShengcaiLiao,JinpengLi,SaadUllahAkram,
and Ling Shao. Pedestrian detection: Domain general- [25] Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu,
ization, CNNs, transformers and beyond. arXiv preprint Gang Niu, and Yang Liu. Learning with noisy labels re-
arXiv:2201.03176,2022. 4 visited: Astudyusingreal-worldhumanannotations,2022.
1
[12] Zhouzhou He, Xi Li, Zhongfei Zhang, Fei Wu, Xin Geng,
Yaqing Zhang, Ming-Hsuan Yang, and Yueting Zhuang. [26] JonasWulffandAntonioTorralba. Improvinginversionand
Data-dependent label distribution learning for age estima- generation diversity in stylegan using a gaussianized latent
tion. IEEETransactionsonImageProcessing,26(8):3846– space. arXivpreprintarXiv:2009.06529,2020. 1
3858,2017. 2 [27] XingchengXu.Gammt:Generativeambiguitymodelingus-
[13] Sara Hooker, Aaron Courville, Gregory Clark, Yann ingmultipletransformers,2023. 2
Dauphin, and Andrea Frome. What do compressed deep [28] Zhuoran Zheng and Xiuyi Jia. Label distribution learn-
neuralnetworksforget? arXivpreprintarXiv:1911.05248, ing via implicit distribution representation. arXiv preprint
2019. 1 arXiv:2209.13824,2022. 2
[14] Davood Karimi, Haoran Dou, Simon K Warfield, and Ali
Gholipour. Deeplearningwithnoisylabels:Exploringtech-
8