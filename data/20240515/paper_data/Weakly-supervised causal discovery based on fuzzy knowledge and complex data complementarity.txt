1
Weakly-supervised causal discovery based on fuzzy
knowledge and complex data complementarity
Wenrui Li, Wei Zhang, Qinghao Zhang, Xuegong Zhang and Xiaowo Wang*
Abstract‚ÄîCausal discovery based on observational data is
A. Prior Work
important for deciphering the causal mechanism behind complex
systems. However, the effectiveness of existing causal discovery Conventional causal discovery methods can be mainly
methods is limited due to inferior prior knowledge, domain categorized into four groups [1], [10], including constraint-
inconsistencies, and the challenges of high-dimensional datasets based methods, score-based methods, hybrid methods and
with small sample sizes. To address this gap, we propose a novel function-based methods. All of them start from a foundational
weakly-supervised fuzzy knowledge and data co-driven causal assumption that the causal structure corresponds to a directed
discovery method named KEEL. KEEL adopts a fuzzy causal
acyclic graph (DAG), and aim to discover the DAG from the
knowledge schema to encapsulate diverse types of fuzzy knowledge,
observational data [11], [12].
and forms corresponding weakened constraints. This schema not
Constraint-based methods uncover causal DAGs by
only lessens the dependency on expertise but also allows various
analyzing conditional independence through statistical tests [1].
types of limited and error-prone fuzzy knowledge to guide causal
discovery. It can enhance the generalization and robustness of For instance, the method CouplaPC is based on Gibbs sampling
causal discovery, especially in high-dimensional and small-sample that integrates the Gaussian Copula model with the PC
scenarios. In addition, we integrate the extended linear causal algorithm [13]. CouplaPC can effectively handle mixed data
model (ELCM) into KEEL for dealing with the multi-distribution and increase the reliability of causal discovery. Another method
and incomplete data. Extensive experiments with different LatentPC combines the mixed latent Gaussian Copula model
datasets demonstrate the superiority of KEEL over several state-
with the PC algorithm [14], which can effectively identify
of-the-art methods in accuracy, robustness and computational
causal structures in mixed data. However, constraint-based
efficiency. For causal discovery in real protein signal transduction
methods require high precision in conditional independence
processes, KEEL outperforms the benchmark method with
limited data. In summary, KEEL is effective to tackle the causal
testing which is hard to achieve [15]. As the dimensionality of
discovery tasks with higher accuracy while alleviating the the data increases, the computational complexity of conditional
requirement for extensive domain expertise. independence tests also rises [16].
Score-based methods find the optimal graph by maximizing
Index Terms‚Äîcausal discovery, complex system, fuzzy knowledge, a scoring function that measures how well the graph fits the
knowledge-data co-driven, weakly-supervised learning observed data [1]. These methods involve searching through a
space of possible graphs to identify the one with the highest
score. For example, CGGES is a causal discovery method based
I. INTRODUCTION
on conditional Gaussian scoring [17], while GGES is a causal
C
AUSAL relationships are the key factors that determine discovery method based on generalized score functions [18].
the behavior and evolution of systems [1], [2]. From the However, these methods have a vast search space, which often
interactions of microscopic particles to the requires heuristic search algorithms which are easily trapped
development of human society, causal relationships are into local optimization. Additionally, both the constraint-based
interwoven throughout all natural and human activities. Causal and score-based methods fail to distinguish between the
discovery refers to the identification of causal relationships Markov equivalence class [19].
between entities within a system using observational data, Hybrid methods combine the constraint-based and score-
which is crucial for understanding and intervening in the based approaches with the aim of improving the accuracy and
functioning of systems [1], [3]. In contrast to correlation computational efficiency [1]. For example, HCM employs a
analyses, causal discovery aims to eliminate confounding score-based method called CVMIC and a constraint-based
effects, elucidating the mechanisms and dependencies behind method named MRCIT, enabling it to learn causal structures
the observed data [4], [5]. It reveals how changes in one from observed mixed-type data [20]. However, hybrid methods
variable can affect others, thereby aiding prediction, generally require to integrate the logic and processes of multiple
intervention, and decision-making across various fields such as approaches, leading to a relatively complex algorithm design
biology [6], medicine [7], economics [8], social sciences [9]. and implementation [21]. Additionally, the performance of
Wenrui Li is with the Department of Automation, Tsinghua University, Xuegong Zhang is with the Department of Automation, Tsinghua
Beijing, 100084, China (e-mail: li-wr23@mails.tsinghua.edu.cn). University, Beijing, 100084, China.
Wei Zhang is with the School of Control Science and Engineering, Xiaowo Wang (Corresponding Author) is with the Department of
Shandong University, Jinan, Shandong, 250061, China. Automation, Tsinghua University, Beijing, 100084, China (e-mail:
Qinghao Zhang is with the Department of Electrical Engineering, Tsinghua xwwang@mail.tsinghua.edu.cn).
University, Beijing, 100084, China.2
Fig. 1. The framework of KEEL.
those integrated methods can disturb each other, leading to an and inalterable understandings of the causal relationships of
even worse result. partial variables (required direct or forbidden causal
Function-based methods discover DAGs using function relationships), it is efficient to discard inconsistent inference
models [10]. These methods can handle more complex causal from the solution set to enhance performance. In cases with
relationships, such as non-linear and multivariable interactions limited available data, knowledge assistance can provide
with high efficiency. For instance, Notears transforms the additional support, filling in data gaps and aiding causal
problem of DAG structure learning into a continuous discovery. However, these methods heavily rely on hard-to-
optimization problem and thus reduces computational obtain reliable expertise and are in the preliminary stage of
complexity [22]. This kind of methods has strong flexibility, converting prior knowledge into strict constraints. There is a
expansibility, and can distinguish Markov equivalence classes, lack a systematical definition and representation of general
thus becoming a research hotspot [23],[24]. However, these knowledge with varying quality. Thus, it is challenging for
methods‚Äô performance depends on the fitness between the these methods to incorporate various knowledges which are
selected model and data, which limits the generalization [10]. usually fuzzy, failing to fully leveraging the potential of a wide
Moreover, their performance suffers under complex data range of knowledge to enhance causal discovery performance.
characterized by high-dimensional and small-sample size Moreover, these methods are unable to adjust imprecise,
which increases the risk of underfitting [25],[26],[27]. uncertain or unsuitable knowledge, thereby constraining
The above-mentioned causal discovery methods encounter flexibility and algorithmic performance. Despite demonstrating
the following common challenges. First, they may overlook or the potential of causal discovery through the combination of
violate fundamental principles and known facts within the knowledge and data, these methods struggle to circumvent the
domain, affecting the credibility of conclusions. [28]. Second, tradeoff between high expertise dependency and the intricacies
they encounter difficulties in addressing high-dimensional and of causal discovery in complex systems.
small-sample data. As the number of variables and interactions
B. Contribution
increase, the risk of false discoveries increases, presenting
To bridge the gaps identified in current causal discovery
computational and statistical hurdles [26], [27], [29].
methods, we propose a weakly-supervised fuzzy knowledge-
Meanwhile, the reliability of existing methods is significantly
data co-driven causal discovery method named KEEL (Fig. 1).
compromised in the limited samples, leading to inaccurate
KEEL synergistically integrates fuzzy knowledge and data,
causal results and diminished robustness [30], [31].
effectively improving the accuracy and computational
To enhance the performance of conventional causal discover
efficiency of causal discovery in complex systems while
methods, knowledge-assisted methods are proposed and gain
reducing the dependency on expertise. KEEL adopts a novel
increasing attentions [32], [33], [34]. These methods utilize
fuzzy knowledge schema that implements weakened
prior knowledge to assist causal discovery. Such knowledge
knowledge constraints from fuzzy knowledge. This schema
may come from expert judgments, literature or experimental
supports knowledge correction and supplementation thorough
results. By integrating prior knowledge, knowledge-assisted
interaction with data, thus allowing diverse knowledge types
methods can eliminate unreasonable assumptions, effectively
with varying quantities, purity, precision and certainty levels
reducing the search space and computational complexity in the
(even limited and error-prone) to guide the causal discovery
high-dimensional scenario. For instance, if there are explicit
process, significantly expanding the generalization. In addition,3
the utilization of ELCM in KEEL enables adaptability to mutually independent., i.e.:
diverse data types in the real world. In-depth theoretical ùëã:=ùõΩTùëã +ùúÄ, ùúÄ~P(ùúÄ). (1)
i i PAi i i i
analysis demonstrates the efficacy of KEEL, highlighting its
Assumption 3: Discrete variable ùëã takes the value of 1 when
i
superior theoretical reliability compared to traditional methods.
the linear function of its parent ùëã and any distributed latent
Experiments with synthetic data demonstrate that, even with
PAi
variable ùúÄ exceeds 0. The latent variables are continuous and
increased system complexity and a reduction in the quality of i
mutually independent., i.e.:
knowledge, KEEL maintains high levels of accuracy and
1, ùõΩTùëã +ùúÄ >0
robustness. This is particularly evident for high-dimensional, ùëã ‚âî{ i PAi i , ùúÄ~P(ùúÄ). (2)
small-sample dataset. Additional validation on the real protein i 0, ùõΩTùëã +ùúÄ ‚â§0 i i
i PAi i
signal transduction dataset further highlights the advantages of Definition 1: The data generation model fulfilling these
KEEL in practical applications. The main contributions of this assumptions is called the extended linear causal model
article are as follows. (ELCM), i.e.:
1Ôºâ We propose a novel formal definition and ùëã ‚âîùëì(ùõΩTùëã +ùúÄ), ùúÄ~P(ùúÄ), (3)
i i i PAi i i i
representation of fuzzy causal knowledge, maximizing
where symbol ‚âî denotes a one-way relationship. ùëã =
the utility of available knowledge with varying quality.
PAi
[ùëã ,ùëã ,‚Ä¶,ùëã ]T is the p-dimension parent variables of
This approach formalizes 7 common types of fuzzy PAi1 PAi2 PAip
ùëã,and ùõΩ is a ùëù√ó1 vector quantifying the direct causal effect
knowledge. To our best knowledge, it is the first time i i
of ùëã on ùëã. ùúÄ represents the continuous latent variable which
to systematically define the fuzzy causal knowledge PAi i i
formalization. It provides the theoretical basis for contributes to ùëã i, following any distribution ùëÉ(ùúÄ i). If ùëã i is
weakly supervised causal discovery which incorporate continuous, ùëì is the identity function. If ùëã is discrete, ùëì is a
i i i
fuzzy knowledge to enhance accuracy, robustness, and step-like function with a zero value at the threshold.
computational efficiency in complex systems. Based on this model, we propose an objective function to
2Ôºâ We propose weakened constraints to incorporate minimize:
different types of fuzzy knowledge. This enables the ùëì(ùë©,ùúΩ)=‚àílnùêø(ùë©,ùúΩ|ùëã)=‚àílnùëù(ùëã|ùë©,ùúΩ),
weakly supervised causal discovery which is where
characterized by the simultaneous optimization of ùê∑
discovering DAGs from observational data and refining ùëù(ùëã|ùë©,ùúΩ)=‚àèùëù bi(ùëã i|ùëã PAi,ùúΩ Œµi)ùëßiùëù ci(ùëã i|ùëã PAi,ùúΩ Œµi)1‚àíùëßi
fuzzy knowledge, thus reducing the reliance of i=1
ùê∑ ùëÅ
expertise.
=‚àè‚àè(1‚àíùêπ (‚àíùõΩTùë• |ùúΩ
))ùë•inùëßi
¬∑
3Ôºâ We propose an extended linear causal model (ELCM) bi i PAin Œµi
with identifiability proof as well as its corresponding ùëñ=1 ùëõ=1
optimization as the center of KEEL to capture causality ùêπ bi(‚àíùõΩ iTùë• PAin|ùúΩ Œµi)(1‚àíùë•in)ùëßi¬∑
patterns of data. This model is adaptable to mixed
(ùëì (ùë• ‚àíùõΩTùë• |ùúΩ
))1‚àíùëßi
, (4)
discrete and continuous data with various distributions ci in i PAin Œµi
ùë© is the adjacency matrix of the weighted DAG. ùúΩ is the
in the presence of latent variables, thus extending the
identifiable space and application scales of KEEL. parameter for the latent variable probability function. ùë• in is the
ùëõ-ùë°‚Ñé sample of variable ùëã. N is the sample size. ùëù and ùëù
i bi ci
II. METHODOLOGY represent the probability and probability density functions for
the discrete and continuous variables, respectively. ùëß is an
In this section, we offer the theoretical motivation and formal ùëñ
indicator variable, assigning 1 if ùëã is a discrete variable and 0
definition of KEEL. We begin by introducing the ELCM as the i
otherwise. ùêπ and ùëì represent the probability distribution
cornerstone of KEEL. The incorporation of ELCM enables bi ci
function and the density function of the latent variables for
KEEL to conduct causal discovery in scenarios involving multi-
discrete and continuous variables, respectively.
distribution and incomplete data. Furthermore, we formalize 7
Based on (4), we solve the following optimization problem
distinct common types of fuzzy knowledge and convert them into
to ensure sparsity and acyclicity:
weakened constraints.
min ùêø (ùë©,ùúΩ)=ùëì(ùë©,ùúΩ)+‚Äñùõ¨‚ãÖùë©‚Äñ , (5)
ùë© ùõ¨ 1
A. Extended Linear Causal Model
subject to
For simplification, we consider the case where all discrete
‚Ñé(ùë©)=0.
variables are binary, and make the following assumptions:
Assumption 1: The generation mechanism of all research Here, ‚Ñé(ùë©) ensures that the directed graph corresponding to B
variables is faithful to a weighted DAG G, where nodes is acyclic. Œõ is the regularization parameter matrix which
represent the research variables and edges represent their causal allows distinct parameters for different edges. l 1-regularization
relationships. ‚Äñùõ¨‚ãÖùë©‚Äñ =‚Äñvec(ùõ¨‚ãÖùë©)‚Äñ is applied to avoid overfitting.
1 1
Assumption 2: Continuous variable ùëã has a linear Notably, the element ùëè of B quantifies the direct causal effect
i i,j
relationship with its parents ùëã and latent variable ùúÄ following of ùëã on ùëã assuming there are no confounding variables. ùëè =
PAi i i j i,j
any distribution ùëÉ(ùúÄ). The latent variables are continuous and 0 indicates the absence of a causal relationship, implying no
i4
edge from ùëã to ùëã. Conversely, ùëè ‚â†0 suggests the potential Definition 4: Assume each fuzzy causal knowledge
i j i,j
existence of a causal relationship, indicating an edge from ùëã to correspond to a fuzzy causal mechanism ùëÑ. ùëÑ is a quintuple
i
ùëã. Following the optimization method proposed by Zheng et (ùêè,ùêÇ,ùêπ,ùêå,ùêã), where ùêè is a non-empty set of parent variables,
j
al. [22], we employ augmented Lagrange method to convert (5) ùêÇ is a non-empty set of child variables, ùêπ is the fuzzy causal
into the unconstrained function (6). The L-BFGS algorithm is function, ùêå is the set of the mediating variables in ùêπ, and ùêã is
then used to solve it [35]. Here, ùúå is penalty parameter and ùõº is the corresponding set of the mediation steps.
Lagrange multiplier. Due to the limitations of machine Notation 1: In this paper, we denote a fuzzy causal
precision, ùëè is not precisely zero [22]. Therefore, we introduce knowledge as K and the corresponding fuzzy causal mechanism
i,j
as ùëÑ . The variable representing entity T is denoted as ùëâ .
a threshold ùúè and set ùëè to zero for values smaller than ùúè in K T
i,j
Supposing S is the set of statements implying fuzzy causal
absolute terms.
knowledge, F from ùöø to ùõÄ is denoted as ùêπ . The crisp set of
ùëÜ
min max ùêø (ùë©,ùúΩ,ùõº)=ùëì(ùë©,ùúΩ)+‚Äñùõ¨‚ãÖùë©‚Äñ + ùöø‚ÜíùõÄ
ùë© Œ± ùõ¨,ùúå 1 research variables N, and the target variables X and Y are
ùúå
ùõº ‚Ñé(ùë©)+ |‚Ñé(ùë©)|2. (6) denoted as N, X and Y, respectively. Both X and Y are subsets
2
of N.
When the prior knowledge is available, we replace Example 1: K: The promotion on Black Friday stimulates
‚Äñùõ¨‚ãÖùë©‚Äñ 1 by a prior causal knowledge constraint ùêø know (see consumption.
Section II.B). Thus, Equation (6) can be reformulated as:
ùëÑ :ùë∑={ùëâ }, C={ùëâ }, S={stimulate},
min max ùêø (ùë©,ùúΩ,ùõº)=ùëì(ùë©,ùúΩ)+ùêø + K promotion consumption
ùë© Œ± ùõ¨,ùúå know
ùúå ùêπ =ùêπ , ùúá (ùëâ ,ùëâ )>0.5, M=‚àÖ, L=‚àÖ.
ùõº ‚Ñé(ùë©)+ |‚Ñé(ùë©)|2. (7) ùêè‚ÜíùëÜ ùêÇ ùêπ promotion consumption
2
For more examples of Definition 4-4.5, please see
For the proof of causal direction identifiability of ELCM as
Supplementary Materials.
well as the Optimization details of KEEL, please see
Definition 4.1: A fuzzy causal knowledge K is called EOP
Supplementary Materials. 1
(exposure and outcome property) if it corresponds to a ùëÑ such
K1
B. Incorporate Fuzzy Causal Knowledge that:
Knowledge about causal relationships is generally fuzzy, P=N, C=X, ùúá (ùëÅ,ùëã)<0.5 or P=X, C=N, ùúá (ùëã,ùëÅ)<0.5;
ùêπ ùêπ
with fuzzy knowledge easier to acquire but more difficult to
M=‚àÖ, L=‚àÖ.
process. To circumvent this tradeoff, we propose the fuzzy
Definition 4.2: A fuzzy causal knowledge K is called ETE
knowledge schema. Specifically, we formulate various types of 2
(end to end) if it corresponds to a ùëÑ such that:
fuzzy causal knowledge and the corresponding weakened K2
constraints, thus incorporating knowledge which may be ùêè=ùêó,ùêÇ=ùêò,ùúá ùêπ(ùëã,ùëå)‚âä1,
uncertain or imprecise to guide the causal discovery process. M={(ùëÅ,ùúá (ùëÅ))|ùëÅ ‚ààùêç},
ùêå
These constraints can be applied individually or in combination
based on task requirements and available knowledge. Thus, we L={((ùëÅ i,ùëÅ j),ùúá ùêã((ùëÅ i,ùëÅ j)))|ùëÅ i ‚ààùêç,ùëÅ j ‚ààùêç,i‚â†j}.
can specify ùêø in (7) to form the constrained optimization.
know Definition 4.3: A fuzzy causal knowledge K 3 is called CCE
Definition 2 [36]: For a given universe of discourse X, a
(conditional cause and effect) if it corresponds to a ùëÑ such
K3
fuzzy set ùê¥ is defined as:
that:
ùê¥={(ùë•,ùúá ùê¥(ùë•))|ùë• ‚ààùëã} P=X, C=Y,ùúá ùêπ(ùëã,ùëå)>0.5, M=‚àÖ, L=‚àÖ
where ùúá :ùëã ‚Üí[0,1] is the membership function of ùê¥ . Remark 1: On the one hand, a conditional cause is a
ùê¥
ùúá (ùë•) denotes the degree of membership of ùë• in ùê¥. potential cause that has a lower likelihood of leading to a
ùê¥
Definition 3: ùöø={ùõπ} and ùõÄ={ùõ∫} are two non-empty specific outcome. On the other hand, relationships that
i i‚ààI j
j‚ààJ
supported by such knowledge are more likely to be causal
sets, and ùëÉÃÉ(ùõÄ) is the fuzzy power set of ùõÄ. Fuzzy causal
compared to those lack knowledge assurance. Conditional
function F from ùöø to ùõÄ is the mapping of ùöø into ùëÉÃÉ(ùõÄ) such
causality is often observed in situation where plausible causal
that for ‚àÄ(ùõπ,ùõ∫)‚ààùöø√óùõÄ, ùúá (ùõ∫)=ùúá (ùõπ,ùõ∫),
ùêπ(ùõπ) ùêπ networks or subnetworks provide a broad understanding of
where ùúá (ùõπ,ùõ∫) is the membership of ùõπ causing ùõ∫.
ùêπ causality, even though there may be exceptions or oversights in
Corollary 1:ùúá (ùõπ,ùõ∫) is the degree to which the relation of
ùêπ certain cases. For example, causal knowledge derived from a
ùõπ to ùõ∫ satisfies the causality property in research domains.
knowledge graph can effectively demonstrate conditional
ùúá (ùõπ,ùõ∫)=0 implies the relation from ùõπ to ùõ∫ is exactly non-
ùêπ causality.
causal, while ùúá (ùõπ,ùõ∫)=1 implies the relation from ùõπ to ùõ∫ is
ùêπ Definition 4.4: A fuzzy causal knowledge K is called BNC
4
exactly causal. Considering 0<ùúá (ùõπ,ùõ∫)<1, ùúá (ùõπ,ùõ∫)>
ùêπ ùêπ (basically noncausal) if it corresponds to a ùëÑ such that:
K4
1‚àíùúá (ùõπ,ùõ∫),i.e.ùúá (ùõπ,ùõ∫)>0.5 implies the relation from
ùêπ ùêπ P=X, C=Y,ùúá (ùëã,ùëå)<0.5,
ùõπ to ùõ∫ is not exactly causal, while ùúá (ùõπ,ùõ∫)<0.5 implies the ùêπ
ùêπ
relation from ùõπ to ùõ∫ is not exactly non-causal. Otherwise, M={(ùëÅ,ùúá ùêå(ùëÅ))|ùëÅ ‚ààùêç},
ùúá ùêπ(ùõπ,ùõ∫)=0.5 implies no constructive opinions about causal L={((ùëÅ ùëñ,ùëÅ ùëó),ùúá ùêã((ùëÅ ùëñ,ùëÅ ùëó)))|ùëÅ
ùëñ
‚ààùêç,ùëÅ
ùëó
‚ààùêç,ùëñ ‚â†ùëó}.
relation from ùõπ to ùõ∫, indicating maximum fuzziness.
Remark 2: This knowledge is a belief that two target5
variables is basically noncausal. With this belief, it is preferable of hops, and paths from ùë• to ùë¶ are unclear. Therefore, we
to exclude potential spurious causality, such as confounding constrain the condition holds: there exists at least a k-length
effects and data selection bias. It indicates unnecessary or path from ùë• to ùë¶, where ùëò <ùê∑ and ùê∑ is the number of nodes.
incorrect inferences about causal mechanisms. For the graph‚Äôs binary adjacency matrix ùë®, (ùë®ùëò) equal to
i(ùë•), i(ùë¶)
Definition 4.5: A fuzzy causal knowledge K 5 is called UCD the number of k-length paths from ùë• to ùë¶. Thus, such condition
(unknown causal direction) if it corresponds to a ùëÑ K5 such that: holds if and only if ‚àëùê∑ ùëò=‚àí 01(ùë®ùëò) i(ùë•), i(ùë¶)>0. To generalize this to
P={(ùëã,ùúá (ùëã)),(ùëå,ùúá (ùëå))|ùëã ‚ààùêó,ùëå‚ààùêò},
ùêè ùêè adjacency matrix ùë© with both positive and negative values and
C={(ùëã,ùúá (ùëã)),(ùëå,ùúá (ùëå))|ùëã ‚ààùêó,ùëå‚ààùêò}, simplifies the power sum, we derive the constraint:
ùêÇ ùêÇ
ùúá (ùëã)+ùúá (ùëã)=1,ùúá (ùëå)+ùúá (ùëå)=1, (ùêº+ùë©‚Ä¢ùë©)ùê∑‚àí1 >0,
ùêè ùêÇ ùêè ùêÇ i(ùë•),i(ùë¶)
ùúá ùêè(ùëã)+ùúá ùêè(ùëå)=1,ùúá ùêπ(ùëã,ùëå)=1, and the penalty function:
M=‚àÖ, L=‚àÖ.
|min (0,(ùêº+ùë©‚Ä¢ùë©)ùê∑‚àí1 ‚àíùë†)|ùõº,ùõº =1,2.
Remark 3: This knowledge gives two causal connected i(ùë•),i(ùë¶)
entity ùëã and ùëå, but provide insufficient evidence or no where ùë† is the slack variable, ùë†>0. We discover the paths
preference for ùëã cause ùëå or vice versa. It indicates the cause- from ùë• to ùë¶ and the rest of the graph structure fitting the data
and-effect pairs to be further investigated, reducing the pattern in the constraint domain.
likelihood of no-correlation and spurious causality due to CCE: In the causal DAG, this fuzzy knowledge indicates that
confounder. the edge from node ùë• to ùë¶ is more likely to exist but lacks
Remark 4: To generalize the fuzzy causal knowledge and confidence. On the one hand, compared to general potential
mechanism pairs (K,ùëÑ ), we can also represent the crisp edges, such an edge is more likely to be identified, so we push
K
knowledge about required direct or forbidden causal its weight away from zero. On the other hand, there lacks
relationships in our fuzzy schema. A causal knowledge about evidence supporting this high likelihood of existence, so we
direct causal relationships (DC) from X to Y can be interpreted push its weight towards zero. For sparsity, all potential edges‚Äô
as a fuzzy causal knowledge K
6
with ùëÑ K6=(ùêó,ùêò,ùêπ,‚àÖ,‚àÖ) where existence has an l 1-penalty with a penalty coefficient of ùúî 1.
ùúá (ùëã,ùëå)=1. A causal knowledge about forbidden causal Since the existence of such an edge is based on a higher
ùêπ
relationships (FC) from X to Y can be interpreted as a fuzzy likelihood, its penalty should be smaller than that for general
causal knowledge K with ùëÑ = (ùêó,ùêò,ùêπ,‚àÖ,‚àÖ) where potential edges. Therefore, edges supported by CCE are
7 K7
ùúá (ùëã,ùëå)=0. assigned a smaller penalty coefficient than those without such
ùêπ
support. The penalty function corresponding to this trade-off is:
1 1
|ùë© | ‚àíùõΩmax (0,|ùë© | ),
i(ùë•),i(ùë¶) i(ùë•),i(ùë¶)
where 0<ùõΩ ‚â§1,ùõΩ ‚âä1. Namely, the penalty function is:
1
1
|ùë© | ,
ùõæ i(ùë•),i(ùë¶)
where ùõæ ‚â´1.
BNC: In the causal DAG, this fuzzy knowledge indicates that
node ùë¶ is not reachable from node ùë•, yet it still potentially
Fig. 2. DAG representation of fuzzy causal knowledge
considers that node ùë¶ is reachable from node ùë•. Therefore, we
We incorporate these 7 types of fuzzy causal knowledge (Fig. make a constraint:
2) as weakened constraints in the causal discovery process. This (ùêº+ùë©‚Ä¢ùë©)ùê∑‚àí1 =0,
i(ùë•),i(ùë¶)
enables the complementary integration of knowledge and data.
with tolerance to violation. The penalty function is:
Thus, fuzzy knowledge helps to improve accuracy and
computational efficiency, while data helps to correct and |(ùêº+ùë©‚Ä¢ùë©)ùê∑‚àí1 |ùõº,ùõº =1,2.
i(ùë•),i(ùë¶)
supplement knowledge.
It tends to exclude the possibility that there exists a path from
We denote the row/column index of node ùë• as i(ùë•). We
node ùë• to ùë¶. Thus, it helps to distinguish weakly connected
denote |ùë©|1 =‚Äñvec(ùë©)‚Äñ , |ùë©|2 =‚Äñùë©‚Äñ2.
1 ùêπ (confounding structure (ùë• ‚Üêùëõ‚Üíùë¶), colliding structure (ùë• ‚Üí
EOP: In the causal DAG, this fuzzy knowledge indicates that
ùëõ‚Üêùë¶)) and unconnected structure (ùë• ùëõ‚Üíùë¶) from path (ùë• ‚Üí
the node ùë• representing target variable X tends to have no
ùëõ‚Üíùë¶ ). It can narrow down solution space and reduce
ancestors, or the node ùë¶ representing target variable Y tends to
unexpected discovered paths from observational data.
have no descendants. Therefore, we penalize the in-degree of ùë•
Meanwhile, it allows for emerging paths countering to common
and the out-degree of ùë¶, making the corresponding edge
sense but with strong data support.
weights approach zero. The penalty function can be articulated
UCD: In the causal DAG, this fuzzy knowledge implies the
as follows:
presence of an edge with node ùë• and ùë¶ as endpoints, but its
|ùë© |ùõº+|ùë© |ùõº,ùõº =1,2.
*,i(ùë•) i(ùë¶),* direction is uncertain. Therefore, we constrain that there exists
ETE: In the causal DAG, this fuzzy knowledge indicates that an edge between node ùë• and ùë¶, regardless of its direction.
node y is reachable from node x, but the hops, topological order
Namely, the constraint is that the edge weight ùëè and
i(ùë•), i(ùë¶)6
Fig. 3. The performance of different methods in Case A, Dataset1. The evaluation considers varying node numbers, average degree, binary
ratio (BR), and sample size. The circle size represents the relative magnitude of the standard deviation.
ùëè cannot both be zero: local causal direction identification of targeted bivariate pairs.
i(ùë¶), i(ùë•)
Moreover, it can embed partially modifiable graph skeleton.
ùëê =0,
Thus, it aids in reducing solution space, decreasing omissions
where
of inferred edges, and can be used in finetuned causal discovery
1,ùëñùëì |ùëè |=0 ùëéùëõùëë |ùëè |=0 with putative multivariate graph skeletons.
ùëê ={ i(ùë•),i(ùë¶) i(ùë¶),i(ùë•) .
0,ùëúùë°‚Ñéùëíùëüùë§ùëñùë†ùëí DC: The direct edge from node ùë• to ùë¶ can be explicitly
The penalty function is: determined. It can be bounded that the edge weight from node
ùë• to node ùë¶ is greater than the threshold:
|[max(0,ùúè‚àí|ùë©|)‚Ä¢max (0,ùúè‚àí|ùë©T|)] |ùõº,ùõº =1,2,
i(ùë•),i(ùë¶)
ùë© ‚â•ùúè.
where ùúè is the threshold, ùúè>0. This penalty function being
i(ùë•),i(ùë¶)
equal to zero stipulates that at least one of the following is true: FC: It is explicitly indicated that there is no direct edge from
the edge weight from node ùë• to ùë¶ surpasses the threshold, or the node ùë• to ùë¶. It can be bounded that the edge weight from node
ùë• to ùë¶ is zero:
edge weight from node ùë¶ to ùë• does so. Notably, the acyclicity
constraint in (5) prevents a mutual causal loop between node ùë• 0‚â§ùë© ‚â§0.
i(ùë•),i(ùë¶)
and node ùë¶. It implies that bi-direction cannot hold. Therefore,
combined with the acyclicity constraint, this penalty tries to III. RESULTS AND DISCUSSIONS
ensure there is one and only one directed edge. It pays more
In this section, we validate the effectiveness and advantages
attention to putative edges, while using data to conduct
of KEEL through a series of comparative experiments, followed
refinement, test or correction. Thus, it enables simultaneous
by the comparison with eight state-of-the-art causal discovery7
Fig. 4. The performance of different types of weakened constraints in Case B, Dataset 1. The evaluation considers varying node numbers,
average degree, binary ratio (BR), and sample size. The circle size represents the relative magnitude of the standard deviation.
methods on synthetic datasets simulating different scenarios, equivalence class. Additionally, we compare KEEL with
including high-dimensional and small-sample situations and Notears which learns continuous DAGs by modeling discrete
different data distributions. We also investigate the impact of variables as Gaussian distributions. The other 6 methods
knowledge constraints on improving global accuracy and local arecapable of handling mixed data types.
interpretability, highlighting the advantages of utilizing fuzzy The accuracy of causal discovery is evaluated using the
knowledge. In addition, we demonstrate that integrating diverse following metrics: true positive rate (TPR), false discovery rate
types of knowledge constraints can further enhance the (FDR), and structure hamming distance (SHD). TPR and FDR
performance, suggesting that all types of knowledge provide values range between 0 and 1. Higher TPR, along with lower
unique benefits without redundance. Moreover, the robustness FDR and SHD indicate improved accuracy. For datasets
of KEEL is assessed under varying levels of knowledge noise generated from DAGs with 10 and 30 nodes, the average
and quantity. Finally, we validate KEEL on real bioinformatics metrics are calculated over 10 random replicates. For datasets
data, and discover the protein signaling transduction network. derived from DAGs with 100 nodes, these metrics are averaged
over 3 random repetitions. Both the mean values and standard
A. Benchmarking Methods and Evaluation Metrics
deviations for those metrics are calculated.
We perform a comparison between KEEL and 8 benchmark
methods. These include constraint-based methods (CouplaPC B. Synthetic Datasets with Various Knowledge Type
and LatentPC), score-based methods (CGGES, GGES, and We adopt the ER model for random DAG generation,
CGHC), hybrid methods (HCM and MMHC) and a function- sampling edges independently and uniformly without
based method (Notears). We evaluate KEEL against MMHC replacement. The edge weights follow uniform distributions
which learns discrete CPDAGs by discretizing continuous within the intervals [-2, -0.5] and [0.5, 2]. This procedure yields
variables and selecting the optimal DAG from the Markov weighted DAGs and their corresponding adjacency matrix B.8
Table 1. The improvement of global accuracy and local interpretability for adding ETE and UCD
ETE UCD
Scenario
FDR TPR CP Prop FDR TPR CD Prop
N50 0.287 ¬± 0.165 0.841 ¬± 0.142 0.524 ¬± 0.382 0.287 ¬± 0.165 0.912 ¬± 0.078 0.771 ¬± 0.343
Sparse N500 0.025 ¬± 0.043 0.950 ¬± 0.050 1.000 ¬± 0.000 0.025 ¬± 0.043 0.967 ¬± 0.047 1.000 ¬± 0.000
N5000 0.150 ¬± 0.050 0.850 ¬± 0.050 1.000 ¬± 0.000 0.150 ¬± 0.050 0.950 ¬± 0.050 1.000 ¬± 0.000
BR 0.1
N50 0.122 ¬± 0.070 0.653 ¬± 0.112 0.704 ¬± 0.328 0.122 ¬± 0.070 0.900 ¬± 0.050 0.671 ¬± 0.303
Dense N500 0.055 ¬± 0.066 0.706 ¬± 0.103 0.830 ¬± 0.154 0.055 ¬± 0.066 0.914 ¬± 0.113 0.893 ¬± 0.182
N5000 0.058 ¬± 0.055 0.713 ¬± 0.100 0.750 ¬± 0.250 0.058 ¬± 0.055 0.936 ¬± 0.051 0.809 ¬± 0.350
N50 0.149 ¬± 0.099 0.763 ¬± 0.116 0.709 ¬± 0.378 0.149 ¬± 0.099 0.800 ¬± 0.176 0.648 ¬± 0.355
Sparse N500 0.032 ¬± 0.053 0.819 ¬± 0.079 0.696 ¬± 0.301 0.032 ¬± 0.053 0.889 ¬± 0.110 0.815 ¬± 0.266
N5000 0.059 ¬± 0.059 0.819 ¬± 0.088 0.577 ¬± 0.434 0.059 ¬± 0.059 0.920 ¬± 0.108 0.850 ¬± 0.320
BR 0.5
N50 0.163 ¬± 0.097 0.522 ¬± 0.094 0.462 ¬± 0.168 0.163 ¬± 0.097 0.838 ¬± 0.042 0.762 ¬± 0.119
Dense N500 0.113 ¬± 0.077 0.631 ¬± 0.140 0.393 ¬± 0.190 0.113 ¬± 0.077 0.833 ¬± 0.085 0.686 ¬± 0.146
N5000 0.160 ¬± 0.119 0.610 ¬± 0.126 0.554 ¬± 0.276 0.160 ¬± 0.119 0.925 ¬± 0.075 0.750 ¬± 0.250
Cp Prop refers to the proportion of iterations that correctly identify complete paths when traversing the path endpoints that are overlooked without applying the ETE
constraint. CD Prop refers to the proportion of correctly identified causal directions in skeletons that are overlooked without applying the UCD constraint. This table reports
the ‚Äòmean +/- standard deviation‚Äô of performance metrics across 10 runs on 10 nodes DAGs.
Each column vector in B corresponds to a variable ùëã, of which comparative analysis with the random noisy knowledge graph.
i
non-zero weight coefficients indicate the parent variables of On Dataset 1, we consider the following cases and conduct
ùëã.For the generated DAGs, we create Dataset 1 and Dataset 2 experiments.
i
via ELCM. For scenarios that require a knowledge graph as the Case A: KEEL-without knowledge (denoted as KEEL_wk)
fuzzy knowledge source in Dataset 1, we simulate synthetic is compared with benchmark methods that lack prior
knowledge graphs. knowledge. Additionally, by incorporating CCE constraints
1) Dataset 1 from a random noisy knowledge graph, we demonstrate the
To comprehensively evaluate the effectiveness of various benefits of integrating fuzzy knowledge.
causal discovery methods, we simulate DAGs with varying Case B: We compare KEEL_wk with all seven constraints
node numbers and average degree, as well as the corresponding mentioned above to analyze the impact of different knowledge
datasets with varying binary ratio and sample size. constraints on global accuracy, including the cases of a random
To investigate the impact of increasing node numbers on noisy knowledge graph and an APG noisy knowledge graph.
performance, we simulate DAGs with 10, 30, and 100 nodes, Additionally, we investigate the impact of knowledge
respectively. To evaluate how different levels of edge sparsity constraints on improving local interpretability. This is achieved
affect performance, we consider two scenarios of sparse and by highlighting the efficacy of the ETE constraint in identifying
dense DAG. For sparse DAGs, the average degree is set to 2 for causal chains and the UCD constraints in in identifying cause
D=10, and 4 for both D=30 and D=100. For dense DAGs, it is and effect.
set to 4 for D=10 and 10 for D=30 and D=100. The latent Case C: We generate EOP and CCE and evaluate the
variables in this study are generated from the standard Gaussian performance of KEEL under individual and combined
distribution. We vary the proportion of discrete nodes to 0.1 and constraints.
0.5. The sample sizes are set as 50, 500, and 5000 to evaluate Case D: We generate random noisy knowledge graphs of
performance under conditions of data scarcity and sufficiency. various sizes by sampling true edges at 10%, 30%, 50%, 70%,
We construct partial knowledge graphs with noise. Positive and 90%. Simultaneously, we simulate noise by sampling
edges for simulating knowledge are randomly selected from the different ratios of edges from the set of non-true edges (1%, 2%,
true edge set, with probabilities ranging from 0.1 to 0.9. False 5%, and 10%). This is used to compare the effect of different
positive edges for simulating noise are randomly selected with noise levels on the performance of KEEL under the CCE
probabilities between 0.01 and 0.1. This synthetic knowledge constraint.
graph is referred to as a random noisy knowledge graph and 2) Dataset 2
serves as the default setting. Additionally, considering that Similar to Dataset 1, we generate DAGs with 30 nodes with
relationships with stronger causal effects are more likely to be varying sparsity and the corresponding datasets with varying
established, we further design sampling strategy based on edge binary ratios and sample sizes. Based on this, we adjust the
weights. In details, the weight interval [0.5, 2] is transformed to distributions of the latent variables, assigning the matched or
the interval [-2.5, 2.5], and a sigmoid function is used to derive mismatched distribution assumptions to KEEL_wk to assess the
the sampling probabilities for the positive edges. This synthetic its scalability.
knowledge graph is termed as APG (absolute probability Gaussian-Gaussian: All latent variables follow a Gaussian
sampling generated) noisy knowledge graph, designed for distribution. First, we test the performance of KEEL with12
Fig. 5. Discovered protein signal transduction network. (A) The original result derived from the original dataset. The PIP3-Plcr connection is
mistakenly identified in the opposite direction. (B) The results obtained by the KEEL_CCE on the observational data.
matched assumptions. Second, we test the performance with The results in Fig. 4 highlight the effects of the different
mismatched assumptions that continuous variables are types of weakened constraints on improving the accuracy of
generated from Laplace latent variables, while discrete causal discovery. Overall, the proposed knowledge constraints
variables come from Logistic latent variables. robustly improve the accuracy of causal discovery across
Cauchy-Gaussian: Cauchy distributed latent variables for various scenarios. These constraints led to an increase in TPR
the continuous variables and Gaussian distributed latent ranging from 2.5% to 31%, and a decrease in FDR ranging from
variables for the discrete variables. First, we test the 0.1% to 34%. Among them, the CCE constraint show the most
performance of KEEL with the matched assumptions. Second, significant improvement, with its advantage becoming more
we test the performance with the mismatched assumptions that evident with increasing data dimensionality, decreasing sample
all the variables generated from Gaussian distributed latent size, and increasing binary ratios. Additionally, we find that
variables. strict constraints on direct causal relationships might interfere
with the discovery of other relationships. For example, while
C. Results for Synthetic Datasets
the FC constraint also reduces FDR and SHD, its improvement
1) Results of Case A of Dataset 1
in TPR is inconsistent. Introducing the DC constraint can
From Fig. 3, it is evident that KEEL outperforms other
increase TPR, especially with small to medium sample sizes,
methods. In high-dimensional graphs, the parent set of a node
but it also carries a risk of increasing FDR and SHD. Therefore,
may exceed 10, and the size of the adjacency matrix may reach
introducing crisp knowledge does not always guarantee better
100√ó100, with each directed edge potentially interacting with
performance. It may lead to overly strict and redundant
others, making the probability space vast and the DAG
constraints, undermining overall accuracy. Loosening
identification challenging for all methods. The constraint-based
constraints appropriately helps to fully explore the valuable
methods may struggle due to statistical test limitations and the
information within the data, which is in line with the initial
score-based methods fail to distinguish Markov equivalence
intention of introducing weakened constraints in this study.
class and may suffer from high computational complexity. For
It is worth noting that some constraints are effective in
instance, GGES fails to scale to 100 nodes and dense scenarios
explaining local structures. For example, in low-dimensional
due to its unacceptable computational complexity. The
scenarios, the ETE and UCD constraints improve TPR while
performance of function-based methods suffers when
FDR and SHD remained relatively stable. In medium and high-
confronted with multi-distributed incomplete data due to the
dimensional scenarios, these constraints can reduce overall
model assumptions may not hold. Additionally, identifying
accuracy, primarily due to oversampling of redundant relations
causal graph from observed data is hard not only due to high
and prioritizing local structure accuracy. Further study on the
dimensionality and limited sample size, but also because the
local interpretability of ETE and UCD find that ETE increases
causal identifiability is only ensured under specific conditions
the likelihood of correctly identifying the complete path, while
in theory. In contrast, KEEL can handle various types of mixed
UCD helps accurately identify causal directions within
data and exhibits stable performance as the number of nodes
multivariable undirected graph skeletons (Table 1).
and edges increases and the sample size decreases. Additionally,
Overall, we can confirm the effectiveness of all proposed
compared to KEEL_wk, KEEL with weakened knowledge
constraints. It is concluded that the proposed fuzzy knowledge
constraints consistently achieve optimal performance. It
formalization schema enables knowledge of various precision
indicates that the proposed knowledge constraints can
and certainty levels to facilitate causal discovery. It reduces the
effectively complement data, extend the causal identifiable
reliance on expertise and expands the scope of prior information
space, and improve the accuracy and efficiency of causal
that can be utilized to enhance the accuracy. Additionally, it
discovery in high-dimensional and small-sample data scenarios.
aids in identifying complete causal chains and cause-effect
2) Results of Case B of Dataset 1
( A )
P P 2
P lc
P P 3
n k
P 3 8
P
A
P
A
k t
R a f
e k
rk
( B )
P P 2
P
P
lc
P 3
n k
P 3 8
P
P A
A k t
R a f
e k
rk
P
P
R
N
h o s
h o s
r u e
e v e
is se
w
p
p
r
e
h
h
s e
d
o
o
d
-
-
P r o
ip
te
id
in
s
s11
Table 2. Sachs Result
Scenario FDR TPR SHD NNZ Scenario FDR TPR SHD NNZ
opulaP 0.42 0.35 18 12 eel- OP 0.28 0.65 10 18
atentP 0.42 0.35 18 12 eel- 0.07 0.65 8 14
GG S 0.50 0.35 20 14 Keel-CCE 0.09 1.00 2 22
GG S 0.59 0.45 22 22 eel-BN 0.18 0.70 9 17
GH 0.44 0.50 21 18 eel-U D 0.21 0.75 8 19
H 0.47 0.40 20 15 eel-D 0.26 0.70 10 19
H 0.70 0.15 18 10 eel-F 0.24 0.65 10 17
Notears 0.57 0.30 15 14 Sachs_observational 0.20 0.40 12 10
Notears- P 0.63 0.30 16 16 Sachs_interventional 0.06 0.80 4 17
eel-wk 0.20 0.60 10 15 eel- OP 0.28 0.65 10 18
relationships within fixed graph skeletons, suggesting its results in decreased performance. Therefore, the ability of
applicability to a broader range of causal-related tasks. KEEL to effectively handle variables with various distributions
3) Results of Case C of Dataset 1 provides a significant advantage in the field of causal discovery.
As shown in Supplementary Fig. S1, the performance
D. Real-World Application
improvement gained from combining two knowledge
Next, we apply KEEL to analyze the Sachs dataset [39]. This
constraints exceeds the effect of any single constraint. This
dataset consists of a validated protein signaling network with
suggests that different knowledge constraints contain unique
information, and their combination can further enhance the 20 connections (edges). The original interventional-
observational combined dataset contains continuous
performance of causal discovery.
4) Results of Case D of Dataset 1 measurements from 7466 single-cell samples, covering 11
The results in Supplementary Fig. S2 show that the protein and phospholipid variables. We extract the
introduction of merely 10% random uncertain knowledge in observational data from the original dataset and discretize the
KEEL can boost TPR by up to 14% and reduce FDR by up to relatively balanced distributed features of PKA and PKC into
17%. As the quantity of knowledge increases, the performance binary vectors using the mean values of their distributions. This
improvement becomes more pronounced. Specifically, the allows for inputting suitable mixed data into mixed methods for
introduction of 30% knowledge strikes the best balance further analysis. It is worth noting that our method uses only
between performance improvement and the cost of acquiring 853 observational samples for causal discovery, whereas the
knowledge. However, introducing a higher proportion of study of Sachs et al. uses all 7,466 observational and
knowledge, such as 90%, may exhibit diminishing marginal interventional samples.
benefits, despite achieving the best performance. Furthermore, We extract a series of established connections to serve as the
the introduction of noisy knowledge enables robust source for fuzzy causal knowledge. Briefly, for EOP, we input
identification of causal structures even when the signal-to-noise the knowledge that PIP3 may have no excitations, and AKT,
ratio is approximately 1, with a moderate improvement in TPR P38, and Jnk may have no response among the 11 variables. For
and reductions in FDR and SHD, despite potential slight effects ETE, we input knowledge that Raf regulates Erk via unknown
on performance gains due to increased noise levels. paths. For CCE, we input the endogenous knowledge of the
5) Results of Dataset 2 noisy inference of KEEL-wk and exogenous knowledge of
One advantage of KEEL lies in its theoretical ability to adapt potential influence connections, including Raf-Mek, Mek-Erk,
to variables of any distribution. In the Gaussian-Gaussian case Plcr-PKC, PIP2-PKC, PIP3-AKT, and PKA-Raf [40], [41]. For
(Supplementary Table S1), the proposed method with matched BNC, we input knowledge that there may be no path from Mek
assumptions outperforms that with mismatched assumption of to Raf. For UCD, we input knowledge that connections exist
the Laplace-Logistic distribution, which is the designated between Raf and PKA, PKC and Plcr, PKA and PKC, P38 and
distribution in related mixed causal discovery methods [37]. In PKA. Similarly, for DC, we specify that there must be
the Cauchy-Gaussian case (Supplementary Table S2), the connections between Raf-Mek and Mek-Erk. Additionally, for
proposed method with matched assumptions significantly FC, we specify that there is no connection from Mek to Raf.
outperforms that with the mismatched assumption of the In this study, we compare different methods using TPR, FDR,
Gaussian-Gaussian distribution. Related causal discovery SHD as well as the corresponding number of estimated edges
methods like Notears assume a Gaussian distribution when (NNZ). Considering the nonlinear relationships in real-world,
dealing with continuous variables [22], [38]. These methods we also compare KEEL with Notears-MLP which is designed
demonstrate that even on non-Gaussian distributed data, the for nonlinear data [42]. Notears-MLP estimates 16 edges with
mismatched assumption can still yield reasonable performance. an SHD of 16. In contrast, KEEL without knowledge estimates
However, we find that on data far from the Gaussian 15 edges with an SHD of 10, highlighting the superiority of
distribution, such as the heavy-tailed distributions like the KEEL even without knowledge in practical applications. We
Cauchy distribution, the mismatched Gaussian assumption further analyze the results of KEEL with fuzzy knowledge.12
KEEL_CCE achieves the best performance among all the systems, characterized by high-dimensional and small-sample
methods. (Fig. 5 and Table 2). In prior research, Sachs et al. size, while reducing the reliance on expertise.
reports predicting an undirected graph of 10 edges using the
observational data, which is less consistent with the ground REFERENCES
truth. They augment the dataset with interventional samples, [1] A. Zanga, . Ozkirimli, and F. Stella, ‚ÄúA Survey on ausal Discovery:
resulting in a 7466-sample dataset, and improve the heory and Practice,‚Äù Int. J. Approx. Reason., vol. 151, pp. 101‚Äì129, Dec.
2022.
performance to an SHD of 4 with 17 estimated edges. In
[2] S. K. Stavroglou, A. A. Pantelous, H. E. Stanley, and K. M. Zuev,
comparison, using less observational data, KEEL_CCE ‚ÄúUnveiling causal interactions in complex systems,‚Äù Proc. Natl. Acad.
estimates 22 edges with an SHD of 2, accurately estimating all Sci., vol. 117, no. 14, pp. 7599‚Äì7605, Apr. 2020.
[3] D. Yang, G. Yu, . Wang, Z. Wu, and . Guo, ‚ÄúReinforcement ausal
known connections. Moreover, all other knowledge constraints
Structure earning on Order Graph,‚Äù Proc. AAAI Conf. Artif. Intell., vol.
also performed relatively well on the observational data. For
37, no. 9, pp. 10737‚Äì10744, Jun. 2023.
example, ETE helps identify the biologically significant Raf- [4] J. Pearl and D. Mackenzie, The Book of Why: The New Science of Cause
Mek-Erk pathway, even outperforming the DC case that and Effect, New York, NY, USA: Basic Books, 2018.
[5] S. Cong, Y. Guoxian, W. Jun, Y. Zhongmin, and . izhen, ‚ÄúA review
directly requires Raf-Mek and Mek-Erk connections. This
on causality-based fairness machine learning,‚Äù Intell. Robot., vol. 2, no.
demonstrates the advantages of weakened constraints. 3, pp. 244‚Äì274, 2022.
Additionally, UCD helps to identify excitations and responses [6] P. F. ho, D. . Glubb, D. . hompson, A. B. Spurdle, and . A. O‚Äô ara,
‚ÄúAssessing the Role of Selenium in ndometrial ancer Risk: A
in protein signal transduction, and improves the overall causal
endelian Randomization Study,‚Äù Front. Oncol., vol. 9, Mar. 2019.
discovery performance with respect to TPR and SHD. [7] L. M. Anderson et al., ‚Äú ausal discovery analysis: A promising tool in
We further conduct an in-depth analysis of the results from advancing precision medicine for eating disorders,‚Äù Int. J. Eat. Disord.,
vol. 56, no. 11, pp. 2012‚Äì2021, 2023.
KEEL_CCE. As shown in Fig. 5, despite the erroneous
[8] G. Borboudakis and I. Tsamardinos, "Towards robust and versatile causal
inclusion of the Plcr-PIP3 direction in the prior knowledge discovery for business applications", Proc. KDD, pp. 1435-1444, Aug.
graph, KEEL_CCE successfully identifies the PIP3-Plcr 2016.
[9] F. Zhang and D. . Graham, ‚ÄúAir transport and economic growth: a review
connection, which is incorrectly identified in the opposite
of the impact mechanism and causal relationships,‚Äù Transp. Rev., vol. 40,
direction in the original estimation [39]. This finding confirms no. 4, pp. 506‚Äì528, Jul. 2020.
the robustness of the proposed method against knowledge noise. [10] C. Glymour, K. Zhang and P. Spirtes, "Review of causal discovery
methods based on graphical models", Front. Genet., vol. 10, Jun. 2019.
Additionally, the two new connections discovered by
[11] J. Peters, D. Janzing and B. Sch√∂lkopf, Elements of Causal Inference:
KEEL_CCE (PKC-Erk and PKC-AKT) have been
Foundations and Learning Algorithms, Cambridge: MA, 2017.
experimentally validated in recent years, which were not [12] J. Pearl, Causality: Models Reasoning and Inference, Cambridge, U.K.:
identified by computational methods in previous studies [43], Cambridge Univ. Press, 2011.
[13] R. Cui, P. Groot and T. Heskes, "Copula PC algorithm for causal
[44].
discovery from mixed data", Proc. Joint Eur. Conf. Mach. Learn. Knowl.
These results not only verify the effectiveness of the Discovery Databases, pp. 377-392, 2016.
knowledge formalization schema but also demonstrate that the [14] Z. ai, D. Xi, X. Zhu, and R. i, ‚Äú ausal discoveries for high dimensional
mixed data,‚Äù Stat. Med., vol. 41, no. 24, pp. 4924‚Äì4940, 2022.
reasonable incorporation of even a small amount of fuzzy
[15] P. Spirtes, "Introduction to Causal Inference", Journal of Machine
knowledge as weakened constraints can effectively improve Learning Research, vol. 11, pp. 1643-1662, 2010.
causal discovery performance and reduce the dependence on [16] G. Wan, Y. Wu, . Hu, Z. hu, and S. i, ‚ÄúBridging ausal Discovery
and Large Language Models: A Comprehensive Survey of Integrative
interventional experiments, expertise, and data. Thus, KEEL is
Approaches and Future Directions.‚Äù Feb. 16, 2024, arXiv:2402.11068.
potential to provide new insights for future computational [17] B. Andrews, J. Ramsey and G. F. Cooper, "Scoring Bayesian networks
approaches to uncover complex biological mechanisms. of mixed variables", Int. J. Data Sci. Anal., vol. 6, no. 1, pp. 3-18, 2018.
[18] B. Huang, K. Zhang and Y. Lin, "Generalized score functions for causal
discovery", Proc. 24th ACM SIGKDD, pp. 1551-1560, 2018.
IV. CONCLUSION [19] A. R. Nogueira, A. Pugnana, S. Ruggieri, D. Pedreschi and J. Gama,
"Methods and tools for causal discovery and causal inference", Wiley
In this study, we develop a weakly-supervised fuzzy
Interdiscipl. Rev.: Data Mining Knowl. Discov., vol. 12, no. 2, 2022.
knowledge and data co-driven causal discovery method named
[20] Y. i, R. Xia, . iu, and . Sun, ‚ÄúA Hybrid ausal Structure earning
KEEL. KEEL adopts a new fuzzy knowledge inspiration Algorithm for Mixed- ype Data,‚Äù Proc. AAAI Conf. Artif. Intell., vol. 36,
schema. This allows different amounts, purities, precision and no. 7, Art. no. 7, Jun. 2022.
[21] A. Gerhardus and J. Runge, "High-recall causal discovery for
certainty levels of knowledge to be represented as weakened
autocorrelated time series with latent confounders", Proc. Adv. Neural Inf.
constraints in the causal discovery process, effectively reducing
Process. Syst., vol. 33, pp. 12615-12625, 2020.
the search space and guiding the causal discovery. This [22] X. Zheng, C. Dan, B. Aragam, P. Ravikumar and E. Xing, "Learning
improves the accuracy and computational efficiency of causal sparse nonparametric DAGs", Proc. Int. Conf. Artif. Intell. Statist., pp.
3414-3425, 2020.
discovery and enhances the robustness to data scarcity and
[23] . Deleu et al., ‚ÄúBayesian structure learning with generative flow
knowledge error through a complementary mechanism.
networks,‚Äù Feb. 28, 2022, arXiv:2202.13903.
Additionally, the use of ELCM in KEEL extends its application [24] H. Morioka, A. Hyvarinen, "Connectivity-contrastive learning:
to scenarios with multi-distribution and incomplete data. We Combining causal discovery and representation learning for multimodal
data", Proc. Int. Conf. Artif. Intell. Statist., pp. 3399-3426, 2023.
also integrate causal discovery based on observational data,
[25] N. K. Kitson, A. C. Constantinou, Z. Guo, Y. Liu and K. Chobtham, "A
knowledge revision, and supplementation into a continuous
survey of Bayesian network structure learning", Artif. Intell. Rev., 2023.
optimization task to achieve more reliable identification of [26] . . Vowels, N. . amgoz and R. Bowden, "D‚Äôya like dags? A survey
causal relationships. Experiments demonstrate that KEEL can on structure learning and causal discovery", ACM Comput. Surv., vol. 55,
no. 4, pp. 1-36, 2022.
accurately and robustly identify causal relationships in complex13
[27] X. Shen, S. Ma, P. Vemuri and G. Simon, "Challenges and opportunities
with causal discovery algorithms: Application to alzheimer‚Äôs
pathophysiology", Sci. Rep., vol. 10, no. 1, pp. 1-12, 2020.
[28] L. von Rueden et al., "Informed machine learning-A taxonomy and
survey of integrating prior knowledge into learning systems", IEEE Trans.
Knowl. Data Eng., vol. 35, no. 1, pp. 614-633, Jan. 2023.
[29] R. Guo, L. Cheng, J. Li, P. R. Hahn and H. Liu, "A survey of learning
causality with data: Problems and methods", ACM Comput. Surv., vol. 53,
no. 4, pp. 1-75, Jul. 2020.
[30] A. . onstantinou, N. Fenton, and . Neil, ‚ÄúHow do some Bayesian
Network machine learned graphs compare to causal knowledge?,‚Äù Jan.
02, 2021, arXiv: 2101.10461.
[31] Y. Zeng, S. Shimizu, R. Cai, F. Xie, M. Yamamoto and Z. Hao, "Causal
discovery with multi-domain LiNGAM for latent factors", Proc. Int. Joint
Conf. Artif. Intell., pp. 2097-2103, 2021.
[32] S. leinegesse, A. R. awrence, and H. hockler, ‚ÄúDomain nowledge
in A*-Based ausal Discovery.‚Äù Aug. 17, 2022, arXiv: 2208.08247.
[33] . howdhury, R. Rashid, and G. erejanu, ‚Äú valuation of nduced
xpert nowledge in ausal Structure earning by NO ARS.‚Äù an. 04,
2023, arXiv: 2301.01817.
[34] U. Hasan and M. O. Gani, "KCRL: A prior knowledge based causal
discovery framework with reinforcement learning", Proc. Mach. Learn.
Res., pp. 691-714, 2022.
[35] R. H. Byrd, P. Lu, J. Nocedal and C. Zhu, "A limited memory algorithm
for bound constrained optimization", SIAM J. Sci. Comput., vol. 16, no.
5, pp. 1190-1208, 1995.
[36] L. A. Zadeh, "Fuzzy Sets", Inform. Contr., vol. 8, pp. 338-353, 1965.
[37] W. Wei, L. Feng and C. Liu, "Mixed causal structure discovery with
application to prescriptive pricing", IJCAI, pp. 5126-5134, 2018.
[38] Y. Yu, . hen, . Gao, and . Yu, ‚ÄúDAG-GNN: DAG Structure
earning with Graph Neural Networks.‚Äù Apr. 22, 2019, arXiv:
1904.10098.
[39] . Sachs, O. Perez, D. Pe‚Äôer, D. A. auffenburger and G. P. Nolan,
"Causal protein-signaling networks derived from multiparameter single-
cell data", Science, vol. 308, no. 5721, pp. 523-529, 2005.
[40] K. Shah, A. Al-Haidari, . Sun, and . U. azi, ‚Äú cell receptor ( R)
signaling in health and disease,‚Äù Signal Transduct. Target. Ther., vol. 6,
no. 1, pp. 1‚Äì26, Dec. 2021.
[41] A. S. Dhillon, C. Pollock, H. Steen, P. E. Shaw, H. Mischak, and W.
Kolch, ‚Äú yclic A P-Dependent Kinase Regulates Raf-1 Kinase Mainly
by Phosphorylation of Serine 259,‚Äù Mol. Cell. Biol., vol. 22, no. 10, pp.
3237‚Äì3246, May 2002.
[42] X. Zheng, C. Dan, B. Aragam, P. Ravikumar and E. Xing, "Learning
sparse nonparametric dags", Proc. Int. Conf. Artif. Intell. Stat., pp. 3414-
3425, 2020.
[43] D. Wu et al., ‚ÄúP -beta1 mediates glucose-induced Akt activation and
TGF-beta1 upregulation in mesangial cells,‚Äù J. Am. Soc. Nephrol. JASN,
vol. 20, no. 3, pp. 554‚Äì566, Mar. 2009.
[44] . orricelli, G. Valacchi, and . aioli, ‚ÄúNovel P s activate R
through PKD1 in MCF-7 cells,‚Äù Vitro Cell. Dev. Biol. - Anim., vol. 47,
no. 1, pp. 73‚Äì81, Jan. 2011.