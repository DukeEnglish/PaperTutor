EEG-Features for Generalized Deepfake Detection
ArianBeckmann*1 (arian.beckmann@hhi.fraunhofer.de)
TilmanStephani*2 (stephani@cbs.mpg.de)
FelixKlotzsche2 (klotzsche@cbs.mpg.de)
YonghaoChen2 (cheny@cbs.mpg.de)
SimonM.Hofmann2 (simon.hofmann@cbs.mpg.de)
ArnoVillringer2 (villringer@cbs.mpg.de)
MichaelGaebler2 (gaebler@cbs.mpg.de)
VadimNikulin2 (nikulin@cbs.mpg.de)
SebastianBosse1 (sebastian.bosse@hhi.fraunhofer.de)
PeterEisert1,3 (peter.eisert@hhi.fraunhofer.de)
AnnaHilsmann1 (anna.hilsmann@hhi.fraunhofer.de)
1Fraunhofer Heinrich-Hertz-Institute, Einsteinufer 37, 10587 Berlin, Introduction
Germany
The pope wearing puffer jackets, Tom Cruise doing magic
2Max Planck Institute for Human Cognitive and Brain Sciences,
tricks on TikTok, Donald Trump being arrested by the police.
Stephanstraße1A,04103Leipzig,Germany
Visual ”proof” of these situations went viral on social media
3Humboldt-Universita¨tzuBerlin,UnterdenLinden6,10099Berlin,
–yettheyneverhappened. Deepfaketechnologycanreadily
Germany
delude a viewer’s beliefs about what a certain person says,
does, and looks like. To maintain the delineation between
Abstract truth and lie, it is hence of paramount importance for mod-
ern society to be able to identify and counteract such Deep-
Since the advent of Deepfakes in digital media, the de-
faketechnologies. AcommonapproachfordevelopingDeep-
velopment of robust and reliable detection mechanism
fakedetectorsinvolvestrainingconvolutionalneuralnetworks
is urgently called for. In this study, we explore a novel
(CNNs) to detect the spatio-temporal artifacts appearing in
approach to Deepfake detection by utilizing electroen-
Deepfakes(Ro¨ssleretal., 2019; Wang, Bao, Zhou, Wang,&
cephalography(EEG)measuredfromtheneuralprocess-
Li,2023). Althoughtheyperformwellonbenchmarkdatasets,
ing of a human participant who viewed and categorized
thesedetectorsoftenstruggletogeneralizetonewmanipula-
DeepfakestimulifromtheFaceForensics++datset.These
tion domains that omit unfamiliar artifacts (Beckmann, Hils-
measurements serve as input features to a binary sup-
mann, & Eisert, 2023). Another possibility may be to add
portvectorclassifier,trainedtodiscriminatebetweenreal
the human in the detection loop, and, more specifically, take
andmanipulatedfacialimages.WeexaminewhetherEEG
advantage of the high-dimensional information contained in
data can inform Deepfake detection and also if it can
neurophysiologicalmeasurementsoftheperceptualandcog-
provideageneralizedrepresentationcapableofidentify-
nitive processing of Deepfake stimuli that leads or does not
ing Deepfakes beyond the training domain. Our prelim-
leadtothesubjectiveperceptofafakehumanface. Previous
inary results indicate that human neural processing sig-
workdemonstratedthatfakevideoscanbediscriminatedfrom
nalscanbesuccessfullyintegratedintoDeepfakedetec-
genuine ones if the observer is familiar with at least one of
tionframeworksandhintatthepotentialforageneralized
the displayed persons (Tauscher, Castillo, Bosse, & Magnor,
neural representation of artifacts in computer generated
2021). Moreover, (Moshel, Robinson, Carlson, & Grootswa-
faces. Moreover, our study provides next steps towards
gers,2022)demonstratedthatGANgeneratedimagescanbe
theunderstandingofhowdigitalrealismisembeddedin
decoded by people’s neural activity. In this proof-of-concept
thehumancognitivesystem,possiblyenablingthedevel-
study,wetestwhetherhumanelectroencephalography(EEG)
opmentofmorerealisticdigitalavatarsinthefuture.
can inform the detection of deepfaked faces and whether it
Keywords:EEG;Deepfake;perception;realism allows – in contrast to naively trained CNNs – to generalize
*EqualContribution. acrossdifferentDeepfakegenerationmethods.
4202
yaM
41
]GL.sc[
1v72580.5042:viXraMethods werecutintoepochsfrom-300to+700msrelativetostimu-
lus onset, including a baseline correction from -200 to 0 ms.
Stimuli Forourstimulusset,weutilizetheFaceForensics++
Epochswithvaluesexceeding+-400µVatanyelectrodewere
(Ro¨ssleretal.,2019)benchmarkdatasetasitcontainsforged
excludedfromfurtheranalysis(n=4).
facial videos originating from various different manipulation
methods.Weusestimulioftwodifferentfakemethods,”Deep- Deepfake classification We construct the following exper-
fakes” (DF)2 and ”FaceSwap” (FS), along with their respec- iment to analyze whether the recorded EEG data can inform
tive original counterparts. We chose these two fake meth- Deepfake detection, particularly assessing the potential of a
ods as they produce different characteristic artifacts that are generalized artifact representation: For each video in each
not difficult to identify. Per category, 500 videos were se- category, we average over all recorded trials to obtain a de-
lected of which we randomly selected 8 (16) frames as fake noised sample. Thus, we are left with 1500 denoised sam-
(real)images,intotalresultingin16,000imageswithbalanced ples, distributed evenly across the three categories – ”Deep-
fake/real labels. Note that we selected the videos such that, fakes”(DF),”Faceswap”(FS)and”real”. Notethatfordenois-
per category, 360 videos belong to the training set and 70 ingrealsamples,weuse8insteadof16recordedtrialstoen-
videostothevalidationandtestingsetsrespectively,asspec- sure a similar signal quality between real and fake samples.
ifiedinRo¨ssleretal.(2019). Then, we form training, validation and testing sets according
to Ro¨ssler et al. (2019). We process the data in two differ-
Experimental procedure The images were presented in
entvariations,resultingfromanextensiveablationstudy. We
random order on a computer screen to a human observer
denotethesevariantsbyV1andV2respectively. Bothvaria-
(co-author, male, 22 years), whilemeasuring EEG. Each im-
tionsignorethefirst300msprestimulusonsetand,ultimately,
age was centrally presented for 350 ms, followed by a blank
merge the spatial and temporal dimensions before applying
screen with a fixation target for 350 ms. Subsequently, in a
dimensionality reduction. For V1, we use all remaining data
subsetofthetrials, theparticipantwastaskedtoindicatevia
and reduce its dimensionality via PCA with 64 components.
buttonpresswhetherheperceivedthestimulusasrealorfake
ConcerningV2,wesplitthedatawithrespecttotheremaining
(within 1000 ms). The tasks appear at random, in 12.5% of
700msalongthespatialandtemporaldimensionsintochunks
thetrials,astoavoidtheparticipantexpectingthetask. Inthe
of length 100 ms per electrode, resulting in 441 chunks (63
remaining87.5%oftrials,theexperimentcontinuedwithstim-
electrodes X 7 100 ms intervals). For each chunk, we train
uluspresentationofthefollowingtrial. Thewholeexperiment
a separate binary support vector classifier (SVC) to discrim-
consisted of 160 blocks with 100 trials each, amounting to a
inate between neural signals representing real or deepfaked
totaldurationofaround4hoursmeasurementtime.
stimuli. Subsequently,weevaluatetheclassifiersonthevali-
EEG setup and preprocessing EEG data were recorded dationsetsoftherespectivechunks. Thetop100chunksby
from63Ag/AgClelectrodesatasamplingfrequencyof1000 validation F1-score were selected, consolidated and further
HzwithaNeurOneTeslaEEGsystem(Bittium,Oulu,Finland). reducedbyICAwith128components.
Abuilt-inband-passfilterbetween0.16and250Hzwasused. Thefollowingtrainingandevaluationprocessisperformed
Electrodes were placed according to the international 10-10 separately for data pre-processed according to both V1 and
system,mountedinanelasticcap(EasyCap,Hersching,Ger- V2: WetrainanSVC(withdefaultparametersinscikit-learn)
many). FCz served as reference and CPz as ground elec- to discern real and fakes on training data containing DF and
trode. During offline processing, the EEG data were band- ”real” and evaluate it on the respective test set. Moreover,
pass filtered between 0.5 and and 40 Hz, re-referenced to totestout-of-domaindetectionperformance,weevaluatethe
an average reference, and ICA served to remove eye blink, classifier on the testing subset of FS. Likewise, we perform
eye movement, and heart artifacts. Subsequently, the data theexperimentincludingFSinsteadofDFinthetrainingset,
whilestilltestingonbothfakesubsets. Theresultsofourex-
2ThegeneraltermDeepfakeoriginatesfromthisseminalforgery periments are shown in Table 1. DF→FS refers to the case
method,toavoidconfusionwerefertoitsolelyasDF.
Figure1: MeanEEGresponseswithrespecttothethreestimuliclassesforelectrodePO8aswellasthetopography(acrossall
electrodes)ofthedifferencebetweenfakeandrealimagesat385msafterstimulusonset(greenbox).mation hiding and multimedia security (p. 175–180). New
Table1:MacroF1-Scoresforbothvariationsonmultipletrain-
York,USA. doi: 10.1145/3577163.3595106
testsplits. Boldnumbershighlightout-of-domaintesting.
Moshel, M. L., Robinson, A. K., Carlson, T. A., & Grootswa-
Variation DF→DF DF→FS FS→DF FS→FS gers, T. (2022). Are you for real? decoding realistic ai-
generated faces from neural activity. In Vision res. 2022
V1 0.62 0.58 0.59 0.61
oct;199:108079.
V2 0.61 0.58 0.61 0.56
Ro¨ssler,A.,Cozzolino,D.,Verdoliva,L.,Riess,C.,Thies,J.,&
Nießner, M. (2019). FaceForensics++: Learning to detect
manipulated facial images. In International conference on
inwhichthetrainsetcontainsDFand”real”andthemodelis
computervision(iccv).
evaluatedonthetestingsetscorrespondingtoFSand”real”.
Tauscher,J.-P.,Castillo,S.,Bosse,S.,&Magnor,M. (2021).
Theothercolumnsfollowthesamelogic.
Eeg-based analysis of the impact of familiarity in the per-
ception of deepfake videos. In 2021 ieee international
ResultsandDiscussion
conference on image processing (icip) (p. 160-164). doi:
Theleft-handsideofFigure1showstheEEGresponsesaver-
10.1109/ICIP42928.2021.9506082
agedovertherespectiveclassesforelectrodePO8.Themag-
Wang,Z.,Bao,J.,Zhou,W.,Wang,W.,&Li,H. (2023,June).
nifiedregionsontheright-handsideshowasignificantdiffer-
Altfreezingformoregeneralvideofaceforgerydetection. In
encebetweentheresponsestotherealimagesandtheirma-
Proceedingsoftheieee/cvfconferenceoncomputervision
nipulatedcounterparts(confirmedbycluster-basedpermuta-
andpatternrecognition(cvpr)(p.4129-4138).
tiontesting). Additionally,thegreenboxdisplaysthetopogra-
phy of the difference in the responses to faked (DF and FS)
and real images at 385 ms after stimulus onset. These de-
scriptive results tentatively demonstrate that neural process-
ing may contain a generalized representation of artificiality
withrespecttocomputer-generatedfaces. Thisinterpretation
obtainsfurthersupportfromthedecodingresultsdepictedin
Table 1. As can be seen in the third and fourth columns,
the classifier is able to produce above chance level perfor-
mance when confronted with fakes not seen during training.
Wecheckthesignificanceoftheseresultsbypermutationtest-
ingagainstchance-levelwith10,000repetitionsfor p=0.05.
The resulting p-values are .0309 and .0128 for V1, as well
as.0277and.0036forV2(sameorderasshowninTable1).
Nonetheless,tofurthersupportourhypothesis,weaimtoper-
formmoreexperimentswithawidervarietyofDeepfakesand
moreparticipantsinourfuturework.
Conclusion
In this pilot experiment, we not only demonstrated that fea-
tures derived from EEG recordings can be used to detect
Deepfakes,butalsothatthesefeaturescanbeutilizedforout-
of-domain fake detection – hinting at the potential for a gen-
eralized representation of artifacts or uncanny content within
neural processing signals. For subsequent experiments, we
plantoincludemorehigh-qualityimagesandtomanuallyadd
a variety of artifacts, to enable more control and a broader
analysis.
Acknowledgments
This work has received funding through the Max Planck-
FraunhofercollaborationprojectNeuroHum.
References
Beckmann, A., Hilsmann, A., & Eisert, P. (2023). Fooling
state-of-the-art deepfake detection with high-quality deep-
fakes. InProceedingsofthe2023acmworkshoponinfor-