What’s Wrong? Refining Meeting Summaries with LLM Feedback
FredericKirstein1,2,TerryRuas1,BelaGipp1
1Georg-August-UniversitätGöttingen,Germany
2kirstein@gipplab.org
Abstract et al., 2024a). Existing techniques, like AMR-
graphsforcapturingspeakerrelations(Huaetal.,
Meeting summarization has become a criti-
2023),areoftentailoredtospecificbackbonemod-
caltasksincedigitalencountershavebecome
a common practice. Large language models els, typically using BART (Lewis et al., 2020),
(LLMs)showgreatpotentialinsummarization, PEGASUS (Zhang et al., 2020a) or their varia-
offering enhanced coherence and context un- tions. Recentexplorationsoflargelanguagemod-
derstandingcomparedtotraditionalmethods. els(LLMs)formeetingsummarizationrevealtheir
However, they still struggle to maintain rele- strong capabilities (e.g., high-quality summaries
vance and avoid hallucination. We introduce
of long inputs) (Laskar et al., 2023). However,
amulti-LLMcorrectionapproachformeeting
these LLM-generated summaries are still error-
summarizationusingatwo-phaseprocessthat
mimics the human review process: mistake prone(Kirsteinetal.,2024b)andcostlytofine-tune
identificationandsummaryrefinement. We (Chauhanetal.,2022;Wangetal.,2022).
releaseQMSumMistake,adatasetof200au- The shift to LLMs as backbone models raises
tomaticallygeneratedmeetingsummariesan-
thequestionofhowtobetterusetheircapabilities
notatedbyhumansonnineerrortypes,includ-
and mitigate their weaknesses. (Self-)correction
ingstructural,omission,andirrelevanceerrors.
throughfew-shotpromptingimprovesLLMperfor-
Ourexperimentsshowthattheseerrorscanbe
mancebyaskingittoreviewandcorrectitsoutput
identifiedwithhighaccuracybyanLLM.We
transform identified mistakes into actionable (Panetal.,2023). Whilesuccessfulinvarioustasks
feedbacktoimprovethequalityofagivensum- (e.g.,questionanswering(Jiangetal.,2024),rea-
marymeasuredbyrelevance,informativeness, soning(Madaanetal.,2021),andsummarization
conciseness,andcoherence. Thispost-hocre- (Saunders et al., 2022)), self-correction still falls
finementeffectivelyimprovessummaryquality
short to identify and correct errors (Huang et al.,
byleveragingmultipleLLMstovalidateoutput
2024). Toaddressthis,Tyenetal.(2024)proposea
quality. Ourmulti-LLMapproachformeeting
multi-LLMrefinementprocessforreasoningtasks
summarizationshowspotentialforsimilarcom-
plextextgenerationtasksrequiringrobustness, with,leadingtoamorerobustcorrectionapproach.
actionplanning,anddiscussiontowardsagoal. Analogoustohowhumansiterateoversugges-
tionsandeditswhenwritingtexts,weexplorehow
1 Introduction
LLMs may be employed in the same way to im-
Meetingsummariesareessentialforprofessional prove meeting summarization in a two-stage ap-
conversations,theyserveasareferenceforsubse- proachconsistingofmistakeidentificationinan
quent processes, update absentees, and reinforce existing summary and a subsequent refinement
themostimportanttopicsdiscussed. Thegrowing (Figure1). Formistakeidentification,weannotate
importance of summarization systems is evident QMSum (Zhong et al., 2021) on nine error types
fromtherecentreleaseoftoolsinvirtualmeeting (e.g.,omission,structuralmistakes)(Kirsteinetal.,
software(e.g.,Zoom1,MicrosoftTeams2,Google 2024b;Changetal.,2024). GPT-4Turbo4 identi-
Meet3). Still, meeting summarization faces chal- fieserrorsonaveragewith∼89%accuracy,butit
lenges,suchashandlingspokenlanguageidiosyn- struggleswithirrelevance(∼81%)andhallucina-
crasies and identifying salient content (Kirstein tion(∼72%)errors. Weachievethebestresultson
1https://www.zoom.com/en/ai-assistant themistakeidentificationtaskusingmultipleLLM
2https://copilot.cloud.microsoft
3https://support.google.com/meet/ 4WewillrefertothisasGPT4throughoutthepaper.
4202
luJ
61
]LC.sc[
1v91911.7042:viXraFigure1:Overviewofthetwo-stagerefinementprotocoldisplayingtheassessedvariants. TheMistakeIdentification
blockisanalyzedSection4andtheRefinementblockinSection5.
instancesforeacherrortypeandChain-of-Thought ditionalencoder-decodermodelstoLLMs. Tradi-
(CoT)prompting(Weietal.,2023). Fortherefine- tionalmodels,suchasBART(Lewisetal.,2020)
ment stage, we use an additional model instance and PEGASUS (Zhang et al., 2020a), improved
to adjust an erroneous summary according to the throughtechniquestailoredtospecificchallenges
detailedfeedbackfromthemistakeidentification likelanguage,structure,comprehension,speaker,
stage. Weexplorewhatcontentarefinementmodel salience, and factuality (Kirstein et al., 2024a,b).
requires,consideringtheCoTexplanationfromthe These models integrated methods such as AMR-
mistakeidentificationtask,acorrectionsuggestion, graphs for speaker relations (Hua et al., 2023),
and the original meeting transcript as additional role vectors for speaker correlation (Asi et al.,
informationsourcesforpointed-outmistakes. We 2022; Naraki et al., 2022), and additional train-
further analyze if the feedback should be passed ingstagestobridgethegapbetweenpre-training
throughanintermediateplanningstagethatextracts on written texts and spoken dialogue tasks (Raf-
whichcontenttoadd,remove,orrewriteinasum- fel et al., 2020; Khalifa et al., 2021; Lee et al.,
mary. We identify strong quality improvements 2021b). Recently, LLMs have been explored for
for refined summaries over the original ones and meeting summarization by prompting the model
baselineswhenusingtheCoTexplanationfromthe to create a TL;DR (Laskar et al., 2023; Kirstein
mistakeidentificationasfeedbackalongtheerro- et al., 2024b), showing comparable performance
neoussummarywithoutadditionalprocessing. Our to specialized encoder-decoder models but with
contributionsaresummarizedasfollows: better context comprehension. They thereby use
LLMswithoutanyadaptationsandserveasthefirst
• QMSumMistake5,adatasetof200meeting workstoreportonLLMperformanceonmeeting
summariesandhuman-annotatederrors. summarization. Ourworkexaminestheeffective-
• A multi-LLM approach to finding mistakes ness of LLMs as post-processors for summaries,
in meeting summaries considering different assessingifthisapproachcanachievehigh-quality
promptingapproaches. summarieswithoutrequiringtechniquestailoredto
• A transformation of identified mistakes into aspecificchallengeofmeetingsummarization. We
actionable feedback to refine an erroneous compare this against original summaries, single-
summaryandderivearefinementprotocol. LLMbaselines,andhumansummaries,providing
anupdatedbenchmarkforLLMsinmeetingsum-
marization. ForthecreationofQMSumMistake,
2 RelatedWork
weextendtheworkbyKirsteinetal.(2024b),re-
Meeting Summarization and its parent domain finingtheirdefinitionoferrors.
dialoguesummarizationaretransitioningfromtra- Self-correction methods have been extensively
studied in recent literature (Pan et al., 2023), in-
5ThedatasetwillbelateravailablethroughHuggingface
andtheproject-accompanyingGithubrepository. cluding training-time correction strategies likeDataset #Meetings #Turns #Speakers #Len.ofMeet. #Len.ofGoldSum. #Len.ofAut.Sum.
AMI 124(113) 535.6 4.0 6007.7 108.8 112.4
ICSI 52(42) 819.0 6.3 13317.3 103.0 108.2
WPCP 24(14) 207.7 34.1 13761.9 129.5 112.9
QMSumMistake 200(169) 556.8 9.2 9069.8 109.1 116.9
Table1: StatisticsfortheQMSumMistakedataset. Valuesareaveragesoftherespectivecategories. Lengths(Len.)
areinnumberofwords. In#Meetings,valuesinparenthesesarethenumberoferroneoussamples.
Reinforcement Learning from Human Feed- ofvaryingsummarizationstylesandqualitylevels.
back (RLHF) (Ouyang et al., 2022) and self- Thehumanannotationprocess,whichachievedan
improvementtechniques(Huangetal.,2024). Our averageKrippendorff’salphaof0.780(seeTable5),
feedbackandrefinementmethodfallsintothecate- isdescribedinAppendixD.
goryofpost-hoccorrection,whichisappliedtoout-
putsalreadygenerated. Previouspost-hoccorrec- 3.1 Observableerrors
tionmethods,suchasReflexion(Shinnetal.,2023)
We refine existing error types (Kirstein et al.,
andRCI(Kimetal.,2023),focusonreasoninger-
2024b; Chang et al., 2024) into nine error types
rorsandoftendegradeperformancewithoutoracle
withminimaloverlap. Table2holdstheshortdefi-
labels (Huang et al., 2024). Our work uniquely
nitions. Preliminarytestingandannotatorfeedback
appliespost-processingcorrectiontomeetingsum-
informtherefinementoftheerrortypesandpoint
marization,focusingonqualitativeimprovements
outoverlapinerrordefinitions,makingacleardis-
withindependentmodels,andfurtherexploresthis
tinctiondifficult. Thisleadstomajoradaptationsto
toothermodelfamiliesandrelatedsummarization
preciselydelimittherepetition,incoherence,struc-
domains. Our approach is informed by the two-
ture, and linguistic inaccuracy errors, while the
stagesetupof(Tyenetal.,2024)whichweextend
omissionerrorsundergominortweaksinwording.
with an extensive mistake identification architec-
Hallucinationerrorsarepackedintoasinglecate-
tureandamulti-stagerefinement.
gorytoreduceoverlapforedgecasesbetweenthese
two. Theinitialobservationsfurtherindicatethat
3 QMSumMistakeDataset errorssofarweredesignedtocapturemissingorin-
correctinformation,nottheinclusionofunrelated
QMSumMistakeconsistsof200samples,with169
content, which our summary-generating models
(85%) automatically created meeting summaries
tend to generate. Thus, we add the ’Irrelevance’
annotatedonnineerrortypes(Section3.1)and31
category.
error-freesummariesservingascontrolstoanalyze
if the mistake identification is too sensitive. Ta-
4 MistakeIdentification
ble1providesdatasetstatistics. Thesamplesstem
fromQMSum’s(Zhongetal.,2021)trainingand Table 3 shows GPT4’s6 accuracy in identifying
testsets,includingAMI(stagedbusinessmeetings) summarization-relatederrors(Section3.1)onthe
(Carletta et al., 2005), ICSI (academic meetings) QMSumMistakedataset. WechoseGPT4forits
(Janinetal.,2003), andparliamentmeetings. As contextsize,understandingcapabilities,robustness
gold summaries lack typical errors of automatic to handle spoken language, and superior results
summaries,wegeneratesummariesusingencoder- compared to Gemini (Team et al., 2024) and Phi
decoder models (i.e., LED (Beltagy et al., 2020), (Abdin et al., 2024) in early experiments. We
DialogLED (Zhong et al., 2022), PEGASUS-X providecomplementaryanalysisforthediscarded
(Phang et al., 2022)) for more severe mistakes in modelsinAppendixB.
automaticsummariessuchascoreferenceandstruc-
ture errors and LLMs (i.e., GPT-3.5, Phi-3 mini 4.1 Mistakeidentificationprotocol(MIP)
128k(Abdinetal.,2024))forsubtleerrorssuchas
We consider two prompting strategies to identify
relevance. Models have a context size of at least
possible mistakes in a summary: direct and CoT
16ktofittheentiremeetingintheinput,usedefault
prompting. In Direct prompting (Tyen et al.,
settings, and generate up to 200 tokens to match
gold summary lengths. Table 9 shows examples 6gpt-4-turbo-2024-04-09,defaultsettings,temperature=0ErrorType Transcript Definition
Redundancy notrequired Thesummarycontainsrepeatedorredundantinformation,whichdoesnothelpthe
RED understandingorcontextualization.
Incoherence notrequired Themodelgeneratessummariescontainingcharacteristicsthatdisruptthelogical
INC flow, relevance, orclarityofcontenteitherwithinasentence(intra-sentence)or
acrosssentences(inter-sentence).
Language notrequired Themodelusesinappropriate,incorrect(ungrammatical),orambiguouslanguageor
LAN failstocaptureuniquelinguisticstyles.
Omission required Missinginformationfromthemeeting,suchassignificantdecisionsoractions.Total
(partial,total) omission:Relevanttopicsandkeypointsarenotstated.Partialomission:Salient
P-OM,T-OM topicsarementionedbutnotcapturedindetail.
Coreference required Themodelfailstoresolveareferencetoaparticipantorentity,misattributesstate-
COR ments,oromitsnecessarymentions.
Hallucination required Themodelproducesinconsistenciesnotalignedwiththemeetingcontent.Intrinsic:
HAL Misrepresentsinformationfromthetranscript. Extrinsic: Introducescontentnot
presentinthetranscript.
Structure required Themodelmisrepresentstheorderorlogicofthemeeting’sdiscourse,misplacing
STR topicsorevents.
Irrelevance required Thesummaryincludesinformationthatisunrelatedornotcentraltothemaintopics
IRR orobjectivesofthemeeting.
Table2: DefinitionofthenineerrortypesannotatedinQMSumMistakebasedonexistingerrortypes(Kirstein
etal.,2024b;Changetal.,2024)
2024),giventhepredictedsummaryandthemeet- hypothesis behind current LLM-based automatic
ing transcript, when required (see Table 2), the metricsthatleveragesimilarmodelstoassesstext
modeloutputs’Yes’or’No’foreacherrortoindi- characteristicssuchasfluency,readability,orclar-
cateitsexistence. ForCoTprompting(Weietal., ity(Lietal.,2024).
2023),weextenddirectpromptingbyhavingthe
modelexplainwhyapassageiserroneousfollow-
Impactofmistakeidentificationprotocolonac-
ingthe’let’sthinkstepbystep’approach,allowing
curacy of error detection. Comparing results
fordetailedanalysisofthemodel’sunderstanding.
across the four MIP variants (Table 3a), we find
As GPT4 is not specifically trained to identify
that accuracy in detecting mistakes increases sig-
errors,weenrichthemistakeidentificationprompt
nificantly on all error types when using a multi-
with few-shot examples of erroneous summaries
instancesetupcomparedtothesingle-instanceap-
(non-overlapping with our test set). The mistake
proach. While the difference between single and
identification prompt consists of four parts: the
multi-instanceiscomparablysmall(∼7%)forboth
model role and error definition for context, two
omissionerrortypes(T-OM,P-OM),theaccuracy
few-shot examples of the error type, an optional
candeviatebyupto∼29.5%inthecaseofHAL.
request for the CoT prompting, and the primary
Figure2showsthattheaverageaccuracyacrossall
taskofreportingtheerror’sexistence. Weinclude
error types reveals a gain of at least 13.5% when
moredetailsontheexactpromptinAppendixD.
usingmultipleLLMinstancesfordetection,which
We consider two setups to explore the MIP: a
alignswithrecentworks(Huangetal.,2024;Tyen
single-instanceofasingleGPT4askedtodetect
etal.,2024). Weobservetheaveragefalsenegative
allerrortypesatonce(Zhangetal.,2023a)anda
ratesdecreaseby∼27%fromsingle(CoT)(30.0%,
multi-instancearchitecture(Mousavietal.,2023)
worstoverall)tomulti(CoT)(3.4%,bestoverall).
usingoneGPT4instanceforeacherrortype.
Wehypothesizethattheweakersingle-modelper-
formancemaystemfromtheextendedcontentand
4.2 Mistakeidentificationdiscussion
its additional tasks, which must be handled by a
While both setups achieve high accuracy scores, single model compared to the multi-instance set-
thesingle-instancesetupstrugglestoconsistently ting. As a result, the single-instance approach is
beat an always true baseline on the whole QM- unable to process the long dependencies, which
SumMistakedataset. Overall,thisalignswiththe limitscontextualizationandcomprehension (Leesingle-instance multi-instance alwaystrue single-instance multi-instance alwaystrue
Error direct CoT direct CoT Error Direct CoT Direct CoT
P-OM 75.0 82.2 82.5 84.5 79.0 P-OM 86.4 89.9 93.5 94.1 93.5
T-OM 78.5 81.5 87.0 90.0 81.0 T-OM 87.0 87.6 94.7 94.1 95.9
REP 73.0 72.0 92.0 95.5 48.5 REP 68.0 66.9 90.5 94.7 57.4
INC 73.0 66.5 83.0 89.5 39.0 INC 68.0 60.4 79.9 88.2 46.2
COR 76.0 63.0 85.0 91.5 19.0 COR 71.6 61.5 82.8 89.9 22.5
HAL 42.5 59.0 73.5 72.0 62.0 HAL 50.3 60.4 75.7 75.1 73.3
LAN 61.5 68.5 77.5 88.5 43.0 LAN 61.5 63.9 75.7 82.2 50.9
STR 71.0 62.5 69.5 87.0 47.0 STR 66.9 60.9 67.5 89.9 55.6
IRR 60.5 59.0 76.5 81.0 51.0 IRR 55.6 60.4 76.9 82.8 60.4
(a)ResultsonthewholeQMSumMistakedataset. (b)ResultsontheerroneoussamplesofQMSumMistake.
Table3: MistakeidentificationaccuracyofGPT4forallMIPvariants. AlwaysTruebaselineprovidedforreference.
Bestvaluesarebold.
tofalselyflagT-OM,P-OM,STR,HAL,andIRR
errors. We derive from this observation that the
model expects a content-richer summary, seeing
additionalcontentasrelevant. Ourresultssuggest
thatthemulti-instancesetupwithCoTprompting
provides the most reliable mistake identification,
whichweuseforthefollowingexperiments.
Difficultiesinidentifyingerrors. Basedonthe
bestMIP’saccuracy,wecategorizeerrorsintothree
groups: reliable (≥ 90.0%: COR, REP, T-OM),
Figure2: Averagemistakeidentificationaccuracy,false
good (≥ 85.0%: INC, LAN, STR), and hard to
positiveandfalsenegativeratesforeachMIPvariant.
detect(<85.0%: P-OM,IRR,HAL).Following,we
For the accuracy, higher score is better. For the false
discussthedifficultiesrelatedtoeachcategoryby
positive/negativerate,lowerisbetter.
analyzingthemodels’CoTexplanationstoidentify
patternsandthepossiblereasontheystruggle7.
etal.,2021a). Inaddition,whilethemulti-instance Errorsfromthereliablegrouphavedescriptions
setupbenefitsfromtheCoTprompting,thesingle- closetowhatanLLMwithoutaccesstoourdefini-
modeloneisnegativelyaffectedwithgainsinfalse tionswouldgeneratewhenpromptedtodefinethe
negativeerrorrate. TheCoTexplanationsshowing error. The rare accuracy decreases are related to
inconsistency in assessing requested error types oversensitivitycases,e.g.,assigningaT-OMerror
duetomisunderstandingofthedefinitionsupports when expecting more details, indicating that the
theseobservations. modelmayapplyerrordetectionrulestoostrictly.
Consideringthemulti-instanceapproachasbet- FalseidentificationofCORerrorstypicallyoccurs
tersuitedformistakeidentification, weconclude when conversations become less structured, and
that the CoT prompting is beneficial to improve multipleparticipantsmentionsimilarinformation,
accuracyevenfurthercloseto90%. Notethatthe asinthesamplesderivedfromtheAMIdataset.
CoTexplanationmightcontainwrongstatements. Forerrorsfromthegoodgroup,themainissue
Atthesametime,theresultingerroridentification isthemodel’stendencytofailtoproperlycontex-
iscorrection,whichhasalsobeenobservedintasks tualizeerrordefinitionsandapplythemtoostrictly
suchassortingandlogical(Tyenetal.,2024). compared to human annotators. For example, a
The nearly constant average false positive rate summary’slinearitymaybecountedasaSTRer-
(between12.4%and15.4%)acrossallMIPs(Fig- ror,asthesummarydoesnotpreservetheidentical
ure2)suggestsamodeltendencytopointoutnon- structure. FalsedetectionofLANerrorsincludes
existingerrors,whichweinterpretasoversensitiv- markingdomain-typicalterms(e.g.,gradstudent
itytoerrortypes. Analyzingtheaccuracychange forgraduatestudentinICSI)asmistakesandori-
between the whole dataset (Table 3a) and the er-
7Duetotheamountofdata,themodelresponsesconsi-
roneoussubset(Table3b)wefindthatGPTtends deredforthissectionwillbeshareduponacceptance.ents on the transcript’s language level, rendering through detailed, structured information but may
fracturedandbrainstorming-likecontent(e.g.,con- leadtoconfusionifthereasoningiswrong(Tyen
versationfromtheICSI)difficult. et al., 2024). Correction suggestions provide ex-
Errors from the hard group are challenging amplesofhowtocorrecttheerror,eitherastipsor
mainlyduetothemodel’sdifficultyinunderstand- preciserewritesthatcanbedirectlyapplied. The
ingtheerrortype. InthecontextofHALthemodel transcriptprovidesallavailableinformationinits
occasionallylooksforcloselyrelatederrors(e.g., originalform,allowingittodecidewhethertoac-
T-OM,COR),leadingtowrongdetection. GPT4 cept or reject the feedback and how to integrate
struggleswithP-OMandIRRduetotheinherent it. Thethreeoptionalinformationsourcescanbe
subjectivity,whichwealsoobserveintheslightly combined,determininghowmuchinformationis
lowerinter-annotatoragreementscoresduringthe requiredandiffeedbackwithoutatranscriptisas
QMSum Mistake annotation (Table 5). We con- informativeasaddingthetranscriptforlookup.
cludethatGPT4applieserrordetectiondefinitions
slightlytoostrictlyandmistakesrelatedtosubjec- 5.2 Transferprotocol(TP)
tivityareinfluencedbythemodel’sheuristic.
Weconsidertwoapproachesforstructuringfeed-
back for the refinement model: direct feedback
5 SummaryRefinement
(Mousavietal.,2023)andconsolidation(Zhang
Building on the finding that an LLM can iden- et al., 2023a). Direct feedback transfers derived
tify typical meeting summarization errors (Sec- feedback without additional processing, stating
tion 4.2), we analyze how the quality of original whether an error type is observed or not. In the
predicted summaries changes when an LLM re- caseofCoTexplanation,itinformsthemodelstep-
finesthembasedonidentifiedmistakes. Ourmulti- by-stepwhichsentencesareerroneousorerror-free,
model refinement approach mimics a four-stage whytheyarecorrectorincorrect,andwhatshould
humanreviewprocesstoformarefinementproto- be changed (or kept) to have a correct sentence.
col (Figure 1): (1) locating errors using the best- Consolidationconsidersonlyidentifiederrorsand
performingMIP,(2)generatingfeedbackoniden- generates an editing plan using an intermediate
tified errors (feedback protocol), (3) structuring LLM,extractingwhatinformationtoadd,remove,
feedback(transferprotocol),and(4)refinement. oralterfromthefeedbackprotocol. Theconsolida-
Following, we explore the setup of the feedback tionprotocoldoesnotaffectanappendedtranscript.
andtransferprotocolstoderivearefinementproto-
colformeetingsummarization. 5.3 Experimentalsetup
WerefinetheerroneoussummariesfromQMSum
5.1 Feedbackprotocol(FP)
Mistake using each refinement protocol variant
Feedbackonanerrorcanrangefrompointingout withthemulti-instanceCoT-promptedMIP.GPT4
itsexistence,similartosomeonehighlightingatext isusedasthebackbonemodelfortherefinerand
passageandleavingashortcomment,toin-depth optional intermediate LLM to consolidate feed-
explanations of what is wrong with the marked back, with other model families explored in Ap-
passage and rewrite suggestions. Following this pendix B. We focus the following experiment on
analogy, our feedback protocol consists of an es- evaluating how summary quality changes based
sentialandanadditionaldetailpart. Theessential onfeedbackandshowasetupforameetingsum-
partincludesminimalfeedbackontheexistenceof marization refinement protocol. We consider a
anerrortypeandashortexplanationaboutwhyand one-shot improvement here and provide insights
whereitwasdetected,butmaynotmentionallerror on multi-round improvement in Appendix B.3.
instances. Theadditionaldetailpartconsidersthree To help understand and categorize the quality
optional information sources: CoT explanation changes, we report metric results for the original
(Weietal.,2023),correctionsuggestion(Zhang erroneoussummaries(ORIG),error-freeQMSum
et al., 2023a), and the original transcript. CoT goldsummaries(GOLD),summariesgeneratedby
explanation, the output of MIP’s CoT prompting oneGPT4(GPT-S),andsummariesrefinedbyone
(Section4.1),containsallobservederrorinstances GPT4(GPT-R)8 asreferencesinTable4.
and details on why they are considered errors. It
helpstherefinementmodelderivearewritingplan 8’Refinethissummarybyconsideringthetranscript’.TP FP Overall REL INF CON COH
(Ranking↓) (Likert↑) (Likert↑) (Likert↑) (Likert↑)
essentialonly 5.44 3.08 2.99 3.29 3.14
CoT 3.75 3.10 3.14 3.46 3.20
Cor 3.79 3.04 2.83 3.57 3.23
CoT+Cor 4.11 3.11 2.88 3.40 3.09
direct
Tra 4.68 3.12 2.93 3.65 3.37
Tra+CoT 4.74 3.14 3.36 3.67 3.56
Tra+Cor 4.93 3.10 3.14 3.68 3.44
CoT+Cor+Tra 5.10 3.05 3.05 3.43 3.18
essentialonly 6.10 2.53 2.27 2.58 2.36
CoT 5.61 2.69 2.62 2.99 2.70
Cor 6.07 2.96 2.85 3.22 2.98
CoT+Cor 6.40 2.93 2.92 3.34 3.03
consolidated
Tra 4.86 3.08 3.12 3.50 3.33
Tra+CoT 4.89 3.04 3.05 3.49 3.22
Tra+Cor 4.88 3.11 3.29 3.60 3.59
CoT+Cor+Tra 4.92 3.21 3.18 3.70 3.46
GOLD 4.04 3.08 3.05 3.53 3.21
ORIG 6.75 2.28 2.15 2.41 2.22
GPT-S 4.84 3.00 3.00 3.40 3.10
GPT-R 4.82 3.09 3.09 3.72 3.44
Table4: QualityreportingofrefinedsummariesforallTranscriptProtocols(TP)andFeedbackProtocols(FP)
combinations(CoT=CoTexplanation,Cor=correction,Tra=Transcript).Rankingistheaveragerankingacrossall
samples. Lowerrankingscoresindicatehigherpreference(1(alwayspreferred)to20(alwaysdisliked)). REL,INF,
CON,COHaretheAUTOCALIBRATELikertscoresonrelevance,informativeness,conciseness,andcoherence
usinga5-stepLikertscale(1(worst)to5(best)). BestscoresperTParebold,bestscoresoverallareunderlined.
5.4 Evaluationapproach setupaGPT4-poweredrankingsystem,motivated
bytypicalhumanannotationrankings,basedonob-
ROUGE(Lin,2004)andBERTScore(Zhangetal.,
servableerrorsfromSection3.1(seeAppendixD
2020b),establishedmetricsformeetingsummary
forpromptdetails). Wefollowtheapproachused
evaluation(Kirsteinetal.,2024a),yieldscorestoo
beforetoensurereliabilityandalignmentwithhu-
similarforinterpretationacrossprotocolvariants
manannotations(inter-annotatoragreement: 0.784
(see Table 8). As human evaluation on all gener-
Krippendorff’salpha,GPT4acc.: 92.1%).
atedrefinedsummaries(total∼3.4k)isinfeasible,
weusetheLLM-basedmetricAUTOCALIBRATE
5.5 Summaryrefinementdiscussion
(Liu et al., 2023) to report Likert scores on rele-
vance(REL),informativeness(INF),conciseness Influence of feedback and transfer protocols
(CON), and coherence (COH). Since this metric on quality. Table 4 shows the overall ranking
is not developed for meeting summarization, we andLikertscoresofeachrefinementprotocolvari-
assess alignment with human judgment by hav- ant. ORIGsummariesareconsistentlyrankedlow-
ingsixannotatorsrateasubsetof200summaries est,indicatingthatrefinementpositivelyinfluences
according to AUTOCALIBRATE prompts (inter- quality,asobservedintheassignedLikertscores.
annotatoragreement(Krippendorff’salpha): REL: HavingonlytheessentialpartintheFPleadsto
0.775,INF:0.798,CON:0.833,COH:0.803). As minorimprovementsinrankingandLikertscores
theLLM-basedevaluationalignssufficientlywith forbothTPscomparedtotheORIGsummary,but
annotatorlabels(accuracy: 89.1%),weuseAUTO- fallingbehindthescoresofmostprotocolvariants
CALIBRATEasourmainqualityproxy. Neverthe- using additional information. This indicates that
less, we manually check every fourth score tuple pointing out errors on a high level already leads
and model reasoning to confirm alignment with toqualityimprovement. Theresultisexpected,as
theevaluationtaskandhumanjudgment. Incase theminimalisticexplanationmaynotcontainevery
of misalignment, three annotators would instead errorinstance,precisereasoning,orallinformation
rate the summary. As AUTOCALIBRATE only toresolvespecificerrorssuchasomission. Com-
assessesspecificcharacteristicsanddoesnotcon- paringtheessentialpartsscoresofbothTPsreveals
sideromission,hallucination,orrepetition,wealso that the Likert scores and rankings differ notablybetweenthetwowiththescoresusingconsolidated format compresses information about individual
TP being ∼ 0.7 points less. We derive from this errorstoomuch,makingithardfortherefinement
observationthattheprovidedfeedbackinfluences model to interpret when the total number of er-
scoresandleadstoqualitychanges. rorsislarge. Thiscanhappenespeciallywithlong
For the direct TP, CoT explanation and correc- meetings(16ktokensinputtext)comparedtonews
tionarerankedhigher(avg. ranks∼3.75)thanthe summarizationwithinputtextsof200tokens. We
GPT-S summaries (avg. rank 4.84) and are close leave to future work the exploration of a similar
to GOLD summaries (avg. rank 4.04). CoT ex- planningsetupthatappliesthedescribedconsolida-
planationandcorrection-basedrefinementoutper- tionstructuretoeacherror-relatedfeedbackblock
formtranscript-basedrefinementsinoverallrank- ratherthantothewholefeedback
ing (avg. rank 4.68 to 5.10) but fall behind in We conclude that the feedback from the MIP
Likertscores,whichappearscounter-intuitive. The containing CoT explanations already provides a
ranking LLM’s reasoning reveals that transcript- strongfoundationforimprovingORIGsummaries
basedrefinementcontainsrepetitions,failstosepa- andbringingtheirqualityclosetothatofahuman
ratetopics,andlacksdetails,leadingtoanoverall summary. Correctionsuggestionisapromisingal-
worseratingcomparedtoCoTandcorrection. As ternativeforCoTexplanationasFPwithcompara-
thelongerpromptwhenprovidingtranscripts(avg. bleratingsonquality,allowingforfurtherresearch
20ktokenswithtranscript,4ktokenswithouttran- toidentifywhentousewhichFP.
script)isstillonlyasixthofGPT4’scontextsize,
we hypothesize that the additional task of cross- 6 FinalConsiderations
checkingerrorswiththetranscriptmayconfusethe
model due to content repetition and noise in the Inthispaper,weinvestigatedGPT4’sabilitytofind
formofunnecessarydetails. CoTexplanationand mistakes in a given meeting summary and refine
correctionappearasaleanalternativecontaining them accordingly. We found that GPT4 achieves
relevantinformationforqualityimprovement. a high accuracy of ∼89% on average, measured
CoT explanation and correction (avg. ranks against human labels, in identifying typical mis-
∼3.75) both outperform the combined use of the takes(e.g.,repetitionofcontent)whenusingaded-
two (avg. ranking of 5.1 with and 4.11 without icatedmodelinstancepairedwithCoTprompting
transcript). The analysis of the ranking model’s toidentifyindividualerrors. However,itstruggles
explanation shows that the repetition of content to identify similar and subjective errors, such as
inCoTandcorrectioncanleadtomultipleoccur- hallucination(72%acc.) withomissionandirrele-
rencesofthesameinformation,whilecontradicting vance(81%acc.). Weshowedstrongevidencethat
contentmayleadtotheinclusionofwronginfor- adedicatedLLMcanrefineasummarybasedon
mation(seeanexampleinFigure9). identifiederrors. ByprovidingaCoTexplanation
FortheconsolidationTP,FPswithouttranscripts foreacherrortypecontainingreasoningwhyand
barelyimprovesummaryquality(avg. ranksrange whereanerrorwasobserved,weimprovethequal-
from5.61to6.40). Transcript-usingvariantsper- ityofrelevance,informativeness,conciseness,and
formsimilarlytotheirdirectTPcounterpartsbut coherencesignificantly. Theserefinedsummaries
withrankingsandscoresclosertogether. Further, arecomparableinquality,witherror-freegoldsum-
their scores are close to the GPT-R results. This maries. Ourposthocrefinementapproachcanbe
indicatesthattheconsolidatedfeedbackhaslessin- appliedtorefinemeetingsummariesgeneratedby
fluenceonrefinementthanthedirectfeedbackand traditionalmodelsandLLMsandmarksanearly
thattherefinementmodelreliesmoreonthetran- entryintomethodsthatallowthefullpotentialof
scripttorewritethesummary. Therefinermodel’s LLMs for meeting summarization. We leave the
reasoning reveals that the refinement approaches developmentofmoresophisticatedrefinementpro-
with consolidation TP and without transcript ac- tocols,e.g.,usingmulti-agentdiscussion,andthe
cessoftenomitdetailsandlackconciseness,which applicationofourmulti-LLMapproachtosimilar
isalsoobservableintheLikertscores(e.g.,CON complextextgenerationtasks(e.g.,storywritingto
up to 0.47 points down). We conclude that the reflectongivensetting)andreal-worldapplications
consolidatedapproach,effectiveinshortnewssum- (e.g.,assistingLLMagentstochecktheoutcometo
marization(Zhangetal.,2023a),doesnotperform atask)tofuturework. WereleaseQMSumMistake
wellformeetingsummarization,likelybecausethe toencourageresearchonrefinement.Acknowledgements thatthedatasetsinourstudy,publiclyavailable,do
nothousesensitiveorpersonaldetails. Whileour
This work was supported by the Lower Saxony
studyleveragesexistingresourcesandgenerative
MinistryofScienceandCultureandtheVWFoun-
models, it’s important to note that these models
dation. Frederic Kirstein was supported by the
canpossessbiasesandmayoccasionallygenerate
Mercedes-BenzAGResearchandDevelopment.
summarieswithdistortions,biases,orinappropri-
atecontent. Tocounteractthis, we’veconfigured
PotentialImpact
our models to omit potentially harmful or unsafe
The multi-LLM approach proposed here, influ- content. Whileourresearchaimstoenhancemeet-
enced by psychological observations on produc- ingsummarizationtobenefitcommunicationand
tivityandcollaboration,exemplifieshowotheraca- productivity across sectors, we’re acutely aware
demicfieldscaninformNLPresearch(Wahleetal., of the ethical challenges posed by AI in this do-
2023b). Thisworkdemonstratesthepotentialfor main. Meeting summarization models must be
enhancingcomplextextgenerationtasksrequiring wielded with respect to privacy and consent, es-
robust output such as machine translation (Feng peciallywhenprocessingsensitiveorconfidential
et al., 2024), reasoning (Kalyanpur et al., 2024), material. It’sparamountthatthesemodelsneither
questionanswering(Kimetal.,2024),orparaphras- violateprivacynorperpetuateharmfulbiases. As
ing(Beckeretal.,2023;Wahleetal.,2023a),that thefieldevolves,westresstheimportanceofmain-
maybenefitfromanoutput-challengingsystemthat tainingtheseethicalconsiderationsandencourage
assessescontentalignment. Byincorporatingmulti- fellow researchers to uphold them, ensuring that
LLMstrategiesandpersonalization,weopennew AI advancements in meeting summarization are
avenuesforimprovingNLPoutputsacrossvarious bothbeneficialandethicallygrounded. Anintegral
applications,underscoringthevalueofinterdisci- aspect of our ethical commitment is reflected in
plinaryapproachesinadvancingNLPtechnologies ourapproachtoannotatorrecruitmentandmanage-
andtheirreal-worldapplicability. ment. Theteamofannotators,consistingofinterns,
studentassistants,anddoctoralstudents,wasmetic-
Limitations ulously selected through internal channels. This
strategywaschosentoupholdahighstandardof
Although our proposed QMSum Mistake might
annotationquality—aqualitywefoundchalleng-
seem small (i.e., 200 samples), its size is com-
ing to guarantee through external platforms such
parable to the original QMSum dataset (i.e., 232
asAmazonMechanicalTurk. Ensuringfaircom-
samples). Wecontributetoextendingtheoriginal
pensation, these annotators were remunerated in
dataset with careful human error annotations for
accordance with institutional guidelines for their
almost all examples available. Another possible
respectivepositions. Further,flexibilityintheanno-
limitationinourworkistheuseofonlyGPT4in
tationprocesswasalsoapriority. Annotatorshad
ourmainexperiments. WechoseGPT4becauseof
thefreedomtochoosetheirworkingtimesanden-
its large context size (e.g., 128k tokens) and bet-
vironmentstopreventfatiguefromaffectingtheir
terinitialresultsinidentifyingerrors. Evaluating
judgment.
and error annotation and refinement for multiple
modelsbyhumanswouldbetime-consumingand
financiallyunfeasible. However,wereportthede-
References
tailed results in Appendix B to provide insights
on other language families and different models
Marah Abdin, Sam Ade Jacobs, and Ammar Ahmad
(e.g.,Phi(Abdinetal.,2024),Gemini(Teametal., Awan. 2024. Phi-3 Technical Report: A Highly
2024))consideredinourstudy. Weevaluatetheir Capable Language Model Locally on Your Phone.
Preprint,arxiv:2404.14219.
performanceonmistakeidentificationandquality
changeswhenrefiningasummary.
Abedelkadir Asi, Song Wang, Roy Eisenstadt, Dean
Geckt,YarinKuper,YiMao,andRoyiRonen.2022.
EthicsStatementandBroaderImpact
AnEnd-to-EndDialogueSummarizationSystemfor
SalesCalls. InProceedingsofthe2022Conference
Our research abides by ethical guidelines for AI
of the North American Chapter of the Association
researchandiscommittedtoprivacy,confidential-
for Computational Linguistics: Human Language
ity,andintellectualpropertyrights. We’veensured Technologies: IndustryTrack,pages45–53,Hybrid:Seattle,Washington+Online.AssociationforCom- AdityaKalyanpur,KailashSaravanakumar,VictorBar-
putationalLinguistics. res,JenniferChu-Carroll,DavidMelville,andDavid
Ferrucci. 2024. LLM-ARC: Enhancing LLMs
JonasBecker,JanPhilipWahle,TerryRuas,andBela with an Automated Reasoning Critic. Preprint,
Gipp.2023. ParaphraseDetection: Humanvs.Ma- arXiv:2406.17663.
chineContent. Preprint,arXiv:2303.13989.
MuhammadKhalifa,MiguelBallesteros,andKathleen
Iz Beltagy, Matthew E. Peters, and Arman Cohan. McKeown.2021. ABagofTricksforDialogueSum-
2020. Longformer: The Long-Document Trans- marization. InProceedingsofthe2021Conference
former. https://arxiv.org/abs/2004.05150v2. onEmpiricalMethodsinNaturalLanguageProcess-
ing,pages8014–8022,OnlineandPuntaCana,Do-
JeanCarletta,WesselKraaij,SimoneAshby,Sebastien minican Republic. Association for Computational
Bourban, Michael Flynn, M. Guillemot, T. Hain, Linguistics.
J. Kadlec, V. Karaiskos, M. Kronenthal, G. Lath-
oud,MichaelLincoln,A.Lisowska,W.Post,D.Rei- Geunwoo Kim, Pierre Baldi, and Stephen McAleer.
dsma,P.Wellner,andL.McCowan.2005. TheAMI 2023. LanguageModelscanSolveComputerTasks.
MeetingCorpus. ProceedingsofSymposiumonAn- Preprint,arxiv:2303.17491.
notatingandMeasuringMeetingBehavior.
Jaehyung Kim, Dongyoung Kim, and Yiming Yang.
2024. LearningtoCorrectforQAReasoningwith
YapeiChang,KyleLo,TanyaGoyal,andMohitIyyer.
Black-boxLLMs. Preprint,arXiv:2406.18695.
2024. BooookScore: A systematic exploration
of book-length summarization in the era of LLMs.
Frederic Kirstein, Jan Philip Wahle, Bela Gipp, and
Preprint,arxiv:2310.00785.
TerryRuas.2024a. CADS:ASystematicLiterature
ReviewontheChallengesofAbstractiveDialogue
VipulChauhan,PrasenjeetRoy,LipikaDey,andTushar
Summarization. Preprint,arxiv:2406.07494.
Goel. 2022. TCS_WITM_2022 @ DialogSum :
Topic oriented Summarization using Transformer
Frederic Kirstein, Jan Philip Wahle, Terry Ruas, and
basedEncoderDecoderModel. InProceedingsof
BelaGipp.2024b. What’sunderthehood:Investigat-
the15thInternationalConferenceonNaturalLan-
ingAutomaticMetricsonMeetingSummarization.
guage Generation: Generation Challenges, pages
https://arxiv.org/abs/2404.11124v1.
104–109,Waterville,Maine,USAandvirtualmeet-
ing.AssociationforComputationalLinguistics.
KlausKrippendorff.1970. BivariateAgreementCoeffi-
cientsforReliabilityofData. SociologicalMethod-
Zhaopeng Feng, Yan Zhang, Hao Li, Bei Wu, Jiayu
ology,2:139–150.
Liao,WenqiangLiu,JunLang,YangFeng,JianWu,
and Zuozhu Liu. 2024. TEaR: Improving LLM-
MdTahmidRahmanLaskar,Xue-YongFu,ChengChen,
based Machine Translation with Systematic Self-
andShashiBhushanTn.2023. BuildingReal-World
Refinement. Preprint,arXiv:2402.16379.
MeetingSummarizationSystemsusingLargeLan-
guageModels: APracticalPerspective. InProceed-
YilunHua,ZhaoyuanDeng,andKathleenMcKeown.
ingsofthe2023ConferenceonEmpiricalMethodsin
2023. Improving Long Dialogue Summarization
NaturalLanguageProcessing: IndustryTrack,pages
withSemanticGraphRepresentation. InFindingsof
343–352,Singapore.AssociationforComputational
theAssociationforComputationalLinguistics: ACL
Linguistics.
2023,pages13851–13883,Toronto,Canada.Associ-
ationforComputationalLinguistics. Kahyun Lee, Mehmet Kayaalp, Sam Henry, and
Özlem Uzuner. 2021a. A Context-Enhanced De-
Jie Huang, Xinyun Chen, Swaroop Mishra, identificationSystem. ACMTransactionsonCom-
Huaixiu Steven Zheng, Adams Wei Yu, Xiny- putingforHealthcare,3(1):6:1–6:14.
ingSong,andDennyZhou.2024. LargeLanguage
Models Cannot Self-Correct Reasoning Yet. Seolhwa Lee, Kisu Yang, Chanjun Park, João Sedoc,
Preprint,arxiv:2310.01798. andHeuiseokLim.2021b. WhoSpeaksLikeaStyle
ofVitamin: TowardsSyntax-AwareDialogueSum-
A. Janin, D. Baron, J. Edwards, D. Ellis, D. Gelbart, marizationUsingMulti-TaskLearning. IEEEAccess,
N.Morgan,B.Peskin,T.Pfau,E.Shriberg,A.Stol- 9:168889–168898.
cke,andC.Wooters.2003. TheICSIMeetingCor-
pus. In 2003 IEEE International Conference on Mike Lewis, Yinhan Liu, Naman Goyal, Marjan
Acoustics,Speech,andSignalProcessing,2003.Pro- Ghazvininejad, Abdelrahman Mohamed, Omer
ceedings.(ICASSP’03).,volume1,pagesI–I. Levy, Veselin Stoyanov, and Luke Zettlemoyer.
2020. BART:DenoisingSequence-to-SequencePre-
DongweiJiang,JingyuZhang,OrionWeller,Nathaniel trainingforNaturalLanguageGeneration,Transla-
Weir, Benjamin Van Durme, and Daniel Khashabi. tion,andComprehension. InProceedingsofthe58th
2024. SELF-[IN]CORRECT:LLMsStrugglewith AnnualMeetingoftheAssociationforComputational
Refining Self-Generated Responses. Preprint, Linguistics,pages7871–7880,Online.Association
arxiv:2404.04298. forComputationalLinguistics.Zhen Li, Xiaohan Xu, Tao Shen, Can Xu, Jia-Chen Self-critiquingmodelsforassistinghumanevaluators.
Gu, and Chongyang Tao. 2024. Leveraging Large Preprint,arxiv:2206.05802.
Language Models for NLG Evaluation: A Survey.
Preprint,arxiv:2401.07103. NoahShinn,FedericoCassano,EdwardBerman,Ash-
winGopinath,KarthikNarasimhan,andShunyuYao.
Chin-Yew Lin. 2004. ROUGE: A Package for Auto- 2023. Reflexion: LanguageAgentswithVerbalRe-
maticEvaluationofSummaries. InTextSummariza- inforcementLearning. Preprint,arxiv:2303.11366.
tionBranchesOut,pages74–81,Barcelona,Spain.
AssociationforComputationalLinguistics. Gemini Team, Machel Reid, Nikolay Savinov, Denis
Teplyashin, Dmitry, Lepikhin, and Timothy Lilli-
Yuxuan Liu, Tianchi Yang, Shaohan Huang, Zihan
crap. 2024. Gemini 1.5: Unlocking multimodal
Zhang, Haizhen Huang, Furu Wei, Weiwei Deng,
understandingacrossmillionsoftokensofcontext.
Feng Sun, and Qi Zhang. 2023. Calibrating LLM-
Preprint,arxiv:2403.05530.
BasedEvaluator. Preprint,arxiv:2309.13308.
GladysTyen,HassanMansoor,VictorCa˘rbune,Peter
AmanMadaan,NiketTandon,DheerajRajagopal,Peter
Chen,andTonyMak.2024. LLMscannotfindrea-
Clark,YimingYang,andEduardHovy.2021. Think
soning errors, but can correct them given the error
about it! Improving defeasible reasoning by first
location. Preprint,arxiv:2311.08516.
modelingthequestionscenario. InProceedingsof
the2021ConferenceonEmpiricalMethodsinNatu-
Jan Philip Wahle, Bela Gipp, and Terry Ruas. 2023a.
ralLanguageProcessing,pages6291–6310,Online
ParaphraseTypesforGenerationandDetection. In
andPuntaCana,DominicanRepublic.Association
Proceedings of the 2023 Conference on Empirical
forComputationalLinguistics.
Methods in Natural Language Processing, pages
SajadMousavi,RicardoLunaGutierrez,DesikRengara- 12148–12164, Singapore. Association for Compu-
jan,VineetGundecha,AshwinRameshBabu,Avisek tationalLinguistics.
Naug,AntonioGuillen,andSoumyenduSarkar.2023.
N-CRITICS: Self-Refinement of Large Language JanPhilipWahle,TerryRuas,MohamedAbdalla,Bela
ModelswithEnsembleofCritics. Gipp, and Saif Mohammad. 2023b. We are Who
WeCite: BridgesofInfluenceBetweenNaturalLan-
Yuji Naraki, Tetsuya Sakai, and Yoshihiko Hayashi. guageProcessingandOtherAcademicFields. InPro-
2022. Evaluating the Effects of Embedding with ceedingsofthe2023ConferenceonEmpiricalMeth-
SpeakerIdentityInformationinDialogueSummariza- odsinNaturalLanguageProcessing,pages12896–
tion. InProceedingsoftheThirteenthLanguageRe- 12913, Singapore. Association for Computational
sourcesandEvaluationConference,pages298–304, Linguistics.
Marseille, France. European Language Resources
Association. BinWang,ChenZhang,YanZhang,YimingChen,and
HaizhouLi.2022. AnalyzingandEvaluatingFaith-
LongOuyang,JeffWu,XuJiang,DiogoAlmeida,Car- fulnessinDialogueSummarization. InProceedings
rollL.Wainwright,PamelaMishkin,ChongZhang, ofthe2022ConferenceonEmpiricalMethodsinNat-
SandhiniAgarwal,KatarinaSlama,AlexRay,John uralLanguageProcessing,pages4897–4908,Abu
Schulman,JacobHilton,FraserKelton,LukeMiller, Dhabi,UnitedArabEmirates.AssociationforCom-
Maddie Simens, Amanda Askell, Peter Welinder, putationalLinguistics.
Paul Christiano, Jan Leike, and Ryan Lowe. 2022.
Traininglanguagemodelstofollowinstructionswith JasonWei,XuezhiWang,DaleSchuurmans,Maarten
humanfeedback. Preprint,arxiv:2203.02155. Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le,
andDennyZhou.2023. Chain-of-ThoughtPrompt-
Liangming Pan, Michael Saxon, Wenda Xu, Deepak
ing Elicits Reasoning in Large Language Models.
Nathani,XinyiWang,andWilliamYangWang.2023.
Preprint,arxiv:2201.11903.
AutomaticallyCorrectingLargeLanguageModels:
Surveying the landscape of diverse self-correction
Haopeng Zhang, Xiao Liu, and Jiawei Zhang. 2023a.
strategies. Preprint,arxiv:2308.03188.
SummIt: IterativeTextSummarizationviaChatGPT.
Preprint,arxiv:2305.14835.
JasonPhang,YaoZhao,andPeterJ.Liu.2022. Investi-
gatingEfficientlyExtendingTransformersforLong
Jingqing Zhang, Yao Zhao, Mohammad Saleh, and
InputSummarization. Preprint,arxiv:2208.04347.
Peter J. Liu. 2020a. PEGASUS: Pre-training with
ColinRaffel,NoamShazeer,AdamRoberts,Katherine extractedgap-sentencesforabstractivesummariza-
Lee,SharanNarang,MichaelMatena,YanqiZhou, tion. InProceedingsofthe37thInternationalConfer-
WeiLi,andPeterJ.Liu.2020. Exploringthelimits enceonMachineLearning,volume119ofICML’20,
oftransferlearningwithaunifiedtext-to-texttrans- pages11328–11339.JMLR.org.
former. TheJournalofMachineLearningResearch,
21(1):140:5485–140:5551. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.
Weinberger, and Yoav Artzi. 2020b. BERTScore:
WilliamSaunders,CatherineYeh,JeffWu,StevenBills, Evaluating Text Generation with BERT. Preprint,
LongOuyang,JonathanWard,andJanLeike.2022. arxiv:1904.09675.YusenZhang,YangLiu,ZiyiYang,YuweiFang,Yulong AssessedCharacteristic Krippendorff’sα
Chen, Dragomir Radev, Chenguang Zhu, Michael
Omission(partial) 0.787
Zeng,andRuiZhang.2023b. MACSUM: Control-
Omission(total) 0.834
lableSummarizationwithMixedAttributes. Trans-
Repetition 0.889
actionsoftheAssociationforComputationalLinguis- Incoherence 0.764
tics,11:787–803. Coreference 0.719
Hallucination 0.764
MingZhong,YangLiu,YichongXu,ChenguangZhu, Language 0.748
and Michael Zeng. 2022. DialogLM: Pre-trained Structure 0.795
ModelforLongDialogueUnderstandingandSum- Irrelevance 0.719
marization. Preprint,arxiv:2109.02492.
Table5:Inter-raterreliabilityforthehumanannotations,
MingZhong,DaYin,TaoYu,AhmadZaidi,Mutethia
measured by Krippendorff’s alpha. Scores ≥ 0.667
Mutuma,RahulJha,AhmedHassanAwadallah,Asli
meanmoderateagreement,scores≥0.8meanstrong
Celikyilmaz,YangLiu,XipengQiu,andDragomir
agreement.
Radev. 2021. QMSum: A New Benchmark for
Query-basedMulti-domainMeetingSummarization.
InProceedingsofthe2021ConferenceoftheNorth
AmericanChapteroftheAssociationforComputa- quality,alignunderstanding,andconductongoing
tionalLinguistics: HumanLanguageTechnologies, qualitycontrol. Anexpertannotatorwasavailable
pages5905–5921,Online.AssociationforComputa- to discuss complex issues during the annotation
tionalLinguistics.
process.
A HumanAnnotation
B ExploringAdditionalModelFamilies
Weadaptprovenmethodologiesforathoroughhu- andSetups
manannotation(Zhangetal.,2023b). Sixgraduate
In this section, we task models from the Phi and
students 9 aged 22 to 28, from diverse academic
Geminifamiliesonthemistakeidentificationand
backgrounds(e.g.,computerscience,psychology,
refinementtasks. Particularly,weconsiderGemini
communicationscience),proficientinEnglishand
Flash(Gemini)andthe3.4BparameterPhi-3mini
familiarwithmeetingsummarization,participateas
128k(Phi). Wechosethesemodelsbecausetheir
annotators. Eachannotates2-4subsetsofQMSum
context size is large enough to fit a meeting tran-
Mistake (35 samples per subset, each containing
scriptwithoutrequiringmajorarchitectureadapta-
transcripts,goldsummaries,andmodel-generated
tionandbecausetheyareavailable. Wefurtheropt
summaries),withatleastthreeannotatorspersam-
forsmallermodelversionscomparedtoGPT4to
ple. The annotators identify errors by answering
analyzetheperformancedifferences. Weperform
yes/noquestions(e.g.,"Doesthesummarycontain
theexperimentson25%oftheerroneousQMSum
repetition?")andprovidereasoningforobserved
Mistakesamplestoderiveinitialtrends.
mistakesforqualityassessment. Toensurereliable
and consistent annotation, we implement several
B.1 MistakeIdentificationwithsmaller
measures. Inter-annotator agreement is assessed
models
usingKrippendorff’salpha(Krippendorff,1970),
achieving an average of 0.764 (see Table 5), in-
Error Gemini Phi GPT4
dicating a moderate to strong agreement on the
P-OM 87.5 87.5 87.5
assessment. A training course is run before the
T-OM 75.0 75.0 92.5
annotation task to train annotators, refine guide- REP 35.0 32.5 90.0
INC 62.5 32.5 95.0
lines, and identify new error types. Annotators
COR 15.0 7.5 92.5
practice on QMSum summaries produced by the HAL 57.5 57.5 57.5
LEDmodel,whicharenotusedforthefinalQM- LAN 35.0 35.0 72.5
STR 37.5 20.0 92.5
SumMistakedataset. Duringtheactualannotation
IRR 60.0 60.0 77.5
task, we add gold summaries that the annotators
should be able to evaluate correctly. Otherwise, Table6:MistakefindingaccuracyofGemini,Phi,GPT4
theirannotationwouldberejected,andtheirunder- onasubsetofQMSumMistake.
standingofthetaskwouldbediscussed. Regular
reviewmeetingsareheldtomaintainconsistencyin Table 6 shows the accuracies of these models
in terms of identifying errors, all using the best
9Theoriginofthefundsandannotatorswillbedisclosed
latertoavoidtherisktogivetheauthorsidentity. MIP protocol identified in Section 4, containingmultiplemodelinstancesandCoTprompting. As OVR↓ REL↑ INF↑ CON↑ COH↑
expected,GeminiandPhishowweakeraccuracy,
GPT4 1.24 3.05 3.07 3.21 2.98
which can mostly be attributed to their smaller Phi 1.84 2.78 2.98 2.93 3.04
model sizes. Notably, Phi struggles to report er- GOLD 1.43 3.08 3.05 3.53 3.21
rorsinthepromptedoutputformat,similartohow ORIG 2.77 2.28 2.15 2.41 2.22
GPT4strugglesinthesingle-instancesetup,while
Table 7: Ranking and scoring of Phi and GPT4 ac-
Geminiiscloserinitsanswerpatterntowhatwe
cording to their quality. OVR is the overall ranking,
observedforGPT4inthesingle-instancesetup. Phi
withlowerscoresindicatingamorepreferredsummary.
andGeminialsoshowanoversensitivitytoerrors
REL, INF, CON, and COH are relevant, informative-
as we hypothesize for GPT4 (Section 4.2). This ness,conciseness,andcoherence. Thescoringusesa
oversensitivityismorepronouncedforthesmaller 5-stepLikertscale,with1beingtheworstand5best.
Phi model than for Gemini. This oversensitivity
leadstoamatchinaccuracyforP-OMandHAL,
as all models reported here an always-true result. B.3 Multiplerounds
Consideringthemodels’reasoningforthescores,
Sofarwehaveexploredtheapplicationofthere-
weobservefurthersupportforthishypothesis. For
finementconceptinasingleround,withonepass
example, Gemini reports the mention of partici-
ofthemistakeidentificationandsummaryrefine-
pants’ names as an unnecessary repetition. We
ment. Following, weexplorehowtherefinement
concludethateventhoughthesemodelshaveasim-
qualitychangeswhenGPT4canreconsiderthegen-
ilar(Phi)orlarger(Gemini)contextsizecompared
eratedsummaryfor10rounds. Wekeepthebest-
to GPT4, the significantly fewer parameters hurt
performingsetup(multi-instancewithCoTprompt-
thetaskunderstandingandcontextualization. Fur-
ingforMIP,CoTexplanationFP,directfeedback
ther, the oversensitivity appears to be linked to a
TP)andusethesmallsubsetofQMSumMistake.
model’s understanding capabilities, which in the
Wereporttherankingofthedifferentsummaries
consideredcaseisconnectedtothemodelsize.
in Figure 3, observing that while the one-round
B.2 RefinementPerformancewithSmaller performanceisstrongenoughtoimproveagiven
Models summarytoaqualitylevelcomparabletoahuman
summary, it can be further improved. From the
Table 7 reports the quality of one-round refined
ranking model’s reasoning, we observe that this
summaries using Phi and GPT4 on the subset of
improvementmainlyinvolvesreducingremaining
QMSum Mistake. Note that GEMINI is not re-
omissionerrorsandfittingthesummarybetterto
portedhereasthemodelconsistentlydidnotpro-
the comprehensiveness GPT4 asks for. Notably,
videanyrefinements. Bothmodelswereprompted
weobserveinstancesofstrongdegradation,e.g.,in
withthebest-performingrefinementprotocol,i.e.,
6whichfollowsaprevioustrendofreducedqual-
multipleinstancesofCoTwerepromptedformis-
ity. We derive from this that while there may be
take identification, CoT explanation was used as
more potential to further improve summaries by
feedback,anddirectfeedbackwasusedasatrans-
applying the refinement protocol multiple times,
ferprotocol. Wefollowtheevaluationapproachin
it may quickly saturate, and unwanted errors are
Section5.4. WeobservethateventhoughPhidoes
induced. From the ranking model’s explanation,
notreliablydetecterrors,theexhaustivepointing
weobservethatthiscorrelateswithanincreasein
outofpossibleerrorcasesandtherefinementstep
repetitionandhallucination. Weconcludethatmul-
helptoimprovethequality,consideringtheLikert
tiple rounds of refinement can potentially further
scores by 0.4 to 0.8 points. However, it is note-
improvesummaries,butthisrequiresdedicatedre-
worthythatPhisometimesstruggleswithrefining
search.
asummaryandinsteaddetailsthegivenfeedback.
We therefore conclude, that Phi is capable of re-
fining a summary given a list of observed errors C QMSumMistakevarying
and reasoning for the observation, but the small- summarizationstylesandqualitylevels
est model struggles with the task understanding. ofmodels
Hence,withadaptionssuchasfew-shotexamples
orbyusingPhi-3small,Phimaybeacheapalter- We show one examples of QMSum Mistake for
nativetoGPT4forsummaryrefinement. eachusedlanguagemodelinTable9.Figure3: Rankingofmultiplesummariesrefinedforupto10rounds. Thereddottedlineindicatestherankingof
theGOLDsummaries.
D Prompts
In the following, we present the prompts used to
identify mistakes (Figure 4), to consolidate feed-
back(Figure5),andtorefineasummary(Figure6).
Figure7showsafew-shotexampleofP-OM.Fig-
ure8providestheprompttemplateforLLM-based
ranking.
TP FP BS R-1 R-2 RLS
dir essential 16.20 33.73 07.46 20.53
E AdditionalContentonSummary
dir CoT 16.16 33.89 07.57 20.41
dir Cor 16.19 33.89 07.52 20.39 Refinement
dir CoT+Cor 16.35 33.90 07.56 20.58
dir Tra 15.28 33.89 07.82 20.99 E.1 EstablishedMetrics’scores
dir Tra+CoT+Cor 15.12 33.78 07.94 21.31
Table 8 reports the BERTScore (Zhang et al.,
con essential 14.27 29.79 05.58 18.26
2020b) (re-weighted) and ROUGE (Lin, 2004)
con CoT 14.28 29.36 05.43 18.12
con Cor 15.11 29.64 05.55 18.37 scores for different combinations of FP and TP.
con CoT+Cor 15.15 29.71 05.71 18.13 Note that the scores are very close to each other
con Tra 14.96 29.90 05.55 18.55
withslightvariation,thatdoesnotallowforathor-
con Tra+CoT+Cor 14.98 30.07 05.76 18.47
oughanalysis.
Table 8: Score of the established evaluation metrics
E.2 CorrectionandCoTarecontradictory
BERTScore(BS)andROUGE(R-1=ROUGE1,R2=
ROUGE2,RLS=ROUGELSum). Figure9demonstratesacaseofcontradictinginfor-
mationinCoTexplanationandcorrectionsugges-
tion.Architecture Language Summary Errors
Model
REP,LAN
enc-dec LED Thegroupdiscussedthecomponentsdesignoftheremotecontrol. INC,P-OM
Firstly,theydiscussedtheshapeofthebuttons,thesizeofthescreen, T-OM,HAL
thecolouroftherubbercase,andthematerial. Then,theytalked
aboutthematerialdesign.Afterthat,thegroupdiscussedhowthe
remote should look like a fruit and vegetable. Finally, the team
discussedthedesignofatouch-basedgraphicalinterfacesystem.
Theteamdecidedtousethewheelymaterialinsteadofarubbercase
fortheLCDscreen.Thenthegrouptalkedabouthowthematerial
shouldbeusedfortheremote,andhowitshouldbeeasytoswitch
to.
REP,LAN
INC,P-OM
DialogLED Thiswasthekick-offmeetingforthenewremotecontrolproject.
T-OM,COR
ProjectManagerstartedthemeetingbyintroducingtheteammem-
HAL,STR
berstoeachother.IndustrialDesignerintroducedthegroupasthe
projectmanager. MarketingandUserInterfacegaveabriefabout
theprojectandthedesignoftheremotecontrol. ThenIndustrial
Designergavethebriefabouttheirfavouritecharacteristicsoftheir
favouriteanimals.Thenthegroupgottodrawtheirfavouriteanimal
andsumuptheirfavoritecharacteristicsofit. Industrialdesigner
gavethefinalproductandtheteamgottochoosethefavouriteanimal
ofthegroup.
LAN,P-OM
PEGASUS-X Project Manager introduced some new project requirements that
T-OM
camein,andthenIndustrialDesignerdiscussedtheworkingdesign
oftheremotecontrol.UserInterfaceandIndustrialDesignertalked
aboutthebuttonsandwhatitdoesandthatsortofthing. Project
Managerdiscussedthetargetagegroupandhowit’sgonnaappeal
totheirtargetgroup. MarketingandUserInterfacediscussedthe
functions of the circle disc, the touch pad, and the volume and
channelchangers.IndustrialDesignersaidthatitwouldbeeasyto
implementandthatit’dbecompatiblewithD-V-D-typeremotes.
P-OM,T-OM
autoreg GPT-3.5 Theconversationisaboutateamdiscussingthedesignofanew
HAL,IRR
remotecontrolforatelevision.Theprojectmanagermentionsthat
theremotecontrolshouldbeoriginal,trendy,anduser-friendly.The
teamdiscussesdifferentideasfortheremotecontrol,includingusing
speech recognition for navigation and having a light adaptation
system.Theyalsodiscusstheimportanceofoptimizingthenumber
ofbuttonsandthesizeoftheremotecontrol.Theindustrialdesigner
suggestsgatheringdatafromprogramsorcontentandnavigating
throughthemusingtheremotecontrol.Theteamagreestodiscuss
technicalpointsandgathermoreinformationinthenextmeeting.
Theyalsomentiontheneedtoassignrolesandresponsibilitiesfor
different aspects of the design. The conversation ends with the
projectmanagersuggestingafollow-upmeetinginfiveminutesto
discussotheraspectsofthedesign.
P-OM,T-OM
Phi-3mini Thegroupdiscussedtheprogressondigits,specificallythealmost
HAL
completionoftheTI-digitsprojectandtheplantotrainarecognizer
with the data. They also talked about the possibility of having
transcribers manually input the digits from a meeting recording,
which would result in a more complete transcript. There was a
debateonwhetherthistaskshouldbedonebythetranscribersor
automated.Additionally,theytouchedonthequalityofthecurrent
modelsandthepotentialforimprovement,aswellasthedifferences
inpronunciationwhenreadingdigitscomparedtoconversational
speech.TheyconsideredusingSwitchboarddataforfurtherresearch
anddiscussedtheneedforamorecomprehensiveannotationsystem
thatincludesarticulatoryfeatures.
Table9: SamplesoftheQMSumMistakedataset,oneforeachusedlanguagemodel. Inthearchitecturecolumn,
enc-decmeansencoder-decoderandautoregstandsforautoregressive. Theerrorscolumnpresentsthehuman-
annotatederrorsforeachsummary.Multi-InstanceProtocolPromptTemplate
Youareanexperiencedlinguistandyouwillbegivenonesummaryforameeting. Yourtaskistorate
thesummarybasedontheexistenceofthebelow-providederrortype. Pleasemakesureyoureadand
understandtheseinstructionscarefully. Pleasekeepthisdocumentopenwhilereviewing,andrefertoit
asneeded. Followingistheerrortype(s)youshouldlookfor:
"""errordefinition"""
Evaluationsteps:
1. Readthetranscript,ifavailable,carefullyandidentifythemaintopicandkeypoints.
2. Readthepredictedsummaryandcompareifitcontainsinstancesofthedescribederrortype. Note
every instance you observe that is part of the error type. Only consider the error type and no other
mistakeselse.
3. Ratethesummarybasedontheexistenceoftheerrortypewithyeswhenatleastoneinstanceofthe
errortypeisfoundornoifthesummarydoesnotexhibittheerrortype. (primarytask).
4. You may be given secondary tasks, such as thinking step by step, explaining your decision, or
pointing out the locations of each individual instance of the error type. These secondary tasks are
designedtohelpyoubecomemorecertainaboutyourdecision.
5. Provideyourfindingsinthedesiredformat,sothatyourfinaloutputisareportontheexistenceof
theerrortypeinthegivensummary.
Tip: Considerthewholeinput,i.e.,thetranscriptandthepredictedsummary,providedintheuser’s
prompttomakeagooddecisionthathumanswillagreeon.
Belowaretwoexamplesdemonstratingthedifferentimpactlevelsofthepreviouslydescribederror
type. Pleaselearnfromtheseexamplestheconceptandhowtheratingworks.
Example1: """minorerrorexampleprompt"""
Example2: """majorerrorexampleprompt"""
Your secondary task: """e.g., Let’s think step by step and describe every step you consider
whichleadsyoutotheresultthatanerroroccursornot."""
Yourprimarytask: """Pleaseprovidefeedbackontheexistenceoftheerror. Doesthispassagecontain
anerror? Answer’yes’or’no’."""
Youshouldnowperformtheerrorsearchonthefollowingpredictedsummary: """summary"""
(optional)Ifrequired,youcanusetheoriginaltranscriptforlookup: """transcript"""
Pleasefollowthefollowingstructureforyouroutputandfillintheblanks: """format"""
Figure4: MIPprompttemplateintheformatformulti-instanceusage. Inthesingle-instancesetup,thedefinition
andexampleblocksarerepeatedforeveryerrortype.FeedbackConsolidationPromptTemplate
You are a professional feedback summarizer, that provides a comprehensive, direct version of a
feedback report. Your condensed version should be usable for someone to improve their previous
summary effectively. So you are allowed to structure it in the most effective way to address the
feedback. Therefinementshouldbesuccessfulpurelyfromyourfeedbackandtheprevioussummary
soincludeallrelevantdetailsgiveninthereport.
Please consolidate the following feedback into a plan and provide usable feedback: """posi-
tivefeedback""".
Usetheoutputformat’Add: <Addtheinformationof...>Remove: <Removetheinformationof...>
Rephrase: <Rephrase the information of ...> Simplify: <Shorten the summary regarding ...> Keep:
<Keepthesummaryunchangedat...>’. Includealldetailsfromthefeedback.
Figure5: PrompttehmplateusedtoconsolidateafeedbackfortheconsolidationTP.Themodelistaskedtoextract
fromtheexhaustivefeedbackwhattherefinementmodelshouldconsiderforediting.
SummaryRefinementPromptTemplate
You are an expert in refining and improving summaries. Your task is to improve the summaries of
conversationsbasedonagivenfeedbackreport. Allthecontenttoimprovetheoriginalsummaryand
makeittheverybestisprovidedinthereview,asthereviewerprovidesalldetails.
Pleaseimprovethissummary: """summary"""
consideringthisreview: """feedback"""
Figure6: Thesummary-refiningsub-prompt.
PartialOmissionFew-Shotexample
Transcript: """"Good morning, everyone. Today, we need to address the proposed increase in the
marketing budget. After analyzing current trends and performance, the proposal is to increase the
marketing budget by 50% in Europe. This increase will primarily fuel our new digital marketing
campaigntargetingEurope. Webelievethisstrategicfocuswillsignificantlyboostoursales,andwe
plantoreassessthismoveafterthefirstquartertoevaluateitsimpactonourgrowthmetrics."""
Predicted Summary: """The committee agreed to increase the marketing budget to support new
initiatives."""
Explanation: """This example shows high severity partial omission because the summary fails to
specifythesignificantincreasepercentage,thetargetedgeographicalfocusofthemarketingcampaign,
and the strategic plan for reassessment. These omissions leave out critical details necessary for
understanding the scope and strategic intent of the budget increase, which could lead to significant
misalignmentinexpectationsandpreparationsamongteammembers."""
Figure7: Afew-shotexampleasitisshowntothemodeintheMIPpromptFigure4. Thisfew-shotexamples
countsamajorP-OMexample.LLM-basedRanking
Youareanexpertinthefieldofsummarizingmeetingsandaretaskedwithevaluatingthequalityofthe
following summaries. Rank the following summaries based on their quality, with 1 being the best
summaryand8beingtheworstsummary.
Summariestorank:
Transcript: """transcript"""
Summary1: """summary1"""
...
Summaryn: """<summaryn"""
Thecriteriaforrankingthesummariesinclude:
1. The summary should not contain any content-wise redundant information, that does not aid the
understandingorcontextualization.
2. Thesummaryshouldbecoherent,maintainlogicalflow,relevance,andclaritywithinasentenceand
acrosssentences.
3. Thesummaryshoulduseappropriatelanguagewithcorrectandgrammaticaluse. Languageshould
notbeambiguous.
4. Thesummaryshouldnotommitrelevantcontent. Neithershouldcontentbecompletelyabsentor
relevantdetailsbemissing.
5. Thesummaryshouldcorrectlyreferencestatementsandactionstotherespectivemeetingparticipant.
6. Thesummaryshouldnotaddhallucinatedcontent. Thisincludestheadditionalofnewcontentnot
presentinthetranscriptaswellaschangingdetails.
7. Thesummaryshouldmaintainthelogicalandtemporalstructureandnotmisplacetopicsorevents.
8. Thesummaryshouldnotcontainirrelevantinformationbutfocusonwhatisimportant.
Whenencounteringissueswithanyofthesecriteria,assesstheimpactandrateaccordingly. Omission
andhallucinatedcontentaremoresevereissuesthantheother.
Your task is to rank the summaries based on the criteria provided. Remember to consider the
quality of the summaries and how well they capture the key points of the original transcript. First
provideanargumentationforyourranking. Therefore,usechain-of-thoughtandthinkstepbystep. )
Figure8: Thetemplatepromptforrankingsummariesaccordingtotheirperformanceontheerrorsdescribedin
Section3.1.ContradictionofCorrectionandCoT.
Chain-of-Thought:
1. Thetranscriptdiscussesvariousaspectsoftheremotecontroldesign,includingmaterials,shape,
buttonplacement,andtechnologicalfeatureslikespeechrecognition.
2. ThepredictedsummarymentionsadecisionabouttheLCDdisplayandback-lights,whichisnot
foundinthetranscript.
3. Thesummaryalsotalksaboutascrollwheelontheside,whichismentionedinthetranscriptbutnot
asafinalizeddecision.
4. Thesummarydoesnotreflecttheexploratoryandundecidednatureofthemeeting’sdiscussionon
designelements.
5. The summary introduces specific design elements as decisions, which is not supported by the
transcript,indicatinganextrinsichallucination.
Correction:
The summary should reflect the actual content of the meeting, focusing on the points that were
discussedsuchastheimportanceofafancylook-and-feel,theuseofascrollwheelforvolumecontrol,
theconsiderationoftechnologicalinnovationslikespeechrecognition,andtheoveralldesigndirection
towardsamodern,possiblyiPod-likeappearance. SpecificdecisionsabouttheLCDdisplayandbutton
placementshouldnotbeincludedunlesstheywereexplicitlymentionedinthetranscript.
Figure9: ConfusionbetweenCoTcontentandCorrectionsuggestion.