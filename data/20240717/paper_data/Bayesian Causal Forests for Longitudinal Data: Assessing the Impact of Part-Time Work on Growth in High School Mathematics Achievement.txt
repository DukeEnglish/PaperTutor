Bayesian Causal Forests for Longitudinal
Data: Assessing the Impact of Part-Time
Work on Growth in High School
Mathematics Achievement
Nathan McJames1,2,∗ , Ann O’Shea2, Andrew Parnell1,2
1Hamilton Institute, Maynooth University, Co. Kildare, Ireland
2Department of Mathematics and Statistics, Maynooth University, Co. Kildare, Ireland
July 16, 2024
Abstract
Modelling growth in student achievement is a significant challenge in the field of
education. Understanding how interventions or experiences such as part-time work
can influence this growth is also important. Traditional methods like difference-in-
differences are effective for estimating causal effects from longitudinal data. Mean-
while,Bayesiannon-parametricmethodshaverecentlybecomepopularforestimating
causal effects from single time point observational studies. However, there remains
a scarcity of methods capable of combining the strengths of these two approaches to
flexibly estimate heterogeneous causal effects from longitudinal data. Motivated by
two waves of data from the High School Longitudinal Study, the NCES’ most recent
longitudinal study which tracks a representative sample of over 20,000 students in
the US, our study introduces a longitudinal extension of Bayesian Causal Forests.
This model allows for the flexible identification of both individual growth in mathe-
matical ability and the effects of participation in part-time work. Simulation studies
demonstratethepredictiveperformanceandreliableuncertaintyquantificationofthe
proposed model. Results reveal the negative impact of part time work for most stu-
dents, but hint at potential benefits for those students with an initially low sense of
school belonging. Clear signs of a widening achievement gap between students with
high and low academic achievement are also identified. Potential policy implications
are discussed, along with promising areas for future research.
Keywords: Part-Time Work; Bayesian Non-Parametrics; Causal Inference; Longitudinal
Analysis; Student Achievement
∗Corresponding Author: nathan.mcjames.2016@mumail.ie.
This work has emanated from research conducted with the financial support of Science Foundation Ire-
land under grant number 18/CRT/6049. In addition Andrew Parnell’s work was supported by: a Sci-
ence Foundation Ireland Career Development Award (17/CDA/4695) and SFI Research Centre award
(12/RC/2289 P2). For the purpose of Open Access, the authors have applied a CC BY public copyright
licence to any Author Accepted Manuscript version arising from this submission.
1
4202
luJ
61
]LM.tats[
1v72911.7042:viXra1 Introduction
For many high school students, part-time jobs have become an integral part of their daily
routine, just as important as homework, studying, and completing assignments (Singh &
Ozturk 2000). The reasons for seeking part-time work can vary widely among students.
Some work to support their families financially, others to develop their character, gain
maturity, or simply to earn spending money (Kablaoui & Pautler 1991). Regardless of the
reasons for students choosing to work part-time, however, this work can have a significant
impact on their educational journey (Bachman & Schulenberg 2014). Our study introduces
a new approach for modelling individual level growth in student achievement, and explores
the causal effectof intensive part-timework onthis growth, where part-time workis defined
as upwards of 20 hours of work per week during the school year (Lee & Staff 2007).
Estimating causal effects from longitudinal data is a challenging but essential task.
Established methods include inverse probability weighting (Hogan & Lancaster 2004), two-
way fixed effects (Imai & Kim 2021), and difference-in-differences (DiD, Donald & Lang
2007). A key limitation of many of these approaches is that they often rely on strong
assumptions that may not be appropriate for the target data. The parallel trend assump-
tion of the difference-in-differences method, for example, assumes that the treatment group
would have followed a similar trajectory to the control group had they not received treat-
ment (Roth et al. 2023). This can easily be violated in practice, as confounding variables
may influence both the probability of receiving treatment and the trajectories in the out-
come of interest. Students who self select into part-time work, for example, may experience
less growth than their peers even without part-time work (Monahan et al. 2011). Some
work has been conducted to tackle this limitation by relaxing the assumption of parallel
trendsconditionaloncovariates(Abadie2005,Callaway&Sant’Anna2021), butimportant
limitations remain.
Other methods rooted in structural equation modelling such as G-estimation (Robins
1997), andlongitudinalextensionsoftargetedminimumlossbasedestimation(Lendleetal.
2017) excel in estimating causal effects from longitudinal data when faced with challenges
such as drop-out, time varying covariates, and dynamic treatment regimes. A weakness of
thesemethods,however,isthattheyareoftenrestrictedtoestimatingaveragecausaleffects,
without the ability to explore individual level variations or heterogeneity in responses to
treatment. This is an important limitation, especially in the context of part-time work, as
there is research to show that the effects of part-time employment can vary significantly
depending on factors such as gender, motivations for working part-time, and socioeconomic
backgrounds (Entwisle et al. 2000).
Whenunderstandingheterogeneityincausaleffectsisimportant,Bayesiannon-parametric
methods based on Bayesian Additive Regression Trees (Hill 2011, Chipman et al. 2010) and
Bayesian Causal Forests (Hahn et al. 2020) have become the gold standard. The default
implementations of these methods are only applicable to single time point observational
data, however, precludingthestudyoftrendsineducationaloutcomesovertime. Ourstudy
extends BART and BCF to the setting of longitudinal data. By combining the flexibil-
ity of these methods with the highly interpretable structure of the difference-in-differences
model, we simultaneously relax the parallel trend assumption of the DiD methods, while
also allowing for the study of individual level variations in the growth curves of student
achievement, and the heterogeneous impact of part-time work on this growth.
2While other studies (Wang et al. 2024) have also introduced longitudinal extensions of
BART and BCF, with a focus on situations where there is a staggered adoption of treat-
ment, our proposed model assumes a very different structure, and includes three important
features targeted specifically at our motivating data. First, our model places separate pri-
ors directly over the growth trajectories and the effects of treatment on this growth. This
allows us to inform the model with prior information, and comes with the added advantage
of allowing the incorporation of model explainability tools, and variable importance met-
rics directly associated with the parameters of interest (Inglis et al. 2022a,b). The model
structure also accommodates time varying covariates, such as evolving levels of student
motivation which are common in education studies. Finally, while not the main focus of
the present study, an additional feature not included in BCF models before is the ability
to handle missing data in the covariates or the treatment assignment. We tackle this issue
with a feature borrowed from Kapelner & Bleich (2015), and a novel update step for the
treatment status indicator.
The remainder of our paper is structured as follows: In Section 2 we describe our
motivating dataset, the High School Longitudinal Study of 2009 (HSLS), and outline some
key features of the data. Section 3 introduces the proposed model, and shows how we
extend BART and BCF to provide a foundation for estimating growth curves of student
achievement and heterogeneous treatment effects of part-time work. To further support
the credibility of our proposed methodology, Section 4 applies our model to simulated data
designedtomirrorthecharacteristicsoftheHSLSdataset. Webenchmarkourperformance
against other potential candidate models, showcasing the unique capabilities of our model
in overcoming challenges that remain difficult for existing approaches. In Section 5, we
deploy our model to the HSLS data and present the results of our study. Finally, we
conclude our paper in Section 6 with a discussion of our findings, implications for policy,
and areas for future work.
2 Data
The High School Longitudinal Study of 2009 (Ingels et al. 2011) is an ongoing study of a
nationally representative sample of high school students in the US. It is the most recent of a
series of five longitudinal studies launched by the National Center for Education Statistics.
The first wave of data collection for HSLS took place in the fall of 2009 at the start of the
academic year when the students were in the ninth grade. More than 20,000 high school
students took part in this part of the study. A follow up of these students then took place
in the spring of 2012 when the students were in the eleventh grade. Further follow ups have
also taken place in 2013, 2016, and 2017 to discover how the students are progressing in
the years after high school, but did not involve mathematics achievement tests so we will
focus solely on the first two waves of the data. Due to some students dropping out of high
school, some schools closing, and others disagreeing to continue their participation in the
study, the second wave of data collection involved just under 19,000 of the original Wave 1
sample.
Data collection during HSLS followed a similar procedure during both waves of the
study. Mathematics achievement was assessed during both waves using a computer deliv-
ered assessment with questions designed to measure the algebraic reasoning abilities of the
3students. The resulting achievement estimates assigned to the students were calculated
using Item Response Theory (Cai et al. 2016). The contextual data gathered as part of the
study was based on a survey answered by the students, a parent, school administrators,
and school teachers. Information collected from the student survey includes characteristics
such as sex, age, self concept in mathematics, sense of school belonging, and other details
such as participation in activities like part-time work. Data from the parent survey in-
cludes important socioeconomic variables such as family income, parental employment and
education. School related data includes information such as the administrator’s perception
of the overall climate within the school, and the level of expectations of student academic
success.
To ensure a representative sample of students, a stratified, two-stage random sampling
design was employed by the study organisers. This involved first approaching eligible high
schools, 944 of which agreed to participate in the study, and then randomly sampling stu-
dents from each of those schools, leading to a total sample of 21,444 participating students.
Sampling weights resulting from this design are provided in the dataset to account for
non-participation bias and were used to appropriately weight the results discussed later in
the paper. Table 3 of the supplementary material provides weighted summary statistics for
a subset of the categorical variables from the base year (Wave 1), and also provides mean
achievement levels from both waves of the study.
Our study uses the public-use version of the HSLS data. Some of the data in this
public use version of the dataset has been obfuscated or removed in order to maintain the
anonymity of the students and the schools who took part in the study. Therefore, a school
identifier indicating which students attend the same school is not available in this version of
the dataset, precluding a hierarchical modelling strategy. The restricted use version of the
datasetdoesincludethisinformationbutisonlyavailablewithstrictcontrolsinplace. This
is a limitation of our study, but ensures our results are more easily reproducible without
requiring a restricted use version of the dataset. Furthermore, there is evidence to suggest
that part-time work is more likely to be influenced by student and family related variables
than school related variables (Howieson et al. 2012), partially mitigating the potential for
unmeasured confounders to bias our results.
3 Methodology
3.1 The Model
Our motivating dataset consists of two waves, but for the sake of generality in this section
we will describe how the model applies to datasets of up to T waves of student data. We
are interested in modelling trajectories of student achievement where we have data on n
1
students participating in an initial base year assessment, and subsequent follow-ups on
n ...n of the same students during waves 2 to T. We allow for the possibility of drop-
2 T
out, whereby n ≤ n ≤ ... ≤ n . We will represent the contextual data associated with
T T−1 1
student i up to time t by x , where t = 1 indicates the data is from the base year (Wave
i,t
1), and subsequent values of t indicate the data encompasses extra information collected
up to and including Wave t. We will not distinguish between data from different surveys or
questionnaires, so x captures all of the student, parent, and school level data associated
i,t
with student i up to time t. Given the accumulation of information on students over time
4as they complete more surveys from additional waves, the number of columns in x will be
i,t
less than the number of columns in x . To distinguish between students who do and do
i,t+1
not work part-time, we will let Z be a binary indicator of length n which indicates
i,t+1 t+1
for each student if they reported having a part-time job which involved them working on
average 20 hours or more per week during the period between Waves t and t + 1. For
the achievement data, let y denote the observed mathematics achievement of student i
i,t
recorded at time t.
Our research questions concern two quantities of interest. The first is related to the
growth in mathematics achievement between Waves t and t+1, which we will denote by
G = y −y . The second concerns the impact of part-time work on this growth. To
i,t+1 i,t+1 i,t
understand this impact, we adopt the Neyman-Rubin causal model (Splawa-Neyman et al.
1990, Sekhon 2008), and postulate that for each individual i, there are two potential growth
values. One that would be observed if the student worked part-time, G (Z = 1),
i,t+1 i,t+1
and one that would be observed if the student did not, G (Z = 0). With these
i,t+1 i,t+1
quantities defined, the impact of part-time work on the growth in student achievement
during this period is captured by τ = G (Z = 1)−G (Z = 0). Of course,
i,t+1 i,t+1 i,t+1 i,t+1 i,t+1
we only ever observe one of these potential growth values, namely G = G (Z =
i,t+1 i,t+1 i,t+1
1)Z +G (Z = 0)(1−Z ), so we make the following assumptions:
i,t+1 i,t+1 i,t+1 i,t+1
Assumption 1: The Stable Unit Treatment Value Assumption. We assume that
the potential growth values of every student i between periods t
and t+1 are independent of whether or not any other student j
worked part-time in any period.
Assumption 2: The Sequential Ignorability Assumption. We assume that condi-
tional on their observed characteristics and treatment history up
to the period of interest, the potential growth values of student
i are independent of whether or not they worked part-time. No-
tationally, we assume that G (Z = 0),G (Z = 1) ⊥
i,t+1 i,t+1 i,t+1 i,t+1
Z |x ,Z .
i,t+1 i,t+1 i,t
Assumption 3: The Overlap Assumption. We assume that for every observed
covariate and treatment history, there is a non-zero probability of
working, or not working part-time during any period of interest:
0 < P(Z = 1|x ,Z ) < 1.
i,t+1 i,t+1 i,t
If these conditions hold (Angrist et al. 1996, Kurz 2022, Myint 2024, Hern´an & Robins
2020), then we may write that
E[G (Z )|x ] = E[G |Z ,x ].
i,t+1 i,t+1 i,t+1 i,t+1 i,t+1 t+1
Our model for student achievement across all waves of data then becomes:
 
T−1
(cid:88)
y = µ(x )+ δ (x ,y ...y ,πˆ )+τ (x ,y ...y )Z I(t > w)+ϵ
i,t i,1  w+1 i,w+1 i,1 i,w i,w+1 w+1 i,w+1 i,1 i,w i,w+1 i,t
(cid:124) (cid:123)(cid:122) (cid:125)
w=1
Gw+1(xi,w+1,yi,1...yi,w,πˆi,w+1)
where the different parts of the model work together in a cumulative fashion to predict
different parts of a student’s mathematics achievement. Predictions for achievement at
5Wave 1 are given by µ(), while achievement at any subsequent Wave t is given by adding
this to a cumulative sum of achievement growths, G (). Within each time period, δ ()
w+1 w+1
and τ () represent the growth that would have been realised without part-time work, and
w+1
theexpectedimpactofpart-timeworkonthisgrowthrespectively. Theadditionalcovariate
πˆ included in the δ () part of the model is a propensity score, which estimates the
i,w+1 w+1
probability of observation i receiving treatment during this period conditional on their
covariates. This inclusion follows the advice of Hahn et al. (2020), who demonstrated that
incorporating this “clever covariate” can help mitigate the issue of regularisation-induced
confounding. Finally, ϵ represents the error term for student i at time t, which we assume
i,t
to be normally distributed with mean 0 and variance σ2, ϵ ∼ N(0,σ2).
i,t
In our model, the contributions made by µ() and each of δ () and τ () come from
w+1 w+1
ensembles of n , n , and n regression trees based on the BART model of Chipman et al.
µ δ τ
(2010). For ease of exposition as we discuss the Bayesian backfitting MCMC algorithm
by which the regression trees fit to the data, let us consider the simplest scenario where
n = n = n = 1 and T = 2, leaving the general case for the supplementary material. The
µ δ τ
MCMC sampler begins with each of µ(), δ (), and τ () initialised as stumps (decision trees
2 2
where the root is also the sole terminal node, and the terminal node parameter of each
tree is set to zero). Next, each iteration starts by selecting at random one of four possible
operations(grow, prune, change, orswap)toapplytotheµ()treeinorder toproposeanew
tree structure. This proposal is then accepted or rejected with a Metropolis-Hastings step
before the terminal node (or now possibly nodes) of the µ() tree are updated via a Gibbs-
samplingstepwhichattemptstoexplainanyleftovervariationinthepartialresidualy less
i,t
the contribution from δ () and τ (). Analogous operations are then applied to the δ () and
2 2 2
τ () trees before the residual variance parameter is also updated via Gibbs-sampling. This
2
cycle repeats for a specified number of iterations, providing a desired number of posterior
draws for the tree structure and terminal node parameters of µ(), δ (), and τ (), as well as
2 2
the residual variance parameter σ2.
Overfitting is prevented through the use of the tree prior from Chipman et al. (2010)
which specifies that the probability of any node at depth d being non-terminal is given by
α(1+d)−β. Therefore, for a tree T with terminal nodes h ...h , and non-terminal nodes
1 K
b ...b , we have that:
1 L
K L
(cid:89) (cid:89)
P(T) = α(1+d(h ))−β [1−α(1+d(b ))−β]
k l
k=1 l=1
The strength of this prior can be adjusted through setting different values for α and β. For
the µ() and δ() trees we adopt the default prior from Chipman et al. (2010), of α = 0.95,
β = 2, while for the τ() trees we impose stronger regularisation as we expect there to be
less heterogeneity in the effects of part-time work than in y itself, choosing α = 0.25, β = 3
as suggested by Hahn et al. (2020).
To ensure each tree contributes approximately equally to the overall prediction, the
terminal node parameters of each tree are given a normal prior. In each type of tree, we
have
µ ∼ N(0,σ2), δ ∼ N(0,σ2), τ ∼ N(0,σ2)
µ δ τ
Afterscalingy tofollowastandardnormaldistributionpriortofittingthemodel, asensible
choice for σ2 is 1/n , ensuring the terminal mode parameters in the µ() trees have adequate
µ µ
6room to cover the range of the data. Similarly, we use a prior of σ2 = 1/n , but given we
δ δ
expect the magnitude of the treatment effects to be relatively small in comparison to y we
set σ2 = 0.52/n . Finally, the conjugate prior for σ2 is an inverse gamma distribution:
τ τ
σ2 ∼ Inverse-Gamma(ν/2,νλ/2),
for which we have found a reliable default choice is to set ν = 3, and λ = 0.1.
3.2 Special Features
Two challenges related to missing data required us to build some extra functionality into
our model. The first challenge was related to missing data in the covariates. Missing
data in the covariates can arise for several reasons in the dataset. For example, some
questions may have been purposely skipped by students, their parents, or teachers, and
other times the answer to a particular question may not have been known. On average,
1.9% of the data was missing, and the most data missing for any particular variable was
19%. Common approaches for dealing with missing data in the covariates include single or
multipleimputation(Lin&Tsai2020),butanextrapossibilityspecifictotreebasedmodels
is the approach developed by Kapelner & Bleich (2015), which involves treating missing
data as an important feature of the data, operating under the assumption that the data
is missing at random. To summarise, this approach involves directing observations with
missing data to the left or right child of a node that is being split on, allowing the model
to learn from any relationship between missingness and the outcome variable, handling
missing data as an integral part of the model, thus accounting for uncertainty that may be
present.
The second challenge was related to missing data in the treatment Z itself, as not all
i,2
students answered the question on how many hours they worked part-time during school
weeks. This type of missingness affected 3.4% of the observations in the data. This chal-
lenge is addressed by introducing an additional Gibbs-sampling step at the end of each
iteration of the MCMC sampler, where the missing Z values are themselves treated as
i,2
parameters to be updated, with prior probability p , conditional on the rest of the data:
i
1
P(Z = 1|...) = .
i,2 (cid:16) (cid:17)(cid:16) (cid:17)
1+ 1−pi e 2σ1 2[(yi,2−µi−δi−τi)2−(yi,2−µi−δi)2]
pi
These two added features allowed us to keep a full representative sample of students while
accounting for the added uncertainty introduced into our results by the presence of missing
data.
One final challenge that is common when working with assessment data of student
achievement is the use of plausible values (Wu 2005, Khorramdel et al. 2020). In order to
prevent the computer delivered assessment from taking unduly long, it was only possible
for HSLS to present each student with a limited number of questions. This introduces some
room for error in the achievement estimates of the students, and as a result, HSLS provides
researchers with five plausible values of student achievement from the posterior of each
student’s achievement estimate. In line with best practice, we therefore ran five chains of
our model, one applied to each plausible value of student achievement, and pooled them
together after burn-in to appropriately handle this uncertainty.
73.3 Alternative Methodologies
Our work shares connections with several areas of Bayesian non-parametric modelling, and
longitudinal methods for causal inference. First there is the clear connection to BART
(Chipman et al. 2010), as this method provides a foundation for the different parts of our
model. BART based methods have become popular in the area of causal inference (Hill
2011) and have demonstrated impressive performance and reliable uncertainty quantifica-
tion. A second strong connection is with the Bayesian Causal Forest model developed by
Hahn et al. (2020), which also uses BART as a foundation for estimating causal effects.
Both methods could potentially be applied to our research questions but fall short of of-
fering the same abilities in this context as our own model in several important ways which
are worth discussing.
The most natural way for BCF to be applied to our problem setting would be to
manually calculate the growth values G for each student i, and each time period t to
i,t+1
t+1. Applying the BCF model to a specific time period would then yield the following,
allowing us to recover what our model captures with the δ () and τ () part of the model:
t+1 t+1
G = δ (x ,y ,πˆ )+τ (x ,y )Z +ϵ , ϵ ∼ N(0,σ2)
i,t+1 t+1 i,t+1 i,t i,t+1 t+1 i,t+1 i,t i,t+1 i i
A key limitation of this approach is that it does not model the full data generating process,
only the growth between Waves t and t+1. This means that students who participate in
Wave t but not in Wave t + 1 (and consequently have no calculable G ) are excluded
i,t+1
from the model and are unable to inform the predictions made by the model. Secondly,
manually calculating the G growth values (to be used as the response variable in this
i,t+1
approach), is likely to lead to a smaller signal to noise ratio in the response as the error
terms from y and y combine, making it more difficult for the model to detect the
i,t i,t+1
relationships it is trying to model. A BART only approach could also be applied to the
data in a similar way using G as the response, but this approach would share the same
i,t+1
limitations. Of course, if treatment effects were the only quantity of interest then it would
also be possible to apply BART or BCF directly to y , but this would preclude any
i,t+1
inference on the growth values G , so would fail to address this aspect of our study.
i,t+1
Researchers more familiar with difference-in-differences (Roth et al. 2023) based ap-
proaches might like to think of our model as a Bayesian non-parametric DiD model where
our δ () trees model the difference for the control group (non part-time workers), and our
t+1
τ () trees model the difference in this difference experienced by the treatment group (the
t+1
part-time workers). Crucially, our approach handles this situation much more flexibly than
traditional DiD based methods, as the flexibility of the δ () trees means we can relax the
t+1
assumption of parallel trends conditional on the covariates of the students, and the τ ()
t+1
trees also allow us to capture heterogeneity in the effects of part-time work which is often
not possible with DiD based methods. See the supplementary material for an illustration
of how our proposed model fits into this framework.
Finally, our method also shares similarities with causal methods applicable to longitudi-
nal data such as G-estimation (Tompsett et al. 2022), or longitudinal extensions of targeted
minimum loss based estimation (LTMLE, Lendle et al. 2017). Both methods have gained
popularity owing to their ability to handle complex situations such as time varying con-
founding, situations where the primary interest is in the causal effect of a series of sustained
or irregular treatments, and where the interest is in the lagged effects of a treatment. Our
8focus however, will be on heterogeneity in the direct effect of a single period of part-time
work on the immediately following mathematics assessment, which is not achievable with
the available implementations of these methods. Additionally, our model will also provide
insights into the growth trajectories of student achievement, a feature that is not modelled
by these other approaches.
4 Simulation Studies
In this section, we assess our proposed model’s performance in a simulation study designed
to match the features of the motivating HSLS data. We also compare our proposed model
with alternative approaches in order to highlight the added performance offered by our
method. Our simulation study consists of two data generating processes. DGP1 focuses
on heterogeneity in treatment effects and growth curves, making it well-suited to flexible
approaches based on BART and BCF. It features two waves of data to accommodate the
alternative methods which can not handle multiple time periods. DGP2 is inspired by a
syntheticdatasetfromtheRpackagegesttools. Thisprocessincludesmorethantwotime
pointsandfeaturestime-varyingcovariates. ItfocusesonestimatingtheAverageTreatment
Effect, enablingafaircomparisonofourmethodwiththegesttoolsandLTMLEpackages,
which do not support the estimation of heterogeneous treatment effects, but are correctly
specified for the features of this DGP.
4.1 Data Generating Process 1
Our first data generating process is based on a modified version of the first Friedman
dataset (Friedman 1991), a common benchmarking dataset featuring non linear effects
and interaction terms. We will use this dataset to assess how well each of the flexible
causal machine learning methods can capture heterogeneity in the growth curves of student
achievement, and the treatment effects themselves. We simulate ten covariates measured
at Wave 1: x ...x , and a second observation of each of these ten variables again at the
1 10
final Wave 2: x ...x , where the second observation of each variable is equal to the first
11 20
plus a small amount of random noise, e.g., x = x +r, with r a uniform random variable
16 6
between 0 and 0.4. The structure of the simulated achievement level of each student is of
the form described earlier:
y = µ(x )+δ (x ,y ,πˆ )I(t > 1)+τ (x ,y )Z I(t > 1)+ϵ , ϵ ∼ N(0,σ2)
i,t i,1 2 i,2 i,1 i,2 2 i,2 i,1 i,t+1 i,t i,t
(cid:124) (cid:123)(cid:122) (cid:125)
G(xi,2,yi,1,πˆi,2)
1
where µ(x ) = 10sin(πx x )+20(x −0.5)2 +10x +5x , δ () = µ(x )+3x2 +2x2 ,
i,1 1 2 3 4 5 2 3 i,1 11 15
and τ () = −x −x2 −x3 . The true propensity scores are given by p = P(Z = 1|x ) =
2 4 14 15 i i,2 i,2
Plogis(µ∗ + δ∗), where µ∗ + δ∗ is a normally scaled version of each of the original µ + δ
i i i i i i
values.
The compared methods are our longitudinal BCF model, BART using the approach
outlined in Hill (2011), a standard BCF model from Hahn et al. (2020), and the causal
Generalised Random Forest model (GRF) from Wager & Athey (2018). The recently
proposed BCF extension by Wang et al. (2024) would also make an excellent method for
comparison when a documented R package becomes available.
9Growth Treatment Effects
3.5
2.0
3.0
2.5
1.5
2.0
1.0
1.5
1.0 0.5
LBCF BART BCF LBCF BART BCF GRF
Method
Figure 1: Visualisation of RMSE and PEHE metrics evaluated over 1000 replications of
DGP1 for the BART, BCF, GRF, and LBCF models. In the left panel, which displays the
RMSE of the δ predictions, the LBCF approach is clearly the strongest performer, with
i
considerably lower RMSE values. In the right panel, which visualises the PEHE metrics,
LBCF is again the strongest performer, but by a narrower margin.
As outlined earlier, given that the longitudinal BCF model is the only one capable of
directly modelling the growth curves, we will apply the other competing methods to the
transformedoutcomey −y , thedifferenceinoutcomesbetweenWaves1and2, toenable
i,2 i,1
the prediction of growth using BART and BCF. For the longitudinal BCF model, we use
100 trees in the µ() part of the model responsible for predicting y at Wave 1, 70 trees
i,1
in the δ() part of the model responsible for predicting the growth under control, and 30
trees in the τ() part of the model responsible for predicting the heterogeneous treatment
effects. For the standard BCF approach, we use 170 trees in the prognostic part of the
modelwhichwillprovideestimatesforthegrowthundercontrol, and30treesforestimating
the treatment effects. The BART and GRF approaches both use 200 trees in total. Each
simulation consists of 500 training observations, and 1000 test observations. The Bayesian
methods are run for 500 burn-in and 500 post burn-in iterations. Satisfactory convergence
was assessed via visual inspection of the posterior samples for a small subset of the 1000
replications of the data generating process.
Table 1 summarises how the compared approaches perform when tasked with pre-
dicting δ and τ across 1000 replications of the simulation. For δ , this performance is
i i i
evaluated using the average root mean squared error (RMSE) over the 1000 simulations:
(cid:113)
RMSE = 1 (cid:80)N (δ −δˆ )2. The equivalent metric used for τ is the precision in esti-
N i=1 i i i
(cid:113)
mating heterogeneous effects (PEHE): PEHE = 1 (cid:80)N (τ −τˆ)2, also averaged over
N i=1 i i
the 1000 simulations. Mean coverage rates of the 95% credible intervals, bias, and credible
interval widths are also provided for both δ and τ . A visual representation of these results
i i
can be found in Figure 1.
The clearest differences in Figure 1 relate to model performance predicting the δ values,
i
10
EHEP/ESMRwith our proposed LBCF model achieving much lower RMSE values. Comparison with the
GRF model was not possible here, as the GRF model output only provides treatment effect
estimates. In the right panel of Figure 1, the differences are more subtle, but the proposed
model performs marginally better than the BART and BCF methods, which in turn both
outperform the GRF based approach.
δ predictions τ predictions
i i
LBCF BART BCF LBCF BART BCF GRF
RMSE/PEHE 1.362 2.470 2.671 0.886 0.907 0.958 1.057
Mean Absolute Bias 0.265 0.311 0.303 0.324 0.424 0.424 0.604
95% Coverage 0.980 0.996 0.891 0.935 0.921 0.911 0.769
95% CI Width 6.559 14.306 8.624 3.409 3.343 3.515 2.654
Table 1: Summary of important metrics measured for δ and τ predictions, averaged over
i i
1000 simulations of DGP1. The proposed LBCF model performs competitively, achieving
a lower mean RMSE and PEHE than the alternative models. Bias, coverage, and credible
interval widths are also close to ideal. Best results are highlighted in bold where a clear
winner exists.
Finally, the LBCF estimates are the least biased of all the compared methods, and are
accompanied by close to ideal coverage rates. The credible interval widths from the LBCF
estimator are similar to the competing methods when estimating the treatment effects, but
are considerably narrower than the competing methods when estimating the growth values,
offering a high degree of precision.
4.2 Data Generating Process 2
Our second data generating process comes from the R package gesttools (Tompsett et al.
2022), which implements G-estimation for longitudinal data. Our focus here is on esti-
mating the average treatment effect. As described in Tompsett et al. (2022), the dataset
includes:
• A baseline covariate U ∼ N(0,1)
• Covariates L ∼ N(1+L +0.5A +U),t = 1,2,3,A = 0
t t−1 t−1 0
• Exposure A ∼ Bin(1,expit(1+0.1L +0.1A )),t = 1,2,3
t t t−1
• Time varying outcome Y ∼ N(1+A +γ A +(cid:80)t L +U,1),t = 2,3,4
t t t t−1 i=1 t
• Constants (γ ,γ ,γ ) = (0,0.5,0.5)
1 2 3
In this simulation study, the baseline covariate U remains fixed, while the time varying
covariates L change at each wave in response to the values of the preceding covariates, and
t
whether or not treatment was received. The likelihood of receiving treatment also depends
on previous covariates and treatments. Note that while the time varying outcome depends
on the treatment status at the current and previous time points, we will only estimate the
direct effect of treatment at time t on y .
t
112.0
1.5
1.0
0.5
0.0
gesttools LBCF LBCF LTMLE
Wave 1−2 Wave 2−3
Method
Figure 2: Visualisation of bias in ATE estimates over 1000 replications of DGP2 for the
gesttools, LBCF, and LTMLE models. The gesttools package, which assumes a con-
stant treatment effect at all time points shows minimal bias. This strong performance is
closely followed by the proposed LBCF model, which provides estimates for the treatment
applied between Waves 1 and 2, and 2 and 3. The LTMLE estimates appear to be much
more biased.
The methods we will compare are G-estimation as implemented by gesttools, longitu-
dinal targeted minimum loss based estimation from the LTMLE package, and our proposed
method. ThegesttoolsandLTMLEapproacheswillusethedefaultsettingsoftheRpack-
ages, which make them the correctly specified models, while our approach will use the same
setup from the previous simulation study. As before, we will run 1000 replications of the
simulation study, but will evaluate performance on the training sample of 500 observations
(the LTMLE and gesttools packages can not make predictions on unseen data).
Figure 2 visualises the ATE estimates from the proposed approach, the gesttools
package, and the LTMLE package. For the gesttools and LTMLE results, only one
boxplot is shown. In the case of the gesttools results, this is because the package assumes
the treatment has the same effect at all time points. In this simulation, this assumption
is valid, but in general, the ability of our model to provide separate estimates at each
time point is likely to be valuable. With the LTMLE package, it is necessary to define a
contrast in order to estimate the effect of some sequence of treatments on the final observed
outcomevariable(inthiscaseY ). Forthesimulationabove, wetaskedtheLTMLEpackage
3
with estimating the effect of the treatment sequence (A = 0,A = 0,A = 1) relative to
1 2 3
(A = 0,A = 0,A = 0). This will recover the direct effect of A on Y , which is equal to
1 2 3 3 3
the direct effect of A on y , consistent across time. In contrast, our proposed LBCF model
t t
is able to provide ATE estimates for both the effect of A on Y , and the effect of A on
2 2 3
Y , offering a more detailed and flexible analysis.
3
Figure 2 visualises the absolute bias in estimating the ATE for each of the approaches
over 1000 replications of DGP2. The gesttools package is the best performer here, closely
followed by the LBCF estimates which are consistently accurate across both time periods.
12
saiB
etulosbAModel/Metric gesttools LBCF Wave 1-2 LBCF Wave 2-3 LTMLE
Mean Absolute Bias 0.077 0.097 0.107 0.476
95% Coverage 0.950 0.913 0.936 0.838
Mean 95% CI Width 0.384 0.438 0.502 1.688
Table 2: Absolute bias, coverage rates, and credible/confidence interval widths averaged
over 1000 replications of DGP2. Coverage rates are very good for gesttools and LBCF,
butlessthanidealforLTMLE.Thegesttoolspackageprovidesthemostpreciseestimates,
with slightly narrower confidence interval widths than LBCF. Best results are highlighted
in bold where a clear winner exists.
We note, however, that the gesttools package assumes the treatment effect is the same
at all time points, and this is unlikely to always be valid. The bias of the LTMLE package
is consistently much higher, indicating the model often struggled to identify the true ATE
from the data.
A similar pattern is observed in Table 2, which provides additional information on the
coverage rates, and mean credible/confidence interval widths. Here, the coverage achieved
by the gesttools package and the two estimates provided by the proposed LBCF model
are very close to ideal. The LTMLE package appears to underestimate the uncertainty
in its estimates, however, and only achieves 76.8% coverage. The LBCF model’s credible
interval widths at both time points are slightly wider than those of the gesttools package
but remain significantly narrower than the LTMLE package’s confidence interval widths.
In summary, the results from both data-generating processes in our simulation study
underscore the proposed model’s ability to provide flexible and accurate predictions, even
when confronted with highly non-linear growth patterns or heterogeneity in treatment ef-
fects. The model achieved near-ideal coverage rates, exhibited minimal bias, and produced
narrower credible intervals compared to other non-parametric causal models. In the second
data-generating process, where the proposed model was benchmarked against a correctly
specified G-estimation model, the LBCF model matched its strong performance, without
making the same assumption that the treatment effect was consistent over time. Encour-
aged by the robust performance of our proposed model, we proceed to the next section,
where we apply the longitudinal BCF method to the motivating HSLS dataset to assess
the impact of part-time work on student achievement.
5 Application to High School Longitudinal Study
Recall that HSLS includes two waves of data, with student achievement and other back-
ground characteristics measured at both time points. We are interested in understanding
the amount by which the mathematics achievement of the students increases between these
waves, how this growth depends on the characteristics of the students, the effect of part-
time work on this growth, and how this effect is potentially moderated by other observed
variables.
We apply our model to this dataset using the same model structure from the simulation
study, with the same number of trees, but run a larger number of burn-in (3000) and
post burn-in iterations (2000), to ensure satisfactory convergence. As described in the
13Posterior of the Mean d Growth Value Histogram of Individual d Growth Values
i i
50
2000
40
1500
30
1000
20
500
10
0 0
0.60 0.62 0.64 0.66 −1 0 1 2
Mean d Growth Value Individual d Growth Values
i i
Figure 3: The left plot shows the posterior distribution of the average growth, while the
one on the right displays a histogram of the individual δ estimates. The solid line in
i
the left plot shows the posterior mean, while the dashed lines indicate a 95% credible
interval. Substantial variability is present in the δ values, indicating that some students
i
are predicted to increase their achievement by much more than others who may even
experience a decrease in achievement.
methodology, missing data is handled internally by the model, so there is no requirement
for multiple imputation. The plausible values of student achievement are appropriately
accounted for by pooling 5 separate chains, each of which were applied to one of the 5 sets
of plausible values. Sampling weights are also accounted for by appropriately weighting
the average treatment effect results displayed below.
Figure 3 shows the posterior distribution of the average growth, and a histogram of
the individual δ estimates for each student present in Wave 2 of the dataset. The average
i
growth is close to 0.63, and the majority of the growth estimates are positive, indicating
that most students are expected to increase their mathematics achievement between Waves
1 and 2. Within the sample there is large variation, however, with some students predicted
to increase their mathematics achievement by up to 2 units on the achievement scale, while
for a small number of students, mathematics achievement is actually predicted to decrease
by a small amount. For context, achievement at Wave 1 was normally distributed with
a mean of approximately 0, and a standard deviation of approximately 1. Therefore, an
increase in achievement by two units, or two standard deviations, is quite significant.
To identify key moderating variables contributing to the variation in δ values, variable
i
importance measures were calculated for the δ() trees by counting how often different vari-
ables were selected for the splitting rules used in this part of the model. This investigation
identified the achievement of the students measured at Wave 1 as being highly influential.
Prompted by this finding, we created Figure 4 which shows a scatter plot of the δ predic-
i
tions versus the achievement of the students measured at Wave 1. The very strong positive
relationship between Wave 1 achievement and predicted growth indicates that students
who initially perform well in mathematics are predicted to increase their achievement by
14
ytisneD
ycneuqerF2
1
0
−1
−2 −1 0 1 2 3
Wave 1 Mathematics Achievement
Figure 4: Scatterplot of the relationship between Wave 1 achievement and predicted δ
i
values. Studentswithinitiallyhighlevelsofacademicachievementarepredictedtoincrease
their achievement by higher amounts than their peers.
substantially more than those with lower achievement levels. At the extremely high levels
of Wave 1 achievement, students are predicted to increase achievement by 1.5 units on
average, while for students at the opposite end of the spectrum, growth in achievement is
minimal. This observation points to a widening achievement gap between students at the
high and low ends of the achievement spectrum (McCall et al. 2006, Rowley et al. 2020).
The posterior distribution of the average treatment effect for working part-time at an
intensity of greater than 20 hours per week between Waves 1 and 2 is displayed in Figure 5.
The posterior mean of the ATE is approximately -0.08, with a 95% credible interval ranging
from -0.050 to -0.110. This indicates that on average, part-time work is expected to reduce
the growth in student achievement between Waves 1 and 2 by between 0.050 and 0.110
units. To contextualise this effect size, note that the standard deviation of the δ growth
i
valuesinachievementisapproximately0.44. Thus, theobservedeffectsizecorrespondstoa
decrease in achievement growth by nearly 0.2 standard deviations, which can be considered
a medium to large effect size (Kraft 2020).
A histogram of the individual conditional average treatment effects (ICATEs) for each
of the students in the sample can be found in Figure 5. The majority of the ICATEs are
centered quite close to the ATE of -0.08, but there are also signs of heterogeneity. Notably,
there is an interesting tail of the histogram stretching across into a positive area where
the effect of part-time work is actually predicted to have a positive effect on achievement
growth. To explore this finding further, we calculated variable importance metrics for
the τ() trees in our model to identify any variables that might strongly moderate the
treatment effect. The most influential variable resulting from this analysis was a measure
of the students’ sense of school belonging at Wave 1 of the study. Figure 6 visualises this
variable’s relationship with the ICATEs from the model. The results suggest that the
students predicted to experience a positive effect from part-time work are those with an
initially low sense of school belonging.
15
seulaV
htworG
d
iPosterior of the Average Histogram of Individual Conditional
Treatment Effect Average Treatment Effects
25
20 3000
15
2000
10
1000
5
0 0
−0.10 −0.05 −0.2 −0.1 0.0 0.1 0.2
ATE ICATES
Figure 5: The posterior distribution for the Average Treatment Effect (ATE) is shown on
the left, and a histogram of the individual conditional average treatment effects is provided
on the right. The solid line shows the posterior mean, while the dashed lines indicate a 95%
credible interval. An interesting subgroup of students on the right tail of the histogram are
predicted to benefit from part time work.
0.2
0.1
0.0
−0.1
−4 −2 0 2
Wave 1 Sense of School Belonging
Figure 6: Scatterplot of the relationship between Wave 1 school belonging and the effect
of working part-time. The effect of part-time work is negative for most students, but for a
subgroup of students with low sense of school belonging the predicted effect is positive.
16
ytisneD
SETACI
ycneuqerFThis interesting finding, which might initially appear quite strange, aligns well with
some ‘traditional’ views that part-time work can benefit students. Early research has sug-
gested, for example, that part-time employment can provide students with greater time
management skills (Robotham 2012), and other benefits such as a sense of purpose and re-
sponsibility. These benefits can be especially pronounced among students with low achieve-
ment or a diminished sense of belonging in school (King et al. 1989, Steinberg et al. 1982).
This sense of purpose and responsibility acquired through part-time work could serve to re-
focus students, leading to spillover effects benefiting their academic performance (Zimmer-
man & Kitsantas 2005). Therefore, while part-time work may be associated with negative
outcomes for the majority of students, there may be certain subgroups, such as students
experiencing a low sense of belonging in school, who may experience positive effects from
employment.
In summary, this section presented two key findings from the analysis of the HSLS
data. Firstly, substantial variation was observed in the extent to which students improved
their achievement between Waves 1 and 2. Further analysis showed that this variation
was driven primarily by the baseline achievement levels of the students, with initially
high performing students showing much higher growth than their peers. These students,
starting from a solid foundation of high achievement may find it easier to build upon their
academicprogress,astheyareinabetterplacetoacquireanddigestnewknowledgeinclass.
The second key finding was that on average, part-time work had a modest, but negative
effect on the growth of student achievement. This supports the “zero-sum” argument
that part-time work detracts from study time, homework completion, and rest, hindering
academic progress as a result. A notable exception was that students with initially low
school belonging might actually benefit from part-time work, highlighting the ability of our
model to capture complex relationships between student performance and employment.
6 Discussion
Drawing on longitudinal data from the High School Longitudinal Study of 2009, our study
introduced an innovative method for modeling growth in student achievement. Our model
also estimates the causal impact of interventions such as part-time work on this growth.
By extending Bayesian Additive Regression Trees (Chipman et al. 2010) and Bayesian
Causal Forests (Hahn et al. 2020), the primary strength of our model lies in its ability
to flexibly capture both individual growth trajectories in student achievement and the
potentially heterogeneous treatment effects of part-time work, which may be influenced by
variouscovariates. Thisapproachcontrastswithmanyexistingmethodsthateitherlackthe
flexibility to model individual variations or are confined to single time-point observational
data, precluding an analysis of achievement growth over time.
Our model was also equipped with two special features that allowed it to handle miss-
ing data in the covariates and the treatment status indicator. Simulation study results
from Section 4 provide strong support for the impressive predictive performance of the
model, which demonstrated clear advantages over three competing methods when tasked
with predicting growth values at the individual student level, and heterogeneous treat-
ment effects. Close to ideal coverage rates were also achieved. The proposed model also
showed strong performance in a second simulation study, matching the performance of two
17correctly specified models designed specifically for use with longitudinal datasets.
The results from our model application to the motivating HSLS data produced some
interesting findings. First, the model was able to reveal a large disparity in the predicted
growth values among students with initially high and low levels of academic achievement.
This finding of a widening achievement gap underscores the importance of early inter-
ventions in schools and academic institutions. By addressing achievement gaps at the
elementary and middle school levels, policy decisions can prevent these disparities from
becoming entrenched. This is especially important given previous research which indicates
that it becomes much more challenging to effectively remedy these gaps by the ninth or
eleventh grade (Morgan et al. 2016).
On average, part-time work was found to have a negative effect on student achievement,
withthe95%credibleintervalfortheATErangingfrom-0.050to-0.110. Thisisimportant,
aswecalculatednearly50%ofstudentsinoursampleparticipatedinsomelevelofpart-time
work during high school, and more than 15% of students participated in intensive part-time
work, requiring upwards of 20 hours of work a week. Large amounts of heterogeneity were
apparent in the ICATEs, however, and an analysis of the variable importance metrics from
the model identified sense of school belonging during Wave 1 as a significant contributor
to this variation. The finding that students with a low sense of school belonging may
actually be benefiting slightly from part-time work ties in with previous findings that show
students can benefit from the routine, sense of purpose and responsibility that part-time
work can provide (Robotham 2012, King et al. 1989, Steinberg et al. 1982). From a policy
perspective, however, we do not recommend that students beginning to disengage from the
school system should take on intensive part-time work. Instead, we suggest that further
research is needed to explore how disengaging students can be encouraged to find a sense of
purposeorroutinethroughotheractivitiessuchassportsoryouthprograms. Alternatively,
part-time work with moderate hours may be a more balanced approach.
A limitation of the model proposed in our study is that owing to the fact each growth
period and associated treatment effect is dedicated a separate BART model, the computa-
tional cost of running the model may become quite large in settings with many waves of
data. Replacing the BART models with more efficient XBART models as in He & Hahn
(2023) and Krantsevich et al. (2023) would therefore make a promising area for future
work, widening the applicability of the proposed method.
Given the flexibility and widely adopted nature of the underlying BART framework, a
naturalextensionofthelongitudinalcausalmodeladoptedinourstudymightbetosurvival
data (Sparapani et al. 2016). Other natural extensions could include allowing multivari-
ate (McJames et al. 2024) or multinomial outcomes (Murray 2021), or the incorporation
of random effects (Wundervald et al. 2022, Yeager et al. 2022). Additionally, given the
specificity of our results to a representative sample of ninth to eleventh grade high school
students from the US, an application of a similar model to other countries or grade levels
would be of interest. More generally, we expect that the model’s flexibility will allow it to
be applied to a wide variety of datasets across diverse fields and application areas.
18References
Abadie, A. (2005), ‘Semiparametric difference-in-differences estimators’, The Review of
Economic Studies 72(1), 1–19.
Angrist, J. D., Imbens, G. W. & Rubin, D. B. (1996), ‘Identification of causal effects using
instrumental variables’, Journal of the American Statistical Association 91(434), 444–
455.
Bachman, J. G. & Schulenberg, J. (2014), How part-time work intensity relates to drug
use, problem behavior, time use, and satisfaction among high school seniors: Are these
consequences or merely correlates?, in ‘Risks and Problem Behaviors in Adolescence’,
Routledge, pp. 198–213.
Cai, L., Choi, K., Hansen, M. & Harrell, L. (2016), ‘Item response theory’, Annual Review
of Statistics and Its Application 3(1), 297–321.
Callaway, B. & Sant’Anna, P. H. (2021), ‘Difference-in-differences with multiple time peri-
ods’, Journal of Econometrics 225(2), 200–230.
Chipman, H. A., George, E. I. & McCulloch, R. E. (2010), ‘BART: Bayesian additive
regression trees’, The Annals of Applied Statistics 4(1), 266–298.
Donald, S. G. & Lang, K. (2007), ‘Inference with difference-in-differences and other panel
data’, The Review of Economics and Statistics 89(2), 221–233.
Entwisle, D. R., Alexander, K. L. & Olson, L. S. (2000), ‘Early work histories of urban
youth’, American Sociological Review 65(2), 279–297.
Friedman, J. H. (1991), ‘Multivariate adaptive regression splines’, The Annals of Statistics
19(1), 1–67.
Hahn, R. P., Murray, J. S. & Carvalho, C. M. (2020), ‘Bayesian regression tree models for
causal inference: Regularization, confounding, and heterogeneous effects (with discus-
sion)’, Bayesian Analysis 15(3), 965–1056.
He, J.&Hahn, P.R.(2023),‘Stochastictreeensemblesforregularizednonlinearregression’,
Journal of the American Statistical Association 118(541), 551–570.
Herna´n, M. A. & Robins, J. M. (2020), Causal Inference: What If, Boca Raton: Chapman
& Hall/CRC.
Hill, J. L. (2011), ‘Bayesian nonparametric modeling for causal inference’, Journal of Com-
putational and Graphical Statistics 20(1), 217–240.
Hogan, J. W. & Lancaster, T. (2004), ‘Instrumental variables and inverse probability
weighting for causal inference from longitudinal observational studies’, Statistical Meth-
ods in Medical Research 13(1), 17–48.
Howieson, C., McKechnie, J., Hobbs, S. & Semple, S. (2012), ‘New perspectives on school
students’ part-time work’, Sociology 46(2), 322–338.
19Imai, K. & Kim, I. S. (2021), ‘On the use of two-way fixed effects regression models for
causal inference with panel data’, Political Analysis 29(3), 405–415.
Ingels, S. J., Pratt, D. J., Herget, D. R., Burns, L. J., Dever, J. A., Ottem, R., Rogers,
J. E., Jin, Y. & Leinwand, S. (2011), ‘High school longitudinal study of 2009 (HSLS:
09): Base-year datafile documentation.NCES 2011-328.’, National Center for Education
Statistics .
Inglis, A., Parnell, A. & Hurley, C. (2022a), ‘Visualizations for Bayesian additive regression
trees’, arXiv preprint arXiv:2208.08966 .
Inglis,A.,Parnell,A.&Hurley,C.B.(2022b),‘Visualizingvariableimportanceandvariable
interaction effects in machine learning models’, Journal of Computational and Graphical
Statistics 31(3), 766–778.
Kablaoui, B. N. & Pautler, A. J. (1991), ‘The effects of part-time work experience on high
school students’, Journal of Career Development 17(3), 195–211.
Kapelner, A. & Bleich, J. (2015), ‘Prediction with missing data via Bayesian additive
regression trees’, Canadian Journal of Statistics 43(2), 224–239.
Khorramdel, L., von Davier, M., Gonzalez, E. & Yamamoto, K. (2020), Plausible val-
ues: principles of item response theory and multiple imputations, Springer International
Publishing.
King, A. J. et al. (1989), Improving Student Retention in Ontario Secondary Schools. Stu-
dent Retention and Transition Series., ERIC.
Kraft, M. A. (2020), ‘Interpreting effect sizes of education interventions’, Educational Re-
searcher 49(4), 241–253.
Krantsevich, N., He, J. & Hahn, P. R. (2023), Stochastic tree ensembles for estimating het-
erogeneous effects, in ‘International Conference on Artificial Intelligence and Statistics’,
PMLR, pp. 6120–6131.
Kurz, C. F. (2022), ‘Augmented inverse probability weighting and the double robustness
property’, Medical Decision Making 42(2), 156–167.
Lee, J. C. & Staff, J. (2007), ‘When work matters: The varying impact of work intensity
on high school dropout’, Sociology of Education 80(2), 158–178.
Lendle, S. D., Schwab, J., Petersen, M. L. & van der Laan, M. J. (2017), ‘LTMLE: an
R package implementing targeted minimum loss-based estimation for longitudinal data’,
Journal of Statistical Software 81, 1–21.
Lin, W.-C. & Tsai, C.-F. (2020), ‘Missing value imputation: a review and analysis of the
literature (2006–2017)’, Artificial Intelligence Review 53, 1487–1509.
McCall, M. S., Hauser, C., Cronin, J., Kingsbury, G. G. & Houser, R. (2006), ‘Achievement
gaps: An examination of differences in student achievement and growth. the full report.’,
Northwest Evaluation Association .
20McJames, N., O’Shea, A., Goh, Y. C. & Parnell, A. (2024), ‘Bayesian causal forests for
multivariate outcomes: application to Irish data from an international large scale educa-
tion assessment’, Journal of the Royal Statistical Society Series A: Statistics in Society
p. qnae049.
Monahan, K. C., Lee, J. M. & Steinberg, L. (2011), ‘Revisiting the impact of part-time
work on adolescent adjustment: Distinguishing between selection and socialization using
propensity score matching’, Child Development 82(1), 96–112.
Morgan, P. L., Farkas, G., Hillemeier, M. M. & Maczuga, S. (2016), ‘Science achievement
gaps begin very early, persist, and are largely explained by modifiable factors’, Educa-
tional Researcher 45(1), 18–35.
Murray, J. S. (2021), ‘Log-linear Bayesian additive regression trees for multinomial lo-
gistic and count regression models’, Journal of the American Statistical Association
116(534), 756–769.
Myint, L. (2024), ‘Controlling time-varying confounding in difference-in-differences studies
using the time-varying treatments framework’, Health Services and Outcomes Research
Methodology 24(1), 95–111.
Robins, J. M. (1997), Causal inference from complex longitudinal data, in ‘Latent variable
modeling and applications to causality’, Springer, pp. 69–117.
Robotham, D. (2012), ‘Student part-time employment: characteristics and consequences’,
Education+ Training 54(1), 65–75.
Roth, J., Sant’Anna, P. H., Bilinski, A. & Poe, J. (2023), ‘What’s trending in difference-in-
differences? a synthesis of the recent econometrics literature’, Journal of Econometrics
235(2), 2218–2244.
Rowley, K. J., Edmunds, C. C., Dufur, M. J., Jarvis, J. A. & Silveira, F. (2020), ‘Con-
textualising the achievement gap: Assessing educational achievement, inequality, and
disadvantage in high-income countries’, Comparative Education 56(4), 459–483.
Sekhon, J. S. (2008), ‘The Neyman-Rubin model of causal inference and estimation via
matching methods’, The Oxford Handbook of Political Methodology 2, 1–32.
URL: https://doi.org/10.1093/oxfordhb/9780199286546.003.0011
Singh, K. & Ozturk, M. (2000), ‘Effect of part-time work on high school mathematics and
science course taking’, The Journal of Educational Research 94(2), 67–74.
Sparapani, R. A., Logan, B. R., McCulloch, R. E. & Laud, P. W. (2016), ‘Nonparametric
survival analysis using Bayesian additive regression trees (bart)’, Statistics in Medicine
35(16), 2741–2753.
Splawa-Neyman, J., Dabrowska, D. M. & Speed, T. (1990), ‘On the application of prob-
ability theory to agricultural experiments. Essay on principles. Section 9.’, Statistical
Science 5(4), 465–472.
URL: https://doi.org/10.1214/ss/1177012031
21Steinberg, L. D., Greenberger, E., Garduque, L. & McAuliffe, S. (1982), ‘High school stu-
dents in the labor force: Some costs and benefits to schooling and learning’, Educational
Evaluation and Policy Analysis 4(3), 363–372.
Tompsett, D., Vansteelandt, S., Dukes, O. & De Stavola, B. (2022), ‘gesttools: General
purpose G-estimation in R’, Observational Studies 8(1), 1–28.
Wager, S. & Athey, S. (2018), ‘Estimation and inference of heterogeneous treatment effects
using random forests’, Journal of the American Statistical Association 113(523), 1228–
1242.
Wang, M., Martinez, I. & Hahn, P. R. (2024), ‘Longbet: Heterogeneous treatment effect
estimation in panel data’, arXiv preprint arXiv:2406.02530 .
Wu, M. (2005), ‘The role of plausible values in large-scale surveys’, Studies in Educational
Evaluation 31(2-3), 114–128.
Wundervald, B., Parnell, A. & Domijan, K. (2022), ‘Hierarchical embedded Bayesian ad-
ditive regression trees’, arXiv preprint arXiv:2204.07207 .
Yeager, D. S., Bryan, C. J., Gross, J. J., Murray, J. S., Krettek Cobb, D., HF Santos, P.,
Gravelding, H., Johnson, M. & Jamieson, J. P. (2022), ‘A synergistic mindsets interven-
tion protects adolescents from stress’, Nature 607(7919), 512–520.
Zimmerman, B.J.&Kitsantas, A.(2005), ‘Homeworkpracticesandacademicachievement:
The mediating role of self-efficacy and perceived responsibility beliefs’, Contemporary
Educational Psychology 30(4), 397–417.
22Supplementary Materials - Table of Summary Statistics
Table 3: Summary statistics for selected categorical variables. The proportion column
provides the proportion of students belonging to each category in Wave 1, while the Wave
1 and Wave 2 achievement columns provide the mean achievement level within each group.
1
2
evaW
tnemeveihcA
1
evaW
tnemeveihcA
1
evaW
noitroporP
elbairaV
redneG
tnedutS
36.0
80.0-
%3.05
elaM
06.0
60.0-
%7.94
elameF
egaugnaL
tsriF
36.0
50.0-
%3.28
ylnO
hsilgnE
85.0
51.0-
%1.6
rehtO
dna
hsilgnE
85.0
61.0-
%5.11
rehtO
puteS
ylimaF
39.0
12.0
%2.34
stneraP
lacigoloiB
htoB
htiW
eviL
17.0
20.0
%9.23
tnemegnarrA
rehtO
52.0
83.0-
%9.32
esnopseR
oN
leveL
noitacudE
tneraP
93.0
32.0-
%7.74
eergeD
s’rolehcaB
nahT
sseL
32.1
54.0
%4.82
rehgiH
ro
eergeD
s’rolehcaB
52.0
83.0-
%9.32
esnopseR
oN
snoitatcepxE
erutuF
tnedutS
50.0
65.0-
%5.12
eergeD
s’rolehcaB
nahT
sseL
98.0
81.0
%8.65
rehgiH
ro
eergeD
s’rolehcaB
14.0
52.0-
%7.12
eruS
toN
tnedutS
epyT
loohcS
75.0
11.0-
%8.29
cilbuP
12.1
53.0
%2.7
etavirP
ro
cilohtaCSupplementary Materials - LBCF Diagram
𝜏
𝛿
𝜇
Figure 7: Diagram of how the proposed LBCF model fits into the framework of the
difference-in-differences approach. Two observations are shown for the purposes of illus-
tration - one from an imaginary control group, and one from a corresponding treatment
group. The solid lines indicate the realised achievement trajectories, while the dashed line
in red indicates a counterfactual trajectory for the treated unit had it actually not received
treatment. Initial achievement estimates at Wave 1 are provided by µ. The expected
growth (difference) in achievement without treatment is provided by δ, while the effect of
treatment on this growth (the difference-in-differences) is captured by τ. Note that while
only one µ value is indicated in the diagram to avoid overprinting, the model does in fact
provide individual µ estimates for every observation. Similarly, individual estimates are
provided for each of the δ and τ estimates as well.
2Supplementary Materials - LBCF Algorithm
Algorithm 1: LBCF MCMC Algorithm
Data: Outcome variable y (response for individual i at time t of T time periods);
i,t
time varying covariates x (covariates collected on individual i up to time t);
i,t
treatment variable Z (to indicate if individual i received treatment between periods t and
i,t+1
t+1: 1 for treatment, 0 for control)
Result: Posterior list of trees, values of σ2, fitted values µˆ , δˆ , and τˆ
i i,t i,t
Initialisation;
Hyper-parameter values of α , β , α , β , α , β , σ2, σ2, σ2, ν, λ;
µ µ δ δ τ τ µ δ τ
Number of µ trees n ;
µ
Number of δ trees n ;
δ
Number of τ trees n ;
τ
Number of iterations N;
Initial value σ2 =1;
Set µ trees T ; j =1,...,n to stumps;
j µ
Set δ trees T ; j =1,...,n to stumps;
j δ
Set τ trees T ; j =1,...,n to stumps;
j τ
Set terminal node parameters of all µ, δ, and τ trees to 0;
for iterations i from 1 to N do
for µ trees j from 1 to n do
µ
Compute partial residuals from y minus predictions of all trees except µ tree j;
Grow a new tree Tnew based on grow/prune/change/swap;
j
Accept/Reject tree structure with Metropolis-Hastings step using
P(T |R ,σ2)∝P(T )P(R |T ,σ2);
µ,j µ,j µ,j µ,j µ,j
Sample µ values from normal distribution using P(M |T ,R ,σ2);
µ,j µ,j µ,j
end
for Time periods t from 2 to T do
for δ trees j from 1 to n do
t δ
Compute partial residuals from y minus predictions of all trees except δ tree j;
t
Grow a new tree Tnew based on grow/prune/change/swap;
j
Accept/Reject tree structure with Metropolis-Hastings step using
P(T |R ,σ2)∝P(T )P(R |T ,σ2);
δt,j δt,j δt,j δt,j δt,j
Sample δ values from normal distribution using P(M |T ,R ,σ2);
t δt,j δt,j δt,j
end
for τ trees j from 1 to n do
t τ
Compute partial residuals from y minus predictions of all trees except τ tree j;
t
Grow a new tree Tnew based on grow/prune/change/swap;
j
Accept/Reject tree structure with Metropolis-Hastings step using
P(T |R ,σ2)∝P(T )P(R |T ,σ2);
τt,j τt,j τt,j τt,j τt,j
Sample τ values from normal distribution using P(M |T ,R ,σ2);
t τt,j τt,j τt,j
end
end
Get predictions yˆfrom all trees;
Update σ2 with Inverse-Gamma distribution using P(σ2|yˆ);
end
3