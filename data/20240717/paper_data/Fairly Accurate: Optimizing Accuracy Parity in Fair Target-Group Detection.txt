FAIRLY ACCURATE: OPTIMIZING ACCURACY PARITY IN FAIR
TARGET-GROUP DETECTION
APREPRINT
SoumyajitGupta1,4,VenelinKovatchev5,MariaDe-Arteaga2,4andMatthewLease3,4
1DepartmentofComputerScience
2McCombsSchoolofBusiness
3SchoolofInformation
4TheUniversityofTexasatAustin
5SchoolofComputerScience,TheUniversityofBirmingham
smjtgupta@utexas.edu,v.o.kovatchev@bham.ac.uk
dearteaga@mccombs.utexas.edu,ml@utexas.edu
July17,2024
ABSTRACT
Inalgorithmictoxicitydetectionpipelines,itisimportanttoidentifywhichdemographicgroup(s)are
thesubjectofapost,ataskcommonlyknownastarget(group)detection. Whileaccuratedetectionis
clearlyimportant,wefurtheradvocateafairnessobjective: toprovideequalprotectiontoallgroups
whomaybetargeted. Tothisend,weadoptAccuracyParity(AP)—balanceddetectionaccuracy
acrossgroups—asourfairnessobjective. However,inordertoalignmodeltrainingwithourAP
fairnessobjective,werequireanequivalentlossfunction. Moreover,forgradient-basedmodelssuch
asneuralnetworks,thislossfunctionneedstobedifferentiable. Becausenosuchlossfunctionexists
todayforAP,weproposeGroupAccuracyParity(GAP):thefirstdifferentiablelossfunctionhaving
aone-on-onemappingtoAP.WeempiricallyshowthatGAPaddressesdisparateimpactongroups
fortargetdetection. Furthermore,becauseasinglepostoftentargetsmultiplegroupsinpractice,we
alsoprovideamathematicalextensionofGAPtolargermulti-groupsettings,somethingtypically
requiringheuristicsinpriorwork. OurfindingsshowthatbyoptimizingAP,GAPbettermitigates
biasincomparisonwithothercommonlyemployedlossfunctions.
1 Introduction
ToxicLanguageinsocialmediaisoftenassociatedwithvariousrisksandharms: cyber-bullying,discrimination,mental
healthproblems,andevenhatecrimes. Giventhemassivevolumeofusergeneratedcontentonline,manualreviewof
allpostsbyhumanmoderatorssimplydoesnotscale. Consequently,NaturalLanguageProcessing(NLP)methods
havebeendevelopedtofullyorpartiallyautomatetoxiclanguagedetection[52]. However,studieshavealsofoundthat
modelaccuracycanvarygreatlyacrossdemographicattributes,suchasraceorgender[44,51,9]whenoptimizingan
overallmeasurewithoutconsideringthedemographicgroupspresentinthedata.
Inadditiontodetectingtoxiclanguageitself,animportantrelatedtaskistarget(group)detection: identifyingwhich
demographicgroup(s)arethesubjectofagivenpost. Ingeneral,theabilitytodetectwhichdemographicgroup(s)are
thesubjectofaposthasbroadvalue(e.g.,supportingsearchfordemographic-relatedposts). Inthecontextoftoxic
languagedetection,identifyingwhichgroup(s)arebeingdiscussedortargetedisimportantinstrivingtoprovideequal
protectiontoallgroups. Inaddition,becausethelanguageoftoxicitycanvarybytargetedgroup(e.g.,racialslurs),
annotatingtrainingdatafortargetedgroupscanenablemoreaccurateandfairerdetectionoftoxicity[22].
Todate, researchontargetdetectionhastraditionallyassumedthateachpostdiscussesonlyonegroup[5,51,60].
However,recentwork[32,20]hasrelaxedthisassumptionwiththerealizationthatevenasinglepostcantargetmultiple
groupssimultaneously,emphasizingthepracticalneedfortargetdetectionmethodstosupportthisreal-worldsetting.
4202
luJ
61
]GL.sc[
1v33911.7042:viXraAlgorithmicfairnesstasksthathavereceivedmostattentioninthepastyearsaretypicallyassociatedwithallocating
goodsorburdens(e.g.collegeadmissionisagood,anddenyingbailisaburden). Insuchsettings,itiseasytoidentify
a“positive"anda“negative"class,anderrorstypicallyhaveasymmetriccosts. Forexample,errorsinbeingmistakenly
grantedadmission(falsepositive)vs.beingmistakenlydenied(falsenegative)arenotequal. However,targetdetection
presentsamulti-labelpredictiontaskwherelabelscorrespondtodemographicgroups(e.g.,Latinx,Black,andNative
American). As such, there is no notion of “positive" and “negative" label, and the motivation of providing equal
protectiontoallgroupsresultsinconsideringerrorsassymmetric. Ifatoxicposttrulytargetsgroup-Latinxbutis
mistakenlydetectedastargetinggroup-Black,thiswouldbeequallyundesirableasatoxicposttargetinggroup-Black
butmistakenlydetectedastargetinggroup-Latinx. Thus,afairtargetdetectionmodelinvolvesequalizingaccuracy
acrossallgroups,i.e.AccuracyParity(AP)[61].
Aparticularchallengewhileoptimizingforafairness(oranystandard)evaluationmeasureistheneedforanequivalent
lossfunctionduringmodeltraining,toalignmodeltrainingwithone’sfairnessobjective. Withoutsuchalignment,we
runtheriskpotentialdivergencefromourtrueobjective,aphenomenonknownasMetricDivergence[40,38,54]. For
gradient-basedmodelssuchasneuralnetworks,thelossfunctionneedstobedifferentiable.
Conceptually,APisoftenmentionedasafairnessmetricofpotentialinterest[39,24,3]. However,perhapsbecause
itisrarelyofempiricalinterestinallocationtasks,therehasbeenscantresearchinoptimizationmethodstoactually
operationalizeit. Inparticular,weknowofnodifferentiablelossfunction(optimizer)forAP.Additionally,priorworks
[12,24,3,9]havestrictlyconsideredAPasanevaluationmeasureonly,andundera2-group(binary)setting,with
heuristicextensionsformorethan2groups.
Inthiswork,weproposeanovellossfunction,GroupAccuracyParity(GAP),providingadirect,one-on-onemapping
totheAPevaluationmeasure. Whileourmotivatingtaskistarget(group)detection,ourGAPlossfunctionismodel,
task,anddatasetagnostic,beinggenerallyalignedwithAPasafairnessobjectivetopreventdisparateimpactacross
groups. BecauseGAPisdifferentiable,itcanbedirectlyusedtooptimizedescent-basedmodels. Moreover,becausea
singlepostcanactuallytargetmultiplegroups,weprovideamathematical,non-heuristicextensionofGAPtogeneralize
tolargermulti-groupsettingsbeyondbinary. Weprovidebothatheoreticalderivation(frombasiccross-entropy)andan
empiricalsupportforGAP.EmpiricalresultsshowaclearbenefitofoptimizingGAPforthetargetmeasureAP,rather
thanusingalternativelossfunctions,suchascrossentropyorotherdifferentiablefairnesslosses[53,60].
Ourkeycontributionsinclude:
• Anovel,differentiableloss(GAP)thatoptimizesAPmeasure,i.e.balancedaccuracyacrossgroups.
• AtheoreticalderivationofGAPwithcorrectnesschecksandextensiontoreal-world,multi-groupscenarios.
• ExperimentswithGAPinfairtarget-groupdetection,showingthatitmitigatesdisparateimpactacrossgroups.
• Acomparisonoverfairnesslosses,demonstratingthatGAPachievesthebestAPvaluecomparedtoothers.
• Forreproducibilityandadoption,weoursourcecodewillbeavailablesoon.1.
2 RelatedWork
Toxicity Detection and Fairness. Detection of toxic language in its various forms [15] has attracted signficant
attentionduetoitsprevalenceinonlinesocialmediaplatforms. Todate,manydatasetshavebeencreatedtosupport
modeltrainingandevaluation[46,56,58,57,11,16,30,47]. WhileNLP/MLmethodstendtooptimizeforoverall
performance,recentstudieshighlighttheracialbiasinducedinsuchclassificationtasks,whengroupidentifiersare
notconsideredduringmodeltraining[51,10,60]. Here,fairnessconcernswithrespecttomultiplestakeholdersarise,
includingtheauthorofthepost[51]andthegroupstargetedbyapost. Wefocusourattentiononfairnesswithrespect
todemographicgroupstargetedinthecontent.
Toaddresstheproblemofbiasintoxiclanguagedetection,avarietyofworkhassoughttoimprovethetrainingand
testing data [44, 51, 48, 32, 21, 49, 26], with the expectation that fairer data will lead to fairer models. Sap et al.
[51]proposetoresolvetheproblembyusingraceanddialectprimingduringannotation. Parketal.[44]proposea
data-focusedfairnessapproachforthecloselyrelatedproblemofgenderbias. Theycreatecontrastiveexamplesby
usinggenderswapdataaugmentation. Röttgeretal.[48]framedasetoffunctionaltestsandarguedthatautomated
toxicitydetectionmodelsshouldbeevaluatedonallfunctionalities. LikeSapetal.[51],theotherworksabovealso
considerannotatoridentityandtaskdesigninmitigatinglabelbias.
1Source code at https://github.com/smjtgupta/GAP.
2FairnessMeasures. Measuresbasedonconfusionmatrices(e.g.accuracy,precision,recall,andF1)helpmeasuring
performanceofmachinelearningsystems. However,severalstudiesunveilMLsystemscanbediscriminatorybased
ondifferentsensitiveattributes(race,genderetc.). TheamplificationofsystemicunfairnessthroughAIapplications
hasbeenpronouncedacrossdifferentcriticalapplicationareassuchashiring,finance,legalapplications,andcontent
moderation[1]. Toaddressthis,severalmethodshavebeenintroducedtoquantitativelymeasureandmitigateunfairness
inmachinelearningsystemsborrowingfromlegalliteratureonanti-discrimination[13].
Friedler et al. [17] show that these different worldviews can lead to conflicting statistical targets, which makes it
impossibletosimultaneouslyachieveconflictingfairnesstargets. Becausefairnessmeasurescanbeatoddswitheach
otherbasedontheunderlyingassumptionsandstatisticalchoices[41],selectinganappropriatefairnessmetricsoften
dependsonthetask,usecase,andstakeholderpriorities[18,2,27].
DifferentiableFairnessLosses. Typically,toxicitydetectionsystemsaretrainedwithasingleobjectiveofminimizing
cross-entropy[16,44,48],whichisdifferentiable. Forimposingafairnessconstraintintheoptimizationproblem,a
standardapproachistoaddadifferentiableregularizationtermwithahyper-parameterλ,asshowninEq. 1. While
decreasingcross-entropyleadstodecreasingOverallError(OE),effectivelyincreasingOverallAccuracy(OA),we
typicallyneedafairnesslossfunctionwhosedecreaseleadstoincreaseinacorrespondingfairnessevaluationmeasure.
min Cross-Entropyloss(f )+λ·Fairnessloss(f ) (1)
1 2
Whilemanyfairnessevaluationmeasuresexists, oursurveyofexistingfairness-relatedlossfunctions, thatstrictly
optimizesforanequivalentmeasureduringmodeltraining,findsonlyfewvariants. Fore.g.theCLA[53]losshas
one-on-onecorrespondenceforoptimizingFalseNegativeRatesacrossgroups. OtheradversariallosseslikeADV[60]
triestooptimizeforFalsePositiveRates,butsuffersfrommetricdivergence. Rankingliteraturesuffersfromlackof
equivalentoptimizersowingtothediscontinuousnatureofrankorder,hencetheyfocusondesigningsurrogateswith
closeasymptoticbounds[43,54].
SameUsage,VeryManyMonikers. InthisworkwefocusonoptimizingforAccuracyParity(AP)[61],which
referstoequalperformanceofamodelacrossdifferentdemographicgroups,ensuringthataccuracyremainsconsistent
irrespectiveofgroupmembership. Thisisapopularfairnessmeasureandhasbeenproposedinliterature,yetwithvery
manydifferentnames. TheoneswefoundincludeAccuracyEquity[12],EqualityofAccuracy[24],AccuracyParity
[61],EqualAccuracy[39],OverallAccuracyEquality[3]andAccuracyDifference[9]. However,notethatallthese
workhaveusedAPasanevaluationmeasureintheirclassificationprotocoltoevaluatedegreesofun-fairness.
3 GroupAccuracyParity(GAP)
Inthiswork,wefocusonbalancingaccuracyacrossgroups,knownasAccuracyParity(AP)[61],motivatedbyits
relevancetotheproblemoffairtarget-groupdetection. WeprovidethefirstdifferentiablelossfunctionforAPandits
extensiontoaccommodatemultiple(beyondbinary)groups. Ifafairnesstaskdemandssymmetricerrorcosts,itcanbe
directlyoptimizedviaourGroupAccuracyParity(GAP)losswithoutmetricdivergence[40]w.r.t.theAPevaluation
measure.
3.1 AccuracyDifference
WhileAPisanequalitycondition,westillneedtoquantifythedeviationfromequalityincasesofunequalperformance
acrossgroups. WethereforeuseAccuracydifference(AD)Dasetal.[9],acontinuousversionofAPtomeasurethis
deviation. ADisshownin(Eq. 2),whereyˆ,y,g arethepredictedlabel,truelabel,andgroupattributerespectively.
ThusADisdefinedbasedontheconfusionmatrix. Sincetheformulationisprobabilisticinnature,i.e.ratioofnumbers
overthedataset,andnotdistributionovervariable,ADbecomesnon-differentiable. Thatis,ADcanonlybeusedin
apost-hocmannerandcannotbedirectlyusedforgradient-basedbackpropagation. Furthermore,Eq. 2inherently
assumesthatthemajoritygroupaccuracy(g = 1)willalwaysbehigherthanthevulnerablegroup(g = 0),which
mightnotalwaysholdtrue,resultinginpotentialnegativevaluesofADintherange[-1,1]. Naturally,asapost-hoc
measure,ADisdisconnectedfromtheoptimizationobjectiveofthemodelusedduringtraining.
AD =P[yˆ=y|g =1]−P[yˆ=y|g =0] (2)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
AccGroup1(g=1) AccGroup0(g=0)
TheselimitationsmotivatedustodefineadifferentiablelossfunctionforAD,whichwereferasGroupAccuracyParity
(GAP),allowinganydescent-basedmodelduringtrainingtooptimizeforequalaccuracyacrossgroup-attribute,and
addressestherangeissueofAD.
33.2 GAPFormulation,UsageandProperties
Cross-Entropy(CE)lossiscommonlyusedasalossfunctioninclassificationtasksandisdesignedtomeasurethe
differencebetweenprobabilitydistribution(yˆ)predictedbythemodelandthetruedistribution(y)ofthedata. CEisa
generaldifferentiablelossthatcanbeusedtooptimizeovertheentiredataorindependentlyacrossgroups(g). Although
notastrictone-to-onecorrespondence,itisgenerallyobservedthatminimizingCEleadstominimizingOverallError
(OE),therebymaximizingOverallAccuracy(OA),duetoCEprovidingnon-asymptoticguaranteesandplacingan
upperboundaryontheestimationerroroftheactualloss[35].
(cid:88)
CE(y,yˆ)= y(c)log(yˆ(c)) (3)
c∈class
Forbalancedclassificationacrossgroups,e.g.demographicinformationofpostsubject,weformulateourGAPloss
functionasfollows: wefirstcalculatetheCEacrosseachgroup,thenminimizethedifferenceacrossthemandfinally
frameitasaSingleObjectiveOptimizationproblemcorrespondingtoEq. 1. TheGAPlossfunctioninEq. 4isequal
tooverallcrossentropyloss(OE=CE(y,yˆ))inEq. 3onlywhenbothCEerrorsareequalacrossthegroups.
GAP =OE+λ∥ CE(g =1) − CE(g =0) ∥2 (4)
2
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
errGroup1(g=1) errGroup0(g=0)
Remark. GAPoptimizesforAP,toreducetheaccuracygapacrossgroups,thereforeminimizingthistypeofdisparate
impact across groups. Additionally, GAP formulation is flexible with different weighted variants of accuracy w.r.t.
chosenentropy,dependingontheevaluationneed.
TheformulationoftheGAPlossinEq. 4isgeneralizabletodifferentweightedvariantsofaccuracy. Fore.g.Binary
CrossEntropy(BCE)inEq. 5isusedasalossfunctionforoptimizingabinaryclassifieri.e.labelsof0sand1s. BCE,
however,doesnottakeintoaccountthelabelimbalance.
1 (cid:88)
BCE =− ylog(yˆ)+(1−y)log(1−yˆ) (5)
N
N
WeightedBinaryCrossEntropy(wBCE)re-weightstheerrorfortheclasslabelsproportionaltotheirinversefrequency
inthedata. Theclassre-weightingstrategyw(·)inEq. 6isavailableinpackageslikeSkLearn[45]anddiscussed
indetailbyLinetal.[33]. Sincemostreal-worlddatasetsoftenhavelabelimbalance,wBCEaimstopenalizeboth
labels(1sand0s)equally. Thus,minimizingwBCEleadstomaximizingbalancedaccuracy(BA),abettermeasurethan
accuracy,inpresenceoflabelimbalance.
1 (cid:88)
wBCE =− w(y)·ylog(yˆ)+w(1−y)·(1−y)log(1−yˆ) (6)
N
N
Remark. InthisimplementationwechoosetheweightedBinaryCrossEntropy(wBCE)variantintheGAPterms
toaccountforbinarylabelimbalancewithineachgroup. Consequently,weuseBalancedAccuracy(BA)toevaluate
performanceofeachgroup,tomaintainfunctionalmapping.
TheGAPfunctionhasthefollowingproperties:
1. GAPmapstoAD.GAPhasaone-to-onecorrespondencetoADi.e.minimizingGAPalsominimizesAD.
2. GAPisdifferentiable. GAPisdefinedasthesummationofoverallerrorandthesquared2-normdifference
betweenthewBCEacrossthegroups. SincewBCEisdifferentiable,soisthe2-normdifference. HenceGAP
canbeoptimizedforanydescentbasedmodel.
3. GAPissmooth. GAPhasa2-normformulation,thustherangeofattainableevaluationvaluesarewithin
[0,1],avoidingthenegativityissueinAD.Beingasquared2-normmeasure,thesurfaceofGAPissmoother
thanothercomparablemeasureslikeCLA[53],whichuses1-norm. Asmoothersurfaceleadstobetterdescent
ratesandhasabetterchanceofavoidingshallowoptima[6].
ForaderivationfromCEtoGAP,readersarereferredtoAppendixA,showingthestrictcorrespondencebetweenthe
lossmeasures. InthispaperweimplementGAP(Eq. 4)correspondingtoAD(Eq. 2). Assuch,GAPcanbeoptimized
forbinarylabelsandbinarygroups.
43.3 ExtensionofGAPbeyondBinaryGroups
Itissometimesthecasethatapostmaytargetmultiplegroups,thusweneedameasurethataccommodatesamulti-group
setting. As noted in Das et al. [9], the binary AD concept can be extended for multi-class and multi-group tasks.
However,itisleftasanheuristicexerciseforthereader. TomakeourGAPformulationnon-heuristic,weprovidea
mathematicalextension(seeAppendixforproof)ofittoaccommodatemultiple(beyondbinary)groupsofcardinality
G,whilekeepingtheformulationsimilartointerpret.
(cid:88)
GAP =OE+λ ∥CE(g =i)−CE(g =j)∥2 (7)
2
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
i,j∈[G],i̸=j
errGroupi(g=i) errGroupj(g=j)
Themulti-groupextensionofGAPinEq.7hasGC termsintheregularizationfactor,correspondingtoallcombinations
2
ofdistinctgrouppairs(i,j)∈[G],i̸=j withinthedatasetofgroupcardinalityG,whilebeingsmoothinnaturedueto
thesquared2-norm. Thisformulationallowsustoaccountforpracticalscenarioswhereapostcanpotentiallytarget
multiplegroup(s)simultaneously.
3.4 CodeFlow
Alg. 1presentsthelogicofthewBCE lossinEq. 6, wheretheweightsw[g]representinverselyscaledvaluesof
labels(0sand1s),withineachgroupg. Thuserr_grp[g]equivalentlymapstoBalancedAccuracy(BA),anevaluation
measurewidelyusedindatasetswithlabelimbalance. Absenceofthisweightingtermwouldstrictlymaptostandard
accuracy,followingthemappingfromBCE. Theoverallerrorerr_overallisthendefinedassummationoferrors
across groups. Note that we do not weight groups while adding their errors since: a) we want to treat all groups
equally;andb)TensorFlow’sbcefunctionisscaleindependent,i.e.itproducessameerrorvalueforequalratiosof
mispredictionsw.r.t.totalsamples,irrespectiveofsamplesize. Fore.g.bcevalueover5sampleswith1mispredictionis
equaltobcevalueover15sampleswith3misprediction.
Algorithm1overall_loss(y_true,y_pred,w[g])
LossfunctionforoptimizingOverallError
1: Input:y_true,y_pred ▷TrueandPredictedLabels
2: Input:w[g] ▷BalancedweightsofGroupg
3: y_true_lab=y_true[:,0] ▷LabelInfo
4: y_true_dem=y_true[:,1] ▷DemographicInfo
5: foreachgroupgrp[g]∈Gdo
6: pos_grp[g]=group(y_true_dem==g) ▷Findindices
7: y_true[g]=y_true_lab[pos_grp[g]] ▷Truegrouplabels
8: y_pred[g]=y_pred[pos_grp[g]] ▷Predictedgrouplabels
9: err_grp[g]=bce(y_true[g],y_pred[g],w[g]) ▷wBCE
10:
err_overall=(cid:80)Gerr_grp[g]
▷summationofgrouploss
11: Output:err_overall
Alg. 2presentsthelogicofourproposedGAPloss. AftercomputingoverallerrorviaAlg. 1,GAPcomputestheGC
2
group-pairwiseerrors. Theerrorsaresquaredtoenforcepositivevaluesandallowforasmoothlosssurface. Thefinal
SOOerrorasperEq. 1isthesummationoftheoverallerrorandaregularizedsumofgroup-pairerrors.
Algorithm2gba_loss(y_true,y_pred,w[g])
LossfunctionforoptimizingGroupBalancedError
0: RepeatSteps1-10ofAlg.1
1: forgrouppairs[i,j]∈G,[i̸=j]do ▷GC iterations
2
2: err_group_pairs=(cid:80) (err_grp[i]−err_grp[j])2
3: err_balanced=err_overall+λ·err_group_pairs
4: Output:err_balanced
4 ExperimentalDetails
Wedescribethedatasetusedforvalidation,theproblemformulation,theneuralarchitecture,thebaselineloss,andtwo
otherfairnesslossesusedforcomparingperformanceofourproposedGAPloss. Implementationdetailsregarding
setup,datapre-processing,andrelateditemsareincludedinAppendixB.
54.1 Dataset
Toassessfairtarget-groupdetectionweusetheHuggingFaceDLabdataset[14]originallyopen-sourcedin[28]as
theMHScorpus. Thedatasethas135,556posts,whereeachposthasanexplicitannotationforthetargetgroup(s)i.e.
demographicsofthetargetentity(target_race). Weselectpostshavingthetarget-demographicsflagasTrue,wherea
posttargetsoneormoregroups,irrespectiveofthetoxicitylabelofthepost. Wehavebooleanscoresonannotator
consensusforsevendemographicgroups: Asian,Black,Latinx,Middle-Eastern,Native-American,Pacific-Islanderand
White. Fig. 1showsthesplitofthetargetedgroupsbyposts. Fig. 2showsthesplitofpostsbythenumberofgroups
targeted2. Wedoa80%-20%splitfortrainingandtestingdatarespectively.
Posts in Each Target Group
22899
20000
15000
10000 9450 9797
8497
7025
5000
2819
2358
0
Asian Black Latinx Middle Native Pacific White
Eastern American Islander
Targeted Groups
Figure1: StatisticsofpoststargetingvariousdemographicgroupsintheDLabdataset[28]. TheBlackcommunityis
thestatisticalmajorityinthedataset,emphasizingthattheyaremosthighlytargetedinposts.
4.2 ProblemSetup
Inourfairtarget-groupdetectionproblem,wearegivenadatasetX ∈RN×F,withN samples(posts)andF features.
Thesex∈RF dimensionalfeaturescanbeextractedforeachpostusinganyoff-the-shelfNLPmodel. LetY ∈RN×G
denotethelabelspace,wherey ={0,1}GrepresentsthesetofallpossiblecombinationsofGbinarylabels,indicating
whethereachoftheg ∈Ggroupsistargeted(1)ornot(0)bythepostx.Theobjectiveistolearnafunctionf :X →Y
thatmapseachpostxtoitscorrespondinglabelvectory. Thisleadstoamulti-labelclassificationproblemsetting
[37,25].
4.3 NeuralModelandBaselineMeasure
WeusetheDistilBERT[50]representationlayertoextractnumericalfeaturesfromposts. Thisisfollowedbylayers
of dense neurons with relu activation and biases, ending in classification nodes with sigmoid activation with 0.5
classificationthreshold. Forexperiments,wefreezetheweightsoftheDistilBERTlayer. Theonlytrainableparameters
inthemodelsarethedenseneuronunitsthatfollowtheDistilBERTlayeruntiltheoutputnodes. Giventhemulti-label
binaryclassificationsetupofourproblem, weuseweightedBinaryCrossEntropy(wBCE)asourbaselinelossto
optimizeOverallError (OE)fortheGoutputnodes. OnecanreplacetheDistilBERTlayerwithanyotherfeature
representationwithoutalteringtherestofthemodel.
2Forgroupsofcardinalitysixandseven,thepostsaretargetedtowardsmostgroups,hencetheincreaseinnumber.
6
stsoP
fo
rebmuNComments having Multiple Targets
37269
104
4056
1103
103 1008
690
458
232
1 2 3 4 5 6 7
Number of Groups Targeted
Figure2: Statisticsofpoststargetingmultiplegroups.
BalancedAccuracy(BA)(↑)
Loss Asian Black Latinx MiddleEastern NativeAmerican PacificIslander White Max.Diff.(↓) Avg.BA(↑) #BestBA(↑)
OE 80.31 86.91 81.07 84.87 64.99 67.91 75.01 21.9±1.3 77.29±0.29 2/7
CLA 82.51 85.34 81.67 84.62 73.91 74.92 80.44 11.4±0.8 80.49±0.14 0/7
GAP 83.18 83.86 83.47 83.42 78.95 78.32 82.58 5.5±0.5 81.97±0.13 5/7
Table 1: Balanced Accuracy (BA) achieved by each loss function (OE and CLA baselines vs. our GAP) over the
7demographicgroups(ontestdata)foronerun. Foreachloss, wealsocolorwhichgroupexhibitsthemaximum
andminimumBAvaluesachievedforthatthelossoverthe7groups,withthedifferencebetweenthismaximumvs.
minimum shown in the Max. Diff. column (for BA, we want to minimize this difference). GAP achieves a lower
maximumdifference(Max. Diff. =5.54)thaneitherbaselinelossfunction,evidentfromthevisualizationinFig. 3.
GAPalsoachievesthehighest(macro)averageBAacrossgroups(Avg. BA=81.97),andthebestBAformostofthe
groups(#BestBAcolumn=5/7). WealsoreportthestandarddeviationofMax. DiffandAvg. BAoverfiveruns,with
CLAandGAPhavingsimilardeviation.
4.4 OtherDifferentiableFairnessMeasures
SincenodifferentiablevariantofAPexists,weadditionallydocomparisonsusingtwodifferentiablefairnesslosses,
CLAandADV.Bothlossesoptimizeforcertainasymmetricerrorratesacrossgroupshighlightingthedeviationfrom
symmetrywhenusingAPforevaluation.
ThefirstfairnesslossCLAss-wiseequalopportunity(CLA)[53]seekstobalanceFalseNegativeRate(FNR)across
protectedgroups[8],alsoknownasequalityofopportunity[23]. CLAminimizestheerrorinabsolutedifferences
betweenerrorw.r.t.alabel(BCE(y))anderrorw.r.t.alabelgiventhegroupattribute(BCE(y,g)).
(cid:88) (cid:88)
CLA=BCE+λ· |BCE(y,g)−BCE(y)| (8)
y∈Cg∈G
Thesecondfairnessloss[60]isanadversarialapproachtodemotingunfairness,whichwedenoteasADV.Itseeksto
providefalsepositiverate(FPR)balance[8]acrossgroups,otherwiseknownaspredictiveequality(ibid.)
ADV =β·BCE+(1−β)·(adversary(y,g)−0.5) (9)
Note that while CLA is applicable to multi-group setting, ADV by design is only for two-group setting. In our
implementation,wereplaceBCEwithwBCEinEqs. 8,9tomakeafaircomparisonunderlabelimbalance.
7
stnemmoC
fo
rebmuN5 Results
Allreportedresultsinthemainmaterialareforthe7-groupsetting. ForgroupperformanceonallpossibleGC isolated
2
pairs,pleaserefertoAppendixC.ADVdidnotrunfor7-groupsetting,itsisolatedpairvaluesareinAppendix.
5.1 EvaluationMeasuresConsidered
BalancedAccuracy(BA) Unlikestandardaccuracy,whichcanbemisleadinginthepresenceoflabelimbalance,BA
providesamorereliablemodelassessmentwhendealingwithimbalanceddatasets. Itcomputestheaverageaccuracyof
eachlabel,therebyofferingabalancedperspectivetoaccountfortheunequallabeldistribution. Byconsideringboth
thesensitivity(TPR:truepositiverate)andspecificity(TNR:truenegativerate)ofeachlabel,BAeffectivelycaptures
themodel’sabilitytocorrectlyclassifyinstancesacrossalllabels,regardlessoftheirprevalence.
BA=(TPR+TNR)/2.0 (10)
AverageBalancedAccuracy(Avg. BA). Whenoptimizingaccuracyacrossgroups,wereporttheaverageoverthe
group-specificBAs(knownasmacro-averaging)asasummarystatistics. TheAvg. BA(macro)treatseachgroup
equally,ensuringthattheclassifier’sperformanceisevaluatedinabalancedmanneracrossalldemographicgroups.
G
1 (cid:88)
Avg.BA= BA(g) (11)
G
g=1
HammingLoss(HL) Itisawidelyemployedmetricforassessingtheperformanceofmulti-labelclassifiers.Formally,
foradatasetwithN instancesandGlabels,theHammingLoss(HL)quantifiesthefractionofincorrectlypredicted
labelsacrossallinstancesinthedataset,withhamming(y (g),yˆ(g))asanindicatorfunctionof1,iftheg-thlabel
i i
forinstanceiisincorrectlypredicted, 0otherwise. Specifically, itmeasurestheaveragefractionoflabelsthatare
misclassifiedincomparisontothetruelabelset. HLandSubsetAccuracyLossarecomparableundersmalllabelcases
[59],hencewejustreportHL.
N G
1 (cid:88)(cid:88)
HL= hamming(y (g),yˆ(g)) (12)
NG i i
i=1g=1
Othermeasuresofinterest AlthoughwearestrictlyoptimizingforsimilarBAacrossgroups,itisimperativetostate
thatthegaininfairnessdoesnotcomeatastricttrade-offtoothermeasuresofinterestlikePrecision,Recall,F1. Given
ourmulti-labelsetup,wereportthemacrovariants(averageovergroup-specificnumbers)ofthementionedmeasures.
(cid:80)
Prc(g)
Prc = g∈G (13)
macro G
(cid:80)
Rec(g)
Rec = g∈G (14)
macro G
2·Prc ·Rec
F1 = macro macro (15)
macro Prc +Rec
macro macro
5.2 Evaluation&LossPerformance
ThevaluespresentedinTable1illustratetheachievedBAvaluesacrossvariousgroupsduringasinglerunforthe
testset,forthetwobaselinelosses(OEandCLA)vs.ourGAP.Notably,theBlackgroup,constitutingthestatistical
majorityinthedatasetasoutlinedinKennedyetal.[28],demonstratesthemaximumBAvaluesforthethreelosses.
Weshowthemaximumdifference(Max. Diff.) betweenthegroupsinTable1,tohighlighttheperformancegapwhen
theoptimizationmethoddoesnotalignwiththeintendedevaluation. Specifically,optimizingforoverallerror(OE)
failstoaccountforvariationsingroupperformance,resultinginthehighestdifferencevalues(Max. Diff. of21.9). In
contrast,boththeGAPandCLAapproachesincorporateconsiderationsofgroupperformancealongsideoverallerror,
leadingtosubstantiallylowerMax. Diff. comparedtoOE.Notably,giventhatGAPoptimizesforbalancederrorrates
acrossgroups,itexhibitsthesmallestdifference(Max. Diff. of5.5),indicatingleastdisparitiesacrossgroups.
WereporttheaverageBA(macro)scoreobtainedinallthreelossesinTable1,withGAPhavingthehighestvalue(Avg.
BA=81.97). Wehypothesizethatbyincorporatingtheadditionalgroupinformationinthelosswhilemodeltraining,
boththegroup-informedlosses(CLAandGAP)areabletofindbetterlocaloptimacomparedtoOE.TheBestBAisa
890 MaxDiff
21.9 MaxDiff
11.4 MaxDiff
85 5.5
80
75
70
65
60
OE CLA GAP
Groups
Asian Latinx NativeAmerican White
Black MiddleEastern PacificIslander Avg. BA
Figure3: VisualizationoftheBAvaluesachievedbyeachlossfunctionoverthe7demographicgroups. Themaximum
difference(Max. Diff.) betweenthemaximumandminimumBAachievedforeachlossacrossgroupsisalsoshown.
SeeTable1foradditionaldetailanddiscussion. GAPperformsbestwithlowestMaxDiff. of5.5.
groupperformancemeasureindicatinghowmanyamongstthe7groupsareperformingbestacrossthethreelosses. For
thismeasure,weobserveOEtohavethehighestgroupBAvaluesfor2groups(Black,MiddleEastern),whileGAP
performsbestforrestofthefivegroups. ThisalsoemphasizesthefactthatGAPdoesnotprioritizetheperformanceof
onegroupoverothersinitsoptimizationcriteria,therebybeingthebestperforminglossacrossthegroups.
Tofurtherhighlightperformancedisparitiesbetweendemographicgroupsinourtarget-groupdetectionsetting,we
presentFig. 4. ThisfiguredisplaysthepairwiseabsolutedifferencesinevaluatedBalancedAccuracy(BA)across
variousdemographicgroups(|left-bottom|). Notably, aseachgroupisinherentlyequivalenttoitself, alldiagonal
entriesarenaturally0.0. Highervaluesintheheatmapindicatetheclassifier’sbiastowardsonegroupcomparedto
another. Throughthecolorgradientintheheatmap,weobserveconsistentpatternsofunequalgroupperformance,
particularlyevidentintheoptimizationforoverallerrorrates(OE).Thisillustratesthatsolelyoptimizingforoverall
performancemayresultindisproportionateandinequitableperformancesacrosstheinternalgroupswithinthedataset.
Apartfromthe(Black,NativeAmerican)pairwhichhasaMax. Diff. of21.9,weseeothergrouppairsaswellwith
awiderangeofperformancedisparity,whengroupindicatorsaren’tconsideredinOE.Twokeyobservationscanbe
drawnfromthefigure:a)TheBlackgroupbeingthestatisticalmajorityhasadominantperformancegapovertheNative
Americangroupbeingoneofthestatisticalminorities. b)Evenforgrouppairswithsimilarstatisticalpopulation,for
e.g.the(MiddleEastern,White)pair,therecanbeperformancedisparities(BAgapof9.9)becauseonegroupmightbe
simplyeasiertoclassifythantheother. CLA,whichoptimizesforFNR,hasimprovedperformanceoverOE,however,
sinceit’soptimizationcriteria(minimizingfalsenegatives)doesnotalignwithoutintendedevaluation(havingsimilar
performanceacrossgroups)itsheatmapliesin-betweenthatofOEandGAP.
Incontrast,ourGAPloss,whichisexplicitlydesignedtoachievesimilar(balanced)performanceacrossgroupswhile
optimizingoverallperformance,showssubstantiallyfewerextremesingroupperformancegaps. Theheatmapreveals
smoother transitions between groups, indicating a more equitable distribution of the performance of the classifier.
Moreover,theextremevaluesofMaximumDifference(Max. Diff.) presentedinTable1arereflectedasoutliersin
theseheatmaps,correspondingtospecificgrouppairs.
9
)AB(
ycaruccA
decnalaBAsian 0.0 Asian 0.0 Asian 0.0 20.0
Black 6.6 0.0 Black 2.8 0.0 Black 0.7 0.0 17.5
15.0
Latinx 0.8 5.8 0.0 Latinx 0.8 3.7 0.0 Latinx 0.3 0.4 0.0
OE CLA GAP
12.5
EM asid ted rl ne 4.6 2.0 3.8 0.0 EM asid ted rl ne 2.1 0.7 2.9 0.0 EM asid ted rl ne 0.2 0.4 0.1 0.0
10.0
AmN ea rit ci av ne 15.3 21.9 16.1 19.9 0.0 AmN ea rit ci av ne 8.6 11.4 7.8 10.7 0.0 AmN ea rit ci av ne 4.2 4.9 4.5 4.5 0.0 7.5
IslP aa nc dif eic r 12.4 19.0 13.2 17.0 2.9 0.0 IslP aa nc dif eic r 7.6 10.4 6.8 9.7 1.0 0.0 IslP aa nc dif eic r 4.9 5.5 5.2 5.1 0.6 0.0 5.0
2.5
White 5.3 11.9 6.1 9.9 10.0 7.1 0.0 White 2.1 4.9 1.2 4.2 6.5 5.5 0.0 White 0.6 1.3 0.9 0.8 3.6 4.3 0.0
0.0
Asian Black Latinx Middle Native Pacific White Asian Black Latinx Middle Native Pacific White Asian Black Latinx Middle Native Pacific White
EasternAmericanIslander EasternAmericanIslander EasternAmericanIslander
Figure4: HeatmapofpairwiseabsolutedifferenceofBAacrossgroupsintestsetasanindicatorforbiasanddisparate
impact. OEhasthehighestperformancegap(MaxDiff=21.9)acrossgroupsasindicatedbytheextremesofcolor,not
onlyacrossonegroup-pairbutconsistentlyacrossmultiplegrouppairs. GAPhastheleastspreadinpairwiseerror
values(MaxDiff=5.5),evidentfromtheflatnessofcolor,indicatingleastdisparateimpactacrossgroups.
OE CLA GAP
HammingLoss(HL)%(↓) 7.65 12.10 6.85
Table2: HLvaluesacrossdifferentlossesfortestdata. Lowervaluesarebetter. GAPoptimizesforjointlyoverTPR
andTNR,therebyachievinglowestvalues,indicatingbetterclassifierperformance.
WepresenttheHL(Eq.12)valuesinTable2asasummarystatisticinoutmulti-labelclassificationsetup.TheHLmetric
quantifiestheaveragefractionofmisclassifiedlabels,withlowerHLvaluesindicatingenhancedclassifierperformance.
WhiletheCLAlossprioritizesminimizingFNR,whichinherentlyinvolvesasymmetry,theremaybeinstanceswhere
itdisproportionatelyoptimizesforthisaspectattheexpenseofotherperformancemetrics. Consequently,CLAmay
exhibitpoorerHLperformancecomparedtoOEloss. Incontrast,theGAPlossmaintainssymmetry,resultingina
balanced trade-offwhile jointly minimizing TPR and TNR. As a result, GAP consistently achieves the lowest HL
values,indicativeofsuperiorclassifierperformance.
Loss Prc (↑) Rec (↑) F1 (↑)
macro macro macro
OE 0.7083 0.5808 0.6383
CLA 0.5418 0.7143 0.6162
GAP 0.7854 0.6837 0.7310
Table3: Summarystatisticsofotherevaluationmeasures. SinceCLAstrictlyoptimizesforminimizingFNR,itindeed
achievesthehighestRecall(1-FNR). However,thiscomesatthecostoflosingoutonPrecision. SinceGAPjointly
minimizesbothTPRandTNR,itperformsbestbothintermsofPrecisionandF1scoresacrossthreelosses.
Table3presentssummarystatisticsofevaluationmeasureslikePrecision,RecallandF1,inourmulti-labelclassification
setupatthemacrolevel. TheCLAapproach,characterizedbyitsemphasisonminimizingtheFalseNegativeRate
(FNR),inherentlyyieldsthehighestRecall,however,thisoptimizationstrategycomesattheexpenseofPrecisionand
F1,bothbeinglowerthanOE.OurGAPloss,designedtojointlyminimizeTruePositiveRate(TPR)andTrueNegative
Rate(TNR),emergesastheoptimalperformerintermsofbothPrecisionandF1scoreacrosstheevaluatedlosses.
5.3 RuntimePerformance
ThenumbersshowninTable4areoverthetrainingdatasetof36kposts,wherewereporttheaveragetimeperepoch,
numberofepochstillconvergence,totalruntime,andtheextratime(∆)forlossescomparedtoOE.
SinceOEinAlg. 1isweightedBinaryCrossEntropy(wBCE),ittakestheleastamountoftimeperepochandalso
numberofepochtoconverge. GAPinAlg. 2takesallthestepsofAlg. 1forcomputingtheoveralllossinaddition
tocalculatingGC lossesandfinallythebalancedloss. TherebyGAPtakesadditionalcomputetimeforsolvingits
2
10Avg. Time Epochstill Runtime ∆(s)
PerEpoch(s) Convergence Total(s) w.r.t.OE
OE 154 21 3234 0
CLA 158 41 6478 3244
GAP 163 27 4401 1167
Table4: LossRuntimeAnalysis. WhileOEtakestheleasttime,GAPgainsmoreinoptimizingperformanceacross
groupsforanextraof∼9sperepoch.ThesmoothnessofGAPloss(27epoch)alsoallowsfasterconvergencecompared
toCLA(41epoch).
intendedoptimization. ThesameargumentholdstrueforCLAandADVaswell,sinceallofthemarevariantsofthe
SingleObjectiveOptimizationformatinEq. 1.
AlthoughGAPdoestheGC extracomputation,hencetheextraruntime(∆=1167s),itisnotthatsignificant(extra
2
9sperepoch)comparedtoOE,whilegainingmuchmoreintermsofoptimizationimprovement. WhileOEandGAP
operateonsmoothlosses(Eq. 6,4)theirconvergenceepochisrelativelyfast(∼21,∼27). CLAusesa1-normloss(Eq.
8),hencetheempiricallosssurfaceisnotassmoothastheprevioustwo. Assuch,itisobservablethatCLAonaverage
takesmoreepochs(∼41)toconvergewithahigher∆.
6 AnalysisandDiscussions
DifferentiableMeasures. Whileimportantfairnessmeasureshavebeenproposedintheliterature,cateringtoevaluate
differentscenarios,manylackanequivalentdifferentiableloss,makingthesemeasuresdifficulttooptimize. Model
trainingwithapproximatelossfunctionsmightleadtopotentialmetricdivergence[40,38]betweenoptimizationcriteria
usedintrainingvs.evaluationmeasureofinterest. “Nomatterwhatmeasureischosenforoptimization,aninexact
metricnecessarilyleadstoadivergencebetweenthegoalandthemetricinthetail.” [34]. Continuingformulationof
equivalentdifferentiablelossfunctionsw.r.t.otherimportantfairnessmeasurescouldyieldbetterperformanceforthem.
Goodhart’sLawandOver-optimization. Goodhart’sLawstatesthat“Whenameasurebecomesatarget,itceases
tobeagoodmeasure”[19]. ThomasandUminsky[55]detailproblemsarisingoverly-narrowfocusonmetricsinthe
broaderfieldofAI.Fairnessmeasuresarenotanexceptiontothischallenge. Over-optimizingforanyonemetricin
isolationrisksdegradingperformanceonothers. Forexample,Table3showsthatCLA’soptimizationforFNRleadsto
largedropsinPrecisionandF1,whereitunderperformsw.r.t.tobothOEandGAP.
AsFriedleretal.[17]andothershavenoted,differentworldviewsleadtoconflictingdefinitionsoffairnessthatare
mutuallyincompatible. Sinceonecannothaveitall,specificfairnessmeasuresmustbeselected(suitabletothegiven
task,context,andstakeholdersathand). Inthiswork,giventhenatureofthesymmetricerrors,weoptimizeamodelto
providebalancedAccuracyParity(AP)acrossdemographicgroups[61]viaourGAPlossfunction.
Balanced Measure vs. Overall Performance. As its name reflects, OE optimizes for cross-entropy (wBCE); it
does not consider group (sub-population) performance. Overall accuracy will be driven by several factors. First,
under-represented groups may suffer at the cost of benefiting the over-represented groups (i.e. group prevalance).
Second,evenwhengroupsarebalanced,somegroupsmaybeintrinsicallymoredifficulttomodelforagiventask,and
thussacrificedinoptimizationtobenefitothergroups. Sincewetraindirectlyonthedata(noover-/under-sampling),
usingthetrainingobjectivetoachieveAPacrossgroups,weareabletoaccommodatebothofthethecasesabove.
Readersarereferredto2-groupsetting: Fore.g.Asianvs.BlackandWhitevs.Latinxgroup-pairsinAppendixCasan
illustrationofbothcases.
ImprovedOverallPerformancewithBalancing. Forthe7-groupsettinginTable1,wenoticethatbyoptimizing
for group-related errors alongside overall error (OE), both GAP and CLA driven classifiers achieve better overall
performance(intermsofAvg. BA),aswellasachievingtheirintendedgroup-specificobjective. Thisobservationgoes
abitbeyondtraditionalMLwherethenatureofSingleObjectiveOptimization(Eq. 1)forcesoneobjectivetobebetter
attheexpenseoftheotherobjective,inabsenceofanyalternatedominatedsolutionsets[36]. Giventhatourproblem
setupisMulti-Labelclassification(andcorrespondinglythearchitecturalsetupisaseriesofone-vsrestclassifiernodes),
wehypothesizethatthegroupindicatorgivesanextrafeaturedimensionfortheclassifiertoconsider,boostingitto
learnsomethingmoreaboutthedatathanitwouldhavewithoutthegrouplabel. Byconsideringthegroup-associated
11terms,bothlossfunctionshaveamodifiedsurfacecomparedtoOE,allowingconvergencetoabetteroptima. Wesee
thispatternemerginginsomeofthe2-groupsetting: Fore.g.theLatinxvs.MiddleEasterngroup-pairinAppendixC.
ModelMultiplicity[4]highlightstheabilityofatasktohavevariabilityinthepredictionsgeneratedbydifferentmodels,
althoughtheyperformwithequalaccuracy. Sucheffectsariseduetofactorslikedataimbalance,inherentbiasesetc. A
simplecaseinourtarget-groupdetectionsettingcouldhavethreeclassifiers—trainedwiththreelosses(OE,CLAand
ourGAP)—performingequallywellintermsofoverallaccuracy,yetdifferingwidelyingroup-accuracyperformance.
Insuchascenario,APprovidesvaluableinsightasafairnessmeasurebyhighlightingtheamountofdisparateimpact
acrossgroups,withGAPhavingtheleastpairwiseperformancegapacrossgroups,amongstthethreelosses.
TaskAgnosticMeasure. Whileinthisworkweexplicitlyfocusaroundfairtarget-groupdetection,ourproposed
measureGAPismodel,task,anddatasetagnostici.e.itisdesignedtopushforequalaccuracynumbersacrossgroups
witharbitrarilydefinedgroups. Thus,balancingbetweenaccuracyvs.fairnessisnotexclusivetothetaskofToxic
LanguageDetection,andcanbeextendedtootherproblems,datasets,andmodels. Itcanalsobeusedtoforclassifiers
involvinggroups,setsorcategories.
ExploringFairnesstaskswithSymmetricErrors. Byrecognizingandincorporatingsymmetricerror(i.e.typeIand
typeIIerrorsareequallyharmful)considerationsintofairnesstasks,wenotonlyenhancethefairnessofourtarget-group
detectionmodelbutalsoopenavenuestoexplorereal-lifescenariosaddressingsimilarscenarios,challengesandneeds
inotherdomains. Byacknowledgingandaddressingthesymmetricnatureoferrorsacrossdifferentgroups,wecan
achieveabalancedperspectiveonfairnessandmoreequitableoutcomesinalgorithmicdecision-makingprocesses.
AuthorDemographicsvs.TargetDemographics. Whileauthordemographics[5]focusesonidentifyinggrouptags
aboutthepost’sauthor,identifyingTargetDemographicsinvolvesdetermininggrouptagsofpostwhenitsdirected
towardsspecificgroupsorcommunities[30,14]. Inscenariosinvolvingsensitivetopicsorpotentiallytoxiclanguage,
suchgroupidentificationbecomescrucial. Fore.g.apostcontainingraciallychargedlanguagemaybeindicativeof
targetingaparticulardemographicgroupasaslur. However,theinterpretationofsuchlanguagemayvarydependingon
thecontextoftheinteraction. Ifboththeauthorandthetargetbelongtothesamedemographicgroups,theuseofsuch
languagemaybeconsideredasafriendlybanterorcolloquialcommunicationwithinthatgrouponly. Conversely,ifthe
authordoesnotbelongtothetargetedgroup,thesamelanguagemaybeconsideredmorelikelyastoxic,reflecting
potentialdiscriminatorybehavior. Thus,bothauthorandtargetdemographicsneedtobeconsideredjointlyinNLP
modelingtocombattoxiclanguage.
Target group identification and Large Language Models. The task of fair target group detection can also be
relevantinthecontextoftraininganddeployingLargeLanguageModels(LLMs). Existingstudieshavefoundthat
LLMscontainbiaswithrespecttoprotectedcharacteristicssuchasgenderandrace[42,31]. Explicitlyincorporating
targetgroupdetectionduringtrainingandfine-tuningviareinforcementlearningfromhumanfeedback(RLHF)isa
promisingdirectionforreducingLLMbias.
7 Conclusion
Inthisworkwemadecontributionstowardsalgorithmicfairnessbydesigningadifferentiablelossoptimizer,with
aspecificfocusonprovidingfairprotectionstoallpotentiallytargetedgroupsinsocialmediaposts. Ournovelloss
function Group Accuracy Parity (GAP) successfully achieves balanced detection accuracy across groups, thereby
mitigatingrisksofdisparateimpact. GAPisdifferentiableandprovidesdirectmeansofoptimizingdescent-based
modelswhilemaintainingalignmentwiththeAccuracyParity(AP)evaluationmeasure,thusavoidingmetricdivergence.
Furthermore,weproposeanextensionofGAPtoaccommodatemulti-groupsettings,increasingthemetricimpactand
coverage. EmpiricalvalidationofGAPconfirmsourtheoreticalclaimthatoptimizingforGAPachievesthebestAP
scores,comparedtootherlosses.
Avarietyofimportantdirectionsremainforfuturework. Inthecontextoftoxiclanguagedetectionpipelines,onecould
exploretheimpactoffairtarget-groupdetectionondownstreamtasks,suchasconversationalassistants,recommendation
systems,emotionandsentimentdetectionsystems. Inaddition,thetaskoftarget-groupdetectioncouldbeextendedto
includeallparticipantsinthediscussionorsocialmediathread. Thiswouldprovideadditionalcontexttoresearchers
andmachinelearningmodelsandwillallowforamorefine-grainedimplementationoffairnesscriteria.
Aswenotedattheoutset,algorithmicfairnesstasksthathavereceivedthemostattentioninthepastyearsaretypically
associatedwiththeallocationofgoodsorburdens(e.g.collegeadmissionisagood,anddenyingbailisaburden).
However,forscenariosthatdonothaveaconceptof’positive’and’negative’labels(asconsideredhere),thegoal
ofprovidingequalprotectiontoallgroupsleadstoconsideringerrorsassymmetric. WebelieveGAPthusstandsto
12benefitavarietyofotherdomainswithsymmetricerrorsinwhichAPcouldnowbeoptimized(forneuralnetworksor
othermodelsofinterest).
References
[1] Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. Machine bias. In Ethics of Data and
Analytics.AuerbachPublications,254–264.
[2] RachelKEBellamy,KuntalDey,MichaelHind,SamuelCHoffman,StephanieHoude,KalapriyaKannan,Pranay
Lohia,JacquelynMartino,SameepMehta,AleksandraMojsilovic,etal.2018. AIFairness360: anextensible
toolkitfordetecting,understanding,andmitigatingunwantedalgorithmicbias.arXivpreprint. arXivpreprint
arXiv:1810.01943(2018).
[3] RichardBerk,HodaHeidari,ShahinJabbari,MichaelKearns,andAaronRoth.2021. Fairnessincriminaljustice
riskassessments: Thestateoftheart. SociologicalMethods&Research50,1(2021),3–44.
[4] EmilyBlack,ManishRaghavan,andSolonBarocas.2022. Modelmultiplicity: Opportunities,concerns,and
solutions.InProceedingsofthe2022ACMConferenceonFairness,Accountability,andTransparency.850–863.
[5] SuLinBlodgett,JohnnyWei,andBrendanO’Connor.2017. Adatasetandclassifierforrecognizingsocialmedia
english.InProceedingsofthe3rdWorkshoponNoisyUser-generatedText.56–61.
[6] StephenBoyd,StephenPBoyd,andLievenVandenberghe.2004. Convexoptimization. Cambridgeuniversity
press.
[7] FrançoisChollet.2015. keras. https://github.com/fchollet/keras.
[8] AlexandraChouldechova.2017. Fairpredictionwithdisparateimpact: Astudyofbiasinrecidivismprediction
instruments. BigData5,2(2017),153–163.
[9] SanjivDas,MicheleDonini,JasonGelman,KevinHaas,MilaHardt,JaredKatzman,KrishnaramKenthapadi,
Pedro Larroy, Pinar Yilmaz, and Muhammad Bilal Zafar. 2021. Fairness Measures for Machine Learning in
Finance. TheJournalofFinancialDataScience3,4(2021),33–64.
[10] ThomasDavidson,DebasmitaBhattacharya,andIngmarWeber.2019. Racialbiasinhatespeechandabusive
languagedetectiondatasets. arXivpreprintarXiv:1905.12516(2019).
[11] ThomasDavidson,DanaWarmsley,MichaelMacy,andIngmarWeber.2017. Automatedhatespeechdetection
andtheproblemofoffensivelanguage.InProceedingsoftheInternationalAAAIConferenceonWebandSocial
Media.
[12] WilliamDieterich,ChristinaMendoza,andTimBrennan.2016. COMPASriskscales: Demonstratingaccuracy
equityandpredictiveparity. NorthpointeInc7,4(2016).
[13] MichaelDEkstrand,AnubrataDass,RobinBurke,FernandoDiaz,etal.2022. FairnessinInformationAccess
Systems. FoundationsandTrends®inInformationRetrieval16,1-2(2022),1–177.
[14] HuggingFace.2022. ucberkeley-dlab/measuring-hate-speech. https://huggingface.co/datasets/
ucberkeley-dlab/measuring-hate-speech
[15] Paula Fortuna, Juan Soler, and Leo Wanner. 2020. Toxic, hateful, offensive or abusive? what are we really
classifying? anempiricalanalysisofhatespeechdatasets.InProceedingsoftheTwelfthLanguageResourcesand
EvaluationConference.6786–6794.
[16] Antigoni-MariaFounta,ConstantinosDjouvas,DespoinaChatzakou,IliasLeontiadis,JeremyBlackburn,Gianluca
Stringhini, AthenaVakali, MichaelSirivianos, andNicolasKourtellis.2018. Largescalecrowdsourcingand
characterizationofTwitterabusivebehavior. https://open.bu.edu/handle/2144/40119
[17] SorelleAFriedler,CarlosScheidegger,andSureshVenkatasubramanian.2021. The(im)possibilityoffairness:
Differentvaluesystemsrequiredifferentmechanismsforfairdecisionmaking. Commun.ACM 64,4(2021),
136–143.
[18] SorelleAFriedler,CarlosScheidegger,SureshVenkatasubramanian,SonamChoudhary,EvanPHamilton,and
DerekRoth.2019. Acomparativestudyoffairness-enhancinginterventionsinmachinelearning.InProceedings
oftheconferenceonfairness,accountability,andtransparency.329–338.
[19] CharlesAEGoodhart.1984. Problemsofmonetarymanagement: theUKexperience. Springer.
[20] Mitchell L Gordon, Michelle S Lam, Joon Sung Park, Kayur Patel, Jeff Hancock, Tatsunori Hashimoto, and
Michael S Bernstein. 2022. Jury learning: Integrating dissenting voices into machine learning models. In
Proceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems.1–19.
13[21] NiteshGoyal,IanDKivlichan,RachelRosen,andLucyVasserman.2022. Isyourtoxicitymytoxicity? exploring
theimpactofrateridentityontoxicityannotation. ProceedingsoftheACMonHuman-ComputerInteraction6,
CSCW2(2022),1–28.
[22] Soumyajit Gupta, Sooyong Lee, Maria De-Arteaga, and Matthew Lease. 2023. Same Same, But Different:
ConditionalMulti-TaskLearningforDemographic-SpecificToxicityDetection.InProceedingsoftheACMWeb
Conference2023.3689–3700.
[23] MoritzHardt,EricPrice,andNatiSrebro.2016. Equalityofopportunityinsupervisedlearning. Advancesin
neuralinformationprocessingsystems29(2016).
[24] HodaHeidari,MicheleLoi,KrishnaPGummadi,andAndreasKrause.2019.Amoralframeworkforunderstanding
fair ml through economic models of equality of opportunity. In Proceedings of the conference on fairness,
accountability,andtransparency.181–190.
[25] FranciscoHerrera,FranciscoCharte,AntonioJRivera,MaríaJDelJesus,FranciscoHerrera,FranciscoCharte,
AntonioJRivera,andMaríaJdelJesus.2016. Multilabelclassification. Springer.
[26] DanulaHettiachchi,IndigoHolcombe-James,StephanieLivingstone,AnjaleedeSilva,MatthewLease,FloraD.
Salim,andMarkSanderson.2023. HowCrowdWorkerFactorsInfluenceSubjectiveAnnotations: AStudyof
TaggingMisogynisticHateSpeechinTweets.InProceedingsofthe11thAAAIConferenceonHumanComputation
andCrowdsourcing(HCOMP).38–50.
[27] Lily Hu and Yiling Chen. 2018. Welfare and distributional impacts of fair classification. arXiv preprint
arXiv:1807.01134(2018).
[28] Chris J Kennedy, Geoff Bacon, Alexander Sahn, and Claudia von Vacano. 2020. Constructing interval vari-
ablesviafacetedRaschmeasurementandmultitaskdeeplearning: ahatespeechapplication. arXivpreprint
arXiv:2009.10277(2020).
[29] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980(2014).
[30] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani,
Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. 2021. Wilds: A benchmark of
in-the-wilddistributionshifts.InInternationalConferenceonMachineLearning.PMLR,5637–5664.
[31] Hadas Kotek, Rikker Dockum, and David Sun. 2023. Gender bias and stereotypes in Large Language Mod-
els. In Proceedings of The ACM Collective Intelligence Conference (<conf-loc>, <city>Delft</city>, <coun-
try>Netherlands</country>,</conf-loc>)(CI’23).AssociationforComputingMachinery,NewYork,NY,USA,
12–24. https://doi.org/10.1145/3582269.3615599
[32] DeepakKumar,PatrickGageKelley,SunnyConsolvo,JoshuaMason,ElieBursztein,ZakirDurumeric,Kurt
Thomas, and Michael Bailey. 2021. Designing toxic content classification for a diversity of perspectives. In
SeventeenthSymposiumonUsablePrivacyandSecurity(SOUPS2021).299–318.
[33] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár. 2017. Focal loss for dense object
detection.InProceedingsoftheIEEEinternationalconferenceoncomputervision.2980–2988.
[34] David Manheim and Scott Garrabrant. 2018. Categorizing variants of Goodhart’s Law. arXiv preprint
arXiv:1803.04585(2018).
[35] Anqi Mao, Mehryar Mohri, and Yutao Zhong. 2023. Cross-entropy loss functions: Theoretical analysis and
applications.InInternationalConferenceonMachineLearning.PMLR,23803–23828.
[36] RTimothyMarlerandJasbirSArora.2004. Surveyofmulti-objectiveoptimizationmethodsforengineering.
Structuralandmultidisciplinaryoptimization26,6(2004),369–395.
[37] AndrewKachitesMcCallum.1999.Multi-labeltextclassificationwithamixturemodeltrainedbyEM.InAAAI’99
workshopontextlearning.
[38] DonaldMetzlerandW.B˜ruceCroft.2007. Linearfeature-basedmodelsforinformationretrieval. Information
Retrieval10,3(2007),257–274.
[39] ShiraMitchell,EricPotash,SolonBarocas,AlexanderD’Amour,andKristianLum.2021. Algorithmicfairness:
Choices,assumptions,anddefinitions. AnnualReviewofStatisticsandItsApplication8(2021),141–163.
[40] WilliamMorgan,WarrenGreiff,andJohnHenderson.2004. Directmaximizationofaverageprecisionbyhill-
climbing,withacomparisontoamaximumentropyapproach.InProceedingsofHLT-NAACL2004: ShortPapers.
93–96.
14[41] Arvind Narayanan. 2018. 21 Fairness Definitions and Their Politics: A Tutorial. In Proceedings
of the ACM FAccT Conference on Fairness, Accountability and Transparency. Association for Com-
puting Machinery, New York, NY, USA. https://shubhamjain0594.github.io/post/
tlds-arvind-fairness-definitions/.
[42] RobertoNavigli,SimoneConia,andBjörnRoss.2023. BiasesinLargeLanguageModels: Origins,Inventory,
andDiscussion. 15,2,Article10(jun2023),21pages. https://doi.org/10.1145/3597307
[43] HarrieOosterhuisandMaartendeRijke.2018. Differentiableunbiasedonlinelearningtorank.InProceedingsof
the27thACMinternationalconferenceoninformationandknowledgemanagement.1293–1302.
[44] Ji Ho Park, Jamin Shin, and Pascale Fung. 2018. Reducing Gender Bias in Abusive Language Detection. In
Proceedingsofthe2018ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.AssociationforCom-
putationalLinguistics,Brussels,Belgium,2799–2804. https://doi.org/10.18653/v1/D18-1302
[45] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R.
Weiss,V.Dubourg,J.Vanderplas,A.Passos,D.Cournapeau,M.Brucher,M.Perrot,andE.Duchesnay.2011.
Scikit-learn: MachineLearninginPython. JournalofMachineLearningResearch12(2011),2825–2830.
[46] Fabio Poletto, Valerio Basile, Manuela Sanguinetti, Cristina Bosco, and Viviana Patti. 2021. Resources and
benchmarkcorporaforhatespeechdetection: asystematicreview. LanguageResourcesandEvaluation55,2
(2021),477–523.
[47] MdMustafizurRahman,DineshBalakrishnan,DhirajMurthy,MucahidKutlu,andMatthewLease.2021. An
InformationRetrievalApproachtoBuildingDatasetsforHateSpeechDetection.InProceedingsoftheThirty-fifth
ConferenceonNeuralInformationProcessingSystems(NeurIPS):DatasetsandBenchmarksTrack.
[48] PaulRöttger,BertieVidgen,DongNguyen,ZeerakWaseem,HelenMargetts,andJanetPierrehumbert.2021.
HateCheck: FunctionalTestsforHateSpeechDetectionModels.InProceedingsofthe59thAnnualMeetingof
theAssociationforComputationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguage
Processing (Volume 1: Long Papers). Association for Computational Linguistics, Online, 41–58. https:
//doi.org/10.18653/v1/2021.acl-long.4
[49] PratikSSachdeva,RenataBarreto,ClaudiavonVacano,andChrisJKennedy.2022. Assessingannotatoridentity
sensitivity via item response theory: A case study in a hate speech corpus. In Proceedings of the 2022 ACM
ConferenceonFairness,Accountability,andTransparency.1585–1603.
[50] VictorSanh, LysandreDebut, JulienChaumond, andThomasWolf.2019. DistilBERT,adistilledversionof
BERT:smaller,faster,cheaperandlighter. arXivpreprintarXiv:1910.01108(2019).
[51] MaartenSap,DallasCard,SaadiaGabriel,YejinChoi,andNoahASmith.2019. Theriskofracialbiasinhate
speechdetection.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics.
1668–1678.
[52] Anna Schmidt and Michael Wiegand. 2017. A Survey on Hate Speech Detection using Natural Language
Processing.InProceedingsoftheFifthInternationalWorkshoponNaturalLanguageProcessingforSocialMedia.
AssociationforComputationalLinguistics, Valencia, Spain, 1–10. https://doi.org/10.18653/v1/
W17-1101
[53] AiliShen,XudongHan,TrevorCohn,TimothyBaldwin,andLeaFrermann.2022. OptimisingEqualOpportunity
Fairness in Model Training. In Proceedings of the 2022 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies. Association for Computational
Linguistics,Seattle,UnitedStates,4073–4084. https://doi.org/10.18653/v1/2022.naacl-main.
299
[54] RobinSwezey,AdityaGrover,BrunoCharron,andStefanoErmon.2021. Pirank: Scalablelearningtorankvia
differentiablesorting. AdvancesinNeuralInformationProcessingSystems34(2021),21644–21654.
[55] RachelLThomasandDavidUminsky.2022. RelianceonmetricsisafundamentalchallengeforAI. Patterns3,5
(2022),100476.
[56] BertieVidgenandLeonDerczynski.2020. Directionsinabusivelanguagetrainingdata,asystematicreview:
Garbagein,garbageout. Plosone15,12(2020),e0243300.
[57] ZeerakWaseem.2016. AreYouaRacistorAmISeeingThings? AnnotatorInfluenceonHateSpeechDetection
onTwitter.InProceedingsoftheFirstWorkshoponNLPandComputationalSocialScience.Associationfor
ComputationalLinguistics,Austin,Texas,138–142. https://doi.org/10.18653/v1/W16-5618
[58] ZeerakWaseemandDirkHovy.2016. HatefulSymbolsorHatefulPeople? PredictiveFeaturesforHateSpeech
DetectiononTwitter.InProceedingsoftheNAACLStudentResearchWorkshop.AssociationforComputational
Linguistics,SanDiego,California,88–93. https://doi.org/10.18653/v1/N16-2013
15[59] GuoqiangWuandJunZhu.2020. Multi-labelclassification: doHamminglossandsubsetaccuracyreallyconflict
witheachother? AdvancesinNeuralInformationProcessingSystems33(2020),3130–3140.
[60] MengzhouXia,AnjalieField,andYuliaTsvetkov.2020. DemotingRacialBiasinHateSpeechDetection.In
ProceedingsoftheEighthInternationalWorkshoponNaturalLanguageProcessingforSocialMedia.Association
forComputationalLinguistics,Online,7–14. https://doi.org/10.18653/v1/2020.socialnlp-1.
2
[61] HanZhao,AmandaCoston,TameemAdel,andGeoffreyJGordon.2020. ConditionalLearningofFairRepresen-
tations.In8thInternationalConferenceonLearningRepresentations,ICLR2020.
A MappingofGAPfromCE
Cross-Entropy(CE)lossiscommonlyusedasadifferntiableandsmoothlossfunctioninclassificationtasksandis
designedtomeasurethedifferencebetweenprobabilitydistributionpredictedbythemodel(yˆ)andthetruedistribution
(y)ofthedata. Althoughnotastrictone-to-onecorrespondence,itisgenerallyobservedthatminimizingCEleads
tominimizingOverallError(OE),therebymaximizingOverallAccuracy(OA),duetoCEprovidingnon-asymptotic
guarantees. Whileasymptoticerrorsprovideanexactboundatinfinity,CEbeingnon-asymptoticsimplyupperbounds
ontheestimationerroroftheactualloss[35],theoreticalanalysisofwhichhelpsintighteningthegap.
(cid:88)
CE(y,yˆ)= y(c)log(yˆ(c))
c∈class
CEcanbecomputedovertheentiredataorindependentlyacrosseachgroup(g ∈ G). Forbalancedclassification
accuracyacrossgroups,e.g.demographicinformationofpostsubject,weneedtoensurethatthecrossentropyforeach
group(CE(g))roughlyequatesascloselyaspossible. Hence,fromanoptimizationstandpoint,wefirstcalculatetheCE
acrosseachgroup,thenminimizethedifferenceacrossthemunderthetermpairwise-grouperrorCE . Thesquared
pair
2-normformulationinCE ensuresthatallpairwise-groupdifferencesarepositiveandthelosssurfaceissmooth.
pair
allowingforabetterdescenttrajectory.
OE =CE(y,yˆ)
CE =∥CE(g =1)−CE(g =0)∥2
pair 2
FinallyframeitasaSingleObjectiveOptimizationproblembycombiningtheoverallerrorOE andCE witha
pair
regularizationtermλtoformtheGAPlossfunction. TheGAPlossequatestooverallcrossentropyloss(OE)ifand
onlyifbothCE(g)errorsareequalacrossthegroups.
GAP =OE+λ·CE
pair
GAP =OE+λ∥ CE(g =1) − CE(g =0) ∥2
2
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
errGroup1(g=1) errGroup0(g=0)
TheGAPlossisdifferentiablesincealltheCE-relatedtermsassociatedwithitaredifferentiable. TheGAPformulation
isgeneralizabletodifferentvariantsofaccuracy. Asthesituationdemands,onemightswitchoutoneweightedvariant
of accuracy for another with an equivalent change in corresponding entropy loss. For our experiments we use the
weightedbinarycrossentropyvariant.
Ifthemeasureofinterestinbalancedaccuracy(BA),wesuggestreplacingtheCEtermswithwBCE.WeightedBinary
CrossEntropy(wBCE)re-weightstheerrorfortheclasslabelsproportionaltotheirinversefrequencyinthedata. Since
mostreal-worlddatasetsoftenhavelabelimbalance,wBCEaimstopenalizebothlabels(1sand0s)equally. Thus,
minimizingwBCEleadstomaximizingbalancedaccuracy(BA),abettermeasurethanaccuracy,inpresenceoflabel
imbalance.
1 (cid:88)
wBCE =− w(y)·ylog(yˆ)+w(1−y)·(1−y)log(1−yˆ)
N
N
GAP =wBCE +λ∥wBCE(g =1)−wBCE(g =0)∥2
overall 2
16ExtensionofGAPbeyondBinaryGroups. Itissometimesthecasethatapostmaytargetmultiplegroups,thuswe
needaGAPvariantthataccommodatesamulti-groupsetting. TheCE termdefinedbeforecanbeextendedfroma
pair
binarysetting(2-groups)toamulti-groupsetting(G-groups)byconsideringallGC possiblecombinationofpairwise
2
errorsofdistinctgrouppairs(i,j)∈[G],i̸=j withinthedatasetofgroupcardinalityG.
(cid:88)
CE = ∥CE(g =i)−CE(g =j)∥2
pairs 2
i,j∈[G],i̸=j
Thisupdatedversionallowsustoaccountforscenarioswhereapostcanpotentiallytargetmultiplegroup(s).
GAP =OE+λ·CE
pairs
(cid:88)
GAP =OE+λ ∥CE(g =i)−CE(g =j)∥2
2
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
i,j∈[G],i̸=j
errGroupi(g=i) errGroupj(g=j)
OnecanmakesimilarsubstitutionsforBCEorwBCEinplaceofCEinthemulti-groupformulationofGAP,depending
ontheevaluationmeasureofinterestandproblemsetup.
B ExperimentalDetails
B.1 Setup
ExperimentsuseaNvidia2060RTXSuper8GBGPU,IntelCorei7-9700F3.0GHz8-coreCPUand16GBDDR4
memory. WeusetheKeras[7]libraryonaTensorflow2.0backendwithPython3.7totrainthenetworksinthispaper.
Foroptimization,weuseAdaMax[29]withparameters(lr=0.001)and1000stepsperepoch.
B.2 DataPre-processing
Fromthesetofallposts,wefilteroutonesthattargetatleastoneormoredemographicgroup(s),resultinginadataset
sizeof44,816posts. Fromthereweperforma80%-20%splitfortrainingvs.testingdata,forallclustersizesthat
allowedforaSkLearn’s[45]stratifiedsamplingfollowingthelabelsplitratio. Thisresultedinatrainsetofsize36,412
postsandtestsetofsize8,404posts.
B.3 ClassBalancingStrategy
Inourmulti-labelclassificationsetup,wehavebinaryclasslabelsforeachgroup. 1indicatesthataposttargetsthat
specificgroup,0otherwise. Ascommoninmostreal-worlddatasets,theDLabdatasethasaclasslabelimbalance
acrossmostgroups,withmajorityofthelabelsbeing0s. Toaccountforthis,weperformaclassbalancingstrategyto
assignmoreweighttothetargetedexamplesduringmodeltraining. WeuseaweightedversionofBinaryCrossEntropy
(BCE)measurethatre-weightstheerrorforthebinaryclassesproportionaltotheirinversefrequencyinthedata[33].
WeuseSKLearn’s[45]compute_class_weights=‘balanced’flagforextractingweights(w ,w )forclasses
targeted non-targeted
ineachgroup,givenas3:
n_samples/(n_classes×bincount(y)) (16)
B.4 ModelTraining
Forourneuralmodel,weconsiderafixedarchitectureinFig. 5acrossthethreelosses. WeuseDistilBERT(Sanhet
al. 2019)representationlayertoextractnumericalfeaturesfromposts. Thisisfollowedbylayersofdenseneuron
connectionswithreluactivationandaddedbiases. Thedenselayersareof(512,128,64)neuronsrespectively,witha
dropoutrateof0.1,topreventmodeloverfitting. ThelayersendinG(7fortheall-groupcase)classificationnodes,
eachwithsigmoidactivation,nobiasesand0.5classificationthreshold. Forexperiments,wefreezetheweightsofthe
DistilBERTlayer,hencetheonlytrainableparametersarethenodesinthedenselayersandthefinalclassificationlayer.
WealsosetupanEarlyStoppingcriteriaincasethewithamin_deltaof1e-4andpatienceof5.
3https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.
compute_class_weight.html
17Figure5: OurMulti-LabelArchitecture
B.5 TrainingLossTrajectory
WeshowthelosstrajectoryoverthetrainingdatainFig. 6. SinceweareusingAdamax,weachievefastdropsinthe
GAPlossinEq. 4. Thelossstabilizesaround23epochsandthendoessomeadditionalepochsbeforeselfterminating
asperthepatiencelimitset.
Training Loss Trajectory
101
100
10 1
0 5 10 15 20 25 30
Epochs
Figure6: TrainingLosstrajectoryforourGAPlossviaAdaMaxgradientdescentoptimizer.
B.6 VarianceacrossRuns
Table1(mainmaterial)showsthevarianceofMaxDiff. andAvg. BAoverfiverunsofthemodelusingthethree
differentlosses. WeobservethatOEhasthemostvariancewhileGAPhastheleastvarianceacrossruns. Notethatall
thefiverunswereindependenti.e.theirnetworkweightswererandomlyinitializedatstartofeachtrainingrun.
18
ssoL
PAGC PairwiseGroupClassifiers
SinceADVcannotaccommodatemultiplegroups,wewereunabletoreportADVnumbersforthe7-groupcasein
themainmaterial. Wepresenttheperformanceacrossallfourlosses(OE,CLA,ADVandourGAP)forsomeofthe
2-groupcasetoshowdifferentscenariosandperformances. Bestvaluesarebolded(higherforBA,lowerforDiff.).
BalancedAccuracy(BA)
Loss Latinx MiddleEastern Avg. BA Diff.
OE 90.98 83.67 87.33 7.31
CLA 91.52 88.73 90.12 2.79
ADV 91.04 84.20 87.62 6.84
GAP 92.34 91.79 92.06 0.55
Table5: Optimizingacrossgroupsresultsinimprovingoverallerror,indicatingthatthegrouplabelprovidesanextra
dimensionforthelosstostabilizeatabetterlocaloptima.
BalancedAccuracy(BA)
Loss Asian Black Avg. BA Diff.
OE 86.59 92.32 89.46 5.73
CLA 87.02 92.22 89.62 5.20
ADV 87.49 92.10 89.79 4.61
GAP 89.65 90.82 90.23 1.17
Table6: Performancevariesacrossgroupsduetotheirpopulationsize,wherethestatisticallymajorgroupdominates.
BalancedAccuracy(BA)
Loss White Latinx Avg. BA Diff.
OE 88.89 82.19 85.54 6.70
CLA 88.20 85.55 86.87 2.65
ADV 88.18 82.19 85.18 5.99
GAP 88.36 86.23 87.29 2.13
Table7: Groupshavesimilarpopulation,butperformancevariesduetoonegroupbeingmoredifficulttomodel.
ADV [60] is an approximate adversarial loss for balancing FPR rates across groups. We notice similar issues of
convergenceinstabilityastheyobservedinXiaetal.[60]aswell. Consequently,letADVrunforafixedepochsand
reportthebestBAvalueachievedoveriterations.
19