[
    {
        "title": "Does Refusal Training in LLMs Generalize to the Past Tense?",
        "authors": "Maksym AndriushchenkoNicolas Flammarion",
        "links": "http://arxiv.org/abs/2407.11969v1",
        "entry_id": "http://arxiv.org/abs/2407.11969v1",
        "pdf_url": "http://arxiv.org/pdf/2407.11969v1",
        "summary": "Refusal training is widely used to prevent LLMs from generating harmful,\nundesirable, or illegal outputs. We reveal a curious generalization gap in the\ncurrent refusal training approaches: simply reformulating a harmful request in\nthe past tense (e.g., \"How to make a Molotov cocktail?\" to \"How did people make\na Molotov cocktail?\") is often sufficient to jailbreak many state-of-the-art\nLLMs. We systematically evaluate this method on Llama-3 8B, GPT-3.5 Turbo,\nGemma-2 9B, Phi-3-Mini, GPT-4o, and R2D2 models using GPT-3.5 Turbo as a\nreformulation model. For example, the success rate of this simple attack on\nGPT-4o increases from 1% using direct requests to 88% using 20 past tense\nreformulation attempts on harmful requests from JailbreakBench with GPT-4 as a\njailbreak judge. Interestingly, we also find that reformulations in the future\ntense are less effective, suggesting that refusal guardrails tend to consider\npast historical questions more benign than hypothetical future questions.\nMoreover, our experiments on fine-tuning GPT-3.5 Turbo show that defending\nagainst past reformulations is feasible when past tense examples are explicitly\nincluded in the fine-tuning data. Overall, our findings highlight that the\nwidely used alignment techniques -- such as SFT, RLHF, and adversarial training\n-- employed to align the studied models can be brittle and do not always\ngeneralize as intended. We provide code and jailbreak artifacts at\nhttps://github.com/tml-epfl/llm-past-tense.",
        "updated": "2024-07-16 17:59:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.11969v1"
    },
    {
        "title": "Efficient Training with Denoised Neural Weights",
        "authors": "Yifan GongZheng ZhanYanyu LiYerlan IdelbayevAndrey ZharkovKfir AbermanSergey TulyakovYanzhi WangJian Ren",
        "links": "http://arxiv.org/abs/2407.11966v1",
        "entry_id": "http://arxiv.org/abs/2407.11966v1",
        "pdf_url": "http://arxiv.org/pdf/2407.11966v1",
        "summary": "Good weight initialization serves as an effective measure to reduce the\ntraining cost of a deep neural network (DNN) model. The choice of how to\ninitialize parameters is challenging and may require manual tuning, which can\nbe time-consuming and prone to human error. To overcome such limitations, this\nwork takes a novel step towards building a weight generator to synthesize the\nneural weights for initialization. We use the image-to-image translation task\nwith generative adversarial networks (GANs) as an example due to the ease of\ncollecting model weights spanning a wide range. Specifically, we first collect\na dataset with various image editing concepts and their corresponding trained\nweights, which are later used for the training of the weight generator. To\naddress the different characteristics among layers and the substantial number\nof weights to be predicted, we divide the weights into equal-sized blocks and\nassign each block an index. Subsequently, a diffusion model is trained with\nsuch a dataset using both text conditions of the concept and the block indexes.\nBy initializing the image translation model with the denoised weights predicted\nby our diffusion model, the training requires only 43.3 seconds. Compared to\ntraining from scratch (i.e., Pix2pix), we achieve a 15x training time\nacceleration for a new concept while obtaining even better image generation\nquality.",
        "updated": "2024-07-16 17:59:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.11966v1"
    },
    {
        "title": "Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling",
        "authors": "Jaehyeok KimDongyoon WeeDan Xu",
        "links": "http://arxiv.org/abs/2407.11962v1",
        "entry_id": "http://arxiv.org/abs/2407.11962v1",
        "pdf_url": "http://arxiv.org/pdf/2407.11962v1",
        "summary": "This paper introduces Motion-oriented Compositional Neural Radiance Fields\n(MoCo-NeRF), a framework designed to perform free-viewpoint rendering of\nmonocular human videos via novel non-rigid motion modeling approach. In the\ncontext of dynamic clothed humans, complex cloth dynamics generate non-rigid\nmotions that are intrinsically distinct from skeletal articulations and\ncritically important for the rendering quality. The conventional approach\nmodels non-rigid motions as spatial (3D) deviations in addition to skeletal\ntransformations. However, it is either time-consuming or challenging to achieve\noptimal quality due to its high learning complexity without a direct\nsupervision. To target this problem, we propose a novel approach of modeling\nnon-rigid motions as radiance residual fields to benefit from more direct color\nsupervision in the rendering and utilize the rigid radiance fields as a prior\nto reduce the complexity of the learning process. Our approach utilizes a\nsingle multiresolution hash encoding (MHE) to concurrently learn the canonical\nT-pose representation from rigid skeletal motions and the radiance residual\nfield for non-rigid motions. Additionally, to further improve both training\nefficiency and usability, we extend MoCo-NeRF to support simultaneous training\nof multiple subjects within a single framework, thanks to our effective design\nfor modeling non-rigid motions. This scalability is achieved through the\nintegration of a global MHE and learnable identity codes in addition to\nmultiple local MHEs. We present extensive results on ZJU-MoCap and MonoCap,\nclearly demonstrating state-of-the-art performance in both single- and\nmulti-subject settings. The code and model will be made publicly available at\nthe project page: https://stevejaehyeok.github.io/publications/moco-nerf.",
        "updated": "2024-07-16 17:59:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.11962v1"
    },
    {
        "title": "Context-Guided Diffusion for Out-of-Distribution Molecular and Protein Design",
        "authors": "Leo KlarnerTim G. J. RudnerGarrett M. MorrisCharlotte M. DeaneYee Whye Teh",
        "links": "http://arxiv.org/abs/2407.11942v1",
        "entry_id": "http://arxiv.org/abs/2407.11942v1",
        "pdf_url": "http://arxiv.org/pdf/2407.11942v1",
        "summary": "Generative models have the potential to accelerate key steps in the discovery\nof novel molecular therapeutics and materials. Diffusion models have recently\nemerged as a powerful approach, excelling at unconditional sample generation\nand, with data-driven guidance, conditional generation within their training\ndomain. Reliably sampling from high-value regions beyond the training data,\nhowever, remains an open challenge -- with current methods predominantly\nfocusing on modifying the diffusion process itself. In this paper, we develop\ncontext-guided diffusion (CGD), a simple plug-and-play method that leverages\nunlabeled data and smoothness constraints to improve the out-of-distribution\ngeneralization of guided diffusion models. We demonstrate that this approach\nleads to substantial performance gains across various settings, including\ncontinuous, discrete, and graph-structured diffusion processes with\napplications across drug discovery, materials science, and protein design.",
        "updated": "2024-07-16 17:34:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.11942v1"
    },
    {
        "title": "Fairly Accurate: Optimizing Accuracy Parity in Fair Target-Group Detection",
        "authors": "Soumyajit GuptaVenelin KovatchevMaria De-ArteagaMatthew Lease",
        "links": "http://arxiv.org/abs/2407.11933v1",
        "entry_id": "http://arxiv.org/abs/2407.11933v1",
        "pdf_url": "http://arxiv.org/pdf/2407.11933v1",
        "summary": "In algorithmic toxicity detection pipelines, it is important to identify\nwhich demographic group(s) are the subject of a post, a task commonly known as\n\\textit{target (group) detection}. While accurate detection is clearly\nimportant, we further advocate a fairness objective: to provide equal\nprotection to all groups who may be targeted. To this end, we adopt\n\\textit{Accuracy Parity} (AP) -- balanced detection accuracy across groups --\nas our fairness objective. However, in order to align model training with our\nAP fairness objective, we require an equivalent loss function. Moreover, for\ngradient-based models such as neural networks, this loss function needs to be\ndifferentiable. Because no such loss function exists today for AP, we propose\n\\emph{Group Accuracy Parity} (GAP): the first differentiable loss function\nhaving a one-on-one mapping to AP. We empirically show that GAP addresses\ndisparate impact on groups for target detection. Furthermore, because a single\npost often targets multiple groups in practice, we also provide a mathematical\nextension of GAP to larger multi-group settings, something typically requiring\nheuristics in prior work. Our findings show that by optimizing AP, GAP better\nmitigates bias in comparison with other commonly employed loss functions.",
        "updated": "2024-07-16 17:23:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.11933v1"
    }
]