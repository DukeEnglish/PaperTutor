[
    {
        "title": "Map of Elections",
        "authors": "Stanisław Szufa",
        "links": "http://arxiv.org/abs/2407.11889v1",
        "entry_id": "http://arxiv.org/abs/2407.11889v1",
        "pdf_url": "http://arxiv.org/pdf/2407.11889v1",
        "summary": "Our main contribution is the introduction of the map of elections framework.\nA map of elections consists of three main elements: (1) a dataset of elections\n(i.e., collections of ordinal votes over given sets of candidates), (2) a way\nof measuring similarities between these elections, and (3) a representation of\nthe elections in the 2D Euclidean space as points, so that the more similar two\nelections are, the closer are their points. In our maps, we mostly focus on\ndatasets of synthetic elections, but we also show an example of a map over\nreal-life ones. To measure similarities, we would have preferred to use, e.g.,\nthe isomorphic swap distance, but this is infeasible due to its high\ncomputational complexity. Hence, we propose polynomial-time computable\npositionwise distance and use it instead. Regarding the representations in 2D\nEuclidean space, we mostly use the Kamada-Kawai algorithm, but we also show two\nalternatives.\n  We develop the necessary theoretical results to form our maps and argue\nexperimentally that they are accurate and credible. Further, we show how\ncoloring the elections in a map according to various criteria helps in\nanalyzing results of a number of experiments. In particular, we show colorings\naccording to the scores of winning candidates or committees, running times of\nILP-based winner determination algorithms, and approximation ratios achieved by\nparticular algorithms.",
        "updated": "2024-07-16 16:18:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.11889v1"
    },
    {
        "title": "Learning to Imitate Spatial Organization in Multi-robot Systems",
        "authors": "Ayomide O. AgunloyeSarvapali D. RamchurnMohammad D. Soorati",
        "links": "http://arxiv.org/abs/2407.11592v1",
        "entry_id": "http://arxiv.org/abs/2407.11592v1",
        "pdf_url": "http://arxiv.org/pdf/2407.11592v1",
        "summary": "Understanding collective behavior and how it evolves is important to ensure\nthat robot swarms can be trusted in a shared environment. One way to understand\nthe behavior of the swarm is through collective behavior reconstruction using\nprior demonstrations. Existing approaches often require access to the swarm\ncontroller which may not be available. We reconstruct collective behaviors in\ndistinct swarm scenarios involving shared environments without using swarm\ncontroller information. We achieve this by transforming prior demonstrations\ninto features that sufficiently describe multi-agent interactions before\nbehavior reconstruction with multi-agent generative adversarial imitation\nlearning (MA-GAIL). We show that our approach outperforms existing algorithms\nin all investigated swarm scenarios, and can be used to observe and reconstruct\na swarm's behavior for further analysis and testing, which might be impractical\nor undesirable on the original robot swarm.",
        "updated": "2024-07-16 10:50:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.11592v1"
    },
    {
        "title": "Navigating the swarm: Deep neural networks command emergent behaviours",
        "authors": "Dongjo KimJeongsu LeeHo-Young Kim",
        "links": "http://arxiv.org/abs/2407.11330v1",
        "entry_id": "http://arxiv.org/abs/2407.11330v1",
        "pdf_url": "http://arxiv.org/pdf/2407.11330v1",
        "summary": "Interacting individuals in complex systems often give rise to coherent motion\nexhibiting coordinated global structures. Such phenomena are ubiquitously\nobserved in nature, from cell migration, bacterial swarms, animal and insect\ngroups, and even human societies. Primary mechanisms responsible for the\nemergence of collective behavior have been extensively identified, including\nlocal alignments based on average or relative velocity, non-local pairwise\nrepulsive-attractive interactions such as distance-based potentials, interplay\nbetween local and non-local interactions, and cognitive-based inhomogeneous\ninteractions. However, discovering how to adapt these mechanisms to modulate\nemergent behaviours remains elusive. Here, we demonstrate that it is possible\nto generate coordinated structures in collective behavior at desired moments\nwith intended global patterns by fine-tuning an inter-agent interaction rule.\nOur strategy employs deep neural networks, obeying the laws of dynamics, to\nfind interaction rules that command desired collective structures. The\ndecomposition of interaction rules into distancing and aligning forces,\nexpressed by polynomial series, facilitates the training of neural networks to\npropose desired interaction models. Presented examples include altering the\nmean radius and size of clusters in vortical swarms, timing of transitions from\nrandom to ordered states, and continuously shifting between typical modes of\ncollective motions. This strategy can even be leveraged to superimpose\ncollective modes, resulting in hitherto unexplored but highly practical hybrid\ncollective patterns, such as protective security formations. Our findings\nreveal innovative strategies for creating and controlling collective motion,\npaving the way for new applications in robotic swarm operations, active matter\norganisation, and for the uncovering of obscure interaction rules in biological\nsystems.",
        "updated": "2024-07-16 02:46:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.11330v1"
    },
    {
        "title": "Conditions for Altruistic Perversity in Two-Strategy Population Games",
        "authors": "Colton HillPhilip N. BrownKeith Paarporn",
        "links": "http://arxiv.org/abs/2407.11250v1",
        "entry_id": "http://arxiv.org/abs/2407.11250v1",
        "pdf_url": "http://arxiv.org/pdf/2407.11250v1",
        "summary": "Self-interested behavior from individuals can collectively lead to poor\nsocietal outcomes. These outcomes can seemingly be improved through the actions\nof altruistic agents, which benefit other agents in the system. However, it is\nknown in specific contexts that altruistic agents can actually induce worse\noutcomes compared to a fully selfish population -- a phenomenon we term\naltruistic perversity. This paper provides a holistic investigation into the\nnecessary conditions that give rise to altruistic perversity. In particular, we\nstudy the class of two-strategy population games where one sub-population is\naltruistic and the other is selfish. We find that a population game can admit\naltruistic perversity only if the associated social welfare function is convex\nand the altruistic population is sufficiently large. Our results are a first\nstep in establishing a connection between properties of nominal agent\ninteractions and the potential impacts from altruistic behaviors.",
        "updated": "2024-07-15 21:35:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.11250v1"
    },
    {
        "title": "Time Shift Governor for Constrained Control of Spacecraft Orbit and Attitude Relative Motion in Bicircular Restricted Four-Body Problem",
        "authors": "Taehyeun KimIlya KolmanovskyAnouck Girard",
        "links": "http://arxiv.org/abs/2407.11170v1",
        "entry_id": "http://arxiv.org/abs/2407.11170v1",
        "pdf_url": "http://arxiv.org/pdf/2407.11170v1",
        "summary": "This paper considers constrained spacecraft rendezvous and docking (RVD) in\nthe setting of the Bicircular Restricted Four-Body Problem (BCR4BP), while\naccounting for attitude dynamics. We consider Line of Sight (LoS) cone\nconstraints, thrust limits, thrust direction limits, and approach velocity\nconstraints during RVD missions in a near rectilinear halo orbit (NRHO) in the\nSun-Earth-Moon system. To enforce the constraints, the Time Shift Governor\n(TSG), which uses a time-shifted Chief spacecraft trajectory as a target\nreference for the Deputy spacecraft, is employed. The time shift is gradually\nreduced to zero so that the virtual target gradually evolves towards the Chief\nspacecraft as time goes by, and the RVD mission objective can be achieved.\nNumerical simulation results are reported to validate the proposed control\nmethod.",
        "updated": "2024-07-15 18:45:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.11170v1"
    }
]