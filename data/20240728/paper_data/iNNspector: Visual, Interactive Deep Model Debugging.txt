iNNspector:Visual,InteractiveDeepModelDebugging
THILOSPINNER,ETHZurich,Switzerland
DANIELFÜRST,UniversityofKonstanz,Germany
MENNATALLAHEL-ASSADY,ETHZurich,Switzerland
Deeplearningmodeldesign,development,anddebuggingisaprocessdrivenbybestpractices,guidelines,trial-and-error,andthe
personalexperiencesofmodeldevelopers.Atmultiplestagesofthisprocess,performanceandinternalmodeldatacanbeloggedand
madeavailable.However,duetothesheercomplexityandscaleofthisdataandprocess,modeldevelopersoftenresorttoevaluating
theirmodelperformancebasedonabstractmetricslikeaccuracyandloss.Wearguethatastructuredanalysisofdataalongthemodel’s
architectureandatmultipleabstractionlevelscanconsiderablystreamlinethedebuggingprocess.Suchasystematicanalysiscan
furtherconnectthedeveloper’sdesignchoicestotheirimpactsonthemodelbehavior,facilitatingtheunderstanding,diagnosis,and
refinementofdeeplearningmodels.Hence,inthispaper,we(1)contributeaconceptualframeworkstructuringthedataspaceofdeep
learningexperiments.Ourframework,groundedinliteratureanalysisandrequirementsinterviews,capturesdesigndimensionsand
proposesmechanismstomakethisdataexplorableandtractable.Tooperationalizeourframeworkinaready-to-useapplication,we
(2)presenttheiNNspectorsystem.iNNspectorenablestrackingofdeeplearningexperimentsandprovidesinteractivevisualizations
ofthedataonalllevelsofabstractionfrommultiplemodelstoindividualneurons.Finally,we(3)evaluateourapproachwiththree
real-worlduse-casesandauserstudywithdeeplearningdevelopersanddataanalysts,provingitseffectivenessandusability.
CCSConcepts:•Human-centeredcomputing→Visualanalytics;Graphicaluserinterfaces;•Computingmethodologies→
Neuralnetworks;•Softwareanditsengineering→Softwaretestinganddebugging;•Generalandreference→Reference
works.
AdditionalKeyWordsandPhrases: NeuralNetworkDebugging,ExplainableAI,ModelDebugging,DeepLearning,NeuralNetwork
Visualization,ModelRefinement,InteractiveVisualization,ConceptualFramework,DesignGuidelines
ACMReferenceFormat:
ThiloSpinner,DanielFürst,andMennatallahEl-Assady.2018.iNNspector:Visual,InteractiveDeepModelDebugging.J.ACM37,4,
Article111(August2018),48pages.https://doi.org/XXXXXXX.XXXXXXX
1 INTRODUCTION
Despitetherecentprevalenceofdeeplearningalgorithms,themodel-buildingprocessisstillatrial-and-errorone,
primarilyguidedbythedeveloper’sexperienceorafewknownbestpractices[S.Liuetal.2017].Typically,different
architecture–andhyperparameterconfigurationsaretestedmanuallyorbyautomatedarchitecturesearch[Elskenetal.
2019],fromwhichthebest-performingmodelisthenselectedandfurtherrefined.Assessmentandselectionareoften
basedonperformancemetrics,suchaslossoraccuracy,whichhighlyaggregateinformationandleavethemodel’s
innerworkingsopaque[Schneideretal.2021].However,conflictingwithdeep-learningmodel’sblack-boxcharacter,a
Authors’addresses:ThiloSpinner,ETHZurich,Zurich,Switzerland,thilo.spinner@inf.ethz.ch;DanielFürst,UniversityofKonstanz,Konstanz,Germany,
daniel.fuerst@uni-konstanz.de;MennatallahEl-Assady,ETHZurich,Zurich,Switzerland,menna.elassady@ai.ethz.ch.
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenot
madeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirstpage.Copyrightsforcomponents
ofthisworkownedbyothersthantheauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,toposton
serversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org.
©2018Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
ManuscriptsubmittedtoACM
ManuscriptsubmittedtoACM 1
4202
luJ
52
]CH.sc[
1v89971.7042:viXra2 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
deepunderstandingofthemodel’sinnerworkingsisessentialforwell-informedmodeldiagnosis,verification,and
refinement.Furthermore,suchunderstandingisfundamentalfortrust-buildingandmodelverification,e.g.,forits
deploymentinsafety-criticalenvironmentssuchasintheautomotiveormedicalsector.
Techniquesforexplainableartificialintelligence[Guidottietal.2018]trytotacklethischallenge;however,many
approachesaremodel-agnostic,leavingthemodel’sinnerworkingsopaque,andoperateonalocallevel,explaining
decisionsonlyforsingleinputsamples.Toachieveadeepunderstandingofthemodelandestablishaconnection
betweenitsbehaviorandtheunderlyingarchitecture,amoreholisticviewonthemodelanditsdevelopmentprocessis
needed.Therefore,wearguethatthestructureddebuggingofneuralnetworksshouldbecomearoutineinthedaily
workflowofmodeldevelopmentand–design.Complementarytothedebuggingintraditionalsoftwaredevelopment
Laymanetal.[2013],wedefinethedebuggingofdeeplearningmodelsasfollows:
Wedefinethedebuggingofdeeplearningmodelsastheprocessofidentifyingandfixingerrorsin
themodel’sarchitecture,behavior,ortrainingdataeitherduringtrainingorpost-trainingby
Definition
iterativelycalibratingtheunderstandingofthemodelbehaviorthroughthestructuredanalysisofits
DebuggingofDLModels
architecture,hyperparameters,performancemetrics,learnedfeatures,activations,andoutputs.
Incontrasttotraditionalsoftwaredebugging,thereoftenisnodefiniteconnectionbetweenanerroranditssource.
Therefore,erroridentificationindeeplearningmodelsmightinvolveseveraltechniquesusedseparatelyorincombina-
tion.Forinstance,localoutputanalysiscanhelpidentifyinstanceswherethemodelperformspoorlyorprovides
incorrectpredictionsandthendeterminewhytheseerrorsoccur.Incontrast,globaloutputanalysiscanreveal
patternsinthemodel’sbehaviorovertheentireinputdataspace,e.g.,toidentifybiasesoroverfitting.Methodsfor
interpretabilityandexplainabilityprovideadditionaltoolstointerpretthedecision-makingprocessofamodel.
Forinstance,attentionmapsinconvolutionalneuralnetworkscanhelpunderstandwhichpartsoftheinputaremost
influentialinthemodel’sdecisions.Whiletheprevioustechniquesfocusonin–andoutputdataanditsmodel-internal
representations,architectureanalysisfocusesonthemodel’scomputationalgraph.Forexample,thegraphcanbe
analyzedtoidentifyunusualorerroneouscombinationsoflayersoroperations.Particularlyrelevanttoassessthe
successofamodelareperformancestatistics.Overfitting,forinstance,canbedetectedbycheckingthelearning
curve,whichplotsthemodel’sperformanceonthetrainingandvalidationdatasetsovertrainingepochs.Finally,
modelstatisticsusestatisticalmethodstounderstandthemodel’sinternalstate,suchasweightsandactivationsor
outputcharacteristics,forexample,toidentifymodelbiases.Visualizationssupporttheabovementionedtechniques,
helpingtheanalystunderstandtheresults.E.g.,avisualrepresentationofthearchitecturegraphcanrevealsuspicious
patterns[Wongsuphasawatetal.2018],oraplotofactivationscanrevealaneuron’sfocus[Yosinskietal.2015].
Thiswayofdebuggingallowsthedeveloperaholisticviewofthemodeland,thus,isequallyrelevantincases
wheretherearenoapparenterrorsinthemodel.Ifthemodelisnotbehavingaccordingtothedeveloper’sintention,
systematicdebuggingalsoallowsfortheidentificationoferrorsources,indicatingpossibleareasformodelrefinement.
Existingcommercialandopensourcesystemssupportingmodelexplainabilityanddebugging[TensorBoard2020;
Weights&Biases2021]dogeneralize welltodifferentdata,models,andtasks.However,theycomewithnarrow
limitationsregardingtherichnessofavailabletools,thedatathatisaccessibleafterfinishingthetrainingstage,and
theirprovidedvisualizationsandinteractions,leavingthedebuggingprocessshallow.Incontrast,therehasbeena
multitudeofvisualanalyticssystemsforexplainabledeeplearninginthelastyears[Endertetal.2017;Hohman,Kahng,
etal.2018],allowingforthoroughinvestigationofmodels.Theyprovidehighlyspecializedtools,visualizations,and
interactions,withthedownsideofsubstantiallimitationsregardingtheirtransferabilitytodifferentdata,architectures,
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 3
Continuous Evaluation & Refinement
Formal Framework ([4X).X]
Requirements Analysis ([3X)]
Capturi en xg
p
t eh re
im
D ea nt ta
s
(S [4Xp ..1a X)c ]e of DL
n
(2
years)
iNNspector System ([5X)]
Final Evaluation(7)
Ide inn t Rif eyi ln ag
te
o dp Wen
o
c rh ka ([3l Xle ..1n X)g ]es S Dtr imuc etu nr si in og
n
D
s
(e [4Xs .i .2g X)n
]
ntatio
Application Walkthrough ([5X..1X)]
Use-C ases ([6X)]
e
Capturing the needs of MDs in Proposing Global Mechanisms em System Architecture &
Requirements Study ([3X..2X)] to navigate the data space ([4X..3X)] pl Implementation ([5X..4X)] Expert User Study ([7X)]
m
I
Fig.1. Theworkflowwefollowtosubstantiate,design,implement,andevaluatetheiNNspectorsystemforsystematicmodel
debugging,whichalsoreflectsinthestructureofthispaper.
ortasks.Withthiswork,wearguefortheneedtocombinegeneralizabilityandthoroughnesstobridgetheprevalent
researchgapinstate-of-the-arttechniquesformodeldebugging.Hence,weaimtoanswerthefollowingresearch
questionsarisingfromtheidentifiedresearchgap:whichstepsanddatainthemodeldevelopmentworkflowareofinterest
tothedeveloperfordebugging?Followingthat,whatarethemechanisms,interfaces,andvisualizationsasystemshould
implementtomaketheseunitsofanalysisaccessible?
To enable this kind of systematic debugging, the machine learning community has to get away from tedious
single-iteminspection,oftenrequiringthemanualsetupofloggingmechanisms,time-consumingre-trainingofthe
model,andsingle-usedatavisualizationpipelines.Instead,alldataarisinginamachinelearningexperimentmustbe
readilyavailableduringthedebuggingstage.Additionally,human-interpretablerepresentationsofthisdatashouldbe
effortlesslygeneratedbythemachinelearningdeveloper,minimizingtheentrybarrierforsystematicmodeldebugging.
Totacklethesechallenges,inthispaper,wecontribute:
1)DebuggingFramework— Wecaptureandstructurethedesignspaceofsystematicmodeldebugging,focusing
ontheentiretyofdatageneratedinmachinelearningexperimentsandthenecessarymechanismstoexploreit.We
provideanintegratedconceptualframeworkthatcombinesthestructuredcomponentsintoanoverarchingapproach.
Theframeworkcapturesthedifferentaspectstobeconsideredandestablishesfundamentalguidelinesfordesigning
real-worldmodeldebuggingapplications.Todate,suchcomprehensivecharacterizationandsystematizationofthe
debuggingprocessismissinginthefield.
2)SystemImplementation— WithiNNspector,wepresentacomprehensivesystemforthesystematicdebugging
ofdeeplearningexperiments.Thesysteminstantiatesthemechanismsandguidelinesformalizedinourconceptual
debuggingframework.Thesystemisreleasedasopen-sourcesoftwareandisdesignedasaplatformforreal-worldmodel
debuggingscenarios,goingbeyondthesoledemonstrationofourconceptualframework’sactionability.iNNspectorisa
newkindofdebuggingsystem,providinggeneralizingaccesstoalldataarisinginthedeeplearningworkflowthrough
implementingappropriatevisualizations,navigationpatterns,andanextensibletoolpalette.
3)RequirementsAnalysisandEvaluationStudy— Ourconceptualdebuggingframeworkandsystemimplementa-
tionaregroundedincurrentresearchgaps,andaqualitativerequirementsstudywithreal-worldmodeldevelopers.We
capturethedevelopers’everydaydebuggingworkflowsand–needs,revealingsignificantchallengesinthestate-of-the-
art.Finally,weevaluateoursystemwithmodeldevelopers,assessingtheapplicabilityandusefulnessofourapproach
andhowitclosestheidentifiedgaps.
ManuscriptsubmittedtoACM4 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
Toestablishourapproach,wefollowtheworkflowofsubstantiating,designing,implementing,andevaluatingthe
iNNspectorsystemforsystematicmodeldebugging,diagramedinfigure1.Startingwithanextensiverequirements
analysis(section3),weidentifyopenresearchchallengesfromrelatedwork(section3.1)andcapturetheneedsof
modeldevelopersinarequirementsstudy(section3.2).Following,westructuretheserequirementsintoaconcecptual
framework(section4),coveringthedifferentaspectsthathavetobeconsideredforthedesignofasystemsupporting
systematicmodeldebugging.Namely,thisincludesthedatathatisrelevantduringthedebuggingstage(section4.1),
thedesigndimensionsthathavetobeconsideredinsuchasystem(section4.2),andthemechanismsthesystemneeds
toimplementtomakethedataexplorablebytheanalyst(section4.3).Basedontheconceptualframework,wepresent
theiNNspectorsystemforsystematicmodeldebugging(5).Inadetailedapplicationwalkthrough(section5.1),we
explaintheinterface,visualizations,andinteractionsthesystemimplements,linkingthembacktotherequirements
analysisandtheframework.Ashortdescriptionofthesystemarchitectureand–implementation(section5.4)explains
howiNNspectorcanbeintegratedintotheexistingmodeldevelopmentworkflow.Weevaluateourapproachbasedon
usecases(section6),showcasingallcomponentsofthesystem.Theusecasesarethefoundationforanexpertuser
study(section7),whichevaluatestheusabilityandusefulnessofsystemandframework.
2 RELATEDWORK
Weidentifyseveralsubtopicstouchingthefieldofdeepmodeldebugging,providingabroadspectrumoftoolsand
methodologies,eachwithitsstrengthsandlimitations.Incontrasttoourapproach,thestate-of-the-arttechniques
Summary
onlytacklesub-partsofdeeplearningexperiments,constrainingthemtospecificdomains,models,tasks,orstages
Sec.2
ofthemodeldevelopmentworkflow.
Theworkrelatedtothedebuggingofneuralnetworkscanbedividedintoseveralsubtopics,includingtechniques
forautomatedmachinelearning,explainableartificialintelligence,visualanalyticsformachinelearning,andsystems
fortrackingandassessingmachinelearningexperiments.Notethatwechosetostructureourliteraturereviewof
explainableartificialintelligenceintothreesubsections,namelyalgorithm-centeredXAI(coveringthetechnicalML
perspective),human-centeredXAI(coveringthehuman-computerinteractionperspective),andapplication-centered
XAI(coveringthevisualanalyticsperspective).
2.1 AutomatedMachineLearning
AutoMLtechniquesaimtoautomatemodelbuildingandtuning.Thesubfieldsincludehyperparameteroptimization,
Summary meta-learning,andneuralarchitecturesearch.Whilethesetechniquesofferautomationofmodelrefinement,they
Sec.2.1 stillrequiresystematicdebuggingforhumancontrolandtrust-building.
Incontrasttothemanualmodelbuilding,–diagnosis,and–refinementprocess,techniquesforautomatedmachine
learning (AutoML) strive to automate the time-consuming hyperparameter search by systematically probing the
search space, as summarized by [Hutter et al. 2019]. They divide the field into three subtopics: hyperparameter
optimizationisthemostbasictaskinAutoML,addressingthesearchforparameterconfigurations(e.g.,layercapacities,
optimizationalgorithms,regularization)thatmaximizethemodel’sperformance.Here,recently,Bayesianoptimization-
basedapproaches[Bergstra,Bardenet,etal.2011],multi-fidelitymethods[LishaLietal.2017],andacombinationof
both[Falkneretal.2018]provedsuccessful.Incontrast,metalearning,orlearningtolearn,strivestospeeduplearning
anewtaskbylearningfromexistingmodels.Indeeplearning,prominentexamplesaretransferlearning[Thrunand
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 5
Pratt1998],wheremodelstrainedonasourcetaskareusedasastartingpointtolearnatargettask,andfew-shot
learning[Y.Wangetal.2021],wherepriorexperienceswithsimilartasksareexploitedtotrainamodelonanewtask
forwhichonlyfewtrainingsamplesareavailable.Finally,neuralarchitecturesearchfocusesontheautomatedsearch
formodelarchitectures[Elskenetal.2019],makingitthemostcomplextaskofAutoML.Severalsearchstrategies
exist;evolutionaryalgorithms[Floreanoetal.2008]havealonghistoryinthefield[Milleretal.1989]andstillprove
successful[Realetal.2019].Morerecently,ZophandLe’sadvancementsusingreinforcementlearning[ZophandLe
2017]broughtnewmomentumtothefield.OtherapproachesrelyonBayesianoptimization[Bergstra,Yamins,etal.
2013]orrandomsearch[LiamLiandTalwalkar2020].
WhileAutoMLtechniquescanautomatelargepartsofthemodelrefinementandparametertuningprocess,systematic
debuggingisneverthelessrelevant.Trackingsearchspacecoverage,trust-building,andmodelverificationareessential
whenthemodel-buildingprocessislefttoanopaqueoptimizationalgorithm.Forinstance,toruleoutoverfittingofthe
AutoMLalgorithm[CawleyandTalbot2010]orwhenmodelexplainabilityismandatory[Gunning2016].
2.2 Algorithm-CenteredXAI
Algorithm-centeredXAItechniquestackletheblack-boxnatureofneuralnetworksbyproviding(external)explana-
tionsoftheirpredictions.Theapproachescanbecategorizedbasedonattributeslikebeinglocalorglobal,intrinsic
Summary orpost-hoc,andmodel-agnosticormodel-specific.Whileuseful,Algorithm-centeredXAItechniquesarecriticized
Sec.2.2 fortheirfragilityandlimitedapplicabilityforarchitecturaladjustments,whichourapproachaddressesbylinking
modelbehaviortoitsarchitecture.
Explainableartificialintelligence(XAI)providestechniquestobreakuptheblack-boxnatureofdeeplearning
models,enablinginsightsintotheirworking[Gunning2016].It,therefore,spansanessentialsubtopicofneuralnetwork
debugging.AdadiandBerrada[2018]surveypopularXAItechniquesandclassifythemaccordingtomutualproperties,
suchaslocal(explainingsinglepredictions)vs.global(explainingthemodelasawhole).Furthermore,theydistinguish
betweenintrinsic(themodelisinherentlyexplainable,e.g.,decisiontrees)vs.post-hoc(themodelisablack-boxandneeds
externalexplanation,e.g.,DNNs)andmodelagnostic(theexplanationworksfordifferentmodeltypes)vs.modelspecific
(thetechniqueonlyworksforspecificmodeltypes).Thisclassificationiswidelyacceptedinrelatedliterature[Molnar
2022;Spinneretal.2020].Simultaneously,Guidottietal.[2018]presentanextensivestate-of-the-artreportonXAI,
formalizingtheproblemofexplainingblack-boxmodels.Theyclassifyexplanationsbasedontheproblemfaced,the
typeofexplanator,theblackboxmodelthattheexplanatorcanopen,andthetypeofdatausedasinputbytheblack-box
model.WithexplAIner,Spinneretal.[2020]structuretheprocessofexplanation,integratingthevariousXAItechniques
intoanoverarchingframeworkandsystem.
GuidedbyMolnar’sneatlystructuredoverviewoninterpretablemachinelearning[Molnar2022],inthefollowing,
wesummarizethestate-of-the-artXAItechniquesmostprominentindeeplearning.Allpresentedtechniquesare
post-hocsincedeeplearningmodelshaveablack-boxcharacterbydefault.Here,wefocusonlocal,attribution-based
techniques.Incontrast,globaltechniquesfocusontheexplanationoflearnedfeatures;duetotheirstrongrelation
tothenetworkarchitecture,wecoverthemasasubtopicofsection2.3.Localattributionmethodscanbefurther
dividedintomodel-agnosticandmodel-specifictechniques.Model-agnosticmethods,suchasLIME[Ribeiroetal.
2016],Anchors[Ribeiroetal.2018],orSHAP[LundbergandLee2017],perturbatetheinputtogenerateexplanations,
allowingtoassesstheimportanceofindividualinputfeatures.Incontrast,counterfactuals[Wachteretal.2017]probe
thedecisionboundaryofamodelbyfindingthesmallestpossiblechangeintheinputtogenerateadesirableoutcome,
ManuscriptsubmittedtoACM6 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
e.g.,toflipthepredictedclass.SaliencyMaps[Simonyanetal.2014]andGradCAM[Selvarajuetal.2017]areexamples
ofgradient-basedtechniquesandare,therefore,model-specific.Theygeneratepixelattributionsasaspecialformof
featureattribution.
Notably,thedescribedtechniquesarewidelycriticizedforbeingfragile[Ghorbanietal.2019],pronetomanipula-
tions[Dombrowskietal.2019],missleading[Lipton2018],andbarelyactionabletowardsarchitecturalchanges[Spinner
etal.2020].Ourpresentworktacklestheseissuesbytargetingaholisticviewofneuralnetworks,inherentlyconnecting
themodel’sbehaviortoitsarchitecture.Thediscussedalgorithm-centeredXAItechniquescanbeconsideredpotential
toolsinouroverarchingdebuggingframework,spanningasub-taskofneuralnetworkdebugging.
2.3 NeuralNetworkVisualization
Varioustoolsexistforvisualizingneuralnetworkarchitecturesandlearnedrepresentations.Ourworkextendsthe
architectureviewbyincorporatingahigher-ordergraphtoshowrelationshipsbetweendifferentmodelgenerations,
Summary
providingacomprehensiveviewfordebugging.Also,wesimplifyaccesstolearnedrepresentationsthrough
Sec.2.3
single-clicktools.
With the abundance of network architectures and –types, various approaches to visualize these architectures
arose.Patel[2021]presentsacomprehensiveoverviewoftoolstovisualizeneuralnetworks.WithNN-SVG,LeNail
[2019]provideatooltogenerateSVGvisualizationsinthefully-connected–,LeNet–[Lecunetal.1998],andAlexNet-
styles[Krizhevskyetal.2017].TensorSpace.js1combinesinteractive3Dvisualizationsofthenetworkswithexplanations
ofthemodel’spredictionprocess.TensorBoard[TensorBoard2020]visualizesthecomputationalgraphofTensorFlow
modelsdowntosingleoperations.Incontrast,Netron[Roeder2022]supportsvariousDLframeworksandgenerates
moreabstract,layer-basedgraphrepresentations.Q.Wangetal.[2019]presentaninteractivegeneologyofprevalent
networktypesand–architectures.
Besidesorinconjunctionwitharchitecturevisualization,manyapproachesfocusonthevisualizationoflearned
representations,particularlyincomputervision[Seifertetal.2017].Commonarepixeldisplaysofactivations[Grün
etal.2016]orkernels[BrachmannandRedies2016],andheatmaps[Sameketal.2017].Approachesforfeature
visualization[Olahetal.2017]strivetoexplainthefunctionalityofindividualneurons,channels,orlayersthrough
activationmaximization,puttingitatthejunctionoffeature-basednetworkvisualizationandglobal,algorithm-centered
XAI.Hohman,Park,etal.[2020]combinefeaturevisualizationswithdisplaysofthenetworkarchitectureintheformof
attributiongraphs,associatingindividualdatasetclasseswithstronglyactivatedsubnetworks.Whiletheseapproaches
canprovidevaluableinsights,theyareoftenhardtoaccessandrequireexpertknowledgetoimplement.
Thepresentworkcombinesarchitecturevisualizationsoflayersandneuronswithvisualizationsoflearnedrepresen-
tations.Forthefirsttime,weextendthevisualizationofmodelarchitectureswithahigher-ordergraph,expressingthe
relationshipbetweenmodelsanddifferencesbetweenmodelgenerations.Furthermore,ourtoolbox-basedapproach
allowssingle-clickvisualizationsoflearnedrepresentations,makingthemeasilyaccessible.
1https://tensorspace.org/
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 7
2.4 Human-CenteredXAI
Human-centeredXAIfocusesonintegratinghumanunderstandingintotheexplanationprocess.Ourworkaligns
Summary withthisbymakingmodeldebugginganinteractiveprocessreconcilinghumanintentionswithalgorithmic
Sec.2.4 behavior.
Human-centeredexplainableAI(HCXAI)[EhsanandRiedl2020]strivestofixtheshortcomingofalgorithmcentered
techniquesdiscregardingthehuman’sroleintheexplanationprocess.Recently,therehasbeenasurgeincallsfor
explainabilitythatdoesnotonlyopentheblack-boxbutalsoconsiderstheindividualandsocialfactorsofthehuman
interactingwiththeblack-box[Ehsan,Wintersberger,etal.2022].ThefieldofHCXAIiscurrentlyevolving;recent
positions[Singhetal.2021],designguidelines[Liaoetal.2020],frameworks[Gobboetal.2022],andstudies[Smith-
Renneretal.2020]outlinepossiblefuturedirections.Ourworktakesuptheconceptoftightlyintegratingthehuman
intothemachinelearningloop;modeldebugginginherentlyisaboutmatchinghumanintentionsagainstthebehavior
ofthealgorithm[Reiss2014].
2.5 Application-CenteredXAI
Application-centeredXAIinvolvesvisualanalyticssystemsspecializedtodata,tasks,ormodels.Thestrong
Summary specializationofexistingsystemsoftenlimitsreusabilityacrossdifferenttasksanddata,whichourapproach
Sec.2.5 overcomesbystructuringthedebuggingprocessinageneral-purposeframeworkformodeldebugging.
CloselyrelatedtoHCXAIarevisualanalyticstechniquesforMLandmodelexplanation.Inrecentyears,various
visualanalyticssystemsformachinelearninghavebeenpresented,spanningawiderangefromparticularapplication
areastotoolscoveringoneormultiplestagesofthemachinelearningworkflow[Yuanetal.2020].Incontrastto
thealgorithm-centeredtechniquesdiscussedinsection2.2,thesesystemsnotonlyprovidevisualizationsofmodels
anddatabutintegratethehumanintotheinteractiveMLloop[Sachaetal.2019].Hohman,Kahng,etal.[2018]
reviewandstructurerecentapproachesbasedonthe5W’sandHow.Theyidentifydifferententitiesthatcanbe
explained(i.e.,“What?”),suchascomputationalgraph&networkarchitecture[Wongsuphasawatetal.2018],learned
modelparameters[M.Liuetal.2018],individualcomputationalunits[Kahng,Andrews,etal.2018],orneuronsin
high-dimensionalspace[Strobelt,Gehrmann,Pfister,etal.2018].
Mostofthesesystemsarehighlyspecializedtodata,tasks,ormodels,preventingre-usabilityandhinderingapplication
inpractice.Ourpresentworktacklestheselimitationsbyproposingmechanismstomaketheentiretyofdataexplorable
andpresentinganextensiblesystemimplementingthosemechanisms.Bäuerleetal.[2022]identifyasimilarresearch
gapandproposeSymphony,aframeworkforcomposinginteractiveinterfacesformachinelearning.WhileiNNspector
isdesignedasastandalonetool,SymphonyintegratesintoexternalplatformslikeJupyternotebooks.Also,thesystems
differintheirwayofaccessing,navigating,andvisualizingdata,e.g.,Symphonyprovidesnomechanismstoaccessor
navigatestructuraldata(c.f.,section4.3).
IntheirDLdebuggingframeworkCockpit,Schneideretal.[2021]gatherhigher-orderinformationonthegradients
during training and visualize them to identify common bugs in data processing, parameter selection, and model
architecture.Tothisend,theydefinedifferentquantitiestrackedandcomputedduringtrainingandvisualizethemin
plotscalled“instruments.”WhilebothCockpitandiNNspectorprovideplotsofinternalmodeldynamics,theydifferin
theirfocus.Cockpitprovidesspecializedinstrumentsvisualizingadvancedinternaldynamicsduringtraining.Incontrast,
iNNspectorprovidesabroaderrangeofinstruments,coveringtheentiredeeplearningworkflow,complementingthe
ManuscriptsubmittedtoACM8 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
plotsofmodelmetricswithvisualizationsofmodelarchitectures,in-andoutputdata(e.g.,imagesandclassification
results),andmodel-internalrepresentations(e.g.,kernelsoractivations).
2.6 Systems&Toolkits
Varioussystemsandtoolkitsexistfortrackingandassessingmachinelearningexperiments.Whilethesesystems
providedifferentfunctionalitiesformodelmanagement,visualization,andassessment,aholisticviewofthedeep
Summary
learningworkflowmustbeincluded.Ourconceptualframeworkstructuresthedebuggingprocessandproposes
Sec.2.6
componentsandmechanismstoguidethedevelopmentofsuchsystems.
Keepingtrackofexperimentsisanessentialtaskinthedailymachinelearningworkflow.SystemslikeTensor-
Board[TensorBoard2020]orWeights&Biases[Weights&Biases2021]providevarioustoolsformodelmanagement,
–assessment,and–comparison.Furthermore,TensorBoardofferstoolsforvisualizingarchitectureanddataflowofa
model[Wongsuphasawatetal.2018],aswellasexplainabilitytechniques[Wexleretal.2019].TensorWatch[Shahetal.
2019]isadebuggingandvisualizationtoolthatintegratesintoJupyter2Notebooks.TheErrorAnalysistoolkit[Microsoft
2021]providestoolstoidentifyanddiagnosedatacohortswithhigherrorrates.Specializedinthefieldofnatural
languageprocessing,theLanguageInterpretabilityTool[Tenneyetal.2020]supportsmodelunderstandingbasedon
what-if-probing.
Thediscussedtechniquesandsystemscovermodeldebuggingconcerningspecificdomains,models,ortasks.In
contrast,thispapertargetsthesystematicdebuggingofdeeplearningexperiments(1)acrossallstagesand(2)overany
dataarisinginthedeeplearningworkflow.Theconceptualframeworkwepresentstructuresthedataanddesignspace
andprovidestoolsandtechniquestocoverthespacesaccordingly,withoutintroducingconstraintstodomain,model,
ortask.
3 THENEEDFORSYSTEMATICMODELDEBUGGING
Toeffectivelytackleourgoaloffacilitatingandestablishingthesystematicdebuggingofdeeplearningexperimentsin
everydaymachinelearningworkflows,westartbycapturingresearchgapsandopenchallengesinexistingacademic
andindustryworks.Wegroundthedesigndecisionsofourapproachinrequirementinterviewswithreal-worlddeep
learningdevelopers.Wegathershortcomingsintheirexistingtoolchains,collectreal-worldusecaseswheresystematic
debuggingwouldhavebeencrucial,andcapturerequirementsforasystemenablingsuchdebugging.
2https://jupyter.org/
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 9
3.1 ResearchGapandOpenChallenges
Thereexistmultipleresearchgapsandchallengesinthedomainofexplaininganddebuggingneuralnetworks.
Currentvisualanalyticsapproachesarehighlyspecializedeitherintermsofnetworktypes,domains,or
goals.Whilethisspecializationisnecessaryfordeepinsights,itlimitsthetechniques’generalizabilityand
transferabilitytobroaderdeeplearningworkflows.ExistingXAItechniquesmainlyofferlocalexplanationsand
areoftenmodel-agnostic.Theydonoteffectivelyexplaintheentirespaceofmodelinputsandoutputsand
cannottraceerrorsbacktomodelarchitecture.Whileneuron-orlayer-wiseexplanationscanprovidesuch
Summary
globalviews,theyarelimitedbytheirlackofintegratedaccesstoboththetechniqueitselfandlowerlevels
Sec.3.1
ofthenetwork.Modeltrackingisunderrepresentedinexistingwork,lackingvisualrepresentationsofmodel
iterationsandchangesbetweentheseiterations.Implementationcomplexityaffectsalloftheabove:elaborate
dataprovisioningandintricateimplementationactasabarrier,hinderingthewidespreadadoptionofdebugging
andexplainabilitytechniques.Theidentifiedchallengesemphasizetheneedforageneral-purposeframeworkto
addressthesegaps.
Systematicmodeldebugginghasrecentlygainedmomentuminthemachinelearningcommunityasthefoundation
fortrust-building,informeddecisionmaking,andeffectivemodelrefinement[Lakkarajuetal.2019].Inthefollowing,
weidentifyresearchgapsinthestate-of-the-art,substantiatingwhythiskindofdebuggingcurrentlyisnotcommon
practiceandwhatopenchallengeshavetoberesolvedtoclosethesegaps.
OverspecializationofCurrentVisualAnalyticsTechniques— Currentresearchaddressingthedebuggingof
machinelearningmodelspredominantlyfocusesonspecializednetworktypes,domains,andanalysisgoals[Endert
etal.2017;Hohman,Kahng,etal.2018;Yuanetal.2020].
Mostoftherecentlypresentedapproachestargetahighlyspecificproblem;thus,thepresentedVA
techniquesarealsohighlyspecialized.Forexample,Kahng,Thorat,etal.[2019]proposeanapproachfor
Example investigatinganddebuggingGANs(specializationonnetworktype),Strobelt,Gehrmann,Behrisch,etal.
SpecializationofVAin [2019]presentatoolforthedebuggingofsequence-to-sequencemodelsfortexttranslation(specialization
ML onnetwork–anddatatype),andCabreraetal.[2019]focusondetectingintersectionalbias(specialization
onanalysisgoal).
Itshouldbenotedthatthespecializationofthesetoolsisessentialtofacilitatethedeepinsightstheycanprovideand
tosolvethespecifiedtasks,and,therefore,isnotashortcoming.However,ourapproachaimsatageneraltechnique
enablingmodeldebuggingintheeverydaydeeplearningworkflow.Inthissetting,thespecializationofthepresented
toolslimitstransferabilityandgeneralizability,renderingtheminappropriateforourgoal.Particularly,withiNNspector,
westrivetostructurethedebuggingprocessinawaythatallowsfortheintegrationofspecializedtechniqueswhile
stillprovidingageneral-purposeframeworkforsystematicmodeldebugging.
Limitations of State-of-the-Art XAI Methods— Prevalent XAI techniques primarily provide local explana-
tions[AdadiandBerrada2018],renderingthemincapableofprovidingexplanationsovertheentirespaceofpossible
modelin-andoutputs.Furthermore,theexplanationsgeneratedbytheseapproachesareoftenmodelagnostic,leaving
theinnerworkingofthemodelanditsinfluenceonthemodelbehavioropaque.
ManuscriptsubmittedtoACM10 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
LIME[Ribeiroetal.2016]andLRP[Bachetal.2015]aretwopopularXAItechniquesthatprovidelocal
explanationsforamodel’spredictions,i.e.,theyexplainthemodel’sbehaviorforasingleinputsample.
Theresults,oftenusedtoannotatetheinputwithaheatmap,canrevealthemostrelevantfeaturesfor
Example theprediction.Thisconveystwosignificantlimitations:First,onlyknowninputscanbeinspected.A
LimitationsofCurrent prominentexampleisTesla’sautopilotmisinterpretingthemoonasatrafficlight[JordanTeslaTech2021],
XAIMethods whichcouldonlybeidentifiedasproblematicbeforehandbyLIMEandLRPifimagesofthemoonwere
partofthetestdata.Second,theexplanationsarepost-hocand,therefore,donotprovideanyinformation
onwhythemodelbehavesthewayitdoes.
ThisleavessuchXAItechniqueslimitedregardingthesystematicmodeldebuggingsince,typically,theidentifiederrors
cannotbeprojectedbackontoarchitecturalissuesandpossiblerefinements.ThenarrowconstraintsofexistingXAI
implementationsintheirapplicabilitytospecificdatatypesandmodelarchitecturesfurthercomplicatetheirusageasa
generaldebuggingtool.
MissingAccesstoNeurons— Neuron-orlayer-wiseexplanations,suchasfeaturevisualization[Olahetal.2017]or
attributiongraphs[Hohman,Park,etal.2020]areapowerfullglobalalternativetothedata-specific,localexplanation
ofsinglesamples.Here,integratedaccesstoboththetechniquesthemselvesandtolowerlevelsofthenetworkseems
currentlythemostlimitingfactor.
InsufficientModelTracking— Theproblemofmodeltrackingismostlyignoredbyrelatedworkandonlycovered
onatechnicallevelbycommercialoropen-sourcetools,relyingontabularrepresentations[Weights&Biases2021]or
Gitlogs[Kuprieievetal.2022].However,visualrepresentationsofmodeliterationsandchangesbetweeniterationsare
currentlymissing.
LackofAccessibility— Finally,allofthepreviouslymentionedaspectssharethefundamentalchallengeofrequiring
elaboratedataprovisioningandintricateimplementation,preventingthewidespreaduseofdebuggingandexplainability
techniquesinthedailyworkflowofdeeplearningdevelopers.Thus,easeofaccessandadaptabilitytoindividualtasks
anddomainsiscrucialtoestablishingthesystematicdebuggingofdeeplearningmodelsasacommonpractice.
3.2 CapturingDeveloperRequirements
Weinterviewedthreemodeldeveloperstoidentifyrequirementsforasystemaidingindeeplearningdebugging.
Theresultsshowthat:(1)Modelmanagementiscrucial,especiallychangedetectionandmodelcomparison.
Summary (2)Developersneedaccesstohigh-levelperformancemetricsandruntimevisualizations.(3)Differentlevelsof
Sec.3.2 architecturaldetailaredesiredforcomparingorcloselyanalyzingmodels.(4)Userguidanceandautomatedmistake
detectionareconsidereduseful.(5)Variedinterestexistsinvisualizingneuronactivationsandnetworkweights.
Tocapturetheneedsandexpectationstowardsasystemfacilitatingsystematicdebuggingofdeeplearningexperi-
ments,weconductstructuredrequirementsinterviewswiththreereal-worldmodeldevelopers.Ineachinterview,we
capturethefieldofexpertiseofthedevelopers,includingtasks,datatypesandmodelarchitecturestheytypicallydeal
with,aswellastheirtoolchainandworkflow.Subsequently,theinterviewfocusesonthedevelopers’currentdebugging
workflow,coveringhabits,usedtools,and,particulary,concretechallengesandusecasestheyexperiencedintheir
workwhereanin-depthdebuggingwasnecessarytofinallyresolveissueswiththemodel.Theusecasesusedforthe
finalevaluationofourapproach(seesection6)areinspiredbytheexperiencesandworkflowsourdevelopersreported
intherequirementinterviews.Asfoundationforthedesignofoursystem,theinterviewcontinueswithopen-ended
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 11
questionsonexpectationstowardssuchasystem.Particularly,weaskaboutthepartsofthemodelthedevelopers
areinterestedinduringdebugging(e.g.,differentpartsofthearchitectureormetrics),andhowcommontasks(e.g.,
modelcomparison)couldbesolvedinsuchasystem.Finally,wepresentearlyideasofhowsuchasystemcouldwork,
particularly,howweplantousethestructuralbackbone(seesection4.3,M2)andnavigationoverdifferentlevelsof
modelabstraction(seesection4.3,M3)toprovideaccesstoallentitiesofanexperiment.
Summarizingtheresultsofourstudy,weidentifythefollowingrequirementsfromtheperspectiveofthemodel
developers.Foradditionalresultsoftherequirementsstudy,includingdescriptionsofthedeveloper’scurrentworkflows,
thedatarelevantfordebugging,andconcretedebuggingusecases,pleaserefertoappendixA.
(R1)ModelManagement— Atthetopoftheiriterativemodeldevelopmentandrefinementworkflow,themodel
developersnamemodelmanagementacrucialtask.Whilethisalsoinvolvestheorganizationandstorageofsource
codeandmodels,themosthighlightedfunctionalitiesinthistaskarechangedetectionandmodelcomparison.All
intervieweddevelopersuse,besidesTensorBoard,customizedworkflowsformodelmanagement,oftenrelyingon
simpletoolslikefilenames,folderstructures,andcommand-linescripts.
(R2)PerformanceMetrics— Forhigh-levelmodeloverviewandcomparison,themodeldeveloperswanttoassess
theperformanceofmodelsbasedonthevisualizationofsummarizingmetrics,likelossoraccuracy.Also,visualizing
themodel’sruntimeperformanceisrequestedfortime-criticalenvironments.
(R3)ArchitectureRepresentation— Thedeveloperswishforanabstractarchitecturerepresentationwhencompar-
ingmultiplemodels.Forthecloseranalysisofonespecificmodel,morearchitecturaldetailsandinformationaboutthe
model’sparameterizationarerequested.Whenviewingasinglemodel,theflowofdatainthemodelisrelevanttothe
developers,aswellastheindividuallayercapacitiesandoperations.
(R4)InspectionofWeightsandActivations— When the analysis gets more detailed, e.g., when searching for
specificissuesinamodel,thedevelopersaskforvisualizationsofunderlyingdata.Thereby,theyseemmoreinterested
intheactivationsofneuronsonsinglesamplesorwholedatasetclassesthaninthetrainableweightsofthenetwork.
Forboth,theyidentifyusecaseswheretheyneedtoinspectthedistributionofvaluestodetectissueswithbottlenecks,
gradients,ornetworkcapacity.However,thetasksandrequirementsinvolvingdatainspectionandvisualizationvaries
stronglybetweendevelopers.Whilesomepreferasummarizingrepresentationofdatawithnointerestinweightsor
activations,othersdescribeusecasesintheirdevelopmentworkflowwherethedetaileddepictionofsuchdataplays
acrucialrole.Notably,thedevelopersmentionthatallnetworkpartsarerelevantformodelexplainability.Forthe
analysisofweightsandactivations,anevencloserfocusonspecificlayersiswishedfor.Particularinterestisshownin
visualizingthedevelopmentofsuchvariablesovertime,forexample,forconvolutionalkernels.
(R5)GuidanceandAbnormalityDetection— Userguidanceismentionedasausefulextensionbythedevelopers
tocoverthevastsearchspacethatasystematicmodelanalysisopens.Especiallytheautomateddetectionofcareless
mistakes,suchasaccidentallyapplyinganactivationfunctiontwiceafteralayer,isafrequentrequirement.
4 FORMALFRAMEWORKFORTHESYSTEMATICDEBUGGINGOFDLEXPERIMENTS
Severalfundamentalrequirementsandmechanismshavetobeconsideredtofacilitatethesystematicdebuggingof
deeplearningexperiments,whichwestrivetoformalizewiththeconceptualframeworkpresentedinthissection.The
frameworkprovidesguidelinesandservesasachecklistfordesigningsystemsforthedebuggingofdeeplearning
experiments.
Westructurethissectionbythetwosubstantialaspectsthathavetobeconsideredforthedesignofsuchasystem:
thevarioustypesofdataarisingindeeplearningexperiments(section4.1)andthenecessarymechanismsandvisual
ManuscriptsubmittedtoACM12 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
representationsrequiredtomakethisdataeffortlesslyaccessiblebythedeeplearningdeveloperduringdebugging
(section4.3).
4.1 CapturingtheDataSpaceofDeepLearningExperiments
Loggingqualitymetricsandmodelcheckpointsisinsufficientforeffectivemodeldebugging.Thus,wedefine
thedataspaceofamachinelearningexperimentasalldataarisingduringthemachinelearningworkflowand
classifythisdataaccordingtoitsorigin,dimensionality,andvariabilityovertimeintofourmaincategories:
Summary
structuraldata,scalardata,high-dimensionaldata,andfunctions.Thisclassificationbuildsthefoundationof
Sec.4.1
ourconceptualframeworkbyformalizingthedatathatshouldbemadeavailabletothedeeplearningdeveloper
duringdebugging.
Theassessmentofmodelqualityandtrainingprogressionisusuallybasedonqualitymetricsloggedduringthetraining
process.Togetherwithmodelcheckpoints,whichencodethemodelinstanceatacertainpointforlateruse,they
formtheentiretyofdatabeingtypicallyloggedduringmachinelearningexperiments.However,wearguethatfor
systematicmodeldebugging,variousotherdataarisingintheDLworkflowisrelevantandshouldbeconsideredduring
theanalysisphase.
Therefore,extendingthedatatermusedinthemachinelearningcommunity,usuallyreferringtothesolein–and
outputdata(whichwewillrefertoasdataset),wedefinethedataspaceofadeeplearningexperimentasfollows:
Wedefinethedataspaceofadeeplearningexperimentastheentiretyofdataarisinginadeeplearning
Definition
experiment.Adeeplearningexperimentdenotestheentiremodelbuilding,diagnosis,andrefinement
DataSpaceof
workflowovermultiplemodeliterationstosolveaparticulartask.
DLExperiments
Thisdatacanbecategorizedaccordingtoitsorigin,dimensionality,andvariabilityovertime.Additionally,weclassify
thedataintothecategoriesstructural,scalar,high-dimensional,andfunctions.Inthefollowing,wegiveadetailed
characterizationofthosecategories,buildingthefoundationforourproposedframework.Table1providesanoverview.
(D1)Structural(𝐺 =(𝑉,𝐸))— Dataentitiesthatlogicallyformagraph.Thegraphstructurecanbeeitherinherentto
thedataororiginatefromthetemporalevolutionofitsentities(cf.afamilytree).Followingthisdefinition,thereare
primarilytwosourcesofstructuraldataintheMLworkflow,onebeingtheevolutionofmodelsovertimeandtheother
beingthearchitecturalgraphofeachmodel.
(D1.1)TreeofModels— Startingfromaninitialarchitecture,theiterativediagnosisandrefinementprocesswilllead
toever-newmodelgenerationswithslightmodificationscomparedtotheancestorgeneration.Addressing(R1),we
proposetomodelthisprocessasadirectedgraph,withnodesrepresentingmodelarchitecturesandlinksindicating
aparent-childrelationship.Itshouldbenotedthatthisgraphdoesnotalwaysstriclyformatreesincedesirable
characteristicsofmultiplemodelsintheancestorgenerationmightbemergedintoanewarchitecture,embodying
multipleinheritance.
(D1.2)ArchitectureGraph— Thearchitecturegraphrepresentstheorderofoperationsappliedtodatawhileflowing
throughthemodelasadirectedgraph.Thisgraphrepresentation,targeting(R3),canbeofvaryinggranularity;typically,
nodesencodethebuildingblocksmodernMLframeworksofferformodelbuilding,suchaslayersorfunctions,while
linksindicatethedataflowbetweennodes.
Structuraldataisconsideredconstantovertime.Whilethisassumptionseemsevidentforthearchitecturalgraphofa
model,itmightatfirstbecontra-intuitiveforthetemporalevolutionofmodels.However,thedifferentarchitectures
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 13
Category Domain Sub-category Variability Examples
TreeofModels constant —
Structural(D1) 𝐺 =(𝑉,𝐸)
ArchitectureGraph constant —
Hyperparameters constant BatchSize
Scalar(D2) R
Metrics variable Loss,Accuracy
In–andOutput Time-Series(1D)
constant
(∼Dataset) Images(2/3D)
𝑛-dimensional(D3) R𝑛 Bias(1D)
Weights variable
DenseKernel(2D)
Activations variable —
Reshape
Structural constant
Concatenate
Function(D4)
c.f.,ArchitectureGraph
R𝑛 →R𝑛
Convolution
Mathematical constant
ActivationFunction
Table1. Overviewofthedifferenttypesofdataarisinginthedeeplearningworkflow,eachhavingdifferentdomains,origins,and
instantiations.Ifthedataischangingduringtrainingitiscategorizedasvariable,otherwiseasconstant.
couldhavebeendeterminedsincethebeginningoftheexperiment.Theydonotdependontraining,nordoindividual
nodeschangeovertime.Therefore,weconsiderthetreeofmodelsfinalunderthemostrecentmodeliteration.
(D2)Scalar(R)— Realnumberdescribingthemodelconfiguration(hyperparameters)orthemodelstateatasingle
pointintime(metrics).
(D2.1)Hyperparameters Learningrateorthebatchsizeareaformofscalardatadescribingpropertieswhichsignifi-
cantlyinfluencetheperformanceofthemodel,despiteneitherbeingpartofthearchitecturenorthetrainedinstance.
Theyare(usually)onlydefinedonceand,therefore,consideredconstantovertime.
(D2.2)Metrics Accuracyandloss(R2)aretypicalrepresentativesofthiscategory.However,otherscalardescriptors
mightberelevantfordebugging,suchasamodel’sexecutiontimeoritsmemoryconsumption.Metricsareconsidered
variableovertime,i.e.,changingthroughoutthetrainingprocess.
(D3)High-Dimensional(R𝑛 )— Vectorsormatricesrepresentinghuman-interpretable,butalsoabstractdataentities.
For example, visual representations of image data can be readily understood by humans, whereas abstract data
distributionsmightrequiretransformationsortargetedvisualizationstomakethemapproachablebyahuman.High-
dimensionaldatacovers(R4).Itoftenconsistsofseveralthousandindividualvaluesandthereforeplaceshighdemands
onstorage,memory,andcalculations.InthecontextoftheDLworkflow,wedistinguishdifferentsub-categoriesof
high-dimensionaldata,dependingontheirorigin:
(D3.1)In-/Output— Datathatisfedintothemodelormatchedagainstthemodeloutput.In–andoutputdata
describeeithersinglesamplesoraggregationsusedformodeltrainingand–inference.Itisconsideredconstantover
time,sincetheindividualsamplesdonotchangeduringtraining.In–andoutputdatais1to𝑛-dimensional.Examples
includetimeseries(1D)orimages(2/3D).
(D3.2)Weights— Datathatisinherenttothecurrentnetworkinstance.Werefertoweightsasallthenetworkvariables
thatarelearnedduringthetrainingprocess.Therefore,theyareconsideredvariableovertime.Thedimensionalityof
ManuscriptsubmittedtoACM14 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
weightscanrangefrom1D(e.g.,biases),over2D(e.g.,densekernels)to𝑛D(e.g.,convolutionkernels).Theirvaluesare
ofteninitializedaccordingtoacertainstrategy,e.g.,bysamplingfromaGaussiandistribution.
(D3.3)Activations— Data that is dependent both on the network instance and the network input. Specifically,
activationsaretheresponseofeachnetworkentityunderthedatafedthroughthenetwork.Sinceactivationscombine
inputdataandweights,theychangeoverthetrainingprocessofthenetworkand,therefore,areconsideredvariableover
time.Activationscanbehuman-interpretablebydefault(e.g.,inconvolutionalnetworks)orabstract1to𝑛-dimensional
distributions(e.g.,densenetworks).
(D4)Function(R𝑛 →R𝑛 )— Mappings between number ranges or matrix shapes. Functions can be seen as the
elements forming the architecture graph. A function’s output is only dependent on its input; thus, functions are
consideredconstantoverthetrainingtime.Intermsofneuralnetworks,wedistinguishtwosub-categories:
(D4.1)StructuralFunctions— Functionsthatmodifytheshapeorstructureofdataentitieswiththeprimarygoalto
renderthemcompatiblewithmathematicalfunctions.Examplesincludeconcatenationorreshaping.
(D4.2)MathematicalFunctions— Mathematicaloperations,mappinganinputtoaspecificoutput.Regardingneural
networks,manymathematicalfunctionstakelearnedweightsasadditionalparameters.Theweightsareiteratively
adjustedduringtrainingtomakethefunctionresultsresemblethetrainingdatadistributionascloseaspossible.
Examplesincludematrixmultiplications,convolutionoperations,oractivationfunctions.
Whilethevariabilityofeachoftheintroduceddatacategoriesmightatfirstseemsecondary,itisfundamentalforthe
conceptualframeworkwederiveinthefollowing.Particularly,(1)constantdataentitiescanbeusedasabackbonefor
variabledataand(2)wedonothavetoresolvetheprogressionoverthecourseoftrainingwhenvisualizingthem.
4.2 StructuringDesignDimensionsforRepresentationandInteraction
Toprovidethenecessaryflexibilityforageneral-purposedebuggingframework,weproposeamodularapproachfor
creatingdebuggingcomponents.Adebuggingcomponentisauser-interfaceelementvisualizingoneofthediscussed
Summary dataentities.Guidingthedesignofdebuggingcomponents,wederivedifferentaspectsandconstraintsthathaveto
Sec.4.2 beconsideredtomakedataaccessibletotheuserduringthedebuggingprocess,calleddesigndimensions.Overall,
weidentify6designdimensionsthatinfluencetheinstantiationandappearanceofadebuggingcomponent.
Adebuggingcomponentisamodularuser-interfaceelementvisualizingoneofthediscusseddataentities.Following,
wedescribehowadebuggingcomponentisinstantiatedandwhichdimensionsinfluenceitsappearance.
Besidesthepreviouslycovereddataspace,thesystematicdebuggingofDLexperimentsinvolvesvariousother
dimensions.Table2givesanoverviewofthosedimensions,includingtheircharacteristicsandprovidingexamplesfor
each.Dependingontheusecaseandtheindividualmachinelearningworkflow,otherimportantcharacteristicsmay
arise,complementingthepre-identifiedaspects.Inthefollowing,ashortdescriptionofeachdimensionisgivento
substantiatethedimensionsandtheircharacteristics.
4.2.1 DesignDimensionsforDataRepresentationandInteraction.
(I1)Task— Thegoaloftheanalysisand,thereby,thedebuggingprocess.Theanalysistaskisstronglyrelatedtothe
underlyingmachinelearningtask,i.e.,thetaskforwhichthemodelisdesigned.Forexample,inasettingwherehigh
classificationaccuracyisdemanded,modelassessmentmightbetheprimaryanalysistask.Incontrast,ifthemodel
isdesignedtobeusedinasecurity-criticalenvironment,formalverificationwilllikelybeofabsolutepriority.The
analysistaskisalsoinfluencedbythestageofthemachinelearningworkflow.Usually,multiplearchitecturesare
comparedagainsteachotherduringtheinitialmodelselection,focusingonmodelassessmentand–comparison.Ina
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 15
Dimension Characteristics Examples
Data Seesection4.1,“CapturingtheDataSpaceofDeepLearningExperiments”.
Assessment Assessmodelquality
Verification/
Task(I1) Verifythatmodelbehaviorfollowshumanintentions
correctnesscheck
Comparison Comparearchitctures
Multi-model Modelchangetracking
Levelof Singlemodel Qualitymeasures
abstraction(I2)
Layers/Units Distributions
Weights/Neurons Activationmaximization,deepdream
None(raw) Images,text,scalars
Transformation Re-shaping,projection
Processing(I3)
Aggregation Binning,clustering
Statisticaldescriptors Variance,min,max,densityestimation
Visualization Charts,histograms,images
Representation(I4)
Verbalization Text,tables
Dataset Image,text,categorical
Dependencies(I5) Model Feed-forward,recurrent
Layer Dense,covn.,operation
Table2. Thedesigndimensionsinfluencingappropriatedatarepresentations.Despitethembeingmostlyorthogonaltoeachother,
dependenciesmightariseupontheircombination.Forexample,whilebinnedvaluescouldberepresentedthroughvisualizationor
verbalizationandcouldbeusedforassessmentorcomparison,theycanneverbeappliedtostructuraldata.
laterstage,whentherougharchitectureisfinishedandshouldbefine-tunedonthemachinelearningtask,correctness
checkingisneededtoverifyifthemodelbehavesaccordingtohumanintention.Forexample,localXAImethods
mightbeusedinthisstage,ordistributionsinthelatentspaceofthemodelcouldbeinvestigated.
(I2)LevelofAbstraction— Thegranularityinwhichthemodelisinspected.Thelevelofabstractionstronglydepends
onthestageofthedebuggingprocess.Inthebeginning,anoverviewovermultiplemodelsmightberequired,e.g.,to
assessandcomparetheirperformance.Then,excitingdetailslikeabnormalitiesintheirarchitecturesorahighlosscan
betrackeddownintosinglemodels.Foranevencloserdebugging,architecturaldetailsorkerneldistributionsofsingle
layersmightbeobservedtounderstandwhereaparticularmodelbehaviororiginates.Finally,forhighlyspecialized
usecases,evenaninspectionofsingleneuronsorweightsmightbeneeded,e.g.,toassesstheperformanceofpruning
strategiesorbyusingadvancedXAItechniques,suchasactivationmaximizationwithadeepdreamapproach.
(I3)Processing— Transformationstobringdataintoahuman-readableformatandreducestorage–andcompuational
complexity.Forexample,aweightmatrixconstitutesanabstractdatadistribution,beingopaquetoahumaninitsraw
formand,therefore,requiringappropriateabstraction.Usually,relevantfeaturesshouldbepreservedandemphasized
whilereducingthetotalamountofdata,whichstronglyrelatestotheanalysistask:iftheanalystisonlyinterestedin
therangeofvaluesintheweightmatrix,minimumandmaximumasstatisticaldescriptorsalreadyfulfilltheanalysis
ManuscriptsubmittedtoACM16 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
Scalar High-D imensional Assessment Statistical Descriptors Transformation
MNIST Dense (Skip Connections) C
Structural Data Functions Comparison Task Verification Aggregation Processing Raw om
p
Priority 1 Priority 2
(R i.e ep
.,
r Ve
G
is
sr
ue
a
an
p
lt
ih
za at ti io on n:
)
TrP ar no sc foe rs msi an tg io:
n
M baN b9I 8S 7T
3
5D -e dn 1s 1e
9
-( 42 30 30 d, -1 a0 80 9)
3-08232533973e
0 M9 N99 Ia S5 T1 f C-5 o1 n1 v4-471a-8322-9fa40ae60387 on en
t In
stan
Data: Alternative 1 Constraint 2.1 c3f60635-72e1-4fc6-9271-0a5eb551eca4
ce
1
Task: Level of Abstraction:
Architecture
Comparison 3 - Multi Model
(i.e., Structural) Alternative 2 Constraint 2.2 C
om
p
Constraint 1
Re Vp er re bs ae lin zt aa tit oi non:
P DSr eo
t
sac cte
ris
is pts
i
tci on
a
rg
l
s: on
en
t
In
stan
3 - Multi- M 2o -d Se il ngleL e Mv oe dl
e
o lf Ab
1
s
-
t Lr aa yec rt si o
/
n Units0 - Neurons / Weights Visualiza At uio gn meR ne tap tir oe nsenta Rt ui lo e-n baseV derbalization ce
2
Fig.2. Anexemplaryinstantiationofadebuggingcomponent.Theuserselectscharacteristicsforpreferreddimensions,possibly
constrainingotherdimensions.Eventually,alldimensionsaredeterminedbyiteratingthisprocess,andthecomponentcanbecreated.
goal.Ideally,theappropriateprocessingtransformsthedataintoaformatthatdirectlyanswerstheanalysisquestion
(e.g.,minormaxtoassessthevaluerange),isinherentlyinterpretablebyahuman(e.g.,imagesortext),orconforms
withthehuman’smentalmodelofthedata.Forexample,thedistributionoflatentactivationscouldbeaggregated
usingbinning,tellingthehumanifthedatadistributionfollowshisintuitiononhowthevaluesshouldideallybe
distributedinthelatentspace.
(I4)Representation— Howthedataispresentedtotheuser.Theidealrepresentationdependsonvariousfactors,
suchastheanalysistaskorthekindofdata.Furthermore,humanperceptionplaysanessentialrole:datatypesthat
areinherentlyinterpretablebyahuman,suchasgraphsorimages,benefitfromavisualrepresentation,whiletextor
tabulardataareideallyrepresentedasverbalization.
(I5)Dependencies— Somedebuggingtechniquescomewithlimitationsregardingtheirapplicability,referredtoas
dependencies.Thecharacteristicsoftheotherdimensionsdeterminethedependencies;therefore,theyformaninferred
dimension,denyingdirectusercontrol.Forexample,adatasetdependencyarisesupontheinspectionofactivations,
whichonlyexistsunderinputdata.Thiscontrastswithaninspectionof,e.g.,themodelarchitecture,whichalready
existsatdesigntimeand,therefore,isdatasetagnostic.Otherinspectionsmightonlyapplytoaspecifictypeofmodel
orlayer,formingmodel–orlayerdependencies,respectively.ExamplesareinvestigatingtimestepsinRNNsorthe
image-basedinspectionofconvolutionkernels.
4.2.2 CombiningDesignDimensions. Tocombinetheidentifieddimensionsintoanoverarchingguidelineforthe
systematicdebuggingofmachinelearningexperiments,weproposeasystematizationbasedondebuggingcomponents.
Adebuggingcomponentisamodularuser-interfaceelement,givinginsightsintooneofthediscusseddatacategories.
Toinstantiateadebuggingcomponent,oneormultipleidentifieddimensionsmustbesettoaparticularcharacteristic,
determiningitsfinalappearance.
Aclassiclinechart,showingthedevelopmentofthelossoverthetrainingtime,isadebuggingcomponent
combiningthefollowingcharacteristics:
Example
Debugging Data Task LevelofAbstr. Processing Represent. Dependencies
Component
Scalar Assessment SingleModel Raw Visual None
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 17
Ourproposedframeworkdescribesthecreationofdebuggingcomponentsasamodularapproach,comparableto
choosingelementsfromatoolboxandcombiningthem.Typically,theuserhasclearpreferencesonwhichaspectsthe
debuggingprocessshouldfocus.Bychoosingcharacteristicsforpreferreddimensions,theusercannarrowdownthe
appearanceofthedebuggingcomponent.Thisprocessmustbeiterateduntilalldimensionsarefixedbytheuserorby
constraintsarisingfromcombinationsofalready-defineddimensions.Therefore,withincreasingspecificity,moreand
moreoptionswilleitherbefixedorget“greyedout”,untilalldimensionsaresettoaparticularvalue,determiningthe
finalappearanceofthedebuggingcomponent.
Figure2showsanexemplaryinstantiationofadebuggingcomponent,followingthedescribedprocess.Initially,
noconstraintsarepresent,andtheusercanfreelydeterminehispreferreddimensions.Thedatadimensionissetto
structuralintheexamplesincetheuserwantstoassessthemodelarchitecture.Next,comparisonissetasthetask,
whichinfersthefirstconstraint:foracomparison,multiplemodelsmustbeconsideredsimultaneously.Therefore,a
degreeoffreedomisremovedinthelevelofabstractiondimension,automaticallyinferringthemulti-modellevel.
Therearestilldegreesoffreedominthedimensionsrepresentationandprocessing.Theusercannowdecidebetween
avisualandaverbaldatarepresentation,whichinbothcasesautomaticallyconstraintstheprocessingdimensionto
transformationorstatisticaldescriptors,respectively.Thisleadstoalldimensionsbeingfixed,fullydetermining
thedebuggingcomponent’sappearanceandallowingitsinstantiation.
4.3 NavigatingtheDataSpacethroughGlobalMechanisms
Complementingthedesigndimensionsthatdeterminetheappearanceofadebuggingcomponent,weproposea
setofglobalmechanismstonavigatethedataspace.Themechanismsaresuggestedfunctionalitiesasystemfor
Summary debuggingDLexperimentsshouldprovide.Thesemechanismssetourframeworkapartfromexistingdebugging
Sec.4.3 systemsbyproposingacomprehensivewaytolocateentitiesofinterestandaccesstheirunderlyingdatathrough
them.
Existingsystems,suchasTensorBoard,treattheloggeddataasindependententitiesthatarenotconnected
toeachother.E.g.,onetabshowsthearchitecturegraph,anothertabshowsscalars,andathirdtabshows
images.Incontrast,ourframeworkleveragesthenaturalconnectionbetweentheentities.E.g.,models
Example
arecomposedoflayers,whicharecomposedofkernelsandoperations.Trainingmetricsarerelatedtoa
GlobalMechanisms
model,activationsarerelatedtolayers,andweightsarerelatedtokernels.Therefore,ourframeworkuses
vs.ExistingSystems
thearchitecturegraphtonavigatetotheentityofinterest,e.g.,aconvolutionallayer.Fromthere,theuser
canaccessthelayer’sweightsandactivationsbyapplyingtoolstothem,revealingtheirunderlyingdata.
Inthefollowing,weidentifyglobalmechanismswhichtheanalysistoolchaincanimplementtomakethepreviously
structureddataspaceexplorablebythemodeldeveloper.Althoughthesemechanismsshouldareconsideredindependent
ofeachother,theybecomeparticularlyeffectiveincombination.Figure3showsanoverviewofthemechanismsand
howtheyworktogethertonavigatethespace.
(M1)UnitsofAnalysis(UoA)— Thedataspacehastoberecursivelysegmentedintologicallycompletesubcom-
ponents,makingthemaccessiblebytheanalyst.Forexample,dependingontheanalysistask,theanalystmightbe
interestedinasinglemodel,aspecificlayer,orevenasingleneuronofamodel,representingunitsofanalysisof
differentgranularity.Analogously,suchunitsofanalysiscanbedeterminedforthemajorityoftheidentifieddata
categoriesandsub-categories.
ManuscriptsubmittedtoACM18 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
(M2)StructuralBackbone— Linkingabstractdatatoreal-worldentitiesfacilitatesintegrationintotheanalyst’s
mentalmodel.Forthis,structuraldatacanbeusedasabackbone,providingaccesstounitsofanalysisinanavigablegraph
representationoftheabstractdataentities.Besidesthevisualrepresentationofthemodelarchitecture,whichisprevalent
inexistingtools[TensorBoard2020]andrelatedworks[Krizhevskyetal.2017;LeCunetal.1989;Wongsuphasawatetal.
2018]andtrackingofmodelsinversioncontrolsystems[Kuprieievetal.2022],ourframeworkproposestoadditionally
visualizetheevolutionofthemodelsthemselvesinatree-likestructure,offeringapowerfultoolformodeltrackingand
changeanalysis.
Forexample,ananalystmightwanttodebugavisionmodelbyapplyingLRP[Bachetal.2015]toits
Example layers.Henavigatestothemodelandlayerofinterest(∼unitofanalysis)bydescendingintoavisual
ApplyingToolsto representationofthemodel’sarchitecture(∼structuralbackbone).Fromthere,hecanapplytheLRPtool
UoAs tothelayer,lettinghimselectaninputsampleandautomaticallyvisualizetheresultingsaliencymap.
(M3)LevelsofAbstraction— Theelementsofthestructuralbackboneinherentlyformahierarchy,i.e.,someunits
aresub-componentsofotherunits.Thishierarchyisimplementedinourframeworkasdifferentlevelsofabstraction.
Theanalystcangofromoverviewtodetailsbynavigatingovertheselevelswhilekeepingtheglobalcontext.For
example,iftheanalystisinterestedinaspecificfilterkernelofaconvolutionoperation,thegraphcanbenavigated
overnamespaces,layers,andoperationsdowntothekernelofinterest.
(M4)Search(Highlighting)— Thevastdataspacespannedbymachinelearningexperimentsrenderssearchmecha-
nismsimperative.BysearchingforcertainUoAtypesand,subsequently,highlightingtheminthestructuralbackbone,
entitiesofinterestcanbeeffortlesslyspottedandtrackeddown.Forthis,thehighlightshavetopropagatethroughthe
structuralbackboneuptothehighestlevelsofabstraction.E.g.,bysearchingforconvolutionalanddenseoperationsand
propagatingtheresultsuptothetreeofmodels,theanalystcaneffortlesslydistinguishbetweendenseandconvolutional
modelarchitecturesasanentrypointtotheanalysis.
(M5)Interestingness— Complementingthesearchmechanism,whichhelpstolocatedatawhoseshapeisknown
beforehand, interestingness detection can point the user to irregularities in the data [Geng and Hamilton 2006],
covering(R5).Forexample,theanalystmightbeinterestedinkernelswhosedistributiondivergessignificantlyfroma
baseline.Interestingnessmeasurescouldidentifysuchentitiesasabnormalandpointtheusertothecorresponding
unitofanalysis.Automatedinterestingnessdetectionisessentialsincemanualannotationisnotfeasibleduetothe
largeamountofdatatocover.
Analogoustotheacceptedclassificationsofinterestingnessmeasuresinthecontextofdatamining[GengandHamilton
2006;Sharmaetal.2020],weprovidethefollowingdefinitioninthecontextofdebuggingneuralnetworks.
Inthecontextofdebuggingneuralnetworks,wedefineinterestingnessasaquantifiablemeasureof
abnormalityinthedata,describedasthedeviationfromaspecifiedbaseline.Dependingonthe
Definition
typeofentitywhoseinterestingnessismeasured,thebaselinecanbeafixedvalue,adistribution,ora
InterestingnessinDL
ruleset.Thebaselinecaneitherbeinferredfromthedatadomain(objective),learnedfromotherdataor
Debugging
agroundtruth(subjective),ordefinedbytheusers(user-defined).
Inthefollowing,weprovideexamplesofinterestingnessmeasuresinthecontextofdebuggingneuralnetworksto
concretizetheprovideddefinition.
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 19
(M4) (M5) (M2) (M6)
(M1) (M6) (M7)
Fig.3. Overviewoftheglobalmechanismstonavigatethedataspace.Thestructuraldataprovidesabackbonefornavigationover
multiplelevelsofabstraction.Entitiesofthestructuraldataarereferredtoasunitsofanalysis,whichcanhavemultipledebugging
componentswithdifferentcharacteristicsattached.Interestingnessmeasuresandfiltersguidethroughthestructuralbackboneto
relevantunitsofanalysis.
Neuralnetworksaretypicallycomposedofpre-definedbuildingblockscombinedinaspecificorder,such
aslayersoroperations.Forexample,aconvolutionallayermightbefollowedbyapoolinglayerin85%of
Example
itsoccurrencesinadataset,whileareshapelayermightbefollowedbyanotherreshapelayerinonly2%
Deviationfrom
ofitsoccurrencessinceitsemanticallydoesnotmakesense.Fromthisobservation,arulecanbelearned
LearnedRule
thatdefinestheexpectedorderofoperations,assigningahigherinterestingnesstothesecondexample.
Theweightsofaneuralnetworkaretypicallyinitializedaccordingtoaspecificstrategy,e.g.,bysampling
Example
fromaGaussiandistribution.Aweightthatdeviatessignificantlyfromtheinitialdistributionduring
Deviationfrom
learningmightindicateaprobleminthetrainingprocess,e.g.,anexplodinggradient.
ObjectiveDistribution
(M6)AppropriateDataRepresentation— Onlyasmallshareofthedataarisinginmachinelearningexperimentsis
inherentlyinterpretablebyhumans.Often,thedataencodescomplexrelationships(e.g.,graphs),isofhighdimensionality
(e.g.,kernels),orofabstracttype(e.g.,timeseries).Therefore,processingandrepresentationhaveagreatimpactonthe
accessibilityofthedata.Ideally,thedatarepresentationhelpstheuserfocusontherelevantdetailswhileinsignificant
orredundantinformationisdiscarded.Furthermore,therepresentationshouldbetargetedtowardshumanperception.
Forexample,humanshaveanintuitiveunderstandingofimagesandtext;incontrast,makingsenseofaseriesofsensor
valuesisinherentlycomplicated.
(M7)ComparativeAnalytics— Comparingdataacrossdifferentunitsofanalysisisafundamentalusecaseinthe
debuggingworkflow,allowingtheanalysttoevaluatethemagainsteachotherorreasonoverabnormality.Therefore,
itisessentialtoenabletheconcurrentinspectionofmultipleUoAs,e.g.,byimplementingside-by-sideviews.Inthis
scenario,multipledatarepresentationsfromremoteunitsofanalysismightbesimultaneouslyvisible,e.g.,when
comparingtwolayersoriginatingindifferentmodels.Therefore,navigationalpatternsforretrievingtheunderlying
unitofanalysishavetobeprovided,allowingtheusertojumptoadebuggingcomponent’srespectiveunitofanalysis.
ManuscriptsubmittedtoACM
)3M(20 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
Fig.4. TheiNNspectorfrontend.Itisbuiltaroundtheinspectionpanel(a),showingnodes(a1)andlinks(a2)ofthestructural
backboneonthecurrentlevelofabstraction.Theminimap(b)helpstonavigatetheviewport.Tools(c1)fromtheToolbox(c)canbe
appliedtounitsofanalysisinthestructuralbackbonetocreatewidgets(d1),showingunderlyingdata.Widgetsarearrangedinthe
widgetpanel(d),wheretheyareorganizedaccordingtotheirlevelofabstraction.Semanticallyrelatedwidgetscanbecombined
intogroups(d2).Widgetsshowingclass-dependantdatacanbeconstrainedtocertainclassesusingtheglobalclassselector(e).The
localizationandinterestingesspanel(f)providestoolstoidentifyunitsofinterest.
5 THEINNSPECTORSYSTEMFORSYSTEMATICMODELDEBUGGING
Materializingthebefore-proposedconceptualframework,wepresenttheiNNspectorsystemforsystematicmodel
debugging.Morethantwoyearsofconceptualideasandimplementationworkhavegoneintothesystem.Thesystem
isdrivenbythreeprimarycomponents:thecustomkerascheckpoint,collectingdataforiNNspectorduringtraining,
thebackend,providingthedataoftheexperimentsviaRESTAPI,andthefrontend,providingtheactualiNNspector
userinterface.
5.1 ApplicationWalkthrough
Inthefollowing,wegiveadescriptionoftheiNNspectorinterfaceanditscomponentsintheformofanelaborate
applicationwalkthrough.Thereby,weillustratehowiNNspectormeetsitsclaimofbeingacomprehensivesystem
facilitatingthesystematicdebuggingofDLmodels.Byconsequentlylinkingsystemfeaturestotherespectivedata
category(seesection4.1),designdimension(seesection4.2),andglobalmechanism(seesection4.3),weshowhowthe
systemdesignisanchoredintherequirementsanalysis(seesection3)andthefoundationscompiledintoourconceptual
framework(seesection4).
InspectionPanel— iNNspectorisbuiltaroundacentralgraphview,referredtoasinspectionpanel(figure4a).It
visuallyrepresentsthestructuraldataoftheexperiment,i.e.,thetreeofmodels,themodel’sarchitectures,andsubsets
oftheweight-neuronnetwork.Thus,itimplementsthestructuralbackbone(M2)andbuildstheprimarycomponent
tolocateunitsofinterest(M1)overdifferentlevelsofabstraction(M3).Startingwiththemultimodelview(5.1,L3),
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 21
(a)Firstexperiment,with3models. (b)Secondexperiment,with2models.
Fig.5. InspectionpanelonL3,‘Multi-model’.Experiment(a)hasthreemodelsandexperiment(b)two,eachmodelrepresentedbya
uniquecolor.Edgesdenoteparent-childrelationships,withtooltipsandedgewidthindicatingchangesbetweenmodelpairs.
showingthetreeofmodelsasitevolvedduringtheexperiment,thegraphcanbenavigatedtolowerlevels:bydouble-
clickingamodeland,subsequently,alayer,theusercandescendoverthesingle-model-view(5.1,L2)downtothe
neuron-weight-networkview(5.1,L1).Thefollowingparagraphsoutlinethespecificsandfunctionalitiesofeachlayer.
Multi-ModelView[L3]— Thehighestlevelofabstractionisthemultimodelview.ItshowsallmodelsintheiNNspector
system,groupedintoexperiments.Anexperimentdenotesaconnectedsubsetofmodels,i.e.,asubsetwhereeachmodel
sharesaparent-childrelationshipwithatleastoneothermodel.Figure5showstwoexperiments,thefirstconsistingof
three,thesecondoftwomodels.Eachexperimentissurroundedbyadashedoutline,whichformsaunitofanalysis
itself.Eachmodelisassignedacolorbasedonasequentialcolorscale,whichisre-usedbyotherpartsofthesystem
tomarkthepartasbelongingtoacertainmodel,e.g.,whendescendingintolowerlevelsofabstraction.Eachmodel
isdepictedbyabox,containingitsfriendlyname,whichissetbytheprogrammeratdevelopmenttime(see5.4.1,
“iNNspectorHeader”),itsuniqueID,andanabstractrepresentationofitsarchitecture.Eachtreeofmodelsisarranged
fromlefttoright,withtheleftmostmodelbeingtheinitialarchitectureanddescendantmodelsbeingrankedaccording
totheirdepthinthetree.Theedgesindicateaparent-childrelationship,whichisdefinedduringdevelopmenttime,
eithermanuallybytheprogrammerorbyautomaticallybranchingmodelsusingtheavailabletoolfromthetoolbox.
Thechangeintheedgewidthbetweenmodelsdenotestherelativechangeinthenumberoftrainableparameters,with
theabsolutevaluesbeingshowninatooltipwhenhoveringtheedge.
SingleModelView[L2]— Bydouble-clickingamodel,theusercandescendbyonelevelintothesinglemodel
view.Figure6showsthe(shortened)singlemodelviewoftheupperleftmodelvisibleinfigure5.Itprovidesagraph
visualizationofthemodel’sarchitecture,witheachboxrepresentingalayerofthemodelandtheedgesdenotingthe
dataflowbetweenlayers.Thedashedoutlinedenotesthemodelasawhole.Alllayersuniversallyshowtheirnamein
thetopleft,andtheirtypeandoutputsizeinthebottomleft.Additionally,layerscontainoneormultipleinnerelements,
encodinginformationspecifictotheirtypeandconfiguration.Theseinnerelementsformagraphonthemselves,which
representsthewaymathematicalfunctionsandvariablesaresubsequentlyappliedtothelayerinput.E.g.,thedense
layerinfigure6startswithamatrixmultiplication oftheinputwithakernel ,continueswithadding abias
,andfinallyappliesasoftmaxactivation totheresult.Thepictogramsgiveavisualimpressionoftherespective
operationorvariable,renderingthesystemusefulforlessexperiencedmodeldevelopersorforeducationalpurposes.
Additionally,operationsandvariablesareaugmentedwithinformationrelevantformodeldevelopment,suchasinput
andoutputshapes,kernelinitializers,orfiltershapes.
ManuscriptsubmittedtoACM22 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
Fig.6. InspectionpanelonL2,“SingleModel”.Theviewshowsthearchitectureofamodel,witheachboxrepresentingalayerand
theedgesdenotingthedataflowbetweenlayers.Elementsinsidethelayerboxesrepresentoperationsappliedtothelayerinput.
(b)Slidertosetthenumber𝑘
(a)Theneuron-weight-networkview. oftopweightstoshow.
Fig.7. InspectionpanelonL1,“Neuron-Weight-Network”.Theviewshowsthetop-𝑘mostsignificantsubsetofneuronsforboth
layers,accordingtotheirmeanactivationunderthecurrentclassselection.Theedgesbetweentheneuronsrepresenttheelementsof
theweightmatrixconnectingtwoneuronsthroughamatrixmultiplicationoraconvolutionoperation.
Neuron-Weight-NetworkView[L1]— Bydouble-clickingalayeronL2,theusercandescendtothefinallevelL1,
theneuron-weightnetworkview,ofwhichanexampleisshowninfigure7a.Likethenamesuggests,itfocussesonthe
weightsconnectingtheprevioustothecurrentlayer.Forthis,wevisualizeasubsetofneuronsforbothlayers,sorted
bytheirmeanactivationunderthecurrentclassselection(see5.1,“ClassSelectorPanel”).Theneuronsarecolored
accordingtoalinearcolorscale,mappingthelowestactivationtodarkblueandthehighestactivationtodarkred.
Edgesbetweentheneuronsrepresentthelargest𝑘weights,i.e.,theelementoftheweightmatrixwhichconnectsthe
twoneuronsthroughamatrixmultiplicationoraconvolutionoperation.Thevaluefor𝑘canbesetusingaslider,which
isshowninfigure7b.Sincethenumberofneuronsinalayercanquicklygrowtotheorderofseveralthousands,we
filterfortheonesthat(1)areconnectedthroughatleastoneofthetop-𝑘weights,or(2)featureeitheroneofthe10
highestor10lowestmeanactivations.Neuronsandedgescanbehighlightedbyhoveringorclickingthem,which
makesiteasiertoobservesingleconnectionsinlargenetworks.Besidestheactivationcolor,weaugmenttheneurons
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 23
(a)Neurons×Classespanel. (b)TheiNNspectortoolbox. (c)Anexemplarywidget.
Fig.8. Panels,tools,andwidgetsintheiNNspectorUI.(a)AL1-specificpanelshowingtheactivationofeachneuronwithrespectto
eachclass.(b)Thetoolbox,providingtoolstoinvestigateunitsofinterest.Thetoolscanbeappliedtocompatibleelementsinthe
inspectionpaneltocreatewidgets.(c)Anexemplarywidget,showingtheactivationofaneuronwithrespecttoeachclass.
withadditionalinformation,suchastheirrelativeandabsoluteshareofthesummedactivationscurrentlyviewed.
Furthermore,foractivationshavinganimage-interpretableformat(i.e.,two-dimensionalgrayscaleorthree-dimensional
coloscale),weshowtheirmeanactivation𝑐
𝑖
for𝑖 =0,...,𝑛−1forthe𝑛currentlyselectedclasses,aswellasanaverage
overtheselectedclassesavg(𝑐)= 𝑛1 (cid:205)𝑛 𝑖=− 01𝑐 𝑖.
Sincetheneuron-weight-networkcanonlyvisualizeasubsetofneuronsandweightsandalwaysaveragesoverthe
currentclassselection,weaugmenttheL1viewwiththeNeurons×Classespanel,showninfigure8a.Itprovidesa
matrixviewshowingtheactivationofeachindividualneuronwithrespecttoeachclassofthedatset,renderingit
especiallyusefulforthedebuggingoffailedclassificationsanddisentanglementoflatentspaces.Byclickingtheheader
ofaclasscolumn,allcolumnsarere-sortedaccordingtotheclickedclass,enablingcorrelationanalysisacrossclasses.
Notably,withdecreasinglevelofabstraction,thedataspacewehavetocovershrinkssignificantly.Therefore,more
datacanbeshownbyspecializedpanels(e.g.,Classes×Neurons)andthestructuralviewitself,reducingthenumberof
toolsthatareneededtoshowunderlyingdata.
Toolbox,Widgets— Thetoolbox(figure4c)providesavarietyoftoolstoinvestigateandannotateunitsofinterest,
extendthetreeofmodelsbynewmodelvariations,and–mostimportantly–visualizetheunderlyingdataofunits
ofanalysis.Eachtoolisrepresentedthroughasmallicon,which,whenhovered,offersadetaileddescriptionofthe
tool’sfunctionality,asdisplayedinfigure8b.Afterselectingatool,itstaysactiveuntilappliedtoaunitofanalysis,
e.g.,amodeloralayer.Thetoolsinthetoolboxresolveseveraldependencies(I5)bynarrowingtheirapplicabilityto
specificUoAtypesandlevelsofabstraction.E.g.,theHistogramtool,whichcreatesahistogramvisualizationofadata
distribution,canonlybeappliedtoUoAscomprisinghigh-dimensionaldata(D3),suchaskernelsoractivationsofalayer.
Inmostcases,applyingatooltoaUoAresultsinthecreationofawidget(figure8c).Awidgetoffersvisualorverbal
representations(I4)oftheunderlyingdataofaunitofanalysis.Thisdatacanbescalar(D2)orhigh-dimensional(D3),
renderingappropriateprocessing(I3)essential.Therefore,eachtooldefineswhichdatatoqueryandhowtotransform
thisdatabeforeforwardingittothenewlycreatedwidget.Thetransformationpipelineisexpressedasalistoftransform
operationsthatareconsecutivelyappliedbythebackendtothequerieddatabeforereturningthem.Thedataquerying
ManuscriptsubmittedtoACM24 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
Fig.9. TheiNNspectorwidgetpanel.Widgetsareorganizedaccordingtotheirlevelofabstraction.Theycanbegroupedbydragging
anddroppingthemontootherwidgetsorgroups.
mechanismsfollowastandardizedformat,makingthesystemeffortlesslyexpandablebycustomtool.Fortechnical
detailsonthedataqueryingroutesandthetransformationgrammar,seesection5.4.2.
Weprovideacomprehensivesetofpre-definedwidgets,supportingavarietyofusecasesandanalysisscenarios.
Thewidgetscanbeclassifiedintothreegroups:(1)generalizingrepresentations,(2)data-specificrepresentations,and
(3)functional.Generalizingrepresentationsprovidetypicalchartsforcommontypesofdata.Whiletheysetstrict
conditionsontheformatofthedata,theydonotintroduceanyfurtherdependencies(I5).Forexample,weprovide
linechartsfortime-dependent,scalardataorbarchartsforsingle-timescalardata.Complementary,weofferdifferent
typesofhistogramsforhigh-dimensionaldata.Data-specificrepresentationsarechartsspecializedtoacertaintype
ofmodel,layer,ordataset.Forexample,forclassifiers,weincludeavisualizationoftheclassprobabilitydistribution,
whileforimage-to-imagemodels,wevisualizethedifferencebetweeninputandreconstruction.Bothonlyworkfor
thestatedtypeofmodel.Finally,functionalwidgetsdonotvisualizeunderlyingdataoftheexperiment,butprovide
informationformodelmanagementanddocumentationoftheanalysisprocess.Forinstance,theNotetoolcreatesa
widgetfeaturingamarkdowneditor,whiletheBranchModeltoolgeneratesanewiNNspectorheader,denotinganew
parent-childrelationshipinthetreeofmodels.FordetailsontheiNNspectorheader,refertosection5.4.1,“iNNspector
Header”.
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 25
(a)Groupofthreewidgets. (b)Merged.
Fig.10. iNNspector’swidgetgroupview.(a)Groupedwidgetscanbeopenedinadetailview,showingthemside-by-sideinan
enlargedpageoverlay.(b)Widgetsfeaturingcompatibledatacanbechosentoeitheruseacommonscaleorbemergedintoasingle
meta-widget.
Widgetscanbeextendedthrougharbitraryinteractions,e.g.,tofilterorexcludedataseries,orconstrainthewidget
toasubsetofUoAs.Particularly,thisincludeslinkingandbrushingofwidgetsandtheircontaineddataacrossall
componentsoftheiNNspectorsystem.See“LinkingandBrushing”formoredetails.
WidgetPanel— Widgetsareorganizedinthewidgetpanel,depictedinfigure9.Thepanelisimplementedasa
verticalaccordionUIelement,witheachaccordionflaprepresentingonelevelofabstraction.Upontheircreation,
widgetsareinsertedintotheflapoftheircorrespondingunitofanalysislieson,reflectingthestructuralhierarchy
alsointhewidgetpaneland,hence,helpingtheusertolocatesearched-forwidgets.Thiseffectcouldbeprovenin
ourevaluationstudy(seesection7.2).Topreventthecumulativeclutteringofthewidgetpanelduringtheadvanceof
theanalysisprocess,widgetscanbegroupedbydragginganddroppingthemontootherwidgetsorgroups.Besides
visuallysortingsemanticallyrelatedwidgets,groupsalsocanbeopenedinadetailview,showingthemside-by-sidein
anenlargedpageoverlay.Inthegroupview,depictedinfigure10a,widgetsfeaturingcompatibledatacanbechosen
toeitheruseacommonscaleorbemergedintoasinglemeta-widget.Scalingandmergingmakesthedatabetter
comparableacrossunitsofanalysis.Figure10bshowsthesamegroupasfigure10abutwiththewidgetsmergedintoa
singlemeta-widget.
LinkingandBrushing— Toemphasizeconnectionsbetweenrelatedentities,weconsistentlyimplementlinkingand
brushingoverallpartsofthesystem.Onthecomponentlevel,thisaffectslinksbetweenUoAs,widgets,andfilters.E.g.,
hoveringalayerinamodel’sarchitectureresultsinavisualhighlightofallwidgetsrelatingtothelayer,andviceversa.
Onthedatalevel,differentrepresentationsofthesamedata-pointordatasetsamplearelinkedacrossthesystem.E.g.,
whenhoveringtheprojectedactivationforacertaindatasetsampleinascatterplotwidget,thedatapointsrelating
tothesamedatasetsamplearehighlightedinallotherwidgets,enablinganinteractivecomparisonacrosslayersor
models.
ClassSelectorPanel— Theclassselectorpanellistsallclassesoccuringinthedataset,allowingtotogglearbitrary
classes. After modifying the class selection, all components of the system are updated to adhere to the selected
ManuscriptsubmittedtoACM26 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
(b)Minimap.
(c)Breadcrumbs.
(a)Classselector.
Fig.11. ConfigurationandnavigationpanelsiniNNspector.(a)Theclassselectorpanellistsallclassesoccuringinthedataset,
allowingtotogglethem.Theclassselectionaffectsthedataofallwidgetsinthewidgetpanelthatareclass-dependent.(b)The
minimapindicatestheviewportoftheiNNspectionpanel,guidingtheuserinlargeexperimentsormodels.(c)Breadcrumbsshowthe
pathtotheUoAcurrentlyfocussedintheiNNspectionpaneloverthedifferentlevelsofabstraction.
classes.Particularly,thisaffects(1)theappearanceoftheiNNspectionpanelonL1,constrainingthestructuraland
high-dimensionaldatadisplayedtotheselectedclasses,and(2)thedataofthewidgetsinthewidgetpanel.The
onlyexceptionsarewidgetsshowingdatawherethedatapointsarenotdirectlyassociatedtoaclass(liketheyare,
e.g., for activations), but which would still change under different classes (compared to, e.g., weights, which are
classindependent).Forsuchwidgetsand𝑛datasetclasses,wewouldhavetopre-computeandstore2𝑛−1possible
combinations.Anexampleforsuchawidgetiscreatedbythe“Performance-Metrics”-tool:metricslikelossoraccuracy
changeunderdifferentdatasetclasses,however,sincethosevaluesarecomputedattrainingtime,wewouldeitherhave
topre-computethedataforarbitrarycombinations,resultinginhugeruntimeandstorageoverheads,orre-evaluate
themodeljust-in-time,affordingaccesstothefulltrainingandtestingdataset,aswellasinformationonthecomputed
metrics.Wemarkthosewidgetswitha -symbolinthewidgetheader.
NavigationFunctionalities— Forefficientexplorationofthestructuraldataspace,weincludeadditionalfunction-
alitiesthathelptheusertokeepanoverviewandlocatethemselvesinthelevelsandgraphs.Aminimap,depicted
infigure11b,indicatestheviewportoftheiNNspectionpanel,i.e.,thesectionofthepanelthatiscurrentlyvisiblein
thebrowserwindow.Byclickingapointontheminimap,thevieportautomaticallycentersatthatposition,allowing
theusertoquicklyjumptoanareaofinterest,whichisparticullarlyusefulforlargemodelarchitecturesonL2.Besides
theminimapprovidingorientationinthex-y-plane,breadcrumbsshowthepathtotheUoAcurrentlyfocussedinthe
iNNspectionpaneloverthedifferentlevelsofabstraction.Figure11cshowsthebreadcrumbswhilehavingthelayer
“hidden_1”ofmodel“ts_mnist_dense_skip-connections”focusedonL1.Clickinganelementinthebreadcrumbpath
directlyteleportstheusertotherespectivelevelofabstraction.Asimilarfunctionalityisofferedbythe -buttoninthe
headerofallwidgets.Byclickingit,thesystemautomaticallyjumpstothelevelofabstractionandtheUoAthewidget
belongsto,regardlessofthecurrentposition.
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 27
(a)UoAtypesand–badges. (b)Interestingnesstypesand–annotations.
Fig.12. LocalizationandinterestingnessfunctionalitiesiniNNspector.(a)ThelocalizationpanellistsdifferentUoAtypesoccuringin
thecurrentlyvisiblemodels.Bytogglingthem,smallbadgesintheinspectionpanelindicatethelocationofrespectiveUoAsinthe
structuraldata.(b)TheinterestingnesspanelcolorsUoAsaccordingtotheirinterestingnessscores.
Localization— Thestructuralbackbone(M2)mightgrowtosignificantsizeanddepthforlargeexperimentsand
complexmodelarchitectures.Therefore,iNNspectorincludesapanelallowingtosearch(M4)forandlocatecertain
UoAtypesandarchitecturalstructures.Figure12ashowsasegmentofthelocalizationpanel,listingdifferentUoAtypes
occuringinthecurrentlyvisiblemodels.Bytogglingthem,smallbadgesintheinspectionpanelindicatethelocationof
respectiveUoAsinthestructuraldata.ForUoAshiddeninlowerlevelsofabstraction,badgesarepropagatedupwards
tothecurrentlevel,helpingtheusertotrackdownUoAsofinterest.BesidesUoAtypes,theusercanalsosearchfor
commonstructuresinthemodelarchitecture[Q.Wangetal.2019],suchasmulti-branches(c.f.,Inception,Szegedy,
Ioffe,etal.[2017])orskip-connections(c.f.,ResNet,Heetal.[2016]).
Interestingness— Complementingthefilters,whichworkexclusivelyonastructurallevel,weimplementautomated
interestingnessmeasures(M5)onadatadistributionlevel.Particularly,wecomputeavarietyofstatisticaldescriptors
overthehigh-dimensionaldata(D3),includingskew,variance,minimum,andmaximum,aswellasthedivergenceof
thedistributionshapefromdifferentbaselines.Theinterestingnesspanelinfigure12ballowstotogglethedifferent
descriptors,whicharethenvisualizedintheinspectionpanel.InterestingnessiscomputedperUoAonthelowest-level
wheredataoccurs,andthenpropagatedupwardsoverthestructuralbackbone.Sincethestatisticaldescriptorsare
onlycomparablewithinonevariabletype(i.e.,activation,densekernel,conv2dbias),wecomputethevaluesforeach
variabletypeseparately.Thevaluesarenormalizedandaggregatedoverlayersandmodels.Visually,weannotatethe
interestingnessbyre-coloringtheUoAsonalinearcolorscale,rangingfromblueforlowtoredforhighinterestingness
values.Interestingnesscandirectlypointtheanalysttoannomaliesinthedatawithoutthetedious,manualinspection
oflargepartsofthedataspace,providinganentry-pointtothedistributionanalyis.
5.2 DesignRationales
Throughoutourtwo-plus-yeardevelopmentprocess,wewentthroughvariousdesigniterationsuntilthesystem
reacheditscurrentform.Inthefollowing,wewillelaborateonthemoreprominentdesignrationalesthatshapedthe
iNNspectorfrontend.
Widgets— Asproposedbyourframeworkand,consequently,implementedbyiNNspector,weusethestructural
backbonetolocalizeUoAsandvisualizetheirunderlyingdata.Followingthisprincipleofconnectingabstractdatato
ManuscriptsubmittedtoACM28 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
semanticallyrelated,tangiblevisualrepresentatives,weattachedthewidgetsdirectlytotheirrespectiveUoAsinthe
firstversionofthesystem.WhilethisemphasizedtheaffiliationbetweenwidgetandUoA,wefoundseveralissueswith
thedesign.Forexample,theinterfacegotincreasinglycrowdedduringtheinspection,andtherewasnonaturalwayto
creategroupsofwidgets.Furthermore,thecloselinkbetweenwidgetandUoAwasadisadvantageforcomparative
tasksovermultiplelevelsofabstraction:wherewouldweputawidgetifitscorrespondingUoAisnotcurrentlyvisible
intheinspectionpanel?Therefore,wedecidedtoorganizethewidgetsinaglobalpanelandvisuallylinkthemthrough
labelsandcolors.Inourevaluationstudy(seesection7),ourusersreportedlikinghowwidgetsareorganizedinthe
widgetpanel.
GlobalClassSelector— Theclassselectorisimplementedasaglobalpanelinsteadofaper-widgetclassselection.
Inourdifferentdesigniterations,weexperimentedwithdifferentmechanismstoconstrainvisualizationstospecific
classes,advancingfromhavingnoclassselectionoverper-widget,single-classselectiontothecurrent,globalmulti-class
selector.Itbestsupportedthedebuggingofclassificationusecasesandpreventedconfusionwithaper-widgetclass
selectionwhencomparingacrossdifferentwidgets.
Toolbox— Thetoolboxisatypicalpatterninexistingsystems(e.g.,imageediting–orCADsoftware).Itprovides
astraightforwardandtidyinterfacetocomplexfunctionalities,iseasytolearnanduse,andcanadapttochanging
contextsbyonlyshowingthecurrentlyapplicabletools.
LevelsofAbstraction— Inthefirstiterationofthesystem,multipleinspectionpanelscouldbespawnedsimulta-
neously,eachofwhichcouldbeonadifferentlevelofabstraction.Throughthis,wetriedtoresolvethepreviously
discussedproblemofsimultaneouslyinspectingwidgetsindifferentmodelsandlevelsofabstraction,backwhenwidgets
werestilldirectlyattachedtotheirrespectiveUoAs.However,thisledtoalossofglobalcontextandcrowdedthescreen
withdifferentrepresentationsofthesamestructuraldata.Therefore,tokeepfocusedandpreservetheglobalcontext,
wemovedtostrictlyhierarchicalnavigationoverlevelsofabstraction.InthecurrentversionofiNNspector,navigation
overlevelsofabstractionfeelslikebrowsingthez-axiswhilezoomingandpanningcoverthex-y-plane.Inouruser
study(seesection7)weobservedthenavigationoverlevelsofabstractiontobeintuitivetotheusers.
5.3 DeveloperWorkflow
TheiNNspectorsystemisdesignedtobeeasilyintegratedintothemodel-buildingworkflow.Inthefollowing,wewill
describethestepsneededtobringanexperimentintotheiNNspectorsystem.iNNspectorprovidesaPythonpackage,
consistingofthreemaincomponents:(1)thecustommodelcheckpoint,providingtheloggingmechanisms,(2)several
pre-defineddatagenerators,implementingconveniencefunctionstoretrievethenumberofclassesandasubsetofthe
evaluationdataset,and(3)adatabaseconnector,providingmethodstostoreandloadthemodel’smetadatatoandfrom
themodeldatabase.
CreatingaModel— ThemodelcreationprocessissimilartotheoneinordinaryTensorFlow/Keras.Theonly
differenceisthatthemodelhastobeannotatedwithaniNNspectorheaderfunction(seesection5.4.1,“iNNspector
Header”).Thefunctionhastobecalledbeforetrainingthemodelandreturnsadictionarycontainingthemodel’smeta
information.
TrainingtheModel— Fortraining,aninstanceofthecustomizediNNspectorcheckpoint(seesection5.4.1,“iNN-
spectorCheckpoint”)hastobepassedasacallbacktothefitmethodofthemodel.Thecheckpointreceivesareference
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 29
tothedictionarycreatedbytheiNNspectorheaderfunctionandextendsitwithinformationonthelocationofthe
checkpointfilesandthegraphfile.
StoringtheMetadatatotheModelDatabase— Aftertraining,themodel’smetadatahastobeappendedtothe
modeldatabaseusingthedatabaseconnector.
CreatingNewModelIterations— Whenrefiningtheinitialarchitecturetogenerateanewmodeliteration,the
userhastocreateanewiNNspectorheader,denotingthenewmodelasachildofthepreviousone.Thiscanbedone
manuallyorbyusingtheBranchModeltool,whichautomaticallygeneratesanewiNNspectorheaderwiththeselected
modelasparent.
InspectingModelsintheUser-Interface— AfterstartingtheiNNspectorback-andfrontend,thestoredmodelsare
automaticallyloadedintothesystem.
5.4 SystemArchitecture&Implementation
TheiNNspectorsystemisdrivenbycustomloggingmechanismsandabackendprovidingaccesstothedataaccumulated
duringtraining.Inthefollowing,weprovideashortoverviewoverthesecomponentstoconveyanimpressiononhow
thesystemworksandwhichstepsittakestointegrateitintothemodelbuildingworkflow.
5.4.1 iNNspectorKerasLogs. WeprovidetwocustomcomponentstomakeordinaryTensorFlow/Kerasavailable
intheiNNspectorsystem.ThefirstoneistheiNNspector header,whichprovidesmetadataaboutamodel,andthe
secondoneistheiNNspectorKerasLog,whichmodifiesthedefaultcheckpointstoalsoincludeasubsetofthetesting
datasettogetherwiththecorrespondingactivationsforeachlayer.Inthefollowing,wewilldescribehowthosetwo
componentsworktogethertobringmodelsintotheiNNspectorsystem.
iNNspectorHeader— TheiNNspectorheaderisasmallcodeblockinthemodeldefinitionfileencodingthemodel’s
meta-informationinakey-valuestructure,suchasitsnameandparent-childrelationships.Listing1showsanexemplary
functiontogeneratetheheader.
Duringmodeltraining,theiNNspectorheaderisusedbytheiNNspectorloggingmechanismtocreateamodel
database.Besidesmetainformation,thedatabaseencodesinformationonthelocationofgraphfilesandcheckpoints,
valuesofperformancemetrics,andotherhigh-levelstatistics,suchasthenumberoftrainableparameters,memory
consumption,andcreationtimeofthemodel.Toreducemanualeffort,theBranchModeltoolautomaticallygeneratesa
newiNNspectorheaderwiththeselectedmodelasparent.
iNNspectorCheckpoint— TheiNNspectorcheckpointextendsthedefaultKerascheckpointbydatasetsamplesand
sampleactivations.Forthat,were-structuretheHDF5fileaccordingtothehierarchydiagrammedinfigure13.Dataset
def make_innspector_header():
return {
"id": "0999a51f-5114-471a-8322-9fa40ae60387",
"name": "ts_mnist_dense_skip-connections",
"label": "MNIST Dense (Skip Connections)",
"parents": ["bab98735-d119-433d-a893-08232533973e"]
}
Listing1. FunctiontogeneratetheiNNspectorheaderencodingamodel’smetainformation.
ManuscriptsubmittedtoACM30 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
iNNspectorCheckpoint
layers datasamples
layer0 ... layern x1 ylabel1 yprediction1 ...
activations1 meanclassactivations weights2
1.1:1relation
2.onlytrainablelayers
class0 ... classk bias3 kernel3 3.onlyifusedbylayer
Fig.13. HDF5-structureofiNNspectorcheckpointfiles.Westoreweightsandactivationslayerwise,whiledatasetsamples,their
labels(ifavailable),andtheirpredictionsarestoredgloballypercheckpoint.
samples(∼x),datasetlabels(∼y_label),andmodelpredictions(∼y_prediction)arestoredgloballypercheckpointin
thedata_samplesgroup,sincetheydonotchangeoverlayers.Incontrast,weightsandactivationshavetobestored
layerwise.Therefore,thelayersgroupcontainsanentryforeverylayerofthemodel,referencedbytheKeraslayer
name.Sinceactivationsandpredictionsarecomputedperdatasetsample,inputs,labels,predictions,andactivations
shareaone-to-onerelationship,reflectinginequalsizeoftheirfirstmatrixdimension.Furthermore,eachlayerstores
pre-computedaveragedactivationsfortheindividualclassesofthedataset(∼mean_class_activations).Thisavoids
thatthebackendhastorepeatedlyloadandaggregateallactivations,sincethisdataisfrequentlyrequestedbythe
iNNspectorfrontend.Layerswithtrainablevariablesalsohaveaweightsgroup,containingthevaluesofthelayer’s
kernel orbias,respectively.Itshouldbenotedthatstoringpre-computedactivationsmightnotbeviableforhuge
modelsormodelsfeaturingconvolutionswithlargeoutputsizesduetostoragesizeissues.Inthiscase,wewould
havetofallbacktoloadingandexecutingthesavedmodelinstanceontheflywiththedrawbackofhigherresponse
times.Togiveanestimate:forourthreeusecases,wetrainedeightimageclassificationmodelsandtenvariational
auto-encoderswithdifferentarchitecturesontheMNISTdataset.EachmodelhadeleveniNNspectorcheckpointssaved
overthetraining,resultinginanoverallsizeof≈70GB.
5.4.2 iNNspectorBackend. TheiNNspectorbackendexposesthedatastoredintheiNNspectorsystemoverdifferent
RESTAPIroutesforaccessfromtheiNNspectorfrontend.Itconstantlymonitorsthecontentsoftheloggingdirectory
andreloadsthemodeldatabaseuponchanges.TheAPIendpointscanbegroupedintothefollowingcategories:
ModelIDs Asingle GET -endpointreturningtheIDsofallmodelsinthedatabase.
ModelInfo Different GET -endpointstakingthemodelIDasaparameterandreturninginformationaboutthe
model,suchasarchitecturegraph,performancemetrics,oracatalogofcheckpoints.Allthisinformationisstored
inthemodeldatabase.
Checkpoints Different POST -endpointstakingthemodelIDandaJSONbodyasparameterandreturning(trans-
formed)valuesstoredin–andextractedfromcheckpoints,suchasweights,activations,orinterestingnessvalues.
TheAPIisbuiltusingFastAPI3andprovidesdetailedOpenAPI4documentation,accessibleunderthebackendURL.To
speeduprepeatedquerieswithsimilarparameters,wecacheresultsinRedisforlaterre-use.
3https://fastapi.tiangolo.com/
4https://swagger.io/specification/
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 31
DataTransformation— High-dimensionaldata(D3)necessarilyhastoundergotask-specificprocessing(I3)to
createhuman-interpretablerepresentations(M6).Therefore,allbackendroutesreturninghigh-dimensionaldatatake
anadditionaltransformspecification,allowingtoexpressarbitrarytransformationsthatshouldbeappliedtothedata.
Thetransformspecificationisdefinedinagrammarwhichallowsspecifyingalistofoperationsthataresubsequently
applied.ThoseoperationsmapfunctionalitiesofPandasandNumpyintoourgrammar.Furthermore,ourgrammar
providesproductionrules,allowing,e.g.,tobranchandmergedatacolumns.
Byusingtransformationstofilterandaggregatetherequesteddataaggressively,wecanmitigatetheissueswith
thehugesizeofsomehigh-dimensionaldataentities,facilitatingthesmoothexchangeofdatabetweenbackendand
frontendoverHTTPrequests.Thetransformationsallowustotradememorysizeforcomputationaleffort;combining
themwithcachingallowsustoutilizebothadvantages,leadingtoquickeroverallresponsetimes.
5.4.3 iNNspectorFrontend. Interfaceandfunctionalitiesofthefrontendaredescribedexhaustivelyinsection5.1.The
frontendisbuiltusingReact5andTypeScript6.ThemodularityenabledbytheReactframeworkandthestrongtype
systemenforcedbyTypeScriptallownewdeveloperstoquicklyfindtheirwayaroundthecode,supportingourgoalof
systemextensibility.
6 USE-CASES
Weshowtheapplicabilityofourapproachbasedonthreeusecases,whichwederivedfromourmodeldeveloper
interviewsanddescribedinappendixA.2.Weselectedthesethreeusecases,since,duringtheinterviews,thedevelopers
emphasized their importance. All mechanisms proposed in section 4.3 and their corresponding implementations
describedinsection5willbeutilizedtosolvetheusecases,providinganimpressiononhowtheirintegrationinthe
everydaymodelbuilding,modeldiagnosis,andmodelrefinementworkflowenablessystematicanalysisanddebugging
oftheconnectionbetweenmodelbehavioranditsarchitecturalparts.Usecase1isrelativelyuniversal,demonstrating
howthesystemfacilitatestheeverydaymodelbuildingand–refinementworkflow.Subsequently,usecases2and3go
intoincreasingdetailonaspecificdebuggingtask.Weutilizetheseusecasesinouruserstudy,asdescribedinsection7.
6.1 UseCase1:ModelAssessment,–Comparison,and–Refinement
Amodeldeveloperwantstobuildamodelforimageclassification,whichshouldeventuallyruninreal-timeonan
embeddeddevice.Thehardwarehaslowcomputationalpowerandlimitedstoragesize.Therefore,executiontimeand
modelsavesizemustbeminimizedwhilemaximizingtheclassificationperformance.Basedonhispriorexperiencesin
deeplearning,thedevelopercreatesaninitialmodelarchitecture.Duringtraining,themodelalreadyshowspromising
results,reachinganaccuracyof88%after20epochs.However,hewantstorefinearchitectureandhyperparameters
furthertoboostthemodel’sperformancewhilekeepingthehardwarerequirementsconstant.Inaniterativeapproach,
thedevelopercreatesmultiplemodelvariations,experimentingwith2Dconvolutions,networkstructures,andlayer
sizes.Thereby,heusestheiNNspectorloggingmechanismtotrackanddebughisexperimentsintheiNNspector
system.UsingL3,thetreeofmodelsindicatesthevariationsbetweenthemodelsintheabstractmodelarchitecture
representationwhilealsoconfirmingthechangeintrainableparametersbetweenmodelvariants.Byapplyingthe
performancemetricstooltothegroupoftrainedmodels,hecanevaluateandcomparetheirclassificationaccuracy.Since
computationalcomplexitymattersinthereal-timescenario,theruntimestatisticstoolprovidesagoodestimateofthe
5https://reactjs.org/
6https://www.typescriptlang.org/
ManuscriptsubmittedtoACM32 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
Fig.14. iNNspectorwidgetstoassessmodelperformanceoveranexperiment.ThePerformanceMetricswidgetshowstheaccuracyof
eachmodel,theRuntimeStatisticswidgetshowstheirexpectedexecutiontime,andtheModelSaveSizetheirsizeondisk.
expectedmodelexecutiontime.Respectively,themodelsavesizetoolgivesanoverviewofthemodelsize.Comparing
accuracy,savesize,andexecutiontimes,twomodelsseempromising,ashighlightedinfigure14.Thedeveloperadds
single-modelperformancemetricswidgetsforthosetwomodelsindividually.Toestimatetheirtendencytooverfit,he
mergesthewidgetsinthegroupviewtocomparetraining–andvalidationloss,showingthatonemodelseemsto
bettergeneralizethantheother.Outgoingfromthissuperiormodelvariant,thedeveloperwantstofurthertweakthe
performancebyassessingtheconfigurationofitslayersandinspectingeachlayer’svaluedistribution.Henavigatesto
L2,exposingmorearchitecturaldetailsandprovidingaccesstothemodel’svariables.Hecreateswidgetsvisualizing
convolutionalanddensekernels,enablinghimtocomparetheindividualdatadistributions.Inthesecondlayer,the
varianceincreasessignificantlyoverthetrainingepochs,whilethethirdlayershowsmanyvaluesstayingclosetozero,
indicatingabottleneckinlayertwo,whichlimitstheinformationflow.Withthisinsight,thedeveloperhasaclear
leveragepointforfurthermodeltweaking.Hecreatesanewgenerationofmodelswithimprovedperformanceby
re-balancingthecapacitybetweenlayerstwoandthree.
6.2 UseCase2:BalancingLosses
Adeveloperwantstobuildavariationalauto-encoder(VAE)[KingmaandWelling2014]forimagegeneration.Con-
strainingthelatentdistributiontoresembleanormaldistributionensuresthatwhensamplingthelatentvectorfrom
anormaldistribution,validdecoderoutputisgenerated.ThedeveloperusestheKullback–Leibler(KL)divergence
tocalculatethedifferencebetweentheactualdistributioninthelatentspaceandthedesirednormaldistribution.To
optimizebothreconstructionresultsandshapeofthelatentdistribution,hemustpreciselybalancereconstructionloss
andKLdivergenceagainsteachother.However,duetothisparameterbeingdependentondataset,model,andhuman
perception,thereisnoanalyticalsolutiontothisproblem.Therefore,thedevelopercreatesmultiplevariationsofthe
network,alteringthelossbalancingfactorbetweenmodels.ThecustomizedKerasmodeloverridesthetrain_step
andtest_stepfunctionstoalsoreturnKL–andreconstructionloss,whichare,thereby,automaticallytrackedbythe
iNNspectorloggingmechansism.
Whilethereconstructionlosscanbevisuallyevaluatedbysimplydisplayingthereconstructedimagesusingthe
input/reconstructiontoolshowninfigure15a,theKLlossisaratherabstractfactor.Toassessitandexaminethevalue
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 33
(a)Imagereconstructionsfor (b)Featuredistribution(∼probabilitydensityfunction)foreachdimension
differentdatasetsamples. inthelatentvariableoftwomodels.
Fig.15. iNNspectorwidgetstobalancelossesinaVAE.(a)Theinput/reconstructionwidgetshowstheinputimagesandtheir
reconstructionsforasubsetofthetestdataset.(b)Thefeaturedistributionwidgetshowstheshapeofthelatentdistribution,
suggestingtheleftmodeltobebettersuitedforsampling.
distributioninthelatentspace,thedeveloperdescendsintoL2,enablinghimtovisualizehowtheoveralldistribution
ofactivations𝑙 inthelatentlayerdevelopedoverthetrainingepochs.Usingautomatedinterestingnessmeasures,
hefindsthatthemodelwitha25 : 75balancebetweenreconstruction–andKLlosshasamuchlowervarianceof
Var(𝑙25:75) = 2.02thanthemodelwitha90 : 10balance,wherethevarianceisVar(𝑙90:10) = 12.38.Since,inVAEs,
uniformityofeachdimensioninthelatentvariableisimportant,thedeveloperusesthefeaturedistributionplot to
plottheprobabilitydensityfunctionforeachdimensionindividually,depictedin15b.Itshowsthatthemodelwith
moreweightontheKLlosshasamoreuniformdistributioninalllatentdimensions.Forthefollowingiterationsofthe
modeldevelopmentandrefinementprocess,theinspectionresultsenablethemodeldevelopertomakewell-founded
decisionsoverthelossbalance.
6.3 UseCase3:DebuggingDistributions
Extendingusecase2,whileweightingreconstructionandKLloss,thedeveloperseemsnottobeabletofindasatisfying
balance.Instead,eitherthereconstructedimageorthelatentdistributiondeviatessignificantlyfromthedesiredresults.
Thestrongskewofthetheactivationsinthelatentspace,visualizedbythewidgetsinfigure15b,promptsfurther
investigation.UsingtheActivationSkewinterestingnessmeasureonL3,henoticesevenstrongerskewintwolayersof
thelatentblock,depictedinfigure16a.Totracedownthedetectedabnormalitytoitsrootcause,thedeveloperdescends
toL2andcloselyinvestigatestherespectivelayers,namelythez_meanandz_log_varlayers,whichdeterminethe
parametersofthenormaldistribution.ApplyingtheHistogramtoolconfirmsthisobservation,asshowninfigure16b;
thereareonlypositiveactivationsonthatlayer.Uponcloserinspectionofthelayer’sinnerelements,thedeveloper
identifiesthereasonsforthatbehavior:duetoacarelessmistakewhendefiningtheDenselayerinKeras,thelayer’s
outputispassedthroughaReLuactivationfunctiondepictedinfigure16c,resultinginallnegativevaluesbeingcut
off.ThedevelopercreatesanewmodelgenerationusingtheBranchModeltoolandremovesthesuspiciousactivation
function.Re-trainingthenewmodelprovestherefinement’ssuccess.
ManuscriptsubmittedtoACM34 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
(a)Skewnessinthelatent
block. (b)Histogram. (c)LayerGraph.
Fig.16. Widgetstoinvestigatethedistributionofactivationsinthelatentblock.(a)Interestingngessannotationspointsthedeveloper
totheskewnessoftheactivationsinthelatentblock.(b)TheHistogramwidgetprovidesadetailedviewonthedistributionof
activationsinthelatentlayer.(c)TheLayerGraphrevealstheerroneousactivationfunction,leadingtotheskeweddistribution.
7 EXPERTUSERSTUDY
ToevaluatetheiNNspectorsystem,weconductauserstudywithfourparticipants.Thepriorobjectivesoftheevaluation
studyaretoassess(1)whetherthesystemdoesfulfillitsclaimofbeingauniversaltoolformodeldebugging,(2)the
usabilityandeffectivenessofthesystem,and(3)identifyopenchallengesandfuturework.
7.1 StudySetup
Inthissection,wedescribeourstudysetup,guidedbythemethodologyproposedbySperrleetal.[2021].First,we
explainourstudyprocedureforeachsession;second,wedescribetheparticipantsofourstudy;andlastly,wediscuss
thedatausedinourpairanalyticssessions.
StudyProcedure— Wedivideeachstudysessionintofourblocks.Eachsessiontakesapproximatelytwohoursandis
recordedforlatertranscriptionandqualitativeevaluation.
CurrentWorkflow(≈5min): Westartbycapturingpersonalinformation,suchastheamountofexperienceour
participantshavewithdeeplearning.Wecontinuewithquestionsontheparticipant’susualdevelopmentworkflow,
includingquestionsonexperimenttracking,modelassessment,andpotentialdebuggingroutines.Thisblock
isclosedbyopen-endedquestionsondeficienciesofcurrentdebuggingtoolsandwishestowardsasystemfor
universaldeepmodelinspection.
FormalFramework(≈10min): Byreferencetotable1andfigure3,webrieflydescribethepartsofourconceptual
frameworkbeingmostrelevantfortheimplementationofadebuggingsystem,namelythedatacategories(4.1)
andthemechanismstomakethisdataaccessible(4.3).Following,wecapturefeedbackontheframeworkina
semi-structuredinterview,coveringitscompletenessandanticipatedapplicability.
iNNspectorSystem&UseCases(≈45min): Thisisthecentralpartoftheinterview,takingupaboutonehour
oftheoveralltwo-hourinterviewslot.Inaguidedexplorationphase,weexplaintheiNNspectoruserinterface
totheparticipant,similartotheapplicationwalkthroughinsection5.1.Whentheparticipantsconfirmthey
feelconfidentwiththeinterface,theyaresuccessivelyaskedtosolveusecases1to3describedinsection6ina
pair-analytics[Arias-Hernandezetal.2011]session.Theparticipantsreceiveahandoutexplainingthesettingof
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 35
eachusecaseanddefiningitscorrespondinganalysistasks,whichwealsosummarizeverbally.Theparticipants
aresupposedtosolvetheusecasesmainlyontheirown;however,whentheyarticulatethattheyarelooking
foraparticulartoolorhavequestionsoneithertaskorsystem,wejumpintohelp.Tocaptureimpressionsand
feedbackonthesystem,weencouragetheparticipantstospeakoutloudabouttheirreasoningduringthisprocess.
QuestionnaireandFeedback(≈15min): Finally,wecollectquantitativeandqualitativeuserfeedbackonthe
system.Basedonacustomizedquestionnaire,inspiredbytheNASATaskLoadIndex[HartandStaveland1988]
andtheSystemUsabilityScale[Brooke1996],weevaluateiNNspector’susability,usefulness,taskload,andeffects
onthedebuggingbehavior.Furthermore,thequestionnairecapturestheusefulnessofspecificsystemcomponents,
suchasthedifferentlevelsofabstractionorthetoolbox.Theinterviewfinisheswithopen-endedquestionsand
broaderfeedbackonthesystem,includingmissingcomponents,ideasforfutureextensions,andgeneralthoughts
onthesystem.
Participants— Allfourparticipants(P1,P2,P3,andP4)haveaneducationalbackgroundininformationscienceon
masterslevel.P1,P2,andP4havespecializedindeeplearningandshowmultipleyearsofexperiencewithdeeplearning
developmentinbothresearchandindustry.P3hashadpriorexperiencesindeeplearningaspartofhisbachelors
andmaster’sdegrees.P1andP4werealreadypartoftherequirementsstudy,whileP2andP3wereonlypartofthe
evaluationstudy.NeitherthestudyleadernortheparticipantsarenativeEnglishspeakers;nevertheless,thestudy
sessionsareconductedinEnglishtoachievethemostaccuratetranscriptionandcitation.
Data— ThemodelsavailableintheiNNspectorsystemarepre-trainedontheMNISTdataset.Foreachusecase,
aselectionofmodelssupportingtheusecaseispresentedtotheuser.Themodelssimulatearepresentativereal-
worldmodelbuildingandrefinementworkflow,withmodeliterationsimplementingarchitecturalchangesbasedon
observationsfrompastgenerations.Forusecase1,themodelsareclassifiers,whileforusecases2to4themodelsare
variationalauto-encoders.
7.2 StudyResults
Whiletheparticipantsshoweddifferentexplorationstrategies,theyallreachedtheanalysisgoalsofusecases1and
2insimilartimes(P1:40min,P2:36min,P3:22min,andP4:30min).P3wasthefastestparticipant;however,also
beingtheleastexperienced,hedidnotreachananalysisdepthcomparabletotheotherparticipants,despiteintheend
drawingthesameconclusions.Usecase3wasintroducedasanoptional,open-endedtask,whereweonlyaddedanew
modelgenerationwiththesuspiciousactivationfunctionremovedandaskedtheparticipanttodetermine(1)possible
issueswiththepreviousgenerationand(2)howthenewgenerationchangedandwhythisresolvestheissue.Here,
theparticipantsfocussedoncomparingthearchitecturesand,subsequently,foundthedifferenceinthelatentblock.
However,theydidnotrecognizeamajorimprovement,whichmightbeduetorelativelyblurryreconstructionresults
ofbothmodelvariants,causedbythelimitedcapacityofthelatentvariable(dim=10).
Inthefollowing,wesummarizethefeedbackofourparticipants.Duetothelimitednumberofparticipants,we
presentquantitativeandqualitativeresultstogether.
7.2.1 FeedbackontheFramework. BeforefacingourparticipantswiththeiNNspectorsystem,wecollectfeedback
onourconceptualframework.Particularly,weintroducethedatacategories(section4.1)andglobalmechanisms
(section4.3)andcollectfeedbackontheframework’scorrectness,completeness,andusefulness.
ManuscriptsubmittedtoACM36 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
3 higher is better higher is better higher is better lower is better
2 P2
P3
P2 P1 P2 P4 P1
1 P4 P3 P4 P2
P1 P3 P1 P3 P4
0
1 2 3 4 5 6 7 1 2 3 4 5 6 7 1 2 3 4 5 6 7 1 2 3 4 5 6 7
(i) Ease of Use (ii) Completeness (iii) Effectiveness (iv) Frustration
Fig.17. QuantitativestudyresultsontheusabilityoftheiNNspectorsystem.Thebarsshowthecountofparticipantsratingthe
systemwiththerespectivescore.
Data— Ingeneral,ourparticipantsconfirmedthedatacategoriestomakesenseandmatchtheirmentalmodelabout
thedataarisinginmachinelearningexperiments(P1,P2,P3,P4).P1wasmissingadatacategoryformeta-parameters
abouttheexperiment,suchasbatchsizeoroptimizationparameters.P2hadsimilarconcerns,butreadilyproposedan
integrationofthoseparametersintoourcategorizationasconstantscalardata,whichperfectlycomplieswithourmodel.
Weupdatedthecategorizationaccordingly.P2alsomentionedthatheseesfunctions(D4)aspartofthestructural
architecturegraph(D1.2)sincethey“definethegeometryofthegraph.”Weaddedarespectivepointertotable1.
Mechanisms— Whenintroducingthemechanisms,ourparticipantsinstinctivelystartedtocomparetheframework
tostate-of-the-arttoolsformodeldebugging.E.g.,P4identifiedadiscrepancybetweenusefulnessandconvenience
inexistingtools:“eitheryouneedtoself-makeyourtools,whichareverylowlevel[...],oryoucanuseTensorBoard
buttheyhaveonlyverygeneralstatisticalevaluations.”Therefore,hevaluedtheframeworkasan“improvementover
existingtools[...],ifapplied[implemented]correctly.”Withregardstotheproposeddatarepresentation(M6),P2stated
that“scalarvaluesandimagescanbevisualizedinexistingtools,butthat’smostlyit.”.Also,hementionedtonotuse
thegraphviewinTensorBoardveryoften,sinceityields“notmuchnewinformation.”Incontrast,ourframework
proposestheentitiesofthestructuralbackbone(M2)asanavigationalcomponentandahooktoaccessunderlyingdata.
Overall,ourparticipantsagreedthatthemechanismswerereasonable(P1,P2,P3,P4)andexpressedtheiranticipation
forthesystemimplementation.
7.2.2 FeedbackontheSystem. Gatheringfeedbackonthesystemisdividedintothreephases:first,weintroduceour
participantstotheiNNspectorsysteminajointexplorationphase.Wedescribetheinterfacesimilartosection5.1while
theparticipantalreadyhasfullcontroloverthesystemtodiscoverandexploreitsfunctionalities.Inthesecondphase,
theusersolvestheusecases1to3describedinsection6.Finally,wegatherfeedbackviaaquestionnairecontainingboth
quantitativeandqualitativequestions.Inthefollowing,wesummarizethefeedbackstructuredbyourmainevaluation
goalsusability,usefulnes,andtheclaimofthesystemtobeageneralizingtoolforsystematicmodeldebugging.
Usability— Usabilityiscapturedintermsofeaseofuse,completeness,effectiveness,andfrustration.Figure17shows
thequantitativeresultsoftheevaluation,whicharesubstantiatedbyqualitativefeedbackinthefollowing.
Overall,thesystemwasdescribedas“intuitive”(P1,P3,P4)and“veryusable”(P2).Particularly,functionalitieslike
thenavigationoverlevelsofabstraction,filters,andwidgetgroupswereintuitivelyusedbyallourparticipants.In
contrast,someparticipantsneededaquickreminderthattheclassselectorpanelcouldhelpsolveusecase2.Thetwo
majorpointsofcritiquewerethatthesystemisquitecomplexandwouldneedtrainingtofullyexploitallfunctionalities
(P1,P2,P4)andthatthetooliconsand–descriptionscouldbeimproved(P1,P3,P4).Ingeneral,theparticipantswere
pleasedwiththecompletenessofthesystem.Theprimarypointofcritiqueweremissingtools,withaconfusionmatrix
ManuscriptsubmittedtoACM
tnuoCiNNspector:Visual,InteractiveDeepModelDebugging 37
2 lower is better lower is better higher is better lower is better
P1 P1 P2
1 P2 P3 P4
P3 P4 P2 P4 P3 P1 P1 P2 P4 P3
0
1 2 3 4 5 6 7 1 2 3 4 5 6 7 1 2 3 4 5 6 7 1 2 3 4 5 6 7
(i) Mental Demand (abs.) (ii) Temporal Demand (abs.) (iii) Performance (abs.) (iv) Effort (abs.)
(a)Absoluteusefulnessrating,i.e.,withoutconsideringthecomplexityofthetasksorhowitwouldbesolvedusingtraditionaltools.
3 higher is better higher is better higher is better higher is better
2 P1 P1
P3 P2
P4 P4 P2 P1
1 P3 P3
P2 P3 P4 P1 P4 P2
0
--- -- - 0 + ++ +++ --- -- - 0 + ++ +++ --- -- - 0 + ++ +++ --- -- - 0 + ++ +++
(i) Mental Demand (comp.) (ii) Temporal Demand (comp.) (iii) Performance (comp.) (iv) Effort (comp.)
(b)Relativeusefulnessrating,comparingtotheusualworkflowasabaseline.“–(––)”meansa(strong)negativeand“+(++)”a
(strong)positiveinfluenceoftheiNNspectorsystem.
Fig.18. Quantitativeresultsontheusefulnessofthesystem.Whilethementaldemandandeffortareratedhighontheabsolute
scala,thesystemisratedasagreatimprovementincomparisontotheusualworkflow.
beingthemostfrequentlyrequested(P1,P2,P4).Asaresponse,weaddedthetoolafterthestudy.Theeffectiveness
ofthetoolwasratedbetweenokayandgoodwithoutfurthercomments.Thefrustrationfactorwaslowformost
participants(P1,P2,P3),despiteamemoryleakagebugoccurringforP2causingsignificantlag.However,P2stated
that“[thebug]wasnotabigdeal.”Inthemeantime,theerrorhasbeenfixed.P1toldthefrustrationtobe“actuallyvery
low”;however,healsoexperiencedabugcausingtheclassselectortomalfunction:“[iftherewasn’tthebug],Iwould
putitat1,as[thesystem]worksquitenice.”P4statedmediumfrustration,causedbyalackoftoolstosolveusecase2.
Particularly,hewasmissingaconfusionmatrixtoolandlinkingandbrushingbetweenmisclassifiedsamplesacross
differentmodels.
Usefulness— Usefulnessiscapturedintermsofmentaldemand,temporaldemand,performance,andeffort.Each
questionhastwoparts,withthefirstoneaskingabsolutevalues(figure18a)andthesecondonecomparingtothe
usualworkflowofourparticipantsasabaseline(figure18b).Inthefollowing,wewillreportboththequantitativeand
qualitativefeedbackonthesystem’susefullness.
Despitethementaldemandofusecases1to3beingratedrelativelyhighontheabsolutescale(P1,P2),allparticipants
aggreedthatthesystemsignificantlysimplifiedthetasksand“helpedalotsothatthementaldemandwasnotvery
high.”However,P2mentionedconcernsaboutmentaloverloadwhenusingthesystem:“it’smorestuffatonce;for
example,inaJupyternotebookorinmynormalworkflowit’smoresequential.”Ourparticipantsagreedonthesystem
stronglydecreasingthetemporaldemand,ratingthetimegainhigh(P1,P2,P4)toveryhigh(P3).P2notedthat“doing
allof[thedebuggingintheusecases]woulddefinitelytakesometime,configurations,andstuff.”P1particularly
mentionedthatthesystemmakesit“mucheasiertocomparedifferentarchitectures.”Allparticipantsweresatisfied
withtheperformancetheyachievedwhensolvingtheusecases.Incomparison,P2atfirstexpectedsimilarperformance
withtraditionaltoolsbutonsecondthoughtrevisedhisopinion:“withthelatentdistributionsitwouldhavetakenway
ManuscriptsubmittedtoACM
tnuoC
tnuoC38 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
3 higher is better higher is better higher is better higher is better
2 P1 P1
P2 P2
P3 P2 P4
1 P3
P4 P2 P1 P4 P3 P1 P4 P3
0
1 2 3 4 5 6 7 1 2 3 4 5 6 7 1 2 3 4 5 6 7 1 2 3 4 5 6 7
(i) Simplified Data Access (ii) Time Saving (iii) Universal Tool (iv) Integrate into Workflow
Fig.19. QuantitativeresultsontheadequacyoftheiNNspectorsystemforsystematicmodeldebugging.Particularlythesystem’s
abilitytosimplifyaccesstothedataarisingindeeplearningexperimentswasratedhigh.
longerandwouldnotbethateasy.”Generally,theabsoluteefforttosolvethetaskswasratedmid(P1,P2)tohigh(P3,
P4).P4ascribedthismainlytobeing“newtothesystem.”However,incomparison,thesystemstillwasratedasan
improvement(P2,P3,P4).OnlyP4wassceptical:“[thesystemdidnotreducetheeffort]incomparisonwithstatistical
evaluation.”
AdequacyforSystematicModelDebugging— Concludingourquestionnaire,wecapturegeneralimpressionsof
thesystembasedonthefollowingquestions.
(i) Howmuchhasthesystemincreasedorsimplifiedyouraccesstothedataarisinginmachinelearningexperiments?
AllourparticipantsagreedthatiNNspectorsimplifiesaccesstodatagreatly(P1,P2,P3)toverygreatly(P4).P4
confirmedthecoverage:“youcanlookateverythingyouwant.”Overall,duringtheexploration–andusecase
phasesofoursessions,noneoftheparticipantsrequesteddatathatwasnotavailableinthesystem;critiquewas
onlymentionedabouttherepresentationofdata,i.e.,ourparticipantswantedtocustomizetoolsandwidgets
accordingtotheirneeds.
(ii) HowmuchtimewouldiNNspectorsaveyouinyoureverydaymodeldevelopmentanddebuggingworkflow?
Thetimesavingwasratedbetweenneutral(P2)overgood(P1,P4)toveryhigh(P3).P2expressedhisuncertainty:
“Icannotreallysayyet.Iwouldhavetouseitabitmore.”Sincethemodelswerepre-trainedpreliminarytothe
studyduetotimeconstraints,ourparticipantsgavetoconsiderationthat“thisdependsonhowmuchtimeyou
needtosetupthemodel[s]likethis”(P3).Afterexplainingtheloggingmechanismdescribedinsection5.4.1,P3
addedthat“thissoundslikeitisreallyeasy;soIthinkitwouldsavereallymuchtime.”
(iii) Inyouropinion,towhatextentdoesiNNspectorfulfilltheclaimofbeingauniversaltoolforsystematicdeepmodel
debugging?
Theuniversalityofthesystemwasratedfromokay(P1)overgood(P2,P3)toveryhigh(P4).Here,customizability
andexpandabilitywerethedecisivepointsforallparticipants.However,P1addedthatthesystem“alreadyhasa
lottooffer.”P4justifiedhisdistinctvote:“IthinkIcouldn’tcomeupwithausecasethatIcouldn’tsolvewith
thesystem.”
(iv) HowlikelyareyoutodeployiNNspectorinyoureverydaymodeldevelopmentanddebuggingprocess?
P1,P2,andP4statedtheywouldprobablyintegratethesystemintotheireverydayworkflow.P3notbeing
confrontedwithdeepleraningonaregularbasisreasoned“[he]wouldliketousethisif[he]woulddevelop
machinelearningmodels.”Again,thesimplicityoftheloggingmechanismwasidentifiedascrucial:“ifIcould
runiteasilywithmymodels,Imostlikelywoulduseit.”
ManuscriptsubmittedtoACM
tnuoCiNNspector:Visual,InteractiveDeepModelDebugging 39
8 DISCUSSION
Summarizing our work, we identify concrete recommendations guiding the design of real-world systems for the
systematicdebuggingofmachinelearningexperiments.Furthermore,wediscusscurrentlimitationsofourapproach
andhowtheywillbeaddressedinfuturework.
8.1 Take-HomeMessages
Thissectionsummarizesthemajortake-homemessagesofourapproachanddistillsgeneralrecommendationsforthe
designofsystemsforsystematicnetworkdebugging.
ConsistentLoggingofAppropriateData— Allrelevantdatageneratedinmachinelearningexperimentsshould
beloggedforlateruseinthedebuggingstage.Modelevolutionshouldbeactivelytrackedbyencodingparent-child
relationshipsinthemodelmetadata,allowinglaterreconstructionsoftheexperiment’sprogression.Loggingsectionsof
thetrainingandtestingdatasetiscrucialintwoways:firstly,singlesamplesandtheirmodeloutputcanbeinspectedin
thedebuggingstage,e.g.,toinvestigatemiss-classifications.Secondly,theactivationsofamodelonlyexistunderinput
data.Therefore,theactivationsshouldbecomputedandstoredforeachmodelcheckpointanddatasample,allowing
theinspectionofactivationdistributionsandsingleneurons.
Notably,theso-loggeddatacangrowtoasignificantsize.However,wearguethatthevastmajorityofphysicalstorage
requirementstracebacktocheckpoints,whichareinmostcasesloggedanywaytorestoreaparticularmodelstate.Ifthe
amountofloggeddataexceedsafeasiblestoragesize,pre-aggregationsbeforestoringthedatacansignificantlyreduce
itssize.Sincethiscomesatthecostofreducedflexibilityinthedebuggingstage,theadvantagesanddisadvantages
ofpre-aggregationsshouldbecarefullyweighed.Forarchitecturesproducingparticularlylargeactivationdata(e.g.,
convolutionalnetworksonlargeimagesizes),theactivationscanbecomputedontheflywiththedownsideofslower
querytimes.
ModularApproachforSystematicDebugging— Often,thereisnoidealdefaultrepresentationofthedatato
inspect.Ourproposedframeworktacklesthischallengebystructuringthedimensionsthatinfluenceanddetermine
thedatarepresentation,maximizingflexibilitywhilesimultaneouslyresolvingmutualdependencies.Thepresented
systemshowshowdifferentvisualizationandinteractiontechniquescanworktogethertocombinethesedimensions
inareasonableway.
GlobalMechanisms— Theglobalmechanismstonavigatethedataspaceelaboratedinsection4.3provideentrypoints
forimplementingasystemforthesystematicdebuggingofdeeplearningmodels.Whilenotallproposedmechanisms
havetobestrictlyfollowedtomakesuchasystemwork,theyhighlightthechallengesthatmustbeconsideredand
suggestpotentialsolutions.TheiNNspectorsystemdemonstrates,howthemechanismscanbeinstantiatedintoa
real-worldapplication,givingthedeveloperaccesstothevastdataspaceofmachinelearningexperiments.
8.2 LimitationsandFutureWork
In more complex experiments, both the tree of models and the architecture graph might rapidly grow to an
unmanagablesize,leadingtoinformationoverload,asalsonotedbyseveralofourstudyparticipants.Tomitigate
thisproblemwewillincludemechanismsforsemanticblockdetectioninfutureversionsofthesystem,leveraging
commonpropertiesoftheiterativemodelrefinementprocessandarchitecturegraphs.Particularly,modelvariations
oftensharecommonarchitectureorhyper-parameterconfigurations,e.g.,wecouldvisuallygroupmodelsthatonly
ManuscriptsubmittedtoACM40 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
containchangesinoneparameter,suchasthebatchsize.Likewise,architecturegraphsfrequentlycontainrepetitions
ofsimilarstructures,e.g.,stackedresidualblocks[Heetal.2016],orcommonsemanticblocks,e.g.,encoder/decoder
structures[Vaswanietal.2017].Again,suchblockscouldbevisuallyabstracted,significantlyreducingthecomplexity
ofadvancedmodelarchitectures.
Extensibility— The iNNspector system is designed to be easily extendable by own tools and widgets. To fully
determinetoolandcorrespondingwidget,thefollowingaspectshavetobedefined:
ToolDefintion— Theappearanceofthetool,includingicon,name,description,andcategory.Furthermore,the
UoAtypetowhichthetoolisapplicablehastobespecified.
DataSource— Thekindofdatatoqueryfromthebackend,i.e.,theAPIendpointtogetherwithitscorresponding
paramters.Thisincludesmodelidandthekindofdata,butalsothetransformationspecification.
VisualAppearance— Finally,theappearenceofthewidget,includingvisualizationsandinteractions,hastobe
configuredinastandardizedway.
Whileatthemoment,thisstillaffordsprogrammingskillsinReactandTypeScript,futureversionsofthesystem
willsupportspecifyingtoolsasexternalplugins.Particularly,tooldefinitionanddatasourcecaneasilybedefined
inastandardizeddata-serializationformat,suchasYAML7orJSON8.Toalsosupportsuchdefinitionforthevisual
appearanceofthewidget,werelyontheVega-Litegrammarofinteractivegraphics[Satyanarayanetal.2017],allowing
todefinecomplexinteractivevisualizationsinplainJSON.
SpecializedDefaultTools— Complementarytotheextensibilityofthesystem,wewillprovideadditional,specialized
toolsforcommondebuggingtasks.Particularly,asidentifiedinourconceptualframework(seesection4.2.1,“Design
DimensionsforDataRepresentationandInteraction”),weconsiderformalverificationandcorrectnesscheckingas
importantdebuggingtasks.Therefore,asafirststeptowardsformalverification,e.g.,throughSMT[Katzetal.2017],
wewillprovidetoolstoinvestigatethedecisionboundariesofneuralnetworks,e.g.,throughcounterfactuals[Looveren
andKlaise2021]andtocheckitsrobustness,e.g.,throughadversarialexamples[CarliniandWagner2017;Goodfellow
etal.2015].
Transferability— Itsflexibledesign,thedescribedextensibility,andtheformalguidelinesprovidedbytheframework
makeiNNspectorgeneralizewelltovarioustypesofdata,models,andtasks.However,particularapplicationdomains
mightaffordextensionsgoingbeyonddefiningnewwidgetsandtools.E.g.,todebugmodelsfordeepreinforcement
learning,closely-integratedtoolstovisualizestatespaceandagentpoliciesmightbebeneficial[Metzetal.2022;
Saldanhaetal.2019].Anotherexamplearelanguagetransformers[Vaswanietal.2017],whereatightintegrationof
attentionvisualizationsintothestructuralbackboneseemsuseful.
Explainability— Adirectintegrationofsystemsformodelexplainability[Kokhlikyanetal.2020;Spinneretal.
2020]intotheiNNspectorsystemfacilitateslocal,model-agnosticdebugging.ThisenrichestheiNNspectortoolbox
withvariousstate-of-the-artXAItechniques,suchasLIME[Ribeiroetal.2016],LRP[Bachetal.2015],orIntegrated
Gradients[Sundararajanetal.2017].
ComparativeAnalytics— Modelcomparisonisanessentialtaskfordeeplearningdevelopers,whichwasconfirmed
inourrequirements–andevaluationinterviews.WhileiNNspectoralreadysupportscomparisonofscalar–andhigh-
dimensionaldatathroughmulti-model–andside-by-sidewidgets,adedicatedtoolforarchitecturecomparisoncan
7https://yaml.org/
8https://www.json.org/json-en.html
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 41
enhancetheanalysisofstructuraldata.Forthis,infutureversions,wegeneratenodeembeddingsforthearchitectural
blocksofamodel,allowingtocomputeabi-directionalmappingbetweentwomodelgraphs.Thismappingisusedto
alignthegraphsandvisualizethemside-by-side,highlightingcommonalitiesanddifferencesinthetwoarchitectures.
9 CONCLUSION
Withthiswork,wefacilitatethesystematicdebuggingofdeeplearningexperiments.
Asaformalfoundationforimplementingsystemsenablingthis,westructurethedesignspaceofsuchsystemsand
compileitintoaconceptualframework.Particularly,theframework(1)categorizesthedataarisinginmachine
learningexperiments,(2)capturesthedesigndimensionsthathavetobeconsideredwhenbuildingsuchasystem,and
(3)definesconcretemechanismstoincorporatedataanddesigndimensionsintoacomprehensivesystemforsystematic
debugging.Theconsiderationsthatwentintothesystemarederivedfrom(1)openchallengesinthefieldand(2)
requirementinterviewswithreal-worlddeeplearningdevelopers.
OurframeworkproposesmodularUIelements,calleddebuggingcomponents,whichcanbeinstantiatedinatoolbox-
likeapproach.Theuserdeterminestheappearanceofadebuggingcomponentthroughprioritizingcharacteristicsofthe
availabledesigndimensions.E.g.,theusercanchoosebetweenanassessmentorcomparisontask,oravisualorverbal
datarepresentation.Debuggingcomponentscanbeattachedtodifferentunitsofanalysisinthemodelarchitecture.We
proposetomakethemodelarchitecturesexplorableondifferentlevelsofabstraction,rangingfromamulti-modelview
downtosingleweightsandneurons.
Wetransferourconceptualworkintoaready-to-usesystemimplementationcallediNNspector.Analogously
totheframework,iNNspectorletstheuserexploremodelsandtheirarchitecturesovermultiplelevelsofabstraction.
Differenttoolsareavailableinatoolbox,whichcanbeappliedtounitsofanalysisinthearchitecturerepresentation.
Theapplicationofatoolresultsincreatingawidgetdisplayingthedata.Thewidget’sappearanceisdeterminedbythe
toolsspecificationandtheUoAtypeitisappliedon,automaticallyresolvingdependenciesbetweendesigndimensions.
Variousadditionalfunctionalities,suchasinterestingnessmeasures,localizationofUoA,orclassselection,enrich
thesystemonaglobalscale.Notably,iNNspectorgoesbeyonddemonstratingthefeasibilityofourframework;upon
publicationofthiswork,itwillbereleasedasopen-sourcesoftwareand,hopefully,finditswayintotheeverydaymodel
buildingand–debuggingworkflowofdeeplearningdevelopers.
TheevaluationoftheiNNspectoristwofold.First,wepresentthreeusecasesdemonstratinghowitcanbeusedto
debugavarietyofproblemsoccurringinreal-worldmodel-buildingscenarios.Second,weconductauserstudywith
threedeeplearningdevelopersandadatascientisttoevaluatethesystem’susability,usefulness,andversatility.
Wearguethataglobalunderstandingofmodelsandtheirevolutioncanonlybeachievedbysystematicallydebugging,
buildingthefoundationforawell-informeddiagnosis,verification,andrefinementprocess.Alldataarisinginmachine
learningexperimentsarerelevantforthedebuggingstageandshouldbeloggedandmadeexplorable.iNNspector
enablesthiskindofdatatrackingandsystematicdebugging.
ManuscriptsubmittedtoACM42 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
REFERENCES
AminaAdadiandMohammedBerrada.2018.“PeekingInsidetheBlack-Box:ASurveyonExplainableArtificialIntelligence(XAI).”IEEEAccess,6.doi:
10.1109/access.2018.2870052.
RArias-Hernandez,LTKaastra,TMGreen,andBFisher.2011.“PairAnalytics:CapturingReasoningProcessesinCollaborativeVisualAnalytics.”In:
HawaiiInternationalConferenceonSystemSciences.IEEE.doi:10.1109/hicss.2011.339.
SebastianBach,AlexanderBinder,GrégoireMontavon,FrederickKlauschen,Klaus-RobertMüller,andWojciechSamek.2015.“OnPixel-WiseExplanations
forNon-LinearClassifierDecisionsbyLayer-WiseRelevancePropagation.”PLoSOne,10,7.doi:10.1371/journal.pone.0130140.
AlexBäuerle,ÁngelAlexanderCabrera,FredHohman,MeganMaher,DavidKoski,XavierSuau,TitusBarik,andDominikMoritz.2022.“Symphony:
ComposingInteractiveInterfacesforMachineLearning.”In:ProceedingsoftheSIGCHIConferenceonHumanFactorsinComputingSystems.doi:
10.1145/3491102.3502102.
JamesBergstra,RémiBardenet,YoshuaBengio,andBalázsKégl.2011.“AlgorithmsforHyper-ParameterOptimization.”In:ProceedingsoftheInternational
ConferenceonNeuralInformationProcessingSystems(NIPS’11).CurranAssociatesInc.,Granada,Spain,2546–2554.isbn:9781618395993.
JamesBergstra,DanielLKYamins,andDCox.2013.“Makingascienceofmodelsearch:Hyperparameteroptimizationinhundredsofdimensionsfor
visionarchitectures.”InternationalConferenceonMachineLearning,115–123.
AnselmBrachmannandChristophRedies.2016.“UsingConvolutionalNeuralNetworkFilterstoMeasureLeft-RightMirrorSymmetryinImages.”
Symmetry,8,12,144.doi:10.3390/sym8120144.
“SUS–aquickanddirtyusabilityscale.”Taylor&Francis,189–194.
AngelAlexanderCabrera,WillEpperson,FredHohman,MinsukKahng,JamieMorgenstern,andDuenHorngChau.2019.“FAIRVIS:VisualAnalytics
forDiscoveringIntersectionalBiasinMachineLearning.”In:2019IEEEConferenceonVisualAnalyticsScienceandTechnology(VAST).IEEE.doi:
10.1109/vast47406.2019.8986948.
NicholasCarliniandDavidWagner.2017.“TowardsEvaluatingtheRobustnessofNeuralNetworks.”In:2017IEEESymposiumonSecurityandPrivacy(SP).
IEEE.doi:10.1109/sp.2017.49.
GavinC.CawleyandNicolaL.C.Talbot.2010.“OnOver-FittinginModelSelectionandSubsequentSelectionBiasinPerformanceEvaluation.”Journalof
MachineLearningResearch,11,2079–2107.
Ann-KathrinDombrowski,MaximillianAlber,ChristopherAnders,MarcelAckermann,Klaus-RobertMüller,andPanKessel.2019.“Explanationscanbe
manipulatedandgeometryistoblame.”In:AdvancesinNeuralInformationProcessingSystems.Vol.32.CurranAssociates,Inc.
UpolEhsanandMarkO.Riedl.2020.“Human-CenteredExplainableAI:TowardsaReflectiveSociotechnicalApproach.”In:LectureNotesinComputer
Science.SpringerInternationalPublishing,449–466.doi:10.1007/978-3-030-60117-1_33.
UpolEhsan,PhilippWintersberger,Q.VeraLiao,ElizabethAnneWatkins,CarinaManger,HalDauméIII,AndreasRiener,andMarkORiedl.2022.
“Human-CenteredExplainableAI(HCXAI):BeyondOpeningtheBlack-BoxofAI.”In:CHIConferenceonHumanFactorsinComputingSystemsExtended
Abstracts.ACM.doi:10.1145/3491101.3503727.
ThomasElsken,JanHendrikMetzen,andFrankHutter.2019.“NeuralArchitectureSearch:ASurvey.”JournalofMachineLearningResearch,20,55,1–21.
A.Endert,W.Ribarsky,C.Turkay,B.L.W.Wong,I.Nabney,I.D.Blanco,andF.Rossi.2017.“TheStateoftheArtinIntegratingMachineLearninginto
VisualAnalytics.”ComputerGraphicsForum.doi:10.1111/cgf.13092.
StefanFalkner,AaronKlein,andFrankHutter.2018.“BOHB:RobustandEfficientHyperparameterOptimizationatScale.”In:Proceedingsofthe
InternationalConferenceonMachineLearning(ProceedingsofMachineLearningResearch).Vol.80.PMLR,1437–1446.
DarioFloreano,PeterDürr,andClaudioMattiussi.2008.“Neuroevolution:fromarchitecturestolearning.”EvolutionaryIntelligence,1,1,47–62.doi:
10.1007/s12065-007-0002-4.
JonathanFrankleandMichaelCarbin.2018.“TheLotteryTicketHypothesis:TrainingPrunedNeuralNetworks.”CoRR,abs/1803.03635.https://arxiv.org/a
bs/1803.03635 arXiv:1803.03635.
LiqiangGengandHowardJ.Hamilton.2006.“InterestingnessMeasuresforDataMining:ASurvey.”ACMComputingSurveys,38,3,9.doi:10.1145/113296
0.1132963.
AmirataGhorbani,AbubakarAbid,andJamesZou.2019.“InterpretationofNeuralNetworksIsFragile.”ProceedingsoftheAAAIConferenceonArtificial
Intelligence,33,01,3681–3688.doi:10.1609/aaai.v33i01.33013681.
BeatriceGobbo,TommasoElli,UtaHinrichs,andMennatallahEl-Assady.2022.“xai-primer.com—AVisualIdeationSpaceofInteractiveExplainers.”In:
CHIConferenceonHumanFactorsinComputingSystemsExtendedAbstracts.ACM.doi:10.1145/3491101.3519880.
IanGoodfellow,JonathonShlens,andChristianSzegedy.2015.“ExplainingandHarnessingAdversarialExamples.”In:InternationalConferenceonLearning
Representations.http://arxiv.org/abs/1412.6572.
FelixGrün,ChristianRupprecht,NassirNavab,andFedericoTombari.2016.“ATaxonomyandLibraryforVisualizingLearnedFeaturesinConvolutional
NeuralNetworks.”CoRR,abs/1606.07757.https://arxiv.org/abs/1606.07757 arXiv:1606.07757.
RiccardoGuidotti,AnnaMonreale,SalvatoreRuggieri,FrancoTurini,FoscaGiannotti,andDinoPedreschi.2018.“ASurveyofMethodsforExplaining
BlackBoxModels.”ACMComputingSurveys,51,5.doi:10.1145/3236009.
D.Gunning.2016.ExplainableArtificialIntelligence(XAI)DARPA-BAA-16-53.Tech.rep.DefenseAdvancedResearchProjectsAgency(DARPA).
SandraG.HartandLowellE.Staveland.1988.“DevelopmentofNASA-TLX(TaskLoadIndex):ResultsofEmpiricalandTheoreticalResearch.”In:Advances
inPsychology.Elsevier,139–183.doi:10.1016/s0166-4115(08)62386-9.
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 43
KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016.“DeepResidualLearningforImageRecognition.”In:IEEEConferenceonComputerVision
andPatternRecognition(CVPR).IEEE.doi:10.1109/cvpr.2016.90.
FredHohman,MinsukKahng,RobertPienta,andDuenHorngChau.2018.“VisualAnalyticsinDeepLearning:AnInterrogativeSurveyfortheNext
Frontiers.”IEEETransactionsonVisualizationandComputerGraphics,25,8.doi:10.1109/tvcg.2018.2843369.
FredHohman,HaekyuPark,CalebRobinson,andDuenHorng(Polo)Chau.2020.“Summit:ScalingDeepLearningInterpretabilitybyVisualizingActivation
andAttributionSummarizations.”IEEETransactionsonVisualizationandComputerGraphics,26,1,1096–1106.doi:10.1109/tvcg.2019.2934659.
FrankHutter,LarsKotthoff,andJoaquinVanschoren,(Eds.).2019.AutomatedMachineLearning.SpringerInternationalPublishing.doi:10.1007/978-3-03
0-88132-0_1.
JordanTeslaTech.2021.“IncidentNumber145.”AIIncidentDatabase.Ed.bySeanMcGregor.RetrievedAug.4,2023fromhttps://incidentdatabase.ai/cite/145.
MinsukKahng,PierreY.Andrews,AdityaKalro,andDuenHorng(Polo)Chau.2018.“ActiVis:VisualExplorationofIndustry-ScaleDeepNeuralNetwork
Models.”IEEETransactionsonVisualizationandComputerGraphics,24,1,88–97.doi:10.1109/tvcg.2017.2744718.
MinsukKahng,NikhilThorat,DuenHorngPoloChau,FernandaB.Viegas,andMartinWattenberg.2019.“GANLab:UnderstandingComplexDeep
GenerativeModelsusingInteractiveVisualExperimentation.”IEEETransactionsonVisualizationandComputerGraphics,25,1,310–320.doi:
10.1109/tvcg.2018.2864500.
GuyKatz,ClarkBarrett,DavidL.Dill,KyleJulian,andMykelJ.Kochenderfer.2017.“Reluplex:AnEfficientSMTSolverforVerifyingDeepNeural
Networks.”In:ComputerAidedVerification.SpringerInternationalPublishing,97–117.doi:10.1007/978-3-319-63387-9_5.
DiederikP.KingmaandMaxWelling.2014.“Auto-EncodingVariationalBayes.”In:InternationalConferenceonLearningRepresentations(ICLR).
NarineKokhlikyanetal..2020.Captum:AunifiedandgenericmodelinterpretabilitylibraryforPyTorch.(2020).arXiv:2009.07896[cs.LG].
AlexKrizhevsky,IlyaSutskever,andGeoffreyE.Hinton.2017.“ImageNetclassificationwithdeepconvolutionalneuralnetworks.”Communicationsofthe
ACM,60,6,84–90.AlexNet.doi:10.1145/3065386.
RuslanKuprieievetal..2022.“DVC:DataVersionControl-GitforData&Models.”Zenodo.
HimabinduLakkaraju,SarahTan,JuliusAdebayo,JacobSteinhard,D.Sculley,andRichCaruana.2019.DebuggingMachineLearningModels.Workshopat
InternationalConferenceonLearningRepresentations.(2019).https://debug-ml-iclr2019.github.io.
LucasLayman,MadelineDiep,MeiyappanNagappan,JaniceSinger,RobertDeline,andGinaVenolia.2013.“DebuggingRevisited:TowardUnderstanding
theDebuggingNeedsofContemporarySoftwareDevelopers.”In:2013ACM/IEEEInternationalSymposiumonEmpiricalSoftwareEngineeringand
Measurement.IEEE.doi:10.1109/esem.2013.43.
Y.LeCun,B.Boser,J.S.Denker,D.Henderson,R.E.Howard,W.Hubbard,andL.D.Jackel.1989.“BackpropagationAppliedtoHandwrittenZipCode
Recognition.”NeuralComputation,1,4,541–551.LeNet.doi:10.1162/neco.1989.1.4.541.
Y.Lecun,L.Bottou,Y.Bengio,andP.Haffner.1998.“Gradient-basedlearningappliedtodocumentrecognition.”ProceedingsoftheIEEE,86,11,2278–2324.
doi:10.1109/5.726791.
AlexanderLeNail.2019.“NN-SVG:Publication-ReadyNeuralNetworkArchitectureSchematics.”JournalofOpenSourceSoftware,4,33,747.doi:
10.21105/joss.00747.
LiamLiandAmeetTalwalkar.2020.“RandomSearchandReproducibilityforNeuralArchitectureSearch.”In:ProceedingsofTheUncertaintyinArtificial
IntelligenceConference(ProceedingsofMachineLearningResearch).Vol.115.PMLR,367–377.
LishaLi,KevinJamieson,GiuliaDeSalvo,AfshinRostamizadeh,andAmeetTalwalkar.2017.“Hyperband:ANovelBandit-BasedApproachtoHyperpa-
rameterOptimization.”JournalofMachineLearningResearch,18,1,6765–6816.
Q.VeraLiao,DanielGruen,andSarahMiller.2020.“QuestioningtheAI:InformingDesignPracticesforExplainableAIUserExperiences.”In:Proceedings
oftheCHIConferenceonHumanFactorsinComputingSystems.ACM.doi:10.1145/3313831.3376590.
ZacharyC.Lipton.2018.“Themythosofmodelinterpretability.”CommunicationsoftheACM,61,10,36–43.doi:10.1145/3236386.3241340.
MengchenLiu,JiaxinShi,KeleiCao,JunZhu,andShixiaLiu.2018.“AnalyzingtheTrainingProcessesofDeepGenerativeModels.”IEEETransactionson
VisualizationandComputerGraphics,24,1,77–87.doi:10.1109/tvcg.2017.2744938.
ShixiaLiu,XitingWang,MengchenLiu,andJunZhu.2017.“TowardsBetterAnalysisofMachineLearningModels:AVisualAnalyticsPerspective.”
VisualInformatics,1,1.doi:10.1016/j.visinf.2017.01.006.
ArnaudVanLooverenandJanisKlaise.2021.“InterpretableCounterfactualExplanationsGuidedbyPrototypes.”In:MachineLearningandKnowledge
DiscoveryinDatabases.ResearchTrack.SpringerInternationalPublishing,650–665.doi:10.1007/978-3-030-86520-7_40.
ScottM.LundbergandSu-InLee.2017.“AUnifiedApproachtoInterpretingModelPredictions.”In:ProceedingsoftheInternationalConferenceonNeural
InformationProcessingSystems(NIPS’17).CurranAssociatesInc.,LongBeach,California,USA,4768–4777.isbn:9781510860964.
YannickMetz,UdoSchlegel,DanielSeebacher,MennatallahEl-Assady,andDanielKeim.2022.“AComprehensiveWorkflowforEffectiveImitationand
ReinforcementLearningwithVisualAnalytics.”In:EuroVisWorkshoponVisualAnalytics(EuroVA).TheEurographicsAssociation.
Microsoft.2021.ErrorAnalysis:Atoolkittohelpanalyzeandimprovemodelaccuracy.https://erroranalysis.ai/.[Online;accessed10-November-2021].
(2021).
GeoffreyF.Miller,PeterM.Todd,andShaileshU.Hegde.1989.“DesigningNeuralNetworksUsingGeneticAlgorithms.”In:ProceedingsoftheInternational
ConferenceonGeneticAlgorithms.MorganKaufmannPublishersInc.,SanFrancisco,CA,USA,379–384.isbn:1558600663.
ChristophMolnar.2022.InterpretableMachineLearning.AGuideforMakingBlackBoxModelsExplainable.(2nded.).[Online;accessed01-July-2022].
Lulu.com.https://christophm.github.io/interpretable-ml-book.
ChrisOlah,AlexanderMordvintsev,andLudwigSchubert.2017.“FeatureVisualization.”Distill.[Online;accessed11-April-2022].doi:10.23915/distill.00007.
ManuscriptsubmittedtoACM44 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
AshishPatel.2021.ToolstoDesignorVisualizeArchitectureofNeuralNetwork.[Online;accessed27-June-2022].(2021).https://github.com/ashishpatel26
/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network.
EstebanReal,AlokAggarwal,YanpingHuang,andQuocV.Le.2019.“RegularizedEvolutionforImageClassifierArchitectureSearch.”Proceedingsofthe
AAAIConferenceonArtificialIntelligence,33,01,4780–4789.doi:10.1609/aaai.v33i01.33014780.
StevenP.Reiss.2014.“TheChallengeofHelpingtheProgrammerduringDebugging.”In:2014SecondIEEEWorkingConferenceonSoftwareVisualization,
112–116.doi:10.1109/vissoft.2014.27.
MarcoTulioRibeiro,SameerSingh,andCarlosGuestrin.2016.“"WhyShouldITrustYou?":ExplainingthePredictionsofAnyClassifier.”In:Proceedings
oftheACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining,1135–1144.doi:10.1145/2939672.2939778.
MarcoTulioRibeiro,SameerSingh,andCarlosGuestrin.2018.“Anchors:High-PrecisionModel-AgnosticExplanations.”ProceedingsoftheAAAIConference
onArtificialIntelligence,32,1.doi:10.1609/aaai.v32i1.11491.
LutzRoeder.2022.Netron:Visualizerforneuralnetwork,deeplearning,andmachinelearningmodels.[Online;accessed30-April-2020].(2022).https://githu
b.com/lutzroeder/netron.
S.Sacha,M.Kraus,D.A.Keim,andM.Chen.2019.“VIS4ML:AnOntologyforVisualAnalyticsAssistedMachineLearning.”IEEETransactionson
VisualizationandComputerGraphics.doi:10.1109/tvcg.2018.2864838.
EmilySaldanha,BrendaPraggastis,ToddBillow,andDustinL.Arendt.2019.“ReLVis:VisualAnalyticsforSituationalAwarenessDuringReinforcement
LearningExperimentation.”EuroVisShortPapers.
WojciechSamek,AlexanderBinder,GregoireMontavon,SebastianLapuschkin,andKlaus-RobertMuller.2017.“EvaluatingtheVisualizationofWhata
DeepNeuralNetworkHasLearned.”IEEETransactionsonNeuralNetworksandLearningSystems,28,11,2660–2673.doi:10.1109/tnnls.2016.2599820.
ArvindSatyanarayan,DominikMoritz,KanitWongsuphasawat,andJeffreyHeer.2017.“Vega-Lite:AGrammarofInteractiveGraphics.”IEEETransactions
onVisualizationandComputerGraphics.doi:10.31219/osf.io/mqzyx.
FrankSchneider,FelixDangel,andPhilippHennig.2021.“Cockpit:APracticalDebuggingToolfortheTrainingofDeepNeuralNetworks.”In:Advancesin
NeuralInformationProcessingSystems.Ed.byM.Ranzato,A.Beygelzimer,Y.Dauphin,P.S.Liang,andJ.WortmanVaughan.Vol.34.CurranAssociates,
Inc.,20825–20837.
ChristinSeifert,AishaAamir,AparnaBalagopalan,DhruvJain,AbhinavSharma,SebastianGrottel,andStefanGumhold.2017.“VisualizationsofDeep
NeuralNetworksinComputerVision:ASurvey.”In:StudiesinBigData.SpringerInternationalPublishing,123–144.doi:10.1007/978-3-319-54024-5_6.
RamprasaathR.Selvaraju,MichaelCogswell,AbhishekDas,RamakrishnaVedantam,DeviParikh,andDhruvBatra.2017.“Grad-CAM:VisualExplanations
fromDeepNetworksviaGradient-BasedLocalization.”In:IEEEInternationalConferenceonComputerVision(ICCV),618–626.doi:10.1109/iccv.2017.74.
ShitalShah,RolandFernandez,andStevenDrucker.2019.“ASystemforReal-TimeInteractiveAnalysisofDeepLearningTraining.”In:Proceedingsofthe
ACMSIGCHISymposiumonEngineeringInteractiveComputingSystems.AssociationforComputingMachinery.doi:10.1145/3319499.3328231.
RahulSharma,MinakshiKaushik,SijoArakkalPeious,SadokBenYahia,andDirkDraheim.2020.“Expectedvs.Unexpected:SelectingRightMeasuresof
Interestingness.”In:BigDataAnalyticsandKnowledgeDiscovery.SpringerInternationalPublishing,38–47.doi:10.1007/978-3-030-59065-9_4.
KarenSimonyan,AndreaVedaldi,andAndrewZisserman.2014.“DeepInsideConvolutionalNetworks:VisualisingImageClassificationModelsand
SaliencyMaps.”In:InternationalConferenceonLearningRepresentations(ICLR).
RonalSingh,UpolEhsan,MarcCheong,MarkO.Riedl,andTimMiller.2021.“LEx:AFrameworkforOperationalisingLayersofMachineLearning
Explanations.”CoRR,abs/2104.09612.https://arxiv.org/abs/2104.09612 arXiv:2104.09612.
“NoExplainabilitywithoutAccountability:AnEmpiricalStudyofExplanationsandFeedbackinInteractiveML.”ProceedingsoftheCHIConferenceonHuman
FactorsinComputingSystems.AssociationforComputingMachinery,NewYork,NY,USA,1–13.isbn:9781450367080.doi:10.1145/3313831.3376624.
F.Sperrle,M.El-Assady,G.Guo,R.Borgo,D.HorngChau,A.Endert,andD.Keim.2021.“ASurveyofHuman-CenteredEvaluationsinHuman-Centered
MachineLearning.”ComputerGraphicsForum,40,3,543–568.doi:10.1111/cgf.14329.
ThiloSpinner,UdoSchlegel,HannaSchafer,andMennatallahEl-Assady.2020.“explAIner:AVisualAnalyticsFrameworkforInteractiveandExplainable
MachineLearning.”IEEETransactionsonVisualizationandComputerGraphics,26,1.doi:10.1109/tvcg.2019.2934629.
HendrikStrobelt,SebastianGehrmann,MichaelBehrisch,AdamPerer,HanspeterPfister,andAlexanderM.Rush.2019.“Seq2seq-Vis:AVisualDebugging
ToolforSequence-to-SequenceModels.”IEEETransactionsonVisualizationandComputerGraphics,25,1,353–363.doi:10.1109/tvcg.2018.2865044.
HendrikStrobelt,SebastianGehrmann,HanspeterPfister,andAlexanderM.Rush.2018.“LSTMVis:AToolforVisualAnalysisofHiddenStateDynamics
inRecurrentNeuralNetworks.”IEEETransactionsonVisualizationandComputerGraphics,24,1,667–676.doi:10.1109/tvcg.2017.2744158.
MukundSundararajan,AnkurTaly,andQiqiYan.2017.“AxiomaticAttributionforDeepNetworks.”In:Proceedingsofthe34thInternationalConferenceon
MachineLearning-Volume70(ICML’17).JMLR.org,Sydney,NSW,Australia,3319–3328.
ChristianSzegedy,SergeyIoffe,VincentVanhoucke,andAlexanderA.Alemi.2017.“Inception-v4,Inception-ResNetandtheImpactofResidualConnections
onLearning.”In:ProceedingsoftheThirty-FirstAAAIConferenceonArtificialIntelligence(AAAI’17).AAAIPress,SanFrancisco,California,USA,
4278–4284.doi:10.1609/aaai.v31i1.11231.
ChristianSzegedy,WeiLiu,YangqingJia,PierreSermanet,ScottReed,DragomirAnguelov,DumitruErhan,VincentVanhoucke,andAndrewRabinovich.
2015.“Goingdeeperwithconvolutions.”In:IEEEConferenceonComputerVisionandPatternRecognition(CVPR).IEEE.doi:10.1109/cvpr.2015.7298594.
IanTenneyetal..2020.“TheLanguageInterpretabilityTool:Extensible,InteractiveVisualizationsandAnalysisforNLPModels.”In:Proceedings
oftheConferenceonEmpiricalMethodsinNaturalLanguageProcessing:SystemDemonstrations.AssociationforComputationalLinguistics.doi:
10.18653/v1/2020.emnlp-demos.15.
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 45
TensorBoard.2020.TensorBoard:TensorFlow’svisualizationtoolkit.https://www.tensorflow.org/tensorboard/.[Online;accessed20-September-2021].
(2020).
SebastianThrunandLorienPratt.1998.“LearningtoLearn:IntroductionandOverview.”In:LearningtoLearn.SpringerUS,3–17.doi:10.1007/978-1-461
5-5529-2_1.
AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanN.Gomez,LukaszKaiser,andIlliaPolosukhin.2017.“AttentionisAll
youNeed.”In:AdvancesinNeuralInformationProcessingSystems.Vol.30.CurranAssociates,Inc.https://dl.acm.org/doi/10.5555/3295222.3295349.
SandraWachter,BrentD.Mittelstadt,andChrisRussell.2017.“CounterfactualExplanationswithoutOpeningtheBlackBox:AutomatedDecisionsand
theGDPR.”CoRR,abs/1711.00399.arXiv:1711.00399.doi:10.2139/ssrn.3063289.
QianwenWang,JunYuan,ShuxinChen,HangSu,HuaminQu,andShixiaLiu.2019.“VisualGenealogyofDeepNeuralNetworks.”IEEETransactionson
VisualizationandComputerGraphics,1–1.doi:10.1109/tvcg.2019.2921323.
YaqingWang,QuanmingYao,JamesT.Kwok,andLionelM.Ni.2021.“GeneralizingfromaFewExamples.”ACMComputingSurveys,53,3,1–34.doi:
10.1145/3386252.
Weights&Biases.2021.Weights&Biases:Developer-firstMLOpsPlatform.https://wandb.ai.[Online;accessed21-November-2021].(2021).
JamesWexler,MahimaPushkarna,TolgaBolukbasi,MartinWattenberg,FernandaViegas,andJimboWilson.2019.“TheWhat-IfTool:InteractiveProbing
ofMachineLearningModels.”IEEETransactionsonVisualizationandComputerGraphics,1–1.doi:10.1109/tvcg.2019.2934619.
KanitWongsuphasawat,DanielSmilkov,JamesWexler,JimboWilson,DandelionMane,DougFritz,DilipKrishnan,FernandaB.Viegas,andMartin
Wattenberg.2018.“VisualizingDataflowGraphsofDeepLearningModelsinTensorFlow.”IEEETransactionsonVisualizationandComputerGraphics,
24,1,1–12.doi:10.1109/tvcg.2017.2744878.
J.Yosinski,J.Clune,A.Nguyen,T.Fuchs,andH.Lipson.2015.“UnderstandingNeuralNetworksThroughDeepVisualization.”In:ICMLWork.DeepLearn.
JunYuan,ChangjianChen,WeikaiYang,MengchenLiu,JiazhiXia,andShixiaLiu.2020.“ASurveyofVisualAnalyticsTechniquesforMachineLearning.”
arXive-prints,arXiv:2008.09632,arXiv:2008.09632.arXiv:2008.09632[cs.HC].doi:10.1007/s41095-020-0191-7.
BarretZophandQuocV.Le.2017.“NeuralArchitectureSearchwithReinforcementLearning.”In:InternationalConferenceonLearningRepresentations
(ICLR).OpenReview.net.
ManuscriptsubmittedtoACM46 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
A CAPTURINGDEVELOPERWORKFLOWSAND–CHALLENGES
Inthefollowing,wereportadditionalinsightswegainedfromourexpertuserstudy,structuredintoobservationsofthe
currentworkflowsandtheirimplicationsformodeldebugging.Overall,weperceivetheworkflowsofourdevelopersas
disjointed,withtheindividualtasksunconnectedandavarietyofseparatetoolsinvolved.
A.1 CurrentWorkflowsandObservations
Developersinourstudyreportdisjointedworkflowsindeeplearningmodeldevelopmentanddebugging.Their
developmentisusuallybasedonexistingarchitecturesanditerativetrial-and-errorrefinement,hinderedbyalack
Summary
ofguidelinesanddifficultiesindetectingmistakes.Theyusevarioustoolsfortrackingiterationsandassessing
Sec.A.1
modelperformance.Systematicdebuggingworkflowsarerarelyemployed.
Asabaseline,wecapturetheintervieweddevelopers’conventionalmodeldevelopment–anddebuggingpractices,
whichwesummarizeinthefollowing.
CurrentModelDevelopmentWorkflow— Alldevelopersreportbeginningtheirworkflowbyresearchingpromising
architecturesfromrelatedscientificresources(e.g.,papers,blogs)andexistingapproaches(e.g.,GitHubrepositories).
Then,basedonbestpracticesandpersonalexperience,theyadaptthesearchitecturestocreateandtrainaninitial
architecturefortheintendedtask.Followinganiterativetrial-and-errorapproach,thisinitialarchitectureisrefined
andre-traineduntiltheresultsaresatisfying.Asareasonforthisfuzzyprocedure,thedevelopersmentionalack
ofguidelines,bestpractices,andsuitabletoolsformodelinspection.Furthermore,hard-to-detectcarelessmistakes
areidentifiedasthemosthinderingobstacleinthemodelbuildingandrefinementprocess.Totrackthedifferent
modelvariantsand–iterationsarisinginthisworkflow,thedevelopersrelyonfolderstructuresandfilenames,Jupyter
notebooks,customshellscripts,ortheoutputofautomatedhyperparameteroptimizers,c.f.,Hyperopt[Bergstra,Yamins,
etal.2013].Formodelassessment,theyreportedlyrelyonperformancemetrics(e.g.,lossoraccuracy),whicharelogged
andinspectedusinggraphicaltools(e.g.,TensorBoard),Jupyternotebooks,orasraw(textual)command-lineoutputs.
CurrentModelDebuggingWorkflow— Todeduceactualneedsandrequirementsforoursystem’sdesign,we
captureourdevelopers’currentdebuggingpractice,includingpossiblefrustrationfactorsanddiscontentswiththeir
currenttoolchain.Onlyoneofourparticipantsreportsthathe“occasionally”systematicallydebugshismodels,usually
whentherearefundamentalproblemswiththemodel’sperformance.Whendoingso,hewoulddebuginatop-down
approach,inspectingquestionablemodeloutputs,checkingtheactivationsoflayersandneurons,andinvestigating
other experiment factors, such as domain-specific loss functions. The other participants would still rely on their
trial-and-error-basedprocess,changeentirelytoanewarchitecture,or,sometimes,uselocalXAImethodsonindividual
datasetsamples.Thequalityassessmentofamodelinthetrial-and-errorprocessismainlybasedonthelocalinspection
ofdatasetsamplescombinedwithattributionmethods.Asproblemsinthisprocess,oneofourparticipantsnames
missingbestpracticesandalackofleveragepointstorefinemodels.
ManuscriptsubmittedtoACMiNNspector:Visual,InteractiveDeepModelDebugging 47
A.2 ImplicationsforModelDebugging
Inourstudy,weletourparticipantsidentifycrucialdatatypesformodeldebugging,commonpitfalls,anduse
caseswheresystematicdebuggingtoolswouldbebeneficial.Despitetheapparentbenefits,somedevelopersresist
Summary
approachesforsystematicdebugging,favoringpersonalexperience.Ourfindingsadvocateintegratingsystematic
Sec.A.2
debuggingintothedeeplearningworkflowtoimprovemodelperformanceanddecision-making.
Asthecoreofourrequirementsstudy,wecollectwishesandopenchallengesfromourmodeldevelopers,which
theyexperienceintheirdailyworkflows.Fromtheseinsights,wederiveimplicationsandactionablesuggestionson
howasystemenablingthesystematicdebuggingofdeeplearningmodelsshouldlooklike.
ImportantDataforModelDebugging— Thedebuggingofdeeplearningmodelsinvolvesavarietyofdataarisingin
themachinelearningexperiment(c.f.,section4.1).Therefore,ourinterviewscapturethedatathatourmodeldevelopers
considerimportantformodelassessmentand–comparison.Textualandgraphicalrepresentationsofperformance
metricswereratedbyfarthemostrelevant.Fortime-criticalusecases,thisalsoincludesthecomputationalcomplexity
ofthenetwork.Forhigh-levelmodelcomparison,abstracthyperparameterslikethenumberoflayersandnumberof
trainableparameterswerenamedimportant.Formoredetailedarchitectureinspection,layertypes,activationfunctions,
lossfunctions,optimizers,andlearningrateswereofinterestforourdevelopers.Particularlyimportantfordebugging
wasthepossibilitytologandvisualizeactivationsfordatasamples.
UseCasesSuggestedbyStudyParticipants— Wecollectavarietyofusecases,whereeitherin-depthdebuggingor
theabilitytoinspectparticulardatainthemodelpost-trainingwouldhavebeenuseful.
Carelessmistakeswerereportedtobethemostprevalentfrustrationfactor,oftenaffordingtime-consumingnarrowing
downoftheproblem.Onedevelopermentionedtheuseofasigmoidactivationinthelastlayerascauseofsucherror,
naturallypreventingthemodeltoadapttoaregressiontask.However,oftentherootcauseofsuchseeminglysimple
problemsishardtoidentifyduetotheabundanceofpossibleerrorsources.Witheasy,simultaneousaccesstomodel
architecture and the shape of activation distributions, this issue could likely be resolved much quicker. Another
developer listed diverse similar situations, including vanishing gradients through the wrong choice of activation
functions,erroneousdatapreprocessing(wrongfeaturesboosted,timestampsnotconvertedtoUTC),orconfusedorder
ofNumpymatrixindices.Notably,thelattersituationsemphasizeafundamentalchallengeinthedebuggingofdeep
learningmodels:theirtremendousabilitytoadapttoarbitrarydatamakesthemodellearnsomething,evenifthedatais
wrongly(pre)processed.Inconjunctionwiththemodel’sopaqueness,issuesarehardtodetectandlocatesincenostrict
exceptionoccurs;instead,theresultsoftenjustget(slightly)worse.
Asidefromtheseeveryday-mistakes,severalotherusecasesforsystematicdebuggingwereidentified,mostcommon
ofwhichwastobalancelosses(e.g.,thegeneratoranddiscriminatorinGANs)ortoassesstheinfluenceoffrequently
usedtechniques(e.g.,dropout,activationfunctions,orbatchnormalization).
Complementingtheexpertrequirementinterviews,wecapturedadditionalusecasesvoicedbydatascience–and
machinelearning researchers outsideourexpert studygroup. Oneresearcher questionedthe usefulnessof 1×1
convolutionstypicallypartofinceptionblocks.Observingthelayerin–andoutputandstatisticsonthelayeractivations
couldbehelpfultoevaluatetheiruseasadimensionalityreductiontechnique[Szegedy,W.Liu,etal.2015].Another
researchermentionedbeginnersmistakesasasignificantfrustrationfactorwhenenteringthefieldofdeeplearning.
Particularly,hegotconfusedwhenexperimentingwithauto-encodertutorialsandmistakenlyusedclasslabelsas
optimizationtarget.Onemachinelearningengineerhadaparticularinterestinobservingthevaluesofdifferentkernel
ManuscriptsubmittedtoACM48 ThiloSpinner,DanielFürst,andMennatallahEl-Assady
initializationspost-trainingtoevaluatetheirinfluenceontheformationofcapablesub-networks[FrankleandCarbin
2018].Finally,onedeeplearningdeveloperexperiencedstagnanttrainingandpoorreconstructionqualitywhenbuilding
avariationalauto-encoder.Afterhoursofmanualdebugging,herealizedthataleakyreluactivationfunctioninthe
latentspaceinterferedwiththegaussianshapeofthelatentdistribution.Thiscouldhavebeeneasilyrecognizedwith
suitabletoolstoinspectthedistributionoflatentvariablesincombinationwithadetailedarchitecturerepresentation.
TheImportanceofSystematicDebugging— Surprisingly,ourparticipantsoccasionallyshowaveryconservative
opinionaboutusingsystematicdebuggingtosubstantiatetheirdecision-makinginthemodelbuildingandverification
workflow.Forexample,whenaskedwhethertheywouldliketoinspectandattributetheresponsesofsingleneurons,
e.g.,todeterminetheidealsizeofaGAN’slatentspace,theyinsteadwantedtosticktobestpracticesandpersonal
experiences:“inaGAN,alwaysuse100.”
Wearguethatthisexamplehighlightshowmodelinspectionanddebuggingshouldbeafundamentalpartofevery
informedDLworkflow;thefactorsplayingacrucialroleintheperformanceofamodelshouldnotbechosenbasedon
guesses,leadingtoserendipitousresultsandleavingthepotentialofanarchitectureunexplored.
Received20February2007;revised12March2009;accepted5June2009
ManuscriptsubmittedtoACM