IRIS: Wireless ring for vision-based smart home interaction
MaruchiKim∗ AntonioGlenn∗ BandhavVeluri∗
PaulG.AllenSchool,Universityof PaulG.AllenSchool,Universityof PaulG.AllenSchool,Universityof
Washington,Seattle,WA,USA Washington,Seattle,WA,USA Washington,Seattle,WA,USA
mkimhj@cs.washington.edu aglenn5@cs.washington.edu bandhav@cs.washington.edu
YunseoLee EyoelGebre AdityaBagaria
PaulG.AllenSchool,Universityof PaulG.AllenSchool,Universityof PaulG.AllenSchool,Universityof
Washington,Seattle,WA,USA Washington,Seattle,WA,USA Washington,Seattle,WA,USA
yunseol1@cs.washington.edu eyoel23@cs.washington.edu abagaria@cs.washington.edu
ShwetakPatel ShyamnathGollakota∗
PaulG.AllenSchool,Universityof PaulG.AllenSchool,Universityof
Washington,Seattle,WA,USA Washington,Seattle,WA,USA
shwetak@cs.washington.edu gshyam@cs.washington.edu
Figure1:SmarthomeinteractionwithIRIS.(A)AuserunlocksthefrontdoorbypointingandclickingIRISatthesmartlock.
(B)AnotheruserpointsIRISatatelevisionandrotatestheirhandtoadjustitsvolume.(C)TheuserpointsIRISattheirliving
roomlightstoturnthemoffbeforeleavinghome.(D)AuserpointsandclicksIRISattheblindstolowerthemforprivacy.
ABSTRACT control,andsocialacceptability.Ourworkpushestheboundaryof
Integratingcamerasintowirelesssmartringshasbeenchallenging whatispossiblewithringform-factordevices,addressingsystem
duetosizeandpowerconstraints.WeintroduceIRIS,thefirstwire- challengesandopeningupnovelinteractioncapabilities.
lessvision-enabledsmartringsystemforsmarthomeinteractions.
Equippedwithacamera,Bluetoothradio,inertialmeasurementunit CCSCONCEPTS
(IMU),andanonboardbattery,IRISmeetsthesmallsize,weight,and •Human-centeredcomputing→Humancomputerinterac-
power(SWaP)requirementsforringdevices.IRISiscontext-aware,
tion(HCI);Ubiquitousandmobilecomputing;•Computing
adaptingitsgesturesettothedetecteddevice,andcanlastfor16-24 methodologies→Machinelearning;•Computersystemsor-
hoursonasinglecharge.IRISleveragesthescenesemanticsto ganization→Embeddedsystems;•Hardware→Emerging
achieveinstance-leveldevicerecognition.Inastudyinvolving23
technologies.
participants,IRISconsistentlyoutpacedvoicecommands,witha
higherproportionofparticipantsexpressingapreferenceforIRIS
KEYWORDS
overvoicecommandsregardingtogglingadevice’sstate,granular
Smartring,context-awareinteraction,low-powercameras,efficient
∗Correspondingauthors deeplearning,smarthomes,IoT,wearables
Permissiontomakedigitalorhardcopiesofpartorallofthisworkforpersonalor
ACMReferenceFormat:
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation MaruchiKim,AntonioGlenn,BandhavVeluri,YunseoLee,EyoelGebre,
onthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored. AdityaBagaria,ShwetakPatel,andShyamnathGollakota.2024.IRIS:Wire-
Forallotheruses,contacttheowner/author(s). lessringforvision-basedsmarthomeinteraction.InThe37thAnnualACM
UIST’24,October13–16,2024,Pittsburgh,PA,USA
Symposium on User Interface Software and Technology (UIST ’24), Octo-
©2024Copyrightheldbytheowner/author(s).
ACMISBN979-8-4007-0628-8/24/10 ber13–16,2024,Pittsburgh,PA,USA.ACM,NewYork,NY,USA,16pages.
https://doi.org/10.1145/3654777.3676327 https://doi.org/10.1145/3654777.3676327
4202
luJ
52
]CH.sc[
1v14181.7042:viXraUIST’24,October13–16,2024,Pittsburgh,PA,USA Kimetal.
1 INTRODUCTION
Ashouseholdstransitionintosmarthomes,theyareoutfittedwith
anarrayofinterconnecteddevices,likesmartspeakers,doorlocks,
and other smart home appliances [9, 27]. While these devices
promiseimprovedconvenience,themeansbywhichuserscontrol
themremainripeforimprovement.Issuessuchassocialdiscomfort
inusingvoicecommandsandtheunreliabilityofvoiceinputin
noisyenvironmentshinderseamlessinteraction[16,33].Despite
Figure2:IRIShardwareinside3D-printedenclosureandwhen
theavailabilityofsmartphoneappsfordirectcontrol,itisoften
placedbesideaquarter.Thebatterysitsinsidethebandofthering.
more convenient to resort to traditional methods, such as light
Theringdiameterandbandthicknessare17.5and2.9mm.
switchesordedicatedremotes,ratherthanunlockingone’sphones,
locatingtheappropriateapplication,andnavigatingthroughits
thesmallsize,weightandpower(SWaP)requirementsexpected
interface[25,34].
inringform-factordevices.Wepresentcross-layeroptimization
WeintroduceIRIS,shortforInteractiveRingforInterfacingwith
methodsacrosswirelesscamerahardwareandfirmware,and
Smarthomedevices.IRISisanend-to-endwirelessringsystemthat
auserinterfacethatenablesextremelylow-powerstates.We
supportsreal-timeobjectinstancedetectionusingcontextualscene
designedourDIYhardwareusingopen-sourceeCADsoftware,
semantics.Theunderlyingprincipleisrootedintheage-oldadage
outsourcedfabricationandassembly,and3Dprintedtheenclo-
thata“pictureisworthathousandwords,”assertingthatcaptur-
sures.Thefinalfabricationcost(PCBandcomponents)was$471
ingimagesisfarmoreefficientthanverbalizinglengthyauditory
for20units.ThePCB,battery,andenclosureweigh4grams.IRIS
commands.IRISenablesuserstocontrolsmarthomedevicesbysim-
isthefirstringtostreamcameradatawirelessly,andoperatefor
plypointingatthetargetdeviceandperformingacorresponding
over16hoursonasinglecharge.
gesture,offeringanintuitivealternativetotraditionalinteraction
• Instance-levelclassificationbasedonscenesemantics.Our
methods.Finally,IRISrequiresnoadditionalsetupbeyondstandard
machinelearning(ML)pipelinesurpassestraditionalobjectdetec-
smarthomedeviceinstallation,andtheexperimentsandresults
tionmodelsbyenablingscene-basedunderstandinganddetection
presentedinthisworkwereallconductedonexistingsmarthome
ofspecificinstanceswithinaclass,allonresource-constrained
deviceswithnomodification.
devices.Toachieveinstance-levelclassification,westartbyuti-
Achievingthisischallengingforthreekeyreasons.First,while
lizingaself-supervisedvisiontransformermodel,DINOV2[28],
sensorsintegratedintoday’sringdevices,suchasIMUs,arelow-
togeneratescene-levelembeddings.Theseembeddingscapture
power,camerahardwarecangeneratesignificantlymoredata,lead-
notonlytheobjectitselfbutalsothesurroundingenvironment,
ingtoordersofmagnitudehigherpowerconsumption[45].Itis
providingvaluablecontextandscenesemantics.However,DI-
unclearifwirelesscamerasystemscanbedesignedtomeetthesmall
NOV2’ssearchruntimeincreaseslinearlywiththesizeofthe
size,weightandpowerrequirements(SWaP)ofringform-factor
embeddingdatabase,introducingpotentiallatencyissuesforan
devices.Secondly,whileobjectdetectionsystemsexcelinreal-time
interactivesystemlikeIRIS.Toaddressthischallenge,wereduce
detection,theirlimitationsbecomeevidentwhenconfrontedwith
thesearchspaceofDINOV2byutilizingYOLO[31]tofirstde-
multipleinstancesofthesameobjectclass.Forinstance,merely
tectallpotentialsmarthomedeviceswithintheimageframe.
determiningthatauserpointedatasetofblindsisinadequate;the
SinceYOLOcandetectmultipleobjects,weuseacentered-object
systemmustalsodiscernwhichspecificsetofblindsinthehome
detectionalgorithm(CODA).Thisanalyzestheboundingboxes
theuserintendstocontrol.Therefore,asystemcapableofprecisely
generatedbyYOLOandselectstheobject(smartdevice)clos-
identifyinganddistinguishingbetweenindividualdevicesofthe
esttotheimagecenter.TheclassificationfromCODAservesto
sameclassisnecessary.Finally,theentireend-to-endsystemshould
significantlyreducethesearchspaceforDINOV2’squery.Our
operateinreal-timeunderaroundonesecondtobeconsidereda
resultsdemonstratethatthisoptimizationeffectivelyreduces
seamlessinteractionmodality[11,26].
DINOV2’squeryruntimebyhundredsofmilliseconds.
InIRIS,weaddressthesechallengesbymakingtechnicalcontri-
• End-to-endsystemoptimizationforreal-timeoperation
butionsspanninghardware,software,andsystemdesign.Atahigh
andlow-power.Real-timeoperationiscriticalforinteractive
level,thewearerpointsatthedeviceofinterestandpressesthe
mobilesystems[11,26].Weoptimizeourwirelessring’sstream-
buttononthering,asshowninFig.1.Thiswakesuptheon-board
ingperformancetomaximizecamerathroughput,andshowthat
camerawhichcapturesafewframesofthetargetdevice,whichare
theend-to-endsystemcancontroldeviceswithinonesecond,
streamedtoanearbysmartphoneforprocessingviaBluetooth.The
deliveringnearreal-timefeedbacktousersbyconfirmingsuccess-
weareralsoperformsagesture(e.g.rotation)tocontrolthedevice,
fulgesturerecognition.Furthermore,weextensivelyoptimized
theintentofwhichiscapturedusingtheon-boardIMU.Thisis
IRIS’slow-powerdesignforalldayuse,despitethelimitedon-
alsotransmittedtothephonewhichthen,inreal-time,controlsthe
boardbatterycapacity.
targetdevice.Specifically,wemakethreekeycontributions.
Put together, we design an end-to-end wearable ring system
• SWAP-constrainedwirelesscameraring.Wedesignedthe capableof(1)smarthomedeviceinteractionthatcomplements
firstwirelessringform-factordeviceforvision-basedsmarthome voicecommands,(2)instance-basedobjectdetectiontocorrectly
interaction(Fig.2).Ourhardwareisequippedwithacamera, distinguishbetweenindividualinstancesofthesameclass,and
Bluetoothradio,IMU,andanon-boardbattery,whilemeeting (3)real-timeoperation,on-deviceprocessingonastandardmobileIRIS:Wirelessringforvision-basedsmarthomeinteraction UIST’24,October13–16,2024,Pittsburgh,PA,USA
phone.Weevaluateoursysteminfivedifferenthomesfromvar-
iousanglesandlightningconditions.Ourreal-worlddatasetalso
includes98examplesofblinds,57doors,34doorhandles,228lights,
24smartlocks,73speakers,64televisions,37windows,and161
backgroundinstances.Ourresultsshowthat:
• Ourwirelessringhardwarecanstreamvideoat3.4framesper
secondtoaphone,supportscontext-awaregestures,andcan
operatefor16-24hoursonarechargeable27mAhbattery.
• Auserstudywith23participantswhoperformed690interactions
withourringhardwareshowsthatparticipantsgenerallyfavored
IRISoveravoiceassistantforcontrollingdevicesandgreater
socialacceptability.IRISperformsinreal-time,outpacingvoice
commandsby2secondsonaverage,fromcommandinitiation.
• Oursystemenablesinstance-leveldetection,whileoptimizing
forruntimeperformance.Across18uniqueinstancesofdevices,
including2HVACs,2blinds,1door,4lightingsystems,2smart
locks,5speakers,and2TVs,theinstance-basedclassification
accuracywas95%and98%whenprovidedwith2and3reference
images,respectively.Further,weshowanaverageinferencela-
tencyreductionfrom411msfortheDINOV2modelto112msfor
ourDINO+YOLO+CODAsystem.
Webelievethatthispaperintroducesanovelapproachtosmart
home device interaction through IRIS – a wireless, low-power,
camera-enabledringbackedbyreal-timeinstancedetectionand
contextualscenesemantics.Byworkingacrossbothhardwareand
software,IRISprovidesanalternatemodalitytoexistingvoicecom-
mandandapp-basedinteractions.OurresultshighlightIRIS’svia-
bility,showcasingitsreal-timeresponsivenessanduserexperience
achievedwithoptimizationtechniquesacrosshardware,firmware,
andMLruntime.Withthepotentialtoimpactthelandscapeof
Figure3:IRISinAction:Context-awaresmarthomecontrol.
ring-basedhuman-computerinteraction,webelievethatIRIShas
ThisfigureillustratestheapplicationofIRIS,acustom-designed,
thepotentialtobeanimportantsteptowardamorenatural,unob-
camera-enabledwirelessringforcontext-awarecontrolofthesmart
trusive,anduser-friendlyinterfaceforsmarthomes.
home.IRISutilizesinstance-basedobjectdetectionforreal-time
2 RELATEDWORK interactionwiththeenvironment.
Tothebestofourknowledge,wepresentthefirstwirelessring size,weightandpower(SWaP)constraintsofdesigninganend-to-
form-factorsystemforvision-basedsmarthomeinteraction.Below endwearableringsystem,whichcandrasticallychangethedesign
wepresentrelatedworksacrossIoTandringprototypes. decisions.ThermalRing[49]usesawiredinfrared(IR)camerato
VoiceinteractionforIoTdevices.Acommonmodalityforin- captureIRenergyemittedfromthewearer’soppositehandtotrack
teraction with Internet-of-Things (IoT) devices in smart-homes thehandmotionandperformgestureinput.Forobjectdetection
continuestobethroughvoice-basedIoTdevicessuchasGoogle andidentification,ThermalRingrequiresobjectstoberetrofitted
Home[39],AppleHomePod[3],andAmazonAlexa[2].Asnoted withIRreflectivepatchescalledThermalTagssimilartothetags
in[19],asthenumberofIoTdevicesinthehomecontinuestogrow, usedininCyclopsRingandelsewhere[23].Asbefore,ThermalRing
usingvoice,andassociatedapps,tocontroltheseobjectplacesa useswiredcamerasanddoesnotaddresstheSWaPconstraints.
burdenonthementalloadofuserswhichlimitstheirscale. FingerReaderandFingerReader2.0[4,36]arewiredcamerarings
CamerasforIoTinteraction.Camerascanenablecontextualun- designedforvisuallyimpaireduserstoreadtextoraidinshopping.
derstandingofgesturesandintent.Snap-to-It[8]andSnapLink[6], FingerSight[38]usesacamera-enabledringforhapticsensingof
allowuserstotakephotosoftheIoTdevicesfromtheirsmartphone distantobjects,andTouchCam[37]combinesIMUsandcameras
cameras.However,afullywirelesshandorringbasedwearable forgesturesupportandbodylocationclassification.FingerReader,
integratedwithacameraforinteractionhasnotyetbeenrealized FingerSight,andTouchCamareallwireddevices,tetheredtoa
duetoSWaPchallenges. hostmachineorsmartwatch.Unliketheseworks,wecreateafully
CyclopsRing[5]usesapalm-facingwiredRBGcamerawithafish wireless,standalone,camera-enabledringthatmeetstheSWaP
eyelensplacedbetweenthefingerstocapturewholehandgestures. requirementsexpectedinthisformfactor.
Toidentifyobjectsforinteractionintheenvironment,CyclopsRing EyeRing[24]designsawirelesscamera-enabledringforacces-
detectstags[12]placedonobjects.Thecamerahoweveriswired sibilityapplicationssuchasnavigation,currencydetection,and
toapowersourceandhencethedesigndonotconsiderthesmall colordetection.However,theprototypedeviceissignificantlylargeUIST’24,October13–16,2024,Pittsburgh,PA,USA Kimetal.
(aroundthesizeofasmartwatch)anddoesnotaddressthesizeand
weightconstraintsforringdevices.Further,EyeRingdoesnotsup-
portinteractionandcontrolofIoTdevices.Unlikeallthisprevious
work,IRISdoesnotrequireinstrumentingexistingobjectsintheen-
vironmentwithfiducialmarkersandcaninsteadrecognizeobjects
usingvision.Contrarytoconventionalwisdom,weshowthata
fullywireless,camera-enabled,wearableringthatmeetstheSWaP
requirements expected in this form factor is possible. Cameras
consumesignificantpower,andgiventhesmallbatterycapacities
capableoffittingaringformfactor(<27mAh),ourworkintroduces
system-leveloptimizationsnecessarytointegrateacameraintoa
ringwithoutbeingtetheredtoanotherdevice.
OthersensorsforIoTinteraction.SeleCon[1],WristQue[21], Figure4:IRISonaUser’sHand.(A)FrontView,(B)TopView.
andMinuet[19]useultra-wideband(UWB)equippedwatchesto
enablepointinggesturedetectionforIoTdeviceselectionandcon- (2) Ubiquitycomparabletovoiceinteraction
trol.SeleConrequiresinstrumentingeachIoTdevicewithaUWB (3) NomodificationstoexistingIoTdevices
radiowhichlimitsitsscalability.WristQue[21]andMinuet[19] Toaddressthis,wedesignawireless,vision-enabledsmartring.
requireUWBmodulesontheuserandintheenvironmenttode- Achievingthisrequiresustoaddressthefollowingchallenges.
terminethedeviceselectionfrompointinggestures.Minuet[19] • Size,weight,andpowerrequirements.Theoverallweightandsize
utilizesmulti-modalinteractionbyalsocapturingtheusers’voice.
ofthedeviceshouldbeinasimilarballparkasaregular-sized
DespitetheappealoftheseUWBenabledpoint-to-selectwearables,
ring.Whileshrinkingtheringtofitwithintheseconstraintsis
allthesepriorprototypesarewiredand/ordonotdemonstrate
challenging,wemustalsoconsiderall-daybatterylifesothatit
real-timeoperation,andhencedonotaddressthepowerorlatency
doesnotneedtobechargedinthemiddleoftheday.
requirementsofend-to-endinteractiveringdevices.RingIoT[7] • Real-timeoperation.IRISmustbequickandresponsive.Anupper
consistsofaringinstrumentedwithanIMU,IRtransmitter,ca-
boundtonotinterrupttheuser’sflowofthoughtisaroundone
pacitivesensor,andOLEDdisplay.Thisagainusesawiredsetup
second[26].So,wetargetthemaximumend-to-endlatencyfor
forbothpoweranddatatransferandhencedoesnotconsiderthe
IRIStobeonesecond,andbenchmarkitagainstvoiceassistant
SWaPrequirmentsinitsdesign.TRing[48]enablesdeviceinterac-
solutions.
tionbysensingembeddedmagnetsplacedwithineverydayobjects. • Instance-basedobjectdetection.Animagemaynotnecessarily
Similarto[7],thisapproachislimitedasitrequiresinstrumenting
providethespecificityofavoicecommand.Forexample,ina
deviceswithspecializedsensors.Furthermore,TRingcannotenable
scenariowhereauserhasasetofidenticalblindsintwodifferent
interactionfromadistanceasthemagneticfieldsensingislimited
rooms,theycouldsay,"lowertheblindsinroomA"or"lower
tothenear-field.MagicRing[18]hasanonboardradioandantenna
theblindsinroomB."IRISinsteadmustdetectwhichinstancea
tocommunicatewithanintermediarydevicethattranslatesthe
particularobjectisbasedonthesurroundingvisualcontext.
RFsignalsfromtheringintoinfraredsignalsusedtocontrolthe
IoTdevicesandappliancesinthehomesuchasTVsorfans.Ring
3.2 Wirelessvision-enabledringhardware
Zero[10]isacommercialringthatproposestouseanonboard
IMUtocapturegesturesandenablefinegrainedcontrolovermusic Here,wedescribethevariousaspectsofourwirelessringdesign.
volumeandlightbrightness,howeveritisunclearhowthedevice
3.2.1 Hardware. Ourcustomhardwaredesigniscomprisedofan
selectionmechanismisimplementedandwhetheritcanenable
ultra-low-power1/11"320x320QVGACMOSimagesensor(Himax
ad-hoccontroloveranyIoTdevicewithoutpairing.
HM01B0),a6-axisinertialmeasurementunit(BoschBMI270),and
aBluetoothLowEnergy(BLE)microcontroller(NordicnRF52840).
3 IRIS
Thesystemispoweredbya27mAhbatteryandprogrammedvia
Here,webeginbyoutliningtherequirementsforoursystemdesign. SWDoveraMicro-USBconnector.Ourdesignisfullyrecharge-
Wethenpresentourwirelessringhardwaresystemandfinally ablethroughanon-boardpowermanagementintegratedcircuit
describeourreal-timeneuralnetworkpipeline. andprovidesthesystemwithallnecessaryvoltagerails(Maxim
MAX77650).Asingle-pullsingle-throw(SPST)switchisusedfor
3.1 SystemRequirements gestureinitiation,andimagesarestreamedtoamobilephonefor
Ourproposedinteractionmodalityshouldbeasubiquitousasvoice, inputintoourneuralnetwork(seeFig.3).
whileeliminatingtheneedforlengthyvoicecommands.Theinput
3.2.2 WirelessLatency. Thefirstchallengewithourdesignismeet-
modalityshouldbeassimpleandswiftasflickingalightswitchor
inga<500msimageacquisitionlatencytarget.IRISutilizesthemax-
rotatingadial,ensuringasociallyseamlessexperience.Finally,the
imumsupporteddatarateof2MbpsoverBLE[35].Tomaximize
systemshouldrequirenomodificationstothesmarthomedevices
throughput,weutilizetheshortestconnectionintervalavailableto
asthatwouldplaceanunnecessaryburdenondevicemanufacturers.
iOS(15ms)whiletransmitting4packetsperinterval(maximum
Wearriveatthreecoredesignprinciples:
supportedbyiOS)[41].Withapacketsizeof247bytestheeffective
(1) Asimpleinterfaceasintuitiveasflickingaswitch datarateis526,933bitspersecond.TheeffectiveBLEthroughputIRIS:Wirelessringforvision-basedsmarthomeinteraction UIST’24,October13–16,2024,Pittsburgh,PA,USA
Figure5:IRISimageandIMUwirelessdatastreaming.BLEpacketsareformedwiththefollowingstructure:ST-StatusFlags(Startof
Frame,IMUValid,ButtonState),AD-AccelerometerData,GD-GyroscopeData,CD-CameraData.
canbewrittenas: thisbyinputtingan8MHzsignalintotheHM01B0’sclock(MCLK)
1000ms×packets_per_interval×packet_size×8 pinfromthenRF52480.Thissynchronizesthetwochipstogether
Throughput=
connection_interval(ms) andalsolimitsPCLKOto8MHz.Thefinaldetailtomakethisbus
workistoinverttheFVLDsignal.ThenRF52840onlysupports
Thechallengeisthatafull320x320imageis819,200bits,trans-
anactivelowCSline,whereasFVLDisanactivehighsignal.We
latingto1562.5msoflatency(0.64fps)forthefullimagetobetrans-
circumventthisbytriggeringanactive-highinterruptfromFVLD
mittedtothephone.So,weneedtoreducetheimagesizewhile
andloopanexternalGPIObacktothenRF52840totriggeranactive-
preservingasmuchinformationaspossible.Todothis,first,we
lowinterruptfortheSPIporttostartreceivingdata.Thiscouldbe
enable the QVGA window readout on the image sensor, which
optimizedbyincorporatingaNOTgatebetweenFVLDandCS[15].
reducestheresolutionto320x240.Thisisstillinsufficient,sowe
utilizepixelbinningtoimproveimageacquisitiontime.Pixelbin-
3.2.4 Low-powerdesign. IRISmanagespowerconsumptionthrough
ningistheconceptofcombiningelectricalchargesfrommultiple
itsthreedistinctpowerstates:SLEEP,IDLE,andACTIVE.Inthe
adjacentpixelsintoasingle"superpixel"[20,47].Pixelbinning
SLEEPstate,IRISconservesenergybydeactivatingallhardware
essentiallyincreasestheeffectivepixelsize,providinganimprove-
componentsexceptforaninternaltimerwithinthenRF52840chip.
mentinSNR(signal-to-noiseratio)andlowlight.Furthermore,
ThistimerperiodicallyawakensIRIStocheckforthepresenceofa
pixelbinningalsoenablesfasterframerates.Bycombiningpixel
homeWiFinetworkbyreceivingdatafromtheconnectedmobile
data,thesensorcanreadoutinformationfromasmallernumberof
phone.Whileawayfromtheuser’shomeWiFinetwork,IRISre-
"superpixels"comparedtotheoriginalnumberofindividualpixels.
Thisreducedreadouttimeeffectivelyleadstofasterframerates.1 mainsinthisenergy-savingmode,transitioningtoIDLEonlywhen
ahomeWiFiconnectionisestablished.
Thus,whilebinningreducestheresolutionofoursystembyafactor
IntheIDLEstate,IRISenablesallpowerrailsandreadiesall
offourtoQQVGA(160x120),itofferstwokeyadvantages:(1)a4x
peripherals, but clock-gates the camera and suspends the IMU.
improvementinsignal-to-noiseratio,and(2)a4xincreaseinframe
Thisensuresresponsivenesswhileminimizingenergyconsumption.
rate.Inthisconfiguration,ourimageresolutionisnow160x120
IRISexitstheIDLEstatewithasinglebuttonpressviaahardware
bringingtheframerateto3.43fps,orabout290msofend-to-end
interrupt,transitioningitintoACTIVEmode.Duringthismode
latency.Thismeetsourdesigngoaloflessthan500msoflatency
ofoperation,IRIScontinuouslystreamsdatasuchasbuttonstate,
withsomemargintospare.
IMUdata,andcamerapixelstotheconnectedmobiledevice.After
3.2.3 CMOSimagesensorintegration. SincetheBLESoC(nRF52840) 3secondsofstreamingandinactivityfromthebutton,IRISexits
hasnodedicatedcamerainterface,weconfiguretheCMOSsensor ACTIVEandreturnstoIDLEtooptimizelow-powerperformance.
(HM01B0)tooperateina1-bitdatatransfermode.TheHM01B0 Ourlow-powerdesignallowsIRIStooperatecontinuouslyfor
cantheneffectivelyactasaSPIcontrollerandpassdatatothe 16-24hours,dependingonusage.Additionally,IRISsupportsrapid
nRF52840throughaSPI(SPIS)port.Thisisachievedthroughsig- chargingcapabilities,achievingafullrechargeinjustonehour
nalizingthestartofframewitharisingedgeofFrameValid(FVLD), witha1Cchargecurrent,ensuringusageforextendedperiods.
andreceivingtheimagebitsthroughPixelClockOut(PCLKO)and
Data(D0).ThesemaptoCS,SCLK,andMOSI,respectively.The 3.2.5 Fabrication. ThehardwareschematicandlayoutforIRIS
tablebelowshowsaclearerrepresentationofthemappingbetween weredesignedusingtheopen-sourceeCADtoolKiCad.A2-layer
a1-bitcamerainterfaceandSPI: flexibleprintedcircuitwasfabricatedbyPCBWay,whileassembly
1-BitCameraInterface SerialPortInterface(SPI) wasdonebyalocalassembler.The3D-printedenclosureswerede-
PixelClockOut(PCLKO) SerialClock(SCLK) signedusingAutoDeskInventorandprintedwithaFormlabsForm
Data(D0) Master-Out-Slave-In(MOSI) 3Bprinterusingaliquidresinfabricationprocess.Asillustrated
FrameValid(FLVD) ChipSelect(CS) inFig4,thecamerasitsbehindthelidonthering’soutersurface,
SincethemaximumSPIportclockfrequencyonthenRF52840is andthebuttonisplacedclosertotheuser’sthumbwhileremaining
8MHz,welimitthepixelclockfrequencyaccordingly.Weachieve horizontallyalignedwiththecamera.
1InIRIS,theBLEthroughputis527kbps,whiletheHM01B0cameracanstreama
3.2.6 Context-awaregestures. Weemployasimplegesturesetthat
320x320imageat60fps(6Mbps).Reducingtheresolutiondownto160x120allowsIRIS
totransfermoretotalframesovertime. isadaptedtothedetecteddevice.ThissetcomprisestwointuitiveUIST’24,October13–16,2024,Pittsburgh,PA,USA Kimetal.
Figure6:IRISpipeline.(1)Auserpointsandclicksatthesmartdevicetheywouldliketocontrol.(2)IRISwirelesslystreamstheimagesto
asmartphone,and(3)runsYOLOandDinoV2.(4)Thecenteredobjectdetectionalgorithm(CODA)filtersoutthemultipleobjectsYOLO
maydetectandoutputstheobjectclosesttothecenteroftheframe.IRISthenqueriesthesmartdevicelibrary,butsince,inthisexample,
therearetwoinstancesofBlindsinthehomeitstopshereandutilizestheDinov2path.Next,theoutputembeddingfromDinov2ispassed
asinputto(5)theEmbedding+UUIDdatabasetofindtheembeddingwiththehighestsimilarity,andtheoutputofCODAisalsopassedas
inputtoreducethesearchspace.ThehighestsimilaritycorrespondstoBlinds2UUID,andthe(6)HomeDeviceManagercontrolsBlinds2.
gestures:asinglepressfortogglingdevicestateandapress-and- datasetof10classestocontrolasetoffivecommonsmarthome
hold with rotation, mimicking the action of a physical dial, for devices.Afine-tunedYOLOmodelenablesustoaddressthefirst
fine-grainedcontrol.Table.1illustrateshowthesetwogestures requirementofout-of-the-boxfunctionality.However,westillneed
canbeusedacrossanarrayofIoTdevices.Asinglepresstoggles toaddressourotherrequirements,andYOLOfailstodistinguish
thebinarystateofthedevice,whileapress-and-holdwithrotation betweentwoinstancesofthesameclassandalsodoesn’timprove
allowsforgranularcontrol.Therotationgesturewascalculatedby withouttrainingonadditionaldata.Thus,weaugmentoursystem
firstderivingthetilt(indegrees)fortheIMUaxisthatcorresponded withDinov2toaddresstheshortcomingsofYOLO.Todistinguish
torotationaboutthewristfromtheaccelerometervaluesusing betweentwoinstancesofthesameclass,IRISprovidesascanning
trigonometry.Thistiltvaluewasthenoffsetby90degreesand feature,whichenablesuserstotakepictureswhentheyhavemul-
scaledbetween0and180degrees.Arunning-differenceofchanges tiple instancesof the smartdevice in theirhome. We create an
in this scaled tiled value was maintained and each incremental embeddingdatabasewiththesecollectedpictures,anduserscan
changeintiltwasmappedtoanincrementchangeinvolumeor mapreferenceimagestoaspecificinstanceofasmarthomede-
brightness.Whilethegesturesetcouldbereadilyextendedtoad- vice.Finally,userscanaddressspecificfailurescenariosbyadding
ditionaldevicessuchasgaragedoors,HVACsystems,andsmart additionalreferenceimagesintotheembeddingdatabase.
appliances,thisworkfocusesonthesefivedevicestomaintaina
manageablescopeanddatacollectioneffort.
Device SinglePress Rotation 3.3.1 Out-of-theboxobjectdetection. Ourprimaryfocuswason
Lights On/Off Brightness objectdetectionoffivehouseholdobjects:TVs,smartlocks,blinds,
Speaker Play/Pause Volume lights,andspeakers.Weexperimentedwithseveralwell-known
SmartLock Lock/Unlock - modelarchitecturessuchasResNet18[14],ResNet50[14],Efficient-
TV On/Off Volume NetB0[40],andYOLOv8[43].WemovedforwardwithYOLOasit
Blinds Up/Down - isanobjectdetectionmodel,allowingustodesignaheuristicto
controlaspecificdevicewhenmultipleobjectsofinterestarein
Table1:Context-awaregestureset.
theimage.WhileYOLOv8istrainedontheCOCOdataset[43],it
3.3 NeuralNetworkPipeline
lackedsupportforthefivesmarthomedevicesweaimedtodetect.
Our system was designed with several key requirements. First, Toovercomethislimitation,wecollectedover2,000imagesusing
weaimedforabaselinelevelof"out-of-the-box"functionalityto ascraperonGoogleImagesandapproximately500imagesdirectly
minimize setup for end-users, addressing one of the main pain fromIRIS’scamera.TheoutputofYOLOgoesintoanalgorithm
pointsassociatedwithnewdevices[46].Secondly,thevisionmodel whichiteratesthrougheachboundingboxtoretrievetheobjectthat
needstosupportinstance-basedobjectdetectiontodifferentiate isclosesttothecenteroftheframe.Thisisachievedbycalculating
betweenmultiplesmartdevicesofthesameclasswithinthesame theEuclideandistancebetweenthecenterofeachboundingbox
environment. withrespecttothecenteroftheimage.ThisheuristiccalledCODA
OurpipelineconsistsofafusedmodelcomprisedofYOLOv8[43] (CenteredObjectDetectionAlgorithm),allowsIRIStoreturnthe
andDinoV2[28].AYOLOv8modelwasfine-tunedonacustom objectthatisclosesttowhattheuserpointedat.IRIS:Wirelessringforvision-basedsmarthomeinteraction UIST’24,October13–16,2024,Pittsburgh,PA,USA
Figure7:DINOV2queriesbasedonsemanticsimilarity.Row(A)showsaqueryimageofablind(A1),whilethemaximumsimilarity
referenceimageshowsthesameinstanceoftheblind(A2).Row(B)showsadifferentinstanceofablind(B1),andsimilarlyshowshow
semanticsimilarityisusedtofindthereferenceimagethatrepresentsthesameinstance(B2).Row(C)showsanimageofanHVACunit(C1),
aclasswhichisunlabeledinourYOLOdataset.Again,weobservethatthesameinstanceoftheHVACisreturned(C2).Adifferentinstance
ofanHVAC(C5)furthershowsthatsemanticsceneunderstandingcanbeusedtodistinguishbetweentwoinstancesofthesameclass.
3.3.2 Human-in-the-loop learning with semantic similarity. The X = {𝑟 𝑛𝑖 ∈ 𝑅4×4×382 |𝑛 ∈ {1,2,..,𝑁};𝑖 ∈ {1,..,5}}onthesmart-
aboveboundingboxresultscombinedwithourheuristicdisam- phone.Thenduringtheregularuse,theuserpointsatthedevice
biguateinputframeswithmultipleobjects,andprovideuswitha theywishtocontrolbypointingtheIRISringatthedevice.This
singleobjectclassification.Thisclassificationissufficientinscenar- actionleadstheringtocapturetheimageofthesceneandsend
ioswherethereisoneobject(device)perclassthattheuserwishes ittotheIRISapp.Then,asshowninstep3inFig.6,theappcom-
tocontrol.However,ifauserseekstocontrolmultipledevicesbe- putesaqueryembedding𝑞 ∈𝑅4×4×382correspondingtotheframe
longingtothesameclass(e.g.,twoTVs,oneinthelivingroomand capturedbytheuser.Inparallel,theYOLOmodelpredictswhich
theotherinabedroom),wewouldneedtoclassifyspecificinstances classthequerybelongsto.Basedonthisprediction,wecompute
oftheobjects;beyondjustobject-levelclassification.Takingthis asemanticsimilarityscorebetween𝑞andeachoftheembedding
intoaccount,inadditiontoourout-of-the-boxsolutionbasedona belongingtothepredictedclassinXusingthefollowingalgorithm:
pre-definedsetofclasses,weimplementedahuman-in-the-loop
import torch
modelthatallowsuserstodefineaseparateclassforeachdevice. import torch.nn.functional as F
Theintuitionbehindsuchacapabilityisthatadeviceinahome def compute_similarity(q: torch.Tensor,
is characterized by not just its own visual features but that of r: torch.Tensor):
q = q.view(-1, 382) # shape = [16,382]
thesurroundingsitisplacedinaswell.Forexample,twosmart
r = r.view(-1, 382) # shape = [16,382]
speakersofthesamemakecouldbedistinguishedbythevisual
scene_sim = 0.0
characteristicsoftheroomit’splacedin.Thisnecessitatesusto for pe in q:
extractnotjustthefeaturesoftheobjectofinterestintheframe, # pe is patch embedding
butthefeaturesoftheentireframe.Weleverageadvancesinlarge- scene_sim += F.cosine_similarity(
pe.unsqueeze(0), r, dim=-1
scaleself-supervisedlearningofvisualfeaturessuchasCLIP[30]
).max()
andDINOv2[28]tocomputesemanticfeaturesattheimagelevel. scene_sim /= q.shape[0]
Specifically,weusetheopen-sourceDINOv2[28]modelinour return scene_sim
implementation, to obtain image-level semantic features. For a
Thisstepresultsinasetofsimilaritiescorrespondingtoeachof
givenimageresizedto224x224resolution,wesplittheimageinto thereferenceembeddingsinX.If𝑠 𝑛𝑖isthesimilaritycorresponding
4x4gridandcomputea𝑅382embeddingforeachpatchinthegrid.
tothe𝑖threferenceimageof𝑛thdevice,thenthedevicethatthe
Wenotethattheembeddingcorrespondingtoeachpatchconsiders userwantstocontrol,𝑛ˆ,couldbeinferredwith:
notjustthevisualfeatureswithinthepatchbuttheirrelationto
therestoftheimagepatchesaswell. 𝑛ˆ=argmax{𝑠 𝑛𝑖 ∈ [0.0,1.0] |𝑛∈{1,2,..,𝑁};𝑖 ∈{1,..,5}}
𝑛
TheuserwouldfirstperformasetupwiththeIRISsystemby
capturing a few (1-5) images for each device they wish to con- ThisapproachisillustratedinFig.7.Ontheleftmostcolumn,we
trol.Duringthissetup,theIRISappcomputesa𝑅4×4×382DINOv2 showqueryimagesthattheringcapturedduringitsregularuse.
embeddingforeachreferenceimage.Forasmarthomewith𝑁 Therestofthecolumnsshowdifferentreferenceimagescaptured
connected devices placed at certain locations in the home, our duringthesetup.Ineachrow,thereferenceimagesaresortedin
systemwouldcreateadatabaseofasetofreferenceembeddings decreasingorderofsimilaritywiththequeryimageontheleft.We
canobservethatthesimilarityaccountsfornotjusttheobjectsof
interest,butalsothesurroundingstheobjectisplacedin.UIST’24,October13–16,2024,Pittsburgh,PA,USA Kimetal.
3.3.3 Latencyreductionbycombiningthemodels. Akeychallenge
associatedwithembedding-basedretrievalmethods(likeDINOV2),
liesinthesearchtimeincreasinglylinearlywithdatabasesize.To
addressthis,IRISleveragestheoutputfromYOLO+CODA,which
identifiestheobjectclosesttotheimagecenter.Theoutputclassifi-
cationfromCODAservesasaproxyfortheuser’spointoffocus,
enablingustoreducethesearchspacewithintheuser-collectedref-
erenceimages.Thistargetedsearchstrategynoticeablyreducesthe
runtimerequiredforDINO’squery,enhancingend-to-endsystem
latencywithoutcompromisingaccuracy.Weevaluatethismethod
across86referenceimagesin§4.3.1.
3.4 TrainingMethodology
WhiletheCOCOdatasetYOLOv8istrainedonincludesappliances
initssetof20classes,itlackedsupportforthefivesmarthome
Figure8:IRISmobileapp.(Left)Defaultviewwhenuseropens
devicesweaimedtodetect.Furthermore,wedonotrequirethede-
theapp.UserscanobservetheIRIScameraoutput;primarilyfor
tectionmodeltopredictboundingboxesforobjectsnotinourfive
debuggingandexperimentaluse.(Middle)Usercanselectaspecific
classesofinterest.Toaddresstheseaspects,wefine-tuneYOLOv8
devicetotakenewreferenceimagesfor.(Right)UserviewstheIRIS
bycollectingpicturesusingascraperonGoogleImages.While
camerathroughtheapptocreatenewreferenceimages.
theseweb-scrapedimageswereeasytocollect,theyfailtomodel
ourcamera’scharacteristicslikefield-of-view,dynamicrange,and
low-lightsensornoise.Thus,wealsocollectedandcreatedadataset containnoneoftheobjectsthatIRISaimstodetect;thisissothat
directlyfromIRIS’scamera.Weadoptahybridtrainingmethod- themodeloutputsfewerfalsepositives.Afterdataaugmentations,
ologywherewefirsttrainonourweb-scrapeddataset,andthen ourin-the-wilddatasetcomprisedof1225totalimages.Thisdataset
fine-tuneonrealdatafromourhardware.Ourresultsshowthat wassplitfor86%training,7%validation,and7%testingsubsets.
ournetworktrainedinthiswaygeneralizestoreal-worldimages
capturedfromIRIS’scamera. 3.5 MobileDeviceIntegration
3.4.1 Web-scrapeddata. Wecollectedover2000imagesofourde- Uponinitialapplaunchandrelevantuserpermissions,i.e.,access-
siredclasses.Intotal,thisdatasetcontains287lights,309speakers, ingcontrolofsmarthomedevicesandBluetooth,theHomeKit
521smartlocks,178doorhandles,32doors,198blinds,197televi- frameworkretrievesinformationonuser-registeredhomes,smart
sions,and210windowsfromGoogleImages.Weincludedoorsand homedevices,theircapabilities,configurations,anduniqueiden-
doorhandlesasitisdifficultforYOLOtoaccuratelydetectsmart tifiers.Usingthismetadata,webuildasmartdevicelibraryand
locksfromfarawayduetotheirsmallsize,ultimatelyresolvingto anembeddings+UUIDdatabasewhichourHomeDeviceManager
fewfeaturesfromfardistances.Additionally,beingabletodetect usestocontrolthedesiredenddevice.
windowsallowustorejectfalsepositives(e.g.sunlightbeingrecog- After IRIS connects to the iPhone, it waits for the button to
nizedasahomelightsource).Thesystemcanfallbacktodetecting bepressedpriortosendingdatawirelessly.Onceauserpresses
doors at far distances to ultimately trigger a smart lock. These thebuttontoinitiateagesture,IRISenterstheACTIVEstateand
imageswerethenconvertedtogreyscaleandresizedto160x160. startsstreamingwirelessdatapackets,whichcontainasequence
ThesetransformationsweredonetomimicIRIS’scameraspecifica- number,statusflags,IMUvectors,andimagepixels.Eachimage
tions.Further,weapplieddataaugmentationssuchashorizontal frameissplitandtransmittedacrossmultipledatapackets,andthe
flipping,cropping(0-20%),rotations(-15deg,15deg),brightness sequencenumberisamonotonicallyincreasing8-bitvalueused
(-15%,15%),andexposure(-10%,10%).Thesedataaugmentations toinvalidateimageframesintheeventofdroppedpackets.Status
bringtheweb-scrapeddatasettoatotalof3,526images.Wesplit flagsincludefieldssuchasthebuttonstateandstart-of-frame.Since
thisdatainto90%trainingand10%validationsubsets. IRIScontinuouslystreamsimages,thestart-of-frameflagmarks
thestartingpacketofanewimageframeandactsastheboundary
3.4.2 In-the-wilddata. Whilethemodeltrainedonourweb-scraped betweenconsecutiveframes.Thestart-of-frameflagalsosignals
datawasabletodetectobjectsfromour5desiredclassescorrectly, theendofthepreviousframetostartinference.Thedatapipeline
itfailedtoadapttoimagecharacteristicsofIRIS’scamera.Thisis isshowninFig.5.
becausetheweb-scrapedimagesdonotcontaincharacteristicssuch Ourfine-tunedYOLOv8model’sweightsaretransformedtoa
asthecamera’sdynamicrange,resolution,andsensornoise.Toad- CoreMLPackagewhichwethenloadintoApple’sVNCoreMLModel
dressthis,wefurtherfine-tuneonadatasetofcapturedimagesfrom toperformrequestsandreceivepredictionsandtheirbounds/bound-
ourring.Wecollected513imagesacross5differenthomesfrom ingboxes.Therawpixelvaluesofthestreamedimagesaretrans-
variousanglesandlightningconditionstogeneralizetounseen formedintoabitmapimagecalledCGImageandpreprocessedinto
environments.Thisdatasetincludes98blinds,57doors,34door thedesiredshaperequestedbythemodel.CODAthenfindsthe
handles,228lights,24smartlocks,73speakers,64televisions,37 centerobjectbysearchingfortheboundingboxclosesttotheimage
windows,and161background(null)instances.Backgroundimages center,andreturnsthisastheclassifiedobject.IRIS:Wirelessringforvision-basedsmarthomeinteraction UIST’24,October13–16,2024,Pittsburgh,PA,USA
Figure10:UserinteractionwithourIRIShardware.Y-axis
Figure 9: IRIS User Study. A participant from our user study
showsnumberofparticipantswhorankedusingascorefrom1-5.
interactswithalightandaspeakerusingourIRIShardware.
Scoresfor1havebeenomittedasnoparticipantsrespondedwith1.
ForIRIStodetectbetweenmultipleinstancesofthesameclass, .
thesystemrequiresreferenceimages(embeddings)ofthedevice andhavemorerangeofmotioninone’shandifIRISwereplacedon
to besaved to persistentstorage. We implement a "scanmode" themiddledigitoftheindexfinger.Weprovideparticipantswitha
throughtheapp,duringwhichtheusercanpoint-and-clickatthe setofmetalrings(similartoIRIS’sweight)forsizingtheirmiddle
targetdeviceandscenetocreateembeddingsviaDINOv2.Users andproximaldigits.Twomarkersontheringsindicatecameraand
canthenassociatethesereferenceimageswithatargetdevicein buttonpositions.
their home. Due to limitations of CoreML, we relied on ONNX Oncetworingswerechosen,weaskedparticipantstoimagine
Runtimeforsimplifiedcross-platformmachinelearningintegration thatthesemockringsweresmartringsdesignedtocontrolsmart
tohostourDINOv2model.Withtheimagepreprocessingbaked devices.Weinformedparticipantsofthegestureset(point-and-
intotheDINOv2ONNXmodel,wepassintherawpixelvaluesto click,point-hold-rotate,double-click),andhadthemperformthese
createtheembeddingswhichwillthenbeautomaticallycompared gesturesonalampandaspeaker.Afterevaluatingbothplacements,
againststoredreferences. theywereprovidedwithashortqualitativequestionnaire.
Ultimately,theretrievedembeddingwiththehighestsimilarity Thequestionsetincluded:(1)Whichconfigurationfeltmorecom-
actsasakey,whichisthenusedtofetchtheuniqueidentifier(UUID) fortableforuse?,(2)Whichconfigurationdidyouhaveaneasiertime
ofthetargetedsmartdevicewithintheuser’shome.Afterretrieving "aiming"thecamerawith?,and(3)Betweenthetwoconfigurations,
theUUID,wecontrolthecorrespondingdeviceviaHomeKit. whichdidyouprefer?.Theresponsestothesequestionsareshown
inTable2.Foreachquestion,weconductedaone-tailedbinomial
4 EVALUATION testtounderstandiftheresultwasstatisticallysignificant.Overall
comfortwascomparablebetweenthetwoconfigurationswithba-
4.1 UserStudy
sicallyanevensplitacrossthe23participants(52.2%/47.8%).While,
Werecruited23participants(16male,7female)aged18-35(𝜎=4.72) 56.5%ofparticipantspreferredtheproximalpositionduetocon-
forauserstudy.Ourstudyincludedaninitialplacementstudy vention,thisresultisn’tstatisticallysignificantenoughtodesign
tounderstanduserpreferencesfortheplacementofIRISalong theringinthisposition.Easeoftargetingthesmartdevicebetween
theindexfinger.Thesecondpartinvolvedparticipantsinteracting thetwoconfigurationswastheonestatisticallysignificantresult
in real-time with smart devices with IRIS and their voice. The ofthisstudywhere73.9%ofparticipantspreferredthemiddledigit.
participantswerealsoprovidedashortquestionnaireaskingthem Thisresultcorrespondstoap-valueof0.005.
abouttheiroverallexperienceandtocompareIRISagainstvoice
4.1.2 InteractionusingIRIShardwareandvoice. Thegoalofthe
interaction.Priorwork[32]hasshownthatsmartphoneappsand
nextpartofourstudywastocompareIRISagainstacommercial
screen-basedinteractionsareevenslowerthanvoicecontrol,and
voiceassistant.Asourneuralnetworkimplementationandhome
assuch,wereomittedfromthisstudy.
devicemanagementwereimplementedoniOS,weoptedtocom-
pareagainstSiri.BenchmarkingagainstSiriguaranteesthatthe
Question Middle Proximal P-value
communicationunderthehood(i.e.,HomeKit)remainsthesame
Comfort 52.2% 47.8% 0.339
betweenthetwointerfaces.
Targeting 73.9% 26.1% 0.005
ThisnextphaseofourstudybeginswithintroducingIRISto
Preference 43.5% 56.5% 0.202
theparticipants.TofamiliarizetheparticipantswithIRIS,wefirst
Table2:Placementstudyresults. playashort30-seconddemonstrationvideo.Next,wepermitted
themtotryoutIRISbycontrollingapairofsmartdevices,lights
4.1.1 Placementstudy. Ringsaretypicallywornontheproximal andspeaker.Afterconfirmingtheircomfortandconfidenceusing
digitofauser’sfinger.However,conventionalringsarenotde- IRIS,participantsengagedinaseriesoftrials.Thefirsttrialin-
signedforaimingandcontrollingsmartdevices.Whilecreatingour volvedaproctorwhodirectedtheparticipantstocontroleither
hardware,wehypothesizedthatitwouldbeeasiertoaimatdevices thelightsorthespeaker,togglingthedevice’sstateinresponseUIST’24,October13–16,2024,Pittsburgh,PA,USA Kimetal.
IRIS Siri NoDiff P-value
TogglingState 56.52% 39.13% 4.34% 0.202
GranularControl 78.26% 17.39% 4.34% 0.001
SocialAcceptability 69.57% 13.04% 17.39% 0.017
IRIS Siri Both P-value
Day-to-dayUse 34.78% 17.39% 47.82% 0.196
Table3:Head-to-headsubjectiveperformance.
tocues.10ofthesetrialswereconductedforbothIRISandvoice.
(a)
IRIStrialsinvolvedahands-at-reststeptoensurethateachevent
startsindependentlyoftheprevious.Thesecondtrialevaluatedthe
granularcontrolperformancebetweenIRISandvoice.Participants
weretoldtosetthespeakervolumetothatofaloudgatheringora
pleasantambientlevelbasedoniftheproctorsaid"loud"or"quiet".
Intotal,wecollected690IRISandvoicetrials.Finally,thesetrials
wereallcollectedovervideo,whichweusetoassessthespeedand
efficiencybetweenIRISandacommercialvoiceassistant,later.
4.1.3 Qualitativeresults. Weconductedaqualitativeanalysisofthe (b)
overalluserexperience,measuredbyMeanOpinionScore(MOS),
Figure11:HistogramofUserInputtoDeviceOutput. (UIDO)
andassessedsubjectivepreferencesbetweenIRISandvoiceamong
(a)andtimestosetdesiredvolume(b)forIRISandvoice.
participantsinourstudy.Participantsweregiven3questions:
Finally,wesurveyedparticipantsandaskediftheywouldpre-
(1) Howwasyouroverallexperienceusingthesmartring?(1:
fertouseIRIS,Siri,orbothforday-to-dayuse.11outofthe23
Awful,5:Amazing)
participantssurveyedmentionedthattheywoulduseboth,and8
(2) Howdifficultwasittousethesmartring?(1:Verydifficult,
participantspreferredIRIS,while4favoredSiri.Ap-valueof0.196
5:Veryeasy)
indicatesthatIRISisnotposedtoreplacevoiceassistantsoutright,
(3) Hownaturalwasittousethesmartring?(1:Veryunnatural,
butrathercoexistalongsidethem.Participantswhopreferredto
5:Verynatural)
usebothsystemsday-to-daywereaskedafollow-upquestionto
Acrossourparticipants,themeanopinionscoreswere4.22,3.96,and explainfurther.Overall,theysaidthatwhilecontrollingdevicesis
4.17,respectively.Thedistributionofscoresacrosseachcategory easierandfasterwiththering,theremaybetimeswhenthering
isshowninFig.10.Whilethesescoresindicateagenerallypositive isnotworn,inwhichcasetheubiquityofvoicewouldbeadvan-
response, it is difficult to confirm without a direct comparison. tageous.Anotherpopularcommentwasthattheremaybetimes
Toaddressthis,weaskedfourspecificquestionsregardinguser (i.e.,inaconversation)whenusingvoicetocontroladevicewould
experiencebetweenIRISandatraditionalvoiceassistant. beinappropriateascomparedtothering.Afewparticipantshigh-
(1) Betweenusingyourvoiceandthesmartring,whichwould lightedhowmucheasieritwastocontrolvolumewithIRIS,anda
youprefertousetotoggleadevice’sstate(i.e.turningalight singleparticipantreportedthatvoicecontrolwouldbepreferable
ONorOFF)? iftheirhandswereoccupiedandcarryingotheritems.
(2) Betweenusingyourvoiceandthesmartring,whichwould
4.1.4 Quantitativeresults. Weconductedaquantitativeanalysisof
youprefertousetogranularlycontroladevice’soutput(i.e.,
theuserinputtodeviceoutput(UIDO)timebetweenIRISandSiri
aspeaker’svolume)?
fortogglingthestate(on/off)ofasmart-lightandsmart-speakeras
(3) Betweenusingyourvoiceandthesmartring,whichwould
wellassettingthevolumeforthesmart-speaker.Wemeasuredthe
youfindmoresociallyacceptable?
UIDOtimefortogglingthedevicestatemanuallyusingastopwatch.
(4) Whichwouldyoubemoreinclinedtouseday-to-day?
Westartedthetimerattheendofeachproctor’scommandissuance
AsshowninTable.3,IRISoutperformsvoiceacrossallquestions andendeditimmediatelyafterthelightorspeakerstatechanged.
withinouruserstudy.Outoftheparticipantssurveyed,13expressed Forthegranularcontrol,theendofthetrialwasdeterminedby
apreferenceforusingIRISfortogglingthedevice’sstate,while9 avisualconfirmationfromtheparticipantthattheyhadsetthe
favoredSiri.Whilethep-valueisnotstatisticallysignificant(0.202), volumetoalevelthattheydeemedappropriate.
webelievethatthisisattributedtothefactthatourprototype’s ThehistogramsinFig.11showtheUIDOtimeforstatetoggling
camerawasangledslightlyhigherthanitshouldhavebeen.This andvolumecontrolacrossallparticipanttrialsforIRISandSiri
causedsomeparticipantstohavetopointlowerthantheyexpected, control.Fig.11(a)showsthatmostparticipantswereabletocontrol
causingretries.Despitethis,morethanhalfofourparticipants thedevicestatewithin0to2secondsusingIRIScomparedto2
surveyedstillpreferredIRIStoSiri.Intermsofgranularcontrol to4secondswhenusingSiri.Fig.11(b)showsthatforgranular
andsocialacceptability,participantspreferredIRISwithp-values volumecontrolamajorityofparticipantswereabletosettheir
of0.001and0.017,respectively.Consideringthatparticipantswere desiredvolumewithin3to6secondswhenusingbothIRISandSiri.
usingaprototypecomparedtoashippingcommercialproduct,we However,whenusingSiritherewasawiderdistributionoftimes,
believethistobeanotableresult. withawiderpositiveskew.IRIS:Wirelessringforvision-basedsmarthomeinteraction UIST’24,October13–16,2024,Pittsburgh,PA,USA
98
96
94
92
90
1.0 1.5 2.0 2.5 3.0 3.5 4.0
Reference images per instance
Figure13: Accuracyofsemanticsimilaritybasedsearchas
thenumberofreferenceimagesperinstanceincreases..We
reportanaccuracyof98%after3referenceimages.
Figure12:Confusionmatrixresultsacrossourfivesupported AsIRIS’sYOLOnetworkisafine-tunedmodelonanexisting
smartdeviceclassesandbackground.Wereportaclassification architecture,wevalidateitsperformancebasedonmeanaverage
accuracyof95.3%afterprocessingtheimagethroughCODA. prediction(mAP)valuesonthehardwaredataset’stestset.We
usedtheexistingYOLOv8weightsandfine-tuneditonboththe
Forbothcontrolscenarios,themedianUIDOandtimetoset
web-scrapeddataandin-the-wilddatafor75epochseach.After
desiredvolumewaslowerforIRIS(2.2and4.7secondsrespectively)
completingthetrainingagainstthein-the-wilddataset,themodel
thanSiri(4.1and7.6secondsrespectively).Thiscanbeattributed
achievedthefollowingresults:0.793Precision,0.784Recall,0.81
tothefactthatittooklongerforparticipantstoutterafullvoice
mAP50,and0.462mAP50-95.
commandthanperformthebuttonpressandrotationgestures.
WhilethemAP50-95scoremaynotnecessarilyindicatestrong
SinceIRISisimpactedbythepointingaccuracyoftheuser,we
overallperformance,IRISisdependentsolelyonthecorrectclassi-
alsocalculatedtheangularerrorbetweenthecenteroftheimage
ficationofthecenteredobject.Thisisbecauseifmultipledetected
frameandthecenteroftheboundingboxfortheintendeddevice.
objectsexistinaframe,IRISrejectstheoutlierobjectsandoptsto
Theangularerrorwascalculatedbydividingthefield-of-view(FOV)
controltheobjectinthecenteroftheframe.Thus,wecomputeda
ofthecamera(87degrees)bytheresolution,whichwas160toarrive
confusionmatrixtoshowiftheobjectinthecenterwasclassified
atanangular-FOV/pixelof0.54degrees/pixel.Wethenmultiplied
correctly.Fig.12showstheperformanceofourYOLOv8modelaf-
thisvaluebythexandypixelerrorscalculatedfor2344photos
terCODA.Across86images,IRIS’sYOLO+CODAimplementation
gatheredthroughoutthedurationofthestudy.Themedianangular
showsanaccuracyof95.3%forcenterobjectclassification.With
errorwas7.6degreesinthehorizontaldirectionand23.4degreesin
only3falsenegativesand1falsepositiveacrossthetestset,we
theydirection.Weattributethelargererrorintheverticaldirection
believethatthemodelperformssufficientlywellforin-the-wild
duetotherelativepositionofthebuttonandthecameraonIRIS.In
applications.Wenotethatwithalargerin-the-wilddataset,the
thecurrentdesign,thebuttonispositionedtoofarforwardwhich
performanceofthispartofourmodelcouldimprove.
requiredparticipantstohavetorotatethecameratowardsthem
fortheirthumbtoreachthebutton,resultinginthecamerabeing 4.2.2 Human-in-the-loopwithsemanticsimilarity. Forevaluating
angledhigherverticallythanintended. ourinstance-baseddetectionmethod,wecollectauser-definedtest
setof96images.Theseareallcollectedwiththeringandcontain
4.2 VisionPipelineEvaluation 18uniqueinstances(devices):2blinds,1door,4lightingsystems,
2smartlocks,5speakers,2TVs,and2HVACs.Eachinstancehas
We first assess the performance of YOLO+CODA and DINOV2.
3-7imagesassociatedwithittakenfromdifferentperspectives.We
Thesemodelswereevaluatedindependentlyastheirjointperfor-
sampleoneoftheseimageswithoutreplacement anduseitasa
manceprimarilyreducesruntimebyreducingthesearchspace
queryimage.Therestoftheimagesareconsideredreferences.We
intheDINOV2(Embedding)database(seeFig.6).Classification
thenpredicttheinstanceassociatedwiththequeryimageusingthe
accuraciesofourmodelsareindependentofoneanother.Welater
semanticsimilaritybasedsearchalgorithmdescribedin§3.3.2.This
evaluatethelatencyofjointlyrunningthemodels(§4.3.1).
predictioniscomparedagainsttheground-truthinstancethisquery
4.2.1 Out-of-the-boxobjectdetection. Weevaluateourobjectde- wassampledfrom,andmarkedasacorrectorincorrectdetection.
tectionperformanceacross5homes,andthe5classesIRISsupports Thisprocessisrepeatedacrossall18uniqueinstancesinthetest
out-of-the-box(blinds,smart-lock,speaker,tv,lights)alongwith set.Accuracyiscomputedovertheentiresetastheratioofcorrect
background(null).Theobjectswerelocatedinavarietyofrooms predictionsoverthetotalnumberofqueries.
(bedrooms,livingrooms,kitchen,andoffice)andvaryinglighting Toevaluatehowmanyreferenceimagesauserneedstocollect,
conditionsandangles.Therewasnooverlapinimagesbetween werepeatthisprocesswhilelimitingthenumberofreferenceim-
ourtrainingandtestdatasets. agesperinstance.Thisexperimentallowsustogaininsightby
)%(
ycaruccAUIST’24,October13–16,2024,Pittsburgh,PA,USA Kimetal.
Figure14:Anexamplefailurescenariowithsemanticsimilaritysearch.Thisprimarilyoccursduetothelackofsufficientlydiverse
references.Inthetoprow’sinferencewith3referenceimages,thereferenceimagescorrespondingtothecorrectinstancedonotcontainthe
smartlockofinterestintheon-state.Sosemanticsimilaritysearchwronglypickedadifferentsmartlockinstanceintheon-state.Inthe
bottomrow,whenweaddareferencewiththecorrectsmartlockintheon-stateaswell,wepickthecorrectsmartlockinstance.
measuringtheaccuracyasafunctionofthenumberofreference Embeddingdatabasesize 4 50 100
images available per instance. The accuracy obtained from this Hardware 293ms 293ms 293ms
evaluationisobservableinFig.13.Ourresultsindicatethat2ref- YOLOv8 28ms 28ms 28ms
erenceimagesarerequiredperinstancefor95%accuracyand3 EmbeddingGeneration 8ms 8ms 8ms
imagesreachesanupperboundof98%accuracy.Wenotethatthese EmbeddingQuery 9ms 244ms 423ms
referenceimagesareonlyrequiredforwhenmultipleinstancesof Totallatency 338ms 573ms 752ms
thesameclassarewithinthehomeand/oranew/unseenIoTdevice
Table4:LatencyBreakdown.Querytimesareacrosstheentire
(e.g.HVAC)needstobedetected.
database(DINOV2only)andarereducedviaYOLO+CODAsearch
Thisapproachresultsinveryfewinaccuratepredictions(2%),
spacereduction.Resultsareshowninthefigurebelow.
anexampleofwhichareshownintheFig.14.Failureswithse-
manticsearchprimarilyoccurduetoalackofsufficientlydiverse
references.Inthetoprowexample,themodelincorrectlypredicts
adifferentsmartlockasthebestmatch.Wecanobservethatthisis
causedbecausenoneofthereferencescontainthesmart-lockinits
onstate,butanotherreferenceofadifferentsmart-lockcontains
anexampleinitson-state.Weobservethatwhenweincludea
referencewiththequeriedsmart-lockinitson-state,theprediction
isaccurateasshowninthebottomrowofFig.14.
4.3 SystemEvaluation
4.3.1 Latency. End-to-endlatencyinoursystemisdefinedasthe
timeelapsedbetweenaparticipantcompletingagesture(e.g.click-
ing the button) and the corresponding HomeKit command (e.g.
togglinglights)beingtransmittedviaaniPhone.Thisincludesmul- Figure15:Querytimesforspecificclassesagainsttheentire
tiplecomponentsasshowninTable.4.Westartourmeasurement embeddingdatabase.WithonlyDINOV2,wereportaruntime
byfirstputtingIRISintotheIDLEstate(cameraclock-gatedand of411ms.UtilizingtheclassificationoutputfromYOLO+CODA
IMUsuspended)asthisisthedefaultstateofIRISwhennotin allowsustoreducethesearchspacetoaspecificclass,reducing
use.Ahardwareinterrupttriggersuponimagetransfercompletion latencybyhundredsofmilliseconds.
through the nRF52840’s BLE stack. We measured the hardware thislatencyscaleslinearlywiththedatabasesize.Wemeasured
latencyusinganoscilloscope,calculatingthedeltabetweenthe querytimesacrossarangeofdatabasesizes(4to100embeddings),
button’sfallingedgeandtheimagecompletioninterruptpin.This resultinginvaluesrangingfrom9msto423ms,respectively.Even
experimentyieldedahardwarelatencyof293ms,closelyaligning inthescenariowhereIRISqueries100embeddings,thetotalsystem
withtheexpectedvaluediscussedin§3.2.2. latencyremainsat752ms.Thesemeasurementswereallperformed
TheothercontributorstolatencyinoursystemareYOLOand onaniPhone13.
DinoV2.WemeasuredYOLOlatencyontheiPhoneandobserved Tofurtheroptimizeinferencelatency,weutilizedtheYOLO+
valuesbetween24-28ms.ForDinov2,wefirstmeasuredtheem- CODAoutputtoreducethesearchspaceforrelevantembeddings
beddingcomputationtime,whichwas7.69ms.Next,weevaluated thatsolelyalignwiththeclassifieddevice.Wemeasuretherun-
thetimerequiredtoquerytheembeddingdatabase,notingthat timeusingthistechniqueacrossanembeddingdatabasesizeof86IRIS:Wirelessringforvision-basedsmarthomeinteraction UIST’24,October13–16,2024,Pittsburgh,PA,USA
Component SLEEP IDLE ACTIVE
SoC(ISP1807) 4.23𝜇W 3.53mW 19.2mW
IMU(BMI270) 6.3𝜇W 6.3𝜇W 0.76mW
PMIC(MAX77650) 23.5𝜇W 23.5𝜇W 0.148mW
Camera(HM01B0) – – 1.1mW
EstimatedTotal >34.03𝜇W >3.76mW 21.2mW
MeasuredTotal 86.5𝜇W 6.63mW 26.1mW
Table5:IRIShardwarepowerconsumption.
Gestures/hr BatteryLife BatteryLife(SLEEP>8hrs)
10 16.6hrs 32.9hrs
Figure16: IRISDistancePerformance.
30 15.9hrs 31.5hrs
60 14.9hrs 29.5hrs orabsenceofaboundingboxaroundthetargetdevice.Thefurthest
Table6:Batterylife(hours)acrossdifferentgestureratesforthe distanceatwhichaboundingboxwasconsistentlygeneratedfor
27mAhbatteryonourringhardware. the device was recorded as the maximum detection range. Full
detectionrangeperformanceisobservableinFig.16.
images,correspondingto16uniquedeviceinstances(2blinds,1 ThisapproachofferedapracticalwaytoassessIRIS’sperfor-
door,4lights,2smartlocks,5speakers,and2TVs).WeshowinFig. manceinareal-worldsetting.Ourresultsalignedwellwithourex-
15,thatreducingthesearchspaceinthiswayreducesthequery pectationsassmalldeviceswithfewfeaturesfailedfirst(HomePod
runtime on the order of hundreds of milliseconds. This latency Mini).Similarly,largerobjectslikeblinds,televisions,andbright
optimizationcanbequitesignificantforinteractivemobilesystems. lightscouldstillbepickedupbyYOLOatfartherdistancesbutfail
Finally,wenotethatfurtherlatencyoptimizationcouldhavebeen oncetheobjectbecamesmallwithrespecttotheimagedimensions.
achievedbyutilizingbothadedicatedvectorizedmatrixlibraryand Thetechniquesdescribedin[17]couldpotentiallybeusedinfuture
parallelization.However,weleavethistofuturework. toimproveperformancefurtherforsmallobjectdetection.
4.3.2 Powerconsumption. Tocalculatetheexpectedbatterylife 4.3.4 Low-light conditions. We evaluate IRIS’s object detection
duringusage,wefirstconnectedthebatteryterminalsofIRISto performanceinlow-lightenvironmentswithaseriesofcontrolled
apowersupplythathas𝜇Aresolution.Wemeasuredthecurrent
experiments.WeassessedIRIS’sabilitytodetectsmarthomeobjects
drawofIRISat4.2Vduringeachofthethreepowerstates(ACTIVE, acrossarangeofilluminancelevels(lux).Acontrollablelighting
IDLE,andSLEEP)foratleast25seconds.Foreachoperatingmode, systemcapableofadjustingbrightnessfrom0to100%wasused
weaveragedthecurrentdrawandderivedthepowerconsumption tocreateacontrolledtestingenvironmentduringnighttimehours.
numbersshowninTable5. Wesystematicallydecreasedlightintensitywithintheroomuntil
TocalculatetheexpectedbatterylifeofIRIS,webeganbyas- IRISfailedtodetectthetargetdevice.Theminimumluxatwhich
suminganaveragegesturedurationofapproximately3seconds aboundingboxwasconsistentlygeneratedforeachdevicewas
inACTIVEmode(26.1mW,6.23mA).Overthecourseofaminute, recordedastheminimumluxrequiredforproperfunctionality.
thisleaves57secondsforwhichthesystemisinitsIDLEstate Acrossthedevicestested,weobservedthatIRISdetectionfail-
(6.63mW,1.58mA).Fromthesemeasurements,wecalculatedthe uresbeganwhentheroom’silluminancelevel(lux)approached
averagepowerconsumptionfor𝑁 gesturesoverthecourseofan orfellbelow1.Thisindicatessuccessfuloperationinquitedark
hour,givinganaveragecurrentdrawof1.58mAforasingleges- environments.Theseresultsarelargelyduetotworeasons.First,
tureforonehour.Table6showstheexpectedbatterylifeofIRIS ourcameraisconfiguredforauto-exposure,reducingitsshutter
fordifferentnumbersofgesturesperformedperhour.Evenat60 speedinbrightscenarios,whileincreasingitsshutterspeedindark
gesturesperhouror1gestureaminute,IRIScanlast15hoursona scenarios.Wenotethatthecamera’smaximumexposuretimeis
fullcharge.Finally,wemodelIRIS’sbatterylifeforuserswhoare 1/160thofasecond,or6.3ms.Thisistypicallytheupperbound
awayfromhomeforupto8hoursaday.Thisallowsustoenter formodernDSLRcameras,withoutin-bodyimagestabilization,to
SLEEPmode(IRIS’slowestpowerstate),astheuserisawayfrom beabletotakeimageswithoutmotionblurfromtheuser’shand.
theirhomeWi-Fi,andIRISneednotbeconstantlywaitingforuser Second,YOLO’sfeatureextractioncapabilitiesremainrelatively
input.Intheseusecases,IRISisabletolastbeyond24hours. stronguntilthereisanabsenceoflight.Overall,IRISisableto
WhiletheIRISnetworkconsumes774MIPSduringoperation, maintainsomelevelofdetectionforthetargetdeviceseveninex-
thisisexclusivetotheACTIVEstate.SinceIRIS’susecaseisepisodic, tremelylow-lightconditions.Passingandfailingexamplesfrom
theoverallimpactonasmartphone’sbatterylifeisminimal. thisexperimentareshowninFig.17.
4.3.3 Distance. OurimplementationenablesustoobserveIRIS’s
5 LIMITATIONSANDDISCUSSION
detectioncapabilityinreal-timeusinganiPhonedisplay.Thus,the
effectivedetectionrangeofIRISwasevaluatedforvarioussmart OurworkwithIRISlaysthegroundworkforseveralexcitingfuture
homedevicesthroughavisualfeedback-basedapproach.Foreach directions,whichstemfromthelimitationsofourcurrentimple-
device,westartedattheminimumdistanceatwhichaboundingbox mentation.Oneareaofexplorationinvolvesexpandingthegesture
wasobservedandprogressivelysteppedbackward.IRIS’sdetection settoincorporatemoreintuitiveinteractionsoradditionalutility.
capabilityatfartherdistanceswasevaluatedbasedonthepresence Theresultsfromtheringgestureelicitationstudy[13]showendUIST’24,October13–16,2024,Pittsburgh,PA,USA Kimetal.
Runningtheneuralnetworkonthemobilephoneaffectsitsbat-
terylife.Offloadinginferencefromthemobiledevicetothesmart
homehubisanotherpromisingavenueforimprovement.Thisap-
proachwouldbenefitbatterylifebyminimizingthecomputational
demandsplacedontheuser’sphone.Alternatively,embeddingthe
inferenceontheringcouldbeamoreprivacy-preservingapproach,
alleviatingtheneedtostreamimageswirelessly.Withtherecent
advancesinacceleratorhardware,thiscouldbeapossibilityinthe
nearfuture.
SinceIRIShaslimitedusecasesoutsidethehome,incentivizing
userstoweartheringalldayisofnotableimportance.Integrating
IRIS’sfeatureswithexistinghealth-trackingsmartrings,suchas
Oura,Ultrahuman,ortheSamsungGalaxyRing[22,29,42],would
provideusersareasontoweartheringallday.IRISwouldthen
augmentexistingsmartringsbyprovidingsmarthomecontrol
inadditiontotrackingdailyhealthmetrics.Anotherapplication
wouldbetocontrolon-the-goaccessorieslikeBluetoothspeakers
andheadphones.AnaccessibilityapplicationofIRIScouldbefor
Figure 17: Low-light testing examples. Rows ordered in in-
individualsexperiencingspeechdifficultiesduetoconditionslike
creasingilluminance.50%brightnesssetbyourlightingsystemis
stuttering,apraxia,ordysarthria.IRIScouldofferavaluablealter-
approximately12lux,20%-2lux,and10%-1lux.Failuresforspeaker
nativetotheconventionalvoiceassistantforthespeech-impaired
andlightsoccurredwhenourlightingsystemwasturnedto0%,
population.Exploringthishoweverisnotinthescopeofthispaper.
whileblindsfailedat10%.Allexampleswerecollectedatnight.
users’preferencesforanextensivereferentgesturesetperformed
6 CONCLUSION
witharingtocontrolvariousdeviceswithinasmarthome.Many
ofthesecontrolscanbemappedtoIRIS’ssimplegestureset,but WepresentedIRIS,thefirstwirelessringform-factorsystemfor
additionalgesturescouldenableIRIStoscalefordevicesthatof- vision-based smart home interaction. To achieve this, we made
fermorefunctionality.Forinstance,apress-hold-and-draggesture multipletechnicalcontributions,includingaSWaP-optimizedwire-
couldenableuserstopreciselycontrolthestoppingpointforblinds. lesshardwaredesignthatintegratesacamerawithinalow-power,
Similarly,slidingorflickingverticallyandhorizontallycouldbe wirelessringformfactor.Additionally,weachievedinstance-level
usedtomodulatelightbrightnessorspeakervolume,offeringan classificationthatleveragescontextualscenesemantics.Wedothis
alternativetorotationakintoaphysicaldial.Addingredundancy throughacombinationofYOLOforobjectdetectionandCODA
throughadditionalgestureswouldbebeneficialforuserstopick forcenteredobjectselection.Thissignificantlyreducedthesearch
and choosegesturesthat feel most natural(i.e. IRIS couldoffer spacefortheDINOV2model,optimizingforruntimelatencywhile
severalgesturesforcontrollingvolume).Finally,GestuRING[44] notsacrificinginstanceclassificationperformance.Finally,system-
presentshundredsofpotentialgesturesforwearablerings,and leveloptimizationsensuredreal-timeresponsivenessandextended
in-airoron-bodyinputcouldbeutilizedforcontrollingwearable batterylifeto16-24hours.Evaluationsfromouruserstudyand
devices,likeheadphones. experimentsdemonstrateIRIS’seffectivenessanduserpreference
Detectingsmallobjectsacrossfardistances(Fig.16)and/orun- overtraditionalvoicecontrolinterfaces.Webelievethatthiswork
seendevicesremainsachallengeforourcurrentimplementation. representsanimportantstepthatcaninfluencethelandscapeof
InIRIS,userscouldtakereferenceimagesofadesireddevicefrom ring-basedhuman-computerinteraction.
fartherdistances,andthesystemwouldlearntoutilizeinformation
fromthescenetocontroltheobject.ForunseenclassesinourYOLO
7 AUTHORCONTRIBUTIONS
dataset,userscouldpotentiallytakereferenceimagesoftheunseen
deviceandassociatethemwiththedevice’scorrespondingUUID. ManuscriptPreparation:MKandSGled;AGandBVledspe-
WhileFig.7cshowsthetechnicallyfeasibleofthisforHVACswith cificsections;YLandEGcontributed.Systemconceptualization:
ourexistingsystem,wedidnottestthisextensivelyandleavethis MKandSGconceptualizedthesystem.HardwareandFirmware
explorationtofuturework. DesignandDevelopment:MKleddesignandarchitecture;MK
ExpandingIRIS’shardwarepresentsanotherpromisingavenue andAGjointlycontributedtodevelopment.NeuralNetworkDe-
forfutureresearch.Integratingacapacitivetouchsurfaceinplace signandDevelopment:MKandBVleddesignandarchitecture;
of,oralongside,thecurrentbuttoncouldenableuserstonavigate MKledYOLOdevelopment;BVledDinoV2developmentandEG
digitalscreenswhenpointingIRISatthedevice.Thiscoulden- contributed.DataCollection:MK,AG,YL,EG,andABjointly
ablefunctionalitieslikenavigatingatelevisionmenu.Additionally, contributed.MobileApplicationDevelopment:MKandYLled;
swipingacrossthetouchsurfacecouldprovideanotheralternative AGandEGcontributed.InteractionDesign:MKledoverallde-
torotationsforscenariosrequiringgranularcontrol.Finally,inte- sign.UserStudyDesignandAnalysis:MKandAGjointlyled
gratingadigitalmicrophonecouldleadtoamultimodalinterface, andcontributed.SystemEvaluation:MKledoverallevaluation;
andprovideuserstheadditionaloptionofvoiceinput. AGledanalysisfromspecificsections.IRIS:Wirelessringforvision-basedsmarthomeinteraction UIST’24,October13–16,2024,Pittsburgh,PA,USA
ACKNOWLEDGMENTS
the12thInternationalConferenceonMobileandUbiquitousMultimedia(Luleå,
Sweden)(MUM’13).AssociationforComputingMachinery,NewYork,NY,USA,
TheresearcherswerepartlysupportedbytheMooreInventorFel-
Article39,4pages. https://doi.org/10.1145/2541831.2541875
lowaward#10617,NSFGraduatefellowshipandaThomasJ.Cable [19] RunchangKang,AnhongGuo,GieradLaput,YangLi,andXiang’Anthony’Chen.
EndowedProfessorship.Thisworkwasfacilitatedthroughtheuse 2019.Minuet:MultimodalInteractionwithanInternetofThings.InSymposium
onSpatialUserInteraction(NewOrleans,LA,USA)(SUI’19).Associationfor
ofcomputational,storage,andnetworkinginfrastructureprovided ComputingMachinery,NewYork,NY,USA,Article2,10pages. https://doi.org/
bytheHYAKConsortiumattheUniversityofWashington. 10.1145/3357251.3357581
[20] XiaoyuLi,ShuqinZeng,YanweiZhang,PingWan,andJunWang.2012.Analysis
andprocessingofpixelbinningforcolorimagesensor. EURASIPJournalon
REFERENCES
AdvancesinSignalProcessing2012,1(2012),81. https://doi.org/10.1186/1687-
[1] AmrAlanwar,MoustafaAlzantot,Bo-JhangHo,PaulMartin,andManiSrivastava. 6180-2012-81
2016.SeleCon:ScalableIoTDeviceSelectionandControlUsingHandGestures. [21] BrianD.Mayton,NanZhao,MattAldrich,NicholasGillian,andJosephA.Par-
InProceedingsofthe10thACMConferenceonEmbeddedSystemsforEnergy- adiso.2013.WristQue:Apersonalsensorwristband.In2013IEEEInternational
EfficientBuildings,Vol.2017.IoTDI2017(2017),LogAngeles,CA,USA,107–114. ConferenceonBodySensorNetworks(Cambridge,MA,USA).IEEE,Cambridge,
https://doi.org/10.1145/3054977.3054981pmid:29683151 MA,USA,1–6. https://doi.org/10.1109/BSN.2013.6575483
[2] Amazon.2024.AmazonAlexaVoiceAI|AlexaDeveloperOfficialSite.Amazon [22] JayMcGregor.2024.SamsungGalaxyRing:ReleaseDate,Price,Design,Features.
Alexa. https://developer.amazon.com/en-US/alexa Forbes. https://www.forbes.com/sites/jaymcgregor/2024/03/11/samsung-galaxy-
[3] Apple.2024.HomePod.https://www.apple.com/homepod/. ring-release-date-price-design-features/?sh=308cc8f513bf
[4] RogerBoldu,AlexandruDancu,DenysJ.C.Matthies,ThisumBuddhika,Shamane [23] KentoMiyaoku,AnthonyTang,andSidneyFels.2007.C-Band:AFlexibleRing
Siriwardhana,andSurangaNanayakkara.2018. FingerReader2.0:Designing TagSystemforCamera-BasedUserInterface.InVirtualReality,RandallShumaker
andEvaluatingaWearableFinger-WornCameratoAssistPeoplewithVisual (Ed.).SpringerBerlinHeidelberg,Berlin,Heidelberg,320–328.
ImpairmentswhileShopping. Proc.ACMInteract.Mob.WearableUbiquitous [24] SurangaNanayakkara,RoyShilkrot,KianPeenYeo,andPattieMaes.2013.EyeR-
Technol.2,3,Article94(sep2018),19pages. https://doi.org/10.1145/3264904 ing:afinger-worninputdeviceforseamlessinteractionswithoursurroundings.
[5] LiweiChan,Yi-LingChen,Chi-HaoHsieh,Rong-HaoLiang,andBing-YuChen. InProceedingsofthe4thAugmentedHumanInternationalConference(Stuttgart,
2015. CyclopsRing:EnablingWhole-HandandContext-AwareInteractions Germany)(AH’13).AssociationforComputingMachinery,NewYork,NY,USA,
ThroughaFisheyeRing.InProceedingsofthe28thAnnualACMSymposiumon 13–20. https://doi.org/10.1145/2459236.2459240
UserInterfaceSoftware&Technology(Charlotte,NC,USA)(UIST’15).Association [25] JaredNewman.2022. TheSmartHomeIsFlailingasaConceptBecauseIt
forComputingMachinery,NewYork,NY,USA,549–556. https://doi.org/10. Sucks. https://www.fastcompany.com/90660570/the-smart-home-is-flailing-as-
1145/2807442.2807450 a-concept-because-it-sucks
[6] KaifeiChen,JonathanFürst,JohnKolb,Hyung-SinKim,XinJin,DavidE.Culler, [26] JakobNielsen.1993.SmartHomeStatistics.https://www.nngroup.com/articles/
andRandyH.Katz.2018.SnapLink:FastandAccurateVision-BasedAppliance response-times-3-important-limits/.
ControlinLargeCommercialBuildings. Proc.ACMInteract.Mob.Wearable [27] Oberlo.2024.SmartHomeStatistics.https://www.oberlo.com/statistics/smart-
UbiquitousTechnol.1,4,Article129(jan2018),27pages. https://doi.org/10.1145/ home-market.
3161173 [28] MaximeOquab,TimothéeDarcet,ThéoMoutakanni,HuyVo,MarcSzafraniec,
[7] RajkumarDarbar,MainakChoudhury,andVikalpMullick.2019. RingIoT:A VasilKhalidov,PierreFernandez,DanielHaziza,FranciscoMassa,Alaaeldin
SmartRingControllingThingsinPhysicalSpaces.,2–9pages. El-Nouby,MahmoudAssran,NicolasBallas,WojciechGaluba,RussellHowes,
[8] AdrianA.deFreitas,MichaelNebeling,Xiang’Anthony’Chen,JunruiYang, Po-YaoHuang,Shang-WenLi,IshanMisra,MichaelRabbat,VasuSharma,Gabriel
AkshayeShreenithiKirupaKarthikeyanRanithangam,andAnindK.Dey.2016. Synnaeve,HuXu,HervéJegou,JulienMairal,PatrickLabatut,ArmandJoulin,
Snap-To-It:AUser-InspiredPlatformforOpportunisticDeviceInteractions.In andPiotrBojanowski.2024.DINOv2:LearningRobustVisualFeatureswithout
Proceedingsofthe2016CHIConferenceonHumanFactorsinComputingSystems Supervision. arXiv:2304.07193[cs.CV]
(SanJose,California,USA)(CHI’16).AssociationforComputingMachinery,New [29] Oura.2024.OuraRing.https://ouraring.com/. Accessed:March31,2024.
York,NY,USA,5909–5920. https://doi.org/10.1145/2858036.2858177 [30] AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,
[9] RetailDive.2024.27%IncreaseinSmartHomeAdoptionSince2020:YouGovRe- SandhiniAgarwal,GirishSastry,AmandaAskell,PamelaMishkin,JackClark,
port. https://www2.deloitte.com/us/en/insights/industry/telecommunications/ GretchenKrueger,andIlyaSutskever.2021.LearningTransferableVisualModels
connectivity-mobile-trends-survey/2023/smart-home-industry-adoption- FromNaturalLanguageSupervision. arXiv:2103.00020[cs.CV]
trend.html [31] JosephRedmon,SantoshDivvala,RossGirshick,andAliFarhadi.2016. You
[10] DailyDot.2022. RingZero:TheSmartLogbarThatCouldChangeHowWe OnlyLookOnce:Unified,Real-TimeObjectDetection.InProceedingsoftheIEEE
InteractWithTech. https://www.dailydot.com/debug/ring-zero-smart-logbar- ConferenceonComputerVisionandPatternRecognition(CVPR).IEEE,Seattle,WA,
sxsw/ USA,779–788. https://doi.org/10.1109/CVPR.2016.91
[11] YasuhiroEndo,ZhengWang,JBradleyChen,andMargoISeltzer.1996.Using [32] LeonReicherts,YvonneRogers,LiciaCapra,EthanWood,TuDinhDuong,and
latencytoevaluateinteractivesystemperformance. ACMSIGOPSOperating NeilSebire.2022.It’sGoodtoTalk:AComparisonofUsingVoiceVersusScreen-
SystemsReview30,si(1996),185–199. BasedInteractionsforAgent-AssistedTasks.ACMTrans.Comput.-Hum.Interact.
[12] M.Fiala.2005.ARTag,afiducialmarkersystemusingdigitaltechniques.In2005 29,3,Article25(jan2022),41pages. https://doi.org/10.1145/3484221
IEEEComputerSocietyConferenceonComputerVisionandPatternRecognition [33] AnaRodrigues,RitaSantos,JorgeAbreu,PedroBeça,PedroAlmeida,andSílvia
(CVPR’05),Vol.2.IEEE,SanDiego,CA,USA,590–596vol.2. https://doi.org/10. Fernandes.2019. AnalyzingtheperformanceofASRsystems:Theeffectsof
1109/CVPR.2005.74 noise,distancetothedevice,ageandgender.InProceedingsoftheXXInterna-
[13] Bogdan-FlorinGheran,JeanVanderdonckt,andRadu-DanielVatavu.2018.Ges- tionalConferenceonHumanComputerInteraction(Donostia,Gipuzkoa,Spain)
turesforSmartRings:EmpiricalResults,Insights,andDesignImplications.In (Interacción’19).AssociationforComputingMachinery,NewYork,NY,USA,
Proceedingsofthe2018DesigningInteractiveSystemsConference(HongKong, Article8,8pages. https://doi.org/10.1145/3335595.3335635
China)(DIS’18).AssociationforComputingMachinery,NewYork,NY,USA, [34] MiaSapienza.2022. AreYouStillRelyingonYourPhonetoControlYour
623–635. https://doi.org/10.1145/3196709.3196741 Home? https://www.brilliant.tech/blogs/news/are-you-still-relying-on-your-
[14] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016.DeepResidual phone-to-control-your-home
LearningforImageRecognition.InProceedingsoftheIEEEConferenceonComputer [35] NordicSemiconductor.2022. ThingsYouShouldKnowAboutBluetoothRange.
VisionandPatternRecognition(CVPR).IEEE,Redmond,WA,USA,770–778. NordicSemiconductor. https://blog.nordicsemi.com/getconnected/things-you-
[15] VikramIyer,AliNajafi,JohannesJames,SawyerFuller,andShyamnathGollakota. should-know-about-bluetooth-range
2020.Wirelesssteerablevisionforliveinsectsandinsect-scalerobots.Science [36] RoyShilkrot,JochenHuber,WongMengEe,PattieMaes,andSurangaChandima
robotics5,44(2020),eabb0839. https://doi.org/10.1126/scirobotics.abb0839 Nanayakkara.2015. FingerReader: AWearable DevicetoExplore Printed
[16] ShilpiJain,SriparnaBasu,ArghyaRay,andRonnieDas.2023.Impactofirritation TextontheGo.InProceedingsofthe33rdAnnualACMConferenceonHu-
andnegativeemotionsontheperformanceofvoiceassistants:Nettingdissatisfied manFactorsinComputingSystems(Seoul,RepublicofKorea)(CHI’15).As-
customers’perspectives. InternationalJournalofInformationManagement72 sociationforComputingMachinery,NewYork,NY,USA,2363–2372. https:
(2023),102662. https://doi.org/10.1016/j.ijinfomgt.2023.102662 //doi.org/10.1145/2702123.2702421
[17] Shu-JunJi,Qing-HuaLing,andFeiHan.2023.AnImprovedAlgorithmforSmall [37] LeeStearns,UranOh,LeahFindlater,andJonE.Froehlich.2018. TouchCam:
ObjectDetectionBasedonYOLOv4andMulti-scaleContextualInformation. RealtimeRecognitionofLocation-SpecificOn-BodyGesturestoSupportUsers
ComputersandElectricalEngineering105(2023),108490. https://doi.org/10.1016/ withVisualImpairments.Proc.ACMInteract.Mob.WearableUbiquitousTechnol.
j.compeleceng.2022.108490 1,4,Article164(jan2018),23pages. https://doi.org/10.1145/3161416
[18] LeiJing,ZixueCheng,YinghuiZhou,JunboWang,andTongjunHuang.2013. [38] GeorgeStetten,RobertaKlatzky,BrockNichol,JohnGaleotti,KennethRockot,
MagicRing:aself-containedgestureinputdeviceonfinger.InProceedingsof KimberlyZawrotny,DavidWeiser,NathanSendgikoski,andSamanthaHorvath.UIST’24,October13–16,2024,Pittsburgh,PA,USA Kimetal.
2007. Fingersight:FingertipVisualHapticSensingandControl.In2007IEEE ColorizationforIoTCameras.AssociationforComputingMachinery,NewYork,
InternationalWorkshoponHaptic,AudioandVisualEnvironmentsandGames. NY,USA,Chapter25,1–17. https://doi.org/10.1145/3570361.3592523
IEEE,Ottawa,ON,Canada,80–83. https://doi.org/10.1109/HAVE.2007.4371592 [46] P.K.A.Wollner,P.M.Langdon,T.Goldhaber,I.M.Hosking,A.Mieczakowski,and
[39] GoogleStore.2024.HowtoSetUpaSmartHome.Google. Accessed:March31, P.J.Clarkson.2012.Evaluationofsetupproceduresonmobiledevicesbasedon
2024. users’initialexperience.InNordDesign2012-Proceedingsofthe9thNordDesign
[40] MingxingTanandQuocLe.2019. EfficientNet:RethinkingModelScalingfor Conference,PoulKyvsgaardHansen,JohnRasmussen,KajA.Jorgensen,and
ConvolutionalNeuralNetworks.InProceedingsofthe36thInternationalConfer- ChristianTollestrup(Eds.).CenterforIndustrialProduction,AalborgUniversity
enceonMachineLearning(ProceedingsofMachineLearningResearch,Vol.97), andDesignSociety,UniversityofStrathclyde,Aalborg,Denmark,1–8. 9th
KamalikaChaudhuriandRuslanSalakhutdinov(Eds.).PMLR,MountainView, NordDesignConference,NordDesign2012;Conferencedate:22-08-2012Through
CA,USA,6105–6114. https://proceedings.mlr.press/v97/tan19a.html 24-08-2012.
[41] Punch Through. 2022. Maximizing BLE Throughput on iOS and Android. [47] YoonjongYoo,JaehyunIm,andJoonkiPaik.2015.Low-LightImageEnhancement
PunchThrough. https://punchthrough.com/maximizing-ble-throughput-on-ios- UsingAdaptiveDigitalPixelBinning.Sensors15,7(2015),14917–14931. https:
and-android/#:~:text=It%20is%20important%20to%20know,per%20connection% //doi.org/10.3390/s150714917
20event%20in%20Android [48] SangHoYoon,YunboZhang,KeHuo,andKarthikRamani.2016.TRing:Instant
[42] Ultrahuman.2024. Ultrahuman. https://www.ultrahuman.com//. Accessed: andCustomizableInteractionswithObjectsUsinganEmbeddedMagnetand
March31,2024. aFinger-WornDevice.InProceedingsofthe29thAnnualSymposiumonUser
[43] Ultralytics.2024. YOLOv8. https://github.com/ultralytics/yolov8. Accessed: InterfaceSoftwareandTechnology(Tokyo,Japan)(UIST’16).Associationfor
2024-03-31. ComputingMachinery,NewYork,NY,USA,169–181. https://doi.org/10.1145/
[44] Radu-DanielVatavuandLaura-BiancaBilius.2021.GestuRING:AWeb-based 2984511.2984529
ToolforDesigningGestureInputwithRings,Ring-Like,andRing-ReadyDevices. [49] TengxiangZhang,XinZeng,YinshuaiZhang,KeSun,YuntaoWang,andYiqiang
InThe34thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology Chen.2020.ThermalRing:GestureandTagInputsEnabledbyaThermalImaging
(VirtualEvent,USA)(UIST’21).AssociationforComputingMachinery,NewYork, SmartRing.InProceedingsofthe2020CHIConferenceonHumanFactorsin
NY,USA,710–723. https://doi.org/10.1145/3472749.3474780 ComputingSystems(Honolulu,HI,USA)(CHI’20).AssociationforComputing
[45] BandhavVeluri,CollinPernu,AliSaffari,JoshuaSmith,MichaelTaylor,and Machinery,NewYork,NY,USA,1–13. https://doi.org/10.1145/3313831.3376323
ShyamnathGollakota.2023.NeuriCam:Key-FrameVideoSuper-Resolutionand