[
    {
        "title": "Quantifying Population Exposure to Long-term PM10: A City-wide Agent-based Assessment",
        "authors": "Hyesop Shin",
        "links": "http://arxiv.org/abs/2402.05029v1",
        "entry_id": "http://arxiv.org/abs/2402.05029v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05029v1",
        "summary": "This study evaluates the health effects of long-term exposure to PM10 in\nSeoul. Building on the preliminary model Shin and Bithell (2019), an in-silico\nagent-based model (ABM) is used to simulate the travel patterns of individuals\naccording to their origins and destinations. During the simulation, each\nperson, with their inherent socio-economic attributes and allocated origin and\ndestination location, is assumed to commute to and from the same places for 10\nconsecutive years. A nominal measure of their health is set to decrease\nwhenever the concentration of PM10 exceeds the national standard. Sensitivity\nanalysis on calibrated parameters reveals increased vulnerability among certain\ndemographic groups, particularly those aged over 65 and under 15, with a\nsignificant health decline associated with road proximity. The study reveals a\nsubstantial health disparity after 7,000 simulation ticks (equivalent to 10\nyears), especially under scenarios of a 3% annual increase in pollution levels.\nLong-term exposure to PM10 has a significant impact on health vulnerabilities,\ndespite initial resilience being minimal. The study emphasises the importance\nof future research that takes into account different pollution thresholds as\nwell as more detailed models of population dynamics and pollution generation in\norder to better understand and mitigate the health effects of air pollution on\ndiverse urban populations.",
        "updated": "2024-02-07 16:56:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05029v1"
    },
    {
        "title": "Towards Generalizability of Multi-Agent Reinforcement Learning in Graphs with Recurrent Message Passing",
        "authors": "Jannis WeilZhenghua BaoOsama AbboudTobias Meuser",
        "links": "http://arxiv.org/abs/2402.05027v1",
        "entry_id": "http://arxiv.org/abs/2402.05027v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05027v1",
        "summary": "Graph-based environments pose unique challenges to multi-agent reinforcement\nlearning. In decentralized approaches, agents operate within a given graph and\nmake decisions based on partial or outdated observations. The size of the\nobserved neighborhood limits the generalizability to different graphs and\naffects the reactivity of agents, the quality of the selected actions, and the\ncommunication overhead. This work focuses on generalizability and resolves the\ntrade-off in observed neighborhood size with a continuous information flow in\nthe whole graph. We propose a recurrent message-passing model that iterates\nwith the environment's steps and allows nodes to create a global representation\nof the graph by exchanging messages with their neighbors. Agents receive the\nresulting learned graph observations based on their location in the graph. Our\napproach can be used in a decentralized manner at runtime and in combination\nwith a reinforcement learning algorithm of choice. We evaluate our method\nacross 1000 diverse graphs in the context of routing in communication networks\nand find that it enables agents to generalize and adapt to changes in the\ngraph.",
        "updated": "2024-02-07 16:53:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05027v1"
    },
    {
        "title": "S-Agents: self-organizing agents in open-ended environment",
        "authors": "Jiaqi ChenYuxian JiangJiachen LuLi Zhang",
        "links": "http://arxiv.org/abs/2402.04578v2",
        "entry_id": "http://arxiv.org/abs/2402.04578v2",
        "pdf_url": "http://arxiv.org/pdf/2402.04578v2",
        "summary": "Leveraging large language models (LLMs), autonomous agents have significantly\nimproved, gaining the ability to handle a variety of tasks. In open-ended\nsettings, optimizing collaboration for efficiency and effectiveness demands\nflexible adjustments. Despite this, current research mainly emphasizes fixed,\ntask-oriented workflows and overlooks agent-centric organizational structures.\nDrawing inspiration from human organizational behavior, we introduce a\nself-organizing agent system (S-Agents) with a \"tree of agents\" structure for\ndynamic workflow, an \"hourglass agent architecture\" for balancing information\npriorities, and a \"non-obstructive collaboration\" method to allow asynchronous\ntask execution among agents. This structure can autonomously coordinate a group\nof agents, efficiently addressing the challenges of an open and dynamic\nenvironment without human intervention. Our experiments demonstrate that\nS-Agents proficiently execute collaborative building tasks and resource\ncollection in the Minecraft environment, validating their effectiveness.",
        "updated": "2024-02-08 17:01:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.04578v2"
    },
    {
        "title": "Human-guided Swarms: Impedance Control-inspired Influence in Virtual Reality Environments",
        "authors": "Spencer BarclayKshitij Jerath",
        "links": "http://arxiv.org/abs/2402.04451v1",
        "entry_id": "http://arxiv.org/abs/2402.04451v1",
        "pdf_url": "http://arxiv.org/pdf/2402.04451v1",
        "summary": "Prior works in human-swarm interaction (HSI) have sought to guide swarm\nbehavior towards established objectives, but may be unable to handle specific\nscenarios that require finer human supervision, variable autonomy, or\napplication to large-scale swarms. In this paper, we present an approach that\nenables human supervisors to tune the level of swarm control, and guide a large\nswarm using an assistive control mechanism that does not significantly restrict\nemergent swarm behaviors. We develop this approach in a virtual reality (VR)\nenvironment, using the HTC Vive and Unreal Engine 4 with AirSim plugin. The\nnovel combination of an impedance control-inspired influence mechanism and a VR\ntest bed enables and facilitates the rapid design and test iterations to\nexamine trade-offs between swarming behavior and macroscopic-scale human\ninfluence, while circumventing flight duration limitations associated with\nbattery-powered small unmanned aerial system (sUAS) systems. The impedance\ncontrol-inspired mechanism was tested by a human supervisor to guide a virtual\nswarm consisting of 16 sUAS agents. Each test involved moving the swarm's\ncenter of mass through narrow canyons, which were not feasible for a swarm to\ntraverse autonomously. Results demonstrate that integration of the influence\nmechanism enabled the successful manipulation of the macro-scale behavior of\nthe swarm towards task completion, while maintaining the innate swarming\nbehavior.",
        "updated": "2024-02-06 22:41:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.04451v1"
    },
    {
        "title": "Decentralized Blockchain-based Robust Multi-agent Multi-armed Bandit",
        "authors": "Mengfan XuDiego Klabjan",
        "links": "http://arxiv.org/abs/2402.04417v1",
        "entry_id": "http://arxiv.org/abs/2402.04417v1",
        "pdf_url": "http://arxiv.org/pdf/2402.04417v1",
        "summary": "We study a robust multi-agent multi-armed bandit problem where multiple\nclients or participants are distributed on a fully decentralized blockchain,\nwith the possibility of some being malicious. The rewards of arms are\nhomogeneous among the clients, following time-invariant stochastic\ndistributions that are revealed to the participants only when the system is\nsecure enough. The system's objective is to efficiently ensure the cumulative\nrewards gained by the honest participants. To this end and to the best of our\nknowledge, we are the first to incorporate advanced techniques from\nblockchains, as well as novel mechanisms, into the system to design optimal\nstrategies for honest participants. This allows various malicious behaviors and\nthe maintenance of participant privacy. More specifically, we randomly select a\npool of validators who have access to all participants, design a brand-new\nconsensus mechanism based on digital signatures for these validators, invent a\nUCB-based strategy that requires less information from participants through\nsecure multi-party computation, and design the chain-participant interaction\nand an incentive mechanism to encourage participants' participation. Notably,\nwe are the first to prove the theoretical guarantee of the proposed algorithms\nby regret analyses in the context of optimality in blockchains. Unlike existing\nwork that integrates blockchains with learning problems such as federated\nlearning which mainly focuses on numerical optimality, we demonstrate that the\nregret of honest participants is upper bounded by $log{T}$. This is consistent\nwith the multi-agent multi-armed bandit problem without malicious participants\nand the robust multi-agent multi-armed bandit problem with purely Byzantine\nattacks.",
        "updated": "2024-02-06 21:33:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.04417v1"
    }
]