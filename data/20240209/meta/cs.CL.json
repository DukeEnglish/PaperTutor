[
    {
        "title": "Edu-ConvoKit: An Open-Source Library for Education Conversation Data",
        "authors": "Rose E. WangDorottya Demszky",
        "links": "http://arxiv.org/abs/2402.05111v1",
        "entry_id": "http://arxiv.org/abs/2402.05111v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05111v1",
        "summary": "We introduce Edu-ConvoKit, an open-source library designed to handle\npre-processing, annotation and analysis of conversation data in education.\nResources for analyzing education conversation data are scarce, making the\nresearch challenging to perform and therefore hard to access. We address these\nchallenges with Edu-ConvoKit. Edu-ConvoKit is open-source\n(https://github.com/stanfordnlp/edu-convokit ), pip-installable\n(https://pypi.org/project/edu-convokit/ ), with comprehensive documentation\n(https://edu-convokit.readthedocs.io/en/latest/ ). Our demo video is available\nat: https://youtu.be/zdcI839vAko?si=h9qlnl76ucSuXb8- . We include additional\nresources, such as Colab applications of Edu-ConvoKit to three diverse\neducation datasets and a repository of Edu-ConvoKit related papers, that can be\nfound in our GitHub repository.",
        "updated": "2024-02-07 18:59:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05111v1"
    },
    {
        "title": "Image captioning for Brazilian Portuguese using GRIT model",
        "authors": "Rafael Silva de AlencarWilliam Alberto Cruz CastañedaMarcellus Amadeus",
        "links": "http://arxiv.org/abs/2402.05106v1",
        "entry_id": "http://arxiv.org/abs/2402.05106v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05106v1",
        "summary": "This work presents the early development of a model of image captioning for\nthe Brazilian Portuguese language. We used the GRIT (Grid - and Region-based\nImage captioning Transformer) model to accomplish this work. GRIT is a\nTransformer-only neural architecture that effectively utilizes two visual\nfeatures to generate better captions. The GRIT method emerged as a proposal to\nbe a more efficient way to generate image captioning. In this work, we adapt\nthe GRIT model to be trained in a Brazilian Portuguese dataset to have an image\ncaptioning method for the Brazilian Portuguese Language.",
        "updated": "2024-02-07 18:57:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05106v1"
    },
    {
        "title": "A Roadmap to Pluralistic Alignment",
        "authors": "Taylor SorensenJared MooreJillian FisherMitchell GordonNiloofar MireshghallahChristopher Michael RyttingAndre YeLiwei JiangXiming LuNouha DziriTim AlthoffYejin Choi",
        "links": "http://arxiv.org/abs/2402.05070v1",
        "entry_id": "http://arxiv.org/abs/2402.05070v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05070v1",
        "summary": "With increased power and prevalence of AI systems, it is ever more critical\nthat AI systems are designed to serve all, i.e., people with diverse values and\nperspectives. However, aligning models to serve pluralistic human values\nremains an open research question. In this piece, we propose a roadmap to\npluralistic alignment, specifically using language models as a test bed. We\nidentify and formalize three possible ways to define and operationalize\npluralism in AI systems: 1) Overton pluralistic models that present a spectrum\nof reasonable responses; 2) Steerably pluralistic models that can steer to\nreflect certain perspectives; and 3) Distributionally pluralistic models that\nare well-calibrated to a given population in distribution. We also propose and\nformalize three possible classes of pluralistic benchmarks: 1) Multi-objective\nbenchmarks, 2) Trade-off steerable benchmarks, which incentivize models to\nsteer to arbitrary trade-offs, and 3) Jury-pluralistic benchmarks which\nexplicitly model diverse human ratings. We use this framework to argue that\ncurrent alignment techniques may be fundamentally limited for pluralistic AI;\nindeed, we highlight empirical evidence, both from our own experiments and from\nother work, that standard alignment procedures might reduce distributional\npluralism in models, motivating the need for further research on pluralistic\nalignment.",
        "updated": "2024-02-07 18:21:17 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05070v1"
    },
    {
        "title": "SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models",
        "authors": "Lijun LiBowen DongRuohui WangXuhao HuWangmeng ZuoDahua LinYu QiaoJing Shao",
        "links": "http://arxiv.org/abs/2402.05044v2",
        "entry_id": "http://arxiv.org/abs/2402.05044v2",
        "pdf_url": "http://arxiv.org/pdf/2402.05044v2",
        "summary": "In the rapidly evolving landscape of Large Language Models (LLMs), ensuring\nrobust safety measures is paramount. To meet this crucial need, we propose\n\\emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating\nLLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench\ntranscends conventional benchmarks through its large scale, rich diversity,\nintricate taxonomy spanning three levels, and versatile\nfunctionalities.SALAD-Bench is crafted with a meticulous array of questions,\nfrom standard queries to complex ones enriched with attack, defense\nmodifications and multiple-choice. To effectively manage the inherent\ncomplexity, we introduce an innovative evaluators: the LLM-based MD-Judge for\nQA pairs with a particular focus on attack-enhanced queries, ensuring a\nseamless, and reliable evaluation. Above components extend SALAD-Bench from\nstandard LLM safety evaluation to both LLM attack and defense methods\nevaluation, ensuring the joint-purpose utility. Our extensive experiments shed\nlight on the resilience of LLMs against emerging threats and the efficacy of\ncontemporary defense tactics. Data and evaluator are released under\nhttps://github.com/OpenSafetyLab/SALAD-BENCH.",
        "updated": "2024-02-08 02:50:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05044v2"
    },
    {
        "title": "How BERT Speaks Shakespearean English? Evaluating Historical Bias in Contextual Language Models",
        "authors": "Miriam CuscitoAlfio FerraraMartin Ruskov",
        "links": "http://arxiv.org/abs/2402.05034v1",
        "entry_id": "http://arxiv.org/abs/2402.05034v1",
        "pdf_url": "http://arxiv.org/pdf/2402.05034v1",
        "summary": "In this paper, we explore the idea of analysing the historical bias of\ncontextual language models based on BERT by measuring their adequacy with\nrespect to Early Modern (EME) and Modern (ME) English. In our preliminary\nexperiments, we perform fill-in-the-blank tests with 60 masked sentences (20\nEME-specific, 20 ME-specific and 20 generic) and three different models (i.e.,\nBERT Base, MacBERTh, English HLM). We then rate the model predictions according\nto a 5-point bipolar scale between the two language varieties and derive a\nweighted score to measure the adequacy of each model to EME and ME varieties of\nEnglish.",
        "updated": "2024-02-07 17:07:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.05034v1"
    }
]