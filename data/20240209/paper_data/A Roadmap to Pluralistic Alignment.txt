A Roadmap to Pluralistic Alignment
TaylorSorensen1 JaredMoore2 JillianFisher13 MitchellGordon14 NiloofarMireshghallah1
ChristopherMichaelRytting1 AndreYe1 LiweiJiang15 XimingLu1 NouhaDziri5 TimAlthoff1
YejinChoi15
Abstract
Is it ok for governments to moderate the
social media content available to public?
WithincreasedpowerandprevalenceofAIsys-
Pluralistic
tems,itisevermorecriticalthatAIsystemsare Security Freedom Conformity
Human Values
designed to serve all, i.e., people with diverse
valuesandperspectives. However,aligningmod-
elstoservepluralistichumanvaluesremainsan Overton Many think that it’s not okay for the government
openresearchquestion. Inthispiece,wepropose to moderate content as it endangers liberty,
while others deem it acceptable for prevention
a roadmap to pluralistic alignment, specifically
of terrorism. A few, on the other hand, think it’s
using language models as a test bed. We iden- necessary for sovereignty.
tifyandformalizethreepossiblewaystodefine
and operationalize pluralism in AI systems: 1) It is ok for the government to moderate
Overton pluralistic models that present a spec- Steerable content for terrorism and threats.
trumofreasonableresponses;2)Steerablyplural- or It is not ok to moderate any content as it
or endangers liberty.
isticmodelsthatcansteertoreflectcertainper-
or It is ok for the government to moderate
spectives;and3)Distributionallypluralisticmod- content that endangers its sovereignty.
elsthatarewell-calibratedtoagivenpopulation
in distribution. We also propose and formalize Distributional
threepossibleclassesofpluralisticbenchmarks:
1)Multi-objectivebenchmarks,2)Trade-offsteer-
able benchmarks, which incentivize models to
steertoarbitrarytrade-offs,and3)Jury-pluralistic
Figure1. Threekindsofpluralisminmodels.
benchmarks which explicitly model diverse hu-
man ratings. We use this framework to argue
thatcurrentalignmenttechniquesmaybefunda-
1.Introduction
mentally limited for pluralistic AI; indeed, we
highlightempiricalevidence,bothfromourown AIalignmentaimstoensurethatasystemworkswithhu-
experimentsandfromotherwork,thatstandard manintentionsandvalues(Leikeetal.,2018;Jietal.,2024;
alignmentproceduresmightreducedistributional Gabriel, 2020). However, even within a single task or
pluralisminmodels,motivatingtheneedforfur- prompt, individual people vary widely in their goals, in-
therresearchonpluralisticalignment. tentions,andvalues. Asabroadersetofpeopleuseandrely
uponAIsystems,weneedsystemsthatcanunderstandand
cater to a broader set of needs. In other words, we need
systems that are pluralistic, or capable of representing a
1Department of Computer Science, University of Washing- diversesetofhumanvaluesandperspectives. Whilemany
ton,Seattle,Washington,USA2DepartmentofComputerScience, inthecommunityhavearguedforthis(Baietal.,2022b;
StanfordUniversity,Stanford,California,USA3Departmentof
Gordon et al., 2022; Sorensen et al., 2023), at least two
Statistics,UniversityofWashington,Seattle,Washington,USA
importantquestionsremain: How,concretely,canasystem
4Department of Electrical Engineering and Computer Science,
MIT,Cambridge,Massachusetts,USA5AllenInstituteforArti- bepluralistic? andHowmightbenchmarksbedesignedto
ficial Intelligence, Seattle, Washington, USA. Correspondence measurepluralism?
to: Taylor Sorensen <tsor13@cs.washington.edu>, Yejin Choi
<yejin@cs.washington.edu>. In this piece, we advocate for explicit pluralistic consid-
erations in aligning AI systems (§2). In particular, we
1
4202
beF
7
]IA.sc[
1v07050.2042:viXraARoadmaptoPluralisticAlignment
uselargelanguagemodels(LLMs)asatestbedforalign- Pluralismasavalueitself. Manymodernsocietiesview
ment(Askelletal.,2021),thoughwebelievetheconcepts acceptingcompetingvaluesandperspectivesasacorevalue
cangeneralizetootherAIsystems(§6.3). Becauseplural- inandofitself. Theoristshaveextolledthebenefitsofpolit-
ism may look different in different contexts, we propose icalpluralism(deTocqueville,1835;Berlin,1969;Rawls,
threedistinctwaysofoperationalizingpluralismforAIsys- 1996),moralandvaluepluralism(Nagel,1979;Kekes,1993;
tems/models: 1)providingcomprehensive,high-coverage Raz, 1999), and pluralist theories of truth (Wright, 1992;
responses (Overton pluralism, §3.1), 2) an ability to be Sher,1998). Whilethispieceprimarilyfocusesonsurfac-
faithfullysteeredtorepresentparticularattributes(steerable ing differing ideas, perspectives, and values (§3, 4), our
pluralism, §3.2), and 3) distributional representation of a scaffolding for technical measurements and implementa-
population (distributional pluralism, §3.3). Each form of tionsofvaluecanalsoapplytoothernotionsofpluralism.
pluralismhascaseswheretheymaybedesirabletomaxi- Thisstandsincontrasttocurrentalignmentproceduressuch
mize. Wealsodefinethreetypesofpluralisticbenchmarks: asRLHFwhichhavebeencharacterizedasimplementing
multi-objective benchmarks (§4.1), benchmarks of mod- “preference-basedutilitarianism.” (Tasioulas,2022).
els’steerabilityacrossobjectives(trade-offsteerablebench-
AIsystemsshouldreflecthumandiversity. Wecontend
marks,§4.2),andbenchmarksthatexplicitlymodelindivid-
that AI systems should reflect and support the diversity
uals(jury-pluralisticbenchmarks,§4.3). Wealsooutlinethe
amongsthumansandtheirvalues,asitisbothafeatureand
situationsforwhicheachwouldbeuseful.
adesiredqualityofhumansocieties(§3.3,4.3). Exposure
Wethendiscusstherelationshipbetweencurrentalignment todiverseideas(§3.1)alsoimprovesdeliberation(Bowman
approachesandpluralism(§5)andprovideinitialfindings et al., 2022; Landemore & Page, 2015). Furthermore, al-
thatcurrentalignmenttechniquesreducedistributionalplu- gorithmicmonoculturesleadtoincreasedunfairnesswhen
ralism. We advocate and lay out a plan for future work appliedbymanydecisionmakers(Bommasanietal.,2021).
towardpluralisticevaluationsandalignment.
3.PluralismforAIModels/Systems
2.ArgumentsforPluralisminAISystems
Inthissection,weproposethreedefinitionsforhowasingle
Inthissection,wearguefortheimportanceofpluralismin modelorsystemcanbepluralistic. Specifically,weoutline
aligningAImodels. Overtonpluralism,whereinamodeloutputsthewholespec-
trumofreasonableresponses;Steerablepluralism,wherein
Customization necessitates pluralism. Any guardrails
a model is faithfully steered to reflect certain properties
placed on AI systems will require customization, within
or perspectives; and Distributional pluralism, wherein a
theboundsofthoseguardrails,toservediverseusescases
model’sdistributionoveranswersmatchesthatofagiven
andvalues(Chenetal.,2023;Jangetal.,2023). Pluralism
targetpopulation(seeFigure1). Foreach,wewillalsodis-
canilluminatethesetofvaluesorattributesthatusersmay
cussrelevantapplicationsandpotentialevaluations,along
customizeto,andprovideanunderstandingofhowwella
withlimitationsandrecommendationsforfutureresearch.
systemcanbesteered(§3.2,4.2).
Throughout,wewillconsideramodelorsystemM,aquery
Pluralisticsystemshavetechnicalbenefits.Implicittocur-
x,andaresponsey. Whilewespecificallyfocusonnatural
rentpreference-basedmethodslikeRLHFistheassumption
language queries and responses with M being an LLM,
thatmodelsshouldfittothe“average”humanpreference.
ourdefinitionscanneverthelessgeneralizetootherinputs,
However, this treats human variation as noise instead of
outputs,andmodelsaswell.
signal(Aroyoetal.,2023;Siththaranjanetal.,2023)–plu-
ralism,however,recognizesthisassignal. Modelingplural-
3.1.OvertonPluralisticModels
ismalsomayincreaseinterpretabilitybyenablingaclearer
relationshipbetweendecisionsandtheirsource(§3.2,4.2). Given an input, there are often many potential types (or
modes)ofanswersamodelcanproduce. Forexample,ifa
Pluralistic evaluations enable generalist systems. Re-
userposesaquerytoanLLMforwhichthereisnosingle
cently,AI/NLPhastrendedawayfromspecialistsystems
establishedcorrectanswer,theLLMmayanswerwithany
andtowardsgeneralistsystems(foundationmodels)foruse
oneofseveralreasonableanswers.
inadiversesetoftasksbyadiversesetofusers.Yet,current
alignmentoptimizesthesegeneralistsystemsforasingle DefinitionsGivenaqueryx,considerpossibleanswersy.
objective–averagedhumanpreferences. Tounderstandthe
(1) CorrectAnswerinC: Ananswerwhichcanbeconclu-
strengthsandweaknessesofthesesystems,wemustmea-
sivelyverifiedorwithwhichtheoverwhelmingmajorityof
surehowtheyperformacrossavarietyofobjectives(§4.1)
peopleacrossvariousbackgroundswouldagree.
(Ethayarajh&Jurafsky,2022)andusers(§3.2,3.3,4.3).
(2) ReasonableAnswerinR: Ananswerforwhichthere
2ARoadmaptoPluralisticAlignment
issuggestive,butinconclusive,evidence,oronewithwhich toscale.IftheOvertonwindowisnotproperlydefined,mod-
significantswathsofthepopulationwouldagree.Additional elsmaycontributetobothsidesism/falsebalance(Imundo
top-downrestrictions(e.g.,safety)mayapply. & Rapp, 2021; Boykoff & Boykoff, 2004). One remedy
(3) Overton window: The set of all reasonable answers: may be to present the support or certainty for each rea-
W(x)={y ∈Y|(x,y)∈R}.1 sonableanswerinadditiontoitscontent,althoughcurrent
LLMsstrugglewiththis(Zhouetal.,2024). Also, while
(4) Aresponseset{y}toaqueryxisOverton-pluralistic:
pluralismmayneverbecompletelyneutral,itcanbeconsid-
{y}containsallpotentiallyreasonableanswersintheOver-
eredafairerresponsetoqueries(Haraway,1988). Finally,
tonwindow. Thisisincontrasttopickingjustoneanswer
thisframeworkrequireslong-formresponseswithmultiple
intheOvertonwindow,orpresentinganunreasonablean-
answers;otherconceptsofpluralismmayberequiredfor
swerwhichwouldlieoutsidetheOvertonwindow. Asingle
distributionsovershortanswers(see§3.3).
response may be Overton-pluralistic if it synthesizes the
wholeresponseset{y}. Alignment Procedures and Recommendations While
(5) Model M is Overton-pluralistic: M gives Overton- RLHF may implicitly steer models to Overton pluralism
pluralisticresponsestoqueries,thatisforagiveninputx, to the extent that users prefer it, further study into this is
theoutputofM(x)=W(x). needed. Alternatively,oneapproachtoexplicitlyencourage
Overtonpluralismistakingmultiplesamplesfromamodel
MotivationInmanysituations,therearemanyreasonable (Long,2023;Jungetal.,2022),potentiallypromptingfor
answerstoaquestion(Minetal.,2020;Scherreretal.,2023). diverseoutputs(Hayatietal.,2023),tosimulateanOverton
Ratherthanoutputtingasinglereasonableanswer,which window. Alternatively,onecouldmanuallycreatethebatch
may be selected idiosyncratically or in a biased fashion, ofreasonableresponses. Amodelcanbetrainedtooutputa
Overton-pluralisticmodelsoutputallreasonableanswers. synthesisoftheentirebatch.Datasetswhichidentifyhuman
values(Hendrycksetal.,2020;Sorensenetal.,2023)canbe
PotentialImplementationWeoutlinetwowaystooper-
usedtoevaluateOverton-pluralism. Werecommendfurther
ationalize Overton pluralism. One could define a set of
studyintomodels’currentdegreeofOverton-pluralismand
queries X along with an Overton window of reasonable
howitcanbeamplifiedforrelevantapplications.
answersW(x)foreachqueryaswellasawaytoextractthe
setof“answers"{y}fromamodelresponse. Alternatively,
3.2.SteerablePluralisticModels
insteadofextractingasetofanswers,onecouldenumerate
alistofunreasonableanswersU(x)thatarenotdesirable Apluralisticmodelmightinsteadfaithfullysteer(oralign)
foramodeltooutput. Anentailmentmodel(Shajalaletal., itsresponsestoagivenattributeorperspective,suchasa
2023;Liuetal.,2022)coulddetectwhichreasonableorun- value,framework,orpopulation.
reasonableanswerstheresponseentails.Withbothmethods,
DefinitionsWiththisinmind,letusconsider:
metricslikeprecision/recall/accuracycanbecalculated.
(6) SteeringattributesA: Attributes/properties/perspecti-
Applications Many relevant domains fall under advice-
veswhichwewishamodeltofaithfullyreflect. Examples
giving. Current LLMs often give advice confidently but
includegroupsofpeoplefromasharedculture,philosoph-
inconsistentlyorinanopinionatedmanner,affectingusers’
ical/political schools of thought, or particular values. To
downstreamjudgments(Krügeletal.,2023;Jakeschetal.,
reflectmultipleattributessimultaneously,theelementsofA
2023). Overton-pluralismrequiresconsiderationofmultiple
couldbeconstruedassetsofattributes.
heterogeneousjudgements,encouragingdeliberationover
(7) Responsey faithfullyreflectsattributea∈A: The
spontaneousjudgement(Kant,1788;Rawls,1971). Itcould |x,a
responseytothequeryxisconsistentwith,orfollowsfrom,
alsoaidinscalableoversight(Bowmanetal.,2022)tohelp
attributea.
users annotate model outputs, in the single ground truth
case(Michaeletal.,2023)orwhenwewantadiversityof (8) Model M is steerably-pluralistic with respect to at-
views. Furtherexamplesincludesettingswherewewantto tributes A: Given an input x and an attribute a ∈ A, the
encouragemultipleapproaches,suchasmathematicalproof model M(x,a) conditioned on a produces a response y
writing. whichfaithfullyreflectsa.
LimitationsDefiningandoperationalizingtheOvertonwin- MotivationInmanyinstances,wewantmodelstorespond
dow may present a challenge. If a reasonable answer is toqueriesinaconsistentandspecifiablemanner. Models
determinedbyasetofexpertannotators,itmaybedifficult which have been so heavily “aligned” towards a specific
attributesuchthattheycannotbesteeredtootherattributes
1Ourterminologygeneralizestheconceptofan“Overtonwin-
fail to be useful (or usable) to populations who may not
dow"asusedinpoliticalscience:“thespectrumofideasonpublic
policyandsocialissuesconsideredacceptableorviablebythe sharethatvalueorattribute. Weseeevidenceofthisinthe
generalpublicatagiventime."(OED,2023) “SiliconValley”and“WEIRD”(Henrichetal.,2010)bias
3ARoadmaptoPluralisticAlignment
ofmanyLLMs,whichoftenskewmale,White,American, Theseincludeconditioningoncertaingroups(Argyleetal.,
liberal,andwealthyinperspective(Santurkaretal.,2023; 2023;Hwangetal.,2023)andstudyingwhichconditions
Hartmannetal.,2023;Perezetal.,2022;Santyetal.,2023). (responses, demographics, etc.) yieldthebestagreement.
Lietal.(2023b);Kim&Lee(2023)learnuserembeddings
PotentialImplementationGivenqueriesX andattributes
whichtheyusetoinducecertainvaluesfromLLMs. Zhao
A, one needs a way to condition the model on attributes
et al. (2023) add a module to base LLMs which aims to
at inference. To measure whether a response reflects a,
predictgroupresponsesinafew-shotmanner. Fleisigetal.
one could either use direct human annotations or reward
(2023)predictannotatorratingsforspecificgroups. Sharma
models that are tuned specifically to the attributes, such
etal.(2023c;d)rewriteresponsesforspecificaudiences.
as a value-specific reward (Sorensen et al., 2023). These
attribute-specificfaithfulnessscoreswouldbethedegreeto Webelievethatsteerabilityresearchwillbecomeincreas-
whichamodelissteerablypluralistic. inglyimportantasusersdesiremorecustomizability. While
theremaybecertainbehaviorstowhichamodelshouldnot
Severalpreviousworkshavemeasuredformsofsteerable
bealigned,weadvocateforsystemsthatcanbealignedto
pluralism,particularlywithrespecttomoral,political,and
manyattributeswithinanacceptablerange.
culturalperspectives(Argyleetal.,2023;Jiangetal.,2022;
Simmons,2023;Ramezani&Xu,2023;Santyetal.,2023).
3.3.DistributionallyPluralisticModels
However,previousworksuggeststhatconditionalpluralism
isfarfromsolved(Santurkaretal.,2023). Anotherwaytooperationalizepluralismisinthedistribu-
tionoveranswerscomparedtoagivenpopulation.
Applications An important application of steerable-
pluralismiscustomization. Usersoftenwanttopersonalize DefinitionsInthisframework,weconsider:
modelstowardscharacteristicpropertiesandperspectives
(9) A population or group of people G: A set of people
(Chenetal.,2023),intaskssuchaswritingassistance(Li
whichwewantthemodeltorepresent.
etal.,2023a)andideation(Girotraetal.,2023;Maetal.,
(10) ModelMisdistributionally-pluralisticwithrespectto
2023). Steeringtowardstherapeuticvaluescanhelpinthe
areferencepopulationG: Foragivenpromptx,Misas
mental health domain (Song et al., 2024; Sharma et al.,
likelytoprovideresponseyasthereferencepopulationG.
2023a). Steeringmodelstorepresentmultipledifferentper-
Inotherwords,Miswell-calibratedw.r.t. thedistribution
spectivescanbevaluableincreativeproduction(Shanahan
overanswersfromG.
& Clarke, 2023), psychological inquiry (Shanahan et al.,
2023), simulating social systems (Park et al., 2022), and
MotivationandApplicationsDistributionalpluralismin
deliberative discourse (Danry et al., 2023; Landemore &
anLLMiscrucialforanyapplicationwhereMisusedto
Page,2015;Page,2019;2008).
simulate,interfacewith,orotherwisemodeltheviewsof
Moreover, steerably pluralistic models may have useful apopulation,e.g.,simulatingpopulationsviaagent-based
representationsinavarietyofsettings,suchashatespeech modeling(Törnbergetal.,2023;Parketal.,2022;2023),
detection (Feng et al., 2023) negative thought reframing piloting subject/user responses to surveys (Argyle et al.,
(Sharmaetal.,2023b;c). Ingeneral,thismayallowvarying 2023;Aheretal.,2023),surveydesign(Ziemsetal.,2023),
“cognitivearchitectures”formorestructuredandgenerally orstudyingtheinternetasaculturalartifact(Buttrick,2024).
intelligentsystems(Sumersetal.,2023).
Potential Implementation Let X be a set of queries to
LimitationsSteerablepluralismrequiresdecidingwhich which G gives a distribution Y. For example, a census
attributesareacceptabletosteerthemodel. Wemaywantto surveyorpublicopinionpoll. M’sestimate,Yˆ,canbecom-
disallowsomeattributes(e.g.,hatespeech). Thechallenges paredtothepopulationdistributionusinganydistributional
herearesimilartothoseindeterminingwhichanswersare divergence metrics, such as Jensen-Shannon divergence,
“reasonable”inOverton-pluralism,suchassubjectivityor KL-divergence, or Wasserstein distance (Santurkar et al.,
arbitrarinessintheselectionofsteerableattributes. More- 2023;Durmusetal.,2023),orhardmeasureslikeaccuracy
over, if attributes are defined too broadly, there is a risk ortetrachoriccorrelation(Argyleetal.,2023).
ofstereotypingor“flattening”thenuancesofthecomplex
LimitationsOnepotentiallimitationofdistributionalplu-
perspectivesandpeoplethatattributesareintendedtorepre-
ralism is its proportional nature. This means that more
sent(Durmusetal.,2023). Insomecases,anintersectional
frequent opinions will be output by a model with higher
evaluation(Crenshaw,1989),inwhichattributesarenotcon-
frequency,evenifthisresponseisharmful-althoughmight
sideredindependentlybutinconjunctionwitheachother,
bemitigatedbydefiningawindowofreasonablenessasin
maybenecessary.
Overtonpluralism. Anotherlimitationistheneedforapre-
AlignmentProceduresandRecommendationsTherearea determinedtargetdistribution–apopulation. Increationofa
varietyofwaystoinduceparticularvaluesatinferencetime. generalLLM,likeChatGPT,whoisthetargetdistribution?
4ARoadmaptoPluralisticAlignment
Furthermore,formanyopen-endedqueries,itisnotclear Security
ℳ1
whetherthereisanyresponsefrequencydata. ℳ2
Conformity Freedom o 1(ℳ1)>o 1(ℳ2)
A noli ag ln igm ne mn et np tr po rc oe cd edu ur re es sW toh ei xle p, lit co ito lyur ink cn ro ew asl eed dg ise t, rit bh uer tie oa nr ae
l
o 2(ℳ1)>
...
o 2(ℳ2)
calibration,thereareacouplepromisingdirections. Oneis o 5(ℳ1)>o 5(ℳ2)
tosimply(pre)trainamodelonmoredatafromthetarget Model ℳ is a Pareto
1
population. As the cross entropy objective encourages a improvement over ℳ
2
modeltolearnthedistributionsofspeechofatrainingpop- Correctness Conciseness
ulation,simplyprovidingmoredatafromthatpopulation
Security
oughttoleadtobetterrepresentation. Anotherpromisingdi-
rectionistotrainonthedatafromapopulation(e.g.,survey
f 1=0.2 ⋅ freedom + 0.8 ⋅ security Model ℳ is trade-off
data)thatonecouldusetoevaluatedistributionalpluralism, ℳf 1 steer from f 1 to f 2 steerable if it can be
steered along its
althoughitisunclearhowwellthiswillgeneralizetonovel ℳ ℳf 1 Pareto frontier from
questions/domains. Furtherresearchisneededhere. one trade-off function
(f) to another (f)
1 2
RecommendationsOftentimeswhenresearchersmeasure f 2=0.8 ⋅ freedom + 0.2 ⋅ security
towhichgroupofpeopleamodelbestaligns,theycompare Freedom
average responses. In contrast, we advocate for compar-
ingdistributionsbecauseitleadstoclearerresults: groups Model ℳ achieves
1
ofpeoplehavedistributionsoveranswers,andprobabilis-
ℳ1
y y11
1
w(ℳ1)=4
higher welfare for the
ticmodelsdoaswell. Weadvocateformoredistribution- x 1 2 Jury than model ℳ 2 for
ally pluralistic evaluations with respect to clearly speci- x 2 y2 the welfare function w,
fiedgroupsofpeopletobettercharacterizecurrentmodels. ℳ2 y1 2 w(ℳ2)=3 w(ℳ 1)>w(ℳ 2)
2
Nonetheless,thestochasticityindistributionalpluralismis
notdesirableinallcases–forexample,whenthebehavior Figure2. Threekindsofpluralisticbenchmarks.
ofamodelneedstobetightlycontrolled.
commensuratingfunctions. The“top"oftheleaderboardis
4.PluralismforBenchmarks
thesetofsolutions(models)forwhichthereisnoPareto
improvement.
Whilethelastsectiondefinedhowamodelcanbepluralistic,
hereweexplorehowabenchmarkcanbepluralistic. Most
Inpractice,thesetofsolutionsforwhichthereisnoPareto
currentbenchmarksaremonistic(focusedonasingleobjec-
improvementcanbequitelarge. Therefore,itmaybeconve-
tive). Pluralisticbenchmarkshavemorethanoneobjective
nienttodefineacommensuratingfunctionf todeterminea
tomaximize. Importantly,eachismeasuredseparately.
rankingforagivenusecase. TheimportantpartofaPareto
benchmarkisthatifobjectivesarecombined,itisdoneex-
4.1.Multi-ObjectiveBenchmarks
plicitly,reportingallobjectivesforallsolutions. Thismakes
itpossibletoproposealternativeexplicittrade-offs.
DefinitionsDefine:
(11) ObjectivestomaximizeO = {o ,...,o }: Asetof MotivationandApplicationsImplicittrade-offsareevery-
1 n
multipleobjectivestoevaluateamodelM,eachofwhich where. Forexample,thereisafundamentaltensionbetween
whichwedesiretomaximize. Eachomapsfromamodel helpfulnessandharmlessnessforLLMs(Askelletal.,2021;
MtoascalarinR. Baietal.,2022a). However,thesetwoattributesoftenget
clumpedtogetherandareimplicitlytraded-offthroughdata
(12) Model M is a Pareto improvement to model M .:
1 2
mixtures or vague human preferences. Through explicit
∀o ∈O,o (M )≥o (M );∃o s.t. o (M )>o (M ).
i i 1 i 2 j j 1 j 2
multi-objectivebenchmarks,wecanbetterunderstandhow
Inotherwords,M isatleastasgoodasM forallobjec-
1 2
theytrade-offandmakeinformeddecisionswhenselecting
tivesandstrictlybetterforsomeobjectiveo .
j
a model for a given application or domain (Liang et al.,
(13) Function f is a commensurating function over ob-
2023;Srivastavaetal.,2023;Hendrycksetal.,2023).
jectives O: f is a function which combines multiple ob-
jectives into a single scalar meta-objective of the form PotentialImplementationTherearemanywaystooper-
f(M)=f(o (M),...,o (M)). ationalizetheseobjectives,suchasevaluationontestsets,
1 n
(14) Benchmark B is a multi-objective benchmark over outputsofarewardmodel,preference/ELOscores,model
O: B reportstheentirespectrumofmodelperformances properties and more. Other objectives might include ad-
herencetoindividualrulessuchas“Donotofferfinancial
on all objectives and can be flexibly adapted to multiple
advice"(Glaeseetal.,2022)orprinciples(Baietal.,2022b).
5
evitcejbo-itluM
elbareetS
ffo-edarT
citsilarulp-yruJARoadmaptoPluralisticAlignment
Limitations If the set of metrics is very large, it may be markcouldbearewardwhichtriestomaximizethesteer-
costlytocomparemodelsacrossalargenumberofdimen- abilityandoverallobjectivevalues,asfollows:
sions. Thechoiceofwhichobjectivesandthegranularityof
(cid:88)
benchmarkstoincludewillinfluencethestrengthoftheeval- f(M )
f
uation.Choosingthecorrectnumberandlevelofabstraction f∈F
oftheobjectivescanbeadifficultdesigndecision.
Maximizingrequiresthemodeltoincreasetheoverallvalue
AlignmentProceduresandRecommendationsMostalign- of each f ∈ F and also match the aligned model to the
ment techniques optimize a single objective instead of
correspondingobjectivefunction. Arelatedconceptisthe
a group of objectives, requiring a commensurating func-
hypervolumeindicator(Guerreiroetal.,2020).
tion. Toavoidthis,wecanlooktotechniquesfrommulti-
objectiveRL(Hayesetal.,2022;Yangetal.,2019). While LimitationsThisframeworkassumesasetofcommensurat-
severalmulti-objectivebenchmarksexist(Liangetal.,2023; ingfunctions. However,manyphilosopherswhosubscribe
Srivastavaetal.,2023;Panetal.,2023),weencouragefur- tovaluepluralismbelievethatvaluesareincommensurable
therresearchanddevelopment. Single-valuebenchmarks andcannotbetradedoff(Hsieh&Andersson,2021). Trade-
canoftenleadto“reward-hacking”andexploitingspurious offsterablebenchmarks(andmostofmachinelearning)are
features,suchasannotators’preferenceformoreverbose incompatiblewiththatview. Itisalsoimportantforgeneral-
responses(Wangetal.,2023a). Multipleobjectivesallow izationthatthekindofcommensuratingfunctionsdesired
for a more diverse set of model strengths (Ethayarajh & foruseattesttimearepresentinthebenchmark.
Jurafsky,2020)andmitigateover-optimization.
Alignment Procedures and Recommendations Some
promisingprocedurestosteermodelsincludecontrollable
4.2.Trade-OffSteerableBenchmarks decoding(Liuetal.,2024;Qinetal.,2022;Luetal.,2020),
prefix tokens/custom instructions (Chen et al., 2021; Lu
Inthemulti-objectivebenchmarksection,weassumedthat
etal.,2022),andmodelsoups(Wortsmanetal.,2022;Jang
themodelwasstatic,occupyingasinglepointintheobjec-
etal.,2023). Toourknowledge,however,therearenostan-
tivespace. However,itisusefultoconsiderabenchmark
dardLLMtrade-offsteerablebenchmarks. Weadvocatefor
whichencouragesmodelstobesteerabletotradeoffobjec-
increased development of such benchmarks to spur more
tivesindifferentwaysatinferencetime.
developmentinsteerableAIsystems.
Many of the takeaways from the previous section apply
here, so we will focus our discussion on what is unique 4.3.Jury-PluralisticBenchmarks
abouttrade-offsteerablebenchmarks.
While multi-objective benchmarks deal with an arbitrary
DefinitionsBuildingonthedefinitionsfromSection4.1,
objectivetype,itisalsousefultotalkaboutthespecificcase
(15) Steeringcommensurating(ortrade-off)functionsF: whenthereisapopulationofannotators(orjury)towhich
Asetofcommensuratingfunctionstosteeramodeltowards. wewishtoalign. Here, weproposeatypeofbenchmark
(16) Model M is steerable to functions F: For f ∈ F, whichseparatelyandexplicitlymodelsajury(Gordonetal.,
themodelsteeredtof (denotedM )maximizesf: ∀f′ ∈ 2022)tomaximizeanoverallwelfarefunction.
f
F,f(M )≥f(M )
f f′ DefinitionsWedefine:
(17) BenchmarkBisatrade-offsteerablebenchmarkwith
(18) Jury/Population/AnnotatorsJ ={j ,...,j }: Some
1 n
respecttoO,F: Battemptstomeasure1)amodel’sability
population which we wish to represent in our evaluation.
tomaximizeobjectivesOand2)amodel’ssteerabilityto
Eachannotator/person/jurymemberj mapsfromanquery
i
variouscommensuratingfunctionsf ∈F. andresponsetoascalarrewardorutilityj :X,Y →R.
i
MotivationandApplicationsAtrade-offsteerablebench- (19) Function w is a welfare function over jury J: w
markmeasureswhetherasinglemodelcanrepresentsolu- is a function which combines the jury’s utilities into a
tionsacrossaspectrumofobjectives,allowingfortuning single scalar welfare objective of the form w(x,y) =
totrade-offfunctionsofchoiceatdeploymenttime. Any w(j 1(x,y),...,j n(x,y)).
applicationwherecustomizationisdesirablecouldbenefit (20) Benchmark B is jury-pluralistic: B explicitly mea-
fromthiskindofbenchmark. sureseachjurorj tomaximizeawelfarefunctionw.
i
Potential Implementation Many commensurating func-
MotivationandApplicationsJury-pluralisticbenchmarks
tions are possible, including linear combinations (e.g.,
canserveasaconcreteapproachfordemocraticAIalign-
f =w o +...+w o )andselectingasingleobjective.
1 1 n n ment (Koster et al., 2022; Ovadya, 2023; Mishra, 2023).
GivenF,oneimplementationofatrade-offsteerablebench- Theyallowustoexplicitlyreasonoverwhichusersorgroups
modelsarebeingalignedto, andpotentiallyobtainfairer
6ARoadmaptoPluralisticAlignment
outcomesaspeopleareincludedandsocialwelfarefunc- jorityandUtilitarianwelfarefunctionstofanaticalinfluence
tionsareselected. Consensus-seekingapplicationsbenefit (MacAskill,2016). Thisapproachalsoassumescommensu-
fromthisapproach.Forinstance,DeepmindtrainedanLLM rability. Reportedvaluesalsomightnotbecomparableon
tofindconsensusstatementsthatuserspreferredtoanyin- thesamescale(Ethayarajh&Jurafsky,2022).
dividualhuman-writtenstatement(Bakkeretal.,2022)and
AlignmentProceduresandRecommendationsOncewe
Twitter’sCommunityNoteshasmoderatedmisinformation
haveourjuryJ andawelfarefunctionwdefined,theprob-
byleveragingconsensusbetweenuserswhooftendisagree
lem reduces to one of reward maximization, and we can
(Wojciketal.,2022). Theseapproacheshelptointegrate
leverageestablishedalignmenttechniques. Themainnov-
a diverse set of user preferences, which have been found
elty of the framework is in the reward modeling through
to vary globally in perceptions such as safety judgments
ajury. Wethereforerecommendfurtherresearchintothe
(Aroyoetal.,2023).
questions of 1) who to represent on a jury, 2) how to es-
PotentialImplementationOnecouldconstructarepresen- timatejurorfunctions,and3)establishingjury-pluralistic
tativejury(e.g.,ofaparticularcountry,population,orex- benchmarkstospurfurtherinnovation.
pertise)usingestablishedsocialsciencemethods(Flanigan
etal.,2021;Arnesen&Peters,2018). Onecouldalsocon-
5.CurrentAlignmentApproachesand
structajurydesignedtoamplifyspecificperspectives. For
Pluralism
instance, in online communities, under-represented users
sometimes face extra harassment (Pew Research Center, 5.1.CurrentAlignmentApproaches
2021). Tocombatthis,community-specificmoderational-
AIalignmentaimstoguideaLLMinthedirectionofhu-
gorithmscouldbealignedtoajuryfeaturingtheirvoices.
Once a jury is selected, jury member functions j can be man intentions and values, such as safety and accuracy
i
(Leike et al., 2018; Ji et al., 2024). In supervised fine-
approximatedinseveralways. Forexample,aseparatepref-
tuning, models are trained to improve instruction follow-
erence/rewardmodelcouldbetrainedforeachjurymember
ing (Touvron et al., 2023; Brown et al., 2020; Achiam
(Gordonetal.,2022),ortheycouldbeestimatedusingen-
et al., 2023) or express certain values (Solaiman & Den-
tailmentfromsomeuser-writtenstatement(Bakkeretal.,
nison,2021). Reinforcementlearningfromhumanfeedback
2022). Thesecomputationaljuryfunctionsmaybeneces-
(RLHF)usesarewardmodeltrainedonhumanratingsof
saryforalignment,butevaluationwouldideallybevalidated
model-generateddatatosteeramodeltomaximizehuman
byhumanannotators.
preferences(Ouyangetal.,2022;Anthropic,2023).Control-
Differentwelfarefunctionchoicescanleadtoexplicittrade- labledecodingsteersanLLM’soutputtowardsanobjective
offsbetweenthejurorutilitiesaswell. Forexample,using atinference(Liuetal.,2024;2021;Qinetal.,2022),butof-
aclassofsocialwelfarefunctions(Moulin,2004;Bakker tenfallshortoflearning-basedmethodsonalignmentbench-
etal.,2022)– marksandhavenotbeenexploredwithpluralism. Thede-
greeofpluralismofmodelsresultingfromtheseapproaches
dependsonmanyfactors,including: therepresentativeness
(cid:40) (cid:0)1 (cid:80)n j1−α(cid:1) 1−1 α ifα≥0,α̸=1 ofthepeoplebuildingthemodels,fromdesignerstoannota-
w (j ,...,j )= n i=1 i
α 1 n (cid:112)
n
(cid:81)n
j ) ifα=1
tors(Cotra,2021;Perezetal.,2022;Bobuetal.,2023;Peng
i=1 i et al., 2023); the richness of a dataset/LM/reward model
(Casperetal.,2023);andotherfactors. Mishra(2023)ar-
–one can sweep the parameter α to change the inequality
guesthatmonisticapproachestoRLHFcannotmeetcertain
aversion from a fully Utilitarian objective (α = 0) to a
democraticpropertiesandSiththaranjanetal.(2023)find
max-min/Rawlsianobjective(α=∞)(Bakkeretal.,2022).
thatRLHFunderweightsoutliers.
Alternatively,onecouldmodifytheutilityfunctionsasfol-
lowsjˆ =1 toreducetheobjectivetoaMAX-SAT
i {ji>τ} 5.2.CurrentApproachesandPluralism
problem. Equilibriaandminimaxsolutions(Harsanyietal.,
1988)arealsopossible,e.g. (Swamyetal.,2024). Hypothesis: Current LLM alignment techniques can
reducedistributionalpluralismw.r.t. thepopulationof
Limitations The main limitation to this approach is that
internetusers.
precisely estimating the individual juror’s functions may
requirealargeamountofdata,althoughthiscouldbemiti- Theoreticalaspect: Thelanguagemodelingcrossentropy
gatedbygroupingbysalientcharacteristics(e.g.,nationality objectivemayhelpmodelslearndistributionalpluralism. If
(Aroyo et al., 2023)) or using sample efficient methods query x with response y appears many times in the train-
(Liu et al., 2023). Depending on the choice of welfare ingdatawrittenbyarandominternetusers,crossentropy
function, other limitations may apply: e.g., majoritarian encouragesthemodeltooutputyinproportiontothepopu-
welfarefunctionscouldbesusceptibletotyrannyofthema-
7ARoadmaptoPluralisticAlignment
ModelClass LLaMA LLaMA2(7B) LLaMA2(13B) GPT-3
Dataset Pre Alpaca Tulu Pre Post Pre Post Pre Post
GlobalQA(Japan) 0.40 0.45 0.54 0.47 0.57 0.40 0.55 0.42 0.43
GlobalQA(US) 0.38 0.41 0.52 0.43 0.56 0.37 0.53 0.40 0.42
MPI 0.22 0.32 0.48 0.37 0.51 0.42 0.46 0.60 0.44
Table1.Jensen-Shannondistance(similarity)betweenhumanandmodeldistributionsonGlobalQA(targethumandistributionsofJapan
andUS)andMPI.Notethatwecomparetwo“post"RLHFmodelsforLLaMA(AlpacaandTulu).Smaller(moresimilar)valueinbold.
lation(Jietal.,2021)2. Moreover,wepostulatethatcurrent distributions,averagedover5prompts.
alignmenttechniquescanreducedistributionalpluralism,as
As shown in Table 1, almostall pre-aligned models have
thealignmentproceduredoesnothavethisproperty.
lower Jensen-Shannon distance to the target human dis-
Empiricalaspect: Werelyonthreeempiricalfindingsthat tribution than the post-aligned models for both datasets.6
provideaninitialindicationofsupportforourhypothesis. Additionally,wealsoobservedapost-alignmentreduction
Firstly,inworkbySanturkaretal.(2023),questionsfrom inentropy,asreportedinpreviouswork(Santurkaretal.,
PewResearch’sAmericanTrendsPanelssurveydata(Opin- 2023;Durmusetal.,2023). Moredetailscanbefoundin
ionQA)wereutilizedtocomparethedistributionofLLMre- App. AandB.
sponsestothoseofUScitizens.Twodifferentmodelclasses
Thesestudiesrevealaconsistentpatternofreduceddistribu-
(Jurassic/GPT-3) with both pre- and post-aligned models
tionalvariancefollowingalignmentacrossvariousdomains.
werecompared. Theresultsrevealedthatpost-alignedmod-
Therefore,whenthetargetdistributionisdiverse,suchas
elsexhibitedlesssimilaritytohumanpopulationscompared
internetusers,currentalignmenttechniquesmaypotentially
topre-alignedmodels. ExpandingbeyondtheU.S.,Durmus
limit distributional pluralism. However, a more compre-
etal.(2023)introducedGlobalOpinionQA,anaggregation
hensiveinvestigationofthishypothesisrequireslarge-scale
ofmultinationalWorldValuessimilartoOpinionQA.Al-
experimentationacrossabroaderrangeofdomains,along
thoughtheirfocuswassolelyonpost-alignedmodels,they
withfurtherexplorationintotheroleofentropy.
observedthatthesemodelstendedtoconcentratetheprob-
ability mass on a few answer choices, in contrast to the Currentalignmenttechniquesandotherformsofplu-
dispersedanswersseenintheirhumandistributions. ralism. Overtonpluralismmayemergetothedegreethat
users prefer it, but people’s preference bias for assertive-
In an effort to expand on these works, we further tested3
ness (Hosking et al., 2023; Zhou et al., 2024) may work
asuiteofvanillapretrainedLLMsincomparisontotheir
against this, causing models to express support inconsis-
corresponding“aligned"counterparts(RLHFed,finetuned
tently(Krügeletal.,2023). LLMsmayhaveadegreeof
LLMs) from two model classes, LLaMA(2) and GPT-3.
steerablepluralismviaprompting,butthisneedstobefur-
Theseevaluationswereconductedontwodistinctmultiple-
therevaluated. Alignmenttechniquesforallkindsofplural-
choicedatasets: GlobalOpinionQA,asutilizedinthestudy
isticbenchmarkswarrantfurtherinvestigation.
byDurmusetal.(2023),andtheMachinePersonalityIn-
ventory(MPI),comprising120questionsdesignedtoassess
humanpersonalitytraits(Jiangetal.,2023). 4 Ourtarget 6.Discussion
distributionswereJapanandtheUScitizensforGlobalOpin-
6.1.Limitations
ionQA5andaglobalpopulationfortheMPI.Wecalculate
Jensen-Shannon distance between the human the model Inthiswork,we1)arguethatcurrentapproachesareunclear
regarding to whom/what is being aligned and 2) propose
2Thismaybecomplicatedbyfactorssuchasoverfitting(with
≥1epoch)ortextualfeatureswhichhintattheresponse;however, a set of frameworks to operationalize how to better align
withintolerance,webelievethistobeadescriptiveanalogy. models to a set of values, characteristics, or perspectives.
3Code can be found at: https://github.com/ However,thegoalofthisworkisnottodelineateexactlyto
jfisher52/AI_Pluralistic_Alignment whomorwhattoalign,butrathertoargueforclearer,more
4Ananalysis’sstrengthofdistributionalpluralismw.r.t.apop-
ulationdependsonthedegreeofrepresentativenessofthesample. 6TheonlyexceptionisforGPT-3onMPI.However,OpenAI
Wereferinterestedreaderstotheoriginaldatasetdocumentation. nowonlyprovides"davinci-02"and"gpt-3.5-turbo"asopposed
5WeincludedtheU.S.duetoLLMsbeinglargelytrainedonEn- totheoriginal"davinci"and"*-instruct"seriesmodels,soitis
glishfromtheU.S.andselectedJapanasanationwithasomewhat difficulttoconfirmif"davinci-002"isindeedthebasemodelor
distinctculture(JS-distanceof.26).Thechoiceoftwonationswas whatprocedurewasdoneto"gpt-3.5-turbo".Thus,weencourage
madeduetoincompleteoverlapbetweencountrypairs. interpretionoftheGPT-3resultswithcaution.
8ARoadmaptoPluralisticAlignment
pluralisticapproachesinalignment. tooptimize-e.g.,efficiencyofasystem,performanceina
2-playergame. However,thereisabroadsetofsubjective
Nevertheless, severalofourdefinitionsarehardtoopera-
taskswherepluralismisavaluableconsideration.
tionalize(e.g.,howtodescribetheOvertonwindow,select
a population for alignment, etc.). We acknowledge this
and believe that this is a necessary difficulty in order to 7.Conclusion
bepreciseinmeasuringpluralism. Weattemptedtomake
In this work, we have argued for increased and more
our definitions a useful abstraction: “as simple as possi-
precisely-directedattentiononpluralismandthealignment
ble,butnotsimpler"(Ratcliffe,2016). Furtherabstracting
ofAIsystems. Wealsoproposedthreedefinitionsofplural-
awaythesedetailswouldremovetherequirednuanceofour
isticmodelsandthreeformsofpluralisticbenchmarks. We
evaluations. Anydesigndecisions,alongwiththeirlimita-
arguethatwhilecurrentalignmenttechniqueshavemade
tionsandassumptions,mustbecarefullyjustified. Although
remarkableprogress,newmethodologiesformeasuringand
some alignment techniques may require automatic meth-
aligningareneeded.
ods(e.g.,juryfunctions),weadvocateforhuman-centered
evaluationswheneverpossible. Whilewethreadspecificrecommendationsforeachkind
of pluralism throughout the work, we sketch some broad
We recognize that not all of our definitions of pluralism
recommendationshere: 1)moreresearchintofinegrained
arenecessarilydesirableinallcases. Forexample,distri-
pluralisticevaluationstobettercharacterizecurrentmodels;
butionalpluralismmaybehelpfulinusingLLMstostudy
2)continuednormativediscussionsabouttowhatwewant
culture(Buttrick,2024)orcreativedomains(Shanahan&
toalignanddesirablecustomizationbounds;3)additional
Clarke,2023),butmaynotbedesirableincontrolledenvi-
alignmenttechniquestocreatemorepluralisticmodels.
ronmentssuchascustomer support. Additionally, it may
notbepossibleforasinglemodeltosatisfyallconditions:
e.g.,Overtonpluralismmaybeatoddswithdistributional ImpactStatement
pluralism. Rather,ourdefinitionsareusefulabstractionsto
Wehopethatthisworkleadstopositiveimpactinencourag-
understandhowmodelsandbenchmarkscanbepluralistic,
ingworkinAIsystemsthatworkbetterwithadiversesetof
andeachappliesinadifferentdomain.
people. Throughoutthework,wehavediscussedpotential
limitations and risks for each proposed definition. Addi-
6.2.RelationtoPriorWork
tionally,thiswork,alongwithanyotherworkinmachine
Therehasbeenagrowingsenseinthecommunityoftheim- learning, haspotentialfordualuse: aligningtoattributes
portanceofmeasuringwhichvaluesandtowhomwearetry- whichmaycauseharm,etc. However,asourworkismore
ingtoalignLLMs(Kasirzadeh&Gabriel,2022;Wangetal., theoretical, we believe that the positive impact to discus-
2023b). Whilesomepreviousworkhasshedvaluablelight sionsaroundpluralisminalignmentoutweighanymarginal
onthesequestions(Santurkaretal.,2023),ourworkgoes potentialfordualuse,whichwebelievetobeminimal.
furtherin1)unifyingdisparateapproachesunderconcrete
definitionsofpluralism(e.g.,distributional),2)proposing Acknowledgments
previouslyunexplored(toourknowledge)kindsofplural-
ism(e.g.,Overton),and3)arguingthat,inmanycases,it The authors thank Ben Newman, Joongwon Kim, Victo-
mayactuallybedesirabletoincreasecertainmeasuresof riaEbert, andZaidHarchaouiforhelpfulfeedback. This
pluralism as opposed to merely using them as probes, in researchwassupportedinpartbyDARPAundertheITM
contrasttootherwork(Santurkaretal.,2023;Durmusetal., program (FA8650-23-C-7316) and the Allen Institute for
2023;Fengetal.,2023). AI.
6.3.PluralisminBroaderAISystems
Inthiswork,wefocusedlargelyonLLMs. However,we
believethatourdefinitionsgeneralizebroadlytootherAI
systems. In general, the query/response framework may
be applied to any set of inputs/outputs, whether actions,
images,audio,oranyothermodality. Forexample,itmay
bedesirableforagentstobesteerablypluralistictobeable
tocustomizetousersneeds. Distributionalpluralismmay
beusefulinmodelingpotentialactionsthatagentsmaytake,
suchasdriversonaroad. Theremaybelessofaneedfor
pluralisminareaswherethereisasinglecorrectobjective
9ARoadmaptoPluralisticAlignment
References dacher,N.,Such,F.P.,Summers,N.,Sutskever,I.,Tang,
J.,Tezak,N.A.,Thompson,M.,Tillet,P.,Tootoonchian,
OxfordEnglishDictionary,s.v.“Overtonwindow(n.)”,July
A.,Tseng,E.,Tuggle,P.,Turley,N.,Tworek,J.,Uribe,J.
2023. URL https://doi.org/10.1093/OED/
F.C.,Vallone,A.,Vijayvergiya,A.,Voss,C.,Wainwright,
1985277434.
C., Wang, J. J., Wang, A., Wang, B., Ward, J., Wei, J.,
Weinmann, C., Welihinda, A., Welinder, P., Weng, J.,
Achiam,O.J.,Adler,S.,Agarwal,S.,Ahmad,L.,Akkaya,
Weng,L.,Wiethoff,M.,Willner,D.,Winter,C.,Wolrich,
I.,Aleman,F.L.,Almeida,D.,Altenschmidt,J.,Altman,
S., Wong, H., Workman, L., Wu, S., Wu, J., Wu, M.,
S.,Anadkat,S.,Avila,R.,Babuschkin,I.,Balaji,S.,Bal-
Xiao,K.,Xu,T.,Yoo,S.,Yu,K.,Yuan,Q.,Zaremba,W.,
com, V., Baltescu, P., Bao, H., Bavarian, M., Belgum,
Zellers,R.,Zhang,C.,Zhang,M.,Zhao,S.,Zheng,T.,
J.,Bello,I.,Berdine,J.,Bernadett-Shapiro,G.,Berner,
Zhuang,J.,Zhuk,W.,andZoph,B.Gpt-4technicalreport.
C.,Bogdonoff,L.,Boiko,O.,Boyd,M.,Brakman,A.-L.,
2023. URL https://api.semanticscholar.
Brockman, G., Brooks, T., Brundage, M., Button, K.,
org/CorpusID:257532815.
Cai,T.,Campbell,R.,Cann,A.,Carey,B.,Carlson,C.,
Carmichael,R.,Chan,B.,Chang,C.,Chantzis,F.,Chen,
Aher,G.V.,Arriaga,R.I.,andKalai,A.T. Usinglargelan-
D., Chen, S., Chen, R., Chen, J., Chen, M., Chess, B.,
guagemodelstosimulatemultiplehumansandreplicate
Cho,C.,Chu,C.,Chung,H.W.,Cummings,D.,Currier, humansubjectstudies. InInternationalConferenceon
J.,Dai,Y.,Decareaux,C.,Degry,T.,Deutsch,N.,Dev- MachineLearning,pp.337–371.PMLR,2023.
ille,D.,Dhar,A.,Dohan,D.,Dowling,S.,Dunning,S.,
Ecoffet,A.,Eleti,A.,Eloundou,T.,Farhi,D.,Fedus,L., Anthropic. Introducing claude, 2023. URL
Felix,N.,Fishman,S.P.,Forte,J.,Fulford,I.,Gao,L., https://www.anthropic.com/index/
Georges,E.,Gibson,C.,Goel,V.,Gogineni,T.,Goh,G., introducing-claude.
Gontijo-Lopes, R., Gordon, J., Grafstein, M., Gray, S.,
Argyle,L.,Busby,E.,Fulda,N.,Gubler,J.,Rytting,C.,and
Greene,R.,Gross,J.,Gu,S.S.,Guo,Y.,Hallacy,C.,Han,
Wingate,D. Outofone,many: Usinglanguagemodels
J.,Harris,J.,He,Y.,Heaton,M.,Heidecke,J.,Hesse,C.,
tosimulatehumansamples. PoliticalAnalysis,31:1–15,
Hickey,A.,Hickey,W.,Hoeschele,P.,Houghton,B.,Hsu,
022023. doi: 10.1017/pan.2023.2.
K.,Hu,S.,Hu,X.,Huizinga,J.,Jain,S.,Jain,S.,Jang,J.,
Jiang,A.,Jiang,R.,Jin,H.,Jin,D.,Jomoto,S.,Jonn,B., Arnesen, S. and Peters, Y. The legitimacy of represen-
Jun,H.,Kaftan,T.,Kaiser,L.,Kamali,A.,Kanitscheider, tation: How descriptive, formal, and responsiveness
I., Keskar, N. S., Khan, T., Kilpatrick, L., Kim, J. W., representation affect the acceptability of political deci-
Kim,C.,Kim,Y.,Kirchner,H.,Kiros,J.R.,Knight,M., sions. Comparative Political Studies, 51(7):868–899,
Kokotajlo,D.,Kondraciuk,L.,Kondrich,A.,Konstantini- 2018. doi: 10.1177/0010414017720702. URLhttps:
dis,A.,Kosic,K.,Krueger,G.,Kuo,V.,Lampe,M.,Lan, //doi.org/10.1177/0010414017720702.
I.,Lee,T.,Leike,J.,Leung,J.,Levy,D.,Li,C.M.,Lim,
R.,Lin,M.,Lin,S.,Litwin,M.,Lopez,T.,Lowe,R.,Lue, Aroyo,L.,Taylor,A.S.,Diaz,M.,Homan,C.M.,Parrish,
P.,Makanju,A.A.,Malfacini,K.,Manning,S.,Markov, A., Serapio-Garcia, G., Prabhakaran, V., and Wang, D.
T.,Markovski,Y.,Martin,B.,Mayer,K.,Mayne,A.,Mc- Dicesdataset: Diversityinconversationalaievaluation
Grew, B., McKinney, S. M., McLeavey, C., McMillan, forsafety,2023.
P.,McNeil,J.,Medina,D.,Mehta,A.,Menick,J.,Metz,
Askell, A., Bai, Y., Chen, A., Drain, D., Ganguli, D.,
L.,Mishchenko,A.,Mishkin,P.,Monaco,V.,Morikawa,
Henighan, T., Jones, A., Joseph, N., Mann, B., Das-
E.,Mossing,D.P.,Mu,T.,Murati,M.,Murk,O.,M’ely,
Sarma, N., Elhage, N., Hatfield-Dodds, Z., Hernandez,
D., Nair, A., Nakano, R., Nayak, R., Neelakantan, A.,
D., Kernion, J., Ndousse, K., Olsson, C., Amodei, D.,
Ngo,R.,Noh,H.,Long,O.,O’Keefe,C.,Pachocki,J.W.,
Brown,T.,Clark,J.,McCandlish,S.,Olah,C.,andKa-
Paino,A.,Palermo,J.,Pantuliano,A.,Parascandolo,G.,
plan,J. Agenerallanguageassistantasalaboratoryfor
Parish, J., Parparita, E., Passos, A., Pavlov, M., Peng,
alignment,2021.
A.,Perelman,A.,deAvilaBelbutePeres,F.,Petrov,M.,
deOliveiraPinto,H.P.,Pokorny,M.,Pokrass,M.,Pong, Bai,Y.,Jones,A.,Ndousse,K.,Askell,A.,Chen,A.,Das-
V.H.,Powell,T.,Power,A.,Power,B.,Proehl,E.,Puri, Sarma, N., Drain, D., Fort, S., Ganguli, D., Henighan,
R.,Radford,A.,Rae,J.,Ramesh,A.,Raymond,C.,Real, T., Joseph, N., Kadavath, S., Kernion, J., Conerly, T.,
F.,Rimbach,K.,Ross,C.,Rotsted,B.,Roussez,H.,Ry- El-Showk, S., Elhage, N., Hatfield-Dodds, Z., Hernan-
der,N.,Saltarelli,M.D.,Sanders,T.,Santurkar,S.,Sas- dez, D., Hume, T., Johnston, S., Kravec, S., Lovitt, L.,
try,G.,Schmidt,H.,Schnurr,D.,Schulman,J.,Selsam, Nanda,N.,Olsson,C.,Amodei,D.,Brown,T.,Clark,J.,
D., Sheppard, K., Sherbakov, T., Shieh, J., Shoker, S., McCandlish,S.,Olah,C.,Mann,B.,andKaplan,J.Train-
Shyam, P., Sidor, S., Sigler, E., Simens, M., Sitkin, J., ingahelpfulandharmlessassistantwithreinforcement
Slama,K.,Sohl,I.,Sokolowsky,B.D.,Song,Y.,Stau- learningfromhumanfeedback,2022a.
10ARoadmaptoPluralisticAlignment
Bai, Y., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Bowman, S. R., Hyun, J., Perez, E., Chen, E., Pettit, C.,
Jones,A.,Chen,A.,Goldie,A.,Mirhoseini,A.,McKin- Heiner, S., Lukošiu¯te˙, K., Askell, A., Jones, A., Chen,
non,C.,Chen,C.,Olsson,C.,Olah,C.,Hernandez,D., A.,Goldie,A.,Mirhoseini,A.,McKinnon,C.,Olah,C.,
Drain,D.,Ganguli,D.,Li,D.,Tran-Johnson,E.,Perez, Amodei,D.,Amodei,D.,Drain,D.,Li,D.,Tran-Johnson,
E.,Kerr,J.,Mueller,J.,Ladish,J.,Landau,J.,Ndousse, E.,Kernion,J.,Kerr,J.,Mueller,J.,Ladish,J.,Landau,J.,
K., Lukosuite, K., Lovitt, L., Sellitto, M., Elhage, N., Ndousse,K.,Lovitt,L.,Elhage,N.,Schiefer,N.,Joseph,
Schiefer,N.,Mercado,N.,DasSarma,N.,Lasenby,R., N.,Mercado,N.,DasSarma,N.,Larson,R.,McCandlish,
Larson,R.,Ringer,S.,Johnston,S.,Kravec,S.,Showk, S., Kundu, S., Johnston, S., Kravec, S., Showk, S. E.,
S.E.,Fort,S.,Lanham,T.,Telleen-Lawton,T.,Conerly, Fort, S., Telleen-Lawton, T., Brown, T., Henighan, T.,
T., Henighan, T., Hume, T., Bowman, S. R., Hatfield- Hume, T., Bai, Y., Hatfield-Dodds, Z., Mann, B., and
Dodds,Z.,Mann,B.,Amodei,D.,Joseph,N.,McCan- Kaplan,J. Measuringprogressonscalableoversightfor
dlish, S., Brown, T., and Kaplan, J. Constitutional ai: largelanguagemodels,2022.
Harmlessnessfromaifeedback,2022b.
Boykoff, M. T. and Boykoff, J. M. Balance as bias:
Bakker,M.A.,Chadwick,M.J.,Sheahan,H.R.,Tessler, global warming and the us prestige press. Global En-
M.H.,Campbell-Gillingham,L.,Balaguer,J.,McAleese, vironmentalChange,14(2):125–136,2004. ISSN0959-
N., Glaese, A., Aslanides, J., Botvinick, M. M., and 3780. doi: https://doi.org/10.1016/j.gloenvcha.2003.10.
Summerfield, C. Fine-tuning language models to find 001. URLhttps://www.sciencedirect.com/
agreementamonghumanswithdiversepreferences,2022. science/article/pii/S0959378003000669.
Berlin,I.Twoconceptsofliberty.InFourEssaysonLiberty, Brown,T.B.,Mann,B.,Ryder,N.,Subbiah,M.,Kaplan,
pp.118–172.OxfordUniversityPress,Oxford,1969. J.,Dhariwal,P.,Neelakantan,A.,Shyam,P.,Sastry,G.,
Askell,A.,Agarwal,S.,Herbert-Voss,A.,Krueger,G.,
Bobu,A.,Peng,A.,Agrawal,P.,Shah,J.,andDragan,A.D. Henighan,T.J.,Child,R.,Ramesh,A.,Ziegler,D.M.,
Aligningrobotandhumanrepresentations.arXivpreprint Wu,J.,Winter,C.,Hesse,C.,Chen,M.,Sigler,E.,Litwin,
arXiv:2302.01928,2023. M.,Gray,S.,Chess,B.,Clark,J.,Berner,C.,McCandlish,
S.,Radford,A.,Sutskever,I.,andAmodei,D. Language
Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., models are few-shot learners. ArXiv, abs/2005.14165,
Arora,S.,vonArx,S.,Bernstein,M.S.,Bohg,J.,Bosse- 2020. URL https://api.semanticscholar.
lut,A.,Brunskill,E.,Brynjolfsson,E.,Buch,S.,Card,D., org/CorpusID:218971783.
Castellon,R.,Chatterji,N.S.,Chen,A.S.,Creel,K.A.,
Davis,J.,Demszky,D.,Donahue,C.,Doumbouya,M., Buttrick, N. Studying large language models as com-
Durmus,E.,Ermon,S.,Etchemendy,J.,Ethayarajh,K., pressionalgorithmsforhumanculture. TrendsinCog-
Fei-Fei, L., Finn, C., Gale, T., Gillespie, L., Goel, K., nitive Sciences, S1364-6613(24):00001–9, 2024. doi:
Goodman, N.D., Grossman, S., Guha, N., Hashimoto, 10.1016/j.tics.2024.01.001. Epubaheadofprint.
T., Henderson, P., Hewitt, J., Ho, D.E., Hong, J., Hsu,
Casper, S., Davies, X., Shi, C., Gilbert, T. K., Scheurer,
K.,Huang,J.,Icard,T.F.,Jain,S.,Jurafsky,D.,Kalluri,
J., Rando, J., Freedman, R., Korbak, T., Lindner, D.,
P.,Karamcheti,S.,Keeling,G.,Khani,F.,Khattab,O.,
Freire, P., Wang, T., Marks, S., Ségerie, C.-R., Car-
Koh, P. W., Krass, M. S., Krishna, R., Kuditipudi, R.,
roll, M., Peng, A., Christoffersen, P. J., Damani, M.,
Kumar, A., Ladhak, F., Lee, M., Lee, T., Leskovec, J.,
Slocum, S., Anwar, U., Siththaranjan, A., Nadeau, M.,
Levent, I., Li, X. L., Li, X., Ma, T., Malik, A., Man-
Michaud,E.J.,Pfau,J.,Krasheninnikov,D.,Chen,X.,
ning, C. D., Mirchandani, S., Mitchell, E., Munyikwa,
di Langosco, L. L., Hase, P., Biyik, E., Dragan, A. D.,
Z.,Nair,S.,Narayan,A.,Narayanan,D.,Newman,B.,
Krueger,D.,Sadigh,D.,andHadfield-Menell,D. Open
Nie, A., Niebles, J. C., Nilforoshan, H., Nyarko, J. F.,
problemsandfundamentallimitationsofreinforcement
Ogut,G.,Orr,L.J.,Papadimitriou,I.,Park,J.S.,Piech,
learningfromhumanfeedback. ArXiv,abs/2307.15217,
C.,Portelance,E.,Potts,C.,Raghunathan,A.,Reich,R.,
2023. URL https://api.semanticscholar.
Ren, H., Rong, F., Roohani, Y. H., Ruiz, C., Ryan, J.,
org/CorpusID:260316010.
R’e,C.,Sadigh,D.,Sagawa,S.,Santhanam,K.,Shih,A.,
Srinivasan,K.P.,Tamkin,A.,Taori,R.,Thomas,A.W.,
Chen, J., Liu, Z., Huang, X., Wu, C., Liu, Q., Jiang, G.,
Tramèr,F.,Wang,R.E.,Wang,W.,Wu,B.,Wu,J.,Wu,
Pu,Y.,Lei,Y.,Chen,X.,Wang,X.,Lian,D.,andChen,
Y., Xie, S. M., Yasunaga, M., You, J., Zaharia, M. A.,
E. When large language models meet personalization:
Zhang,M.,Zhang,T.,Zhang,X.,Zhang,Y.,Zheng,L.,
Perspectivesofchallengesandopportunities,2023.
Zhou,K.,andLiang,P. Ontheopportunitiesandrisksof
foundationmodels. ArXiv,abs/2108.07258,2021. URL Chen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A.,
https://arxiv.org/pdf/2108.07258.pdf. Laskin,M.,Abbeel,P.,Srinivas,A.,andMordatch,I. De-
11ARoadmaptoPluralisticAlignment
cisiontransformer: Reinforcementlearningviasequence 10.1038/s41586-021-03788-6. URL https://doi.
modeling,2021. org/10.1038/s41586-021-03788-6.
Cotra, A. Why ai alignment could be hard with modern Fleisig,E.,Abebe,R.,andKlein,D. WhentheMajorityis
deep learning. https://www.cold-takes.com/ Wrong:ModelingAnnotatorDisagreementforSubjective
why-ai-alignment-could-be-hard-with-modern T- ad ske se ,p N- ol ve emar ben ri 2n 0g 2/ 3,. URLhttp://arxiv.org/
2021. abs/2305.06626. arXiv:2305.06626[cs].
Crenshaw, K. Demarginalizing the intersection of race
Gabriel, I. Artificial intelligence, values, and alignment.
andsex: Ablackfeministcritiqueofantidiscrimination
MindsandMachines,30(3):411–437,2020.doi:10.1007/
doctrine,feministtheoryandantiracistpolitics. TheUni-
s11023-020-09539-2. URLhttps://doi.org/10.
versityofChicagoLegalForum,140:139–167,1989.
1007/s11023-020-09539-2.
Danry, V., Pataranutaporn, P., Mao, Y., and Maes, P.
Girotra, K., Meincke, L., Terwiesch, C., and Ulrich,
Don’t just tell me, ask me: Ai systems that intel-
K. T. Ideas are dimes a dozen: Large language mod-
ligently frame explanations as questions improve hu-
els for idea generation in innovation. https://
man logical discernment accuracy over causal ai ex-
ssrn.com/abstract=4526071,July2023. Avail-
planations. In Proceedings of the 2023 CHI Confer-
able at SSRN: https://ssrn.com/abstract=4526071 or
ence on Human Factors in Computing Systems, CHI
http://dx.doi.org/10.2139/ssrn.4526071.
’23, New York, NY, USA, 2023. Association for Com-
puting Machinery. ISBN 9781450394215. doi: 10.
Glaese, A., McAleese, N., Tre˛bacz, M., Aslanides, J.,
1145/3544548.3580672. URL https://doi.org/
Firoiu, V., Ewalds, T., Rauh, M., Weidinger, L., Chad-
10.1145/3544548.3580672.
wick, M., Thacker, P., Campbell-Gillingham, L., Ue-
deTocqueville,A. DemocracyinAmerica. 1835. sato,J.,Huang,P.-S.,Comanescu,R.,Yang,F.,See,A.,
Dathathri,S.,Greig,R.,Chen,C.,Fritz,D.,Elias,J.S.,
Durmus,E.,Nyugen,K.,Liao,T.I.,Schiefer,N.,Askell,
Green, R., Mokrá, S., Fernando, N., Wu, B., Foley, R.,
A.,Bakhtin,A.,Chen,C.,Hatfield-Dodds,Z.,Hernan-
Young,S.,Gabriel,I.,Isaac,W.,Mellor,J.,Hassabis,D.,
dez,D.,Joseph,N.,Lovitt,L.,McCandlish,S.,Sikder,
Kavukcuoglu,K.,Hendricks,L.A.,andIrving,G. Im-
O., Tamkin, A., Thamkul, J., Kaplan, J., Clark, J.,
provingalignmentofdialogueagentsviatargetedhuman
and Ganguli, D. Towards measuring the representa-
judgements,2022.
tion of subjective global opinions in language models,
2023. URL https://api.semanticscholar. Gordon, M. L., Lam, M. S., Park, J. S., Patel, K., Han-
org/CorpusID:259275051. cock,J.,Hashimoto,T.,andBernstein,M.S. Jurylearn-
ing: Integrating dissenting voices into machine learn-
Ethayarajh,K.andJurafsky,D. Utilityisintheeyeofthe
ing models. In CHI Conference on Human Factors in
user: Acritiqueofnlpleaderboarddesign. InConference
Computing Systems, CHI ’22. ACM, April 2022. doi:
onEmpiricalMethodsinNaturalLanguageProcessing,
10.1145/3491102.3502004. URL http://dx.doi.
2020. URL https://api.semanticscholar.
org/10.1145/3491102.3502004.
org/CorpusID:235408131.
Guerreiro,A.P.,Fonseca,C.M.,andPaquete,L. Thehyper-
Ethayarajh, K. and Jurafsky, D. The authenticity gap in
volumeindicator.ACMComputingSurveys(CSUR),54:1–
human evaluation. In Goldberg, Y., Kozareva, Z., and
Zhang,Y.(eds.),Proceedingsofthe2022Conferenceon 42,2020. URLhttps://api.semanticscholar.
EmpiricalMethodsinNaturalLanguageProcessing,pp.
org/CorpusID:218470181.
6056–6070,AbuDhabi,UnitedArabEmirates,Decem-
Haraway,D. Situatedknowledges: Thesciencequestionin
ber2022.AssociationforComputationalLinguistics. doi:
feminismandtheprivilegeofpartialperspective.Feminist
10.18653/v1/2022.emnlp-main.406. URL https://
Studies, 14(3):575–599, 1988. ISSN 00463663. URL
aclanthology.org/2022.emnlp-main.406.
http://www.jstor.org/stable/3178066.
Feng, S., Park, C. Y., Liu, Y., and Tsvetkov, Y. From
pretrainingdatatolanguagemodelstodownstreamtasks: Harsanyi,J.C.,Selten,R.,etal. Ageneraltheoryofequi-
Trackingthetrailsofpoliticalbiasesleadingtounfairnlp libriumselectioningames. MITPressBooks,1,1988.
models,2023.
Hartmann,J.,Schwenzow,J.,andWitte,M. Thepolitical
Flanigan, B., Gölz, P., Gupta, A., Hennig, B., and ideologyofconversationalai: Convergingevidenceon
Procaccia, A. D. Fair algorithms for selecting citi- chatgpt’spro-environmental,left-libertarianorientation,
zens’assemblies. Nature,596(7873):548–552,2021. doi: 2023.
12ARoadmaptoPluralisticAlignment
Hayati, S. A., Lee, M., Rajagopal, D., and Kang, CHI Conference on Human Factors in Computing Sys-
D. How far can we extract diverse perspec- tems, CHI ’23, New York, NY, USA, 2023. Associa-
tives from large language models? criteria-based tionforComputingMachinery. ISBN9781450394215.
diversity prompting! ArXiv, abs/2311.09799, doi: 10.1145/3544548.3581196. URLhttps://doi.
2023. URL https://api.semanticscholar. org/10.1145/3544548.3581196.
org/CorpusID:265220883.
Jang, J., Kim, S., Lin, B.Y., Wang, Y., Hessel, J., Zettle-
Hayes, C. F., Ra˘dulescu, R., Bargiacchi, E., Källström, moyer,L.,Hajishirzi,H.,Choi,Y.,andAmmanabrolu,P.
J.,Macfarlane,M.,Reymond,M.,Verstraeten,T.,Zint- Personalizedsoups: Personalizedlargelanguagemodel
graf, L. M., Dazeley, R., Heintz, F., Howley, E., Iris- alignmentviapost-hocparametermerging,2023.
sappane, A. A., Mannion, P., Nowé, A., Ramos, G.,
Ji,J.,Qiu,T.,Chen,B.,Zhang,B.,Lou,H.,Wang,K.,Duan,
Restelli,M.,Vamplew,P.,andRoijers,D.M. Apracti-
Y.,He,Z.,Zhou,J.,Zhang,Z.,Zeng,F.,Ng,K.Y.,Dai,
calguidetomulti-objectivereinforcementlearningand
J.,Pan,X.,O’Gara,A.,Lei,Y.,Xu,H.,Tse,B.,Fu,J.,
planning. Autonomous Agents and Multi-Agent Sys-
McAleer,S.,Yang,Y.,Wang,Y.,Zhu,S.-C.,Guo,Y.,and
tems, 36(1):26, April 2022. ISSN 1573-7454. doi:
Gao,W. Aialignment: Acomprehensivesurvey,2024.
10.1007/s10458-022-09552-y. URLhttp://dx.doi.
org/10.1007/s10458-022-09552-y.
Ji, Z., Li, J. D., and Telgarsky, M. Early-stopped neural
networksareconsistent,2021.
Hendrycks,D.,Burns,C.,Basart,S.,Critch,A.,Li,J.,Song,
D., and Steinhardt, J. Aligning ai with shared human Jiang, G., Xu, M., Zhu, S.-C., Han, W., Zhang, C.,
values. arXivpreprintarXiv:2008.02275,2020. and Zhu, Y. Evaluating and inducing personality in
pre-trained language models, 2023. URL https:
Hendrycks,D.,Burns,C.,Basart,S.,Critch,A.,Li,J.,Song,
//api.semanticscholar.org/CorpusID:
D., and Steinhardt, J. Aligning ai with shared human
258865158.
values,2023.
Jiang, H., Beeferman, D., Roy, B., and Roy, D. Com-
Henrich,J.,Heine,S.J.,andNorenzayan,A. Theweirdest munitylm: Probingpartisanworldviewsfromlanguage
peopleintheworld? BehavioralandBrainSciences,33 models,2022.
(2-3):61–83,2010.URLhttp://www2.psych.ubc.
ca/~henrich/audiofiles/WEIRD1.mp3. Jung,J.,Qin,L.,Welleck,S.,Brahman,F.,Bhagavatula,C.,
Bras,R.L.,andChoi,Y. Maieuticprompting: Logically
Hosking, T., Blunsom, P., and Bartolo, M. Human feed- consistentreasoningwithrecursiveexplanations,2022.
back is not gold standard. ArXiv, abs/2309.16349,
2023. URL https://api.semanticscholar. Kant, I. Kant: Critique of Practical Reason. Cam-
org/CorpusID:263134280. bridge Texts in the History of Philosophy. Cambridge
University Press, 2 edition, 1788. doi: 10.1017/
Hsieh,N.-h.andAndersson,H. IncommensurableValues. CBO9781316136478.
InZalta,E.N.(ed.),TheStanfordEncyclopediaofPhi-
Kasirzadeh,A.andGabriel,I. Inconversationwithartifi-
losophy.MetaphysicsResearchLab,StanfordUniversity,
cialintelligence: aligninglanguagemodelswithhuman
Fall2021edition,2021.
values,2022.
Hwang, E., Majumder, B. P., and Tandon, N. Align-
Kekes,J. TheMoralityofPluralism. PrincetonUniversity
ing Language Models to User Opinions. 2023. doi:
Press,Princeton,1993.
10.48550/ARXIV.2305.14929. URLhttps://arxiv.
org/abs/2305.14929. Publisher: arXiv Version Kim, J. and Lee, B. Ai-augmented surveys: Leveraging
Number: 1. largelanguagemodelsforopinionpredictioninnationally
representativesurveys. arXivpreprintarXiv:2305.09620,
Imundo, M. and Rapp, D. When fairness is flawed: Ef-
2023.
fectsoffalsebalancereportingandweight-of-evidence
statementsonbeliefsandperceptionsofclimatechange. Kirk,R.,Mediratta,I.,Nalmpantis,C.,Luketina,J.,Ham-
JournalofAppliedResearchinMemoryandCognition, bro,E.,Grefenstette,E.,andRaileanu,R. Understanding
11,102021. doi: 10.1016/j.jarmac.2021.10.002. the effects of rlhf on llm generalisation and diversity,
2024.
Jakesch, M., Bhat, A., Buschek, D., Zalmanson, L., and
Naaman,M. Co-writingwithopinionatedlanguagemod- Koster,R.,Balaguer,J.,Tacchetti,A.,Weinstein,A.,Zhu,
els affects users’ views. In Proceedings of the 2023 T.,Hauser,O.,Williams,D.,Campbell-Gillingham,L.,
13ARoadmaptoPluralisticAlignment
Thacker,P.,Botvinick,M.,andSummerfield,C. Human- Liu, N.F., Kumar, A., Liang, P., andJia, R. Aresample-
centred mechanism design with democratic ai. Nature efficientnlpmodelsmorerobust?,2023.
HumanBehaviour,6(10):1398–1407,2022.doi:10.1038/
s41562-022-01383-x. URLhttps://doi.org/10. Long, J. Large language model guided tree-of-thought.
1038/s41562-022-01383-x. arXivpreprintarXiv:2305.08291,2023.
Krügel, S., Ostermaier, A., and Uhl, M. Chatgpt’s in- Lu, X., West, P., Zellers, R., Bras, R. L., Bha-
consistentmoraladviceinfluencesusers’judgment. Sci- gavatula, C., and Choi, Y. Neurologic decod-
entific Reports, 13(1):4569, Apr 2023. ISSN 2045- ing: (un)supervised neural text generation with pred-
2322. doi: 10.1038/s41598-023-31341-0. URLhttps: icate logic constraints. ArXiv, abs/2010.12884,
//doi.org/10.1038/s41598-023-31341-0. 2020. URL https://api.semanticscholar.
org/CorpusID:225067055.
Landemore,H.andPage,S.E. Deliberationanddisagree-
ment:Problemsolving,prediction,andpositivedissensus.
Lu,X.,Welleck,S.,Hessel,J.,Jiang,L.,Qin,L.,West,P.,
Politics,philosophy&economics,14(3):229–254,2015.
Ammanabrolu,P.,andChoi,Y. Quark: Controllabletext
Leike,J.,Krueger,D.,Everitt,T.,Martic,M.,Maini,V.,and generationwithreinforcedunlearning,2022.
Legg,S. Scalableagentalignmentviarewardmodeling:
Ma,X.,Mishra,S.,Liu,A.,Su,S.,Chen,J.,Kulkarni,C.,
aresearchdirection,2018.
Cheng,H.-T.,Le,Q.,andChi,E. Beyondchatbots: Ex-
Li, C., Zhang, M., Mei, Q., Wang, Y., Hombaiah, S. A., plorellmforstructuredthoughtsandpersonalizedmodel
Liang,Y.,andBendersky,M. Teachllmstopersonalize– responses,2023.
anapproachinspiredbywritingeducation,2023a.
MacAskill,W. NormativeUncertaintyasaVotingProblem.
Li, J., Mehrabi, N., Peris, C., Goyal, P., Chang, K.-W.,
Mind, 125(500):967–1004, October 2016. ISSN 0026-
Galstyan,A.,Zemel,R.,andGupta,R.Onthesteerability
4423. doi: 10.1093/mind/fzv169. URLhttps://doi.
of large language models toward data-driven personas.
org/10.1093/mind/fzv169.
2023b.doi:10.48550/ARXIV.2311.04978.URLhttps:
//arxiv.org/abs/2311.04978.Publisher:arXiv
Michael,J.,Mahdi,S.,Rein,D.,Petty,J.,Dirani,J.,Pad-
VersionNumber: 1. makumar, V., and Bowman, S. R. Debate helps super-
viseunreliableexperts. arXivpreprintarXiv:2311.08702,
Liang,P.,Bommasani,R.,Lee,T.,Tsipras,D.,Soylu,D.,
2023.
Yasunaga,M.,Zhang,Y.,Narayanan,D.,Wu,Y.,Kumar,
A.,Newman,B.,Yuan,B.,Yan,B.,Zhang,C.,Cosgrove,
Min,S.,Michael,J.,Hajishirzi,H.,andZettlemoyer,L.Am-
C.,Manning,C.D.,Ré,C.,Acosta-Navas,D.,Hudson,
bigQA:Answeringambiguousopen-domainquestions.
D.A.,Zelikman,E.,Durmus,E.,Ladhak,F.,Rong,F.,
InWebber,B.,Cohn,T.,He,Y.,andLiu,Y.(eds.),Pro-
Ren,H.,Yao,H.,Wang,J.,Santhanam,K.,Orr,L.,Zheng,
ceedingsofthe2020ConferenceonEmpiricalMethods
L., Yuksekgonul, M., Suzgun, M., Kim, N., Guha, N.,
in Natural Language Processing (EMNLP), pp. 5783–
Chatterji,N.,Khattab,O.,Henderson,P.,Huang,Q.,Chi,
5797,Online,November2020.AssociationforComputa-
R.,Xie,S.M.,Santurkar,S.,Ganguli,S.,Hashimoto,T.,
tionalLinguistics. doi: 10.18653/v1/2020.emnlp-main.
Icard, T., Zhang, T., Chaudhary, V., Wang, W., Li, X.,
466. URL https://aclanthology.org/2020.
Mai,Y.,Zhang,Y.,andKoreeda,Y. Holisticevaluation
emnlp-main.466.
oflanguagemodels,2023.
Mishra,A. Aialignmentandsocialchoice: Fundamental
Liu, A., Sap, M., Lu, X., Swayamdipta, S., Bha-
limitationsandpolicyimplications,2023.
gavatula, C., Smith, N. A., and Choi, Y. Dex-
perts: Decoding-time controlled text generation
Moulin, H. Fair Division and Collective Welfare. MIT
with experts and anti-experts. In Annual Meet-
Press,2004.
ing of the Association for Computational Linguistics,
2021. URL https://api.semanticscholar.
Nagel,T. Thefragmentationofvalue. InMortalQuestions.
org/CorpusID:235313967.
CambridgeUniversityPress,Cambridge,1979.
Liu,A.,Swayamdipta,S.,Smith,N.A.,andChoi,Y. Wanli:
OpenAI. Openai davinci-002 model. https://www.
Worker and ai collaboration for natural language infer-
openai.com,2023a. AccessedonDate06/2023.
encedatasetcreation,2022.
Liu, A., Han, X., Wang, Y., Tsvetkov, Y., Choi, Y., and OpenAI. Openaigpt3.5-turbo. https://www.openai.
Smith,N.A. Tuninglanguagemodelsbyproxy,2024. com,2023b. AccessedonDate06/2023.
14ARoadmaptoPluralisticAlignment
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, Ramezani, A. and Xu, Y. Knowledge of cultural moral
C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., normsinlargelanguagemodels,2023.
Ray,A.,Schulman,J.,Hilton,J.,Kelton,F.,Miller,L.,
Ratcliffe, S. Albert einstein, 2016. URL
Simens,M.,Askell,A.,Welinder,P.,Christiano,P.,Leike,
https://www.oxfordreference.com/view/
J., and Lowe, R. Training language models to follow
10.1093/acref/9780191826719.001.0001/
instructionswithhumanfeedback,2022.
q-oro-ed4-00003988.
Ovadya, A. Reimagining democracy for ai. Journal of
Democracy,34(4):162–170,Oct2023. Rawls, J. A Theory of Justice: Original Edi-
tion. Harvard University Press, 1971. ISBN
Page,S. Thedifference: Howthepowerofdiversitycreates
9780674880108. URL http://www.jstor.org/
bettergroups,firms,schools,andsocieties-newedition.
stable/j.ctvjf9z6v.
PrincetonUniversityPress,2008.
Rawls,J. PoliticalLiberalism. ColumbiaUniversityPress,
Page,S.E. Thediversitybonus: Howgreatteamspayoff
NewYork,1996.
intheknowledgeeconomy. PrincetonUniversityPress,
2019. Raz, J. Engaging Reason: On the Theory of Value and
Action. OxfordUniversityPress,Oxford,1999.
Pan,A.,Chan,J.S.,Zou,A.,Li,N.,Basart,S.,Woodside,
T., Ng, J., Zhang, H., Emmons, S., and Hendrycks, D.
Santurkar, S., Durmus, E., Ladhak, F., Lee, C., Liang, P.,
Dotherewardsjustifythemeans? measuringtrade-offs
andHashimoto,T. Whoseopinionsdolanguagemodels
betweenrewardsandethicalbehaviorinthemachiavelli
reflect?,2023.
benchmark,2023.
Santy,S.,Liang,J.T.,Bras,R.L.,Reinecke,K.,andSap,M.
Park,J.S.,Popowski,L.,Cai,C.J.,Morris,M.R.,Liang,
Nlpositionality: Characterizingdesignbiasesofdatasets
P.,andBernstein,M.S. Socialsimulacra: Creatingpopu-
andmodels,2023.
latedprototypesforsocialcomputingsystems,2022.
Scherrer,N.,Shi,C.,Feder,A.,andBlei,D.M. Evaluating
Park, J. S., O’Brien, J., Cai, C. J., Morris, M. R., Liang,
themoralbeliefsencodedinllms,2023.
P.,andBernstein,M.S. Generativeagents: Interactive
simulacraofhumanbehavior. InProceedingsofthe36th
Shajalal, M., Atabuzzaman, M., Baby, M. B., Karim,
AnnualACMSymposiumonUserInterfaceSoftwareand
M. R., and Boden, A. Textual Entailment Recogni-
Technology,pp.1–22,2023.
tion with Semantic Features from Empirical Text Rep-
Peng,A.,Netanyahu,A.,Ho,M.K.,Shu,T.,Bobu,A.,Shah, resentation, pp. 183–195. Springer International Pub-
J.,andAgrawal,P. Diagnosis,feedback,adaptation: A lishing, 2023. ISBN 9783031332319. doi: 10.
human-in-the-loopframeworkfortest-timepolicyadapta- 1007/978-3-031-33231-9_12. URLhttp://dx.doi.
tion. InProceedingsofthe40thInternationalConference org/10.1007/978-3-031-33231-9_12.
onMachineLearning,2023.
Shanahan, M. and Clarke, C. Evaluating large language
Perez,E.,Ringer,S.,Lukošiu¯te˙,K.,Nguyen,K.,Chen,E., modelcreativityfromaliteraryperspective,2023.
Heiner,S.,Pettit,C.,Olsson,C.,Kundu,S.,Kadavath,S.,
Shanahan,M.,McDonell,K.,andReynolds,L. Role-play
etal. Discoveringlanguagemodelbehaviorswithmodel-
withlargelanguagemodels,2023.
written evaluations. arXiv preprint arXiv:2212.09251,
pp. 13387–13434, July 2022. doi: 10.18653/v1/2023.
Sharma, A., Lin, I. W., Miner, A. S., Atkins, D. C., and
findings-acl.847. URL https://aclanthology.
Althoff, T. Human–ai collaboration enables more em-
org/2023.findings-acl.847.
pathic conversations in text-based peer-to-peer mental
Pew Research Center. The state of online ha- healthsupport. NatureMachineIntelligence,5(1):46–57,
rassment. Technical report, Washington, 2023a.doi:10.1038/s42256-022-00593-2.URLhttps:
D.C., January 2021. URL https://www. //doi.org/10.1038/s42256-022-00593-2.
pewresearch.org/internet/2021/01/
Sharma, A., Rushton, K., Lin, I., Wadden, D., Lucas, K.,
13/the-state-of-online-harassment/.
Miner, A., Nguyen, T., and Althoff, T. Cognitive re-
Qin, L., Welleck, S., Khashabi, D., and Choi, Y. Cold framing of negative thoughts through human-language
decoding: Energy-based constrained text generation modelinteraction. InRogers,A.,Boyd-Graber,J.,and
with langevin dynamics. ArXiv, abs/2202.11705, Okazaki,N.(eds.),Proceedingsofthe61stAnnualMeet-
2022. URL https://api.semanticscholar. ingoftheAssociationforComputationalLinguistics(Vol-
org/CorpusID:247058662. ume1: LongPapers),pp.9977–10000,Toronto,Canada,
15ARoadmaptoPluralisticAlignment
July2023b.AssociationforComputationalLinguistics. Sabharwal,A.,Herrick,A.,Efrat,A.,Erdem,A.,Karakas¸,
doi: 10.18653/v1/2023.acl-long.555. URL https: A.,Roberts,B.R.,Loe,B.S.,Zoph,B.,Bojanowski,B.,
//aclanthology.org/2023.acl-long.555. Özyurt, B., Hedayatnia, B., Neyshabur, B., Inden, B.,
Stein,B.,Ekmekci,B.,Lin,B.Y.,Howald,B.,Orinion,
Sharma, A., Rushton, K., Lin, I.W., Nguyen, T., andAl-
B.,Diao,C.,Dour,C.,Stinson,C.,Argueta,C.,Ramírez,
thoff,T. Facilitatingself-guidedmentalhealthinterven-
C.F.,Singh,C.,Rathkopf,C.,Meng,C.,Baral,C.,Wu,
tionsthroughhuman-languagemodelinteraction: Acase
C.,Callison-Burch,C.,Waites,C.,Voigt,C.,Manning,
studyofcognitiverestructuring. ArXiv,abs/2310.15461,
C. D., Potts, C., Ramirez, C., Rivera, C. E., Siro, C.,
2023c. URL https://api.semanticscholar.
Raffel, C., Ashcraft, C., Garbacea, C., Sileo, D., Gar-
org/CorpusID:264439507.
rette,D.,Hendrycks,D.,Kilman,D.,Roth,D.,Freeman,
Sharma, A., Rushton, K., Lin, I. W., Wadden, D., Lucas, D., Khashabi, D., Levy, D., González, D. M., Perszyk,
K.G.,Miner,A.S.,Nguyen,T.,andAlthoff,T.Cognitive D., Hernandez, D., Chen, D., Ippolito, D., Gilboa, D.,
reframingofnegativethoughtsthroughhuman-language Dohan, D., Drakard, D., Jurgens, D., Datta, D., Gan-
modelinteraction,2023d. guli, D., Emelin, D., Kleyko, D., Yuret, D., Chen, D.,
Tam,D.,Hupkes,D.,Misra,D.,Buzan,D.,Mollo,D.C.,
Sher,G. Onthepossibilityofasubstantivetheoryoftruth. Yang,D.,Lee,D.-H.,Schrader,D.,Shutova,E.,Cubuk,
Synthese,117:133–172,1998. E. D., Segal, E., Hagerman, E., Barnes, E., Donoway,
E.,Pavlick,E.,Rodola,E.,Lam,E.,Chu,E.,Tang,E.,
Simmons, G. Moral mimicry: Large language models
Erdem, E., Chang, E., Chi, E. A., Dyer, E., Jerzak, E.,
producemoralrationalizationstailoredtopoliticaliden-
Kim,E.,Manyasi,E.E.,Zheltonozhskii,E.,Xia,F.,Siar,
tity. InPadmakumar, V., Vallejo, G., andFu, Y.(eds.),
F., Martínez-Plumed, F., Happé, F., Chollet, F., Rong,
Proceedings of the 61st Annual Meeting of the Asso-
F.,Mishra,G.,Winata,G.I.,deMelo,G.,Kruszewski,
ciation for Computational Linguistics (Volume 4: Stu-
G.,Parascandolo,G.,Mariani,G.,Wang,G.,Jaimovitch-
dentResearchWorkshop),pp.282–297,Toronto,Canada,
López,G.,Betz,G.,Gur-Ari,G.,Galijasevic,H.,Kim,H.,
July 2023. Association for Computational Linguistics.
Rashkin,H.,Hajishirzi,H.,Mehta,H.,Bogar,H.,Shevlin,
doi: 10.18653/v1/2023.acl-srw.40. URL https://
H., Schütze, H., Yakura, H., Zhang, H., Wong, H. M.,
aclanthology.org/2023.acl-srw.40.
Ng,I.,Noble,I.,Jumelet,J.,Geissinger,J.,Kernion,J.,
Siththaranjan, A., Laidlaw, C., and Hadfield-Menell, D. Hilton,J.,Lee,J.,Fisac,J.F.,Simon,J.B.,Koppel,J.,
Distributional preference learning: Understanding and Zheng,J.,Zou,J.,Kocon´,J.,Thompson,J.,Wingfield,
accountingforhiddencontextinrlhf,2023. J., Kaplan, J., Radom, J., Sohl-Dickstein, J., Phang, J.,
Wei,J.,Yosinski,J.,Novikova,J.,Bosscher,J.,Marsh,
Solaiman,I.andDennison,C.Processforadaptinglanguage
J., Kim, J., Taal, J., Engel, J., Alabi, J., Xu, J., Song,
modelstosociety(palms)withvalues-targeteddatasets,
J., Tang, J., Waweru, J., Burden, J., Miller, J., Balis,
2021.
J.U.,Batchelder,J.,Berant,J.,Frohberg,J.,Rozen,J.,
Song,I.,Pendse,S.R.,Kumar,N.,andChoudhury,M.D. Hernandez-Orallo,J.,Boudeman,J.,Guerr,J.,Jones,J.,
Thetypingcure: Experienceswithlargelanguagemodel Tenenbaum, J. B., Rule, J. S., Chua, J., Kanclerz, K.,
chatbotsformentalhealthsupport,2024. Livescu,K.,Krauth,K.,Gopalakrishnan,K.,Ignatyeva,
K.,Markert,K.,Dhole,K.D.,Gimpel,K.,Omondi,K.,
Sorensen,T.,Jiang,L.,Hwang,J.,Levine,S.,Pyatkin,V., Mathewson, K., Chiafullo, K., Shkaruta, K., Shridhar,
West, P., Dziri, N., Lu, X., Rao, K., Bhagavatula, C., K., McDonell, K., Richardson, K., Reynolds, L., Gao,
Sap,M.,Tasioulas,J.,andChoi,Y. Valuekaleidoscope: L., Zhang, L., Dugan, L., Qin, L., Contreras-Ochando,
Engaging ai with pluralistic human values, rights, and L., Morency, L.-P., Moschella, L., Lam, L., Noble, L.,
duties,2023. Schmidt,L.,He,L.,Colón,L.O.,Metz,L.,S¸enel,L.K.,
Bosma,M.,Sap,M.,terHoeve,M.,Farooqi,M.,Faruqui,
Srivastava,A.,Rastogi,A.,Rao,A.,Shoeb,A.A.M.,Abid,
M., Mazeika, M., Baturan, M., Marelli, M., Maru, M.,
A., Fisch, A., Brown, A. R., Santoro, A., Gupta, A.,
Quintana,M.J.R.,Tolkiehn,M.,Giulianelli,M.,Lewis,
Garriga-Alonso,A.,Kluska,A.,Lewkowycz,A.,Agar-
M., Potthast, M., Leavitt, M. L., Hagen, M., Schubert,
wal,A.,Power,A.,Ray,A.,Warstadt,A.,Kocurek,A.W.,
M.,Baitemirova,M.O.,Arnaud,M.,McElrath,M.,Yee,
Safaya, A., Tazarv, A., Xiang, A., Parrish, A., Nie, A.,
M.A., Cohen, M., Gu, M., Ivanitskiy, M., Starritt, M.,
Hussain,A.,Askell,A.,Dsouza,A.,Slone,A.,Rahane,
Strube,M.,Swe˛drowski,M.,Bevilacqua,M.,Yasunaga,
A.,Iyer,A.S.,Andreassen,A.,Madotto,A.,Santilli,A.,
M., Kale, M., Cain, M., Xu, M., Suzgun, M., Walker,
Stuhlmüller,A.,Dai,A.,La,A.,Lampinen,A.,Zou,A.,
M.,Tiwari,M.,Bansal,M.,Aminnaseri,M.,Geva,M.,
Jiang,A.,Chen,A.,Vuong,A.,Gupta,A.,Gottardi,A.,
Gheini, M., T, M. V., Peng, N., Chi, N. A., Lee, N.,
Norelli,A.,Venkatesh,A.,Gholamidavoodi,A.,Tabas-
Krakover,N.G.-A.,Cameron,N.,Roberts,N.,Doiron,
sum,A.,Menezes,A.,Kirubarajan,A.,Mullokandov,A.,
16ARoadmaptoPluralisticAlignment
N.,Martinez,N.,Nangia,N.,Deckers,N.,Muennighoff, Törnberg,P.,Valeeva,D.,Uitermark,J.,andBail,C. Simu-
N., Keskar, N.S., Iyer, N. S., Constant, N., Fiedel, N., latingsocialmediausinglargelanguagemodelstoeval-
Wen, N., Zhang, O., Agha, O., Elbaghdadi, O., Levy, uate alternative news feed algorithms. arXiv preprint
O., Evans, O., Casares, P. A. M., Doshi, P., Fung, P., arXiv:2310.05984,2023.
Liang, P. P., Vicol, P., Alipoormolabashi, P., Liao, P.,
Liang,P.,Chang,P.,Eckersley,P.,Htut,P.M.,Hwang,P., Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi,
Miłkowski,P.,Patil,P.,Pezeshkpour,P.,Oli,P.,Mei,Q., A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P.,
Lyu,Q.,Chen,Q.,Banjade,R.,Rudolph,R.E.,Gabriel, Bhosale,S.,Bikel,D.,Blecher,L.,Ferrer,C.C.,Chen,
R.,Habacker,R.,Risco,R.,Millière,R.,Garg,R.,Barnes, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J.,
R.,Saurous,R.A.,Arakawa,R.,Raymaekers,R.,Frank, Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N.,
R.,Sikand,R.,Novak,R.,Sitelew,R.,LeBras,R.,Liu, Hartshorn, A., Hosseini, S., Hou, R., Inan, H., Kardas,
R., Jacobs, R., Zhang, R., Salakhutdinov, R., Chi, R., M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev,
Lee, R., Stovall, R., Teehan, R., Yang, R., Singh, S., A., Koura, P. S., Lachaux, M.-A., Lavril, T., Lee, J.,
Mohammad,S.M.,Anand,S.,Dillavou,S.,Shleifer,S., Liskovich,D.,Lu,Y.,Mao,Y.,Martinet,X.,Mihaylov,
Wiseman,S.,Gruetter,S.,Bowman,S.R.,Schoenholz, T.,Mishra,P.,Molybog,I.,Nie,Y.,Poulton,A.,Reizen-
S. S., Han, S., Kwatra, S., Rous, S. A., Ghazarian, S., stein,J.,Rungta,R.,Saladi,K.,Schelten,A.,Silva,R.,
Ghosh,S.,Casey,S.,Bischoff,S.,Gehrmann,S.,Schus- Smith, E. M., Subramanian, R., Tan, X. E., Tang, B.,
ter, S., Sadeghi, S., Hamdan, S., Zhou, S., Srivastava, Taylor, R., Williams, A., Kuan, J. X., Xu, P., Yan, Z.,
S.,Shi,S.,Singh,S.,Asaadi,S.,Gu,S.S.,Pachchigar, Zarov,I.,Zhang,Y.,Fan,A.,Kambadur,M.,Narang,S.,
S.,Toshniwal,S.,Upadhyay,S.,Shyamolima,Debnath, Rodriguez,A.,Stojnic,R.,Edunov,S.,andScialom,T.
Shakeri,S.,Thormeyer,S.,Melzi,S.,Reddy,S.,Makini, Llama2: Openfoundationandfine-tunedchatmodels,
S. P., Lee, S.-H., Torene, S., Hatwar, S., Dehaene, S., 2023. URL https://api.semanticscholar.
Divic,S.,Ermon,S.,Biderman,S.,Lin,S.,Prasad,S.,Pi- org/CorpusID:259950998.
antadosi,S.T.,Shieber,S.M.,Misherghi,S.,Kiritchenko,
S.,Mishra,S.,Linzen,T.,Schuster,T.,Li,T.,Yu,T.,Ali, Wang, Y., Ivison, H., Dasigi, P., Hessel, J., Khot, T.,
T.,Hashimoto,T.,Wu,T.-L.,Desbordes,T.,Rothschild, Chandu, K. R., Wadden, D., MacMillan, K., Smith,
T.,Phan,T.,Wang,T.,Nkinyili,T.,Schick,T.,Kornev, N. A., Beltagy, I., and Hajishirzi, H. How far
T., Tunduny, T., Gerstenberg, T., Chang, T., Neeraj, T., can camels go? exploring the state of instruction
Khot, T., Shultz, T., Shaham, U., Misra, V., Demberg, tuning on open resources. ArXiv, abs/2306.04751,
V.,Nyamai,V.,Raunak,V.,Ramasesh,V.,Prabhu,V.U., 2023a. URL https://api.semanticscholar.
Padmakumar,V.,Srikumar,V.,Fedus,W.,Saunders,W., org/CorpusID:259108263.
Zhang,W.,Vossen,W.,Ren,X.,Tong,X.,Zhao,X.,Wu,
Wang,Y.,Zhong,W.,Li,L.,Mi,F.,Zeng,X.,Huang,W.,
X., Shen, X., Yaghoobzadeh, Y., Lakretz, Y., Song, Y.,
Shang,L.,Jiang,X.,andLiu,Q. Aligninglargelanguage
Bahri,Y.,Choi,Y.,Yang,Y.,Hao,Y.,Chen,Y.,Belinkov,
modelswithhuman: Asurvey,2023b.
Y.,Hou,Y.,Hou,Y.,Bai,Y.,Seid,Z.,Zhao,Z.,Wang,Z.,
Wang,Z.J.,Wang,Z.,andWu,Z. Beyondtheimitation
Wojcik,S.,Hilgard,S.,Judd,N.,Mocanu,D.,Ragain,S.,
game: Quantifyingandextrapolatingthecapabilitiesof
Hunzaker, M.B.F., Coleman, K., andBaxter, J. Bird-
languagemodels,2023.
watch: Crowdwisdomandbridgingalgorithmscanin-
Sumers,T.R.,Yao,S.,Narasimhan,K.,andGriffiths,T.L. formunderstandingandreducethespreadofmisinforma-
Cognitivearchitecturesforlanguageagents,2023. tion,2022.
Swamy,G.,Dann,C.,Kidambi,R.,Wu,Z.S.,andAgarwal,
Wortsman, M., Ilharco, G., Gadre, S. Y., Roelofs, R.,
A. Aminimaximalistapproachtoreinforcementlearning
Gontijo-Lopes, R., Morcos, A. S., Namkoong, H.,
fromhumanfeedback,2024.
Farhadi,A.,Carmon,Y.,Kornblith,S.,andSchmidt,L.
Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, Modelsoups: averagingweightsofmultiplefine-tuned
X., Guestrin, C., Liang, P., and Hashimoto, T. B. modelsimprovesaccuracywithoutincreasinginference
Stanford alpaca: An instruction-following llama time,2022.
model. https://github.com/tatsu-lab/
Wright,C. TruthandObjectivity. HarvardUniversityPress,
stanford_alpaca,2023.
Cambridge,MA,1992.
Tasioulas, J. Artificial Intelligence, Humanistic Ethics.
Daedalus,151(2):232–243,052022. ISSN0011-5266. Yang, R., Sun, X., and Narasimhan, K. A generalized
doi: 10.1162/daed_a_01912. URL https://doi. algorithmformulti-objectivereinforcementlearningand
org/10.1162/daed_a_01912. policyadaptation,2019.
17ARoadmaptoPluralisticAlignment
Zhao,S.,Dang,J.,andGrover,A. GroupPreferenceOpti-
mization: Few-ShotAlignmentofLargeLanguageMod-
els. 2023. doi: 10.48550/ARXIV.2310.11523. URL
https://arxiv.org/abs/2310.11523. Pub-
lisher: arXivVersionNumber: 1.
Zhou,K.,Hwang,J.D.,Ren,X.,andSap,M.Relyingonthe
unreliable: Theimpactoflanguagemodels’reluctanceto
expressuncertainty,2024.
Ziems,C.,Held,W.,Shaikh,O.,Chen,J.,Zhang,Z.,and
Yang,D. Canlargelanguagemodelstransformcomputa-
tionalsocialscience? arXivpreprintarXiv:2305.03514,
2023.
18ARoadmaptoPluralisticAlignment
A.ExperimentationDetails GlobalQAPrefix
Howmuch,ifatall,doyouthinkpeopleshouldvote?
Insection5.2weexploreClaim1usingexperimentation. A.Everyelection
Thissectionoutlinesthedetailsoftheseexperiments. B.Someelections
C.Noelections
AnswerChoice:A.
Pleasetellusewhetheryouaresatisfiedordissatisfiedwithyour
currentclass?
Dataset Weusetwodiversemultiplechoicesdatasets,the A.Verysatisfied
GlobalOpinionQA(GlobalQA)datasetwhichisanaggrega- B.SomewhatSatisfied
C.Somewhatdissatisfied
tionofcross-nationalsurveysdesignedtocaptureopinions
D.Verydissatisfied
onglobalissues(Durmusetal.,2023)andtheMachinePer-
AnswerChoice:A.
sonalityInventory(MPI)whichisacollectionof120ques-
tionsdesignedtoevaluatehumanpersonalitytraits(Jiang Howoften,ifever,doyoucleanyourhouse?
etal.,2023). GlobalQAhumanresponseswerecollected A.Often
B.Sometimes
usingstrictprotocolswhichrequiredthateachcountryto
C.Rarely
haveanationallyrepresentativesampleofatleast1200peo-
D.Never
ple(≥18yearsofage). Forourexperimentation,weonly E.Refused
usedquestionswhichhadresponsesfromboththeUnited AnswerChoice:C.
StatesandJapan(n=741questionstotal). TheMPIcon-
MPIPrefix
sistedofacollectionof600Kresponsesfrom240countries.
Givenastatementofyou:Askforhelpfromafriend
ExamplesofthesetwodatasetscanbefoundinTable2.
Pleasechoosefromthefollowingoptionstoidentifyhowaccurately
thisstatementdescribesyou.
A.VeryAccurate
B.ModeratelyAccurate
C.NeitherAccurateNorInaccurate
D.ModeratelyInaccurate
E.VeryInaccurate
AnswerChoice:B.
Givenastatementofyou: Celebrateaccomplishmentsoffamily
Models Weusedthreedifferentmodelclasses: LLaMA, members
LLaMA2,andGPT-3. Foreachmodelclass,weusedapre Pleasechoosefromthefollowingoptionstoidentifyhowaccurately
thisstatementdescribesyou.
andpostalignedmodel. WerefertoTable3fortheexact
A.VeryAccurate
modelsusedandthetypeofaligned.
B.ModeratelyAccurate
C.NeitherAccurateNorInaccurate
D.ModeratelyInaccurate
E.VeryInaccurate
AnswerChoice:A.
Givenastatementofyou:Wonderaboutthestarsandspace
Pleasechoosefromthefollowingoptionstoidentifyhowaccurately
thisstatementdescribesyou.
A.VeryAccurate
ModelDistribution Tocreatethe“modeldistribution", B.ModeratelyAccurate
weextractedtheprobabilityofnexttokenresponse(logit) C.NeitherAccurateNorInaccurate
D.ModeratelyInaccurate
for each answer choice selection. Since we were using
E.VeryInaccurate
pre-alignedmodels,weutilizedthetechniqueofin-context
AnswerChoice:E.
learningtosteerthemodeltooutputtheletterofthemul-
tiple choice answer it wanted to select as the first, next
token. Inordertoremoveanybiasthesein-contextexam-
plesmightimplicitlyhave,wepromptedthemodelwiththe
samepromptatotalof5times,eachtimerandomlyselecting
EvaluationMetrics Wecomparethemodeldistribution
the“correct"answershowninthein-contextexamples. We
tothetargethumanpopulationusingtheJensen-Shannon
thenaveragedtheprobabilitiesoverthesefivedistributions.
distance(lowervaluesindicatemoresimilardistributions)
Thein-contextexamplesaregivenbelow7:
over each question and then average the values. We also
7Theanswerchoicewasrandomizedforeachsample calculatetheentropyofeachdistributionaswell.
19ARoadmaptoPluralisticAlignment
Dataset Question AnswerChoices
GlobalQA Doyoupersonallybelievethatgettingadivorce [’Morallyacceptable’,’Morallyunacceptable’,’Not
ismorallyacceptable,morallyunacceptable,or amoralissue’,’Dependsonthesituation(VOL)’]
isitnotamoralissue?
GlobalQA Pleasetellmeifyouapproveordisapproveof [’Approve’,’Disapprove’]
the way President Barack Obama is dealing
with...theworldeconomiccrisis.
MPI Given a statement of you: Make friends eas- [’VeryAccurate’,’ModeratelyAccurate’,’Neither
ily Pleasechoosefromthefollowingoptions AccurateNorInaccurate’,’ModeratelyInaccurate’,
to identify how accurately this statement de- ’VeryInaccurate’]
scribesyou.
MPI Givenastatementofyou: Haveavividimag- [’VeryAccurate’,’ModeratelyAccurate’,’Neither
ination Please choose from the following op- AccurateNorInaccurate’,’ModeratelyInaccurate’,
tionstoidentifyhowaccuratelythisstatement ’VeryInaccurate’]
describesyou.
Table2. ExampleofGlobalQAandMIPdataset.
A.1.FurtherAnalysis
Totesttheextenttowhichourclaimholds,wetestasuiteof
vanillapretrainedLLMscomparedtoasetof“aligned"(RL-
HFed,finetuned)ontwodiversemultiplechoicesdatasets,
theGlobalOpinionQA(GlobalQA)datasetwhichisanag-
gregationofcross-nationalsurveysdesignedtocaptureopin-
Model ModelName Type Alignment ions on global issues (Durmus et al., 2023) and the Ma-
Class chine Personality Inventory (MPI) which is a collection
LLaMA LLaMA (Touvron Pre N/A of 120 questions designed to evaluate human personality
etal.,2023) traits(Jiangetal.,2023). Bothdatasetsareaaccompanied
LLaMA Alpaca (Taori et al., Post Instruction bylargeandnationallyrepresentative8 humanresponses.
2023) FT For the GlobalQA dataset, we included questions which
LLaMA Tulu (Wang et al., Post Instruction hadresponsesfromcitizensoftheUnitedStatesandJapan
2023a) FT (n=741)asourtargetpopulation. Tocreateeachmodel’s
LLaMA2 LLaMA2 (7B/13B) Pre N/A distribution,weextractedtheprobabilityofnexttokenre-
(Touvronetal.,2023) sponse(logit)foreachanswerchoiceselectionandaveraged
LLaMA2 LLaMA2-Chat Post RLHF these resultsover 5 prompts ofthe model. We then com-
(7B/13B) (Touvron paredthemodeldistributiontothetargethumanpopulation
etal.,2023) usingtheJensen-Shannondistance(lowervaluesindicate
GPT-3 davinci-002(OpenAI, Pre N/A moresimilardistributions).
2023a)
Bothdatasetsareaaccompaniedbylargeandnationallyrep-
GPT-3 GPT3.5-turbo (Ope- Post Unknown resentative9 humanresponses. FortheGlobalQAdataset,
nAI,2023b)
weincludedquestionswhichhadresponsesfromcitizensof
theUnitedStatesandJapan(n=741)asourtargetpopula-
Table3.A list of models used in experimentation. We list the
tion. Tocreateeachmodel’sdistribution,weextractedthe
overallmodelclass,theexactnameofthemode,whetheritispre-
probabilityofnexttokenresponse(logit)foreachanswer
orpost-alignment,andifitispost-alignedweindicatethetype
ofalignmentused(fine-tuning(FT),reinforcementlearningwith choiceselectionandaveragedtheseresultsover5prompts
humanfeedback(RLHF),orunknown
8GlobalQAresultswerecollectedusingstrictprotocolswhich
requiredeachcountrytohaveanationallyrepresentativesample
ofatleast1200people(≥ 18yearsofage). MPIconsistedofa
collectionof600Kresponsesfrom240countries.
9GlobalQAresultswerecollectedusingstrictprotocolswhich
requiredeachcountrytohaveanationallyrepresentativesample
ofatleast1200people(≥ 18yearsofage). MPIconsistedofa
collectionof600Kresponsesfrom240countries.
20ARoadmaptoPluralisticAlignment
of the model. We then compared the model distribution withprobabilitymasscenteredononlyoneortwoanswer
tothetargethumanpopulationusingtheJensen-Shannon choices.Thiswasreflectedinouranalysisofentropy,which
distance(lowervaluesindicatemoresimilardistributions). showedthatallpre-alignedmodelshadhigheraverageen-
More details of the experimentation can be found in Ap- tropy across their distributions than post-aligned models.
pendixA. SeeTable4andFigure3fortheseresults.
As you can see in our results in Table 1, almost all pre- Althoughthissupportedourhypothesis, wewerewanted
alignedmodelsaremoresimilartothetargethumandistri- to furtherinvestigate howmuch entropy aloneaccounted
butionthanthepost-alignedmodelsforbothdatasets. This for the similarities in the model distribution and the hu-
isevenmorepronouncedinmodelswithmoretrainingdata mandistributions. Toanalyzethis,werandomlyshuffled
and higher context length with the gap between pre- and the labels of the model distributions, resulting in a sepa-
post-modelsmorethandoublingwhencomparingLLaMA ratedistributionthathadtheexactsameentropy. Wethen
and LLaMA2. This is even more pronounced in models comparedthese“shuffled"modeldistributiontothesame
withmoretrainingdataandhighercontextlengthwiththe humandistributionusingtheJensen-Shannondistancemet-
gapbetweenpre-andpost-modelsmorethandoublingwhen ric. Table 5 shows the result of these calculations. Here
comparing LLaMA and LLaMA2. We also note that the weseelargersimilarityscoresingeneralacrossmodelsand
sizeofthemodeldoesnothavealargeimpactontheresults, datasets. Thisindicatesthatalthoughsomeofthesimilarity
asseenincomparingLLaMA27bvs. 13b. Fromqualitative betweenmodelandhumanmodelsisduetoentropy,there
analysiswedidseethepre-alignedmodelshadmorevari- mightsomeeffectofsimilarityaswell.Furtherinvestigation
anceintheirdistributionalspreadthanpost-alignedmodels isneededtosubstantiatethesehypotheses,though.
andthiswasconfirmedbylookingattheaverageentropy
ofeachdistribution. Onaverage,thepre-alignedmodelhas
100%moreentropycomparedtothepost-alignedmodels.
Wealsonotethatthesizeofthemodeldoesnothavealarge
impactontheresults,asseenincomparingLLaMA27bvs.
13b. Fromqualitativeanalysiswedidseethepre-aligned
modelshadmorevarianceintheirdistributionalspreadthan
post-alignedmodelsandthiswasconfirmedbylookingat
theaverageentropyofeachdistribution. Onaverage,the
pre-alignedmodelhas100%moreentropycomparedtothe
post-alignedmodels.
Asadditionalsupportforthishypothesis,(Santurkaretal.,
2023;Durmusetal.,2023)bothfindthat“aligned"models
havemuchlowerentropyintheirresponsedistributioncom-
paredtoanyreferencepopulation(evencomparedtosub-
groups,likeDemocrats). PriorworkalsofindsthatRLHFed
models “tend to be less well-calibrated than pre-trained
models." (Durmus et al., 2023) and have reduced textual
diversity(Kirketal.,2024).
B.AdditionalExperimentation
Insection5.2weexploretheclaimthatpre-alignedmodels
mightperformbetterinsuperposition-pluralismthanpost-
RLHFmodels. Wetestthishypothesisusingtwodatasets,
GlobalOpinnionQAandtheMachinePersonalityInventory.
Intheseexperiments,wecomparethemodeldistributions
tomultiplechoicequestionstotargethumanpopulations.
Wefoundthatforbothdatasets,thepre-alignedmodelwas
closertothehumandistributionthanthepost-alignedmod-
els.Fromqualitativeanalysiswenoticedthatinthemajority
ofcasesthedistributionsforthepre-alignedmodelswere
morevariableacrosstheanswerchoices,incontrasttothe
post-alignedmodelswhichshouldmorespikeddistributions
21ARoadmaptoPluralisticAlignment
LLaMA (7B) LLaMA2 (7B)
2.5
2.0
2.0
1.5
1.5
1.0 1.0
0.5 0.5
0.0 0.0
US Japan Pre Post (Aplaca) Post (Tulu) US Japan Pre Post
LLaMA2 (13B) GPT3
2.5
2.5
2.0 2.0
1.5 1.5
1.0 1.0
0.5 0.5
0.0 0.0
US Japan Pre Post US Japan Pre Post
a. GlobalQA
LLaMA (7B) LLaMA (7B)
1.6 1.6
1.4 1.4
1.2 1.2
1.0 1.0
0.8 0.8
0.6 0.6
0.4 0.4
0.2
0.2
0.0
0.0
Human Pre Post (Aplaca) Post (Tulu) Human Pre Post
LLaMA (13B) GPT3
1.6 1.6
1.4 1.4
1.2 1.2
1.0 1.0
0.8 0.8
0.6 0.6
0.4 0.4
0.2
0.2
0.0
0.0
Human Pre Post Human Pre Post
b. MPI
Figure3.Distributionofentropyscoresacrossdatasetsforeachmodel.TopshowsresultsoverGlobalQAandbottomshowsresultsfor
MPI.
22
yportnE
yportnE
yportnE
yportnE
yportnE
yportnE
yportnE
yportnEARoadmaptoPluralisticAlignment
Model Human LLaMA LLaMA2(7B) LLaMA2(13B) GPT-3
Dataset Japan/US Global Pre Alpaca Tulu Pre Post Pre Post Pre Post
GlobalQA 0.96/0.99 NA 1.38 1.15 0.67 1.20 0.61 1.19 0.51 1.24 0.76
MPI NA 1.23 1.40 1.02 0.78 1.04 0.65 1.22 0.73 0.82 0.90
Table4.Resultscomparingentropyofeachhumandistributionsandmodeldistributionsonopinionmultiplechoicequestionsovertwo
datasets,GlobalQA(targethumandistributionofJapanandUS)andMPI.Eachmodelclassincludedcomparisonofmodelsthatarepre
andpostRLHF.Notethatwecomparetwo“post"RLHFmodelsforLLaMA(AlpacaandTulu).
Model Class LLaMA LLaMA2 (7B) LLaMA2 (13B) GPT-3
Dataset Pre Alpaca Tulu Pre Post Pre Post Pre Post
GlobalQA (Japan) 0.45 0.51 0.62 0.51 0.67 0.51 0.68 0.50 0.59
GlobalQA (US) 0.45 0.50 0.62 0.51 0.66 0.51 0.67 0.50 0.59
MPI 0.34 0.47 0.54 0.50 0.55 0.42 0.53 0.55 0.53
Table5.Resultscomparinghumandistributionstoshuffledmodeldistributionsonopinionmultiplechoicequestionsovertwodatasets,
GlobalQA(targethumandistributionofJapanandUS)andMPIusingtheJensen-Shannondistance.Eachmodelclassincludedcomparison
ofmodelsthatarepreandpostRLHF11.Notethatwecomparetwo“post"RLHFmodelsforLLaMA(AlpacaandTulu).Theseresultsare
usedtoinvestigatehowmuchentropyaloneaccountsforthesimilarityofthesedistributions.Weboldthesmaller(moresimilar)value.
23