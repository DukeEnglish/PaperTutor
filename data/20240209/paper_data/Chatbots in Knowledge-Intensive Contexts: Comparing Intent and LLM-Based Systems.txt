ChatbotsinKnowledge-IntensiveContexts:ComparingIntentandLLM-Based
Systems
S.KERNANFREIRE,DelftUniversityofTechnology,TheNetherlands
C.WANG,WenzhouUniversity,China
E.NIFORATOS,DelftUniversityofTechnology,Netherlands
Cognitiveassistants(CA)arechatbotsthatprovidecontext-awaresupporttohumanworkersinknowledge-intensivetasks.Traditionally,
cognitiveassistantsrespondinspecificwaystopredefineduserintentsandconversationpatterns.However,thisrigidnessdoes
nothandlethediversityofnaturallanguagewell.Recentadvancesinnaturallanguageprocessing(NLP),poweringlargelanguage
models(LLM)suchasGPT-4,Llama2,andGemini,couldenableCAstoconverseinamoreflexible,human-likemanner.However,the
additionaldegreesoffreedommayhaveunforeseenconsequences,especiallyinknowledge-intensivecontextswhereaccuracyis
crucial.AsapreliminarysteptoassessingthepotentialofusingLLMsinthesecontexts,weconductedauserstudycomparingan
LLM-basedCAtoanintent-basedsystemregardinginteractionefficiency,userexperience,workload,andusability.Thisrevealed
thatLLM-basedCAsexhibitedbetteruserexperience,taskcompletionrate,usability,andperceivedperformancethanintent-based
systems,suggestingthatswitchingNLPtechniquesshouldbeinvestigatedfurther.
CCSConcepts:•Human-centeredcomputing→EmpiricalstudiesinHCI;Interactivesystemsandtools;Naturallanguage
interfaces.
AdditionalKeyWordsandPhrases:cognitiveassistant,chatbots,knowledgemanagement,industry5.0,human-centeredAI,knowledge
sharing,naturallanguageprocessing
1 INTRODUCTION
Afoundationlargelanguagemodel(LLM),suchasGPT-4,canoffervariousfunctions,suchasansweringgeneral
knowledgequestions,refiningtext,andcheckinglogic.However,theylackthespecialized,context-specificknowledge
ataworkplace[3,28].Theinformationcontainedinthefoundationmodelscanbeextendedbyprovidingcontext
material,aprocesscalledretrievalaugmentedgeneration(RAG)[14].Thisinvolvesanadditionalstepintheresponse
thatretrievescontextmaterialrelevanttotheuser’squeryfromadatasource(e.g.,alocaldatabaseortheweb).
Resultingly,anLLM-basedtoolcanmorereliablydelivercoherent,context-specificinformation.Previousworkhas
identifiedthepotentialofusingRAGtoolsinspecific,knowledge-intensivedomains,suchasmanufacturing[11].
Knowledgemanagement(KM)isincreasinglyrecognizedasavitaldisciplinethatinvolvescreating,sharing,and
usinganorganization’sknowledge.Aknowledgemanagementsystem(KMS)differsfromaninformationsystem
(IS)becauseusersareexpectedtoshareandretrieveknowledge.Oneofthesesystems,cognitiveassistants(CA),is
aformofKMSthatcancaptureandshareknowledgeamongworkersthroughconversationalinteractions[12].The
prevailingconversationaltechniqueforCAsisintent-basednaturallanguageprocessing(NLP)[26].However,the
rigidityofthistechniquecanresultinfrequentconversationbreakdowns[22].Furthermore,intent-basedsystemsare
resource-intensivetocreateandmaintainasthedevelopermustdefineallpossibleuserintents,howtheassistant
shouldrespond,andwhatfunctionsordataitmightneed[20].LLM-basedsystemscouldhelpalleviatesomeofthese
constraintsastheyarequicktodeploy,andtheirsuperiorNLPcapabilitiescanbeusedtodevelopmoreflexible,robust
conversationalinteractions.ToevaluatethepotentialofLLM-basedsystemscomparedtointent-basedsystems,we
conductedalabstudytocomparethemininteractionefficiency,workload,userexperience,andusability.
1
4202
beF
7
]CH.sc[
1v55940.2042:viXraKernanFreire,etal.
2 RELATEDWORKANDMOTIVATION
Intherelatedworksection,weoutlineexistingliteratureandthemotivationforthiswork.Weaddressadvancements
inAIforKnowledgeManagement(KM),NaturalLanguageProcessing(NLP)techniquesforcognitiveassistants(CA),
andusingLargeLanguageModels(LLMs)inknowledge-intensivecontexts.
2.1 AIforKnowledgeManagement
Intheworkplace,AIhasevolvedfromautomatingsimplecognitivetasks(e.g.,customersupportchatbots)toaiding
complexdecision-making(e.g.,CAsformachineoperators).Toimprovetheefficiencyofknowledgecaptureandsharing,
interactiveartificalintelligence(AI)solutionsarebeingdeveloped.Fenoglioetal.[6]introducedarole-playinggame
forknowledgecapture,andBalaynetal.[2]developedagametoelicittacitknowledge.SolimanandVanharanta[23]
proposedaknowledgeretentionmodel,whileHoerneretal.[9]focusedontroubleshootingsupport.CAsareemerging
associo-technicalsystemsintegratingusergoals,tasks,andtechnology,adaptingtovaryingenvironmentsanduser
needs[1,12,16].
2.2 NaturalLanguageProcessingforCognitiveAssistants
Still,theprevailingNLPtechniqueforCAsisintent-based,thesametechniqueusedformostconversationaluser
interfacessuchascustomerservicechatbotsandvirtualassistantslikeAlexa.OnlyveryrecentlydidLLMsemergeas
analternativeapproachtotacklesomeoftheshortcomingsofintents-basedconversationalsystems.Inthefollowing
sections,weoutlinethemaincharacteristicsofthesetechniquesandhowthese(may)impactuserexperience(UX).
Intent-basedsystems,groundedintheprinciplesofsymbolicAIandrule-basedprocessing,currentlyunderpin
mostmodernCAs.Thesesystems,asStolckeetal.[24]andLuoetal.[15]discuss,aredesignedtorecognizeand
interpretuserintentsthroughpredefinedpatternsandcommands.Theyrelyheavilyonstructuredknowledgebasesand
decisiontrees,enablingthemtorespondtospecificqueriesorexecutetasksaccordingtorecognizedcommands.While
limitedinflexibilityandadaptability,thisapproachprovidesahighdegreeofcontrolandpredictabilityininteractions,
renderingintent-basedsystemssuitableforapplicationswhereprecisionandruleadherenceareimportant.However,
asRahmanetal.[22]noted,theinherentrigidityofintent-basedsystemspresentssubstantialchallenges.Theseinclude
difficultiescomprehendingnuancedexpressionsandoperatingeffectivelyindynamiccontextswhereuserneedsand
environmentalfactorsmayrapidlyshift(e.g.,agilemanufacturing).Inturn,thismayhurtUXasintent-basedsystems
oftenstruggletoaccommodateatypicalconversationpatternsandphrasingthatahumancouldeasilyunderstand[22].
Existingliteratureemphasizeshowintent-basedchatbotsfrequentlyfailtohelpusersachievetheirgoals[7,8,13,18].
Incontrasttotherigidintent-basedsystems,LLMsarehighlyflexible.LLMssuchasGemini1,Claude2,orGPT-4[21]
canunderstand,generate,andinteractwithhumanlanguageatasophisticatedlevel[10].Infact,LLMsmarkasignificant
stepforwardfromtheirpredecessors,RecurrentNeuralNetworks(RNNs).UnlikeRNNs,whichprocesstextsequentially
andoftenstrugglewithlong-rangedependencies,LLMscananalyzeandgeneratetextinparallel,handlingextensive
contextandcomplexlanguagepatternsefficiently[28].ThisinnateabilityofLLMsmakesthemmorepowerfuland
versatilethanintent-basedsystems,whicharetypicallyrule-basedorutilizesimplermachinelearningmodelsscoped
tounderstandspecificuserintentionswithlimitedconsiderationforcontext[19,22].Fromauser’sperspective,an
LLM-basedsystemismorelikelytoresolveconversationalbreakdownsandhandledivergentphrasingbetter[17].
1https://deepmind.google/technologies/gemini–lastaccessedFebruary8,2024.
2https://www.anthropic.com/news/introducing-claude–lastaccessedFebruary8,2024.
2ChatbotsinKnowledge-IntensiveContexts:ComparingIntentandLLM-BasedSystems
2.3 LLM-basedSystemsinKnowledge-intensiveContexts
Workinginfactoriesisknowledge-intensive,dynamic,andfast-paced.FactoriesofferarichresourceforNLPwith
extensivetextdocuments,suchasworkinstructionsandmachinemanuals,andcontinuousknowledgeadditionthrough
reports.Therefore,manufacturingprovidesanidealcasestudyforinvestigatingCAs.However,theunstructuredtext
andinconsistentterminology,typicallyencounteredinmanufacturingcontexts,canbechallengingforNLP[5].State-
of-the-artNLP,suchasLLMs,canmitigatethesechallenges.Forexample,theycaneffectivelyharnesstheinformation
inthesedocumentsusingRAG[14].
ResearchersarealreadyexploringhowtoutilizeLLM-poweredtoolsinthemanufacturingcontext.Xiaetal.[27]
showcasedhowin-contextlearningandtheinjectionoftask-specificknowledgeintoLLMscanimprovetheplanning
andcontrolofproductionprocesses.KernanFreireetal.[11]developedaRAG-basedsystemtohelpshareknowledge
amongworkers.AsystematictestbyWangetal.[25]evaluatedChatGPT’sresponsesto100manufacturing-related
questionsusingazero-shotmethod.Alloftheabovepreliminarystudieshavedemonstratedpromiseintheability
ofLLM-basedsystemstoretrievethecorrectinformationinaspecificdomain.However,theirpracticaleffectiveness
whencoupledwithaCAisyettobeexplored.ThisleadsustoinvestigatehowefficientlyLLM-basedCAscaninteract
withusers.
2.4 ResearchQuestion
Asresearchersinalargeinnovationandresearchproject,wewitnessedashiftintheperceivedusefulnessofthe
CAsatthefactorieswhenweintegratedLLMsinearly2023.WeintegratedLLMsforRAGandcapturingandsharing
knowledgewithworkersinamoreflexiblewaythanthetechniquesavailabletointent-basedAssistants,suchas
FAQsandform-filling.However,wewantedtoempiricallyandmeasurablyconfirmourobservations,formulatingthe
followingresearchquestion:RQ:HowdoLLMandIntent-basedcognitiveassistantscompareininteraction
efficiency,systemusability,userexperience,andperceivedworkloadforworkers?WeexpectthatLLMwill
performbetterinallaspectsduetotheirsuperiornaturallanguageunderstandingwhencomparedtointent-based
systems.
3 SYSTEMS:LLMANDINTENT-BASEDCOGNITIVEASSISTANTS
Forthisstudy,wedevelopedandevaluatedtwocognitiveassistants(CAs)withthesamefunctionalitybutdifferent
NLPtechniques:intent-basedandLLM-based.BothCAsweredevelopedincollaborationwithtwofactoriestosupport
workersthroughconversationalknowledgesharingandinformationretrieval.Thecapturingcomponentofknowledge
sharing involves recording how workers solve issues or set up the machines for a product, whereas knowledge
sharinginvolvesdeliveringittootherworkerswhentheyrequestit.Originally,thefactorymanagementhadobserved
highdisparitiesbetweenworkershiftperformance,pooradherencetostandardworkingprocedures,andinefficient
knowledgesharingpractices.Despitethetop-downinitiationoftheproject,weinvolvedtheworkersthroughout
thedesign&developmentprocesstoensurethatwealsomettheirneedsandvalues(participatorydesign[4]).This
consistedofmultipleroundsofsemi-structuredinterviews,observations,anduserevaluations.Thesystemshadthe
followingcapabilities:capturingandsharingproduct-specificmachinesettingsandadvice;capturingandsharing
issue-handlingknowledge;FAQswithanswerspreparedbyexperts;andinformationretrievalfromstandardwork
instructions.
3KernanFreire,etal.
(a) (b)
Fig.1. (Conversational)UserInterfaces(UIs)of(a)theIntent-basedand(b)theLLM-basedcongitiveassistants.
Theintent-basedsystemreliesonalistofuserintents,andconversationalpatternsforwhichexamplesare
provided.Thisdataisusedtotrainanintentclassifier,entityextractor,andrulesthatdefinehowthesystemshould
respond.Responsescouldincludeatextresponsetousers,executingfunctionstoinsertinformationintoaknowledge
base,displayingastandardworkinstruction,orenteringaform-fillingloop3tocollectthenecessaryinformationfrom
theuser.Trainingphrasesforeachintentwereusedtotrainamodeltoclassifytheintentandextractdesirednamed
entities,suchasmachinecomponentnames.ItwasbuiltusingRasaX4,astate-of-the-artconversationalAIframework
andfeaturedasimplechatinterface(seeFigure1a).Conversely,theLLM-basedsystemwasbuiltusingLlamaIndex
forthebackend5 andGradio6 tobuildacomparablechatinterface(seeFigure1b,andtheGPT-3.5API(version:
gpt-3.5-turbo-0613)7forLLMcalls.ThebehavioroftheLLM-basedsystemwasdefinedusingasystempromptanda
contextchatmodewhichretrievedrelevantinformationfromprovideddocumentsineveryconversationturn8.Weused
thesystemprompttoinstructtheLLMthatitwasanassistantforworkersandtousetheprovidedcontextmaterial
whenresponding.Thetextweprovidedforretrievalaugmentedgeneration(RAG)containedrelevantinformationand
instructionsonrespondingtouserqueriesthatmatchedtheknowledgebaseoftheintent-basedsystem.
Overall,ourgoalwastomatchtheinterfacedesignoftheconditionsascloselyaspossible.Tothisend,theybothhave
asimplechatinterfacewithabuttontosendtextmessages.Furthermore,theyrelyonthesameunderlyingknowledge
basetoanswerquestionsandrequestthesameinformationwhencapturingknowledge.However,severaldifferences
existduetotheintrinsiccharacteristicsofthetwoNLPtechniquesandunderlyingdevelopmentalframeworks.Firstly,
themostprominentdifferenceisthattheintent-basedCAcandisplayimageswhenauserasksaboutastandardwork
procedure,whereastheLLM-basedassistantonlygeneratestext.Eventhoughwedonotasktheuserstousethe
3https://rasa.com/docs/rasa/forms/–lastaccessedFebruary8,2024.
4https://legacy-docs-rasa-x.rasa.com/docs/rasa-x/1.0.x/–lastaccessedFebruary8,2024.
5https://docs.llamaindex.ai/–lastaccessedFebruary8,2024.
6https://www.gradio.app/–lastaccessedFebruary8,2024.
7https://platform.openai.com/docs/models/gpt-3-5–lastaccessedFebruary8,2024.
8https://docs.llamaindex.ai/en/latest/examples/chat_engine/chat_engine_context.html–lastaccessedFebruary8,2024.
4ChatbotsinKnowledge-IntensiveContexts:ComparingIntentandLLM-BasedSystems
retrievedinformation,thismaypositivelypredisposethemtowardthemorevisualintent-basedcondition.Secondly,
thereareminordifferencesinthevisualappearanceoftheuserinterface,forexample,colors,fonts,andfontsize.This
mayhaveaminoreffectontheresults;however,asthedifferencesaresmall,webelievethiscanbeignored.Thirdly,
theintent-basedsystemusesbuttonstosuggestuserresponses,asiscommonlyfoundinintent-basedsystems.This
maybiastheinteractionefficiencyresultstowardtheintent-basedgroupasusersareprovidedwithactionshortcuts.
4 METHOD:QUANTITATIVEUSERSTUDY
AsapreliminaryinvestigationintothedifferencesininteractionefficiencyandUXbetweentheNLPtechniques,we
conductedabetween-groupsuserstudy.First,participantswereintroducedtotheconceptofCAsandthemanufacturing
operationscontextthroughashortlectureandvideos.Afterreadingandsigningtheinformedconsentforminan
onlinesurvey,theparticipantswereinstructedtoaccessthechatinterfaceontheirlaptoporsmartphone,distributed
equallybetweengroups.Then,participantswereinstructedtocompleteeightinformationandknowledge-sharing
tasksandmeasuretheperceivedusability,userexperience(UX),workload,andtaskperformance.Theeightknowledge
exchangetaskswiththeassistantincludeinformationretrieval(e.g.,“Findinstructionsonhowtoperformaprerun.”)
andknowledgesharing(e.g.,"Sharethis[solution]forthis[problem]withtheassistant."Theparticipantswereinformed
thattheyhadtenminutestoattemptalltasks.Furthermore,theywereaskedtoindicatewhethertheycompletedeach
taskbyselectingacheckboxinthesurvey.Participantswerenotaskedtoactupontheretrievedinformationorshare
theirknowledge.Therefore,thisstudyfocusesontheuserinteractioncapabilitiesofthesystem-i.e.,theabilityto
retrieveandsharedomain-specificknowledgethroughconversation-nottheabilitytocompletework-relatedtasks.
Afterthetenminuteshadpassed,theparticipantswereinstructedtoproceedtotherestofthesurveyiftheyhadnot
alreadydoneso,startingwithperceivedworkload(NASA-TLX).
WerecruitedN=55industrialdesignmasterstudentstoparticipateinthestudy.Althoughtheireducationalbackground
differsfromfactoryworkers,webelievetheirexperienceinusingchatbotsiscomparableasthedominantagegroup
(17-29)isthesame.Mostparticipantsfellintothe17-29bracket(n=47),leavingtwointhe30-39bracket,andone
preferrednottodisclose.Genderwasdistributedasfollows:n=26women,n=21men,twonon-binary,andonedidnot
disclose.Weremovedthreecasesforcompletingthetasksunrealisticallyfast(lessthan60seconds)andtwocasesfor
takinglongerthan660seconds(60secondsovertheindicatedmaximumtimeoftenminutes).Datafortheintent-based
condition(n=17)wascollectedinAugust2022,beforethereleaseofChatGPT.Conversely,thedatafortheLLMcondition
(n=35)wascollectedinNovember2023.
5 RESULTS:LLMVERSUSINTENT-BASEDCOGNITIVEASSISTANTS
Beforeselectingourstatisticalanalysismethods,weconductedpre-tests,suchastheShapiro-Wilktestsforassessing
datanormalityandLevene’steststochecktheequalityofvariances.Detailsofthesepreliminarytestsarenotincluded
hereforbrevity.Dependingonthetypeofstatisticalanalysisemployed,weeitherreportmeansandstandarddeviations
forparametrictestsormedianvaluesfornon-parametrictests.Weusedindependentsamplest-testsandMann-Whitney
U-testsfortheparametricandnon-parametrictests,respectively.
Inassessingtheeffectivenessofthetwogroups—IntentandLLMs—inuserexperience,severaldimensionswere
evaluatedusingthesystemusabilityscale(SUS),userexperiencequestionnaire(UEQ),NASAtaskloadindex(NASA-
TLX),tasktime,andtaskcompletionrate.Theresultsrevealeddistinctdifferencesbetweenthetwogroups(intent-based
vs.LLM-based)acrosssomemeasuredfacets,aspresentedbelow.
5KernanFreire,etal.
1,0 100
600 ,8 80
,6 60
400
,4 40
200
,2 20
0 ,0 0
Intent LLM Intent LLM Intent LLM
Assistant type Assistant type Assistant type
(a) (b) (c)
Fig.2. Tasktime(a),Taskcompletionrate*(b),andSystemusabilityscore*(c)betweentheIntentandLLMgroups
5.1 TaskPerformance
Tasktime,whichrepresentsthetimeusersspentcompletingtasks,wasnotsignificantlydifferentbetweengroups(t(48)
=1.864,p=.068)(seeFigure2a).Itwasmeasuredautomaticallybythetimespentonthesurveypagecontainingthe
taskinstructions.TheIntentgrouphadameantasktimeof376.25seconds(standarddeviation(SD)=131.43),whilethe
LLMgrouphadanotablyshortermeantimeof301.11seconds(SD=141.86).
Thatsaid,asignificantdifferencewasfoundinthetaskcompletionrate(seeFigure2b).TheLLMgroupachieveda
highermediantaskcompletionrate(1.00)comparedtotheIntentgroup(.88)(U =153.50,p=.006).Thissuggeststhat
usersintheLLMconditionweremoresuccessfulincompletingtheassignedinteractions.
5.2 SystemUsability
FortheSUS,theIntentgroupreportedameanscoreof44.85(SD=16.75),whiletheLLMgroupdemonstratedahigher
meanscoreof59.85(SD=17.47)(seeFigure2c).Thisdifferencewasstatisticallysignificant(t(48)=-2.958,p=.005),
indicatingthatusersfoundtheLLMconditiontobemoreusablecomparedtotheIntentcondition.
Page 1
Page 1 Page 1
5.3 UserExperience
WeusedtheUEQquestionnairetocompareself-reportedUXbetweenthetwogroups(intent-basedvs.LLM-based).
Thesearereportedassixdimensions(seeFigure3).RegardingtheAttractiveness,theIntentgroup’smeanscorewas
-.13(SD=.85),comparedto.46(SD=.91)fortheLLMcondition.Thisdifferencewasstatisticallysignificant(t(48)
=-2.25,p=.029),suggestingthatusersperceivedtheLLMconditionasmoreattractive.RegardingPerspicuity,the
clarityoftheuserinterface,theIntentgroupscoredamedianof.25,whiletheLLMgroupscoredsignificantlyhigher
withamedianof.75,withaU-valueofU =154.00andp-valueofp=.009.Thisresultindicatesaclearerandmore
understandableinterfaceintheLLMcondition.Efficiencyalsoshowedasignificantdifference.TheIntentgroup’smean
scorewas.08(SD=.87),whereastheLLMgroupscoredameanof1.10(SD=.91),resultinginasignificantdifference
(t(48)of-3.90andp<.001).ThissuggeststhatusersfoundtheLLMconditionmoreefficient.Whenexaminingthe
Dependabilityaspect,theIntentgrouphadameanscoreof.25(SD=.79),andtheLLMgroupscoredhigherwitha
meanof.88(SD=.85).Thisdifferencewassignificant(t(48)=-2.54,p=.01),indicatingagreatersenseofdependability
6
)sdnoces(
emit
ksaT
etar
noitelpmoc
ksaT
erocs
ytilbasu
metsySChatbotsinKnowledge-IntensiveContexts:ComparingIntentandLLM-BasedSystems
3
Attractiveness*
Perspicuity*
2 Efficiency*
Dependability*
Stimulation
1
Novelty
0
-1
-2
-3
Intent LLM
Assistant type
Fig.3. UserExperience(UEQscores)betweentheLLMandIntentgroups
perceivedbyusersintheLLMcondition.Theremainingdimensions,stimulation,andnovelty,didnotsignificantly
differbetweengroups,soweomittedthetestdetailsforbrevity.
5.4 Workload
25
Mental demand
20 Physical demand
Temporal demand
Performance*
15 Effort
Frustration
Total
10
5
0
Intent LLM
Assistant type
Fig.4. Workload(NASA-TLX)betweentheLLMandIntentconditions
NASA-TLXisa21-pointscalewhereahighscoreindicatesahighperceivedworkload.Ofallthecomponents,only
performanceshowedasignificantdifferencebetweentheconditions(seeFigure4).Namely,theLLMgrouphada
significantlybettermedianscoreof4comparedto10fortheIntentgroup(U =123.50,p=.001).Thisindicatesthatusers
intheLLMconditionexperiencedahighersenseofperformance.Weomittheteststatisticsfortheothercomponents
forbrevity.Forthemeanperceivedworkload,thescorefortheIntentgroupwas9.70(SD=3.03),whereasitwas7.89
(SD=4.54)fortheLLMgroup.Thiswasnotsignificantlydifferent,asshownbythefollowingtestscores:t(48)=1.49,p
=.15,suggestingbothconditionsexperiencedasimilaroverallworkload.
7
Page 1
Page 1
ecneirepxe
resU
daolkroWKernanFreire,etal.
6 DISCUSSION
6.1 InsightsandImplicationsforPractice
OurstudysuggeststhatLLM-basedassistantscouldmeasurablyhelpworkersretrieveinformationandshareknowledge
moreefficientlythanintent-basedsystems.Participantsweremoresuccessfulincompletingtheassignedtasks,which
isalsoreflectedintheperceivedperformance(NASA-TLX),userexperience(UEQ),andusability(SUS).Webelievethe
observeddifferencescouldbelargelyattributedtotheflexibilityandsuperiorunderstandingofLLM-basedcognitive
assistants(CAs)comparedtointent-basedones.ThefollowingcommentsfromtheLLMconditionsupportthisview:"It
isreliableandtrustworthy.Whateverinstructionsitgivesme,Iunderstoodthemwellandbelievedit.(S3)";and"Itfelt
quiteintuitive,reallyeasytoaskthe’right’questions.(L11)".Conversely,oncetheintent-basedsystemwentdownthe
wrong"conversationpath",itwasmoretroublesometorecoverfrom,sometimesrequiringrestartingtheconversation,
confirmingexistingliterature[7,8,13,18].Commentsfromtheparticipantsintheintentconditionsupportthese
observations;forexample,"chatbotisnotflexible,youhavetofollowitsstructure.(L29)",and"Annoyinghowyou
sometimeshavetorephrasewhatyouwant.(L11)".
Interestingly,participantsfromtheLLMconditionstillmissedsuggestionsforinput,asstatedbyparticipantL3:
"IwouldstilllikesomesuggestionsortemplateshowIcaninteractwith."Futureworkcouldexplorehowdesigners
couldincorporatesuggestedinputstoguideusersofLLM-basedsystems,atleastinitially.Thiscouldalsodemonstrate
thatshortcutsorkeywordsmightbesufficientwhenapplicable,asparticipantS1suggested:"Ithinkthatactions
thathappenalot(like,Iassume,savingsettingsetc.)shouldnotrequiretypingsomuchonasmartphonescreen".
Furthermore,multimodalitywillbeimportantinknowledge-intensivecontextswherevisualizationsaremoreapplicable
thantext-basedinstructions,asmentionedbyparticipantS2:"Maybeconsidertotakethevisualizationtooltoshowthe
keyinformation/parameterforaclearerunderstandingbetweentheoperatorandthechatbox."
Overall,theresultsdemonstrateseveraladvantagesLLM-basedCAscouldbearoverintent-basedsystemsintermsof
theirabilitiestoexchangeinformationwithusers.However,itisimportanttoconsiderthatwhenintent-basedsystems
fail,theworstthatcanhappenisamisunderstanding,usuallyobvioustotheusers.Conversely,anLLM-basedsystem
couldhallucinateananswerthatappearsplausibletotheuser.Assumingthechanceofhallucinationswillneverbe
zero,itiscrucialtoconsidertheethical,productivity,andsafetyimplications.
6.2 Limitations
Allparticipantswatchedashortpresentationonthefactorycontext,includinga5-minutevideo.However,theywere
notfactoryworkersbytraining.Still,webelievetheresultsarevalidastheexperimentfocusedoninteractingwith
theCAanddidnotrequireactinguponretrievedinformation.AnunavoidablechallengewascomparingthetwoNLP
systemsfairly.Ultimately,wespentsignificantlymoretimedevelopingtheintent-basedsystemtoensureitworked
reliablyforthisstudy.Futureworkcouldcomparehowdevelopmenttimeimpactsthequalityoftheresultingsystems.
7 CONCLUSION
LLM-basedcognitiveassistantsareshowntoimproveinteractionefficiencyovertheirintent-basedcounterparts.This
canbeattributedtotheirsuperiorflexibilityandintelligenceinprocessingnaturallanguage,enablingthemtohelpusers
achievetheirinteractiongoalsinknowledge-intensivecontexts.Whereasthisworkcomparesintent-andllm-based
systemspurelyfromauserinteractionperspective,futureworkcouldexploretheimpactonworktasksandassociated
risks,forexample,hallucinatedinformation.
8ChatbotsinKnowledge-IntensiveContexts:ComparingIntentandLLM-BasedSystems
ACKNOWLEDGMENTS
REFERENCES
[1] 2016.IntelligentCognitiveAssistants:WorkshopSummaryandRecommendations. https://www.nsf.gov/crssprgm/nano/reports/2016-1003_ICA_
Workshop_Final_Report_2016.pdf
[2] AgatheBalayn,GaoleHe,AndreaHu,JieYang,andUjwalGadiraju.2022.ReadyPlayerOne!ElicitingDiverseKnowledgeUsingAConfigurable
Game.InProceedingsoftheACMWebConference2022.1709–1719. https://doi.org/10.1145/3485447.3512241
[3] YejinBang,SamuelCahyawijaya,NayeonLee,WenliangDai,DanSu,BryanWilie,HolyLovenia,ZiweiJi,TiezhengYu,WillyChung,QuyetV.Do,
YanXu,andPascaleFung.2023.AMultitask,Multilingual,MultimodalEvaluationofChatGPTonReasoning,Hallucination,andInteractivity.
arXiv:2302.04023[cs.CL]
[4] ErlingBjörgvinsson,PelleEhn,andPer-AndersHillgren.2010.Participatorydesignand"democratizinginnovation".InProceedingsofthe11th
Biennialparticipatorydesignconference.41–50.
[5] BrettEdwards,MichaelZatorsky,andRichiNayak.2008.Clusteringandclassificationofmaintenancelogsusingtextdatamining.Volume87-Data
MiningandAnalytics2008(2008),193–199.
[6] EnzoFenoglio,EmreKazim,HugoLatapie,andAdrianoKoshiyama.2022.Tacitknowledgeelicitationprocessforindustry4.0.DiscoverArtificial
Intelligence2,1(March2022),6. https://doi.org/10.1007/s44163-022-00020-w
[7] AsbjørnFølstad,TheoAraujo,EffieLai-ChongLaw,PetterBaeBrandtzaeg,SymeonPapadopoulos,LeaReis,MarcosBaez,GuyLaban,Patrick
McAllister,CarolinIschen,etal.2021. Futuredirectionsforchatbotresearch:aninterdisciplinaryresearchagenda. Computing103,12(2021),
2915–2942.
[8] AsbjørnFølstadandPetterBaeBrandtzæg.2017.ChatbotsandthenewworldofHCI.interactions24,4(2017),38–42.
[9] LorenzHoerner,MarkusSchamberger,andFreimutBodendorf.2022.UsingTacitExpertKnowledgetoSupportShop-floorOperatorsThrougha
Knowledge-basedAssistanceSystem.ComputerSupportedCooperativeWork(CSCW)(Sept.2022). https://doi.org/10.1007/s10606-022-09445-4
[10] GaneshJawahar,BenoîtSagot,andDjaméSeddah.2019. WhatDoesBERTLearnabouttheStructureofLanguage?.InProceedingsofthe
57thAnnualMeetingoftheAssociationforComputationalLinguistics.AssociationforComputationalLinguistics,Florence,Italy,3651–3657.
https://doi.org/10.18653/v1/P19-1356
[11] SamuelKernanFreire,MinaFoosherian,ChaofanWang,andEvangelosNiforatos.2023.HarnessingLargeLanguageModelsforCognitiveAssistants
inFactories.InProceedingsofthe5thInternationalConferenceonConversationalUserInterfaces(Eindhoven,Netherlands)(CUI’23).Associationfor
ComputingMachinery,NewYork,NY,USA,Article44,6pages. https://doi.org/10.1145/3571884.3604313
[12] SamuelKernanFreire,SarathSurendranadhaPanicker,SantiagoRuiz-Arenas,ZoltánRusák,andEvangelosNiforatos.2022.ACognitiveAssistantfor
Operators:AI-PoweredKnowledgeSharingonComplexSystems.IEEEPervasiveComputing(2022),1–9. https://doi.org/10.1109/MPRV.2022.3218600
[13] Yi-ChiehLee,NaomiYamashita,andYunHuang.2021.Exploringtheeffectsofincorporatinghumanexpertstodeliverjournalingguidancethrough
achatbot.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW1(2021),1–27.
[14] PatrickLewis,EthanPerez,AleksandraPiktus,FabioPetroni,VladimirKarpukhin,NamanGoyal,HeinrichKüttler,MikeLewis,Wen-tauYih,Tim
Rocktäschel,SebastianRiedel,andDouweKiela.2020.Retrieval-AugmentedGenerationforKnowledge-IntensiveNLPTasks.InProceedingsofthe
34thInternationalConferenceonNeuralInformationProcessingSystems(Vancouver,BC,Canada)(NIPS’20).CurranAssociatesInc.,RedHook,NY,
USA,Article793,16pages.
[15] Bei Luo, Raymond Y. K. Lau, Chunping Li, and Yain-Whar Si. 2022. A critical review of state-of-the-art chatbot designs
and applications. WIREs Data Mining and Knowledge Discovery 12, 1 (2022), e1434. https://doi.org/10.1002/widm.1434
arXiv:https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1434
[16] AlexanderMaedche,ChristineLegner,AlexanderBenlian,BenediktBerger,HennerGimpel,ThomasHess,OliverHinz,StefanMorana,andMatthias
Söllner.2019.AI-baseddigitalassistants:Opportunities,threats,andresearchperspectives.Business&InformationSystemsEngineering61(2019),
535–544. https://doi.org/10.1007/s12599-019-00600-8
[17] AmamaMahmood,JunxiangWang,BingshengYao,DakuoWang,andChien-MingHuang.2023.LLM-PoweredConversationalVoiceAssistants:
InteractionPatterns,Opportunities,Challenges,andDesignGuidelines. arXiv:2309.13879[cs.HC]
[18] RaphaelMeyervonWolff,SebastianHobert,andMatthiasSchumann.2021.Sorry,Ican’tunderstandyou!–Influencingfactorsandchallengesof
chatbotsatdigitalworkplaces.InInnovationThroughInformationSystems:VolumeII:ACollectionofLatestResearchonTechnologyIssues.Springer,
150–165.
[19] BonanMin,HayleyRoss,EliorSulem,AmirPouranBenVeyseh,ThienHuuNguyen,OscarSainz,EnekoAgirre,IlanaHeintz,andDanRoth.2023.
RecentAdvancesinNaturalLanguageProcessingviaLargePre-trainedLanguageModels:ASurvey.ACMComput.Surv.56,2,Article30(sep2023),
40pages. https://doi.org/10.1145/3605943
[20] AntoniosMisargopoulos,FilipposNikolopoulos-Gkamatsis,KonstantinosNestorakis,AlexandrosTzoumas,GeorgiosGiannakopoulos,Christos-
AntoniosGizelis,andMichalisKefalogiannis.2022.BuildingaKnowledge-Intensive,Intent-Lean,QuestionAnsweringChatbotintheTelecom
Industry-ChallengesandSolutions.InIFIPInternationalConferenceonArtificialIntelligenceApplicationsandInnovations.Springer,87–97. https:
//doi.org/10.1007/978-3-031-08341-9_8
[21] OpenAI.2023.GPT-4TechnicalReport. arXiv:2303.08774[cs.CL]
9KernanFreire,etal.
[22] AMRahman,AbdullahAlMamun,andAlmaIslam.2017.Programmingchallengesofchatbot:Currentandfutureprospective.In2017IEEERegion
10HumanitarianTechnologyConference(R10-HTC).75–78. https://doi.org/10.1109/R10-HTC.2017.8288910
[23] YehyaSolimanandHannuVanharanta.2020. AModelforCapturingTacitKnowledgeinEnterprises.InAdvancesinHumanFactors,Business
ManagementandLeadership(AdvancesinIntelligentSystemsandComputing),JussiIlariKantolaandSalmanNazir(Eds.).SpringerInternational
Publishing,Cham,141–148. https://doi.org/10.1007/978-3-030-20154-8_14
[24] AndreasStolcke,KlausRies,NoahCoccaro,ElizabethShriberg,RebeccaBates,DanielJurafsky,PaulTaylor,RachelMartin,CarolVanEss-Dykema,
andMarieMeteer.2000.DialogueActModelingforAutomaticTaggingandRecognitionofConversationalSpeech.ComputationalLinguistics26,3
(092000),339–373. https://doi.org/10.1162/089120100561737arXiv:https://direct.mit.edu/coli/article-pdf/26/3/339/1797531/089120100561737.pdf
[25] XingzhiWang,NabilAnwer,YunDai,andAngLiu.2023.ChatGPTfordesign,manufacturing,andeducation.ProcediaCIRP119(2023),7–14.
https://doi.org/10.1016/j.procir.2023.04.001The33rdCIRPDesignConference.
[26] StefanWellsandt,ZoltanRusak,SantiagoRuizArenas,DorisAschenbrenner,KarlA.Hribernik,andKlaus-DieterThoben.2020. Conceptofa
Voice-EnabledDigitalAssistantforPredictiveMaintenanceinManufacturing.SSRNElectronicJournal(2020). https://doi.org/10.2139/ssrn.3718008
[27] YuchenXia,ManthanShenoy,NasserJazdi,andMichaelWeyrich.2023.Towardsautonomoussystem:flexiblemodularproductionsystemenhanced
withlargelanguagemodelagents. arXiv:2304.14721[cs.RO]
[28] WayneXinZhao,KunZhou,JunyiLi,TianyiTang,XiaoleiWang,YupengHou,YingqianMin,BeichenZhang,JunjieZhang,ZicanDong,YifanDu,
ChenYang,YushuoChen,ZhipengChen,JinhaoJiang,RuiyangRen,YifanLi,XinyuTang,ZikangLiu,PeiyuLiu,Jian-YunNie,andJi-RongWen.
2023.ASurveyofLargeLanguageModels. arXiv:2303.18223[cs.CL]
10