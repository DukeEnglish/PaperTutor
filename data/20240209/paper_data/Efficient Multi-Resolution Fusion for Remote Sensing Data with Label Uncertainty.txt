EFFICIENTMULTI-RESOLUTIONFUSION
FORREMOTESENSINGDATAWITHLABELUNCERTAINTY
HershVakhariaandXiaoxiaoDu
UniversityofMichigan
ABSTRACT factors, and sensor noise, making uncertainties unavoidable
whenfusingreal-worldremotesensingdata.
Multi-modal sensor data fusion takes advantage of comple-
To address these challenges, we previously proposed a
mentary or reinforcing information from each sensor and
MultipleInstanceMulti-ResolutionFusion(MIMRF)method
can boost overall performance in applications such as scene
[2] for integrating multi-modal and imprecisely labeled re-
classification and target detection. This paper presents a
mote sensing data. It formulated the label uncertainty prob-
new method for fusing multi-modal and multi-resolution re-
lemusingMultipleInstanceLearning(MIL)[3]andreliedon
motesensordatawithoutrequiringpixel-leveltraininglabels,
the Choquet integral [4], a powerful non-linear aggregation
which can be difficult to obtain. Previously, we developed a
tooltoperformmulti-resolutionfusion.However,thecompu-
MultipleInstanceMulti-ResolutionFusion(MIMRF)frame-
tational complexity of the original MIMRF algorithm grows
work that addresses label uncertainty for fusion, but it can
exponentiallywiththenumberofsensorsourcestobefused,
be slow to train due to the large search space for the fuzzy
which limits its efficiency. In this work, we propose an effi-
measuresusedtointegratesensordatasources. Weproposea
cient alternative to the original MIMRF algorithm by incor-
newmethodbasedonbinaryfuzzymeasures,whichreduces
poratingbinaryfuzzymeasures(BFMs)withtheMILframe-
the search space and significantly improves the efficiency
work to improve the efficiency while maintaining the effec-
of the MIMRF framework. We present experimental results
tivenessofmulti-resolutionfusion. Resultsarepresentedon
on synthetic data and a real-world remote sensing detection
real-worldremotesensingdatatodemonstratetheefficiency
taskandshowthattheproposedMIMRF-BFMalgorithmcan
andeffectivenessoftheproposedfusionalgorithm.
effectively and efficiently perform multi-resolution fusion
Theremainderofthepaperisorganizedasfollows. Sec-
givenremotesensingdatawithuncertainty.
tion 2 describes the MIMRF framework. Section 3 presents
Index Terms— multi-resolution sensor fusion, multi- our proposed efficient MIMRF with binary fuzzy measures.
modal, Choquet integral, binary fuzzy measure, hyperspec- Section 4 presents experimental results. Section 5 discusses
tral,labeluncertainty,efficiency theproposedmethodandconclusions.
2. THEMIMRFFRAMEWORK
1. INTRODUCTION
TheMIMRFframework[2]takesheterogeneoussensordata
Twofundamentalchallengesexistwithremotesensordatain-
as inputs (e.g., hyperspectral imagery and LiDAR point
tegration. First, existing optical sensors operate on various
cloud)andlearnsasetofreal-valuedvariables(“fuzzymea-
spatial,spectral,ortemporalresolutions. Theymayalsopro-
sures” [5]) that reflects the interactions among input sensor
duceheterogeneousdatarepresentations, suchashyperspec-
sources. AssumethereareS sourcestobefused, thesizeof
tral imagery on a pixel grid or LiDAR (Light Detection and thefuzzymeasureis2S aseachfuzzymeasureelementcorre-
Ranging) point clouds with geometric measurements [1]. It
spondstoasubsetofthesensorcombinations. Amonotonic
is not always feasible to convert all data to the same resolu-
andnormalized(non-binary)fuzzymeasurecantakeanyreal
tion or map to the same grid for fusion without introducing
valuebetween0and1. Thehigherthefuzzymeasurevalue,
misalignmenterrorsorlosingaccuracy. Second,standardsu-
themoreweightingitisplacingonthecombinationofsensor
pervised learning methods generally require accurate labels
sources. The MIMRF algorithm uses the Choquet integral
for each data point, which can be difficult to obtain in high
[4] to perform fusion based on the learned fuzzy measures.
volume. Moreover, raw sensor data often contains missing
TheadvantageoftheMIMRFframeworkisthatitcanwork
andimprecisemeasurementsduetoocclusion,environmental
with uncertain and imprecise labels, where training labels
are associated with groups of data points (called “bags” or
This material is based upon work supported by the National Science
superpixels[6])instead ofeachpixel, whichgreatlyreduces
Foundation under Grant IIS-2153171-CRII: III: Explainable Multi-Source
DataIntegrationwithUncertainty. theneedtoindividuallylabeleverydatapointduringtraining.
4202
beF
7
]VC.sc[
1v54050.2042:viXra3. EFFICIENTMIMRFWITHBFM(PROPOSED) MILassumptionaccountingforlabeluncertaintygivenmulti-
resolutiondata.Thestructureofourobjectivefunctionissim-
3.1. BinaryFuzzyMeasures(BFMs) ilartothestandardMIMRFmethod(Eq.(7)in[2]),butwein-
In contrast to MIMRF, our proposed efficient MIMRF-BFM troducethenoveluseofBFMstocompressthesearchspace
algorithm utilizes binary fuzzy measures (BFMs) to reduce ofthefuzzymeasureforenhancedefficiency. Anevolution-
thesearchspaceandgreatlyimprovetheefficiency. ABFM ary algorithm [7] was used to train and optimize the BFMs.
is defined as a real valued function that maps 2S → {0,1}. The proposed MIMRF-BFM algorithm automatically learns
It satisfies G(∅) = 0 (empty set rule); G(S) = 1 (normal- the non-linear interactions and relationships (as represented
ization); and G(A) ≤ G(B) if A ⊆ B and A,B ⊆ S by the BFM values) among the input sensor data sources to
(monotonicity). Different from a standard real-valued (non- produceanoptimizedfusionresult.
binary)normalizedfuzzymeasureusedinthepreviouswork,
theBFMonlytakevaluesof0or1,insteadof[0,1].Thus,for
4. EXPERIMENTALRESULTS
S sensorsourcestobefused,BFMonlyneedstosearchand
optimizeover{0,1}2S insteadof[0,1]2S forthereal-valued 4.1. MUUFLGulfportHyperspectralandLiDARFusion
fuzzymeasures,whichleadstoasimplerrepresentation,afi-
Our proposed MIMRF-BFM algorithm was tested on a real-
nitesearchspaceandmoreefficientcomputation.
world remote sensing fusion task on the MUULF Gulfport
dataset[8]. Thedatasetcontainshyperspectralimageryand
3.2. ObjectiveFunctionandModelLearning
3-D LiDAR point clouds collected during two aerial flights
As discussed in the Introduction, one challenge with fusing
overtheUniversityofSouthernMississippi–Gulfparkcam-
remote sensor data is to accommodate the difference in res-
pus. Wefollowasimilarsetupasin[2]andperformbuilding
olution and modality among sensor inputs. Assume we are
detection by fusing three types of sensor inputs, one based
fusinghyperspectralimagery(HSI)withLiDARpointcloud
ontheadaptivecoherenceestimator(ACE)todetectbuilding
data. Each pixel in HSI may correspond to multiple data
spectralsignaturesandtwobasedongeometricmeasurements
points in the LiDAR point cloud (see Figure 3 in [2] for an
of building elevation from LiDAR point cloud data. These
illustration). Additionally, we assume pixel-level labels are
three sensor sources are multi-modal and multi-resolutional
notaccurateenoughduringtrainingandwecanonlyleverage
(multipleLiDARpointscorrespondtoeachHSIpixeldueto
bag-levellabelswithuncertainty(i.e.,traininglabelsarepro-
the difference in sensor resolution and measurement inaccu-
vided per superpixel but not on a pixel-level, which is very
racy). Figure 1 shows the MUUFL Gulfport data contain-
common in remote sensing data due to ground sample dis-
ing hyperspectral imagery, the LiDAR point clouds, and the
tance,sensoraccuracy,etc.). Thus,weaccountforthesetwo
groundtruthmapandsuperpixel-levellabelsforfusiontask.
levelsoffusionuncertaintybywritingtheobjectivefunction:
 2
B−
(cid:88)
m Gin J =
a=1S
a−m i∈a Bx a−
x−
km ∈i Sn
a−
iCG(x− k) −0
(1)
 2
B+
(cid:88)
+ min  max CG(x+
l
) −1 ,
S+∈B+ x+∈S+
b=1 bj b l bj
whereB+ isthetotalnumberofpositivebagscontainingthe Fig.1.MUUFLGulfportdata.(a)Hyperspectralimagery.(b)
target object or material we wish to detect (label 1), B− is Ground truth map for building detection (yellow represents
thetargetbuildingsthatwewishtodetect); (c)Bag-levella-
thetotalnumberofnegativebagscontainingonlynon-target
background information (label 0), x− is the ith instance in belmap,wherethesuperpixelscontainingtargetbuildingsare
theathnegativebagandx+isthejthk instanceinthebthpos- labeledpositive(red)andtherestarelabelednegative(blue).
l The superpixels are generated by the simple linear iterative
itivebag,CG istheChoquetintegral(CI)fusionoutputcom-
puted based on the binary fuzzy measure G, B− is the ath clustering(SLIC)algorithm[9]. (d)3-DLiDARpointcloud.
a
negativebag, andB+ isthebth positivebag, andS denotes The proposed MIMRF-BFM algorithm was compared
b
the set of all possible matching combinations of the multi- with the detection results from the three individual sensor
resolution/multi-modal sensor outputs. By minimizing this input sources before fusion as well as a variety of other
objective function, we seek the unknown binary fuzzy mea- fusion methods to analyze its effectiveness and efficiency.
sure G given all the training data points (x) and bag-level The comparison methods include (i) non-multi-resolution
labels. The first term encourages all instances in negative fusionmethodsthatrequirespixel-perfectlabels,suchastak-
bags to produce a fusion result of “0” (non-target) and the ing the min/max/mean of the three input sources and using
second term encourages at least one set of data instance in the support vector machine (SVM) and k-nearest neighbor
positive bags to have label “1” (target), which satisfies the (KNN) for classification; (ii) mi-SVM [11], which is anTable 1. The AUC and RMSE results of building detection
usingtheMUUFLGulfportdatafusion(Best,SecondBest).
AUC↑ / RMSE↓ / PSNR↑
FusionMethod
Train1Test2 Train2Test1
ACE 0.906/0.362/8.839 0.952/0.346/9.214
LiDAR1 0.888/0.267/11.497 0.880/0.272/11.319
LiDAR2 0.850/0.273/11.243 0.839/0.280/11.053
Min 0.877/0.255/12.262 0.867/0.261/11.673
Max 0.916/0.434/7.333 0.932/0.422/7.501
Mean 0.941/0.310/10.492 0.953/0.302/10.400
SVM 0.892/0.415/7.637 0.958/0.285/7.637
mi-SVM 0.951/0.226/12.379 0.972/0.203/13.863
KNN 0.954/0.237/12.437 0.952/0.243/12.279
MICINoisyor 0.943/0.377/8.621 0.946/0.326/9.030
MIMRF 0.976/0.310/10.314 0.989/0.254/10.635
MIMRF-BFM 0.974/0.131/17.661 0.973/0.128/17.859
PSNR, indicating that the BFMs allow background noise to
beeliminatedmoreeffectively.
Figure2showsvisualresultsofthesensorinputsandthe
fusion maps. Compared to the non-binary MIMRF results
(subfigure k), our proposed MIMRF-BFM (subfigure l) sup-
Fig. 2. Confidence maps of the three individual sensor presses the background pixels much better and only assigns
sources generated from the raw hyperspectral and LiDAR a high confidence score to the desired building pixels. This
sensor data and visual results of various fusion techniques. demonstrated that the BFM actually helps improve the con-
The color bar is between 0 and 1 (blue is low and yellow trast between positive and negative classes and benefits de-
is high confidence). (a) ACE detector confidence based on tection,asthelearnedBFMonlytakesvaluesin{0,1}.
theasphaltmaterialinthehyperspectralimagery;(b)(c)Two We also investigated the actual BFM values learned dur-
LiDAR height maps that highlight different building struc- ing the fusion process. The final BFM learned by the pro-
tures; (d)(e)(f) Min, Max, and Mean of the three input sen- posedMIMRF-BFMalgorithmisG 12 = G 13 = 1,andother
sor sources; (g) SVM; (h) mi-SVM; (i) KNN; (j) MICI [10] measure elements (G 1, G 2, G 3, G 23) were zero. This means
(non-multi-res);(k)MIMRF(multi-res,regularFM)[2];and thattheMIMRF-BFMalgorithmcorrectlyidentifiedthatthe
(l)ProposedMIMRF-BFMmethod(multi-res,withBFM). intersectionbetweensource1&2andsource1&3contributed
mosttothedetectionofallfourbuildings. Thismakessense,
as the ACE detector (source 1) highlighted all asphalt ma-
MIL extension to SVM that works with bag-level labels; terials including building rooftops as well as roads, whereas
(iii) the Multiple Instance Choquet Integral (MICI) method source2and3areLiDARheightmapswhichhighlightedpar-
with a noisy-or objective function [12, 10], which is a non- tialbuildingsbutalsotree canopies. Bylearningthecombi-
multiresolution MIL fusion method based on the Choquet nation among these sources, the MIMRF-BFM was able to
integral; (iv) previous MIMRF method with regular (non- suppressfalsedetectionsofothermaterialssuchasroadsand
binary)fuzzymeasures;and(v)ourproposedMIMRF-BFM trees and instead only place high confidence on the targets
method, which incorporates BFMs for added efficiency and (buildings). Intermsofcomputationtime,theMIMRFtakes
works with both multi-resolution remote sensing data and onaverage30mintotrain,whereastheMIMRFcancomplete
bag-leveltraininglabelswithuncertainty. thesearchandfinishtrainingin10s(over180timesfaster).
Figure3showsaROC(receiveroperatingcharacteristic)
curve result and Table 1 shows the AUC (area under curve),
4.2. Multi-SourceBFMEfficiencyAnalysis
RMSE(rootmeansquareerrorfromgroundtruth),andPSNR
(peak signal-to-noise ratio from ground truth) results across To further analyze the efficiency of the proposed MIMRF-
all methods for quantitative comparison. Higher AUC and BFM approach, we generated an additional synthetic multi-
PSNRandlowerRMSEindicatebetterdetectionresultsafter resolution dataset with incrementally growing (6, 8, 10, and
fusion. Asshown,ourproposedMIMRF-BFMachievedhigh 12) number of sensor sources and compared the computa-
detectionperformance,lowerror,andlownoiseoverall. tion efficiency of the proposed MIMRF-BFM to the origi-
MIMRF-BFM produced an AUC score second to non- nal MIMRF (non-BFM) algorithm. The computation time
binary MIMRF, but outperformed other fusion techniques. (the time it took to converge on an optimal FM/BFM) was
MIMRF-BFM also produced the lowest RMSE and highest recorded and presented in Table 2. It is clear that the pro-to fusing alternative sensor modalities accounting for vary-
ing resolution and label uncertainties. Future work includes
adaptingtheMIMRF-BFMtomulti-view,multi-temporaland
multi-spatial sensor data with uncertainty and incorporating
generalized fuzzy measures, such as fuzzy measures on a
bipolarscale(e.g.,whenFMsmapto[−1,1])[13].
6. REFERENCES
[1] DanfengHong,JocelynChanussot,andXiaoXiangZhu, “An
overviewofmultimodalremotesensingdatafusion:Fromim-
age to feature, from shallow to deep,” in IEEE Int. Geosci.
RemoteSens.Symp.(IGARSS),2021,pp.1245–1248.
[2] Xiaoxiao Du and Alina Zare, “Multiresolution multimodal
sensorfusionforremotesensingdatawithlabeluncertainty,”
IEEE Transactions on Geoscience and Remote Sensing, vol.
58,no.4,pp.2755–2769,2020.
[3] ThomasGDietterich,RichardHLathrop,andToma´sLozano-
Pe´rez, “Solving the multiple instance problem with axis-
parallelrectangles,” Artif.Intell.,vol.89,no.1-2,pp.31–71,
Fig. 3. ROC curve results of building detection accuracy Jan.1997.
on the MUUFL Gulfport dataset (cross validated over two [4] Gustave Choquet, “Theory of capacities,” in Annales de
l’institutFourier,1954,vol.5,pp.131–295.
flights). Orangebox: zoomed-inview. Bestviewedincolor.
[5] James M. Keller, Derong Liu, and David B. Fogel, Funda-
mentalsofcomputationalintelligence: Neuralnetworks,fuzzy
posedMIMRF-BFMalgorithmiscapableoflearninghowto systemsandevolutionarycomputation, IEEEPressSerieson
fuse a high number of sources significantly faster than the ComputationalIntelligence.JohnWiley&Sons,Inc.,1stedi-
original(non-binary)MIMRF.Whentheinputsensorsources tion,2016.
[6] Murong Wang, Xiabi Liu, Yixuan Gao, Xiao Ma, and
tobefusedincreasedtooverten,theMIMRFwithoutBFMs
Nouman Q Soomro, “Superpixel segmentation: A bench-
consistently require more than five hours to train without a
mark,” Signal Process.: Image Communication, vol. 56, pp.
guaranteetoconverge, whereastheMIMRF-BFMcanfinish
28–39,2017.
significantlyfasterduetothereductioninsearchspace.
[7] XiaoxiaoDu, AlinaZare, andDerekTAnderson, “Multiple
instance choquet integral with binary fuzzy measures for re-
motesensingclassifierfusionwithimpreciselabels,” inIEEE
Table 2. Computation time comparison between MIMRF
Symp.Comput.Intell.,2019,pp.1154–1162.
and MIMRF-BFM. Mean(Standard deviation) across 5 runs.
[8] Alina Zare, Paul Gader, Jen Aitken, Ryan Close, Grady
Computationwascappedat5hours.
Tuell, Taylor Glenn, Dmitri Dranishnikov, and Xiaoxiao
ComputationTime(s)
FusionMethod Du, “GatorSense/MUUFLGulfport: Release 01 (Version
#6 #8 #10 #12
v0.1)[Dataset],”https://github.com/GatorSense/
MIMRF 149.5(148.0) 772.1(442.1) >5hrs. >5hrs.
MIMRF-BFM 17.6(1.1) 92.1(5.1) 120.3(5.0) 772.4(15.9) MUUFLGulfport/tree/v0.1, 2018, DOI: https://
doi.org/10.5281/zenodo.1186326.
[9] Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien
5. DISCUSSIONANDCONCLUSIONS Lucchi, Pascal Fua, and Sabine Su¨sstrunk, “Slic superpixels
comparedtostate-of-the-artsuperpixelmethods,”IEEETrans.
ThispaperpresentsMIMRF-BFM,aneffectiveandefficient Pattern Anal. Mach. Intell., vol. 34, no. 11, pp. 2274–2282,
extension to the previously developed MIMRF framework 2012.
thatincorporatesbinaryfuzzymeasures. [10] XiaoxiaoDuandAlinaZare, “Multipleinstancechoquetinte-
TheuseofBFMsdrasticallyreducedthesearchspacedur- gralclassifierfusionandregressionforremotesensingappli-
ing model learning and resulted in significant improvements cations,”IEEETrans.Geosci.RemoteSens.,vol.57,no.5,pp.
2741–2753,2019.
in efficiency, which was particularly useful when scaling up
[11] S. Andrews, “Support vector machines for mulitple-instance
thenumberoffusionsources. Additionally,thelearnedBFM
learning,” inAdvancesinNeuralInfo.Process.Syst.,2002.
measure values provide a clear and explainable representa-
[12] XiaoxiaoDu,AlinaZare,JamesMKeller,andDerekTAnder-
tioncorrespondingtothecombinationand(non-linear)inter-
son, “Multipleinstancechoquetintegralforclassifierfusion,”
actions of the sensor input sources, which allows humans to
inIEEECongr.Evol.Comput.,2016,pp.1054–1061.
interpretandgaininsightsonthefusionprocess. [13] MichelGrabischandChristopheLabreuche,“Bi-capacities–II:
In addition to the HSI and LiDAR fusion task presented thechoquetintegral,” Fuzzysetsandsystems,vol.151,no.2,
in this paper, the proposed MIMRF-BFM can be extended pp.237–259,2005.