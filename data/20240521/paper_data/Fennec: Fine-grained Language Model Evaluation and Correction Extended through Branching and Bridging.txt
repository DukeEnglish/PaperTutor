Fennec: Fine-grained Language Model Evaluation and Correction
Extended through Branching and Bridging
XiaoboLiang1 ∗ HaokeZhang1 ∗ Helanhu2 JuntaoLi1 † JunXu3 MinZhang1
1SoochowUniversity,2PekingUniversity,3BaiduInc.
{xbliang3, zctang}@stu.suda.edu.cn,
{huhelan}@stu.pku.edu.cn,
{xujun03}@baidu.com,
{ljt,minzhang}@suda.edu.cn
Abstract
Therapidadvancementoflargelanguagemod-
elshasgivenrisetoaplethoraofapplications
acrossamyriadofreal-worldtasks,mainlycen-
teredonaligningwithhumanintent. However,
thecomplexitiesinherentinhumanintentne-
cessitateadependenceonlabor-intensiveand
time-consuminghumanevaluation.Toalleviate
thisconstraint,wedelveintotheparadigmof
employingopen-sourcelargelanguagemodels
asevaluators,aligningwiththeprevailingtrend
Figure1: TheillustrationofFennecshowcasesthecon-
of utilizing GPT-4. Particularly, we present
structionofdataformodeltrainingthroughbranching
astep-by-stepevaluationframework: Fennec,
andbridgingforconversationaltaskevaluation.
capableofFine-grainedEvaluatioNandcorrec-
tioNExtendedthroughbranChingandbridg- theuseofLargeLanguageModels(LLMs)inau-
ing. Specifically,thebranchingoperationdis-
tomaticevaluationtechniques(Zhengetal.,2023;
sects the evaluation task into various dimen-
Dubois et al., 2023) has demonstrated improved
sionsandgranularities,therebyalleviatingthe
efficiencyandcontrollability: (i)cost: Alleviating
challenges associated with evaluation. Con-
the requirements for domain experts, thereby fa-
currently,thebridgingoperationamalgamates
diversetrainingdatasets,augmentingthevari- cilitating scale expansion. (ii) criteria: Enabling
etyofevaluationtasks. Inexperimentaltrials, theformulationofpredefinedevaluationcriterion,
our7Bmodelconsistentlyoutperformsopen- reducingtheongoingcostofnegotiation(Markov
source larger-scale evaluation models across et al., 2023). (iii) bias: Mitigating model biases
various widely adopted benchmarks in terms
byrefiningtrainingdata,preventingtheincorpora-
of both Agreement and Consistency, closely
tionofchallenging-to-rectifyhumanbiases(Zheng
approachingthecapabilitiesofGPT-4. Weem-
etal.,2023). Theseadvantagespositionautomated
ploythefine-grainedcorrectioncapabilitiesin-
evaluationtechniquesasanindispensablecompo-
ducedbytheevaluationmodeltorefinemulti-
plemodelresponses,andtheresultsshowthat nentinthefuturelandscapeofconversationtasks.
therefinementelevatesthequalityofresponses, Inthispaper,wefocusontheevaluationofthecon-
leadingtoanimprovementof1-2pointsonthe versationalabilityofanLLMassistant(Baietal.,
MT-Bench. OurcodeisavailableatGithub1.
2022;Zhouetal.,2023),specificallyscenariosin-
volving a human intent query and the response
1 Introduction
providedbyAI.Ourgoalistoevaluatehoweffec-
The inherent complexity of real-world tasks has tively these responses can better understand and
ledtoadeficiencyinimpartialandequitableeval- fulfilltheuser’sauthenticintentandrequirements.
uations among diverse models (Saunders et al., The adoption of GPT-4 (OpenAI, 2023) API
2022;Liangetal.,2022),compellingdependence calls as an evaluation model or utilizing the self-
onevaluationmethodsthatarebotheffectiveand instruct(Wangetal.,2022)dataasatrainingcorpus
efficient. As an alternative to human evaluation, fordevelopingnewevaluationmodelshasbecome
a prevailing methodology. However, such meth-
∗EqualContribution
†CorrespondingAuthor ods often overlook the inherent variations in the
1https://github.com/dropreg/Fennec capabilities of the backbone models. For exam-
4202
yaM
02
]LC.sc[
1v36121.5042:viXraple, smaller LLMs (such as the 7B variants) lack Fennecacrossvariousevaluationtasks,encompass-
the robust commonsense and reasoning abilities ing both pairwise-eval and single-eval, and sce-
presented in their larger counterparts (exceeding nariossuchasAuto-P,PandaLMtestset,andMT-
100B), thereby frequently giving rise to halluci- benchbenchmarks. Theresultsemphasizethesu-
natory outputs and even making erroneous judg- periority of our method over recent endeavors in
ments(Chenetal.,2023). Ourapproachintegrates evaluationmodeling,showcasingcompetitiveper-
a sequential thought methodology, like chain-of- formancecomparabletoGPT-4onsomespecific
thought(Weietal.,2022),enrichingthelanguage datasets. Furthermore, our model excels in refin-
modelwithcontextualinformationtosignificantly ingresponseswithlowscores,leadingtoenhanced
augment the accuracy of its outputs. We employ performanceinMT-Bench. Insummary:
abranchingoperationakintothemethodologies
positedinBranch-Solve-Merge(Sahaetal.,2023), (I) Weproposeastep-by-stepevaluationframe-
as depicted in Figure 1. Concretely, the model workFennecbyincorporatingbranchingand
initiatesthegenerationofmultipleevaluationcri- bridging techniques. This initiative aims to
teria based on the user query. Subsequently, it replacehumanevaluationacrossaspectrum
formulates detailed scoring guidelines for these ofconversationaltaskswithcomplexintents.
criteria. Theevidenceinformationgeneratedfrom
(II) We released a novel open-source training
theseintermediateprocessesissuppliedtotheeval-
dataset and a freely accessible evaluation
uation model to render judgments for given AI
modelfortrainingandinferencewithFennec.
responsesandfurnishcorrespondingelucidations.
The diverse comments generated can be directly
(III) Ourextensiveexperimentsandanalysespro-
fed into the evaluation model to generate correc-
vide fresh insights for future evaluation en-
tionsfortheoriginalresponses. Ourmethodology
deavors, tackling aspects like the establish-
aidsthemodelinexploringabroaderspectrumof
mentoffine-grainedevaluation.
evaluationdimensionsandadaptingtodiversegrad-
inggranularity,therebyenhancingitsadaptability
Thesecontributionspavethewayforthedevel-
acrossvariousscenarios. Toensurereproducibility
opmentofautomatedevaluationtechniquesandthe
andversioncontrol(Kimetal.,2023),weestablish
constructionofprivatemodels.
anewopen-sourcetrainingdatasetandutilizeitto
trainourevaluationmodel.2
2 RelatedWork
The scalability of the model is a crucial capa-
With significant advancements in large lan-
bility for addressing a variety of instructions and
guage models across diverse open-end genera-
conversationaltasks. Whatisespeciallynoteworthy
tion tasks, traditional evaluation metrics such as
is the common limitation where numerous evalu-
BLEU(Papinenietal.,2002),ROUGE(ROUGE,
ation models are exclusively trained on datasets
2004), BERTScore (Zhang et al., 2019), and
withinconsistentdataformats,leadingtopoorscal-
GPTScore(Fuetal.,2023)nolongersufficiently
abilityandevenperformancedegradationonout-
capturethenuancedperformancegapsamongvar-
of-distribution datasets. Therefore, a key aspect
ious models in these tasks. As a result, Chatbot
ofscalingupmodelsistheadoptionofauniform
Arena(Zhengetal.,2023)hasemergedasawidely
dataformatandtheintegrationofmultipledatasets
embraced artificial evaluation platform, utilizing
formodeltraining. Wehavedevelopedabridging
Elo rating to rank different open-source models.
operationtointegrateadditionaldatasetsintoour
In addition to human evaluation methods, API-
training corpus. This involves training a reverse
based approaches, exemplified by GPT-4 (Ope-
model using existing datasets, where criteria and
nAI,2023),havedemonstratedtheabilitytoyield
scoring guidelines are generated from evaluation
judgments closely aligned with those of human
judgments. Thisexpansionofourdatasetenhances
experts. However, these methods are plagued by
generalizationcapabilitieswithoutunderminingthe
prohibitivecosts,uncontrolledversioning,closed-
existingstrengthsoftheevaluationmodel.
sourcenature(Kimetal.,2023),andpotentialrisks
We conduct a comprehensive examination of
of data leakage and performance instability. To
mitigatethesechallenges,initiativessuchasPan-
2Our uploaded anonymous code and dataset will be re-
leasedathttps://anonymous.com. daLM(Wangetal.,2023b),JudgeLM(Zhuetal.,Figure 2: This Figure illustrates Fennec to handle two conversation responses. We systematically define the
dimensionsofevaluationandscoringgranularitytoconstructacontextforthedialogueresponse. Subsequently,we
derivejudgmentsandcorrectionoutcomes. MoredetailedoutputresultscanbereferencedintheAppendixA.2.
2023),Auto-J(Lietal.,2023),etc.,haveendeav- Prometheus(Kimetal.,2023),bothofwhichalso
oredtoleverageopen-sourcemodelsandcollected decomposetheevaluationprocess. However,Saha
evaluationdatatotraindedicatedevaluationmod- et al. (2023) only propose a task decomposition
els. The consistency between these models and methodwithoutaddressingspecificinconsistencies,
humanevaluationsonspecificdatasetscaneither suchasevaluationdimensionsandscales. Kimetal.
matchorsurpassthatachievedbyGPT-4. Ourre- (2023)decomposetheevaluationtaskduringdata
searchmethodologyalignswithmainstreamprac- construction but adopt a one-step inference strat-
tices,primarilyconcentratingonevaluationtasks egy, limiting its evaluation capabilities. Our ap-
thatinvolvemoreuniversalandcomplexconversa- proachtakesintoaccountthestrengthsofprevious
tionaldata. Additionally,certaintask-orientedand methodologies,incorporatingbothbranchreason-
multi-agentevaluationmethods(Jiangetal.,2023b; ingandmulti-stepgeneration. Whatisparticularly
Liuetal.,2023;Chanetal.,2023),owingtotheir noteworthyisitscommitmenttomaintainingcon-
specificity, fall outside the current scope of this sistencybetweentrainingandinference,supporting
work. Nonetheless, it is noteworthy that Fennec variousevaluationscenarios.
cannaturallyadapttothesetasksandscenarios.
3 Approach
Inparticular,Wangetal.(2023b)employedhu-
manannotateddatasettofine-tunelargelanguage WeleveragethedatasetD = {Prompt,X,Y}
train
models, leading to the development of an evalua- fortrainingtheevaluationmodel,whereeachsam-
tionmodel. Lietal.(2023)constructedanevalua- pleconsistsofaspecificPrompt,apairedinputX,
tiondatasetcovering58scenariosthroughheuris- andthecorrelatedoutputY. AsshowninFigure2,
ticfilteringstrategiesandpost-processingmethods we offer a thorough explanation of the branch-
andsubsequentlytraineda13Bevaluationmodel ingoperationwithafocusondatasetconstruction
with it. Zhu et al. (2023) established a training andthebridgingoperationtoconsolidatemultiple
datasetof100kinstancesandfocusedondesigning datasetsusedfortrainingtheevaluationmodel.
various training methods, such as swap augmen-
3.1 Branching
tation, reference support, and reference drop, to
alleviatebiasproblemswithintheevaluationmodel Initially, we utilize GPT-4 model P as a substi-
G4
duringtraining. Worksmostsimilartooursinclude tuteforhumanannotationtogeneratetheaforemen-
Branch-Solve-Merge(BSM)(Sahaetal.,2023)and tioneddatasetD ,whichencompassesfoursub-
traindatasets {D ,D ,D ,D }. is noteworthy that the criteria and scoring guide-
criteria score judge correction
It is noteworthy that our evaluation model, dur- linesprovideexplicitguidanceonscoringconsid-
ingtheinference,willadoptthesameprocedural erations,therebysimplifyingthetaskofpredicting
stepsasthedataconstructionprocess,commonly judgmentsandminimizingerrors.
denotedasbehaviorcloning(Ouyangetal.,2022). We aggregate all the evaluation judgements
Given the paired user query and their corre- Y(cid:98)j =
(cid:80)N
i=1Y
j,i
across all N dimensions to gen-
spondingAIassistantresponsedata{Q ,R }, erate correction suggestion datasets D
user AI correction
we first generate criteria datasets D
criteria
= = {X corr,Y corr,Y(cid:98)j}, which will be employed to
{X ,Y } across multiple evaluation dimensions makefocusedrefinements:
c c
for each query. In this context, the incorporation
ofmultipledimensionsaimstoexpandcandidate
Y
corr
∼ P G4(Y|Prompt corr,X corr,Y(cid:98)j), (4)
space, enabling thorough exploration and facili-
whereX ∈ {(Q ,R )}. EveryAIresponse
corr user AI
tating the identification of more rational evalua-
receivingalowscore(scoresbelow3,asspecified
tion(Sahaetal.,2023). Wespecifythemaximum
in the paper) requires correction to attain a more
dimensionsN tocontrolthecandidatespaces:
objectiveandconstructivereply.
Theaforementionedevaluationprocessencom-
Y ∼ P (Y|Prompt ,X ), (1)
c G4 c c
passes four distinct tasks, and we aggregate all
where X c ∈ {Q user} and Prompt c serve as the thesedataD train tofine-tuneanopen-sourcepre-
languageinstructiontoguidethelanguagemodel trainedLLMP θ throughautoregressivemodeling:
togenerateappropriateoutputs. −→
Y ∼ P (Y|Prompt,X). (5)
The scoring guidelines can serve the purpose θ
of offering a more fine-grained specification for
Followingthetraining,intheevaluationphase,we
diverseresponses,enablingsubtledistinctionsbe-
systematicallyexecutetheaforementionedproce-
tween different responses. It is crucial to finely
durestogenerateevaluationjudgmentsandrefine
design scoring guidelines D = {X ,Y ,Y }
score s c s AIresponses. Allpromptsandspecificdetailsare
tocircumscribethemodel’sdecision:
availableforreferenceintheAppendixA.1.
Y s ∼ P G4(Y|Prompt s,X s,Y c), (2) 3.2 Bridging
Increasingthenumberoftasksandimprovingdata
whereX ∈ {Q }andPrompt guidethemodel
s user s
quality(Weietal.,2021;Chungetal.,2022)has
P togeneratedetailedscoringguidelinesranging
G4
proven effective in guiding LLM toward better
from1to5forthecurrentsample.
alignmentwithexpectedbehaviors. Weelaborate
Based on the established criteria and scoring
ontheintegrationofadditionaldatasetstoexpand
guidelines, the final evaluation judgments D
judge
bothquantityandusagescenarios.
= {X ,Y ,Y ,Y }canbederived:
j j c s
Generally, the majority of existing training
Y ∼ P (Y|Prompt ,X ,Y ,Y ), (3) datasets of evaluation models provide judgment
j G4 j j c s
resultsY butlackcomprehensiveevaluationcrite-
j
where X j ∈ {(Q user,R AI)}. The Prompt j can riaY candscoringguidanceY s. Toaddressthis,we
←−
beclassifiedintotwocategories: single-eval and trainareversemodelP usingthepreviouslycon-
θ
pairwise-eval. Single-evaluation primarily ad- structedevaluationdatasetD . Thismodelwill
train
dresses scenarios where only a singular response generatethemissingconditionsbasedonjudgment
necessitates evaluation. Meanwhile, when faced results:
withscenariosdemandingjudgmentbetweentwo
←−
responses,weoptforthepairwise-evaluation. The Y c ∼ P θ(Y|Prompt rc,X r,Y j),
(6)
←−
distinction between the two manners lies in the
Y ∼ P (Y|Prompt ,X ,Y ,Y ),
s θ rs r c j
fact that pairwise-eval considers two responses,
thereby establishing mutual references that en- whereX ∈ {(Q ,R )}. WeutilizePrompt
r user AI rs
hancetheaccuracyofscoring. Pleasenotethatour and Prompt as instructions to ensure that the
rc
newdatasetisonlyconstructedusingthepairwise- model outputs are correlated with both the dia-
evaluation method and achieves the ability for logue response and the judgment. The new judg-
single-evaluationthroughabridgingoperation. It ment datasets D = {X ,Y ,Y ,Y } can be
judge j j c sincorporated into −→the dataset D train to train the Dataset D criteria D score D judge D correction
evaluationmodelP θ. Toensuretheeffectiveness Auto-J ✗ ✗ ✓ ✗
of the training process, we filter out behaviorally JudgeLM ✗ ✗ ✓ ✗
Prometheus ✓∗ ✓∗ ✓ ✗
inconsistentdata,therebyensuringhighquality.
Thisapproachcanbeextendedtonovelscenar- D Fennec ✓ ✓ ✓ ✓
iosthroughthestandardizationoftaskandprompt
Table1: Thedatasetsusedfortrainingtheevaluation
formats. Forexample,asmentionedearlier,wedo
modelencompassdiversetask-relateddatascenarios. (
notspecificallyconstructtrainingdataforsingle- ✓∗ signifiesthattheoriginalworkdidnotencompass
eval. Instead,weintegratedatasetswithsingle-eval thegenerationoftheseoptionsduringinference.)
capabilitiesthroughabridgingmechanism.
JudgeLM4 comprises100kevaluationsamples,de-
4 Implementation
rived from responses provided by 11 LLMs. We
Inthissection,wepresentadetailedimplementa- filteroutinappropriatesamplesinthedatasetthat
tionofhowtoconstructtrainingdatasetsforevalua- requirehigh-qualityreferenceanswerstoachieve
tionmodels. Specifically,weemploythebranching scores. (3)D : Prometheus5consistsof1k
Prometheus
methodtoconstructD ,subsequentlyutilizing fine-grained score rubrics, 20K instructions, and
Fennec
bridgingtechniquestoestablishD . 100Kresponsesandlanguagefeedbacksgenerated
Fennec-bridging
byGPT-4. Weselectivelysampleaportionofthe
4.1 TrainingDatasetConstruction
datatoincorporateintothetrainingdataset,rather
For the currently available open-source datasets, thanutilizingtheentiretyoftheavailabledata.
therearenodatasetssuitablefortrainingmodelsus- Inthepairwiseevaluation,variationsinthepo-
ingabranchingworkflow,asillustratedinTable1. sitionsoftwodifferentAIresponsesmaylead to
Drawinginspirationfromthelatestrelease,specifi- inconsistenciesinoutputresults. Thisphenomenon
callytheconversationaldataset3 intheAuto-J(Li iscommonlyreferredtoaspositionalbias(Wang
etal.,2023),wehaveleveragedthecapabilitiesof etal.,2023a;Zhengetal.,2023). Toaddressthis
GPT-4 to systematically regenerate data for each concern, we have proactively employed a com-
stagewithintheworkflow,asD . Thisdataset monpractice: usingdataaugmentationtechniques,
Fennec
comprisesatotalof57kinstances,including3,314 specificallybyexchangingtheorderofresponses
entries for the formulation of evaluation criteria during training. Similarly, we will employ this
(N = 5), where additional comprehensive data methodtofilteroutsamplesfromthetrainingdata
statisticaldetailscanbefoundinAppendixA.3. exhibitinginconsistentpredictedresults.
Inrecentopen-sourceevaluationendeavors(Li
4.2 TrainingandInference
et al., 2023; Zhu et al., 2023; Kim et al., 2023),
a prevailing practice is the direct presentation of WeutilizeZephyr-7BChat6 (Tunstalletal.,2023),
judgments,notablylackingassociatedcriteriaand an aligned version of Mistral-7B (Jiang et al.,
scoringguidance. Weemploybridgingtechniques 2023a), as the backbone to train an evaluation
tosystematicallyconstructthesemissinginforma- model. We train our model with three epochs on
tion. (1) D : Auto-J comprises 3,436 paired 8 A100s (40GB). We use a cosine learning rate
Auto-J
training samples, encompassing a range of tasks schedulerwithapeaklearningrateof1e−5and
suchassummarization,examquestions,andcode 10% warmup steps. We train all models with a
analysis,spanning58diversescenarios. Eachsce- global batch size of 512 and use packing with a
nario consists of 100 individual samples. We uti- sequence length of 2,048 tokens. It is notewor-
←−
lizedareversemodelP togeneratespecificcon- thythat,despiteitsdiverseorigins,thedatawithin
θ
ditions for these samples. Considering that judg- D Fennec-bridging has been standardized into a uni-
ments may involve various specifications, the re- formtrainingformat,therebyfacilitatingtheutiliza-
sultingscoringguidancecouldpotentiallyencom- tionoffine-tuningframeworksfortraining. During
passmultipleevaluationcriteria,therebyhighlight-
4https://huggingface.co/datasets/BAAI/
ingthemodel’scapacityforgeneralizationbeyond
JudgeLM-100K
strictadherencetothetrainingdata. (2)D JudgeLM: 5https://huggingface.co/datasets/kaist-ai/
Feedback-Collection
3https://github.com/GAIR-NLP/auto-j/blob/main/ 6https://github.com/huggingface/
data/training/pairwise_traindata.jsonl alignment-handbookAuto-P PandaLM-test MT-Bench
Methods Size Dataset
Agreement↑ Consistency↑ Agreement↑ Consistency↑ Agreement↑ Consistency↑
Open-source/Closed-sourceChatModels
GPT-4 - - 62.28 86.28 60.06 74.67 46.71 67.26
GPT-3.5 - - 42.74 62.43 - - - -
Zephyr 7B - 31.15 57.21 48.42 68.16 31.38 54.98
TrainedEvaluationModels
Zephyr 7B DAuto-J 51.67 82.06 60.26 79.28 52.82 84.19
Zephyr 7B DJudgeLM 46.98 84.48 44.54 85.28 46.35 86.26
PandaLM 7B PandaLM 39.44 66.88 - - - -
JudgeLM 7B JudgeLM 46.96 72.30 58.26 76.08 44.25 68.66
Auto-J 13B Auto-J 54.96 83.41 60.68 78.64 50.41 77.84
Ours
Fennec 7B DFennec 55.80 85.52 70.67 87.89 55.24 86.15
7B DFennec-bridging 57.40 87.00 72.17 89.69 55.65 86.73
Table2: Themainresultsonthreebenchmarks,evaluatedthroughthepairwise-eval,boldednumbersrepresentthe
currentbestresults. (DuetothefrequentformaterrorsinGPT-3.5results,someexperimentsdidnotincludeit.)
inference, we do not adopt a sampling approach sistentlyoutperformsexistingopen-sourceevalu-
for correction; instead, other processes utilized a ation models across multiple benchmarks. This
temperaturesettingof0forresultgeneration. highlightstheefficacyofthebranchingmethodin
improvingamodel’sjudgmentcapabilityoncon-
5 Experiments versationaldata. Furthermore,theFennecnotonly
surpasses Auto-J on the Auto-P dataset but also
5.1 PairwiseEvaluation
maintainsperformanceacrossotherdatasets,em-
Weleveragethreebenchmarkstocomparetheper- phasizingtheeffectivenessofourapproach. Itindi-
formanceofdifferentevaluationmodelsunderthe catesasubstantialimprovementinthemodel’sgen-
pairwiseevaluationsettingbycomparingtwodis- eralizationcapacitythroughmultipledimensional
tinctAIresponsesofdifferentmodels: Auto-P(Li andgranularevaluations. Additionally,theutiliza-
et al., 2023), PandaLM7 (Wang et al., 2023b), tionoftheD datasetfurtherenhances
Fennec-bridging
and MT-bench8 (Zheng et al., 2023) (Due to the modelperformance,substantiatingthescalability
model’sparadigmandcontextualconstraints,our ofthebridgingmethod. Furthermore,wecompared
evaluation specifically focused on the first round theperformanceunderthesamebackbonemodel,
of results). To emphasize the efficacy of our ap- Zephyr, training with different datasets, such as
proach, we have selected recent works as base- training with filtered D and D . The
Auto-J JudgeLM
lines, including PandaLM, JudgeLM (Zhu et al., resultsindicatethatthesebridgingdatasetsdonot
2023),andAuto-J,whichhavebeentrainedusing surpasstheperformanceofFennec. Throughthis
specifictrainingdatasetsforevaluation. Addition- comparison,wenotonlyvalidatetheeffectiveness
ally,weintroduceuntrainedbaselineslikeZephyr, ofourdataconstructionandinferenceapproachbut
alongsiderobustcommercialmodelsGPT-3.5and alsodemonstratethatbridgingcanharmonizethe
GPT-4. Furthermore,weemployConsistencyaf- advantagesofmultipledatasetstofurtherenhance
terexchangingresponseordersandAgreementin theevaluationmodel.
consistentassessmentsaligningwithhumanjudg-
ments as the fundamental metrics for the current 5.2 SingleEvaluation
task. Particularly noteworthy is the fact that the Forsingleevaluation,thetaskinvolvesassigning
agreementmetricdoesnotrepresenttheaccuracy areasonablescoretoanindividualresponsewith-
of all data. Instead, it indicates the accuracy of outrelyingonanyreferences. Whiletheabsence
modelpredictionswhenthereisconsistency. of references may lead to a performance reduc-
AsdepictedinTable2,theresultsdemonstrate tion,therearestillnumerousreal-worldscenarios
thatourmodel,trainedontheD Fennec dataset,con- whereevaluatingindividualresponsesisnecessary.
In these settings, there is a widespread absence
7https://github.com/WeOpenML/PandaLM
of human-annotated evaluation datasets, and the
8https://github.com/lm-sys/FastChat/blob/main/
fastchat/llm_judge/README.md lackofaunifieddomainandgranularityinscoringMethods Auto-P PandaLM-test MT-Bench
Pairwise-Eval
Auto-J 60.28 69.44 58.08
PandaLM - 59.26 -
Fennec 61.84 76.91 60.60
Single-Eval
Prometheus 47.09 45.54 47.89
Fennec 58.15 61.46 58.85
Table3: Theresultsevaluatedthroughsingle-eval,em-
ployingAccuracyastheevaluationmetric.
Models MT-Bench Impr↑
Figure 3: The Figure illustrates the performance of
GPT-4 8.96 -
FenneconAuto-Pwithvaryingbranchnumbers.
WizardLM-30B 7.13 -
LLaMA2-13BChat 7.06 -
LLaMA2-70BChat 6.99 - 5.3 ResponseCorrection
LLaMA2-7BChat 6.26 - To test the model’s performance in response cor-
w/FennecCorrection 7.15 +0.89
rection,weconductedanevaluationandcorrection
Alpaca-13B 4.97 - (ifnecessary)usingtheMT-benchdataset. Incon-
w/FennecCorrection 6.84 +1.87
trast to the aforementioned dataset, this dataset
comprises 160 questions spanning eight distinct
Table 4: The main results on the MT-bench, refined
throughFenneccorrectiontoenhancethechatmodel’s domainsofknowledge(wesolelyutilizedresults
output. (Imprsignifiestheperformanceimprovement.) fromthefirstturn). Specifically,weemployedthe
outputofAlpaca(Taorietal.,2023)andLLaMA2
Chat(Touvronetal.,2023)modelsasthedialogues
makes evaluation challenging. In order to effec- requiringevaluation,andsubsequentlyutilizedFen-
tivelytesttheconsistencybetweenmodeljudgment necforevaluationandcorrection. WeemployGPT-
resultsandhumanbehavior,wecontinuetoemploy 4 to assign scores ranging from 1 to 10 (Zheng
three benchmarks similar to pairwise evaluation et al., 2023) and also include the results of Wiz-
settings. Divergingfrompreviousevaluationmet- ardLM(Xuetal.,2023)forcomparison.
rics,single-evaldoesn’trequireswappingtheorder The results are shown in Table 4, and it is evi-
ofresponses. Hence,weemployAccuracyasthe dentthattheresponsesaftercorrectionexhibitasig-
metrictovalidatethemodel. nificantperformanceimprovement. LLaMA2-7B
Chatachievedanimprovementof0.89points,and
AsshowninTable3,itrevealsasignificantsupe-
Alpaca showed a notable increase of 1.87 points.
riorityofourapproachoverthePrometheus,even
Notably,forthelower-performingLLMassistant,
surpassingcertainreference-basedevaluationmod-
amoresubstantialenhancementisobservedcom-
els like PandaLM. One major reason is that our
paredtostrongermodels. Thisemphasizesthecrit-
methodcanprovideclearerevaluationrules,which
icalroleofourFenneccorrectionstepinachieving
aid in implicit alignment across different evalua-
satisfactory responses, particularly for responses
tions,resultinginmoreaccuratescoring. Simulta-
with lower performance. Moreover, the results
neously,theresultsalsodemonstratethatthebridg-
demonstratethatafterrefinement,themodelperfor-
ing approach can effectively decompose various
manceofLLaMA2-7BChatevensurpassesthatof
evaluation processes, facilitating seamless exten-
LLaMA213Band70BChatmodels,highlighting
siontonewscenarios. Besides,wepresenttheAc-
theeffectivenessofourapproach.
curacyresultsofpairwise-eval,highlightingitsper-
formancesuperiorityoversingle-eval. Suchresults 6 DiscussionsandAnalysis
align with previous research findings: reference
6.1 ExploringtheEffectivenessofBranching
itemsplayapivotalroleinevaluations,indicating
thepreferenceforemployingpairwiseevaluation In this section, we delve into the examination of
inpracticalapplications. the influence of varying branch numbers on per-Auto-P
Backbone
Agreement↑ Consistency↑
LLaMA2-7BChat 44.68 86.67
Mistral-7B 54.49 84.25
Zephyr-7B 55.80 85.52
Table5: Theresultsfordifferentbackbonemodels.
formanceevaluation. AspresentedinTable3,the
results encompass diverse branch numbers, rang-
ing from 1 to 5, on Auto-P (other results refer to
Appendix A.4). The results reveal an ascending
trend in both Agreement and Consistency. How-
Figure4:ValuesandrankingonMT-Bench.(Werescale
ever,incontrast,Accuracydemonstratesminimal
theGPT-4scoresto1-5bymultiplyingwithfactor0.5.)
tonovariation. Foradeeperunderstanding,wecar-
riedoutarecalibrationexperimentonthemodel’s bonemodelswithhuman-likebehavioralcapabili-
performance metrics, excluding samples labeled tiesleadstosignificantimprovementsintheevalu-
as“tie”. Thisanalysisrevealedanimprovementin ationmodels’performance. Thisphenomenonalso
consistencyacrossallmetrics. encouragesustotraintheevaluationmodelinthe
futuretopreferentiallyutilizealignedmodels.
Fromtheobservations,wecanconcludethatthe
branching strategy proven more effective in dis-
6.3 System-levelRanking
tinguishing disparities among various dialogue
responses, enabling the identification of a clear As an evaluation model, a crucial attribute is the
winner rather than settling for a tied judgment. abilitytorankdifferentmodels,especiallyforcom-
Nevertheless,theincreaseinbranchnumbersmay paringtheperformanceofmodelstrainedwithdif-
notauthenticallyreflectchangesinmodelperfor- ferent settings or datasets. We gathered output
mance,particularlyindatasetsabundantwithtied results from diverse open-source LLMs, includ-
samples. Therefore,anevaluationexclusivelyon ingLLaMA2,Dolly(Conoveretal.,2023),Chat-
sampleslabeledas“win/los”becomesessential. It GLM(Zengetal.,2022),Koala(Gengetal.,2023),
isimportanttonotethatinstanceslabeledas“tie” Guanaco (Dettmers et al., 2023), etc. To achieve
representacompromisemadebyhumanannotators the experiment, we utilized single-eval to obtain
encounteringchallengesinidentifyingmoresuit- thefinalscoresandthencomparedtherankingre-
ableevaluationdimensions. Ourapproachadeptly sults with GPT-4. From the results in Figure 4,
addressesthislimitationandisparticularlysuitable it is evident that Fennec aligns well with GPT-4.
foraccuratelydistinguishingresponsesinvarious Thisshowcasesourmodel’scapacitytodiscernsub-
scenarios. This flexibility allows for tailored ad- tleresponsedifferencesthroughmultidimensional
justmentstomitigateitsshortcomings. evaluations,resultinginmoreaccuratejudgments.
Certainly,itisinevitablethatevaluatingsomecom-
6.2 TheImpactofBackboneModel plex data may be challenging. We believe that
thisphenomenoncanbeimprovedbyleveraginga
Toinvestigatehowdifferentbackbonemodelsaf-
largerbackboneandmoreextensivedatasets.
fect evaluation datasets, we utilized the D
Fennec
dataset to train various baseline models. In con-
7 Conclusion
trast to the Zephyr used in previous studies, we
also tested models such as Mistral-7B (Jiang In this work, we present Fennec, a step-by-step
etal.,2023a)(withoutalignmenttothepreference frameworkdesignedforevaluatingconversational
dataset)andtheLLaMA2-7BChatmodel. There- responseusingabranchingmechanism,facilitating
sultspresentedinTable5illustratetheperformance asystematicgenerationofevaluationresults. Addi-
oftheseevaluationmodelsonAuto-P.Thefindings tionally,weintroduceanoveltrainingdatasetand
indicatethatFennec,trainedwithZephyr,outper- an expansion method called bridging to enhance
formsallothermodels. Bycontrastingtheseresults the model’s performance and scalability. Fennec
withMistral,thealignedmodeldemonstratessupe- demonstratesremarkableperformanceandcorrec-
riorperformancecomparedtotheoriginalmodel. tioncapabilitiescomparedtothecurrentstate-of-
Thisemphasizesthenotionthataligningtheback- the-artopen-sourceevaluationmodelsacrossvar-iousbenchmarks. Inthenearfuture,weenvision reinforcementlearningfromhumanfeedback. arXiv
more works exploring the application of branch- preprintarXiv:2204.05862.
ing mechanisms in fine-grained evaluation tasks.
Chi-MinChan,WeizeChen,YushengSu,JianxuanYu,
Consideringitsefficacyindiscerningsubtlediffer-
Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan
ences,webelievethisapproachholdspromisefor Liu.2023. Chateval: Towardsbetterllm-basedeval-
evaluationincomplexconversationalscenarios. uators through multi-agent debate. arXiv preprint
arXiv:2308.07201.
Limitations
AnthonyChen,PanupongPasupat,SameerSingh,Hon-
grae Lee, andKelvinGuu. 2023. Purr: Efficiently
Theneedtoaddresstwocurrentpointsforimprove-
editing language model hallucinations by denois-
mentinourmodelisevident. Firstly, weemploy ing language model corruptions. arXiv preprint
a branching method for evaluation, unavoidably arXiv:2305.14908.
leading to increased inference time. In the cur-
HyungWonChung,LeHou,ShayneLongpre,Barret
rentapproach, there isanabsenceof aneffective
Zoph,YiTay,WilliamFedus,YunxuanLi,Xuezhi
rankingsystemforthecandidatespace,necessitat- Wang,MostafaDehghani,SiddharthaBrahma,etal.
ingtraversaltoidentifysuitableevaluationcriteria. 2022. Scalinginstruction-finetunedlanguagemodels.
Therefore,anexpectedimprovementinvolveseffi- arXivpreprintarXiv:2210.11416.
cientlyrankingthecandidatespacethroughprefer-
Mike Conover, Matt Hayes, Ankit Mathur, Xiangrui
encetraining, aidingintheidentificationofhigh-
Meng, Jianwei Xie, Jun Wan, Ali Ghodsi, Patrick
priorityevaluationcriteriawithinareasonabletime Wendell,andMateiZaharia.2023. Hellodolly: De-
limit. Additionally, another aspect to consider is mocratizingthemagicofchatgptwithopenmodels.
thatthecurrenttrainingdataandscenariosarelim-
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and
ited,allowingevaluationonlyforcontentrelatedto
LukeZettlemoyer.2023. Qlora: Efficientfinetuning
single-turndialoguesandcommonscenarios. Con- ofquantizedllms. arXivpreprintarXiv:2305.14314.
sequently,infuturework,ourgoalistoexpandthe
YannDubois,XuechenLi,RohanTaori,TianyiZhang,
rangeofusagescenarios,encompassingmulti-turn
IshaanGulrajani,JimmyBa,CarlosGuestrin,Percy
dialoguesandknowledge-intensivesituationssuch
Liang, and Tatsunori B Hashimoto. 2023. Al-
asfactverificationandcommon-sensereasoning. pacafarm: A simulation framework for methods
that learn from human feedback. arXiv preprint
EthicsStatement arXiv:2305.14387.
JinlanFu,See-KiongNg,ZhengbaoJiang,andPengfei
Onenotableaspectiswhetherourdatasetincludes
Liu.2023. Gptscore: Evaluateasyoudesire. arXiv
content requiring ethical scrutiny. Issues related
preprintarXiv:2302.04166.
tohallucinatoryoutputsanderroneouscontentare
oftenencounteredinLLMs. However,inthecon- XinyangGeng,ArnavGudibande,HaoLiu,EricWal-
structionofourdataset,werigorouslycontrolled lace,PieterAbbeel,SergeyLevine,andDawnSong.
2023. Koala: A dialogue model for academic re-
thesourcesofdialoguedatarequiredandusedGPT-
search. Blogpost.
4forcontentgeneration. Currently,ChatGPThas
strictcontentmoderation,filteringoutasignificant Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-
portionofinappropriatecontent. However,theuse sch,ChrisBamford,DevendraSinghChaplot,Diego
delasCasas,FlorianBressand,GiannaLengyel,Guil-
ofourmodelforcontentmoderationisstilldebat-
laumeLample,LucileSaulnier,etal.2023a. Mistral
able. Ourmodelisdesignedtoidentifyandcorrect
7b. arXivpreprintarXiv:2310.06825.
inappropriate model outputs, but currently, such
content has not been present in the training data. Dongfu Jiang, Yishan Li, Ge Zhang, Wenhao
Huang, Bill Yuchen Lin, and Wenhu Chen. 2023b.
Of course, we will address this in future work to
Tigerscore: Towards building explainable met-
makebetterjudgmentsaboutadditionalcontent.
ric for all text generation tasks. arXiv preprint
arXiv:2310.00752.
References Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang,
Shayne Longpre, Hwaran Lee, Sangdoo Yun,
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda SeongjinShin,SungdongKim,JamesThorne,etal.
Askell, AnnaChen, NovaDasSarma, DawnDrain, 2023. Prometheus: Inducing fine-grained evalua-
StanislavFort,DeepGanguli,TomHenighan,etal. tioncapabilityinlanguagemodels. arXivpreprint
2022. Trainingahelpfulandharmlessassistantwith arXiv:2310.08491.Junlong Li, Shichao Sun, Weizhe Yuan, Run-Ze Fan, Lewis Tunstall, Edward Beeching, Nathan Lambert,
Hai Zhao, and Pengfei Liu. 2023. Generative Nazneen Rajani, Kashif Rasul, Younes Belkada,
judge for evaluating alignment. arXiv preprint Shengyi Huang, Leandro von Werra, Clémentine
arXiv:2310.05470. Fourrier, Nathan Habib, et al. 2023. Zephyr: Di-
rect distillation of lm alignment. arXiv preprint
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris arXiv:2310.16944.
Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian
Zhang,DeepakNarayanan,YuhuaiWu,AnanyaKu- PeiyiWang,LeiLi,LiangChen,DaweiZhu,Binghuai
mar, et al. 2022. Holistic evaluation of language Lin,YunboCao,QiLiu,TianyuLiu,andZhifangSui.
models. arXivpreprintarXiv:2211.09110. 2023a. Largelanguagemodelsarenotfairevaluators.
arXivpreprintarXiv:2305.17926.
MinqianLiu,YingShen,ZhiyangXu,YixinCao,Eu-
nahCho,VaibhavKumar,RezaGhanadan,andLifu
Yidong Wang, Zhuohao Yu, Zhengran Zeng, Linyi
Huang. 2023. X-eval: Generalizable multi-aspect
Yang, Cunxiang Wang, Hao Chen, Chaoya Jiang,
text evaluation via augmented instruction tuning
Rui Xie, Jindong Wang, Xing Xie, et al. 2023b.
with auxiliary evaluation aspects. arXiv preprint
Pandalm: An automatic evaluation benchmark for
arXiv:2311.08788.
llminstructiontuningoptimization. arXivpreprint
TodorMarkov,ChongZhang,SandhiniAgarwal,Flo- arXiv:2306.05087.
rentine Eloundou Nekoul, Theodore Lee, Steven
Adler,AngelaJiang,andLilianWeng.2023. Aholis- YizhongWang, YeganehKordi, SwaroopMishra, Al-
ticapproachtoundesiredcontentdetectioninthereal isaLiu,NoahASmith,DanielKhashabi,andHan-
world. InProceedingsoftheAAAIConferenceonAr- nanehHajishirzi.2022. Self-instruct: Aligninglan-
tificialIntelligence,volume37,pages15009–15018. guagemodelwithselfgeneratedinstructions. arXiv
preprintarXiv:2212.10560.
OpenAI.2023. Gpt-4technicalreport.
Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,
Guu, Adams Wei Yu, Brian Lester, Nan Du, An-
CarrollWainwright,PamelaMishkin,ChongZhang,
drewMDai,andQuocVLe.2021. Finetunedlan-
SandhiniAgarwal,KatarinaSlama,AlexRay,etal.
guagemodelsarezero-shotlearners. arXivpreprint
2022. Training languagemodelsto followinstruc-
arXiv:2109.01652.
tions with human feedback. Advances in Neural
InformationProcessingSystems,35:27730–27744.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
KishorePapineni,SalimRoukos,ToddWard,andWei-
etal.2022. Chain-of-thoughtpromptingelicitsrea-
JingZhu.2002. Bleu: amethodforautomaticevalu-
soninginlargelanguagemodels. AdvancesinNeural
ationofmachinetranslation. InProceedingsofthe
InformationProcessingSystems,35:24824–24837.
40thannualmeetingoftheAssociationforComputa-
tionalLinguistics,pages311–318.
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,
LinCYROUGE.2004. Apackageforautomaticevalu- PuZhao,JiazhanFeng,ChongyangTao,andDaxin
ationofsummaries. InProceedingsofWorkshopon Jiang. 2023. Wizardlm: Empowering large lan-
TextSummarizationofACL,Spain,volume5. guagemodelstofollowcomplexinstructions. arXiv
preprintarXiv:2304.12244.
Swarnadeep Saha, Omer Levy, Asli Celikyilmaz,
Mohit Bansal, Jason Weston, and Xian Li. Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,
2023. Branch-solve-mergeimproveslargelanguage Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu,
model evaluation and generation. arXiv preprint Wendi Zheng, Xiao Xia, et al. 2022. Glm-130b:
arXiv:2310.15123. Anopenbilingualpre-trainedmodel. arXivpreprint
arXiv:2210.02414.
WilliamSaunders,CatherineYeh,JeffWu,StevenBills,
LongOuyang,JonathanWard,andJanLeike.2022.
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q
Self-critiquingmodelsforassistinghumanevaluators.
Weinberger,andYoavArtzi.2019. Bertscore: Eval-
arXivpreprintarXiv:2206.05802.
uating text generation with bert. arXiv preprint
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
arXiv:1904.09675.
Dubois,XuechenLi,CarlosGuestrin,PercyLiang,
andTatsunoriB.Hashimoto.2023. Stanfordalpaca: LianminZheng,Wei-LinChiang,YingSheng,Siyuan
An instruction-following llama model. https:// Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,
github.com/tatsu-lab/stanford_alpaca. Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023.
Judging llm-as-a-judge with mt-bench and chatbot
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al- arena. arXivpreprintarXiv:2306.05685.
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti ChuntingZhou,PengfeiLiu,PuxinXu,SriniIyer,Jiao
Bhosale, et al. 2023. Llama 2: Open founda- Sun,YuningMao,XuezheMa,AviaEfrat,PingYu,
tion and fine-tuned chat models. arXiv preprint LiliYu,etal.2023. Lima:Lessismoreforalignment.
arXiv:2307.09288. arXivpreprintarXiv:2305.11206.Lianghui Zhu, Xinggang Wang, and Xinlong Wang.
2023. Judgelm: Fine-tuned large language
models are scalable judges. arXiv preprint
arXiv:2310.17631.A Appendix
A.1 ThePromptsofFennec
In Table 7, we initially present the system mes-
sagesfortrainingFennecmodels. Thesemessages
can set specific prompts for each execution step,
aiding the model in generating improved results.
In Table 9, we illustrate the prompts needed for
eachtaskinthebranchingprocess. Theseinstruc-
tions assist the model in generating outputs in a
particular format. Utilizing these specific output
formats helps us extract reply scores more effec-
tivelythroughrule-basedapproaches. InTable8,
wehaverephrasedtheevaluationinstructionsfrom
Figure 5: The Figure illustrates the performance of
previousAuto-JandJudgeLMapproaches,incorpo-
FenneconMT-benchwithvaryingbranchnumbers.
ratingevaluationdimensionsandscoringrules. For
Prometheusdata,weemployedsingle-evaluation
prompts,aspreviouslymentioned.
A.2 TheDetailsofOverview
Inthissection,wepresentthecomprehensiveset
ofdatageneratedthroughoutthedialoguetraining
process. Thisencompasses: 1)Craftingevaluation
criteria,asdelineatedinTable11. 2)Articulating
scoringguidelines,elucidatedinTable11. 3)Gen-
eratingjudgments,explicatedinTables12,13,14,
and15. 4)Creatingcorrectioncontent,asdetailed
in Table 16. This meticulous documentation en-
capsulatesthemultifacetedaspectsinvolvedinthe
trainingprocessandprovidesastructuredoverview Figure6: TheperformanceofFenneconthePandaLM
oftheevaluativecomponentsemployed. testsetwithvaryingbranchnumbers.
D ,andD weresubjecttofiltering
Datasets DataNumber JudgeLM Prometheus
toexpeditethetrainingprocess. Inthiscontext,our
EvaluationCriteria 3,314
primary criterion for filtering out redundant data
ScoringGuidelines 16,493
wastheconsistencyinpredictedscores.
Judgement 32,986
Correction 4,846
A.4 ExploringtheEffectivenessofBranching
D 57,639
Fennec
We present Fennec’s performance, manipulating
D 6,872
Auto-J the branch number on both the PandaLM test set
D 53,548
JudgeLM andMT-bench,asdepictedinFigure5andFigure6.
D 16,730
Prometheus
Remarkably,MT-Benchdemonstratesasignificant
D 134,789
Fennec-bridging 30%occurrenceoftielabels, surpassingthePan-
daLMdataset’smoremodest10%frequency. Insit-
Table6: Thestatisticsoftrainingdatasets.
uationswhere“tie”labelsamplesarelessfrequent
A.3 TheStatisticsofTrainingDatasets in the evaluation dataset, our model significantly
outperformsGPT-4,especiallyinevaluationsthat
The Table 6 presents data statistics of the Fen-
incorporate multiple branches. This supports the
nec training dataset. Considering that GPT-4
claimthatourmodelexcelsinsituationsrequiring
API may deem some queries in the conversa-
discernmentinresponserefinement.
tional data unanswerable, these have been ex-
cluded from the final dataset. Notably, within
the D dataset, data from D ,
Fennec-bridging Auto-JStep Content
Criterion Youareafair,faithful,andhelpfulcontentevaluationassistant.Kindlyassistmeinaccom-
plishingtheassignedtaskbycreatingEvaluationCriteriafortheprovideddialogue.
ScoringGuidelines Youareafair,faithful,andhelpfulcontentevaluationassistant.Kindlyassistmefinalizethe
assignedtaskbydevelopingEvaluationCriteriaintocomprehensiveScoringGuidelines.
Pairwise-eval Youareafair,faithful,andhelpfulcontentevaluationassistant.Kindlyassistmeinfinishing
theassignedtaskbyprovidingPairwiseEvaluationsforthegivendialogue. (Tips: This
entailsevaluatingresponsesthroughthecomparisonoftwodistinctreplies.)
Single-eval Youareafair,faithful,andhelpfulcontentevaluationassistant.Pleaseassistmeincompleting
theassignedtaskbyprovidingSingle-ScoreEvaluationsforthegivendialogue.(Tips:This
involvesassessingindividualresponsesindependently.)
Correction Youareanassistantcapableofassistingincontentmodification.Itisnecessarytocorrect
andrefinethedialoguebasedonUserQueries,Responses,andcorrespondingEvaluation
results.
Table7: SystemmessagesforFennec.
Step Content
Auto-J Givena[UserQuery],pleasescoretheresponsesfromtwoAIassistantsaccordingtothe
[EvaluationCriteria]and[ScoringGuideline].Ensureacomparativeandobjective[Judge
Result]basedontheevaluationcriteriaandscoringguideline,aimingtoidentifydeficiencies
intheresponsecontent.Herearetheinstructionstoassessandcomparethetworesponses:1.
Pinpointthekeyfactorstodistinguishthesetworesponses.2. Concludeyourcomparison
byprovidingafinaldecisiononwhichresponseisbetter,ortheyaretied.Beginyourfinal
decisionstatementwith“So,thefinaldecisionisResponse1/Response2/Tie”. Ensure
thatyourdecisionalignscoherentlywiththecomprehensiveevaluationandcomparison
you’veprovided.***[UserQuery]:query***EvaluationCriteria]:criteria***[ScoringGuide-
line]:scoring***[TheStartofResponse1]:response1[TheEndofResponse1]***[TheStart
ofResponse2]:response2[TheEndofResponse2]***Pleasereturn[JudgeResult]:
JudgeLM Givena[UserQuery],pleasescoretheresponsesfromtwoAIassistantsaccordingtothe
[EvaluationCriteria]and[ScoringGuideline].Ensureacomparativeandobjectiveassess-
mentbasedontheevaluationcriteriaandscoringguideline,aimingtoidentifydeficienciesin
theresponsecontent.Provideafinalscoreof1-10alongwithrelevantexplanations.***[User
Query]:query***[EvaluationCriteria]:criteria***[ScoringGuideline]:scoring***[TheStart
of Assistant 1’s Response]:response1[The End of Assistant 1’s Response]***[The Start
ofAssistant2’sResponse]:response2[TheEndofAssistant2’sResponse]***Pleasereturn
[JudgeResult]:
Table8: BridgingpromptsforFennec.Step Content
Criteria ForevaluatinghumansatisfactionwithresponsesfromanAIassistantbasedona[User
Query],weneedtobrainstormandestablishfive[EvaluationCriteria]directlylinkedtothe
user’squery.Thesecriteriaplayacrucialroleinobjectivelyassessingresponsecontent,with
higherpriorityandgreaterevaluationweight.***Asanillustration:1.Relevance:Evaluate
whethertheresponseisdirectlyrelatedtotheuser’squery.2.Criterion:Assessthecorrectness
oftheinformationprovidedintheresponse.etc.***[UserQuery]:query***Pleasereturnfive
[EvaluationCriteria]:
ScoringGuidelines Consider a [User Query] and [Evaluation Criteria] for evaluating response satisfaction.
Reflectonthesecriteriaandofferacomprehensive[ScoringGuideline]onascaleof1-5
(1represents’Notatallsatisfactory’and5represents’Extremelysatisfactory’). Ensure
that these guidelines are closely tied to both the user query and the assessment criteria,
allowingforapreciseevaluationofpossibleresponsestotheuserquery.Conductadetailed
comparisonofthe[ScoringGuideline]toeaseadherenceandassistindividualsinassigning
reasonablescores.***[UserQuery]:query***[EvaluationCriteria]:criteria***Pleasereturn
detailed[ScoringGuideline]:
Pairwise-eval Given a [User Query], please score the responses (A and B) from two AI assistants ac-
cordingtothe[EvaluationCriteria]and[ScoringGuideline]. Ensureacomparativeand
objectiveassessmentbasedontheevaluationcriteriaandscoringguideline,aimingtoiden-
tifydeficienciesintheresponsecontent. Provideafinalscoreof1-5alongwithrelevant
explanations.***[User Query]:query***[Evaluation Criteria]:criteria***[Scoring Guide-
line]:scoring***[The Start of Response A]:response1[The End of Response A]***[The
StartofResponseB]:response2[TheEndofResponseB]***Pleasereturn[JudgeResult]
asfollows:ResponseAScore: 3Explanation: ExplanationofthescorefortheResponse
A.ResponseBScore:3Explanation:ExplanationofthescorefortheResponseB.Comparison:
ThecomparisonoftheResponseAandResponseB.[JudgeResult]:
Single-eval Givena[UserQuery],pleasescoretheresponsesfromAIassistantsaccordingtothe[Eval-
uationCriteria]and[ScoringGuideline]. Ensureacomparativeandobjectiveassessment
basedontheevaluationcriteriaandscoringguideline, aimingtoidentifydeficienciesin
theresponsecontent.***[UserQuery]:query***[EvaluationCriteria]:criteria***[Scoring
Guideline]:scoring***[TheStartofResponse]:response[TheEndofResponse]***Assigna
scoreasanintegerbetween1and5.Provideadetailed[JudgeResult]strictlybasedonthe
givenScoringGuideline,refrainingfromageneralevaluation.Pleasereturn[JudgeResult]
asfollows:ResponseScore:3Explanation:ExplanationofthescorefortheResponse.Please
return[JudgeResult]:
Correction Providedwitha[UserQuery],theAIassistant’s[OriginalResponse],andacomprehensive
objective evaluation of the response, please attend to the identified shortcomings in the
originalresponseaccordingtothe[JudgeResult].Makecertainthatthemodifiedresponse
remainsobjective,non-harmful,andconstructiveinaddressingtheuser’squeryintent,while
alsoaligningwithhumanbehavioralnorms.***[UserQuery]:query***[TheStartofOriginal
Response]:response[TheEndofOriginalResponse]***[TheStartofJudgeResult]:judge[The
EndofJudgeResult].Kindlyreturnonefinal[ModifiedResponse]foruserquerydirectly
withoutadditionalinformation.Pleasereturn[ModifiedResponse]:
Table9: EvaluationpromptsforFennec.Data Content
UserQuery Pleasesummarizetheplotofthebook,TheGreatGatsby.
AIResponseA Hereisasummary:TheGreatGatsbybyF.ScottFitzgeraldwasafamousAmericannovelist,
widelyknownforhisnovelsexploringtheU.S.middleclass.Hewasparticularlyknownfor
hispowerfuldepictionsoffamilialconflict,andforhisuseoflotsofdramaticlanguagewith
lotsofmemorabledetail.
AIResponseB TheGreatGatsbytellsthestoryofJayGatsby,anenigmaticmillionairewholongstoreunite
withDaisyBuchanan,aformerloveofhiswhoisnowmarriedtoTomBuchanan.Gatsby
throwslavishpartiesinthehopesofattractingDaisy’sattentionandreclaimingherheart,
ultimatelyleadingtohistragicdownfall.Throughoutthestory,Gatsby’sstoryofloveand
lossiscontrastedwiththehollownessandfalsevaluesofthewealthyandpowerfulpeople
thatsurroundhim.Intheend,GatsbyisbetrayedbybothDaisyandTomandloseshislife
chasinghisimpossibledreamofaperfectlove.
Table10: TheexhibitedconversationaldatacomprisesuserqueryandresponsesgeneratedbytwoselectedAI.
Data Content
Criteria Accuracy: Evaluatesiftheresponsecorrectlysummarizesthekeyeventsandcharacter
developmentsinthebook,TheGreatGatsby.
Scoring 1. Notatallsatisfactory: Theresponseincludesincorrectornoinformationaboutthe
Guidelines plotofTheGreatGatsby.Majoreventsandcharacterdevelopmentsaremisunderstoodor
unmentioned.
2.Slightlysatisfactory:Theresponseincludessomeaccurateinformationabouttheplot
andcharactersofTheGreatGatsby,butsignificantelementsareomittedormisrepresented.
Theexplanationmaylackcohesionorbedifficulttofollow.
3.Fairlysatisfactory:Theresponseaccuratelysummarizesthemainplotandprovidessome
detailsaboutcharacterdevelopmentsinTheGreatGatsbybutlacksemphasisonkeyevents.
Notallmajorpointsaretouchedupon,ortheexplanationlacksthoroughnessorclarity.
4. Verysatisfactory: Theresponseaccuratelyincludesmostofthemainplotpointsand
characterdevelopmentsinTheGreatGatsby,demonstratingagoodunderstandingofthe
novel.Someminorelementsmaybemissing,ortheexplanationmayhavesmallinaccuracies.
5.ExtremelySatisfactory:Theresponseisacomprehensive,clear,andprecisesummaryof
theplotofTheGreatGatsby,capturingallmajoreventsandsignificantcharacterdevelop-
ments.Itreflectsadeepunderstandingandthoroughreadingofthenovel.
InSummary:1Majorinaccuraciesandomissionsarepresent.2Somecorrectinformation,
butmanykeypointsaremissedorinaccurate.3Goodsummary,althoughsomekeyeventsor
characterdevelopmentsmaybemissing.4Nearlycompletesummarywithminoromissions
orslightinaccuracies.5Full,comprehensivesummarywithperfectaccuracy.
Judgement ResponseAScore:1
Explanation: Response A does not meet the criteria of the evaluation as it consists of
incorrectinformationanddoesnotincludeanydetailsaboutthebook’splotorcharacters.
TheexplanationgivenismoreaboutF.ScottFitzgerald,whoistheauthorofthebookand
nottheactualcontentofthebook.Thedetailsprovidedareincorrectandirrelevant.
ResponseBScore:4
Explanation:ResponseBprovidesafairlyaccuratesummaryofthekeyeventsandchar-
actersinTheGreatGatsby. Itdiscussedthemaincharacter,JayGatsby,hisloveinterest
Daisy,herhusbandTomBuchanan,andtheconsequencesGatsbyfacesduetohisunrequited
loveforDaisy.TheAIcouldhaveincludedmorecontextanddetailaboutthethemeofthe
AmericanDreamandthetimeperiodtosecureascoreof5.
Comparison:ResponseBismuchmorecompetent,providingaconcretesummaryofThe
Great Gatsby with a few minor details missing, while Response A includes no relevant
informationaboutthebook’splotorcharacters.
Table11: Thescoringguidelinesandjudgmentforthe“Accuracy”evaluationcriterion.Data Content
Criteria Comprehensiveness:Assessesiftheresponseencapsulatesallimportantelementsin
thebook,includingthemes,plotlines,andcrucialcharacters.
Scoring 1. Not at all satisfactory: Not at all satisfactory: The response has either not
Guidelines answeredthequeryoronlymentionedthenameofthebookwithoutanyfurtherdetails
aboutitsplot,themes,orimportantcharacters.
2. Slightlysatisfactory: Theresponseaddressesonlyapartoftheuserquery,for
instance,highlightsoneortwomaineventsintheplotormentionsonemaincharacter,
leavingoutothersignificantelementsofthestory.
3. Fairlysatisfactory: Theresponseprovidesasynopsisoftheplotandidentifies
majorcharactersbutlacksdepthsuchasnuancesinthestoryline,interconnectedness
ofcharacters,oromissionofcrucialthemesthatthebookalsoaddresses.
4. Verysatisfactory: Theresponseprovidesacomprehensivesummaryoftheplot,
identifiesalltheessentialcharacters,includingtheircontributiontotheplot,butonly
brieflytouchesuponthethematicelementsinthebookortheirinterpretations.
5.ExtremelySatisfactory:Theresponseprovidesathoroughsummaryoftheplot,
identifiesallkeycharactersandexplainstheirroleinthestory,anddiscussesmajor
themesinthebookliketheAmericanDream,wealth,andsocialstratification.Italso
interpretshowthesethemesplayoutagainstthebackdropofthe1920’sAmerican
society,acoreelementin“TheGreatGatsby”. Theresponseprovidesanin-depth
understandingofthetextandstimulatesfurtherthinking.
InSummary:Incomparingtheseguidelines,itiscrucialtorememberthatascore
ofonemeansthattheresponseisinadequateandfailstosatisfytheuser’squery.In
contrast,ascoreoffivemeansthattheresponseisrobustandoffersacomprehensive
understandingofthebook,meetingalltheuser’sexpectations.Intermediatescores
between 2 to 4 progressively signify the extent of completeness and detail in the
response.
Judgement ResponseAScore:1
Explanation: ResponseAfailedtoprovideasatisfactorysummaryof“TheGreat
Gatsby.” There’sonlyageneralbackgroundabouttheauthorbutnospecificinfor-
mationrelatedtotheplot,characters,orthemesofthebook,whichistheprimary
requirementoftheuser’squery.Thisresponsedoesn’tmeetthenecessarycriteriafor
comprehensiveness,asitdoesnotencapsulateanyimportantelementsofthebook.
ResponseBScore:3
Explanation: Response B mildly satisfies the query. It has summarized the plot
and mentioned the lead characters, i.e., Jay Gatsby, Daisy Buchanan, and Tom
Buchanan.However,theresponsedoesn’tdelvedeeperintothenuancesoftheplotline,
interconnectednessofcharacters,andfailstomentionthesignificantthemesofthe
story.Thesummaryisgoodbutlacksdepthandcomplexity.
Comparison: ResponseBissuperiortoResponseAasitprovidesspecificdetails
abouttheplotandcharactersof“TheGreatGatsby,”partiallysatisfyingtheuser’s
query.Ontheotherhand,ResponseAdidnotprovideanyimportantdetailsaboutthe
bookasidefromagenericreferencetotheauthor’sotherworks.Therefore,interms
ofcomprehensiveness,ResponseBclearlyoutmatchesResponseA.
Table12: Thescoringguidelinesandjudgmentforthe“Comprehensiveness”evaluationcriterion.Data Content
Criteria Coherence:Evaluateswhethertheresponseislogicallystructured,ensuringthatthe
storylinesummarizationflowssensiblyfromthebeginningtotheend.
Scoring 1.Notatallsatisfactory:ThesummarydoesnotreflecttheplotofTheGreatGatsby.
Guidelines Theresponseisscatteredandlackslogicalprogression.There’snoconnectionstated
betweenthebeginning,middle,andendofthestoryandit’sunclearwhathappensin
thebookbasedontheresponse.
2.Slightlysatisfactory:ThesummaryminimallyreflectstheplotofTheGreatGatsby,
butsignificantdetailsaremissingormisrepresented.Theresponseshowsanattempt
atlogicalprogression,butisnotsuccessful,andmightjumparoundchronologically
withinthestoryline.
3. Moderatelysatisfactory: ThesummaryrepresentsthemainplotofTheGreat
Gatsbyinapartiallyclearandcoherentway.Majorplotpointsarecapturedandthe
storylineshowssomediscernableorganization,butminordetailsmaybeoverlooked
ormisrepresented.Theremayexistgapsinchronologicalprogression.
4. Verysatisfactory: ThesummaryclearlyrepresentsthemainplotofTheGreat
Gatsbyandmostkeyeventsarecapturedaccurately.Thestorylinelogicallyprogresses
fromthebeginningtoend,althoughminordetailsmaystillbeoverlookedorslightly
misrepresented.
5.ExtremelySatisfactory:Thesummaryaccuratelyandconciselyencompassesthe
entireplotofTheGreatGatsby.Itisdetailedandthorough,capturingallkeyevents
fromthebeginningtotheendinalogicallycoherentfashion. Nomajororminor
detailsareoverlooked,andtheresponsereflectsaclearandcompleteunderstanding
ofthebook.
In Summary: the scoring increases from 1 to 5, the summary provided becomes
morethorough,accurate,andlogicallystructured. Atlowerscores,therearelarge
gaps within the summary, misrepresentations of important details, and poor flow,
whereasathigherscorestheresponseaccuratelyrepresentseveryaspectoftheplotin
averydetailed,thorough,andlogicalmanner.Ascoreof1wouldindicatealackof
understandingofthestory,whileascoreof5wouldreflectacompleteunderstanding
andperfectrepresentationoftheplot.
Judgement ResponseAScore:1
Explanation:ResponseAdoesnotsummarizetheplotofTheGreatGatsbyatall.It
onlyprovidesageneralcommentontheauthor’sbodyofwork,ratherthanfocusing
on the plot of the requested book. It completely fails to mention any storyline or
characterinthenovel,thusnotprovidinganyformofsummarization,resultinginthe
lowestscoreaspertheScoringGuideline.
ResponseBScore:4
Explanation:ResponseBprovidesanaccurateoverviewofthemainplotofTheGreat
Gatsby.Itcoversthecentralcharacter,JayGatsby,hislongingforDaisyBuchanan,
thepartieshethrows,andhistragicdownfall.However,itfailstomentionsomeminor
butvitaldetailssuchastheroleofthenarrator,NickCarraway,andthedichotomy
betweenEastEggandWestEgg.Therefore,thoughverysatisfactory,thescorecannot
reachthehighestrankduetoslightlymisseddetails.
Comparison:Comparatively,ResponseBprovidesaclear,logicallystructuredplot
summaryofTheGreatGatsby,butResponseAdoesnotaddresstheuserqueryat
all. ResponseBshowsunderstandingandknowledgeofthebook,lackingabitin
detail.Ontheotherhand,ResponseAdoesnotreflectanyunderstandingofthebook,
resultinginalowerscore.
Table13: Thescoringguidelinesandjudgmentforthe“Coherence”evaluationcriterion.Data Content
Criteria Contextuality:Assesseswhethertheresponsereflectsthecontextualbackgroundof
thebook,suchasthesocialandculturalsettinginwhichthestoryisset.
Scoring 1. Notatallsatisfactory: Responsesunderthiscategorybarelyaddresstheuser
Guidelines query. They do not provide an accurate or any summary of “The Great Gatsby”.
Anymentionofthesocial,cultural,orgeographiccontextinwhichthestoryissetis
incorrectorcompletelymissing.
2.Notverysatisfactory:Theseresponsesdoprovideasummaryofthebook,however,
theyareladenwithinaccuraciesormissingkeypointsfromthenovel’splot. They
haveaslightmentionofthesocialandculturalsettingofthebook,butthereferences
addedareincorrect,vague,ortangential.
3.Moderatelysatisfactory:Responsesfallingunderthiscategoryattempttoprovide
anaccuratesummaryof“TheGreatGatsby”.Theymayhaveminorinaccuracies,but
overall,thekeyelementsoftheplotareincluded.Theyalsotouchuponthecontextual
background of the book but may fail to provide a detailed view of the social and
culturalatmospherepertinenttothestoryline.
4.Verysatisfactory:Theseresponsesdeliveranaccurateandcomprehensivesum-
mary of “The Great Gatsby”, identifying crucial plot points. The responses also
includeacleardiscussionofthesocialandculturalsetting,indicatinganunderstand-
ingoftheimpactofthesefactorsonthenarrative;however,moredepthorprecision
mayberequired.
5. Extremely Satisfactory: Responses in this category not only provide a very
accurate, detailed, and comprehensive summary of “The Great Gatsby” but also
successfullyweaveinarichunderstandingofthesocialandculturalsetting.These
responsesdemonstratehowthecontextualatmosphereoftheRoaringTwentiescon-
tributestothecharacters’motivations,decisions,andtheplot’sprogression.
InSummary:Oneshouldconsidertheseguidelinesfluidratherthanstrictlydichoto-
mous. Responsesmightalsodisplaycharacteristicsfromadjacentcategoriesand
shouldberatedaccordingtotheevaluator’sbestjudgment.
Judgement ResponseAScore:1
Explanation:ResponseAdoesnotprovideasummaryof“TheGreatGatsby”.Itonly
mentionstheauthorandvaguelydiscusseshisstyle,missingtheuserqueryaltogether
whichaskedforasummaryoftheplot. Ithasnomentionofthesocial,cultural,or
geographiccontextinwhichthestoryisset.TheratingthusfallsundertheScore1
categoryofthescoringguideline.
ResponseBScore:4
Explanation: Response B provides a coherent summary of “The Great Gatsby”,
identifyingkeyplotpointssuchasGatsby’slongingforDaisy,hisextravagantparties,
andhistragicend. Furthermore,italsohintsatthesocialandculturalsettingof
thenovelbymentioningthe’wealthyandpowerful’peopleandtheir’falsevalues.’
However,itcouldhaveexploredthecontextualsetting,suchastheRoaringTwenties,
inmoredepthtoscorehigher. Therefore,itfallsundertheScore4categoryofthe
scoringguideline.
Comparison:ResponseBsuperiorlyaddressestheuserquerycomparedtoResponse
A,providingnotonlyanaccuratesummaryofthebookbutalsoreflecting,toacertain
degree,thesocialandculturalsettingofthestory. ResponseA,ontheotherhand,
doesn’tevenaddresstheuser’squeryaboutsummarizingthebook’splot.
Table14: Thescoringguidelinesandjudgmentforthe“Contextuality”evaluationcriterion.Data Content
Criteria Conciseness: Evaluatesiftheresponseissuccinctyetcomprehensive,providinga
completesummarywithoutunnecessarydigressionorredundancy.
Scoring 1. Notatallsatisfactory: Theresponsedoesn’tsummarizetheplotof’TheGreat
Guidelines Gatsby’oritincludeswrongdetails. Itramblesordigressessignificantlyfromthe
mainrequest,orisoverlyverbosewithoutprovidingsufficientdetailaboutthestory.
2. Notverysatisfactory: Theresponsegivesavagueorpartialplotofthebook.
There’ssomedigressionorredundancy,butsomekeyelementsofthestoryaremen-
tioned.Someunnecessarydetailsmakethesummarylessconcise.
3.Moderatelysatisfactory:Theresponsesummarizesthemainplotof’TheGreat
Gatsby’, but it might miss some important details or contain some unnecessary
information.There’sabalancebetweenconcisenessandcomprehensiveness.
4.Verysatisfactory:Theresponseisfairlyconciseyetcomprehensive.Itmanages
tosummarizethemainplotof’TheGreatGatsby’withoutmuchdigression.Itmight
missminordetailsoraddabitofextrainformation,butoverallitmaintainsgood
balancebetweenbrevityandthoroughness.
5.ExtremelySatisfactory:Theresponseperfectlysummarizes’TheGreatGatsby’.
It’sconcise,stickingtotheimportantdetailsonly,yetcomprehensive,coveringallkey
aspectsoftheplot.Itdoesn’tincludeanyunnecessaryinformationordigressfromthe
query,achievingaperfectbalanceofconcisenessandcomprehensiveness.
InSummary:Thisscoringguidelineservesasastandardwhenevaluatingresponses,
makingsuretheycatertotheuserquerywhileadheringtothechosenevaluation
criteria, i.e., conciseness and comprehensiveness in this case. Comparatively, a
responsescoring1or2onthisscalewouldneedsignificantimprovement,whilea
responsescoring3demonstratesaverageadherence.Ascoreof4indicatesthatthe
response was strong, whereas a score of 5 should be reserved for responses that
exemplifyanidealbalancebetweenconcisenessandcomprehensiveness.
Judgement ResponseAScore:1
Explanation: ResponseAdoesn’tprovideastrongandconcisesummaryof’The
GreatGatsby’.Itdoesnotadheretouser’srequestofsummarizingtheplot.Rather,it
digressesintotalkingabouttheauthor,whichisirrelevant.Thestoryofthebookitself
isnotexplainedatall,whichisacleardeviationfromtheuserquery.Hence,falling
intothefirstcategoryofourscoringguideline.
ResponseBScore:5
Explanation:ResponseBmanagestobalanceconcisenessandcomprehensiveness
perfectly,asdefinedincategoryfiveofthescoringguidelines. Itdiscussesthekey
elementsoftheplotof’TheGreatGatsby’succinctly.Ittalksabouttheprotagonist,
hisloveinterest,aswellasthematicelementsofthebooklikefalsevaluesoftherich
andGatsby’stragicend,withoutunnecessaryinformationordigression.
Comparison:Thecomparisonofthesetworesponseshighlightsthedeficienciesin
ResponseA.Itdoesn’taddresstheuserqueryatall,whereasResponseBnotonly
answersthequerybutdoessoinasuccinctandcomprehensivemanner,strikinga
perfectbalancebetweenbeingbriefyetdetailed. Therefore,ResponseBshouldbe
consideredastheidealresponse.
Table15: Thescoringguidelinesandjudgmentforthe“Conciseness”evaluationcriterion.Data Content
ResponseACorrection “TheGreatGatsby”byF.ScottFitzgeraldissetintheRoaringTwentiesandrevolvesaround
thewealthyandmysteriousJayGatsby,whoisknownforhislavishparties. Thenovelis
narratedbyNickCarraway, Gatsby’sneighbor, whorecountshisobservationsaboutthe
lifestyleinLongIsland’sWestEggneighborhood. Theplotthickensasitisrevealedthat
GatsbyisardentlyinlovewithDaisyBuchanan,whoismarriedtotheaffluentandarrogant
TomBuchanan. Gatsby’selaborateattemptstowinDaisy’sloveultimatelyleadtotragic
consequences. ThestoryisasharpcritiqueoftheAmericanDream,exploringthemesof
wealth,socialstatus,love,anddisillusionment.
ResponseBCorrection TheGreatGatsbyisarivetingtaleofJayGatsby,amysteriousmillionaire,piningforhis
formerlover,DaisyBuchanan.However,DaisyisnowmarriedtoTomBuchanan.Hoping
toattractDaisy,Gatsbyorganizesextravagantparties,whichemphasizestheextravagance
andemptinessofthewealthyelite.ThenarrativedelvesintoGatsby’srelentlesspursuitof
hisromanticideals,onlytobemetwithtragicrepercussions.Moreso,Gatsby’sinfatuation
withDaisyalsosymbolizeshispursuitoftheAmericanDream,acriticalthemeinthebook.
ThestoryhighlightshowhisquestforloveintertwineswithDaisyandTom’s,leadingtoa
tragicclimaxwhereGatsbyisletdownbythosehetrusted.Thenarrativecommentsonthe
hollownessofhighsocietyandexploresthemessuchaswealth,love,andillusion,makingit
apoignantcritiqueoftheAmericanDream.
Table16: ResultsofAIresponsescorrectionfollowingthepreviousevaluationfeedback.