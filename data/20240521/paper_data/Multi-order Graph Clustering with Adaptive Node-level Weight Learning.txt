Multi-order Graph Clustering with Adaptive Node-level
Weight Learning
Ye Liua,∗, Xuelei Linb, Yejia Chena, Reynold Chengc
aSchool of Future Technology, South China University of Technology, Guangzhou, China
bSchool of Science, Harbin Institute of Technology, Shenzhen, China
cDepartment of Computer Science, The University of Hong Kong, Hong Kong, China
Abstract
Current graph clustering methods emphasize individual node and edge con-
nections, while ignoring higher-order organization at the level of motif. Re-
cently,higher-ordergraphclusteringapproacheshavebeendesignedbymotif-
based hypergraphs. However, these approaches often suffer from hypergraph
fragmentation issue seriously, which degrades the clustering performance
greatly. Moreover, real-world graphs usually contain diverse motifs, with
nodes participating in multiple motifs. A key challenge is how to achieve
precise clustering results by integrating information from multiple motifs at
thenodelevel. Inthispaper,weproposeamulti-ordergraphclusteringmodel
(MOGC) to integrate multiple higher-order structures and edge connections
at node level. MOGC employs an adaptive weight learning mechanism to au-
tomatically adjust the contributions of different motifs for each node. This
not only tackles hypergraph fragmentation issue but enhances clustering ac-
∗Corresponding author
Email addresses: yliu03@scut.edu.cn (Ye Liu ), linxuelei@hit.edu.cn (Xuelei
Lin), 202221062461@mail.scut.edu.cn (Yejia Chen), ckcheng@cs.hku.hk (Reynold
Cheng)
Preprint submitted to Pattern Recognition May 21, 2024
4202
yaM
02
]GL.sc[
1v38121.5042:viXracuracy. MOGC is efficiently solved by an alternating minimization algo-
rithm. Experiments on seven real-world datasets illustrate the effectiveness
of MOGC.
Keywords: Graph clustering, Motifs, Higher-order structure, Spectral
clustering, Optimization
1. Introduction
Nowadays, manycomplexinteractionsystemcanbenaturallyrepresented
as graphs or networks, in which nodes refer to objects to be interested and
edges representing the relationship among objects. Graph clustering which
is one of the fundamental tasks in graph mining, aims to partition the graph
into several densely connected groups with tight internal connections and
sparse external connections. Graph clustering has been widely applied in
many applications, such as social network, and computer vision.
Although many graph clustering methods have been proposed [1], most
of them focus on the lower-order structure at the level of individual nodes
and edges, and ignore the higher-order structure in the network. An impor-
tant higher-order structure is network motif, which is defined as the building
block of networks. Recently, some motif-based higher-order graph cluster-
ing methods [2][3][4] have been proposed, they often perform clustering on a
motif-based hypergraph constructed by utilizing the co-occurence informa-
tion of two nodes in one motif instance. Motif characterizes higher-order
network structures to provide new insights into the organization of complex
systems beyond the clustering of nodes based on edges [4]. However, previ-
ous higher-order clustering methods assume that the motif-based hypergraph
2is a connected graph, which is not hold in some real-world networks. The
motif-based hypergraph usually become fragmented, in which the original
connected graph may be fragmented into a large number of connected com-
ponents and isolated nodes. Then in the process of clustering nodes, these
isolated nodes will not be supported by original network, which makes the
class label of isolated nodes present randomness. Only a few works [5][6] aim
to address the challenges of hypergraph fragmentations, these works all focus
on one kind of motif and utilize edges to solve the fragmentation issue.
However, a large real-world network often consists of many motifs with
various functional roles, and different organizational patterns (clustering re-
sults) would be revealed with different types of motifs. For example, some
3-node motifs and 4-node motifs are found to play different funcitonal roles
in biological systems [4]. Moreover, a node is likely to involved in more than
one type of network motif, and the importance of different types of motifs for
a node varies from node to node in real world [7]. Therefore, different motifs
and sample nodes potentially offer unique contribution to the graph cluster-
ing task. For example, in Fig. 1, blue nodes are closely connected with larger
weights based on triangle motif, while another six nodes are isolated. Based
on 4-node motif, red nodes are well connected with larger weights, while
others are isolated from red nodes. It is obvious that triangle motif based
hypergraph could provide more connectivity information for blue nodes, 4-
node motif based hypergraphs are useful to identify the cluster of red nodes,
different motifs contribute differently for each node in the identification of
communities. Itshouldbenotedthatthesedifferencescouldbenodespecific.
For example, the isolated node #11 becomes outlier in triangle motif based
3hypergraph and 4-node motif based hypergraph, edge-based graph is more
informative to the partition of node #11. For the convenience of description,
original edge-based graph is regarded as a kind of motif-based hypergraph in
this paper. Thus, in order to achieve accurate clustering result, a more effec-
tive approach is to establish a flexible framework in which a weight for each
motif of each node can be assigned and adjusted adaptively in the clustering
process.
To tackle the above mentioned problems, we propose a framework to in-
tegrate multiple higher-order structures (motifs) and lower-order structure
with a independent weighting scaler assigned to each motif for each node.
The formulated optimization model is composed of two parts, the first term
exploits the underlying cluster structure from the integrated hypergraph by
evaluating the contribution of each motif to each vertex. Another term is
regularization term of motif weight to each vertex, such that irrelevant hy-
pergraph would be removed in the clustering process. The proposed opti-
mization problem can be solved by alternating scheme, it is decomposed into
two subproblems which can be analytically solved respectively. Extensive
experiments are conducted on seven datasets, comparison results with exist-
ing methods illustrate the effectiveness of the proposed method. The code of
MOGC is released in the link1.
1https://github.com/SCUTFT-ML/MOGC
4Figure 1: Illustration of fragmentation issue and different motif’s contributions to the
graph clustering task: (a) Original network is fragmented into one connected component
(blue nodes) and six isolated nodes (red nodes and green node) based on 3-node motif.
(b) Original network is fragmented into one connected component (red nodes) and six
isolated nodes (blue nodes and green node) based on 4-node motif. Original network
contains edges with weight 1, numbers on edges demonstrate the edge weight in 3-node
motif based hypergraph and 4-node motif based hypergraph, the corresponding motif
adjacency matrix is shown in the third column.
2. Related Work
2.1. Lower-order Graph Clustering
Lower-order graph clustering finds the partition of vertices by utilizing
the lower-order connectivity patterns of the graph at the level of nodes and
edges. For undirected graph clustering, widely used methods concentrate
on spectral clustering [1], random walk [8], matrix factorization [9], label
propagation [10], affinity propagation [11], louvain method [12] and deep
learning based methods [13]. For example, Nonnegative matrix factorization
(NMF) [9] factorizes the node adjacency matrix into a basis matrix and a
indicator matrix, indicator matrix is the data representation with clustering
information. Affinity propogation [11] seeks cluster of nodes by similarities
between pairs of nodes. The Louvain method [12] is a greedy optimization of
5modularity, which measures the relative density of edges inside communities
with respect to edges outside communities. Spectral clustering [1] utilizes
the eigenvector of graph laplacian matrix to calculate the structure pattern,
which is based on graph cut criteria, inculding ratio cut [14] and normalized
cut [15]. Thus, the main focus of this paper is graph cut criteria based
method.
Notation Description
G;V;E Undirected graph;vertice set; edge set
n;m;K The number of nodes; the number of motifs;the number of clusters
A;D;L Adjacency matrix;degree matrix; laplacian matrix of edge based graph
Bˆ;p Adjacency matrix of bidirectional links; the number of nodes in motif
B;A Binary matrix; the set of indices of the anchor nodes in motif.
Mq,Mq(B,A) Motif set
p p
A Mpq;D Mpq;L Mpq Motif adjacency matrix; motif degree matrix; motif laplacian matrix.
W Mpq Indicator matrix of isolated nodes based on motif M pq.
Λ;Λ˜ importance weight of motifs to nodes; the eigenvalue matrix
A Adjacency matrix with both higher-order and lower-order structures
f
D ;L Degree matrix; laplacian matrix of A
f f f
θ ,θ ; α Lagragian multiplier parameters; trade-off parameter
1 2
Table 1: Summary of notations, different notations are separated by a semicolon (;).
2.2. Motif-based Graph Clustering
Many motif-based graph clustering methods have been proposed. For
example, a generalized higher-order graph clustering [4] is proposed by ex-
tending conductance metric in traditional spectral graph theory to motif
6conductance. Motif-modularity is proposed to define the class of nodes [16].
[3] develops triangle conductance and generalizes random walk to triangle
based higher-order graph. [17] proposes motif-based approximated personl-
ized PageRank algorithm to perform local graph clustering with higher-order
structures. A graph sparsification method based on motif is designed to im-
prove efficiency and quality of graph clustering [18]. A motif correlation
clustering technique for overlapping community detection is developed by
minimizing the number of clustering errors associated with both edges and
motifs [19]. Edge based and motif based multiplex networks are constructed
for community detection to reduce information loss during the aggregation
of multiplex networks [20].
Alltheabovemotif-basedgraphclusteringmethodsignorethefragmenta-
tion issues resulting from motif-based hypergraph construction, which leads
to clustering accuracy degradation. Several methods have been proposed to
address this issue, a edge enhancement approach is proposed in [5] by inject-
ing original graph edges into the high-order graph. A micro-unit modularity
is designed by constructing a micro-unit connection network with integrating
both lower-order structure and higher-order structure [21]. A hybrid-order
stochastic block model is designed from the perspective of generative model
[22]. Both an asymmetric triangle and edges are considered as clustering
measurements to address fragmentation issue [23]. [24] introduces the defini-
tion of mixed-order cut criteria, based on it, spectral clustering is performed
on the mixed-order adjacency matrix generated by random walks and graph
lapalacian. [25] firstly construct sub-higher order network and the corre-
sponding sub-lower order network based on a kind of motif by eliminating
7isolated nodes, then community detection is achieved by contrastive learning
between above two networks. Finally, the isolated nodes are labelled by label
propagation on edge-based graph.
However, current existing defragmentation methods mainly focus on inte-
grating edges and one kind of motif with ignoring other useful motifs. There-
fore, we propose a multi-order graph clustering model (MOGC) to integrate
multiple motifs and edge information in order to resolve fragmentation issue
and achieve more accurate partition results simultaneously.
3. Preliminaries
Given an undirected graph G = {V,E}, where V = {v ,...,v } is a
1 n
set of n vertices, and E represents the set of edges among vertices. The
corresponding adjacency matrix A ∈ Rn×n denotes the similarity between
each pair of nodes, in which A is the similarity between vertice v and
i,j i
vertice v . A = 0 when there is no edge between vertice v and v . The
j i,j i j
degree of vertice v is defined as d =
(cid:80)n
A , the degree matrix D is a
i i j=1 i,j
diagonal matrix with the degrees d ,d ,...,d on the main diagonal. The
1 2 n
laplacian matrix L is constructed as L = D−A.
3.1. Network Motif
The higher-order structure is characterized by motifs, according to [4], a
network motif can be defined as:
Definition 1. Network Motif. A p-node motif Mq is defined by a tuple
p
(B,A), B is a p×p binary matrix and A ⊂ {1,2,...,p} is the set of indices
of the anchor nodes.
8Here B encodes edge pattern between p nodes, and A denotes a subset of the
p nodes for defining the motif-based adjacency matrix. In other words, two
nodes will be regarded as occurring in a given motif only when their indices
belong to A. When A is the entire set of nodes, it is called simple motif,
otherwise it is anchored motif. In this paper, we mainly focus on simple
motif, a simple example for motif with 3 nodes is shown in Fig. 2.
Definition 2. Motif Set. The motif set, denoted as Mq(B,A), is defined
p
in an undirected graph G as:
Mq(B,A) = {(set(v),set(χ (v)))|v ∈ Vp,v ,...,v ,distinct,A = B}
p A 1 p v
where v is an vector representing the indices of p nodes, and χ is a selection
A
function taking the subset of a p-tuple indexed by A, and set(.) is the oper-
ator taking an ordered tuple to an unordered set, e.g., set((v ,v ,...,v ) =
1 2 p
{v ,v ,...,v }. A is the p×p adjacency matrix on the subgraph induced by
1 2 p v
the p nodes of the ordered vector v. Furthermore, any (set(v),set(χ (v))) ∈
A
Mq(B,A) is a motif instance. In this paper, we will use Mq to represent
p p
Mq(B,A) for simplicity.
p
3.2. Motif Adjacency matrix
Definition 3. Motif Adjacency Matrix. Given a motif set Mq, its cor-
p
(cid:80)
respondingmotifadjacencymatrixisdefinedas(A ) = 1(i,j ⊂
Mpq ij
(set(v),set(χA(v)))
set(χ (v))),for i ̸= j. 1(x) is a function, where 1(x) is 1 when x is true, oth-
A
erwise it is 0.
Note that (A ) denotes the number of motif instances when node v and
Mpq ij i
v co-occur in the same p-node motif Mq. The larger (A ) is, the more
j p Mpq ij
9significanttherelationbetweennodev andv iswithinmotifMq. Aconcrete
i j p
example of motif-based adjacency matrix is shown in Fig. 1. After the
motif-based adjacency matrix is generated, the motif diagonal degree matrix
is defined as (D ) =
(cid:80)n
(A ) and the motif Laplacian is L =
Mpq ii j=1 Mpq ij Mpq
D −A .
Mpq Mpq
Generally, the construction of A is related to subgraph counting in
Mpq
large graphs [26][27][28]. We explore motifs with different sizes, including
3-node, 4-node and 5-node motifs in this paper.
Figure 2: Network motif example for 3-node motifs. M3 and M2 are simple motifs, since
3 3
theanchorsetAcontainsallofthenodesinM3 andM2. Bisthebinarymatrixencoding
3 3
edge pattern of corresponding motif.
3.2.1. 3-node Motif-based Adjacency Matrix Construction
For undirected graph G, there are two different kinds of 3-node motifs
ˆ
shown in Fig. 2. Let B is the adjacency matrix of the bidirectional links
of G, then Bˆ = A ◦ AT according to [4], where ◦ denotes the Hadamard
product. For the motif M3, the corresponding motif-based adjacency matrix
3
A = (Bˆ ·Bˆ )◦Bˆ . It is very efficient to generate M3 motif-based adjacency
M3 3
3
matrix when the edge based adjacency matrix A is sparse. For the motif
M2, we obtain the bidirectional links of G, then enumerate all bidirectional
3
links to generate M2 motif-based adjacency matrix A according to [4].
3 M2
3
103.2.2. 4-node and 5-node Motif-based Adjacency Matrix Construction
Foramotifwithpnodes, p = 4orp = 5, weneedcountallmotifinstances
in the graph to calculate its corresponding motif-based adjacency matrix.
O(np) time is needed for enumerating all motif instances, the computation
cost will increase dramatically with the increase of number of nodes. More-
over, there are too many isomorphic types of motifs. For example, there are
199 4-node motifs, 9364 5-node motifs [28]. Several methods with available
softwares have been proposed to discover motif efficiently [26][27][28]. Hence,
for the construction of p-node motif-based adjacency matrix, we firstly uti-
lize a sampling method [28] with software mFinder1 to detect motifs, which
samples numerous p-node motifs based on the probability distribution de-
rived from the frequency of various types of p-node motifs. Besides, mFinder
also can generate all motif instances for each type of p-node motifs. Finally,
we input all motif instances into Algorithm 1 in [29] to construct p-node
motif-based adjacency matrix.
4. The Proposed Method
Given a graph G = {V,E} and a motif Mq, we can obtain a symmetric
p
and weighted motif adjacency matrix A ∈ Rn×n. Note that motif Mq
Mpq p
can be higher-order structure or lower-order structure, e.g., edge, 3-node
motif, 4-node motif. In order to tackle the hypergraph fragmentation issue,
we introduce a diagonal matrix W to denote the isolated nodes based on
Mpq
motifMq, ifthei-thnodeisaisolatednodeinthecorrespondinghigher-order
p
1https://www.weizmann.ac.il/mcb/UriAlon/download/network-motif-software
11graph, then (W ) = 0, otherwise (W ) = 1.
Mpq i,i Mpq i,i
Moreover, assuming there are m different motifs
Mqj
with j ∈ [1,m],
pj
we introduce a nonnegative matrix Λ ∈ Rn×m to denote the weight of each
motif for each node. Each element Λ ( ∀i ∈ [1,n],j ∈ [1,m],Λ ≥ 0)
i,j i,j
is the weight of motif
Mqj
for node v , which illustrates the importance of
pj i
motif
Mqj
to node v . For example, in Fig. 1, the node #11 has connectivity
pj i
with other nodes in edge-based graph, while it becomes outlier in 3-node
motif based hypergraph and 4-node motif based hypergraph. Therefore, the
importance of edge, 3-node motif, and 4-node motif for node #11 are differ-
ent, and the weight of edge for node #11 should be highest. Note that if
i-th node is a isolated node under motif
Mqj,
then we set Λ = 0. There-
pj i,j
fore, to retain both higher-order structure and lower-order structure, we fuse
the information from m motifs by
(cid:80)m
W A diag(Λ ). In order to
j=1 Mpq jj Mpq jj :,j
guarantee symmetry of combined adjacent matrix, we set:
m
1 (cid:88)
A = (W A diag(Λ )+diag(Λ )A W ) (1)
f
2
Mpq jj Mpq jj :,j :,j Mpq jj Mpq jj
j=1
Here, diag() converts a vector into an diagonal matrix with vector as the
diagonalelements, andΛ isthej-thcolumnofΛ, itdenotestheimportance
:,j
weight of motif
Mqj
for every node in the graph. After obtaining fushed
pj
symmetric adjacency matrix A , we can apply popular spectral clustering
f
on fused adjacency matrix, it is formulated as:
mintr(UTL U) s.t. UTD U = I (2)
f f
Λ,U
Here L = D −A , D is a diagonal degree matrix, tr() denotes the trace,
f f f f
U ∈ Rn×K is the indicator matrix, which contains the clustering information.
12Eq. (2) can avoid the degenerated case that all nodes are partitioned into one
connected component [15]. The combined adjacent matrix A depends on
f
unknown variable Λ, which denotes the importance weight of each motif for
each node. To determine appropriate weights that mitigate the influence of
irrelevant motifs while reinforcing meaningful ones, we constrain the sum of
all motif weights for each node equal to one, i.e.,
(cid:80)m
Λ = 1,∀i ∈ [1,n].
j=1 i,j
Finally, the multi-order graph clustering (MOGC) with adaptive weights
learning mechanism is formulated as:
mintr(UTL U)+α∥Λ∥2, s.t. UTD U = I, Λ1 = 1 ,Λ ≥ 0 (3)
f F f m n
Λ,U
1 is a vector of length m with all the elements being 1, I is the identity
m
matrix, the second term ∥Λ∥2 forces a smooth solution, such that irrelevant
F
hypergraphs would be removed in the clustering process. α is a trade-off
parameter.
5. Optimization
It is difficult to solve Eq. (3) directly, since both L and D depend on
f f
unknown variable Λ. We use alternating optimization to solve Eq. (3).
5.1. Fix Λ, solve U:
When Λ is fixed, the minimization problem Eq.(3) would become:
min tr(UTL U) s.t. UTD U = I. (4)
f f
U
Since L is symmetric, Eq. (4) is degenerated to the generalized eigenvalue
f
problem [15] as follows:
˜
L U = D UΛ (5)
f f
13˜ ˜ ˜ ˜
where Λ = diag(λ ,λ ,...,λ ) is the eigenvalue matrix, the solution of U
1 2 n
is given by the corresponding K eigevectors corresponding to the first K
smallest eigenvalues of generalized eigenvalue problem Eq. (5).
5.2. Fix U, solve Λ:
When U is fixed, the minimization problem Eq. (3) would become:
mintr(UTL U)+α∥Λ∥2 s.t. UTD U = I,Λ1 = 1 ,Λ ≥ 0 (6)
f F f m n
Λ
Let U denotes the k-th column of U. Because A satisfies Eq. (1), and
k f
L = D −A = diag(A 1 )−A . Then Eq. (6) would become
f f f f n f
K K
(cid:88) (cid:88)
min UTdiag(A 1 )U − UTA U +α∥Λ∥2 (7)
k f N k k f k F
Λ
k=1 k=1
s.t. UTD U = 1,Λ1 = 1 ,Λ ≥ 0
k f k m n
Let A˜ = [UTW A diag(U ),...,UTW A diag(U )], and Λ˜ =
k k Mpq 11 Mpq 11 k k Mpq mm Mpq mm k
[ΛT ,...,ΛT ]T, then
:,Mpq 11 :,Mpq mm
K K m
(cid:88) 1 (cid:88)(cid:88)
UTA U = UT[diag(Λ )A W +W A diag(Λ )]U
k f k 2 k :,Mpq jj Mpq jj Mpq jj Mpq jj Mpq jj :,Mpq jj k
k=1 k=1 j=1
K m K
(cid:88)(cid:88) (cid:88)
= UTW A diag(U )Λ = A˜ Λ˜ (8)
k Mpq jj Mpq jj k :,Mpq jj k
k=1 j=1 k=1
Similarly,itiseasytoderivethatdiag(A 1 ) = 1 (cid:80)m diag(Λ )diag(A W 1 )+
f n 2 j=1 :,Mpq jj Mpq jj Mpq jj n
diag(W A diag(Λ )1 ), then
Mpq jj Mpq jj :,Mpq jj n
K K m
(cid:88) 1 (cid:88)(cid:88)
UTdiag(A 1 )U = UTdiag(A W 1 )diag(U )Λ
k f n k 2 k Mpq jj Mq pj
j
n k :,Mpq jj
k=1 k=1 j=1
+UTdiag(U )W A diag(1 )Λ (9)
k k Mpq jj Mpq jj n :,Mpq jj
14LetAˆ = [UTdiag(A W 1 )diag(U ),··· ,UTdiag(A W 1 )diag(U )],
k k Mpq 11 Mpq 11 n k k Mpq mm Mpq mm n k
A¯ = [UTdiag(U )W A ,..., UTdiag(U )W A ], then
k k k Mpq 11 Mpq 11 k k Mpq mm Mpq mm
K K
(cid:88) 1 (cid:88)
UTdiag(A 1 )U = (Aˆ +A¯ )Λ˜
k f N k 2 k k
k=1 k=1
Finally, according to Eq. (8) and Eq. (9), the optimization problem Eq. (7)
can be solved instead of
minVΛ˜ +α∥Λ˜ ∥2 s.t. (Aˆ +A¯ )Λ˜ = 1,MΛ˜ = 1 ,Λ˜ ≥ 0,∀ k ∈ [1,K] (10)
F k k n
Λ˜
Here V = 1 (cid:80)K (Aˆ +A¯ )−(cid:80)K A˜ with V ∈ R1×nm, and M = [I ,...,I ]
2 i=1 i i i=1 i n n
(cid:104) (cid:105)T
with M ∈ Rn×nm. Let P = (Aˆ +A¯ )T,(Aˆ +A¯ )T,...,(Aˆ +A¯ )T .
1 1 2 2 K K
Then for Eq. (10), it becomes
min VΛ˜ +α∥Λ˜ ∥2 s.t. PΛ˜ = 1 ,MΛ˜ = 1 ,Λ˜ ≥ 0 (11)
F K n
Λ˜
Denote Φ ∈ Rn×1,Φ ∈ RK×1 as the Lagrangian multiplier, then we can
1 2
write the Lagrangian function of Eq. (11) as
F = VΛ˜ +α∥Λ˜ ∥2 −ΦT(MΛ˜ −1 )−ΦT(PΛ˜ −1 )−ξ (Λ˜ ) (12)
F 1 N 2 K +
ξ represents the delta function which provides +∞ to the negative value.
+
˜
The derivative of Eq. (12) with respect to Λ is
∂F
= 2αΛ˜ +VT −MTΦ −PTΦ (13)
˜ 1 2
∂Λ
With KKT condition,the optimal solution can be defined as
MTΦ +PTΦ −VT
˜ 1 2
Λ = Proj( ) (14)
+
2α
15˜ ˜ ˜ ˜
Where Proj(Λ) indicates that if Λ < 0, then set Λ = 0. Since MΛ =
+
˜
1 ,PΛ = 1 , then it is easy to derive that the optimal Φ and Φ are
n K 1 2
Φ = [MMT −MPT(PPT)−1PMT]−1[2α1 +MVT −MPT(PPT)−1(2α1 +PVT)]
1 n K
Φ = [PPT −PMT(MMT)−1MPT]−1[2α1 +PVT −PMT(MMT)−1(2α1 +MVT)]
2 K n
(15)
Actually the optimal Φ and Φ can be obtained by conjugate gradient method
1 2
[30],thefinalsolutionofΛ˜ canbeobtainedbyEq. (14)withEq. (15),thesolution
of Λ can be obtained by reshaping vector Λ˜ back to matrix.
Based on the above analysis, the detail process for solution Eq. (3) is shown
in the Algorithm 1. Besides, the flowchart of our proposed methods is shown in
Fig. (3).
Algorithm 1 MOGC: Alternating method for solving Eq. (3)
Input: Given input A , W , the parameters α, K and the stopping
Mqj Mqj
Pj Pj
criterion ϵ = 10−5.
Output: U and Λ
1: repeat
2: Compute Uk by (4).
˜ ˜
3: Compute Λ by Eq. (14), and reshape Λ into n×n matrix Λ.
4: until max{∥Uk+1 −Uk∥2,∥Λk+1 −Λk∥2} ≤ ϵ.
F F
166. Theoretical Analysis
6.1. Convergence Analysis
DenoteF := (cid:8) (Λ,U)|UTD U = I,Λ1 = 1 ,Λ ≥ 0,(i,j) ∈ [1,n]×[1,m](cid:9)
f m n i,j
The minimization problem can be written as:
min f(Λ,U), where f(Λ,U) = tr(UTL U)+α||Λ||2.
f F
(Λ,U)∈F
Let {Λ(k),U(k)}+∞ be the iterative sequence generated by the alternating mini-
k=0
mization.
Definition 4. The values of objective function f along the iterative sequence
{Λ(k),U(k)}+∞ is monotonically decreasing and converge to a finite value fˇ≥ 0,
k=0
i.e., 0 ≤ lim f(Λ(k),U(k)) = fˇ< +∞ and fˇ= inf f(Λ(k),U(k)).
k→+∞ k≥0
proof 1. The alternating iterative process implies that
f(Λ(k),U(k)) ≥ f(Λ(k),U(k+1)) ≥ f(Λ(k+1),U(k+1)),
which means the sequence {f(Λ(k),U(k))}+∞ is monotonically decreasing. More-
k=1
over, it is clear that {Λ(k),U(k)}+∞ ⊂ F. Therefore, +∞ > f(Λ(k),U(k))
k=0
≥ 0. Hence, {f(Λ(k),U(k))}+∞ is a monotonically decreasing upper and lower
k=1
bounded sequence. Hence, there exists a finite constant fˇ ∈ [0,+∞) such that
lim f(Λ(k),U(k)) = fˇ. The monotonicity of {f(Λ(k),U(k))}+∞ implies that
k=1
k→+∞
fˇ= inf f(Λ(k),U(k)). The proof is complete.
k≥0
6.2. Computational Complexity
We analyze the complexity of the proposed MOSC method as follows. In
general, the complexity of this algorithm is governed by the computation of motif
adjacency matrix and the alternating minimization algorithm in Algorithm. 1.
17For sparse real networks with adjacency matrix A, the symmetric matrix A
has |A| non-zero elements, we assume that there is |A | non-zero elements at
i
the i-th column. According to the introduction of section 3.2.1, for the mo-
tif M 33, its corresponding motif based adjacency matrix construction is A Mpq jj =
(A◦AT)·(A◦AT)◦(A◦AT), where A◦AT takes |A| flops, and the · opera-
tion takes (cid:80)n |A |2 flops, so the total flops of M3 motif based adjacency matrix
i=1 i 3
construction is (cid:80)n |A |2+3|A| and the corresponding computational complex-
i=1 i
ity is O((cid:80)n |A |2). M2 based adjacency matrix is generated according to [4],
i=1 i 3
O(nJi) complexity is required, where J is the non-zero elements at the i-th row
2 i
of bidirection subgraph adjacency matrix Bˆ corresponding to A.
For p-node motif with p = 4 or p = 5, according to section 3.2.2, a sampling
methodwithmFindersoftwareisfirstlyappliedtocountallmotifinstances, which
has total computation complexity of O(spp+1), where s is the number of samples
[28]. Then, Algorithm 1 in [29] is executed to generate motif-based adjacent ma-
trix, it has complexity O(s p2), where s denotes the number of generated motif
p p
instances of p-node motif. Therefore, the total complexity for calculating 4-node
or 5-node based adjacent matrix is O(spp+1+s p2).
p
Next, we discuss the operation cost of the alternating minimization iterative
process when the matrices A Mpq jj, W Mpq jj are given. For the process of solving Λ
with fixed U, the Λ is calculated by Eq. (14), which requires the value of Φ ,
1
Φ , P and V. By definition of Φ in Eq. (15), its evaluation requires (2K2 +
2 1
5K +1)mn+(4K2 +2K +11)n+K3 +K2 +K flops using conjugate gradient
solver. BydefinitionofΦ inEq. (15), itsevaluationrequires(2K2+3K+2)mn+
2
(2K2−K+1)n+K3/3+5K2/2+K/6 flops. Besides, both of P and V depends
on A˜ , Aˆ and A¯ for i = 1,2,...,K. By definition of A˜ , its evaluation requires
i i i i
(2n−1)m+2s˜ flops for each i. Here, s˜ represents the total number of non-zero
entries in A Mpq 11,...,A Mpq mm. By the definition of Aˆ i, its evaluation requires 2s˜+n
18flops for each i. By definition of A¯ , its evaluation requires 2s˜flops for each i. By
i
definition of P, its evaluation requires Kmn flops with the knowledge of Aˆ and
i
A¯ . By definition of V, its evaluation requires 2Kmn flops with the knowledge of
i
Aˆ , A¯ and A˜ . Eq. (14) indicates that the evaluation of Λ requires (2K +2)mn
i i i
flops with the knowledge of Φ , Φ and V. Therefore, the updating Λ for fixed U
1 2
requires(4K2+15K+5)mn+(6K2+3K+12)n+(6s˜−m)K+4K3/3+7K2/2+7K/6
flops in total, and it is an O(K2mn) sub-problem.
Now, let’s focus on the process of updating U with fixed Λ. It is an eigen-
problem for find the K eigenvectors corresponding to the K smallest eigenvalues
of the symmetric matrix D− 21 LD−1 2, which requires O(K2n) operations by the
truncated SVD algorithm.
To conclude, each alternating minimization iteration requires O(K2mn) oper-
ations in total.
Figure 3: The flowchart of MOGC
197. Experiments
7.1. Testing Datasets
In this section, we conduct experiments on seven real datasets. football1
contains 115 nodes connected with 616 edges which are partitioned into 12 groups.
polbooks1 is a network of 105 books with 441 edges, edges represent frequent
copurchasingofbooksbythesamebuyers. Booksbelongsto3clusters. polblogs1
is a network with 1490 weblogs (nodes) partitioned into 2 clusters and 19090
edges. Cora2 consists of 2708 scientific publications classified into one of seven
classes, nodes are connected with 5429 links. email-Eu-core3 describes the email
sent between members (nodes) within a large European research institution. The
network contains 1005 nodes with 25571 edges are classified into one of 42 classes.
CiteSeer2 consists of 3312 scientific publications classified into one of six classes.
It has 4732 links. Pubmed2 consists of 19717 scientific publications with 44338
links classified into one of three classes. All datasets are undirected graph and
self-loops are removed, the summary of them is shown in Table. 2.
Table 2: Summary of real datasets
Dataset football polbooks polblogs Cora email-Eu-core Citeseer Pubmed
Nodes 115 105 1490 2708 1005 3312 19717
Edges 616 441 19090 5429 25571 4732 44324
Class 12 3 2 7 42 6 3
1http://www-personal.umich.edu/ mejn/netdata/
2https://linqs.org/datasets/
3https://snap.stanford.edu/data/email-Eu-core.html
207.2. Comparison Methods
We mainly compare our method with several lower-order clustering methods
and higher-order clustering methods. The lower-order clustering methods: Spec-
tral Clustering (SC) [31] is performed on edge-based adjacency matrix. Nor-
malizedCut(Ncut)[15]partitionsgraphsbasedongraphnormalizedcut. Non-
negative Matrix Factorization[32]isperformedonthegraphadjacencymatrix
to obtained the group partition. Affinity Propogation (AP) [11] seeks cluster
ofnodesbysimilaritiesbetweenpairsofnodes. Node2vec+Kmeans(N2VKM)
[33]learnslow-dimensionalrepresentationsforverticesbybiasedrandomwalkand
skip-Gram, then K-means is performed to cluster the embedded vectors of vertices
into several groups. The higher-order clustering methods include Motif SC [4],
EdMot SC [5], MWLP [6], MOSC [24], CDMA [20] and MotifCC [25]. They can
only utilize one kind of motif, while our method integrates information from mul-
tiple motifs. In the experiment, higher-order clustering methods with motif Mp
q
means motif Mp is used to generate motif hypergraph. Motif SC [4] extends tra-
q
ditional spectral clustering to higher-order structure by constructing motif-based
adjacencymatrix. EdMot SC[5]proposesaedgeenhancementapproachtoover-
come hypergraph fragmentation issues by adding edges to generate hypergraph,
then the new constructed adjacency matrix is used as input of spectral cluster-
ing to obtain final. MWLP [6] proposes motif-aware weighted label propagation
method to integrate higher-order structure and original lower-order structure by
reweighted network. MOSC [24] performs spectral clustering on the mixed-order
adjacency matrix generated based on edge and one kind of motif by graph Lapla-
cian. CDMA [20] proposes a multiplex network community detection algorithm
based on edge and motif, only one layer is considered in order to make comparison
with our method. MotifCC [25] performs deep contrastive learning on sub-higher
order graph and sub-lower order graph, which generated from motif based graph
21Figure 4: 4-node motif and 5-node motif used in the experiments.
and edge based graph separately.
7.3. Experiments Setting and Evaluation Measurements
For MOGC, α is tuned in {0.1,0.2,...,3} and {4,5,...,20}, and then it is
determined when best score is achieved. In addition, the walk length, the number
of walks per node, the embedding dimension and the window size in Node2vec are
set as 80, 10, 128, and 10 separately. Moreover, the hyperparameter p and in-out
parameter q are tuned such that best performance is achieved. Best parameters
reported in other comparison methods are used in the experiment. We set the
number of clusters as the ground-truth communities for all methods.
We evaluate the clustering results using metrices like Rand Index (RI) [34]
and Normalized Mutual Information (NMI) [35]. For all measurements, a higher
value indicates better performance. All experiments are repeated for 20 times, the
average metrics and their standard deviations are reported.
7.4. Experimental Results
7.4.1. Results of 3-node Motifs
Wefirstlytestourmethodon3-nodemotif,thereare2differenttypesof3-node
motif for undirected graph, i.e., M3 and M2 shown in Fig. 4. Then, we construct
3 3
motif M3 and M2 based adjacency matrix introduced in section 3. The lower-
3 3
order clustering methods including SC, Ncut, NMF, AP, N2VKM are tested on
edge-based graph, the higher-order clustering methods utilizing one kind of motif
and edge, including Motif SC, EdMot SC, MWLP, MOSC, CDMA, and MotifCC,
are tested on edge-based graph and motif-based hypergraph. Our method MOGC
can utilize lower-order graph and multiple higher-order hypergraphs, the results of
MOGCwithM3 andM2 onsevendatasetsmeanthatedge-basedgraph,motifM3
3 3 3
22and motif M2 based hypergraphs are used in Algorithm 1. The experiment results
3
for all methods on seven datasets are shown in Table. 3 and Table. 4, it shows
thatMOGCoutperformsothermethodswithdifferentmotifs, whichdemonstrates
the effectiveness of our method.
We further give a detailed analysis about the results. Firstly, Compared with
traditional edge-based graph partition methods, the corresponding higher-order
methods generally have higher accuracy than most of them, which illustrates that
the higher-order structures play an important role in community discovery. Sec-
ondly, when motif M3 is adopted, MOGC has better performances than other
3
higher-order graph clustering methods on almost all datasets. For Cora, Cite-
seer and Pubmed datasets with very sparse connectivity pattern, the accuracy
of higher-order method Motif SC decreases greatly compared with edge-based
method(SC),sinceMotif SCsuffersfromseriousfragmentationissue. However, in
terms of Rand Index, MOGC achieves about 70%, 65%, 65% improvements over
Motif SC. This shows the effectiveness of MOGC in addressing the hypergraph
fragmentation issue. Moreover, the accuracy of CDMA decreases significantly for
Cora and Citeseer datasets with M3, due to the ignorance of fragmentation is-
3
sue in CDMA. Compared with state-of-the-art defragmented higher-order graph
clustering methods (EdMot SC and MWLP), we also have much higher accuracy
than others, which validates adaptive weights learning mechanism is more help-
ful than edge enchancement approaches in addressing hypergraph fragmentation
issue. Compared with MOSC which combines edge and triangle adjacency ma-
trices with mixing parameter, MOGC performs better on all datasets, it proves
that more accurate results would be achieved by assigning weighting scaler to each
motif for each node. Our method show better performances than MotifCC on al-
most all datasets, since MotifCC adopts two steps for community detection, label
of all nonisolated nodes are obtained firstly by applying contrastive learning on
23Table 3: Rand Index Results on seven real datasets (mean±std).
dataset football polbooks polblogs Cora email-Eu-core Citeseer Pubmed
SC 0.8967±0.0000 0.6445±0.0521 0.0005±0.0000 0.2385±0.0000 0.4145±0.0188 0.3431±0.0000 0.1123±0.0000
Ncut 0.0086±0.0052 0.3524±0.0782 0.3497±0.0441 0.0027±0.0016 0.0260±0.0050 0.0638±0.0145 0.0004±0.0008
edge NMF 0.8810±0.0254 0.5679±0.0523 0.8013±0.0000 0.2745±0.0209 0.4574±0.0200 0.1584±0.0108 0.0976±0.0039
AP 0.3426±0.0460 0.1139±0.0171 0.0501±0.0021 0.0160±0.0011 0.0739±0.0067 0.0117±0.0015 0.0011±0.0002
N2VKM 0.9836±0.0000 0.8485±0.0000 0.8186±0.0000 0.8241±0.0000 0.9553±0.0000 0.7182±0.0005 0.6905±0.0000
MotifSC 0.8967±0.0273 0.6572±0.0713 0.0036±0.0000 0.0788±0.0000 0.3243±0.0104 0.0369±0.0000 0.3511±0.0078
EdMotSC 0.8967±0.0000 0.6622±0.0236 0.7956±0.0000 0.3434±0.0050 0.3667±0.0119 0.1545±0.0342 0.2623±0.0000
M 33 MWLP 0.9420±0.0010 0.6689±0.0138 0.5277±0.0018 0.7761±0.0024 0.1902±0.0000 0.7813±0.0004 0.6405±0.0011
MOSC 0.7733±0.0596 0.6613±0.0073 0.0004±0.0000 0.0053±0.0000 0.4718±0.0211 0.3225±0.0224 0.1880±0.0762
CDMA 0.9597±0.0000 0.4844±0.0000 0.5195±0.0000 0.1999±0.0000 0.7859±0.0000 0.2169±0.0000 0.3580±0.0000
MotifCC 0.9706±0.0063 0.6774±0.0563 0.7131±0.0562 0.7334±0.0015 0.9409±0.0035 0.7147±0.0006 0.5479±0.0003
MOGC 0.9830±0.0047 0.8464±0.0035 0.8963±0.0000 0.7375±0.0000 0.9564±0.0102 0.6965±0.0000 0.6510±0.0081
MotifSC 0.8609±0.0751 0.6636±0.0451 0.8190±0.0000 0.2726±0.0000 0.4431±0.0125 0.3461±0.0000 0.2597±0.0000
EdMotSC 0.8590±0.0000 0.6667±0.0080 0.8072±0.0000 0.2726±0.0000 0.4414±0.0067 0.3461±0.0000 0.2597±0.0000
M 32 MWLP 0.8900±0.0015 0.6559±0.0007 0.5847±0.0000 0.7793±0.0006 0.1485±0.0000 0.7468±0.0000 0.6405±0.0013
MOSC 0.7376±0.0724 0.6326±0.0070 0.8190±0.0000 0.0055±0.0000 0.4399±0.0233 0.3212±0.0214 0.2376±0.0495
CDMA 0.9408±0.0000 0.7170±0.0000 0.4996±0.0000 0.4522±0.0000 0.8306±0.0000 0.3903±0.0000 0.3995±0.0000
MotifCC 0.9617±0.0090 0.7807±0.0390 0.6838±0.0435 0.7351±0.0016 0.9355±0.0032 0.7155±0.0006 0.5454±0.0002
MOGC 0.9858±0.0108 0.8555±0.0000 0.9110±0.0000 0.7888±0.0000 0.9608±0.0009 0.7883±0.0000 0.5405±0.0015
MotifSC 0.8242±0.0000 0.6570±0.0000 0.0509±0.0000 0.1777±0.0000 0.3858±0.0000 0.0408±0.0000 0.0007±0.0000
EdMotSC 0.8242±0.0000 0.6886±0.0000 0.1628±0.0818 0.3453±0.0082 0.3933±0.0036 0.1211±0.0425 0.0626±0.0003
M 4∗ MWLP 0.9396±0.0009 0.8209±0.0141 0.5083±0.0010 0.8024±0.0005 0.9164±0.0001 0.8222 ±0.0000 0.6400 ±0.0000
MOSC 0.7526±0.0472 0.6484±0.0086 0.7371±0.2458 0.0544±0.0028 0.3838±0.0149 0.0180 ±0.0028 0.1017 ±0.0035
CDMA 0.9553±0.0000 0.4727±0.0000 0.5015±0.0000 0.1944±0.0000 0.8114±0.0000 0.2071±0.0000 0.3607±0.0000
MotifCC 0.9712±0.0098 0.7224±0.0598 0.6394±0.0425 0.7333±0.0014 0.9433±0.0032 0.7147±0.0003 0.5478±0.0002
MOGC 0.9759±0.0000 0.8463±0.0081 0.9036±0.0000 0.8196±0.0000 0.9570±0.0008 0.7754±0.0000 0.5855±0.0000
MotifSC 0.8255±0.0000 0.5264±0.0000 0.5065±0.0000 0.0037±0.0000 0.1490±0.0000 0.0082±0.0000 0.0019±0.0000
EdMotSC 0.8419±0.0336 0.3671±0.1539 0.8015±0.0006 0.2215±0.0327 0.2858±0.0070 0.0223±0.0069 0.0906±0.0147
M 5∗ MWLP 0.9068±0.0013 0.7283±0.0137 0.5151±0.0001 0.7796±0.0059 0.3941±0.0592 0.8218±0.0002 0.6391±0.0061
MOSC 0.7619±0.0784 0.6245±0.0057 0.8190±0.0000 0.0017±0.0059 0.3585±0.0248 0.0225±0.0004 0.1124±0.0002
CDMA 0.9613±0.0000 0.4533±0.0000 0.5114±0.0000 0.2365±0.0000 0.7871±0.0000 0.2037±0.0000 0.3584±0.0000
MotifCC 0.9635±0.0120 0.7585±0.0459 0.7052±0.0996 0.7312±0.0021 0.9400±0.0038 0.7145±0.0003 0.5477±0.0001
MOGC 0.9806±0.0000 0.8507±0.0000 0.9021±0.0000 0.7204±0.0000 0.9114±0.0101 0.7710±0.0000 0.5377±0.0000
MOGCM 33M 32 0.9847±0.0060 0.8548±0.0068 0.9110±0.0000 0.7959±0.0000 0.9615±0.0009 0.7865±0.0216 0.5412±0.0000
Multiple MOGCM 33M 4∗ 0.9771±0.0000 0.8530±0.0037 0.9095±0.0000 0.8048±0.0000 0.9568±0.0009 0.7866±0.0000 0.5750±0.0000
motif MOGCM 33M 4∗M 5∗ 0.9844±0.0000 0.8519±0.0062 0.9095±0.0000 0.8066±0.0000 0.9568±0.0009 0.7869±0.0000 0.5656±0.0085
24higher-order and lower-order graph, then labels of isolated nodes are achieved by
the label propagation on the original edge-based graph. While in our method, the
label partitions of isolated and nonisolated nodes are realized within a optimiza-
tion function, such that they can promote each other. Finally, when motif M2 is
3
adopted, the accuracy of MOGC is further improved than that using motif M3.
3
Specially, our method has higher value of all measurements than other methods
on seven datasets. This might be the fact that the density of hypergraph using
motif M2 is larger than those using motif M3, only few M2 based hypergraphs
3 3 3
suffer from fragmentation issue.
7.4.2. Results of 4-node Motifs and 5-node Motifs
In this subsection, we show the performances using 4-node and 5-node motifs.
In the experiment, we select the top one 4-node and 5-node motif generated from
mFinder3 to test our proposed method. Concretely, according to section 3, we
firstly run software mFinder3 to find top one motif, then construct 4-node and
5-node motif-based adjacency matrix according to algorithm 1 in [29]. Finally, we
conduct comparison experiments on seven datasets using 4-node motif and 5-node
motif. For 4-node motif, we show the top one 4-node motif for seven datasets in
Table. 5 and its corresponding visulization in Fig. 4, the top one 4-node motif of
six datasets (football, polbooks, Cora, email-Eu-core, Citeseer, Pubmed) are M1,
4
that of polblogs is M2. The top one 5-node motif and its corresponding figure for
4
seven datasets are also shown in Table. 5 and Fig. 4. The results of all higher-
order graph clustering methods are shown in Table. 3 and Table. 4, MOGC with
M∗ or M∗ mean that both edge-based graph and top one 4-node or 5-node based
4 5
hypergraphs are utilized in Algorithm 1.
As indicated by Table. 3, we can know that the performance of MOGC is
betterthanothersixhigher-ordergraphclusteringmethodsforalmostalldatasets,
25Table 4: NMI Results on seven real datasets (mean±std).
dataset football polbooks polblogs Cora email-Eu-core Citeseer Pubmed
SC 0.9242±0.0000 0.5422±0.0261 0.0029±0.0000 0.3928±0.0000 0.6983±0.0065 0.3701±0.0000 0.1568±0.0000
Ncut 0.2435±0.0135 0.3544±0.0388 0.4166±0.0261 0.0114±0.0037 0.2389±0.0055 0.0718±0.0089 0.0002±0.0001
edge NMF 0.9199±0.0085 0.5247±0.0127 0.7147±0.0000 0.3740±0.0173 0.7005±0.0053 0.2255±0.0100 0.1522±0.0062
AP 0.6534±0.0295 0.3546±0.0182 0.2106±0.0029 0.3694±0.0022 0.5402±0.0081 0.3263±0.0029 0.1637±0.0357
N2VKM 0.9267±0.0000 0.5787±0.0000 0.5501±0.0000 0.4643±0.0001 0.7026±0.0000 0.2498±0.0001 0.2986±0.0000
MotifSC 0.9242±0.0075 0.5531±0.0452 0.0041±0.0000 0.1550±0.0000 0.6498±0.0066 0.0774±0.0000 0.0026±0.0000
EdMotSC 0.9242±0.0000 0.5583±0.0236 0.7013±0.0000 0.4302±0.0020 0.6765±0.0067 0.2500±0.0290 0.2363±0.0000
M 33 MWLP 0.7885±0.0031 0.3641±0.0134 0.1397±0.0033 0.3302±0.0015 0.1053±0.0000 0.0982±0.0005 0.1557±0.0022
MOSC 0.8837±0.0220 0.5564±0.0062 0.1799±0.0000 0.0774±0.0000 0.6974±0.0057 0.3607±0.0187 0.2022±0.0438
CDMA 0.8675±0.0000 0.2000±0.0000 0.1109±0.0000 0.0193±0.0000 0.4593±0.0000 0.0350±0.0000 0.0030±0.0000
MotifCC 0.8922±0.0116 0.5853±0.1027 0.7414±0.0927 0.0290±0.0058 0.5152±0.0378 0.0059±0.0017 0.0006±0.0004
MOGC 0.9214±0.0111 0.5689±0.0066 0.7074±0.0000 0.2427±0.0000 0.6860±0.0694 0.2880±0.0000 0.2693±0.0041
MotifSC 0.8957±0.0377 0.5725±0.0268 0.7306±0.0000 0.4355±0.0000 0.6852±0.0055 0.3680±0.0000 0.2508±0.0004
EdMotSC 0.9043±0.0000 0.5794±0.0068 0.7151±0.0000 0.4355±0.0000 0.6878±0.0035 0.3680±0.0000 0.2508±0.0000
M 32 MWLP 0.4051±0.0063 0.3525±0.0004 0.2324±0.0000 0.3233±0.0017 0.0531±0.0000 0.0987±0.0000 0.1564±0.0014
MOSC 0.8379±0.0388 0.5578±0.0055 0.7380±0.0000 0.1383±0.0000 0.6791±0.0061 0.3458±0.0105 0.2358±0.0329
CDMA 0.7811±0.0000 0.3974±0.0000 0.0003±0.0000 0.2129±0.0000 0.1288±0.0000 0.1480±0.0000 0.0525±0.0000
MotifCC 0.8518±0.0269 0.5875±0.0646 0.6995±0.0707 0.0377±0.0085 0.4200±0.0153 0.0084±0.0025 0.0007±0.0003
MOGC 0.9314±0.0414 0.6058±0.0000 0.7338±0.0000 0.4775±0.0000 0.6880±0.0062 0.3734±0.0000 0.1756±0.0011
MotifSC 0.9003±0.0000 0.5742±0.0000 0.0466±0.0000 0.2843±0.0000 0.6936±0.0000 0.0618±0.0000 0.0070±0.0000
EdMotSC 0.9043±0.0000 0.5761±0.0000 0.1371±0.0691 0.4021±0.0078 0.6975±0.0012 0.1213±0.0377 0.0609±0.0002
M 4∗ MWLP 0.7692±0.0031 0.5349±0.0142 0.1046±0.0040 0.3605±0.0011 0.4488±0.0011 0.3308±0.0006 0.1517±0.0005
MOSC 0.8744±0.0173 0.5688±0.0055 0.7187±0.0218 0.2593±0.0000 0.6893±0.0061 0.0287±0.0025 0.1428±0.0037
CDMA 0.8602±0.0000 0.1830±0.0000 0.0158±0.0000 0.0171±0.0000 0.4525±0.0000 0.0212±0.0000 0.0093±0.0000
MotifCC 0.8883±0.0290 0.5787±0.1062 0.7025±0.0653 0.0283±0.0087 0.5029±0.0199 0.0045±0.0011 0.0005±0.0004
MOGC 0.9043±0.0000 0.5841±0.0093 0.7136±0.0000 0.4628±0.0010 0.6988±0.0041 0.3493±0.0000 0.1877±0.0000
MotifSC 0.8789±0.0000 0.4346±0.0000 0.4051±0.0000 0.0400±0.0000 0.5166±0.0000 0.0610±0.0000 0.0024±0.0000
EdMotSC 0.8943±0.0172 0.3723±0.0933 0.7050±0.0008 0.3821±0.0132 0.6136±0.0044 0.0406±0.0206 0.1710±0.0047
M 5∗ MWLP 0.6222±0.0043 0.4324±0.0131 0.1222 ±0.0020 0.3357 ±0.0048 0.2148 ±0.0125 0.3349 ±0.0013 0.1532 ±0.0038
MOSC 0.8567±0.0416 0.5124±0.0048 0.7287±0.0000 0.1378 ±0.0000 0.6692±0.0111 0.0316 ±0.0016 0.1562 ±0.0001
CDMA 0.8725±0.0000 0.1814±0.0000 0.0830±0.0000 0.0314±0.0000 0.4060±0.0000 0.0153±0.0000 0.0003±0.0000
MotifCC 0.8660±0.0336 0.5288±0.0821 0.7113±0.1615 0.0244±0.0042 0.5356±0.0239 0.0053±0.0015 0.0003±0.0002
MOGC 0.9032±0.0000 0.5815±0.0000 0.7120±0.0000 0.3897±0.0000 0.6032±0.0077 0.1518±0.0038 0.1845±0.0000
MOGCM 33M 32 0.9242±0.0127 0.5881±0.0135 0.7373±0.0000 0.4717±0.0000 0.7029±0.0061 0.3878±0.0100 0.1764±0.0000
Multiple MOGCM 33M 4∗ 0.9134±0.0000 0.5866±0.0072 0.7342±0.0000 0.4416±0.0000 0.6957±0.0033 0.3694±0.0000 0.1914±0.0000
motif MOGCM 33M 4∗M 5∗ 0.9193±0.0000 0.5753±0.0116 0.7342±0.0000 0.4325±0.0000 0.6962±0.0049 0.3642±0.0000 0.1718±0.0053
26which demonstrates the effectiveness of our method. Moreover, compared to the
result of MOGC with M∗, having more nodes in a motif does not lead to better
3
performance. In most cases, the highest accuracy is achieved with M2, the reason
3
may be the noise in motif with a large number of nodes degrades the performance.
7.4.3. Results of Multiple Motifs
Since our method can utilize the information from lower-order structure and
multiplehigher-orderstructures, weconductexperimentstoshowtheperformance
using edges and multiple motifs simultaneously. It is impossible to enumerate
all the combination of all motifs with different number of nodes, so we test the
combination of the top one 3-node, 4-node and 5-node motifs shown in Table. 5,
the top one 3-node motif is M3 for all datasets. The results are shown in Table.
3
3 and Table. 4, MOGC M3 M2 indicates that edge, motif M3 and motif M2 are
3 3 3 3
utilized in Algorithm 1, MOGC M3 M∗ means that edge, motif M3 and top-1
3 4 3
4-node motif M∗ are used, MOGC M3 M∗ M∗ means that edge, motif M3, top
4 3 4 5 3
one 4-node and 5-node motif are used.
As indicated by Table. 3 and Table. 4, compared with other higher-order
methods, our method can achieve better results by intergrating multiple higher-
order structures. For example, in Citeseer dataset, there are 1255 isolated nodes
in M3 motif-based hypergraph, while there are no isolated nodes in M2 motif-
3 3
based hypergraph. The NMI result of MOSC M3 M2 is about 0.13 higher than
3 3
EdMot SC with M3. As for the hypergraph of motif M2, even though hypergraph
3 3
fragmentation does not happen, our method still achieves 0.02 higher than Ed-
Mot SC in terms of NMI. For Cora dataset, highest rand index result is achieved
by MOGC M3 M∗ M∗ with edge and multiple motifs. Similar analysis can be
3 4 5
made for other datasets.
27Table 5: Top one of 3-node, 4-node, 5-node motifs generated by mfinder
dataset football polbooks polblogs Cora email-Eu-core Citeseer Pubmed
3-node motif M3 M3 M3 M3 M3 M3 M3
3 3 3 3 3 3 3
4-node motif M1 M1 M2 M1 M1 M1 M1
4 4 4 4 4 4 4
5-node motif M1 M2 M2 M3 M2 M3 M3
5 5 5 5 5 5 5
7.5. Adaptive Node-level Weights Analysis
Thepolbooksdatasetischosentoillustratetheperformanceofadaptiveweights
Λ, the network in polbooks contains 105 nodes grouped into 3 clusters. The 1st-
13th nodes belong to 1st cluster, the 14th-62nd nodes belong to 2nd cluster, and
the 63th-105th nodes are in 3rd cluster. Fig. 6 shows the weights Λ of each mo-
tif (including lower-order structure, motif M3 and motif M2) for each node, it is
3 3
apparent that the contribution of structures are different to different nodes. We
calculate the average weight for edge, M3 and M2, they are 0.1784, 0.2532, and
3 3
0.5684 respectively, the average weight of M2 is higher than others. Moreover,
3
it is shown that Motif SC with M2 has better performance than Motif SC with
3
M3 and SC in Table.3 and Table. 4, this results validate that the obtained Λ
3 :,j
obtained by MOGC is reasonable.
To further demonstrate the performance of adaptive node-level weight, we
checked two typical nodes marked by red square and green cicle. The red square is
the 59th node with Λ = 0.3920, Λ = 0, Λ = 0.6080. Fig. 5(a) shows the
59,1 59,2 59,3
corresponding adjacent weight of other nodes connected to 59th node, it is shown
that 59th node becomes a isolated node without connectivity with other nodes
under motif M3. From Fig. 5(a), we can conclude that 59th node belongs to the
3
2nd cluster, nodes from the same cluster have higher similarity with 59th node
than others from different clusters according to A and A , so both A
edge M2 edge
3
and A contribute to the clustering of the 59th node. However, Fig. 5(a) also
M2
3
shows that the 59th node has denser within-cluster connectivity with M2 than
3
that with edge, so A can provide more accurate information to the cluster of
M3
3
59th node. This result indicates that the weight of motif M3 would be larger than
3
28that of edge, which is consistent with calculated Λ. The green cicle is the 1st node
with Λ = 0.5060, Λ = 0.4940, Λ = 0. Fig. 5 (b) shows the corresponding
1,1 1,2 1,3
adjacent weight of other nodes connected to 1st node. The 1st node belongs to
first cluster. As can be seen, 1st node has connections with other nodes from 1st
cluster and 2nd cluster. Moreover, nodes from 2nd cluster have more connectivity
with larger weights with 1st node under motif M2, which is not helpful to the
3
correct partition. So it is acceptable that our method assigns 0 to the weight of
motif M2 for 1st node. For lower-order structure and motif M3, nodes both from
3 3
1st cluster and 2nd cluster have connections with 1st node according to A and
edge
A , so it is reasonable that similar weights are assigned to these two motifs.
M3
3
7.6. Parameter Analysis
Theoretically, the parameter α is a trade-off parameter for smooth regulariza-
tion term, an extremely small α leads to an extremely sparse Λ and an extremely
large α leads to a Λ with almost identical entries. Between two extremas, we ob-
tain suitable solutions. We use polblogs as an example to test. Fig. 7 shows the
NMI value of MOGC with edge, M3 and M2 with α within the range of [0,15]. It
3 3
isshownthattheoptimalαlocateswithin[2,3]. Whenαissmall, i.e., α = 0.1, the
average calculated weights for Λ , Λ and Λ are 0.0969,0.1307, 0.7724.
:,edge :,M3 :,M2
3 3
However, when α is larger, i.e., α = 15, the weight of three motifs are 0.1357,
0.1355, 0.7288, a more smooth solution for Λ would be obtained. This results
validates the setting of α should be neither too small nor too large.
8. Conclusion
In this paper, we propose a multi-order graph clustering model (MOGC) for
higher-order graph clustering. Different from the existing methods, the higher-
order structures and lower-order structures are integrated at the level of node
291
Aedge
1
Aedge
0.5 0.5
0 0
10 20 40 A6 M0
33
80 100 120 60 20 40 A6 M0
33
80 100 120
4
0
2
-1 0
200 20 40 A60 M32 80 100 120 200 20 40 A60 M32 80 100 120
10 10
0 0
0 20 40 60 80 100 120 0 20 40 60 80 100 120
Node id
(a)Theweightofadjacencymatrixfor59thnode (b)Theweightofadjacencymatrixfor1stnode
Figure 5: The weight in adjacency matrix for nodes on polbooks dataset. The red dash
lines are used to separate the nodes from different clusters.
samples with an adaptive weights learning mechanism. The proposed method can
automaticallyadjustthecontributionsofdifferentmotifstoeachnodebytheadap-
tive weights. This approach addresses both the hypergraph fragmentation issue
and improves graph clustering accuracy by integrating information from multiple
motifs at the node level. Extensive experiments have been conducted to show the
effectiveness of proposed method.
InthecurrentMOGCmodel,ouraimistoenhancethegraphclusteringprecise
byintegratinghypergraphstructuresfrommultiplemotifslinearly. Itisinteresting
to explore the nonlinear fusion of multiple motif-based hypergraphs. As a future
research work, we plan to extend the multi-order graph clustering model to in-
corporate graph neural networks (GNNs). This extension would enable GNNs to
achieve superior node representations by integrating higher-order structures from
multiple motifs at the node-level nonlinearly. Consequently, this would lead to
improved performances in node classification and node clustering.
References
[1] U. Von Luxburg, A tutorial on spectral clustering, Statistics and computing
17 (4) (2007) 395–416.
[2] L. Huang, C.-D. Wang, H.-Y. Chao, A harmonic motif modularity approach
for multi-layer network community detection, in: 2018 IEEE International
Conference on Data Mining (ICDM), IEEE, 2018, pp. 1043–1048.
30
thgiew
tnecajdA
thgiew
tnecajdA0.6
0.4
0.2
0
0 20 40 60 80 100 120
1
0.5
0
0 20 40 60 80 100 120
1
0.5
0
0 20 40 60 80 100 120
Node id
Figure 6: The weight Λ of each motif for each node on the polbooks dataset. From top
to bottom, three figures correspond to the weight of edge, motif M3, motif M2 for each
3 3
node respectively.
0.738
0.737
0.736
0.735
0.734
0.733
0.732
0.731
0.73
0.729
0.728
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
Figure 7: Sensitivity of α based on polblogs dataset. Each value is the average value of
20 trials in terms of NMI.
[3] C.E.Tsourakakis,J.Pachocki,M.Mitzenmacher,Scalablemotif-awaregraph
clustering, in: Proceedings of the 26th International Conference on World
Wide Web, 2017, pp. 1451–1460.
[4] A.R.Benson,D.F.Gleich,J.Leskovec,Higher-orderorganizationofcomplex
networks, Science 353 (6295) (2016) 163–166.
[5] P.-Z. Li, L. Huang, C.-D. Wang, J.-H. Lai, Edmot: An edge enhancement
approach for motif-aware community detection, in: Proceedings of the 25th
31
IMN
3M,:
2M,:
egde,:
3
3ACM SIGKDD international conference on knowledge discovery & data min-
ing, 2019, pp. 479–487.
[6] P.-Z.Li,L.Huang,C.-D.Wang,J.-H.Lai,D.Huang,Communitydetectionby
motif-aware label propagation, ACM Transactions on Knowledge Discovery
from Data (TKDD) 14 (2) (2020) 1–19.
[7] R. Milo, S. Shen-Orr, S. Itzkovitz, N. Kashtan, D. Chklovskii, U. Alon, Net-
work motifs: simple building blocks of complex networks, Science 298 (5594)
(2002) 824–827.
[8] P. Pons, M. Latapy, Computing communities in large networks using random
walks, in: International symposium on computer and information sciences,
Springer, 2005, pp. 284–293.
[9] D. Cai, X. He, J. Han, T. S. Huang, Graph regularized nonnegative matrix
factorization for data representation, IEEE transactions on pattern analysis
and machine intelligence 33 (8) (2010) 1548–1560.
[10] F. Wang, C. Zhang, Label propagation through linear neighborhoods, IEEE
Transactions on Knowledge and Data Engineering 20 (1) (2007) 55–67.
[11] B. J. Frey, D. Dueck, Clustering by passing messages between data points,
science 315 (5814) (2007) 972–976.
[12] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, E. Lefebvre, Fast unfolding of
communities in large networks, Journal of statistical mechanics: theory and
experiment 2008 (10) (2008) P10008.
[13] S. Cao, W. Lu, Q. Xu, Deep neural networks for learning graph represen-
tations, in: Proceedings of the AAAI conference on artificial intelligence,
Vol. 30, 2016.
32[14] L. Hagen, A. B. Kahng, New spectral methods for ratio cut partitioning and
clustering, IEEE transactions on computer-aided design of integrated circuits
and systems 11 (9) (1992) 1074–1085.
[15] J.Shi,J.Malik,Normalizedcutsandimagesegmentation,IEEETransactions
on pattern analysis and machine intelligence 22 (8) (2000) 888–905.
[16] A. Arenas, A. Fernandez, S. Fortunato, S. Gomez, Motif-based communities
in complex networks, Journal of Physics A: Mathematical and Theoretical
41 (22) (2008) 224001.
[17] H. Yin, A. R. Benson, J. Leskovec, D. F. Gleich, Local higher-order graph
clustering, in: Proceedings of the 23rd ACM SIGKDD international confer-
ence on knowledge discovery and data mining, 2017, pp. 555–564.
[18] P. Zhao, gsparsify: Graph motif based sparsification for graph clustering, in:
Proceedings of the 24th ACM International on Conference on Information
and Knowledge Management, 2015, pp. 373–382.
[19] P. Li, H. Dau, G. Puleo, O. Milenkovic, Motif clustering and overlapping
clustering for social network analysis, in: IEEE INFOCOM 2017-IEEE Con-
ference on Computer Communications, IEEE, 2017, pp. 1–9.
[20] C.Li, X.Guo, W.Lin, Z.Tang, J.Cao, Y.Zhang, Multiplexnetworkcommu-
nitydetectionalgorithmbasedonmotifawareness,Knowledge-BasedSystems
260 (2023) 110136.
[21] L.Huang,H.-Y.Chao,Q.Xie,Mumod: Amicro-unitconnectionapproachfor
hybrid-order community detection, in: Proceedings of the AAAI conference
on artificial intelligence, Vol. 34, 2020, pp. 107–114.
33[22] X. Wu, C.-D. Wang, P. Jiao, Hybrid-order stochastic block model, in: Pro-
ceedings of the AAAI Conference on Artificial Intelligence, Vol. 35, 2021, pp.
4470–4477.
[23] Y. Gao, X. Yu, H. Zhang, Graph clustering using triangle-aware measures in
large networks, Information Sciences 584 (2022) 618–632.
[24] Y. Ge, P. Peng, H. Lu, Mixed-order spectral clustering for complex networks,
Pattern Recognition 117 (2021) 107964.
[25] X.Wu,C.-D.Wang,J.-Q.Lin,W.-D.Xi,S.Y.Philip,Motif-basedcontrastive
learningforcommunitydetection,IEEETransactionsonNeuralNetworksand
Learning Systems (2024).
[26] M. Jha, C. Seshadhri, A. Pinar, Path sampling: A fast and provable method
for estimating 4-vertex subgraph counts, in: Proceedings of the 24th interna-
tional conference on world wide web, 2015, pp. 495–505.
[27] P. Wang, J. C. Lui, D. Towsley, J. Zhao, Minfer: A method of inferring motif
statistics from sampled edges, in: 2016 IEEE 32nd international conference
on data engineering (ICDE), IEEE, 2016, pp. 1050–1061.
[28] N. Kashtan, S. Itzkovitz, R. Milo, U. Alon, Efficient sampling algorithm for
estimating subgraph concentrations and detecting network motifs, Bioinfor-
matics 20 (11) (2004) 1746–1758.
[29] H. Zhao, X. Xu, Y. Song, D. L. Lee, Z. Chen, H. Gao, Ranking users in social
networks with motif-based pagerank, IEEE Transactions on Knowledge and
Data Engineering 33 (5) (2019) 2179–2192.
[30] G. H. Golub, C. F. Van Loan, Matrix computations, JHU press, 2013.
34[31] A. Ng, M. Jordan, Y. Weiss, On spectral clustering: Analysis and an algo-
rithm, Advances in neural information processing systems 14 (2001).
[32] F. Wang, T. Li, X. Wang, S. Zhu, C. Ding, Community discovery using non-
negative matrix factorization, Data Mining and Knowledge Discovery 22 (3)
(2011) 493–521.
[33] A. Grover, J. Leskovec, node2vec: Scalable feature learning for networks, in:
Proceedings of the 22nd ACM SIGKDD international conference on Knowl-
edge discovery and data mining, 2016, pp. 855–864.
[34] W. M. Rand, Objective criteria for the evaluation of clustering methods,
Journal of the American Statistical association 66 (336) (1971) 846–850.
[35] A. Amelio, C. Pizzuti, Is normalized mutual information a fair measure
for comparing community detection methods?, in: Proceedings of the 2015
IEEE/ACM international conference on advances in social networks analysis
and mining 2015, 2015, pp. 1584–1585.
35