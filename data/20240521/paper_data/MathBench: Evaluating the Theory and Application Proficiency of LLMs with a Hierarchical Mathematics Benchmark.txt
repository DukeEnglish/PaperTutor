MathBench: Evaluating the Theory and Application Proficiency
of LLMs with a Hierarchical Mathematics Benchmark
HongweiLiu1 ZilongZheng1,3 YuxuanQiao1,4 HaodongDuan1 ZhiweiFei1,4
FengzheZhou1 WenweiZhang1 SongyangZhang1,† DahuaLin1,2 KaiChen1,†
1ShanghaiAILaboratory 2TheChineseUniversityofHongKong
3BeihangUniversity 4NanjingUniversity
Abstract
Recentadvancementsinlargelanguagemodels
(LLMs) have showcased significant improve-
ments in mathematics. However, traditional
math benchmarks like GSM8k offer a unidi-
mensionalperspective,fallingshortinprovid-
ing a holistic assessment of the LLMs’ math
capabilities. Toaddressthisgap,weintroduce
MathBench,anewbenchmarkthatrigorously Figure 1: MathBench Overview. MathBench com-
assessesthemathematicalcapabilitiesoflarge prisesmultiplestagesofprogressivelyincreasingchal-
language models. MathBench spans a wide lenges. Eachstageencompassesbilingualtheoretical
range of mathematical disciplines, offering a andapplication-orientedquestions,witheachquestion
detailed evaluation of both theoretical under- preciselytaggedwithathree-levellabeltoindicateits
standingandpracticalproblem-solvingskills. fine-grainedknowledgepoint.
Thebenchmarkprogressesthroughfivedistinct
stages,frombasicarithmetictocollegemath-
ematics, andisstructuredtoevaluatemodels ate text that mirrors human-like discourse and to
at various depths of knowledge. Each stage
unravel intricate mathematical conundrums (Liu
includestheoreticalquestionsandapplication
etal.,2023a).
problems, allowing us to measure a model’s
Despite these advancements, the evaluation of
mathematicalproficiencyanditsabilitytoap-
plyconceptsinpracticalscenarios. MathBench LLMs’ mathematical capabilities remains ham-
aimstoenhancetheevaluationofLLMs’math- pered by some inherent limitations of exist-
ematical abilities, providing a nuanced view ing benchmarks (GSM8k (Cobbe et al., 2021),
of their knowledge understanding levels and MathQA(Amini et al., 2019), etc.). These re-
problem solving skills in a bilingual context.
sourcespredominantlyofferasingularperspective
Theprojectisreleasedathttps://github.
onproblem-solvingabilitiesandlackcomprehen-
com/open-compass/MathBench.
sive difficulty grading. Math (Hendrycks et al.,
1 Introduction 2021b)attemptedtoclassifyhigh-schoolmathcom-
petitionproblemsintovaryinglevelsofcomplexity
Mathematicalreasoningandproblem-solvingrep-
basedonannotators’subjectiveevaluations,offer-
resentpivotalfacetsofhumanintelligenceandhave
ing an incomplete picture of mathematical profi-
captivatedtheinterestofartificialintelligence(AI)
ciency. Such datasets, while valuable, fall short
researchfordecades. Thecapabilityofmachines
in encapsulating the full spectrum of mathemat-
tograsp,interpret,andaddressmathematicalchal-
ical knowledge and overlook the importance of
lenges not only serves as a benchmark for their
fundamentaltheoryunderstanding,whichisessen-
cognitiveprowessbutalsofulfillsacriticalrolein
tial for tackling application problems (Upadhyay
theirdeploymentacrossvarioussectors.
and Chang, 2017). Those limitations make it dif-
TheadventofmodernLargeLanguageModels
ficult to conduct a comprehensive evaluation of
(LLMs) such as OpenAI’s ChatGPT and GPT-4
LLMs’ math capability (both theory and applica-
(Achiametal.,2023)hasmarkedasignificantmile-
tion) across different levels and disciplines and
stone,showcasinganunparalleledabilitytogener-
underamultilingualcontext.
†Correspondingauthors. In response to these challenges, we construct
1
4202
yaM
02
]LC.sc[
1v90221.5042:viXraFigure2: FrameworkofMathBench,Wefirstcategorizethemathematicalcontentintofourmaineducational
stages and one basic arithmetic stage. Then, we extend from these to fill in two more fine-grained levels of
knowledgepoints,formingthefinalMathBenchframework.
MathBench, a novel and comprehensive multilin- dataset that features a five-level difficulty mech-
gualbenchmarkmeticulouslycreatedtoevaluate anismwithahierarchicalknowledgesystem.
themathematicalcapabilitiesofLLMsacrossadi- • MathBenchincludesawidevarietyofquestion
verse range of difficulties, from basic arithmetic types,fromfundamentalmathematicalconceptsto
to challenging college-level mathematics. Math- practicalapplicationinreal-worldscenarios.
Benchsetsitselfapartwithauniquefive-stagetax- • We conduct extensive experiments on Math-
onomy,mappedtotheeducationaltrajectoryfrom Bench across different models to identify bottle-
primary school through to college. This mecha- necksincurrentLLMs. Theprovideddiscussion
nism is designed to assess LLMs’ mathematical andanalysisareexpectedtooffernewavenuesfor
understanding in breadth and depth. The bench- improvingtheirmathematicalcapabilities.
markincorporatescarefullycuratedquestionsthat
coverbasictheoryknowledgeandpracticalappli- 2 Methodology
cations. This dual focus enables MathBench to
MathBenchfeaturesawell-crafteddifficultyhier-
probeandinterpretthemodels’capabilitiesfroma
archy and an emphasis on evaluating the theoret-
foundationalstandpoint. Additionally,MathBench
icalknowledgeunderstandingofLLMs. Sec.2.1
supportsbilingualevaluationinbothChineseand
presents the tiered levels and the corresponding
English,whichfacilitatesamorenuancedandcom-
knowledgefoundations,explainingtheabilitytax-
prehensiveassessmentofLLMs’mathcapabilities,
onomy and design rationale. Sec. 2.2 details the
offering a realistic reflection of the global land-
collectionprocessandstatisticsofMathBench.
scapeofmathematicalknowledge.
Inthispaper,wedetailthemethodologybehind 2.1 TheHierarchicalKnowledgeSystem
thecreationofMathBench,includingthehierarchi-
InMathBench,wedefineaknowledgeframework
cal knowledge system that underpins the dataset,
with five main stages and three levels in order to
thedatacollectionprocess,andthecriteriaforques-
obtainfine-grainedevaluationresults. Amongfive
tionselection. WehopethatMathBenchcanserve
stages, four stages are mapped to the four main
asavaluableresourceforresearchersanddevelop-
educationstages: Primary,Middle,High,andCol-
ersseekingtoadvancethemathematicalabilitiesof
lege, while the other stage is named Arithmetic,
LLMsandtounderstandthelimitationsofexisting
serving as the foundation of the remaining four
modelsinsolvingdiverseandcomplexmathemati-
stages.1 Each Stage in MathBench is associated
calproblems.
withtwofine-grainedknowledgelevels: Subject
MathBenchfeaturesthefollowingcontributions:
1The‘Arithmetic’stageevaluatestheabilitytoperform
• We introduce MathBench, a comprehensive fourbasicmathoperations:add,subtract,multiply,divide.
2Table 1: Overview of Datasets Included in Math- 2.2 DataCollectionandStatistics
Bench. MCQstandsforMulti-ChoiceQuestion.
Withthepre-definedknowledgeframework,wepri-
marilycollectquestionsfromtwoperspectives: (a).
Name DatasetType QuestionType
theoreticalknowledgequestions,totestthemodel’s
GSM-X-CN Self-Collected Open-endedQA
GSM-X-Plus Self-Collected Open-endedQA graspofbasicformulas,theories,andtheircorollar-
CEVAL-Math OpenSource MCQ ies,whicharethefoundationforsolvingmathemat-
MMLU-College-Math OpenSource MCQ
icalproblems;(b). practicalapplicationquestions,
Math401 OpenSource MCQ
which often require a good understanding of the
Hungarian-Math-MCQ Self-Collected MCQ
AMC-8&12 Self-Collected MCQ fundamentaltheories,reflectingtheabilitytoapply
SAT Self-Collected MCQ
thesetheoriesinpractice.
Gaokao Self-Collected MCQ
Zhongkao Self-Collected MCQ
QuestionFormatDefinition. Duringtheevalu-
Kaoyan Self-Collected MCQ
SciBench OpenSource MCQ ation,somemodelsstrugglewithopen-endedques-
Arithmetic-HG OpenSource Open-endedQA tions and fail to follow instructions and provide
Theory-Knowledge-Primary Self-Collected MCQ
plainandconciseanswers. Therefore,wereformu-
Theory-Knowledge-Middle Self-Collected MCQ
Theory-Knowledge-High Self-Collected MCQ late questions that could have complex answers2
Theory-Knowledge-College Self-Collected MCQ intothemultiple-choiceformat,typicallywithfour
options. Duringcollectionandannotation,ween-
suretheuniquenessofthecorrectanswerandthe
AreaandTopic,accordingly. AsshowninFigure2,
highconfusion-levelofdistractiveoptions.
we extend MathBench from the basic stages to a
comprehensiverangeofmathematicalconceptsand TheoreticalKnowledgeQuestions. Fortheoret-
problem-solvingskills. Suchtaxonomyisdesigned icalknowledgequestions,wecollectthedefinition
tocapturethedepthandbreadthofmathematical anddetailedcorollariesofknowledgepointstopic
knowledge,fromfoundationalarithmetictocom- bytopicfromthemathtextbooksandtheInternet.
plex,abstractcollege-levelconcepts. Wethentransformthemtomulti-choicequestions
withhigh-qualityannotations.
SubjectAreasincludemajormathematicaldis-
ciplinessuchasAlgebra,Geometry,Trigonometry, PracticalApplicationQuestions. Onselecting
Calculus, Statistics, Probability, etc.. This cate- the practical application questions, we primarily
gorization allows for a wide range of questions, consider the following aspects: 1. The question
facilitatinganorganizedapproachtocoveringthe needstomatchthecorrespondingeducationlevel;
diverseareasofmathematics. Withineachsubject 2. Thequestionsshouldcomprehensivelycoverthe
area, we further refine the classification into spe- previously defined knowledge taxonomy; 3. The
cific Topics. For example, under Algebra, topics questionsshouldbewell-formulatedsothatLLMs
mightincludeLinearEquations,QuadraticEqua- can answer them properly. We primarily focus
tions,Polynomials,andFunctions. TheTopic-level onstage-basededucationalexamsorcompetitions.
granularityensuresthatthedatasetcanprovidede- Thosequestionsarecomprehensiveandrepresenta-
tailed insights into a model’s understanding and tive,offeringacertaindegreeofdifficultygradient,
proficiencyinspecificareasofmathematics. suchasZhongKao,GaoKaoinChineseMathand
AMC,SATinEnglishmath. Additionally,wein-
In MathBench, each question is tagged with
corporate open-source questions to enhance the
metadata indicating its stage (Primary, Middle,
diversityandbreadthofthequestions. Welistthe
High, College, or Arithmetic), subject area, and
sourcesofquestionsinMathBenchinTable1.
topic. Suchtagsenableafine-grainedanalysisof
models’performanceacrossdifferentareasofmath-
Quality Screening. To enhance the quality
ematicsandallowresearcherstoidentifyspecific
of the MathBench dataset, we implement a semi-
strengthsandweaknessesinmathematicalunder-
automatedquestionfilteringprocesstomitigateis-
standing.
suessuchasintrinsicquestionerrorsandalignment
witheducationalstagesutilizingGPT-4,detailspre-
Moreover,theinclusionoftheArithmeticstage
sentedinAppendixA.3.
emphasizestheimportanceofmasteringbasicmath
operations, which is the foundation of all subse-
2Alltheoreticalknowledgequestionsandpracticalappli-
quentmathematicallearningandproblem-solving. cationquestionsfrommiddleschooltocollegelevel
3Dataset Summary. We curate 3709 questions • OpenSource LLMs: We evaluate a wide spec-
for the final MathBench, including both Chinese trum of LLMs, including Llama3(Touvron et al.,
andEnglishlanguagesacrossfivestageswiththree- 2023), Qwen (Bai et al., 2023), InternLM2
level knowledge taxonomy. This compendium is (Team, 2023a), Yi 8, Baichuan2 (Yang et al.,
divided into two distinct sections: MathBench-T, 2023),DeepSeek(DeepSeek-AIetal.,2024),Mix-
whichconsistsof2,209theoreticalquestions,and tral(Jiangetal.,2024)andChatGLM3(Zengetal.,
MathBench-A,comprising1,500questionsfocused 2022).
onpracticalapplications. Eachquestionhasbeen • OpenSource Math LLMs: Llemma(Azerbayev
subjectedtoarigoroussemi-automatedvettingpro- et al., 2023), MetaMath-llemma(Yu et al.,
cess. Detailed statistics can be found in the Ap- 2023),DeepSeek-Math(Shaoetal.,2024),MAm-
pendixA.1. moTH(Yueetal.,2023)andInternLM2-Math(Ying
etal.,2024).
3 ExperimentsandAnalysis
3.2 MainResults
3.1 Configuration
WeshowcasetheprincipaloutcomesofMathBench
EvaluationProtocols. WeemployCircularEval
in Table 2, detailing the application-oriented as-
(CE) (Liu et al., 2023b) and Perplexity (PPL) as
pectsin(MathBench-A),andthetheoreticalcom-
ourprincipalevaluationmethodologyforChatand
ponentsin(MathBench-T).
Base models respectively. CE systematically as-
sessesanN-optionmulti-choicequestionbyevalu- 3.2.1 MathBench-A
atingitN times,eachtimepermutingtheorderof AmongallmodelsevaluatedintheMathBenchap-
theoptions. plication,GPT-4o(GPT-4o-2024-05-13)achieves
Tomaintainconsistencyinevaluations,westan- thehighestoverallaveragescore, particularlyex-
dardized the maximum output length to 2048 to- celling in the more challenging Middle, High,
kensandemployedagreedydecodingstrategyfor and College stages. Following GPT-4o, Claude-
all Large Language Models (LLMs). For open- 3-OpusandDeepSeek-V2-APIoutperforminba-
ended questions, we utilized a few-shot CoT set- sicarithmeticoperations,specificallyintheArith-
ting,whereasformultiple-choicequestionsonChat metic and Primary stages respectively. For open-
models,weimplementedazero-shotCoTapproach. sourceLLMs,Qwen1.5-110B-Chatstandsoutas
InthecaseofBasemodelsduringPPLevaluation, thebestperformer,distinguishingitselfasthelead-
a few-shot setting was adopted. We used Open- ing player among all open-source models. Ad-
Compass (Contributors, 2023) as the evaluation ditionally, DeepSeek-Math-7B-RL, an LLM de-
frameworkforourassessments. signedformathematicaltasks,securesitsposition
asthetopopen-sourcemodelinmathematics,de-
Evaluated Models. Our evaluation encom-
spiteitsrelativelysmallparametersize.
passesbothclosed-sourcecommercialLLMsand
Amongopen-sourcechatmodels,performances
open-sourceLLMs,coveringmorethan20models.
acrossmodelswith∼7B,∼20B,and∼70Bparam-
BasedonMathBench,wedeliverathoroughevalu-
etersizerevealdistinctcapabilities:
ationofthecapabilitiesofcurrentLLMs. Welist
∼7B Chat Models. InternLM2-Chat-7B and
allevaluatedLLMsbelow:
Llama-3-8B-Instructemergesasthesuperiormodel
•Closed-sourcemodels: GPT-3.5andGPT-43from
at the ∼7B scale and outperforms other 7B Chat
Openai,Qwen-Max4,DeepSeek-V2-API5,GLM46
models across all stages. It’s noteworthy that, as
andAnthropicClaude-3-Opus7.
the difficulty of problems increases, the gap be-
3GPT-4 version: gpt-4-0125-preview and tweenLlama-3-8B-Instructandothermodelsalso
GPT-4o(GPT-4o-2024-05-13); GPT-3.5 version: grows. Forinstance,onthefivestagesfromArith-
gpt-3.5-turbo-0125
metictoCollegeMath,ItoutperformsChatGLM3-
4https://help.aliyun.com/zh/dashscope/
create-a-chat-foundation-model?spm= 6B by 43.95%, 73.17%, 82.48%, 258.49%, and
a2c4g.11186623.0.0.581c64d16b7Azw 723.53%, respectively. The trend indicates that
5https://platform.deepseek.com/
asthedifficultyescalates,theperformancedispar-
api-docs
6https://open.bigmodel.cn/dev/howuse/ ity between models significantly increases since
glm4 higher-stage math problems often involve more
7https://www.anthropic.com/news/
claude-3-family 8https://github.com/01-ai/Yi
4Models Arith Primary Middle High College Avg. Models Primary Middle High College Avg.
★Closed-sourceModels ★Closed-sourceModels
GPT-3.5-Turbo-0125 72.7 72.3 27.3 18.3 14.3 41.0 GPT-3.5-Turbo-0125 70.1 56.7 47.3 52.5 56.7
GLM4 61.7 80.0 55.7 38.7 20.7 51.3 GLM4 88.6 79.5 63.7 60.6 73.1
GPT-4-0125-Preview 76.0 82.3 59.0 41.3 35.3 58.8 GPT-4-0125-Preview 87.2 81.0 72.0 73.3 78.4
Qwen-Max-0428 72.3 86.3 65.0 45.0 27.3 59.2 Claude-3-Opus 86.0 79.0 72.6 77.4 78.7
DeepSeek-V2-API 82.7 89.3 59.0 39.3 29.3 59.9 DeepSeek-V2-API 88.9 83.7 70.3 76.3 79.8
Claude-3-Opus 85.7 85.0 58.0 42.7 43.7 63.0 Qwen-Max-0428 90.4 83.2 73.4 74.8 80.4
GPT-4o-2024-05-13 77.7 87.7 76.3 59.0 54.0 70.9 GPT-4o-2024-05-13 92.2 88.3 82.0 85.6 87.0
♡Open-sourceChatModels ♡Open-sourceChatModels
Yi-6B-Chat 35.3 36.3 7.0 3.0 4.3 17.2 DeepSeek-7B-Chat 33.3 26.0 14.4 13.6 21.8
ChatGLM3-6B 38.0 41.0 13.7 5.3 1.7 19.9 ChatGLM3-6B 41.6 32.4 20.2 12.0 26.6
DeepSeek-7B-Chat 48.3 47.7 8.7 4.3 2.7 22.3 Yi-6B-Chat 48.0 33.5 21.8 23.9 31.8
Qwen-7B-Chat 50.7 50.7 22.0 9.3 6.0 27.7 Qwen-7B-Chat 53.1 43.5 32.9 31.2 40.2
InternLM2-Chat-7B 52.0 66.3 30.0 13.7 8.7 34.1 Llama-3-8B-Instruct 60.2 51.3 43.5 53.6 52.1
Llama-3-8B-Instruct 54.7 71.0 25.0 19.0 14.0 36.7 InternLM2-Chat-7B 67.3 55.8 45.4 42.7 52.8
Baichuan2-13B-Chat 40.0 44.7 13.7 4.7 1.7 20.9 Baichuan2-13B-Chat 45.4 36.9 24.1 21.0 31.9
Yi-34B-Chat 50.7 62.0 23.0 14.7 7.7 31.6 InternLM2-Chat-20B 64.5 56.2 49.9 43.2 53.4
Qwen-14B-Chat 63.7 61.7 39.0 21.0 12.0 39.5 Yi-34B-Chat 70.9 57.0 43.6 46.8 54.6
InternLM2-Chat-20B 62.3 72.7 37.7 24.7 13.0 42.1 Qwen-14B-Chat 71.6 64.0 49.7 49.4 58.7
DeepSeek-67B-Chat 62.0 72.7 33.3 21.3 12.0 40.3 DeepSeek-67B-Chat 78.1 65.7 55.6 64.6 66.0
Qwen-72B-Chat 72.0 71.7 53.7 32.0 19.0 49.7 Llama-3-70B-Instruct 71.4 64.3 62.1 71.2 67.2
Llama-3-70B-Instruct 70.3 86.0 53.0 38.7 34.0 56.4 Qwen-72B-Chat 90.9 80.9 67.1 69.8 77.2
Qwen1.5-110B-Chat 70.3 82.3 64.0 47.3 28.0 58.4 Qwen-1.5-110B-Chat 93.4 85.0 76.5 81.5 84.1
△MathematicalModels △MathematicalModels
MammoTH-7B 27.0 24.3 2.7 1.7 0.7 11.3 MammoTH-7B 11.6 9.1 8.4 6.3 8.8
MammoTH-13B 35.0 43.0 5.0 4.7 5.0 18.5 MammoTH-13B 27.5 18.6 15.0 17.1 19.5
MammoTH-70B 35.7 60.0 11.0 10.7 6.0 24.7 MetaMath-Llemma-7B 36.6 33.5 28.8 25.9 31.2
Metamath-Llemma-7B 51.7 51.0 8.3 8.3 5.0 24.9 MammoTH-70B 58.1 47.1 39.3 44.6 47.3
InternLM2-Chat-Math-7B 53.7 67.0 41.3 18.3 8.0 37.7 InternLM2-Chat-Math-7B 65.6 60.2 51.7 46.5 56.0
DeepSeek-Math-7B-Instruct 61.0 74.0 30.3 24.7 14.3 40.9 DeepSeek-Math-7B-Instruct 73.3 58.4 49.3 50.3 57.8
InternLM2-Chat-Math-20B 58.7 70.0 43.7 24.7 12.7 41.9 InternLM2-Chat-Math-20B 73.2 70.5 60.6 53.0 64.3
DeepSeek-Math-7B-RL 68.0 83.3 44.3 33.0 23.0 50.3 DeepSeek-Math-7B-RL 79.6 72.0 61.3 68.7 70.4
MathBench-A. MathBench-T.
Table2:OverallComparisonofModelsonMathBench-A&T.TheArithmeticandPrimarystageforMathBench-
Tarecombinedbecausetheysharethesametheoryknowledge. Modelsareclassifiedintothreecategoriesaccording
totheirpurposeandorigin. ThemodelnameinboldindicatesthetopperformeramongOpen-sourceorClosed-
sourcemodels,whileanunderlinesignifiestheleadingmodelwithinasimilarparametersizegroup.
complexconceptsandproblem-solvingstrategies, models, such as GPT-4-0125-Preview, in solving
imposinggreaterdemandsonthemodels’compre- applicationproblems(58.4vs58.8).
hensionandreasoningabilities. All∼7Bmodels Focusingonmodelsdedicatedtomathematical
strugglewithadvancedmathematicalproblems,in- tasks,theDeepSeek-Math-7B-RLmodelstandsout
dicatingachallengeinsmoothlyresolvingcomplex foritsadeptnessintacklingapplication-basedques-
questionsforsmall-scaleLLMs. tions across a spectrum of stages, encompassing
∼20B Chat Models. InternLM2-Chat-20B per- basic Primary, High and College math. Remark-
forms the best at the ∼20B scale, followed by ably,itoutstripsnotonlyitscounterparts,butalso
Qwen-14B-Chat. ThoughYi-34B-Chathasamuch thesubstantiallylargerDeepSeek-67B-Chatmodel,
larger parameter size, it lags behind other ∼20B byamarginof24.8%. Thisisparticularlynotewor-
models. Similar to ∼7B models, models around thygiventhattheDeepSeek-Math-7B-RLachieves
∼20Balsostrugglewithmorecomplexmathemati- thissuperiorperformancewithamodelsizenearly
calproblemsattheHighSchoolandCollegestage. one-tenththatoftheDeepSeek-67B-Chat, under-
scoringtheefficiencyandtargetedcapabilityofthe
∼70B Chat Models and Math Models. In the
formerinmathematicalproblem-solvingdomains.
realm of large-scale open-source language mod-
els,asignificantperformancedisparityisevident
3.2.2 MathBench-T
whencomparingmodelsofvaryingsizes. Notably,
the Qwen1.5-110B-Chat model demonstrates ex- In the theoretical segment of MathBench, des-
ceptionalproficiencyinaddressingmathematical ignated as MathBench-T, GPT-4o consistently
applicationproblems. Itsperformancenotonlysur- achieved balanced and exceptional results across
passesthatofotheropen-sourcechat-orientedmod- nearlyalltheoreticalstages. AlthoughQwen-1.5-
els but also eclipses the capabilities of numerous 110B-Chatexhibitedslightlysuperiorperformance
specializedmathematicalmodels. Remarkably,it inthePrimarystage,GPT-4oattainedanaverage
exhibitscomparableeffectivenesstoclosed-source theoreticalscoreof87.0. Thisscorewasthehigh-
5est among all tested Closed-source Models and
Open-sourceChatModels. Whencombinedwith
anapplicationscoreof70.9inMathBench-A,these
resultsindicatethatGPT-4odemonstratesbothbal-
ancedandsuperiorperformanceintheoryandap-
plication on MathBench. This underscores GPT-
4o’sstronggraspoftheoreticalknowledgeandits
proficiencyinapplyingsuchknowledgeeffectively.
AmongothermodelsexceptGPT-4o,theQwen
series models stood out, with Qwen-Max-0428
andQwen1.5-110B-ChatrankingjustbehindGPT-
4o. Notably, in the theoretical stage of Primary,
Figure 3: Scores of Application Problems at Each
Qwen1.5-110B-Chatscoredthehighestamongall
Stage. ModelsexhibitsimilarperformancesinArith-
models with an 93.4 CE score. However, GPT-
meticandPrimarystages,whiledemonstratingaclear
4o’sadvantageliesinhighereducationalstagesor
performancedeclinefromPrimarytoCollegestages.
perhapsmoreadvancedtheoreticalstages. Forex-
ample,inthecollege-leveltheoreticalknowledge
stage,GPT-4oachievedaCEscoreof84.1,which Chatmodels,whichleadstosimilarperformance
is16.9pointshigherthanthebestopen-sourcemath trendsacrossmodelswithinthesamecategory.
model,Deepseek-Math-7B-RL.
Notably, ChatGLM3-6B-Base secures the
Similar to MathBench-A, InternLM2-Chat-7B
second-highestrankinginthe7Bbasemodeleval-
demonstrated robust theoretical capabilities at
uation,outperformingseveralothermodels,includ-
the common 7B stage models. Despite achiev-
ingQwen-7BandMistral-7B-v0.1. However,this
ing similar effectiveness to Llama-3-8B-Instruct,
performance is not mirrored in its Chat model
InternLM2-Chat-7Bexhibitedasignificantlylarger
variant, ChatGLM3-6B, which is surpassed by
leadinthetheoreticalstage,surpassingtheQwen-
Qwen-7B-Chat by 95.2% on MathBench-A and
7B-Chat model by 31.3%. Within the domain of
by104.7%onMathBench-T.Thisdiscrepancyin
mathematicalchatmodels,Deepseek-Math-7B-RL
performancebetweentheChatandBaseversions
continuedtooutperformnumerousmathematical
ofthemodelmaybeattributedtothedifferentfine-
models, achieving superior results in both theory
tuningstrategiesappliedduringthesubsequenttun-
andapplication. Notably,itevensurpassedLlama-
ingphase,whichcouldexplaintheobservedgapin
3-70B-Instructinthetheoreticaldomain.
performance.
Overall, in the tests conducted on MathBench,
there was not a significant rank change between
3.4 DetailedAnalysis
modelsintermsoftheoreticalandapplicationca-
pabilities. That is, models that ranked highly in WithMathBench,wecaneasilyassessthemodel’s
applicationcapabilitiesalsotendedtoperformwell mathematicalcapabilitiesatdifferentgranularities
intheoreticaltests,andviceversa. includingeducationstage,language,subjectarea,
orevenspecifictopicswithquestionsonboththeo-
3.3 EvaluationofBaseModels
riesandapplications. Below,wewilldelvedeeper
The results for the Base models are presented in into the evaluation results and discuss about the
Table 3. Consistency in performance is observed followingquestions:
between the Base models and their Chat model
counterparts,withInternLM2-7Bemergingasthe TheGapbetweenCircularandAccuracyEvalu-
optimalmodelinthe7Bparameterrange. Qwen- ation AcomparisonbetweenCircularEvaluation
14B and Qwen-72B demonstrate superior perfor- (CE) scores and Accuracy (ACC) scores is illus-
mance within their respective parameter classes tratedinFigure4. Asmodelperformanceimproves,
on the MathBench benchmark. For mathemati- the discrepancy between CE and ACC scores be-
caltasks,Deepseek-Math-7B-Base’sresultsalign comesincreasinglynarrow, suggestingthatmore
closelywiththoseseenintheChatmodelevalua- powerfulmodelstendtoprovidemorerobustand
tions,indicatingasignificantcorrelationbetween stable answers in mathematical question answer-
theefficacyofBasemodelsandtheircorresponding ing.
6Models Arith Primary Middle High College Avg. Models Primary Middle High College Avg.
♡Open-sourceBaseModels ♡Open-sourceBaseModels
Llama-2-7B 28.0 9.0 27.0 31.3 31.7 25.4 Llama-2-7B 13.6 5.1 6.8 8.4 8.5
Deepseek-7B-Base 31.0 14.0 26.7 32.3 28.0 26.4 Deepseek-7B-Base 24.2 17.7 12.6 17.9 18.1
Baichuan2-7B-Base 44.0 24.3 31.0 33.7 28.7 32.3 Baichuan2-7B-Base 35.2 30.5 20.1 25.6 27.9
Mistral-7B-v0.1 42.7 30.0 35.0 32.7 35.3 35.1 Qwen-7B 38.0 36.8 24.3 26.1 31.3
Qwen-7B 44.3 46.3 38.0 32.3 36.3 39.5 Mistral-7B-v0.1 39.8 33.4 27.8 45.9 36.7
ChatGLM3-6B-Base 39.7 48.3 43.7 38.0 33.0 40.5 ChatGLM3-6B-Base 53.0 48.6 37.1 37.7 44.1
InternLM2-7B 49.0 63.3 46.7 38.7 38.0 47.1 InternLM2-7B 49.0 45.9 43.6 50.5 47.2
Llama-2-13B 30.0 21.0 30.7 31.7 28.3 28.3 Llama-2-13B 29.9 21.4 17.8 22.8 23.0
Baichuan2-13B-Base 47.7 42.3 36.7 31.7 38.7 39.4 Baichuan2-13B-Base 47.2 41.9 28.5 39.9 39.4
Qwen-14B 52.0 57.7 51.7 39.3 43.7 48.9 InternLM2-20B 52.9 48.7 46.1 54.9 50.6
InternLM2-20B 57.3 70.7 45.3 39.3 37.0 49.9 Qwen-14B 68.4 63.0 52.3 55.7 59.9
Llama-2-70B 44.3 50.3 35.3 34.0 40.7 40.9 Llama-2-70B 48.0 42.9 35.6 53.0 44.9
Mixtral-8x7B-v0.1 55.3 49.7 35.0 34.0 42.3 43.3 Mixtral-8x7B-v0.1 55.5 49.1 46.1 61.4 53.0
Deepseek-67B-Base 45.3 62.7 41.3 40.3 41.7 46.3 Deepseek-67B-Base 65.7 61.9 47.7 59.8 58.8
Qwen-72B 62.3 71.7 62.0 58.0 51.3 61.1 Qwen-72B 84.1 77.5 70.9 77.5 77.5
△MathematicalModels △MathematicalModels
Llemma-7B 41.3 27.3 34.7 41.3 41.0 37.1 Llemma-7B 24.3 26.6 22.7 35.8 27.3
Llemma-34B 44.3 45.0 35.7 34.0 40.3 39.9 InternLM2-Chat-Math-7B 34.4 37.7 34.1 48.4 38.7
InternLM2-Base-Math-7B 46.0 42.0 43.0 35.3 38.7 41.0 Llemma-34B 42.7 45.2 40.9 52.8 45.4
InternLM2-Base-Math-20B 48.0 50.3 46.3 42.0 40.3 45.4 InternLM2-Base-Math-20B 48.7 48.4 46.0 53.2 49.1
Deepseek-Math-7B-Base 58.3 62.0 47.0 47.0 47.7 52.4 Deepseek-Math-7B-Base 62.5 64.5 54.2 67.4 62.1
MathBench-A. MathBench-T.
Table3: OverallComparisonofBaseModelsonMathBenchA&T.TheArithmeticandPrimarystagefor
MathBench-Tarecombinedbecausetheysharethesametheoryknowledge. Modelsareclassifiedintocategories
based on their parameter size and the dataset they were trained on. The model name in bold indicates the top
performerwithinallbasemodels,whileanunderlinesignifiestheleadingmodelwithinasimilarparametersize
group.
How Models’ Scores on Application Problems stages, while the gap is larger in more advanced
VaryAcrossStages? Figure3presentstheaver- stages. For example, comparing to Qwen-72B-
ageperformanceofallaforementionedmodelson Chat,thedifferenceintheoreticalandapplication
applicationquestionsinMathBench. Mostmodels scores (D ,D ) increases from (1.4,8.7) in the
t a
perform reasonably well on Arithmetic and Pri- Middlestageto(6.0,11.7)intheHighstage,and
marymathproblems. However,theireffectiveness finallyto(13.5,23.0)intheCollegestage. More-
drastically declines when it comes to the Middle over, from the Middle stage onwards, there is a
stage or above. Such phenomenon suggests that general trend of decline in both theoretical and
existingmodelsaregoodattasksthatcanbesolved applicationabilitiesofmodels. Comparedtotheo-
throughdirectcomputation,patternrecognition,or reticalscores, thedeclineinapplicationscoresis
memorizingbasicconcepts. However,theyshow- moreserious.
caseinferiorperformancewhensolvingmorecom-
DetailedModelPerformanceforEachTopic In
plexmathproblems.
Figure6indicatingaverageknowledgepointper-
IsThereAGapbetweenTheoryUnderstanding formance,itisevidentthattopicsassociatedwith
and Application Capabilities? Theories serve fundamental mathematical skills—such as ’Unit
as the foundation for addressing the majority of Conversion,’ ’Four Operations,’ and ’Basic Con-
application problems. As illustrated in Figure 7, ceptsofEquations’—registerhigheraveragescores.
wepresentthetrendofLLMsintermsoftheoret- Thissuggeststhatthemajorityofmodelsexhibit
icalandapplicationscoresacrossdifferentstages. a proficient command of simple and elementary
In the Primary stage, the two scores are highly mathematicalquestions.
correlated for most LLMs, with only a few ex- Conversely, topics demanding abstract reason-
ceptions. Amongtop-rankedmodels,Qwen-72B- ing and intricate computations, like ’Double In-
Chatdemonstratesthebesttheoreticalability,while tegrals,’ ’Mathematical Logic,’ and ’Set Theory,’
Claude-3-Opusdemonstratessuperiorapplication showloweraveragescores. Addressingthemathe-
ability. When it comes to more advanced stages, maticalqueriesinthesetopicsmayrequirebespoke
models require better computational and reason- modelanalysisandoptimization. Itiscrucialtopin-
ingcapabilitiestoachievegoodapplicationscores. pointthesourceofinaccuracieswithinthesetopics,
GPT-4 leads in the application track across all whether it be due to a deficit in reasoning ability
7Figure4: CEEvaluationvs. ACCEvaluation. TheACCevaluationqueriesthemodelonceperquestionand
checksforcorrectness,whereastheCE(CircularEval)conductsamorestringentandrobustassessmentbyrolling
outevaluationsfourtimeswithshuffledansweroptions,deemingaquestioncorrectonlyifallattemptsareaccurate.
ThepercentagesdepictedinthefigurerepresenttheperformancedecreaseofmodelsintheCEevaluationcompared
totheACCevaluation.
including Qwen-72B-Chat and DeepSeek-Math-
7B-RL also exhibit significant bilingual capabil-
ities. It’s also noteworthy that among all LLMs
evaluated,mostofthemfeatureamuchlargerper-
formancegapbetweenChineseandEnglish,com-
pared to GPT-4. The detailed result of bilingual
testofMathBenchcanbefoundinAppendixB.3.
EnhancingModelProficiencyinFundamental
Theories: Initial Explorations In an effort to
augmentthemodel’sgraspandapplicationofthe-
Figure 5: Bilingual Comparison on MathBench.
oreticalconceptsinproblem-solvingcontexts,we
showcasingscoresinChinese,English,andtheiraver-
ageforthegraydashedline. TheArithmeticstageisnot embarkedonexploratoryinitiatives,focusingpri-
includebecausetherenoimpactoflanguageinit. marily on two methodologies: Chain of Thought
(CoT)andKnowledgeInfusion.
We selectively sampled 200 questions from
or an unstable grasp of the relevant foundational
MathBench,deliberatelyskewedtowardstheoreti-
theoreticalconcepts.
calreasoningandapplication(withadistributionof
WhichModelPerformsBetterundertheBilin- 40%application-orientedand60%theory-centric
gualScenario? Figure5demonstratesthebilin- questions),toperformancillaryexperimentsonthe
gualcapabilitiesofvariousLLMsonMathBench, Qwen-72B-Chatmodel. Theoutcomes,delineated
indicatingtheimportanceoflinguisticversatilityin inTable4,elucidatetheaccuracyachievedthrough
mathematicaltasksthatdemandanunderstanding differentstrategicapproaches.
ofnuancesinlanguageandmathconceptsacross
differentlanguages. AmongallLLMs,GPT-4leads • Straight: Immediate response without pre-
with the highest bilingual score of 67.1, showing cedingCoT.
a balanced performance between Chinese (65.2)
andEnglish(69.0). ThisdemonstratesGPT-4’sad- • CoT:Responsederivedpost-CoT,servingas
vancedbilingualprocessingabilities. Othermodels MathBench’sstandardevaluativecriterion.
8Average Model Performance Splited by Topic
Unit Conversion 70.5
Four Operations 62.2
Basic Concepts of Equations 62.1
Divisibility of Numbers 57.4
Typical Application Problems 56.7
Understanding Basic Shapes 56.4
Integers and Decimals 56.3
Ratios and Proportions 55.5
Linear Functions 55.4
Basic Concepts of Circles 55.1
Fractions and Percentages 53.9
Basic Concepts of Inequalities 52.9
Linear Equations in Two Variables 51.8
Distribution of Multidimensional Random Variables 50.8
Complex Numbers 49.1
Basic Concepts of Geometry 48.8
Sets and Common Logical Terms 48.5
Numerical Characteristics of Random Variables 47.9
Real Numbers 47.8
Data Collection and Organization 46.5
Fractions 46.5
Polynomials and Factorization 46.0
Eigenvalues and Eigenvectors 44.2
Quadratic Functions 43.6
Basics of Triangles 42.4
Determinants 41.8
Plane Vectors 41.6
Matrices 41.0
Foundations of Probability Theory 40.5
Quadratic Forms 40.2
Distribution of Random Variables 40.0
Quadratic Equations in One Variable 38.9
Systems of Linear Equations 38.2
Equations of Lines and Circles 37.1
Elementary Functions and Their Derivatives 36.7
Random Events and Probability 36.4
Applications of Inequalities 34.4
Vectors 33.7
Linear Equations in One Variable 33.1
Lines and Planes in Space 32.9
Inverse Proportion Functions 32.1
Differential Calculus of Single-Variable Functions 31.9
Differential Calculus of Multivariable Functions 30.3
Trigonometric Functions and Solving Triangles 29.7
Quadrilaterals 28.4
Mathematical Statistics 26.7
Solid Geometry 26.0
Integral Calculus of Single-Variable Functions 26.0
Infinite Series 25.6
Equations of Conic Sections 25.4
Ordinary Differential Equations 24.0
Sequences 22.6
Functions, Limits, Continuity 22.3
Data Analysis 20.1
Integral Calculus of Multivariable Functions 17.7
Double Integrals 15.0
Graph Theory 14.3
Mathematical Logic 12.4
Set Theory 11.4
0 10 20 30 40 50 60 70 80
Figure 6: Average Model Scores with Topics. We average the scores of every Chat model for each topic in
MathBench. Themodelsexcelatbasic-levelproblems,suchassingleUnitConversionandbasicFourOperations,
but as the required reasoning and computational abilities for a topic increase, the performance of the models
graduallydeclines,asobservedintopicslikeDoubleIntegrals,SetTheory,andMathematicalLogic.
• Straight-Knowledge: Immediate response, sources. The experimental data suggests a pro-
preconditionedbytheintegrationofrelevant gressiveenhancementinefficacy: Straight<CoT<
knowledgepointspriortoposingthequestion. Straight-Knowledge<CoT-Knowledge. Thispro-
gression evidences the significant impact of both
• CoT-Knowledge: Responsepost-CoT,facili-
CoTandknowledgepointinfusiononaugmenting
tatedbythepreliminaryinclusionofpertinent
model performance for questions heavily reliant
knowledgepoints.
on theoretical reasoning or practical application,
withtheircombinedutilizationyieldingthemost
Strategy Accuracy(%) favorableoutcomes.
Straight 26.6
4 Discussion
CoT 29.8
Straight-Knowledge 31.3
4.1 HowModelsPerformwithCodeAgenton
CoT-Knowledge 33.4
MathBench
Table4: Comparativeaccuracyofdifferentstrategies. We utilize the external code interpreter and fol-
low the ReAct (Yao et al., 2023) protocol in La-
Knowledge points were meticulously curated gent (Team, 2023b) to evaluate LLMs’ ability
from academic textbooks and instructional re- insolvingmathematicalproblemsofMathBench.
9Figure7: TheoreticalScorevs. AppliedScoreonMathBench. PrimaryandArithmeticareaveragedbecausethey
sharethesametheoryknowledgepoints.
dationalskillformodels,requiresmorethanjustex-
ternaltools. Instead,itnecessitatesexploringmore
effectivewaystoenhancelargelanguagemodels’
understandingandapplicationofmathematicalcon-
cepts.
4.2 EffectofModelSizeonMathCapabilities
Wefoundthatformodelsofdifferentsizeswithin
thesameseries,mostofthemconformtotheScal-
ingLaw(Kaplanetal.,2020)onMathBench. For
example,Qwenseries,MammoTHseries,andYi
Figure8: ModelSizevs. AverageScore. Thecompari-
series have shown steady improvement in their
sonchartofmodelparametersizeversusperformance
MathBenchscoresastheparametersizeincreases,
onMathBenchforselectedrepresentativemodels,with
asshowninFigure8. However,itdoesn’tmeanthat
modelsfromthesameseriesconnectedbylinesofthe
same color. The horizontal red dotted line represents modelswithsmallparametersizescannotachieve
thescoreofGPT-4. goodmathperformance. Forinstance,DeepSeek-
Math-7B demonstrates outstanding performance
onMathBenchandoutperformsmodelswith10x
The results, as depicted in Figure 9, show the parameters,includingDeepSeek-72Bandalarger
comparisonofperformancewithandwithoutthe mathmodelMammoTH-70B.
Code Agent on the Theory and Application sec-
4.3 ErrorAnalysis
tionsofMathBench. Overall,theinclusionofthe
CodeAgentsignificantlyenhancesperformancein In our study, we conduct a comprehensive error
theApplicationsection, especiallyinArithmetic, analysis on a set of 80 theoretical and 100 ap-
where it boosts the performance of InternLM2- plication questions random selected from every
7B-Chat by about 64% (from 53.0 to 87.3). This stages,formodelsselectedacrossdifferentscales,
demonstratesthattheadditionoftheCodeAgent as illustrated in Figure 10. The error categories
cansubstantiallyimprovethemodel’sbasicnumer- areuniformlyobservedacrossallevaluatedmod-
ical calculation capabilities. However, for more els,indicatingcommonchallengesthattranscend
complex problems, such as those in the College specific parameter scales. Our selection of mod-
level Application section, the Code Agent does els includes GPT-3.5, GPT-4, InternLM2-Chat-
not notably improve model capabilities and even 7B,Qwen-14B-Chat,Qwen-72B-Chat,Deepseek-
slightly degrades performance. For theoretical Math-7B-RLandMammoTH-70B.Detailedcases
problems, the Code Agent does not significantly forerroranalysiscanbefoundinAppendixC.2.
enhanceInternLM2-7B-Chat’sperformanceacross Insufficiencyofknowledge. Fortheoreticalques-
variousstagesonMathBench. Thissuggeststhat tions,78%ofmodelerrorsareduetomisconcep-
mathematicaltheoreticalability,asacrucialfoun- tionsaboutmathematicalconcepts,whichnotably
10Figure9: CodeAgentPerformanceonMathBench. WeuseInternLM2-7B-Chatforthecomparisonandthe
resultsaredividedintotwopartswithstages: ApplicationandTheory.
exhibit a greater capacity for critical thinking re-
gardingtheoptionspresented,therebyofferingal-
ternativeanswersthattranscendthelimitationsof
predeterminedchoices.
4.4 ReasoningPath
Analyzing the reasoning paths of various models
acrossmultipledifficultylevelsrevealssignificant
performancedisparities. Wesetabriefdiscussion
Figure10: ResponseErrorAnalysisforBothTheo-
belowandprovidemoredetailedcasesforreason-
reticalandApplicationQuestions. Thepredominant
ingpathanalysisinAppendixC.3.
sourcesoferrorsareafundamentalmisunderstanding
Performance across diverse difficulties. In
oftheconcepts,followedbyincorrectreasoningpaths.
straightforwardscenarios,modelsswiftlysolvethe
problems with direct reasoning and yield logical
emergedasasignificantconcerninseveralmodels. outcomes. Yet,complexissues,markedbydense
Such errors accounted for 49.5% of all mistakes, symbols,vastknowledge,andintricatelinks,neces-
underscoringageneralchallengeingraspingfun- sitatebroaderknowledgenavigation,accentuating
damentalknowledgeandterminology. divergencesindeductivestrategies.
Deficienciesinreasoning. Furthermore,models Reasoningpathsofchatmodelswithdifferent
exhibitedshortcomingsinlogicalreasoning,with parametersizes. Small-scalechatmodelsstrive
33.4% of errors attributed to logically consistent for logical coherence in mathematics, yet may
butflawedreasoningprocesses. Moreover,errors makemistakesduetoknowledgedeficiencies,par-
suchasreasoningthatdeviatedfromtheintended ticularly in symbol interpretation and relational
queryaccountingfor9.6%,underscoredthemod- understanding. Incontrast,large-scalemodelsfea-
els’ limitations in understanding user intentions ture expansive knowledge and nuanced insights,
andprovidingpertinentresponses. Wealsonotice whichenhancesymbolprocessingandminimizing
thaterrorsrelatedtoreasoningincreasedwithtask knowledgegaps. However, evenwithsubstantial
difficulty. parameters,challengesinefficientknowledgeman-
Responselengthlimit. Thoughstatisticallynot agementpersist,occasionallyleadingtoirrelevant
theprimaryerrormode(4.0%),responsesthatex- diversionsanddiminishedreasoningefficacy.
ceededthetokenlimitshedlightonthechallenge Reasoning paths of math models. Specialized
ofreasoningcomplextaskswithinlimitedlength mathmodels,despitethesmallerparametersizes,
andadheringtogiveninstructions. exhibitsuperiormathematicalcomprehensionand
Othercases. Occasionally,modelswillgenerate systematiclogicalreasoning. Theyexcelinapply-
responsesdevoidofanexplicitreasoningprocess, ingmathematicalknowledgeandnotationtoreason
obstructing additional scrutiny. Moreover, mod- throughcomplexproblems.
elsendowedwithenhancedreasoningcapabilities Superlative deductive navigation of Closed-
11sourcemodels. GPT-4standsoutforitseffective tonetal.,2019)expandsthesubjectofmathematics
reasoninganddeepproblemcomprehension. Iten- andthisdatasetcoversabroaderspectrumofmath-
gagesinlogical,coherent,andsuccinctdiscussions, ematics,includingarithmetic,algebra,probability,
adeptly navigate complex reasoning paths, and andcalculus. MATH(Hendrycksetal.,2021b)fea-
managemathematicalsymbolseffectively. GPT-4 turesahigherlevelofcomplexity,comprisingprob-
distinctivelyrecognizesproblemstatementambigu- lemsrangingfromarithmetictocalculus,andaims
ities,showcasingadetailedandnuancedreasoning attestingmodels’capabilitiesinunderstandingand
process. solvingcomplexmathematicalchallenges. While
theseeffortshaveenhancedthediversityofthedata
5 RelatedWork
incertainaspects,theyarelackingindiversityin
otheraspectssuchasquestionformulation(Saxton
Solving math word problems through automated
etal.,2019).
methodshasbeenalong-standingconcernforre-
searchers. Thissectionsummarizesseminalstudies
Integrating mathematical problems with do-
and delineates key evaluation datasets proposed
main knowledge NumGLUE (Mishra et al.,
for assessing mathematical problem-solving ap-
2022) not only assesses the ability of models to
proaches,tracingthefield’sevolutionfromitsori-
solvemathematicalproblemsgivendirectcompu-
ginstothepresentday.
tational expressions, but it also designs multiple
PreliminaryMathematicalDatasets Previous taskstocomprehensivelyevaluatethemodels’abil-
works proposed datasets such as Alg514 (Kush- itiestouseotherreasoningskills,suchascommon
man et al., 2014), SingleEq (Koncel-Kedziorski sense and reading comprehension. Lila (Mishra
etal.,2015),andDRAW-1K(UpadhyayandChang, etal.,2023)isdevelopedthroughtheextensionof
2017)areprimarilyconcentratedonelementarylin- 20datasetsthatcoverabroadrangeofmathemat-
ear algebraic problems. Similarly, datasets like ical topics. This dataset exhibits varying degrees
AddSub(Hosseinietal.,2014)andSingleOp(Roy oflinguisticcomplexityandfeaturesdiverseques-
etal.,2015)MultiArith(RoyandRoth,2016)are tionformatsaswellasbackgroundknowledgere-
exclusivelydedicatedtofundamentalarithmeticop- quirements. Theseworksinspireustodesignmore
erations: addition,subtraction,multiplication,and diversifiedtestingscenarios.
division. These datasets are very limited both in
6 Conclusion
theformandcontentoftheirassessments,focusing
solelyonaspecificsmallpartofbasicmathematics.
In summary, MathBench adopts structured ap-
Benchmarks tailored to specific educational proaches to categorize questions by stage and
tiers Some benchmarks are designed based on knowledgelevel. Itaimstoprovideacomprehen-
educational levels. Math23k (Wang et al., 2017) siveevaluationofLLMs’mathematicalproficiency.
collects a corpus of real math word problems for Bycoveringawiderangeofsubjectareasandtop-
elementaryschoolstudents. WhileASDiv(Miao ics across educational stages, MathBench offers
etal.,2021)expandsthetextualpatternstoencom- a unique resource for researchers and educators
passmostproblemtypesfoundinelementarymath- interested in advancing the field of mathematical
ematics. GSM8K(Cobbeetal.,2021)presentsa learningandassessment.
high-qualitycollectionofelementarymathematical
7 Limitations
word problems that, on average, require multiple
stepstosolveandprovidesolutionsinnaturallan-
We have developed a comprehensive mathemati-
guage annotations. These datasets mostly focus
calevaluationbenchmark,MathBench,whichin-
on elementary mathematics and seldom examine
cludesadetailedknowledgeframeworkandmulti-
college-levelknowledge.
dimensional,fine-grainedmathematicalquestions.
Enriching the diversity of mathematical prob- Despiteitsstrengths,thebenchmarkcurrentlyhas
lemtypeswithinbenchmarks MathQA(Amini several limitations, which are summarized as fol-
et al., 2019) seeks to categorize problems from lows:
AQuA(Lingetal.,2017)intodifferentmathemati- DataSource: Toenhancediversity,someques-
caldomainsbasedonthefrequencyofmathemati- tions were sourced from open-source datasets(∼
calterminologyused. MathematicsDataset(Sax- 19%). However,theseopen-sourcequestionsmay
12besubjecttodatacontamination,whichcouldcom- DiogoAlmeida,JankoAltenschmidt,SamAltman,
promisetheassurancethatmodelshavenotbeen ShyamalAnadkat,etal.2023. Gpt-4technicalreport.
arXivpreprintarXiv:2303.08774.
exposed to these questions before. In future iter-
ations, we plan to automate the construction of Aida Amini, Saadia Gabriel, Peter Lin, Rik Koncel-
questionsacrossvariousstagestomoreeffectively Kedziorski, Yejin Choi, and Hannaneh Hajishirzi.
testthemodels’genuinemathematicalcapabilities. 2019. Mathqa: Towards interpretable math word
problemsolvingwithoperation-basedformalisms.
LackofDetailedReasoningPaths: Giventhe
diversityofquestionsandtimeconstraints,Math- ZhangirAzerbayev,HaileySchoelkopf,KeiranPaster,
Benchcurrentlydoesnotprovidedetailedreason- Marco Dos Santos, Stephen McAleer, Albert Q.
Jiang,JiaDeng,StellaBiderman,andSeanWelleck.
ingpathsforeachquestion. Thislimitationmakes
2023. Llemma: Anopenlanguagemodelformathe-
it challenging to unlock the full potential of the
matics.
questions. Movingforward,weaimtoinvestigate
semi-automatedmethodstoofferbothnaturallan- JinzeBai,ShuaiBai,YunfeiChu,ZeyuCui,KaiDang,
XiaodongDeng,YangFan,WenbinGe,YuHan,Fei
guage and code-based reasoning approaches for
Huang, et al. 2023. Qwen technical report. arXiv
each question, thereby maximizing the value of
preprintarXiv:2309.16609.
MathBench’squestions.
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
8 EthicalConsiderations MarkChen,HeewooJun,LukaszKaiser,Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
Forourbenchmarks,wereliedonreferencemate- Nakano, Christopher Hesse, and John Schulman.
rialsandclosed-sourcemodelsthatareaccessible 2021. Training verifiers to solve math word prob-
lems. CoRR,abs/2110.14168.
tothepublic,therebyavoidinganypotentialharm
to individuals or groups. The data produced by
OpenCompass Contributors. 2023. Opencompass: A
theLLMsunderwentameticuloushumanselection universalevaluationplatformforfoundationmodels.
and processing phase to ensure the protection of https://github.com/open-compass/
opencompass.
privacy and confidentiality. We did not use any
personally identifiable information, and all data DeepSeek-AI, :, Xiao Bi, Deli Chen, Guanting
were anonymized prior to analysis. Additionally, Chen,ShanhuangChen,DamaiDai,ChengqiDeng,
we employed ChatGPT and Grammarly to refine Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu,
Huazuo Gao, Kaige Gao, Wenjun Gao, Ruiqi Ge,
ourmanuscript’slanguage.
Kang Guan, Daya Guo, Jianzhong Guo, Guangbo
Hao, Zhewen Hao, Ying He, Wenjie Hu, Panpan
9 Acknowledgements
Huang, Erhang Li, Guowei Li, Jiashi Li, Yao Li,
Y. K. Li, Wenfeng Liang, Fangyun Lin, A. X. Liu,
WethanktheOpenCompassteamfortheirdiligent
Bo Liu, Wen Liu, Xiaodong Liu, Xin Liu, Yiyuan
effortsindatacollectionandvalidation,whichen-
Liu,HaoyuLu,ShanghaoLu,FuliLuo,ShirongMa,
suredthequalityandcompletionofthiswork. We XiaotaoNie,TianPei,YishiPiao,JunjieQiu,HuiQu,
extendourspecialthankstoJiayeGeforproviding Tongzheng Ren, Zehui Ren, Chong Ruan, Zhangli
Sha, Zhihong Shao, Junxiao Song, Xuecheng Su,
comprehensivesupportonthisproject,orchestrat-
JingxiangSun,YaofengSun,MinghuiTang,Bingx-
ing the data collection process, and ensuring the
uanWang,PeiyiWang,ShiyuWang,YaohuiWang,
timelydeliveryofthedataset. WealsothankOpen- YongjiWang,TongWu,Y.Wu,XinXie,ZhendaXie,
DataLabforprovidingdatasourcesforpartofthis Ziwei Xie, Yiliang Xiong, Hanwei Xu, R. X. Xu,
work. OurgratitudeextendstoMoLiforhissug- YanhongXu,DejianYang,YuxiangYou,Shuiping
Yu,XingkaiYu,B.Zhang,HaoweiZhang,Lecong
gestionsonthemodificationsofsomechartsinthe
Zhang, LiyueZhang, MingchuanZhang, Minghua
paper, as well as Kuikun Liu for the Lagent sup- Zhang, Wentao Zhang, Yichao Zhang, Chenggang
port. ChuyuZhangandJingmingZhuoprovided Zhao, Yao Zhao, Shangyan Zhou, Shunfeng Zhou,
valuableadviceonthewritingofthepaper. QihaoZhu,andYuhengZou.2024. Deepseekllm:
Scalingopen-sourcelanguagemodelswithlongter-
ThisworkwassupportedbyNationalKeyR&D
mism.
ProgramofChina2022ZD0161600andShanghai
PostdoctoralExcellenceProgram2022235. ConghuiHe,WeiLi,ZhenjiangJin,BinWang,Chao
Xu,andDahuaLin.2022. Opendatalab: Empower-
inggeneralartificialintelligencewithopendatasets.
References https://opendatalab.com.
JoshAchiam,StevenAdler,SandhiniAgarwal,Lama DanHendrycks,CollinBurns,StevenBasart,AndyZou,
Ahmad, Ilge Akkaya, Florencia Leoni Aleman, MantasMazeika,DawnSong,andJacobSteinhardt.
132021a. Measuringmassivemultitasklanguageunder- Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih Su.
standing. 2021. Adiversecorpusforevaluatinganddeveloping
englishmathwordproblemsolvers.
DanHendrycks,CollinBurns,SauravKadavath,Akul
Arora, Steven Basart, Eric Tang, Dawn Song, and SwaroopMishra,MatthewFinlayson,PanLu,Leonard
JacobSteinhardt.2021b. Measuringmathematical Tang,SeanWelleck,ChittaBaral,TanmayRajpuro-
problemsolvingwiththemathdataset. CornellUni- hit,OyvindTafjord,AshishSabharwal,PeterClark,
versity-arXiv,CornellUniversity-arXiv. and Ashwin Kalyan. 2023. Lila: A unified bench-
markformathematicalreasoning.
MohammadJavadHosseini,HannanehHajishirzi,Oren
Etzioni,andNateKushman.2014. Learningtosolve Swaroop Mishra, Arindam Mitra, Neeraj Varshney,
arithmeticwordproblemswithverbcategorization. BhavdeepSachdeva,PeterClark,ChittaBaral,and
InProceedingsofthe2014ConferenceonEmpirical
AshwinKalyan.2022. Numglue: Asuiteoffunda-
MethodsinNaturalLanguageProcessing(EMNLP).
mentalyetchallengingmathematicalreasoningtasks.
Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei
SubhroRoyandDanRoth.2016. Solvinggeneralarith-
Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu,
meticwordproblems.
Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu,
Maosong Sun, and Junxian He. 2023. C-eval: A SubhroRoy,TimVieira,andDanRoth.2015. Reason-
multi-levelmulti-disciplinechineseevaluationsuite ingaboutQuantitiesinNaturalLanguage. Transac-
forfoundationmodels. tionsoftheAssociationforComputationalLinguis-
tics,3:1–13.
Albert Q. Jiang, Alexandre Sablayrolles, Antoine
Roux, Arthur Mensch, Blanche Savary, Chris
David Saxton, Edward Grefenstette, Felix Hill, and
Bamford, Devendra Singh Chaplot, Diego de las
PushmeetKohli.2019. Analysingmathematicalrea-
Casas, Emma Bou Hanna, Florian Bressand, Gi-
soningabilitiesofneuralmodels.
anna Lengyel, Guillaume Bour, Guillaume Lam-
ple, Lélio Renard Lavaud, Lucile Saulnier, Marie- Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu,
AnneLachaux,PierreStock,SandeepSubramanian, JunxiaoSong, MingchuanZhang, Y.K.Li, Y.Wu,
Sophia Yang, Szymon Antoniak, Teven Le Scao, andDayaGuo.2024. Deepseekmath: Pushingthe
Théophile Gervet, Thibaut Lavril, Thomas Wang, limitsofmathematicalreasoninginopenlanguage
TimothéeLacroix,andWilliamElSayed.2024. Mix- models.
tralofexperts.
InternLMTeam.2023a. Internlm: Amultilinguallan-
JaredKaplan,SamMcCandlish,TomHenighan,TomB.
guagemodelwithprogressivelyenhancedcapabili-
Brown,BenjaminChess,RewonChild,ScottGray,
ties.
AlecRadford,JeffreyWu,andDarioAmodei.2020.
Scalinglawsforneurallanguagemodels. LagentDeveloperTeam.2023b. Lagent: InternLMa
lightweightopen-sourceframeworkthatallowsusers
Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish
toefficientlybuildlargelanguagemodel(llm)-based
Sabharwal, Oren Etzioni, and Siena Dumas Ang.
agents. https://github.com/InternLM/
2015. Parsing algebraic word problems into equa-
lagent.
tions. TransactionsoftheAssociationforComputa-
tionalLinguistics,3:585–597.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Nate Kushman, Yoav Artzi, Luke Zettlemoyer, and
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Regina Barzilay. 2014. Learning to automatically
Bhosale, et al. 2023. Llama 2: Open founda-
solvealgebrawordproblems. InProceedingsofthe
tion and fine-tuned chat models. arXiv preprint
52ndAnnualMeetingoftheAssociationforCompu-
arXiv:2307.09288.
tationalLinguistics(Volume1: LongPapers),pages
271–281.
Shyam Upadhyay and Ming-Wei Chang. 2017. An-
WangLing,DaniYogatama,ChrisDyer,andPhilBlun- notatingderivations: Anewevaluationstrategyand
som.2017. Programinductionbyrationalegenera- datasetforalgebrawordproblems.
tion: Learningtosolveandexplainalgebraicword
XiaoxuanWang,ZiniuHu,PanLu,YanqiaoZhu,Jieyu
problems. arXivpreprintarXiv:1705.04146.
Zhang, Satyen Subramaniam, Arjun R. Loomba,
Wentao Liu, Hanglei Hu, Jie Zhou, Yuyang Ding, Shichang Zhang, Yizhou Sun, and Wei Wang.
Junsong Li, Jiayi Zeng, Mengliang He, Qin Chen, 2024. Scibench: Evaluatingcollege-levelscientific
BoJiang,AiminZhou,andLiangHe.2023a. Mathe- problem-solvingabilitiesoflargelanguagemodels.
maticallanguagemodels: Asurvey.
Yan Wang, Xiaojiang Liu, and Shuming Shi. 2017.
Yuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li, Deepneuralsolverformathwordproblems. InPro-
Songyang Zhang, Wangbo Zhao, Yike Yuan, Jiaqi ceedingsofthe2017ConferenceonEmpiricalMeth-
Wang,ConghuiHe,ZiweiLiu,KaiChen,andDahua odsinNaturalLanguageProcessing,pages845–854,
Lin.2023b. Mmbench: Isyourmulti-modalmodel Copenhagen, Denmark. Association for Computa-
anall-aroundplayer? tionalLinguistics.
14Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Table5: DetailedCompositionoftheMathBench
Zhang,ChaoYin,ChenxuLv,DaPan,DianWang,
Dong Yan, Fan Yang, et al. 2023. Baichuan 2: Stage Type English Chinese Total
Open large-scale language models. arXiv preprint
Theoretical - - -
arXiv:2309.10305. Arithmetic
Application 300 - 300
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Theoretical 109 208 317
Primary
Shafran,KarthikNarasimhan,andYuanCao.2023. Application 150 150 300
React: Synergizingreasoningandactinginlanguage
Theoretical 175 334 509
models. Middle
Application 150 150 300
HuaiyuanYing,ShuoZhang,LinyangLi,ZhejianZhou,
Theoretical 281 470 751
YunfanShao,ZhaoyeFei,YichuanMa,JiaweiHong, High
Application 150 150 300
KuikunLiu,ZiyiWang,YudongWang,ZijianWu,
ShuaibinLi,FengzheZhou,HongweiLiu,Songyang Theoretical 316 316 632
College
Zhang,WenweiZhang,HangYan,XipengQiu,Jiayu Application 150 150 300
Wang, Kai Chen, and Dahua Lin. 2024. Internlm-
math: Openmathlargelanguagemodelstowardveri-
fiablereasoning. entitynamesundertheChinesecontextwhileen-
suringthatthequestions’meaningsremainedun-
Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu,
ZhengyingLiu,YuZhang,JamesT.Kwok,Zhenguo changed. This process creates elementary-level
Li, Adrian Weller, and Weiyang Liu. 2023. Meta- questionssuitableforChineseQ&A.
math: Bootstrapyourownmathematicalquestions
FortheGSM-X-Plusdataset,whichisinEnglish,
forlargelanguagemodels.
wegeneratenewquestionsbyfirstgeneratingsolu-
Zheng Yuan, Hongyi Yuan, Chuanqi Tan, Wei Wang, tioncodefortheoriginaltestsetquestions. Wethen
andSongfangHuang.2023. Howwelldolargelan- replacesomenumericparameters(takenfromthe
guagemodelsperforminarithmetictasks?
originalquestions)inthequestionwithmultiplesof
thevariablek. Byexecutingthemodifiedsolution
XiangYue,XingweiQu,GeZhang,YaoFu,Wenhao
Huang, Huan Sun, Yu Su, and Wenhu Chen. 2023. code,weobtainthenewanswers. InMathBench,
Mammoth: Buildingmathgeneralistmodelsthrough wesetk ∈ (2,10).
hybridinstructiontuning.
ForexamssuchasAMC,GaoKao,ZhongKao,
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,
etc.,weinitiallycollectrelevantquestionsfromthe
Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Internet. Thesequestionsarethenunderwentpro-
Wendi Zheng, Xiao Xia, et al. 2022. Glm-130b: cessingandannotationbydomainexperts. Ques-
Anopenbilingualpre-trainedmodel. arXivpreprint
tions for primary and secondary education levels
arXiv:2210.02414.
are handled and annotated by undergraduate stu-
A MathBenchStatistics dents, whilequestionsforuniversity-levelexams
wereprocessedandannotatedbygraduatestudents
A.1 DatasetStatistics specializing in mathematics or computer science.
ThedetailedstatisticsofMathBenchquestions,Ta- The description of knowledge-based questions is
ble 5 for the data distribution of theoretical and providedinSec.2.2.
applicationquestionsacrossvariousstages,Table6 In addition to the self-collected datasets de-
forfine-grainedknowledgelevels. scribed above, we also incorporate questions
from the following open-source datasets: CE-
A.2 Datacollectiondetails VAL (Huang et al., 2023), MMLU (Hendrycks
Forself-collectedquestionsinMathBench,Wepri- et al., 2021a), Arithmetic-HG, Math401 (Yuan
marilycollectthroughthefollowingmethods: etal.,2023)andSciBench(Wangetal.,2024). We
For the Primary stage GSM-X-CN and GSM- download the data from OpenDataLab (He et al.,
X-Plus datasets, we semi-automatically generate 2022). Allopen-sourcedatasetsweusedareMIT
newquestionsusingGPT-4. Specifically,thecon- License.
structionoftheGSM-X-CNChinesequestionset
A.3 QualityScreening
involvedtwosteps:
We first translate English questions in GSM8k Given the wide variety of sources and types of
test set into Chinese using GPT-4, resulting in a questions,wenoticethatthefollowingissuesmay
Chinese version of GSM8k. We then replace the affect the benchmark quality: 1. Intrinsic errors
15Table6: MathBenchSubjectAreaStatistics. DataisshownattheSubjectArealevelforconciseness,omittingthe
moredetailedTopiclevelduetoitsbreadth.
Stage SubjectArea English Chinese Total
IntroductiontoNumbersandAlgebra 44 73 117
Primary&Arith. IntroductiontoGeometry 10 62 72
ComprehensiveApplication 55 73 128
BasicNumbersandAlgebra 133 182 315
Middle BasicGeometry 33 137 170
BasicProbabilityandStatistics 9 15 24
IntermediateNumbersandAlgebra 146 189 335
High IntermediateGeometry 114 219 333
IntermediateProbabilityandStatistics 21 62 83
AdvancedMathematics 119 119 238
College LinearAlgebra 99 99 198
ProbabilityandStatistics 98 98 196
in the questions, such as being unanswerable or C ExtraAnalysis
havingmultiplecorrectanswers. 2. Questionsof
C.1 PromptsDemonstration
lowevaluationvalue,toodifficultortootrivialfor
theintendededucationstage. Please refer to the respective prompt block for a
All of the above situations can easily lead to detaileddemonstration.
unstablemodelresponsesandincreasedprobability
C.1.1 EnglishOpen-endedtest
of incorrect answers in CircularEval. To address
The corresponding prompt is presented in Fig-
these issues, we employ a novel semi-automated
ure21.
questionfilteringapproachforqualityscreening.
Specifically,weuseGPT-4toperformCircular C.1.2 ChineseOpen-endedtest
Evaluation (CE) on all questions. We then select
The corresponding prompt is presented in Fig-
questionsthatGPT-4answeredincorrectly0,1,or
ure22.
2 times out of four attempts (CE − 0, CE − 1,
CE −2)formanualreviewtoensuretheoverall C.1.3 Englishsinglechoicewithreasoning
questionquality. The corresponding prompt is presented in Fig-
ure23.
B DetailedExperimentalResults
C.1.4 Chinesesinglechoicewithreasoning
B.1 OverallResults
The corresponding prompt is presented in Fig-
The overall experimental results for chat models ure24.
are shown in Table 7, and Table 8 for base mod-
C.2 ErrorTypesDemonstration
els. Wereporttheaveragescoreoftheoreticaland
applicationquestionsforstagesexceptArithmetic, Please refer to the respective cases for a detailed
whichispredominantlyindicativeofpurecompu- errortypesdemonstration.
tationalprowess.
C.2.1 Misunderstandingsofconcepts
B.2 RESULTS WITH ACCURACY ThecorrespondingcaseispresentedinFigure12.
ThedetailedaccuracyresultsarepresentedinTa- C.2.2 Flawedreasoning
ble9.
ThecorrespondingcaseispresentedinFigure13.
B.3 BILINGUAL C.2.3 Misalignedwiththequestion
ThecorrespondingresultsispresentedinTable10. ThecorrespondingcaseispresentedinFigure14.
16Table 7: Overall Comparison of Chat Models on MathBench. Models are classified into three categories
accordingtotheirpurposeandorigin. ThemodelnameinboldindicatesthetopperformeramongOpen-sourceor
Closed-sourcemodels,whileanunderlinesignifiestheleadingmodelwithinasimilarparametersizegroup.
Models Arith Primary Middle High College Avg.
★Closed-sourceModels
GPT-3.5-Turbo-0125 72.7 71.2 42.0 32.8 33.4 48.8
GLM4 61.7 84.3 67.6 51.2 40.6 62.2
GPT-4-0125-Preview 76.0 84.8 70.0 56.7 54.3 68.6
Qwen-Max-0428 72.3 88.4 74.1 59.2 51.1 69.8
DeepSeek-V2-API 82.7 89.1 71.4 54.8 52.8 69.9
Claude-3-Opus 85.7 85.5 68.5 57.6 60.5 70.9
GPT-4o-2024-05-13 77.7 89.9 82.3 70.5 69.8 79.0
♡Open-sourceChatModels
DeepSeek-7B-Chat 48.3 40.5 17.4 9.4 8.1 22.1
ChatGLM3-6B 38.0 41.3 23.0 12.8 6.8 23.2
Yi-6B-Chat 35.3 42.2 20.3 12.4 14.1 24.5
Qwen-7B-Chat 50.7 51.9 32.7 21.1 18.6 33.9
InternLM2-Chat-7B 52.0 66.8 42.9 29.5 25.7 43.5
Baichuan2-13B-Chat 40.0 45.0 25.3 14.4 11.4 26.4
Yi-34B-Chat 50.7 66.5 40.0 29.1 27.3 43.1
Llama-3-8B-Instruct 54.7 65.6 38.1 31.2 33.8 44.4
InternLM2-Chat-20B 62.3 68.6 46.9 37.3 28.1 47.8
Qwen-14B-Chat 63.7 66.6 51.5 35.4 30.7 49.1
DeepSeek-67B-Chat 62.0 75.4 49.5 38.5 38.3 53.1
Llama-3-70B-Instruct 70.3 78.7 58.7 50.4 52.6 61.8
Qwen-72B-Chat 72.0 81.3 67.3 49.6 44.4 63.4
Qwen1.5-110B-Chat 70.3 87.9 74.5 61.9 54.7 71.2
△MathematicalModels
MammoTH-7B 27.0 17.9 5.9 5.0 3.5 10.1
MammoTH-13B 35.0 35.2 11.8 9.9 11.0 19.0
Metamath-Llemma-7B 51.7 43.8 20.9 18.6 15.5 28.0
MammoTH-70B 35.7 59.1 29.1 25.0 25.3 36.0
InternLM2-Chat-Math-7B 53.7 66.3 50.8 35.0 27.3 46.8
DeepSeek-Math-7B-Instruct 61.0 73.7 44.4 37.0 32.3 49.3
InternLM2-Chat-Math-20B 58.7 71.6 57.1 42.6 32.8 53.1
DeepSeek-Math-7B-RL 68.0 81.5 58.2 47.2 45.8 60.4
C.2.4 Exceedmaxoutlength C.3.2 Large-scalechatmodel
ThecorrespondingcaseispresentedinFigure15. ThecorrespondingcaseispresentedinFigure19.
C.3.3 Mathmodel
C.2.5 ResponsesconstrainedtoOptions
ThecorrespondingcaseispresentedinFigure20.
ThecorrespondingcaseispresentedinFigure16.
C.2.6 Non-adherencetotheprompt
ThecorrespondingcaseispresentedinFigure17.
C.3 ReasoningPathsDemonstration
C.3.1 Small-scalechatmodel
ThecorrespondingcaseispresentedinFigure18.
17Table8: OverallComparisonofBaseModelsonMathBench. Modelsareclassifiedintocategoriesbasedontheir
parametersizeandthedatasettheyweretrainedon. Themodelnameinboldindicatesthetopperformerwithinall
basemodels,whileanunderlinesignifiestheleadingmodelwithinasimilarparametersizegroup.
Models Arithmetic Primary Middle High College Average
♡Open-sourceBaseModels
Llama-2-7B 28.0 11.3 16.1 19.1 20.0 18.9
Deepseek-7B-Base 31.0 19.1 22.2 22.5 22.9 23.5
Baichuan2-7B-Base 44.0 29.8 30.8 26.9 27.2 31.7
Qwen-7B 44.3 42.2 37.4 28.3 31.2 36.7
ChatGLM3-6B-Base 39.7 50.7 46.1 37.5 35.3 41.9
InternLM2-7B 49.0 56.1 46.3 41.2 44.2 47.4
Llama-2-13B 30.0 25.4 26.1 24.7 25.6 26.4
Baichuan2-13B-Base 47.7 44.8 39.3 30.1 39.3 40.2
InternLM2-20B 57.3 61.8 47.0 42.7 46.0 51.2
Qwen-14B 52.0 63.0 57.4 45.8 49.7 53.6
Llama-2-70B 44.3 49.2 39.1 34.8 46.8 42.9
Mixtral-8x7B-v0.1 55.3 52.6 42.1 40.1 51.9 48.4
Deepseek-67B-Base 45.3 64.2 51.6 44.0 50.7 51.2
Qwen-72B 62.3 77.9 69.8 64.4 64.4 67.8
△MathematicalModels
Llemma-7B 41.3 25.8 30.7 32.0 38.4 33.6
InternLM2-Base-Math-7B 46.0 38.2 40.4 34.7 43.2 40.6
Llemma-34B 44.3 43.8 40.4 37.4 46.6 42.5
InternLM2-Base-Math-20B 48.0 49.5 47.3 44.0 46.8 47.1
Deepseek-Math-7B-Base 58.3 62.3 55.7 50.6 57.5 56.9
18Table9:OverallComparisonwithAccuracyonMathBench.Modelsareclassifiedintothreecategoriesaccording
totheirpurposeandorigin.
Models Arithmetic Primary Middle High College Average
★Closed-sourceModels
GPT-3.5-Turbo-0125 74.8 71.8 79.5 85.3 85.3 77.9
Claude-3-Opus 83.8 85.2 90.0 87.2 86.0 86.4
DeepSeek-V2-API 83.9 82.0 89.1 90.5 89.7 87.0
GLM4 83.9 81.3 92.2 91.5 93.7 88.5
GPT-4-0125-Preview 91.1 86.4 91.4 92.4 92.7 90.3
Qwen-Max-0428 88.0 87.5 92.9 94.8 87.5 90.8
GPT-4o-2024-05-13 91.9 91.5 93.7 96.2 94.0 93.3
♡Open-sourceChatModels
DeepSeek-7B-Chat 48.3 40.5 17.4 9.4 8.1 22.1
Yi-6B-Chat 35.7 41.3 23.0 12.8 6.8 23.2
Qwen-7B-Chat 50.7 51.9 32.7 21.1 18.6 33.9
InternLM2-Chat-7B 52.0 66.8 42.9 29.5 25.7 43.5
ChatGLM3-6B 41.0 53.2 51.2 38.9 34.0 43.7
Llama-3-8B-Instruct 54.7 65.6 38.1 31.2 33.8 44.4
Baichuan2-13B-Chat 40.0 45.0 25.3 14.4 11.4 26.4
Yi-34B-Chat 50.7 66.5 40.0 29.1 27.3 43.1
InternLM2-Chat-20B 62.3 68.6 46.9 37.3 28.1 47.8
Qwen-14B-Chat 63.7 66.6 51.5 35.4 30.7 49.1
DeepSeek-67B-Chat 62.0 75.4 49.5 38.5 38.3 53.1
Llama-3-70B-Instruct 70.3 78.7 58.7 50.4 52.6 61.8
Qwen-72B-Chat 72.0 81.3 67.3 49.6 44.4 63.4
Qwen1.5-110B-Chat 70.3 87.9 74.5 61.9 54.7 71.2
△MathematicalModels
MammoTH-7B 27.0 17.9 5.9 5.0 3.5 10.1
MammoTH-13B 35.0 35.2 11.8 9.9 11.0 19.0
Metamath-Llemma-7B 51.7 43.8 20.9 18.6 15.5 28.0
MammoTH-70B 35.7 59.1 29.1 25.0 25.3 36.0
InternLM2-Chat-Math-7B 53.7 66.3 50.8 35.0 27.3 46.8
DeepSeek-Math-7B-Instruct 61.0 73.7 44.4 37.0 32.3 49.3
InternLM2-Chat-Math-20B 58.7 71.6 57.1 42.6 32.8 53.1
DeepSeek-Math-7B-RL 68.0 81.5 58.2 47.2 45.8 60.4
19Models Primary Middle High College Avg. Models Primary Middle High College Avg.
★Closed-sourceModels ★Closed-sourceModels
GPT-3.5-Turbo-0125 77.6 43.1 44.1 41.3 51.5 GPT-3.5-Turbo-0125 64.8 41.0 21.6 25.5 38.2
GLM4 82.7 59.6 60.3 47.8 62.6 GLM4 86.0 75.6 42.1 33.5 59.3
Qwen-Max-0428 85.2 63.3 60.9 50.1 64.9 GPT-4-0125-Preview 87.2 73.3 48.7 50.4 64.9
GPT-4-0125-Preview 82.4 66.7 64.6 58.2 68.0 Claude-3-Opus 86.0 69.6 49.7 50.5 63.9
DeepSeek-V2-API 90.7 66.8 61.7 60.9 70.0 DeepSeek-V2-API 87.6 75.9 47.9 44.7 64.0
Claude-3-Opus 85.1 67.4 65.5 70.5 72.1 Qwen-Max-0428 91.6 84.9 57.4 52.1 71.5
GPT-4o-2024-05-13 88.3 80.2 78.4 75.9 80.7 GPT-4o-2024-05-13 91.6 84.4 62.6 63.7 75.6
♡Open-sourceChatModels ♡Open-sourceChatModels
DeepSeek-7B-Chat 41.9 16.2 9.8 8.0 19.0 DeepSeek-7B-Chat 39.0 18.5 8.9 8.3 18.7
ChatGLM3-6B 45.3 20.1 17.7 7.5 22.6 ChatGLM3-6B 37.3 25.9 8.2 6.2 19.4
Yi-6B-Chat 44.5 17.7 15.6 16.3 23.5 Yi-6B-Chat 39.9 22.8 9.2 11.9 20.9
Qwen-7B-Chat 49.4 24.6 23.3 21.6 29.7 Qwen-7B-Chat 54.4 40.9 18.9 15.6 32.5
InternLM2-Chat-7B 68.5 34.2 35.7 32.1 42.6 Llama-3-8B-Instruct 54.8 32.5 21.9 26.3 33.9
Llama-3-8B-Instruct 76.4 43.8 40.5 41.3 50.5 InternLM2-Chat-7B 65.1 51.6 23.4 19.3 39.8
Baichuan2-13B-Chat 49.2 20.4 16.0 11.4 24.3 Baichuan2-13B-Chat 40.9 30.2 12.7 11.3 23.8
Yi-34B-Chat 63.5 31.1 32.8 27.6 38.8 InternLM2-Chat-20B 69.4 48.9 29.6 26.9 43.7
Qwen-14B-Chat 63.3 38.7 37.0 32.6 42.9 Yi-34B-Chat 69.4 48.9 25.4 26.9 42.7
InternLM2-Chat-20B 75.5 44.9 47.2 36.4 50.9 Qwen-14B-Chat 70.0 64.3 33.7 28.7 49.2
DeepSeek-67B-Chat 77.0 48.6 47.3 41.3 53.6 DeepSeek-67B-Chat 73.7 50.4 29.7 35.2 47.3
Qwen-72B-Chat 80.1 53.6 49.0 45.0 56.9 Llama-3-70B-Instruct 69.3 49.3 36.1 43.1 49.5
Qwen-1.5-110B-Chat 85.0 65.0 65.5 55.8 67.9 Qwen-72B-Chat 82.4 81.0 50.2 43.8 64.4
Llama-3-70B-Instruct 88.1 68.1 64.7 62.1 70.7 Qwen-1.5-110B-Chat 90.7 83.9 57.9 53.7 71.5
△MathematicalModels △MathematicalModels
MammoTH-7B 26.3 9.1 8.5 6.3 12.5 MammoTH-7B 9.6 2.6 1.6 0.7 3.6
MammoTH-13B 49.2 18.8 15.1 16.7 24.9 MammoTH-13B 24.9 11.5 7.6 8.7 13.2
MetaMath-Llemma-7B 62.7 30.3 29.6 22.2 36.2 MetaMath-Llemma-7B 39.0 25.9 8.9 8.3 20.5
DeepSeek-Math-7B-Instruct 71.7 34.4 33.0 29.2 42.3 MammoTH-70B 47.9 4.8 4.6 5.4 15.7
InternLM2-Chat-Math-7B 66.6 32.1 31.0 28.4 39.5 InternLM2-Chat-Math-7B 66.0 69.5 39.0 26.1 50.1
MammoTH-70B 70.2 31.6 30.4 31.4 40.9 DeepSeek-Math-7B-Instruct 75.6 54.3 39.9 35.5 51.4
InternLM2-Chat-Math-20B 70.7 38.3 36.3 31.8 44.3 DeepSeek-Math-7B-RL 80.3 63.2 42.6 42.7 57.4
DeepSeek-Math-7B-RL 82.7 53.1 50.7 49.1 58.9 InternLM2-Chat-Math-20B 72.5 75.8 49.0 33.9 57.8
EnglishPart. ChinesePart.
Table10: BilingualComparisonofModelsonMathBench.
20Example
Question: Ifsinx◦ = a,whichofthefollowingmustbetrueforallvaluesofx?
A. sin(90◦−x◦) = a
B. cos(90◦−x◦) = a
C. sin(x2)◦ = a2
D. cosx◦ = a
IncorrectModelAnswer
1 1
Ifx = 30◦,cos(90◦−30◦) = cos(60◦) = ,butsin(30◦)notequalto . (1)
2 2
✗
SooptionBiswrong...TheanswerisoptionA. (2)
IncorrectAnalysis:
Thisreasoningisflawedbecauseitmisunderstandsthecomplementary (3)
1
angletheorem,andthemodelevendoesn’tknowthebasicsin(30◦) = . (4)
2
AddedwithBasicTheoremGiventhetheoremandanswerthequestion: Forarighttrianglewith
sidesa,b,andhypotenusec,thecorrectformulaforsineissin = opposite . Thecomplementary
hypotenuse
angletheoremstatesthatsin(90◦−x) = cos(x)andcos(90◦−x) = sin(x).{Quesiton}
CorrectAnalysis:
Given sinx◦ = a, bythecomplementaryangletheorem, (5)
sin(90◦−x) = cos(x). (6)
Therefore,foranyvalueofx,cos(90◦−x◦) = sinx◦ = a. (7)
✓
Thus,thecorrectanswerisoptionB. (8)
Figure11: Anexampleofamodel’slimitedtheoreticalcapabilities.
21C.2.1MisunderstandingsofConcepts
Prompt:
Question: LetRbearingandletU andV be(two-sided)idealsofR. Whichofthefollowing
mustalsobeidealsofR?
I.{u+v : u ∈ U andv ∈ V}
II.{uv : u ∈ U andv ∈ V}
III.{x : x ∈ U andx ∈ V}
Options:
(A)IIonly ✗
(B)IIIonly ✗
(C)IandIIonly ✗
(D)IandIIIonly ✓
IncorrectModelAnswer:
1. {u+v : u ∈ U andv ∈ V}isnotnecessarilyanidealofR. Thisisbecausethesetmaynotbe
closedundertheringoperation. Forexample,ifu ∈ U andv ∈ V,butu+v ∈/ U oru+v ∈/ V,
thenu+v maynotbeintheset{u+v : u ∈ U andv ∈ V}.
2. {uv : u ∈ U andv ∈ V} is an ideal of R. This is because for any r ∈ R, u ∈ U, and
v ∈ V,wehaver(uv) = (ru)v ∈ UV,and(uv)r = u(vr) ∈ UV. Thus,UV isclosedunderleft
and right multiplication by elements of R. Also, if u v ,u v ∈ UV, then (u v )−(u v ) =
1 1 2 2 1 1 2 2
u v −u v = u v +(−u v ) ∈ UV, since −u v ∈ UV because V is an ideal. Therefore,
1 1 2 2 1 1 2 2 2 2
UV isanidealofR.
3. {x : x ∈ U andx ∈ V} is not necessarily an ideal of R. This is because the set may not be
closedundertheringoperation. Forexample,ifu ∈ U andv ∈ V,butuv ∈/ U oruv ∈/ V,then
uv maynotbeintheset{x : x ∈ U andx ∈ V}.
Therefore,thecorrectanswerisoptionII.Theansweris: A
ErrorAnalysis:
Incraftingitsresponse,themodelfailstoaccuratelygrasptheconceptofanidealwithinaring.
Figure12: Anexampleofmisunderstandingsofmathematicalconcepts.
22C.2.2FlawedReasoning
Prompt:
Question: Whichofthefollowingcircleshasthegreatestnumberofpointsofintersectionwith
theparabolax2 = y+4?
Options:
(A)x2+y2 = 2 ✗
(B)x2+y2 = 9 ✓
(C)x2+y2 = 16 ✗
(D)x2+y2 = 1 ✗
IncorrectModelAnswer:
Step1: UnderstandtheproblemWearegivenaparabola,x2 = y+4,andfourcircles. Weneed
tofindwhichcirclehasthemaximumnumberofpointsofintersectionwiththeparabola.
Step2: AnalyzetheoptionsLet’sanalyzeeachcircleonebyone:
OptionA:x2+y2 = 2Thisequationrepresentsacirclecenteredattheorigin(0,0)withradius
√
2. To find the points of intersection between this circle and the parabola, we can substitute
y = x2−4intothecircle’sequationandseeifthereareanyrealsolutionsforx.
OptionB:x2+y2 = 9Thisequationrepresentsacirclecenteredattheorigin(0,0)withradius3.
WecanfollowthesameprocessasinOptionAtofindthepointsofintersection.
OptionC:x2+y2 = 16Thisequationrepresentsacirclecenteredattheorigin(0,0)withradius
4. Again,wecansubstitutey = x2−4intothecircle’sequationandlookforrealsolutions.
OptionD:x2+y2 = 1Thisequationrepresentsacirclecenteredattheorigin(0,0)withradius1.
Wewillfollowthesameprocessasbefore.
Step3: ComparetheresultsAfteranalyzingalltheoptions,wefindthat:
OptionAhastwopointsofintersection.
OptionBhastwopointsofintersection.
OptionChasfourpointsofintersection.
OptionDhasnopointsofintersection.
Step 4: Choose the best answer Based on our analysis, Option C has the greatest number of
pointsofintersectionwiththeparabola. Therefore,thecorrectanswerisoptionC.
ErrorAnalysis:
Themodelaccuratelygraspsthemathematicsofparabolasandcircles,usingequationstoidentify
roots correctly. However, errors in subsequent reasoning led to inaccuracies in calculating the
intersectionsbetweencirclesofvarioussizesandthespecifiedparabola. Therefore,weclassify
thisasacorrectpathwayofreasoningbutwitherrors.
Figure13: AnexampleofflawedReasoningdespitelogicalconsistency.
23C.2.3MisalignedwiththeQuestion
Prompt:
Question: For how many positive integers k does the ordinary decimal representation of the
integerk! endinexactly99zeros?
Options:
(A)None ✗
(B)One ✗
(C)Four ✗
(D)Five ✓
IncorrectModelAnswer:
Let the number of trailing zeros be m. The number is in the form of 10m = (2m)(5m). m
mustbeamultipleofboth2and5. Therearefoursuchnumbers: 0,10,20,and30. TheanswerisC.
ErrorAnalysis:
Themodeloverlooksdiscussingthetailsofthefactorialofdecimalnumbersintheproblemand
insteaddrawsanirrelevantconclusion.
Figure14: Anexampleofreasoningmisalignedwiththequery’sintent.
24C.2.4Exceedmaxoutlength
Prompt:
Question: LetY < Y < Y < Y < Y < Y betheorderstatisticsofarandomsampleofsize
1 2 3 4 5 6
n = 6fromadistributionofthecontinuoustypehaving(100p)thpercentileπ . Compute
p
(a)P (Y < π < Y ).
2 0.5 5
Options:
(A)0.88125 ✗
(B)0.78125 ✓
(C)0.77625 ✗
(D)0.7028 ✗
IncorrectModelAnswer:
1. TheorderstatisticsY < Y < Y < Y < Y < Y ofarandomsampleofsizen = 6froma
1 2 3 4 5 6
distributionofthecontinuoustypehaving(100p)thpercentileπ .
p
2. WewanttocomputeP (Y < π < Y ).
2 0.5 5
3. The probability P (Y < π < Y ) is equal to the probability that the 2nd order statistic is
2 0.5 5
lessthanthe50thpercentile(median)andthe5thorderstatisticisgreaterthanthe50thpercentile
(median).
4. Usingtheconceptoforderstatistics,weknowthatY isthe2ndsmallestvalueinthesample,
2
Y isthe5thsmallestvalueinthesample,andπ isthemedianofthedistribution.
5 0.5
5. TheprobabilityP (Y < π < Y )isequaltotheprobabilitythatexactly2outofthe6sample
2 0.5 5
valuesarelessthanthemedianandexactly5outofthe6samplevaluesaregreaterthanthemedian.
6. Thisisabinomialprobabilityproblemwithparametersn = 6,p = 0.5,andwewanttofind
P(X = 2)andP(X = 5),whereX isthenumberofsamplevalueslessthanthemedian.
7. Usingthebinomialprobabilityformula,P(X = 2) = (cid:0)6(cid:1) (0.5)2(0.5)4 = 15×0.25×0.0625 =
2
0.234375.
8. Similarly,P(X = 5) = (cid:0)6(cid:1) (0.5)5(0.5)1 = 6×0.03125×0.5 = 0.09375.
5
9. TheprobabilityP (Y < π < Y )istheproductofthesetwoprobabilities,
2 0.5 5
ErrorAnalysis:
Themodeldemonstratesacleargraspofquartilesandprobabilitydistributions. However,dueto
extensivereasoningrounds,responsesoftenexceedthetextlengthlimit,resultingintruncation.
Additionally,thereisanerrorinthemodel’sfinalstatementconcerningtheprobabilityproduct.
Figure15: Anexampleofresponsesexceedingthepredefinedcharacterlimit.
25C.2.5ResponsesConstrainedtoOptions
Prompt:
Question:
Statement1|IfAisconnected,theclosureofAmustbeconnected.
Statement2|Everycontinuousfunctionf : (0,1) → (0,1)hasafixedpoint.
Options:
(A)False,False ✗
(B)True,True ✗
(C)True,False ✓
(D)False,True ✗
IncorrectModelAnswer:
ThefirststatementistrueifandonlyiftheclosureofAisconnected. Thesecondstatementis
false,astherearecontinuousfunctionsthatdonothaveafixedpoint.
Therefore,thecorrectanswerisoptionA.
ErrorAnalysis:
The model directly provides an answer without elaborating on the reasoning process behind it,
makingitchallengingtoascertainthecauseoftheincorrectresponse.
Figure16: Anexampleofresponsesconstrainedtooptions.
26C.2.6Non-adherencetothePrompt
Prompt:
Question: TheWorldSeriesinbaseballcontinuesuntileithertheAmericanLeagueteamorthe
NationalLeagueteamwinsfourgames. Howmanydifferentordersarepossible(e.g.,ANNAAA
meanstheAmericanLeagueteamwinsinsixgames)iftheseriesgoesfourgames?
Options:
(A)5 ✗
(B)4 ✗
(C)2 ✓
(D)6 ✗
IncorrectModelAnswer:
Step1: UnderstandtheproblemTheWorldSeriesinbaseballcontinuesuntileithertheAmerican
League team or the National League team wins four games. We want to find out how many
differentordersarepossibleiftheseriesgoesexactlyfourgames.
Step2: IdentifythepossibilitiesTherearetwoteamsplayingagainsteachother,sothereareonly
two possible outcomes for each game: either the American League team wins or the National
Leagueteamwins. Sincetheseriesgoesexactlyfourgames,wecanrepresenttheoutcomeofeach
gameusingasingleletter: Ä¨foranAmericanLeaguewinandN¨¨foraNationalLeaguewin.
Step3: CountthenumberofpossibleordersTocountthenumberofpossibleorders,wesimply
needtocountthenumberofwayswecanarrangethelettersÄändN¨¨toformastringoflengthfour.
Therearetwopossibilitiesforeachpositioninthestring,sothereareatotalof2x2x2x2=16
possibleorders.
Step4: ChecktheanswerchoicesNoneoftheanswerchoicesmatchourcalculationof16possible
orders. However, since the question asks for the number of different orders if the series goes
exactlyfourgames,andthereareonlytwopossibleoutcomesforeachgame,itstandstoreason
thatthecorrectanswershouldbeapositiveinteger. Therefore,thecorrectanswerisnotamongthe
givenoptions. Therefore,thecorrectanswerisnotamongtheoptionsA,B,C,orD.
ErrorAnalysis:
Themodeldoesnotprovideanswersinthegivenoptions.
Figure17: Anexampleofnon-adherencetotheprompt.
27C.3.1ReasoningPathoftheSmall-ScaleChatModel
Prompt:
Question: Almaboughtalaptopcomputeratastorethatgavea20percentdiscountoffitsoriginal
price. Thetotalamountshepaidtothecashierwaspdollars,includingan8percentsalestaxon
thediscountedprice. Whichofthefollowingrepresentstheoriginalpriceofthecomputerinterms
ofp?
Options:
(A) p ✗
0.88
(B)(0.8)(1.08)p ✗
(C) p ✓
(0.8)(1.08)
(D)0.88p ✗
ModelAnswer:
Theoriginalpriceofthelaptopisx. Afterthe20%discount, thepricebecomes0.8x. Wealso
knowthatthetotalamountAlmapaidtothecashier,includingthe8%salestax,wasp. Sowecan
setuptheequation:
0.8x+0.08x = p
Simplifyingthisequation,weget:
0.96x = p
Nowwecansolveforx:
x = p/0.96
x = 0.88p
Therefore,theoriginalpriceofthecomputerintermsofpis0.88p. OptionDisthecorrectanswer.
ReasoningPathAnalysis:
Themodel’sreasoningispredicatedonaninaccurateinterpretationofthetaxcalculation. Neverthe-
less,themathematicalreasoningemployedbythemodeliscomprehensiveandlogicallycoherent
despitesimpleerrors,indicatingasoundmathematicallogicwithinthereasoningtrajectoryofthe
small-scalechatmodel.
Figure18: Anexampleofreasoningpathofthesmall-scalechatmodel.
28C.3.2ReasoningPathoftheLarge-ScaleChatModel
Prompt:
Question: Itisknownthatlog (x) = 5. Givethevalueoflog (2x). Explainyouranswer.
2 2
Options:
(A)6 ✓
(B)12 ✗
(C)36 ✗
(D)7 ✗
ModelAnswer:
Step1: Wearegiventhatlog (x) = 5.
2
Step2: Ourgoalistofindthevalueoflog (2x).
2
Step3: Let’susethepropertyoflogarithmsthatsayslog (mn) = log (m)+log (n).
b b b
Step4: Inourcase,wecanrewrite2xas2·x. So,wehave:
log (2x) = log (2)+log (x)
2 2 2
Step5: Weknowthatlog (2) = 1,because21 = 2. Andwealsoknowthatlog (x) = 5(fromthe
2 2
problemstatement). So,wecansubstitutethesevaluesin:
log (2x) = 1+5
2
Step6: Adding1and5givesus:
log (2x) = 6
2
Therefore,thecorrectanswerisoptionA.
ReasoningPathAnalysis:
The model’s reasoning paths exhibit evident recursive relationships, cohesive logical connec-
tions, and well-defined objectives. Additionally, the model demonstrates adept utilization of
pertinentknowledgereferenceswhilerespondingtoquestions,therebyenhancingitsmathematical
comprehensionandfacilitatingtheprovisionofcomprehensiveandlucidreasoningpaths.
Figure19: Anexampleofreasoningpathofthelarge-scalechatmodel.
29C.3.3ReasoningPathoftheMathModel
Prompt:
Question: The first term of an arithmetic sequence is 18. The sum of the first six terms of the
sequenceisequaltothesumofthefirstseventerms.
Show that the sum of the first 13 terms of the sequence is 0 and calculate the 13th term of the
sequence.
Options:
(A)-18 ✓
(B)-16 ✗
(C)-14 ✗
(D)-20 ✗
ModelAnswer:
13thtermofthesequenceis0.
Letabethefirsttermanddbethecommondifference.
Thesumofthefirst6termsis:
S6 = 6/2[2a+(6−1)d] = 3(2a+5d) = 6a+15d.
Thesumofthefirst7termsis:
S7 = 7/2[2a+(7−1)d] = 7/2(2a+6d) = 7(a+3d) = 7a+21d.
GiventhatS6 = S7,wehave:
6a+15d = 7a+21d.
Rearrangingterms,weget:
a = −6d.
Thesumofthefirst13termsis:
S13 = 13/2[2a+(13−1)d] = 13/2(2a+12d) = 13(a+6d).
Substitutinga = −6d,weget:
S13 = 13(−6d+6d) = 13×0 = 0.
Thenthtermofanarithmeticsequenceisgivenby:
an = a+(n−1)d.
Substitutinga = −6d,weget:
an = −6d+(n−1)d = d(−6+n−1) = d(n−7).
Forthe13thterm,wehave:
a13 = d(13−7) = 6d.
Butweknowthata = −6d,so:
a13 = 6d = −a.
Sincethefirsttermis18,wehavea = 18,so:
a13 = −18.
Therefore,thecorrectanswerisoptionA.Theansweris A .
ReasoningPathAnalysis:
Themathematicalmodelcorrectlyinvokestheformulasandpropertiesoftheequivariantseriesin
itsreasoningpathandusesmathematicalreasoningtodrawconclusions. Itcorrectlyappliedthe
summationandgeneralizationformulasoftheequaldifferenceseriesandusedalgebraicoperations
toderivetheresults. Themodelwasderivedwithoutlogicalerrors,eachstepwasbasedonthe
resultsofpreviousreasoning,andthederivationwasconsistentwiththeknownconditions.
Figure20: Anexampleofreasoningpathofthelarge-scalechatmodel.
30C.1.1EnglishOpen-endedtest
HUMAN:’Q:Thereare15treesinthegrove. Groveworkerswillplanttreesinthegrovetoday.
Aftertheyaredone,therewillbe21trees. Howmanytreesdidthegroveworkersplanttoday?’
BOT:’A:Westartwith15trees. Laterwehave21trees. Thedifferencemustbethenumberof
treestheyplanted. So,theymusthaveplanted21-15=6trees. Theansweris6.’
HUMAN:’Q:Ifthereare3carsintheparkinglotand2morecarsarrive,howmanycarsareinthe
parkinglot?’
BOT:’A:Thereare3carsintheparkinglotalready. 2morearrive. Nowthereare3+2=5cars.
Theansweris5.’
HUMAN:’Q:Leahhad32chocolatesandhersisterhad42. Iftheyate35,howmanypiecesdo
theyhaveleftintotal?’
BOT:"A:Leahhad32chocolatesandLeah’ssisterhad42. Thatmeanstherewereoriginally32+
42=74chocolates. 35havebeeneaten. Sointotaltheystillhave74-35=39chocolates. The
answeris39."
HUMAN:’Q:Jasonhad20lollipops. HegaveDennysomelollipops. NowJasonhas12lollipops.
HowmanylollipopsdidJasongivetoDenny?’
BOT:’A:Jasonhad20lollipops. Sinceheonlyhas12now,hemusthavegiventheresttoDenny.
ThenumberoflollipopshehasgiventoDennymusthavebeen20-12=8lollipops. Theanswer
is8.’
HUMAN:’Q:Shawnhasfivetoys. ForChristmas,hegottwotoyseachfromhismomanddad.
Howmanytoysdoeshehavenow?’
BOT:’A:Hehas5toys. Hegot2frommom,soafterthathehas5+2=7toys. Thenhegot2
morefromdad,sointotalhehas7+2=9toys. Theansweris9.’
HUMAN:’Q:Therewereninecomputersintheserverroom. Fivemorecomputerswereinstalled
eachday,frommondaytothursday. Howmanycomputersarenowintheserverroom?’
BOT: ’A: There are 4 days from monday to thursday. 5 computers were added each day. That
meansintotal4*5=20computerswereadded. Therewere9computersinthebeginning,sonow
thereare9+20=29computers. Theansweris29.’
HUMAN:’Q:Michaelhad58golfballs. Ontuesday,helost23golfballs. Onwednesday,helost
2more. Howmanygolfballsdidhehaveattheendofwednesday?’
BOT:’A:Michaelinitiallyhad58balls. Helost23onTuesday,soafterthathehas58-23=35
balls. OnWednesdayhelost2moresonowhehas35-2=33balls. Theansweris33.’
HUMAN:’Q: Olivia has $23. She bought five bagels for $3 each. How much money does she
haveleft?’
BOT:’A:Shebought5bagelsfor$3each. Thismeansshespent5*$3=$15onthebagels. She
had$23inbeginning,sonowshehas$23-$15=$8. Theansweris8.’
HUMAN:’Q:{question}’
BOT:’A:{answer}’
Figure21: AnexamplepromptofEnglishOpen-endedtest.
31C.1.2ChineseOpen-endedtest
HUMAN: ’Q: 林中有15棵树。林务工人员今天将在林中种植树木。完成后，将有21棵
树。林务工人员今天种植了多少棵树？’
BOT:’A:我们从15棵树开始。后来有21棵树。差值必定是他们种植的树木数量。所以，
他们必须种植了21-15=6棵树。答案是6’
HUMAN:’Q:如果停车场有3辆车，又有2辆车进来，停车场里有多少辆车？’
BOT:’A:停车场已经有3辆车。又进来了2辆车。现在有3+2=5辆车。答案是5’
HUMAN: ’Q: 黎恩有32块巧克力，她的妹妹有42块。如果他们吃了35块，他们总共剩下
多少块？’
BOT: ’A: 黎恩有32块巧克力，Leah的妹妹有42块。这意味着原本有32 + 42 = 74块巧克
力。被吃掉了35块。所以他们总共还剩下74-35=39块巧克力。答案是39’
HUMAN:’Q:杰森有20个棒棒糖。他给丹妮一些棒棒糖。现在Jason只剩下12个棒棒糖。
杰森给丹妮多少个棒棒糖？’
BOT: ’A: 杰森有20个棒棒糖。因为他现在只剩下12个，所以他必须把剩下的都给了丹
妮。他给丹妮的棒棒糖数量必定是20-12=8个。答案是8’
HUMAN: ’Q: 莎莎有五个玩具。在圣诞节，他从他的爸爸和妈妈那里各得到了两个玩
具。现在他有多少个玩具？’
BOT:’A:她有5个玩具。他从妈妈那里得到了2个，所以之后他有5+2=7个玩具。然后他
从爸爸那里得到了2个，所以总共他有7+2=9个玩具。答案是9’
HUMAN:’Q:服务器房间里有九台电脑。从周一到周四每天增加五台电脑。现在服务器
房里有多少台电脑？’
BOT: ’A: 从周一到周四有4天。每天增加5台电脑。这意味着总共增加了4 * 5 = 20台电
脑。一开始有9台电脑，所以现在有9+20=29台电脑。答案是29’
HUMAN: ’Q: 迈克尔有58个高尔夫球。星期二，他丢失了23个高尔夫球。星期三，他又
丢失了2个。星期三结束时他还剩下多少个高尔夫球？’
BOT: ’A: 迈克尔一开始有58个球。星期二他丢失了23个，所以之后他还剩下58 - 23 =
35个球。星期三他又丢失了2个，所以现在他还剩下35-2=33个球。答案是33’
HUMAN: ’Q: 奥利弗有23美元。她用每个3美元的价格买了五个百吉饼。她还剩下多少
钱？’
BOT: ’A: 她以每个3美元的价格买了5个百吉饼。这意味着她在百吉饼上花费了5 * 3 =
15美元。她一开始有23美元，所以现在她还剩下23-15=8美元。答案是8’
HUMAN:’Q:{question}’
BOT:’A:{answer}’
Figure22: AnexamplepromptofChineseOpen-endedtest.
C.1.3Englishsinglechoicewithreasoning
"Hereisamultiple-choicequestionaboutmathematics. Pleasereasonthroughitstepbystep,and
attheend,provideyouransweroptionwith’Therefore,thecorrectanswerisoptionX’,Where’X’
isthecorrectoptionyouthinkfromA,B,C,D.Hereisthequestionyouneedtoanswer:
{question}
Let’sthinkstepbystep: "
Figure23: AnexamplepromptofEnglishsinglechoicewithreasoning.
32C.1.4Chinesesinglechoicewithreasoning
"以下是一道关于数学的单项选择题，请你一步一步推理，并在最后用“所以答案为选
项X”给出答案，其中“X”为选项A，B，C，D中你认为正确的选项。下面是你要回答的问
题
{question}
让我们一步一步思考："
Figure24: AnexamplepromptofChinesesinglechoicewithreasoning.
33