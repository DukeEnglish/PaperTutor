EXPLORING COMMONALITIES IN EXPLANATION FRAMEWORKS:
A MULTI-DOMAIN SURVEY ANALYSIS
APREPRINT
EduardBarbu MarharythaDomnich
InstituteOfComputerScience InstituteOfComputerScience
Tartu,Estonia Tartu,Estonia
eduard.barbu@ut.ee marharyta.domnich@ut.ee
RaulVicente
InstituteOfComputerScience
Tartu,Estonia
raulvicente@gmail.com
NikosSakkas
ApintechLtd,POLIS-21Group
Cyprus
sakkas@apintech.com
AndréMorim
LTPlabs,AvenidadaSenhoradaHora,459
Porto,Portugal
andre.morim@ltplabs.com
May21,2024
ABSTRACT
Thisstudypresentsinsightsgatheredfromsurveysanddiscussionswithspecialistsinthreedomains,
aiming to find essential elements for a universal explanation framework that could be applied to
theseandothersimilarusecases. TheinsightsareincorporatedintoasoftwaretoolthatutilizesGP
algorithms,knownfortheirinterpretability. Theapplicationsanalyzedincludeamedicalscenario
(involving predictive ML), a retail use case (involving prescriptive ML), and an energy use case
(alsoinvolvingpredictiveML).Weinterviewedprofessionalsfromeachsector,transcribingtheir
conversationsforfurtheranalysis. Additionally, expertsandnon-expertsinthesefieldsfilledout
questionnairesdesignedtoprobevariousdimensionsofexplanatorymethods. Thefindingsindicate
a universal preference for sacrificing a degree of accuracy in favor of greater explainability. Ad-
ditionally,wehighlightthesignificanceoffeatureimportanceandcounterfactualexplanationsas
criticalcomponentsofsuchaframework. Ourquestionnairesarepubliclyavailabletofacilitatethe
disseminationofknowledgeinthefieldofXAI.
Keywords machinelearning·expertsurveys·explainabilityframework
1 Introduction
TheadventofAIsolutionsinvariousdomainshaspromptedasignificantshifttowardsdata-drivendecision-making.
DespitetheremarkablecapabilitiesofMLmodels,theirinherentcomplexityandlackoftransparencyposechallenges,
4202
yaM
02
]GL.sc[
1v85911.5042:viXraarXivTemplate APREPRINT
particularlyinsensitivesectorslikehealthcare,retail,andenergy. Thispaperinvestigatesthecommonalitiesacross
differentexplanationtypeswithinthesedomains,focusingonenhancingunderstandabilityandtrustamongusers. We
identifyessentialfeaturesofanexplanationframeworkthatcouldcatertodiverseusecaseswhilepromotingexplain-
abilityandusertrustbyanalyzingresponsesfromdomainexpertsandlaymanpractitionersthroughquestionnaires
andinterviews. Ourresearchfocusesongeneticprogramming(GP)withinmachinelearning(ML)models. However,
the insights we’ve obtained apply to any ML model category that supports interpretability. Symbolic expressions
derivedfromGPofferseveraladvantagesforenhancingexplainabilityinML,includingintuitiverepresentationseasily
understoodbynon-expertsandthesimplicityandcompactnessofsolutionsthatcaptureessentialpatternsinthedataMei
etal.[2023]. Theirflexibilityallowsadaptationtovarioustypesofproblemsanddata,contributingtothetransparency
ofAIsystemsbyexplicitlyrepresentinghowinputsaretransformedintooutputs. Thepaperisorganizedasfollows:
we begin with an overview of related work. This is followed by introducing the three distinct use cases and their
uniquecharacteristics. InSection4,weelaborateonthemethodologyemployedinconductingthesurveys. Thepaper
concludeswithadiscussionofourfindingsandpresentsconclusions,includingrecommendationsfordevelopingaGP
tooltosupportpractitionersacrossthreeusecases. Thedevelopedquestionnairesarepubliclyavailabletofacilitatethe
disseminationofknowledgeinthefieldofXAI.
2 RelatedWork
Thereisasolidbodyofresearchencompassingvariousperspectivesandmethodologiesrelatedtouserexpectations
fromAIsystemexplanations. Forexample,Langeretal.[2021]outlinesthekeystakeholdergroupsadvocatingforthe
explainabilityoftheAIsystemsandevaluatestheirrequirements. Itpresentsaframeworkdetailingessentialconcepts
andrelationshipstoassess,tailor,select,anddevelopsolutionstomeetstakeholderneeds.
ResearchershavefocusedonunderstandingthehumanaspectofXAIbydevelopingreliabletoolstocollectopinions
fromexperts,andthepublicGunningandAha[2019],Gunningetal.[2021].
InassessingexplanationsinMLsystemusersurveys,theSystemCausabilityScaleisanotabletoolthatconsistsofa
ten-questionsurveyusinga5-pointLikertscale(rangingfromstronglydisagreetostronglyagree). Itisusedtoevaluate
theusabilityofuserinterfacesthatpresentMLmodelexplanations,anditwasintroducedinHolzingeretal.[2019].
Similarly,theSystemUsabilityScaleusesaten-itemLikertquestionnairetogaugeuserfeedbackontheeffectiveness
ofgeneratedexplanationsDragonietal.[2020]. Ontheotherhand,Hoffmanetal.[2023]suggeststheExplanation
GoodnessChecklist,aimedatresearchersforevaluatingexplanationproperties,andtheExplanationSatisfactionScale,
designed to capture users’ appraisal of explanations. These measures, grounded in cognitive psychology and the
philosophyofscience,assessessentialqualitiesthatconstituteagoodexplanation.
Theinsightsfrompsychometricshavebeenleveragedtocreateandassessanewhuman-centeredquestionnairedesigned
toevaluateexplanationsgeneratedbyXAImethodsreliablyViloneandLongo[2023]. Recognizingthatexplainability
encompassesseveraldimensions,thisapproachaimstocomprehensivelyaddressthecomplexityoftheconceptwithin
thecontextofAIsystems.
Intheirliteraturereview,theauthorsinLaatoetal.[2022]definefiveprimarygoalsforAIsysteminteractionswith
endusers: understandability,trustworthiness,transparency,controllability,andfairness. Theyrecommenddesigning
XAIsystemstoachievetheseobjectivesandsuggestguidelinesforcreatingexplanationsfocusingoncrucialsystem
components. Additionally,theyhighlightthenecessityforcompromisesinAIexplanations,underliningtheabsenceof
aone-size-fits-allsolution.
Ourmaincontributionishighlightingkeyelementsofexplanationsacrossvariousfields,suchasmedicine,retail,and
energy,aimingtocreateanAItoolversatileenoughforprofessionalsindiversedomains. Thiscross-domainapproach
seekstoprovideacomprehensivesolutionapplicableinmultiplefields,bridgingthegapbetweendifferentpractitioners’
needs.
3 Theusecases
Thissectionintroducesthethreeusecases,emphasizingtheirdistinctivefeatures. Twoaregearedtowardprediction,
whilethethirdadoptsaprescriptiveapproach.
3.1 Medicalscenario
Themedicalscenarioinvestigatesexplanationsforparagangliomaanddiabetes. Thefocusonparaganglioma,arare
tumoroftheautonomicnervoussystem,highlightsthechallengeofitsunpredictableprogression. Treatmentoptions
2arXivTemplate APREPRINT
varywidely,fromwatchfulwaitingtosurgeryorradiotherapy,dependingonthetumor’sgrowth. Weaimtodevelopa
GPmodeltoassistphysiciansindecidingwhentotreatbyofferingpredictionsontumordevelopmentandpotential
complications. This model intends to facilitate shared decision-making between clinicians and patients, optimize
treatment schedules, minimize unnecessary interventions, and tailor patient monitoring without replacing clinical
judgment.
This approach does not replace clinical decision-making but enriches it with valuable data-driven insights, aiding
cliniciansinnavigatingthecomplexitiesofparagangliomatreatmentplanning.
Thediabetesscenarioutilizesthewell-knowndatasetSmithetal.[1988],employedbyvariousmachinelearningmodels,
todeterminethepresenceorabsenceofdiabetesinapatienttobuildaquestionnairefordiabetesprediction. Thisis
necessaryatthisstagebecausetherearenopredictionmodelsforparaganglioma.
3.2 Retailusecase
Grocery retailers aim to balance operational efficiency with customer satisfaction in their home delivery services,
offeringflexibledeliverywindowswhilekeepingcostslow. DynamicTimeslotPricingaddressesthechallengeof
aligningcustomerpreferenceswithlogisticalcapabilities,utilizingAItoensuretransparentandfairdeliverypricing
andscheduling. Thisapproachinvolves:
1. Utilizingcustomerandlogisticsdatatotrainmodelsthatpredictcustomerwillingnesstopayandthecost-to-
servefordifferenttimeslots.
2. Developing an algorithm to harmonize customer demands with logistical efficiency, guiding timeslot and
pricingstrategies.
Thisstrategy,supportedbyaprescriptivemodelcombiningcustomerwillingnesstopayandcost-to-serveinsights,
seekstooptimizeprofitmarginsandenhanceservicefairness. Regularupdatesandconsultationsensurethemodel’s
relevanceandeffectivenessinareal-worldsetting.
Theheuristic,whichdeterminesslot-priceconfigurationsusingasymbolicformula(PrescriptiveModel),reliesontwo
auxiliarymodels—theWillingnesstoPay(WTP)andCosttoServe(CTS)models—foritspredictiveinsights.
3.3 Energyusecase
Thisusecaseaimstoforecasthomeenergyuse,focusingoncriticalelementslikeweatherconditions,pastenergy
patterns,buildingdynamics,pricingschemes,andindoortemperaturestosuggestsavings. Thechallengeistoprovide
clearexplanationsforusers,facilitatedecision-making,andintegratetheseforecastsintobusinesspracticestoenhance
energyefficiencyanddecisionsupport. Thefollowingkeyfactorsareconsidered:
1. Weatherconditionslikehourlyoutdoortemperatureandcloudcoveragearevitalformodelingenergyusage.
2. Historicalconsumptiondata,providinginsightsintousagepatternsandtheimpactofweatherchangeson
energydemand.
3. Buildingdynamicprofiles,reflectingtheelectricalinfrastructureandconsumptionbehaviors,informingsystem
adjustments.
4. Thecurrentpricingschemeiscrucialforimplementingdemandresponsestrategiestoinfluenceconsumption
basedonpricing.
5. Indoortemperaturemonitoringtosuggestenergy-savingmeasures.
Thecorechallengeliesinprovidinguserswithlocalexplanationstofacilitateinformeddecision-makingandseamlessly
integratingthissolutionintoreal-worldoperations. Thisapproachemphasizesthepracticalapplicationofforecastingin
enhancingenergyefficiencyandoperationaldecision-making.
4 Surveymethods
Thissectionoutlinesthesurveymethodologiesappliedtothethreeinvestigatedusecases. Ourapproachincorporated
twomethods: conductinginterviewswithdomainexpertsanddistributingquestionnairestopractitionerswhomaynot
haveexpertknowledge.
Detailsofthesurveyedexpertsareavailableatthislink: InterviewedExpertsDocument. Linkstothequestionnaires
canbefoundinthefollowingsubsections.
3arXivTemplate APREPRINT
4.1 SurveymethodsfortheMedicalScenario
Thedevelopmentofthequestionnaireforthemedicalusecasewasbasedonspecificcriteriaaimedatunderstanding
doctors’needsandpreferencesregardingmodelexplanations. Thetargetaudiencecompriseddoctors,whorequireda
generaloverviewanddetailedtechnicalinsightsintohowAImodelfeaturesinfluencepredictions. Becausetheproblem
ismuchbetterstudiedandunderstood,thequestionnairefocusedondiabetesriskestimation. Thisstrategyleveraged
existingpatientdataonhighdiabetesrisk,therebyavoidinganybiasesindoctors’explanationpreferenceswhilestill
gatheringrelevantinsights.
Thequestionnaireexploredvariousaspectsofmodelexplanations,focusingon.
1. Accuracyvs. Explainability: Thissectionexploresdoctors’willingnesstoprioritizemodelexplainability
overperformance.
2. PresentationFormats: Variousformatsforillustratingmodellogicwereevaluatedfortheirunderstandability
andeffectiveness,including:
• SymbolicRegressionGraphs: Comparisonoftwographs(GraphAandGraphB)illustratingmodel
behavior,withGraphBbeingmorecomplex.
• ProtocolsfromGeneticProgramming: Describedtwoprotocols,onesimplerwiththreerulesandone
causeperrule,andanothermorecomplexwithfourrulesandmultiplecausesperrule.
• SHAP Lundberg and Lee [2017] Feature Importance Graphs: Displayed the contribution of patient
characteristics(likegender,age,obesity)tothemodel’sdecision,highlightingfeatureimportanceand
datadistribution.
• Coefficients Table: Provided insights into feature importance through numerical coefficients in a re-
gressionmodel,indicatinghoweachcharacteristicinfluencesdiabetesriskpredictions,includingthe
significanceofcoefficientsandp-values.
• TextualExplanations: Evaluatedforofferingconciseexplanationsinvariousforms,includingcausal,
counterfactual,andcontrastiveexplanations.
Accordingtothedocumentlinkedpreviously,twomedicaldoctorshavecompletedthequestionnaires. Participants
wereaskedtorateeachexplanationformatonascalefrom1to5forbothinterpretabilityandeffectiveness,whereone
indicatedthelowestandfivewasthehighestscore. Interpretabilityratingsrangedfromnotinterpretable(1)tovery
intuitive(5),whileeffectivenessratingsassessedhowwelltheexplanationsaidedindecision-making,fromnothelpful
(1)toveryeffective(5).
Thequestionnaireforthemedicalscenariocanbeexploredhere: DiabetesQuestionnaire
Theinterviewwasrecordedandtranscribed,focusingontheparagangliomacase. Severalkeyissueswereexplored,
includingidentifyingtumor-indicativecluesinmedicalimages, theapplicationofstatisticalmodelsforpredicting
tumorgrowth,theroleofgeneticfactorsintumorevolution,thetrainingprotocolspecialistsusefornewdoctorsin
paragangliomacases,theexpectationsdoctorshavefromanAItoolinsuchcases,andthecriticalneedandspecificsof
explanationsrequiredforunderstandingparaganglioma.
4.2 SurveymethodsfortheRetailUseCase
Thefollowingtypesofquestionswereaskedinthequestionnairefortheretailusecase:
1. Pricebreakthrough. Thegoalofpricebreakthroughistoascertainwhetherkeyaspectsoftheretailcase,such
aslocation,demand,basketcontents,andtherelevanceofexplanations,holdsignificanceforthecustomer.
2. ExplanationPreferences: Thesequestionsevaluatethecustomer’spreferredtypeofexplanationandcapability
tocomprehendtheprovidedexplanation.
3. SummarizationAssessment. Thisevaluatesthenecessityforaconcisesummaryexplanationinadditionto
individualitempricebreakdownswhileexaminingtheclarityandimpactoftheoverallexplanationonthe
customer.
Like in the medical scenario, participants were prompted to evaluate each explanation format on a scale of 1 to 5,
coveringbothinterpretabilityandeffectiveness. Here,ascore1representstheminimum,and5denotesthemaximum
achievablescore. Interpretabilityscoresvariedfromnotinterpretable(1)tohighlyinterpretable(5). Ontheotherhand,
effectivenessscoresgaugedtheextenttowhichtheexplanationsfacilitateddecision-making,fromnotatallhelpful(1)
toextremelyeffective(5). Forthisusecase,twoquestionnaireshavebeendevisedfortwocategoriesofusers.
4arXivTemplate APREPRINT
1. Decision-makers Seek a comprehensive understanding of feature contributions to model predictions for
systemoptimization. Withtheirexpertbackground,theypreferdetailed,technicalexplanationstobuildtrust
andvalidatethemodel’susebasedonitsaccuracy. Decision-MakersQuestionnaire
2. Customers Favor straightforward, accessible explanations that still convey essential information, aiding
in understanding the rationale behind received offers without overwhelming technical detail.Customers
Questionnaire
The interview, which was recorded as a video file, delved into issues such as finding a balance between accuracy
andexplainabilityine-commercemodels,theincorporationofgraphsandmathematicalformulasintoexplanations,
understandingcustomerbehaviorthroughthedynamicrelationshipbetweenslotavailabilityandpricing,anddesigning
adynamicdashboardtomanagetheinteractionbetweenoperationalefficiencyandcustomerbehavioreffectively.
4.3 SurveymethodsfortheEnergyUseCase
Thequestionnaireaimstoselectpreferredexplanationformatsliketables,charts,interactivegraphics,andtext,as
wellasexplanationtypessuchascausal,contrastive,andcounterfactual. We’vemadesomeassumptionstostreamline
ourstudyandkeepthequestionnairemanageable. Wefocusonoperationalmanagersastheprimaryaudiencefor
explanations,consideringtheirabilitytoprovideinsightfulfeedback. Thesemanagersseekanin-depthunderstanding
ofhowdifferentfeaturesimpactmodelpredictionsandidentifyoptimizationstrategies. Theirexpertiseallowsthemto
comprehendmoretechnicalandsophisticatedexplanations. Theobjectiveistopersuadedecision-makerstoendorse
and apply the model, assuming it’s sufficiently accurate, by delivering explanations that enhance their trust in the
predictions. Conversely,customersareexpectedtofavorstraightforward,non-technicalexplanationsthathelpthem
graspandacceptthereasoningbehindtheofferstheyget.
Theenergyquestionnaireaddressedquestionsinseveralkeyareas:
1. Accuracy-Explainability Trade-off: Explores the willingness of operational managers to sacrifice some
modelaccuracyinfavorofincreasedexplainability.
2. ImportanceofUserExplanations: Determineshowmuchvalueusersplaceonexplanationsprovidedbythe
systemregardingforecastingoperations,theirnecessityinvariouscustomerscenarios,andpreferencesforthe
typesandfrequencyofexplanations.
3. What-ifExplanations(Counterfactuals): Assessestheimportanceofexplainingtousershowtheiractions
couldimpactforecastingoutcomes,thesignificanceoftheseactionsindifferentscenarios,thepreferredforms
ofwhat-ifexplanations,andhowoftentheyshouldbeprovided.
4. FacilityManagers’Explanations: Evaluatestheneedforcomprehensiveexplanationsforfacilitymanagers
regardingdataandmodelsforalluniquebuildingspaces,includingtherelevanceofwhat-ifexplanationsand
theimportanceofvisualizingfeatureimportancethroughmethodslikeSHAPfeatureimportancegraphs.
Allinterviewedexpertsandfiveadditionalenergyexpertshavecompletedthequestionnaire. EnergyQuestionnaire
The interviews delved into the energy solution from various angles, each tailored to the interviewee’s expertise.
Discussionsrangedfromaddressingmarketchallengesinenergysolutionsandtheimportanceofclearexplanationsfor
end-userstoexploringenergyconsumptiondisaggregationandtheroleofgeneticprogramminginenhancinganalysis.
Insights were also shared on leveraging machine learning for water consumption monitoring to optimize resource
managementandidentifyinefficiencies. Additionally,thedesignandusabilityofuserinterfacesforenergymanagement
systemswereexamined,emphasizingtheneedforintuitiveandengaginginterfacestomanageenergyconsumption
better.
5 Results
5.1 Medicalscenario
Figure1summarizeskeyfindingsfromthediabetesquestionnaire.
Thedoctors’preferencesforAIsystemexplanations’keyfindingsincludeawillingnesstotradeoffasmallpercentage
ofmodelaccuracyforgreaterexplainability,challengesinunderstandingcomplexgraphicalrepresentationslikegraphs
andsymbolicregression,andapreferencefordetailedyetintuitiveexplanationssuchasprotocolsandSHAPfeature
importancegraphs. Simplificationandclaritywerehighlightedasessentialforeffectivelyconveyingmodellogic,with
counterfactualexplanationsbeingparticularlyvaluedfortheirpotentialtoimprovepatientunderstandingandtherapy
compliance.
5arXivTemplate APREPRINT
Figure1: Insightsintodoctors’preferencesformedicalcasederivedfromthequestionnaire.
Featureimportancegraphsweremostfavored,followedbytextualexplanationsandrule-basedprotocols. Graphsand
coefficienttableswereleastpreferredduetoconcernsaboutunderstandability.
Keyinsightsfromtheinterviewshaveilluminatedseveralimportantaspects. Theeffortsindevelopingmodelsfor
paragangliomacasesarepioneering,astherearenoexistingbenchmarkstomeasuretheaccuracyofourmodels. The
potential influence of genetic information on the development and progression of paraganglioma was recognized,
underscoringtheimportanceofpersonalizedmedicine. Additionally,anotabledeficiencyincurrentmedicalpractices
istheabsenceoftoolsforeffectivelymonitoringtumorgrowth,indicatingacrucialareafortechnologicaldevelop-
ment. Furthermore,doctorsareseentovaluethepredictionsprovidedbyourmodels,integratingthemintopatient
communications. Thisunderscorestheneedformodelstooffernumericalpredictionsandprovideexplainableinsights
thatenhancedoctor-patienttrustanddecision-makingprocesses. InitialGPmodelsforparagangliomahaveundergone
testing. Forthoseinterestedinexaminingtheoutcomes,referencesSijbenetal.[2024]offerdetailedinsightsintothe
results.
5.2 Retailusecase
The decision-makers seek explanations across various dimensions: customer behavior, transportation costs, and
strategiesformaximizingprofits. Thequestionnairesfindingsaresummarizedinthefigure2
Figure2: Insightsintoonlineretaildecision-makerspreferencesderivedfromthequestionnaire.
Infeedbackfromdecision-makersonAIsystemexplanations,there’sanopennesstosacrificingaportionofmodel
performance for enhanced explainability, with preferences for detailed yet intuitive insights into model workings.
Thisencompassesabroadinterestincustomerbehavior,costanalysis,andprofitstrategies,highlightingadesirefor
interactivetoolsandvisualizationsthatfacilitatedeeperunderstandingandstrategicadjustments. There’sanotable
emphasis on practical application, with decision-makers valuing features like counterfactual explanations and the
abilitytointerpretandactuponcomplexinformation, allaimedatoptimizingoperationalefficiencyandcustomer
engagement. Theinterviewyieldedseveralimportantinsights. There’sanopennesstosacrificingaccuracyforenhanced
explainability,althoughherlimitedexpertiseinmachinelearningcautionsagainsthastydecisionsonF1scoretrade-offs.
6arXivTemplate APREPRINT
Thepreferenceleanstowardsusingvisualelementsinexplanations,carefullyincludingsimplemathematicalformulas
toavoidconfusionwithcomplexoperationslikelogarithms. Usinggraphicaldashboardsisrecommendedforanalyzing
operationalefficiencyandcustomerbehavior,astheyimprovebothinterpretabilityanduserinteraction. Counterfactual
explanationsareparticularlyvaluedfortheirabilitytoillustratetheoutcomesofspecificdecisions,liketheintroduction
ofnewschedulingslots. Developingmodelsdelineatingcustomercharacteristicsbyregionanddifferentiatingbehaviors
acrosstheseregionsarehighlightedasessentialforgainingdeeperbusinessinsights.
5.3 Energyusecase
Theinsightsfromoperationalandfacilitymanagersaresummarizedinfigure3.
Figure3: Theinsightsfromtheenergyquestionnairefromoperationalandfacilitymanagers
Operational managers are receptive to balancing accuracy with increased transparency, showing flexibility in the
accuracy-explainabilitytrade-off, withthedegreeofcompromisevaryingbasedontheaudience. Preferenceslean
towardsvisualandsimplemathematicalexplanationstocatertodifferenttechnicallevelsamongstakeholders. Insights
into operational efficiency and customer behavior are effectively conveyed through graphical dashboards, while
counterfactual explanations offer valuable scenario analysis tools. The approach includes strategic analyses like
regionalcustomerbehaviormodelingandwhat-ifscenarios,underscoringtheutilityoffeatureimportancegraphsand
counterfactualexplanationsforprovidingclearandactionableinsightsacrossvariousaspectsofdecision-makingand
management. Insightsfromtheinterviewssuggestthataforecastingsolutionincorporatingexplanationsisfavored
overabasicmodel. Themethodologiesusedinforecastingandprovidingexplanationsarealsoapplicabletoother
sectors,includinggasandenergyconsumption. It’srecommendedthatthegraphicalinterfaceforend-usersbedesigned
foreaseofuse,possiblyincludinginteractivefeaturessuchasknobs. Additionally,forenergy-relatedapplications,
incorporatingasmartphonecomponentinthetoolsolutiontosendconvenientnotificationstousersisadvised. For
thoseinterestedinexploringtheperformanceofGPmodelswithintheenergyusecase,furtherinformationanddetailed
analysesareavailableinreferencesSakkasetal.[2023]andSakkasetal.[2021].
5.4 Generalguidelines
Thetable1summarizestheoverarchingguidelinesderivedfromthesurveyfindings.
Table1: GuidelinesandInsightsfromUserStudiesonExplanatoryTool’sArchitecture
Domain Insight Recommendation
All Preferenceforexplainabilityoverperfect Balanceexplainabilityandaccuracy,
accuracy,featureimportancegraphsaseffective utilizefeatureimportancegraphs,and
communicationtools,andvalueof supplementcounterfactualsfor
counterfactualexplanations. comprehensiveunderstanding.
Drawingfromtheseinsights,thedesignoftheexplanatorytoolshouldincorporatetwoessentialmodules: aCoun-
terfactual Module, which calculates the minimal changes required to shift the model’s decision towards a desired
outcome,therebyenabling"What-if"scenariosbasedonuserqueries,andaGlobalImportanceModule,whichprovides
7arXivTemplate APREPRINT
visualization of the significant feature contributions to the model’s predictions, in line with findings from the user
studies. Bothmodulesshouldbeintegratedwithinthetool,ensuringthattheinputs,outputs,andconnectionsbetween
modulesarewell-defined.
6 Conclusions
This study identifies foundational components for an XAI framework intended for various applications through
comprehensivequestionnairesandinterviewswithdomainexpertsinthreedistinctusecases. TheenvisionedXAItool
incorporatesaCounterfactualModuletofacilitate"What-if"scenarios,allowinguserstoseehowminimalchanges
couldleadtodesiredoutcomes. Additionally,aGlobalImportanceModuleisdesignedtovisuallyrepresentthemost
influentialfeaturesinmodelpredictions,resonatingwiththeXAIliteratureemphasizingthecriticalroleoffeature
importanceandcounterfactualexplanations. Whileaimingforsharedapplicability,theframeworkalsoacknowledges
theuniquerequirementsofeachspecificcase,althoughthedetailedexplorationoftheseuniquecaseaspectswasbeyond
thispaper’sscope. ThisapproachinformstheongoingdevelopmentoftheAItool,leveraginginsightsgatheredfrom
userstudiestoensurethetool’seffectivenessacrossdifferentdomains. Forfutureresearch,theinterestinonlineretail
andenergysectorsforcustomizableanduser-specificexplanationspointstowardsagrowingtrend. Thistrendleans
towardsintegratingNLPinteractivityintoexplanations,anareawearebeginningtoexplore.
7 Acknowledgments
ThisresearchwasconductedundertheTransparent,Reliable,andUnbiasedSmartToolforAI(Trust-AI)project,with
GrantAgreementID:952060,fundedbytheEUCommission.
References
Yi Mei, Qi Chen, Andrew Lensen, Bing Xue, and Mengjie Zhang. Explainable artificial intelligence by
genetic programming: A survey. IEEE Transactions on Evolutionary Computation, 27(3):621–641, 2023.
doi:10.1109/TEVC.2022.3225509.
MarkusLanger,DanielOster,TimoSpeith,HolgerHermanns,LenaKästner,EvaSchmidt,AndreasSesing,andKevin
Baum. Whatdowewantfromexplainableartificialintelligence(xai)? –astakeholderperspectiveonxaianda
conceptualmodelguidinginterdisciplinaryxairesearch. ArtificialIntelligence,296:103473,2021. ISSN0004-3702.
doi:https://doi.org/10.1016/j.artint.2021.103473. URLhttps://www.sciencedirect.com/science/article/
pii/S0004370221000242.
DavidGunningandDavidAha.Darpa’sexplainableartificialintelligence(xai)program.AIMagazine,40(2):44–58,Jun.
2019. doi:10.1609/aimag.v40i2.2850. URLhttps://ojs.aaai.org/aimagazine/index.php/aimagazine/
article/view/2850.
DavidGunning,EricVorm,YunyanWang,andMattTurek. Darpa’sexplainableai(xai)program: Aretrospective.
AuthoreaPreprints,2021.
AndreasHolzinger, AndréM.Carrington, andHeimoMüller. Measuringthequalityofexplanations: Thesystem
causabilityscale(SCS).comparinghumanandmachineexplanations. CoRR,abs/1912.09024,2019. URLhttp:
//arxiv.org/abs/1912.09024.
Mauro Dragoni, Ivan Donadello, and Claudio Eccher. Explainable ai meets persuasiveness: Translating reason-
ing results into behavioral change advice. Artificial Intelligence in Medicine, 105:101840, 2020. ISSN 0933-
3657. doi:https://doi.org/10.1016/j.artmed.2020.101840. URL https://www.sciencedirect.com/science/
article/pii/S0933365719310140.
Robert R Hoffman, Shane T Mueller, Gary Klein, and Jordan Litman. Measures for explainable ai: Explanation
goodness, user satisfaction, mental models, curiosity, trust, and human-ai performance. Frontiers in Computer
Science,5:1096257,2023.
GiuliaViloneandLucaLongo. Developmentofahuman-centredpsychometrictestfortheevaluationofexplanations
producedbyxaimethods. InLucaLongo,editor,ExplainableArtificialIntelligence,pages205–232,Cham,2023.
SpringerNatureSwitzerland. ISBN978-3-031-44070-0.
SamuliLaato,MiikaTiainen,A.K.M.NajmulIslam,andMattiMäntymäki. Howtoexplainaisystemstoendusers: a
systematicliteraturereviewandresearchagenda. INTERNETRESEARCH,32(7):1–31,May2022. ISSN1066-2243.
doi:10.1108/INTR-08-2021-0600. FundingInformation: Theinitialliteraturesearchuponwhichthisarticledevelops
wasdoneforthefollowingMaster’sthesispublishedattheUniversityofTurku: Tiainen,M.,(2021),Towhomto
8arXivTemplate APREPRINT
explainandwhat?: SystematicliteraturereviewonempiricalstudiesonExplainableArtificialIntelligence(XAI),
availableat: https://www.utupub.fi/handle/10024/151554,accessedApril2,2022.PublisherCopyright: ©2021,
SamuliLaato,MiikaTiainen,A.K.M.NajmulIslamandMattiMäntymäki.
J.W.Smith,J.E.Everhart,W.C.Dickson,W.C.Knowler,andR.S.Johannes. Usingtheadaplearningalgorithm
toforecasttheonsetofdiabetesmellitus. InProceedingsoftheAnnualSymposiumonComputerApplicationin
MedicalCare,pages261–265,1988.
ScottLundbergandSu-InLee. Aunifiedapproachtointerpretingmodelpredictions,2017.
E.M.C.Sijben,J.C.Jansen,P.A.N.Bosman,andT.Alderliesten. Functionclasslearningwithgeneticprogramming:
Towardsexplainablemetalearningfortumorgrowthfunctionals,2024.
NikosSakkas,SofiaYfanti,PoojaShah,NikitasSakkas,ChristinaChaniotakis,CostasDaskalakis,EduardBarbu,and
MarharytaDomnich. Explainableapproachesforforecastingbuildingelectricityconsumption. Energies,16(20),
2023. ISSN1996-1073. doi:10.3390/en16207210. URLhttps://www.mdpi.com/1996-1073/16/20/7210.
NikosSakkas,SofiaYfanti,CostasDaskalakis,EduardBarbu,andMarharytaDomnich. Interpretableforecastingof
energydemandintheresidentialsector. Energies,14(20),2021. ISSN1996-1073. doi:10.3390/en14206568. URL
https://www.mdpi.com/1996-1073/14/20/6568.
9