DeepVoting: Learning Voting Rules with Tailored
Embeddings
LeonardoMatone*1,BenAbramowitz†1,2,NicholasMattei‡1,and
AvinashBalakrishnan§3
1
DepartmentofComputerScience,TulaneUniversity,NewOrleans,LA70118,USA
2GoodLynx,LongIslandCity,NY,11101
3IBMChiefAnalyticsOffice,Armonk,NY,10504
August27,2024
Abstract
Aggregatingthepreferencesofmultipleagentsintoacollectivedecisionisa
common step in many important problems across areas of computer science in-
cludinginformationretrieval,reinforcementlearning,andrecommendersystems.
AsSocialChoiceTheoryhasshown,theproblemofdesigningalgorithmsforag-
gregationruleswithspecificproperties(axioms)canbedifficult,orprovablyim-
possible in some cases. Instead of designing algorithms by hand, one can learn
aggregationrules,particularlyvotingrules,fromdata.However,thepriorworkin
this area has required extremely large models, or been limited by the choice of
preferencerepresentation,i.e.,embedding.Werecasttheproblemofdesigninga
goodvotingruleintooneoflearningprobabilisticversionsofvotingrulesthatout-
putdistributionsoverasetofcandidates.Specifically,weuseneuralnetworksto
learnprobabilisticsocialchoicefunctionsfromtheliterature.Weshowthatem-
beddingsofpreferenceprofilesderivedfromthesocialchoiceliteratureallowsus
to learn existing voting rules more efficiently and scale to larger populations of
votersmoreeasilythanotherworkiftheembeddingistailoredtothelearningob-
jective.Moreover,weshowthatruleslearnedusingembeddingscanbetweaked
tocreatenovelvotingruleswithimprovedaxiomaticproperties.Namely,weshow
thatexistingvotingrulesrequireonlyminormodificationtocombataprobabilistic
versionoftheNoShowParadox.
1 Introduction
Research in Computational Social Choice (COMSOC) and Algorithmic Game The-
ory (AGT) focuses heavily on the design and analysis of mechanisms for collective
*Email:lmatone@tulane.edu
†Email:babramow@tulane.edu
‡Email:nsmattei@tulane.edu
§Email:avinash.bala@us.ibm.com
1
4202
guA
42
]AM.sc[
1v03631.8042:viXradecision making. Canonically, agents arrive with individual preferences over a set of
alternatives or outcomes, and a centralized mechanism must aggregate these prefer-
encesintoasharedchoice(votingandselection)orallocationofitems(matchingand
auctions)ShohamandLeyton-Brown[2008].Thegoalistodesignmechanismswith
certain desirable properties, characterized by axioms; i.e. optimizing a particular ob-
jectiveorsatisfyingcertainconstraints.
OneofthecentralresultsinsocialchoiceisArrow’sGeneralImpossibilityTheo-
rem Arrow et al. [1963], which identifies a set axioms that no collective mechanism
can satisfy at once. Following Arrow, decades of research has produced myriad the-
orems showing which axioms are satisfied by which mechanisms and which sets of
axioms lead to an impossibility result Sen [2018]. On the algorithmic and computa-
tionalsidethisincludespropertiesofoptimalityandcomputationalcomplexityBrandt
etal.[2016].
Findingrulesthatsatisfyagivensetofaxiomscanbedifficult,especiallywhenitis
unknownifsucharuleexists.Hence,recentworkhasturnedtomachinelearningtech-
niquestodesignnovelmechanisms.Thisideahasbeenappliedinareasfromauctions
tovotingrulestomatchingsXia[2013],Sandholm[2003],Curryetal.[2022],Ravin-
dranath et al. [2021]. Previous work on learning voting rules has been hampered by
technicalchallenges,includingextremelylarge/sophisticatedneuralnetsAnilandBao
[2021],limiteddataBurkaetal.[2022],orfailuretoaccountforthefullconsequences
ofthedesignchoicesFirebanks-Quevedo[2020].
Our approach to improving the learning of existing and novel voting rules is to
use hand-crafted embeddings derived from the social choice literature. As we show,
these embeddings enable fast learning with fewer parameters and the ability to scale
to larger populations of voters. Our embeddings reduce the input size of our neural
net, greatly reducing the number of model parameters. Anil and Bao [2021] found
thatusingamulti-layerperceptron(MLP),i.e.,adeepneuralnetwork,tolearnvoting
rules was limited by the network’s fixed input size, and so they introduced more so-
phisticatedarchitecturestopermitscalingandpadsmallerprofiles.Intheirteststosee
whicharchitecturesscaledbestwiththenumberofvoters,theirMLParchitecturewas
necessarilyexcluded.Bycontrast,ourembeddingsenablethesizeoftheinputlayerof
theMLPtobeindependentofthenumberofvoters,therebyenablinggreatergeneral-
izationwithscale.Similarly,whenwetrainortestourmodelwithpreferenceprofiles
containingfewervoters,ourinputdoesnotrequireanyformofpadding.Asweshow,
when using embeddings to learn particular rules or axioms, the choice of embedding
mustcorrespondtothelearningobjective.
Sen[2018]observedthatmechanismscanbeexaminedintermsofwhatinforma-
tion they use and ignore from preference profiles. A key contribution of our work is
a more complete understanding of the relationship between the choice of embedding
andtheresultinglearnabilityandefficiencyofthemechanisms.Weobservethat,like
anycompressionalgorithm,embeddingscanbelossyandimposeaboundonthelearn-
abilityofrulesandaxioms.Indeed,weshowthatcertainembeddingslosetherequired
informationneededtolearnparticularrules.Ourexperimentshavealsoleadustopose
newtheoreticalquestionsabouttheinformationpreservationofembeddings.
When most people think of voting they think of classical deterministic rules that
takeinpreferencesoverasmallsetofcandidatesandreturnasinglewinnerZwicker
2[2016], Taylor [2005]. However, the full space of social choice mechanisms is much
richerwithmechanismsvaryingbythedatatypesoftheirinputsandoutputs.Forexam-
ple,votersmaygiveapprovalballots,rankings,orweightingstodifferentcandidates;
theoutcomeofthemechanismmaybeasinglewinningcandidate,collectionofwin-
ners,ororderingofthecandidates,amongotheroptions.
We study probabilistic social choice functions (PSCFs) which take a profile over
candidates and return a lottery (probability distribution) over the candidates Brandt
[2017]. PSCFs offer several advantages when learning voting rules with neural net-
worksascomparedtosingle-winnervotingrules.First,sinceweareoutputtingalot-
teryoverthealternatives,wearenotasconcernedwithtie-breaking.Tie-breakingin-
troducescomplicationsintothedesignandanalysisofvotingrulesAzizetal.[2013b],
andrandomtie-breakingisnotlearnable.Second,PSCFsprovideanaturalconnection
betweenthediscreteformulationsofrulesandaxiomsandtheconstructionofcontinu-
ouslossfunctionsfortrainingbasedondivergencesbetweendistributions,e.g.L1.
Afterfirstshowingthatexistingrulescanbeefficientlylearnedusingtailoredem-
beddings,weaddressthechallengeoftakingexistingrulesandtweakingthemtoim-
prove their axiomatic properties. In particular, we focus on the No Show Paradox in
whichavotercaninduceanoutcometheypreferbyabstaininginsteadofvotingMoulin
[1988]. Certain single-winner rules, like Plurality, Borda, and Simpson-Kramer are
knowntosatisfytheParticipationaxiom,sonovotercanbemadebetteroffbyabstain-
ingandtheparadoxdoesnotarise.However,mostothercommonvotingrulesexhibit
thisparadox.Inourexperiments,wetakemodelstrainedtolearnexistingPSCFsand
retrainthemusingalossfunctionthataddsinacontinuousrelaxationoftheParticipa-
tion axiom and show which rules can be adjusted to be more resistant to the paradox
withoutsacrificingaccuracy.
WechoosetheParticipationaxiominparticularbecauseitisaninter-profileaxiom,
which requires reasoning about counterfactuals on what the preference profile could
have otherwise been had the voters behaved differently. Inter-profile axioms are par-
ticularly challenging for learning from data because they increase the computational
complexityofcomputinglossfunctions.Italsorequiresthatthemodelbeabletotake
profilesofdifferentsizes(differingbyonevoter)asinput,whichourembeddingsen-
ableustodo.Sinceabstentioncanbeastrategicbehaviorbyvoters,learningthePar-
ticipationaxiomiscloselyrelatedtoAutomatedMechanismDesign,whichfocuseson
creatingdesirableeconomicmechanismsforstrategicagentsand“shiftstheburdenof
designfrommantomachine”Sandholm[2003].
2 Related Work
Xia [2013] and Procaccia et al. [2009] proposed incorporating voting axioms into a
machine-learning framework as a means of evaluating learned social choice mech-
anisms. In the space of auction design and matching there has been work on using
neuralnetsforbettermechanismsDu¨ttingetal.[2019],Pavlov[2011],Malakhovand
Vohra[2008]includinglearningnewtypesofauctionmechanismsCurryetal.[2022]
as well as complex preference structures Peri et al. [2021]. More recently, the work
of Ravindranath et al. [2021] has looked at how to learn new allocation mechanisms
3that bridge the gap between stability (as compared to the deferred acceptance algo-
rithmGaleandShapley[1962])andstrategyproofness(ascomparedtorandomserial
dictatorship(RSD)Azizetal.[2013a]).WhiletheworkofRavindranathetal.[2021],
Firebanks-Quevedo[2020],andmostrecentlyAnilandBao[2021]hasshownpromise
forlearningmechanisms,theseeffortsdonotcloselyconsidertheroleofembeddings.
Whileformal proposalsto learnvoting rulesdate backover adecade Xia[2013],
considerableattentiontolearningvotingruleshasincreasedinrecentyears.Kujawska
etal.[2020]andBurkaetal.[2022]usedseveralcommonmachinelearningmethods
to mimic existing voting rules. However, both of these works overlooked the impor-
tanceofthechoiceofembeddingintheroleoflearning,findingthatcertainruleswere
“easier” to learn. Subsequently, Anil and Bao [2021] showed that PIN architectures
have the advantage of better generalization to larger numbers of voters. We build on
thisworkbyshowingthatwecanachievehighaccuracyefficientlywithsmallMLPs
byusinghand-craftedembeddings.
Procaccia et al. [2009] showed that positional scoring rules are efficiently PAC
learnable,butlearningpairwisecomparison-basedvotingrulesrequiresanexponential
numberofsamples.Whilewedonotescapetheasymptoticlimits,weexaminetwoem-
beddingsbasedontournamentgraphsthataredesigntofacilitatemoreefficientlearn-
ing of pairwise-comparison based rules. Firebanks-Quevedo [2020] use one measure
ofoptimality(Condorcetconsistency)andstrategyproofnessforlearning.However,the
manipulationsofthechosenembeddingcannotlearnstrategyproofness,leadingtopoor
results.Finally,Wilson[2019]focusontheproblemoflearningavotingrulegivena
set of pair-wise relations and properties that must hold for the optimization criteria.
However,thisworkisfocusedonthepossibilityoflearningthesefunctionsanddoes
notemployanymachinelearningtechniques.
The loss function chosen by Armstrong and Larson [2019] was a function of the
profileandoutcome,andthuscouldlearnarulebutnotinter-profileaxiomslikePar-
ticipation.Recently,Mohsinetal.[2022]focusedontheproblemofdesigningand/or
learningfairandprivaterules,provingthatundermeasuresofdifferentialprivacythere
isanupperboundonthetrade-offbetweengroupfairnessandefficiency.
Learningvotingrulesbearssomesimilaritytothewellstudiedareaoflearningto
rank (L2R) from the machine learning literature Cao et al. [2007]. In L2R one typi-
callyisconcernedonlywithaccuraterecoveryofthepopulationpreferenceandnotthe
axiomsorpropertiesoftheaggregationmethoditself(e.g.,fairness).Indeed,onecan
thinkofourworkenforcinginter-profileaxiomsonthelearnedaggregationprocedures
asanimportantstep.
3 Preliminaries
AgentsandPreferenceProfiles LetV beasetofnvotersandC asetofmcandi-
dates. Each voter i ∈ V reports a strict order x over all the candidates in C as their
i
ballot.Wewilldenotethatistrictlyprefersaoverbbya ≻ bfora,b ∈ C.Thereare
i
m!possibleballots,orwaystostrictlyorder(permute)thecandidatesinC.Alistofn
ballots,oneforeachvoter,constitutesaprofileX = (x ) .Voterirankscandidate
i i∈V
a at position x (a) ∈ [m], using [k] = {1,...,k}. Let X be the set of all possible
i
4profiles.
Probabilistic Social Choice Functions A probabilistic social choice function
(PSCF) is a function f : X → ∆(C) that takes a profile X ∈ X as input and re-
turnsalottery,orprobabilitydistributionf(X) ∈ ∆(C)overthesetofcandidatesin
theprofile,where∆(C)isthesetofalllotteriesoverC.LetF bethesetofallsuch
PSCFs.
AnyPSCFcanbeusedtoconstructanon-deterministicvotingrulebysamplinga
winnerfromthelottery.APSCFthatplacesallprobabilitymassonasinglecandidate
forallprofilesisdeterministic.Ifthecandidatethatreceivesalloftheprobabilitymass
isthesamecandidateforallprofiles,thenitisadictatorialvotingrule.ManyPSCFswe
considerreturnforallprofilesalotterythatisauniformdistributionoveranon-empty
subsetofthecandidates,i.e.,therearemultiplepotentialwinnersthatwewouldhave
tochoosefromforasingle-winnervotingrule.Therefore,letU(Y)denotetheuniform
distribution over any finite set Y. When referring to lotteries over candidates, we let
U(Y)denotethedistributionthatisuniformoverY ⊆C andzeroonC\Y.
Embedding
Simplefeed-forwardneuralnetworksrequireafixed-sizeinputforlearningandinfer-
ence, corresponding to the size of their input layer. If we were to learn voting rules
using neural networks that take the entire profile as input, then not only does the in-
put layer need to be large (m×n), but it also prevents scaling up as the number of
voters grows. Similarly, if the number of voters shrinks, then the profile would have
tobepaddedcarefullyinawaythatdoesn’tnegativelyimpactthemodel.Ifwewant
to learn rules that are agnostic to the number of voters, we need to construct embed-
dingsoffixed-sizethatretaintherelevantinformationforprofileswithanynumberof
voters. Naturally,different embeddingspreservedifferent informationfrom theorigi-
nalprofile,leadingthemtodifferentefficacywhenlearningdifferentrulesandaxioms.
Notethatmostrulesandaxiomsintheliteraturearedefinedforanypositivenumberof
voters,sowewouldlikeourlearnedmechanismstobesimilarlyagnostic.
An embedding T is a function T : X → X′ mapping profiles to some codomain
X′. The embeddings we are concerned with are many-to-one mappings. This means
multipledifferentprofilesmayhavethesameembedding,i.e.T(X)=T(X˜)forsome
X,X˜ ∈ X where X ̸= X˜. In other words, T will not be reversible, and T(X) will
not preserve all information about X. We denote by F′ the set of all probabilistic
functions of the form f′ : X′ → ∆(C). Note that while we designate X to always
containstrictordersovercandidates,thestructureofX′ willbedifferentfordifferent
embeddings. Our three embeddings are drawn from the voting literature, but are not
commonlyrecognizedasembeddingsinthemachinelearningliterature.
Definition1(TournamentEmbedding). Givenaprofile,thetournamentembeddingT
T
producesam×mmatrixM whereM[j,k]=1ifamajorityofvoterspreferj ≻ k,
i
M[j,k]=0ifamajoritypreferk ≻ j,andM[j,k]= 1 ifanequalnumberofvoters
i 2
prefereachcandidate(whenniseven),forcandidatepairsj,k ∈C.
5Figure1:Eachofourthreeembeddingsderivedfromaballotprofile.Notethatthesize
oftheprofile(a)growsinO(mn),whileeachofourembeddingsgrowswithO(m2),
whichisfarsmallerwhenm<<n.However,ourembeddingsdonotalwayspreserve
alloftheinformationintheoriginalprofile.
Definition2(WeightedTournamentEmbedding). Givenaprofile,theweightedtour-
nament embedding T produces a m×m matrix M where M[j,k] = |{i ∈ V :
WT
j ≻ k}|forj,k ∈C.
i
ObservethatT containsstrictlymoreinformationabouttheoriginalprofilethan
WT
T asthetournamentcanbecomputedfromtheweightedtournament.
T
Definition3(RankFrequencyEmbedding). Givenaprofile,therankfrequencyembed-
dingT producesam×mmatrixM showinghowmanyvotersrankeachcandidate
RF
c∈C ineachpositionk ∈[m]whereM[c,k]=|{i∈V s.t. ≻c=k}|.
i
Thereisatensionintheliteraturebetweenrulesthatusepositionalinformation,like
scoringrules,andthosethatrelyonmajoritarianorpairwisecomparisoninformation,
liketournamentrulesBrandtetal.[2014].NoteT maintainspositionalinformation
RF
whileT andT maintainmajoritarian.
WT T
ProbabilisticSocialChoiceFunctions
We now define our PSCFs. Where necessary, we always break ties lexicographically.
DefinitionsforIRVandBlack’sruleareinAppendixA.Weincludetworulesthatare
typically classified as scoring rules in the voting literature, Borda and Plurality. The
outcomeofanyscoringrulecanbeexactlycomputedfromT .
RF
Definition4(Borda). TheBordascoreofcandidatec ∈ C fromprofileX isB(c) =
(cid:80)
(m−x (c)).LetW(X)=argmaxB(c)bethesubsetofcandidateswithmaximum
i
i∈V c∈C
Bordascore.TheprobabilisticBordarulereturnsthelotteryU(W(X)).1
1ReferredtoasBordaMaxbyEndriss[2017].
6Definition 5 (Plurality). The Plurality score of candidate c ∈ C from profile X is
L(c) = |{i ∈ V : x (c) = 1}|. Let W(X) = argmaxL(c) be the subset of candi-
i
c∈C
dateswithmaximumPluralityscore.TheprobabilisticPluralityrulereturnsthelottery
U(W(X)).
Therestofourrulesarenotscoringrules.Copelandistypicallyclassifiedastour-
namentrulesinceit’soutcomecanbecomputeddirectlyfromT Brandtetal.[2014].
T
Definition6(Copeland). TheCopelandscoreofcandidatec∈CfromprofileX isthe
numberofothercandidatesitbeatsinpairwisecompetitionplus 1 timesthenumberof
2
othercandidatesittieswithindirectcompetition(ifniseven).LetW(X)bethesubset
ofcandidateswithmaximumCopelandscoreonprofileX.TheprobabilisticCopeland
rulereturnsthelotteryU(W(X)).
TheSimpson-Kramer(Maximin)andSchulzerulesareeachcomputedfromT .
WT
We will call these weighted-tournament rules. Let G (C,E) be the directed tourna-
X
mentgraphwithedgescorrespondingtoallpositivevaluesofthetournamentmatrixin-
ducedbyX.Leteachdirectededge(a,b)∈Ehaveweightd(a,b)=|i∈V :a≻ b|.
i
Definition7(Simpson-Kramer). LetW bethesubsetofcandidateswhosemaximum
weightincomingedgeisminimalinG .TheprobabilisticSimpson-Kramerworkre-
X
turnsthelotteryU(W(X)).
Definition8(Schulze). ForeachpathfromatobinG ,weletthestrengthofthepath
X
betheminimumweightedgeinthatpath.Foreachpairofcandidatesa,b ∈ C witha
pathfromatob,weletp(a,b)bethemaximumstrengthofanypathfromatob,andlet
p(a,b)=0otherwise.Finally,letW(X)={a∈C :p(a,b)≥p(b,a)forallb∈C}.
TheprobabilisticSchulzerulereturnsthelotteryU(W(X)).
Some,butnotall,oftheruleslistedaboveareCondorcet-consistent,meaningthat
theyplaceallprobabilitymassontheCondorcetwinnerwheneveroneexists.ACon-
dorcet winner is a candidate who beats all other candidates in pairwise competition,
whichcanbeinferredfromT orT .
T WT
4 PSCF Preservation Under Embedding
Weareconcernedwithwhatinformationispreservedbyembeddings,andwhetherthis
informationissufficienttoimplementPSCFs,i.e.tolearnthemperfectly.
Definition9(PSCFPreservation). APSCFf :X →∆(C)ispreservedbyembedding
T :X →X′if∃f′ :X′ →∆(C)suchthatf′(T(X))=f(X)forallprofilesX ∈X.
Proposition 1 says that for an embedding T to preserve a PSCF, there cannot be
two profiles with the same embedding under T for which the PSCF returns different
lotteries.
Proposition1. EmbeddingT preservesPSCFf ifandonlyifforallpairsofprofiles
X,Xˆ ∈X wehaveT(X)=T(Xˆ)⇒f(X)=f(Xˆ).
7T T T
RF WT T
Plurality ✓ × ×
Borda ✓ ? ×
Copeland × ✓ ✓
Schulze × ✓ ×
Ranked Pairs × ✓ ×
Simpson-Kramer × ✓ ×
IRV × ? ×
Black’s Rule × ? ×
Table1:PSFCpreservationunderembedding
Some embeddings preserve strictly greater information than others. For example,
lexicographically sorting the preference orders in a profile preserves all information
necessarytocomputeT ,andT preservesallinformationnecessarytocompute
WT WT
T from a profile. This implies that if T preserves a function f, then T must
T T WT
preservef aswell.
Proposition2. SupposethatforT : X → X′ thereexistT : X → Xˆ andT : Xˆ →
1 2
X′ suchthatT(X) = T (T (X))forallX ∈ X.Thenforallf ∈ F,T preservesf
2 1
onlyifT preservesf.
1
SincewecancomputeT fromT ,T canonlypreserveaPSCFifT doesas
T WT T WT
well.However,thereversedoesnothold.T maypreservePSCFsthatarenotpre-
WT
servedbyT .IfanembeddingpreservesaPSCF,thenthePSCFisperfectlylearnable
T
fromtheembedding.
Table1showswhichPSCFsarepreservedbyourembeddings.SeeAppendixBfor
proofsofthenegativeresultsinTable1wherePSCFsarenotpreserved.Thequestion
marksinthetablerepresentrule-embeddingpairsforwhichwecouldnotfindsucha
counterexamplefrombruteforcesearch,andyetdonothaveaproofthatpreservation
holds.
5 Learning Lotteries from PSCFs
In our first set of experiments, we show that with proper embeddings we can learn
PSCFsthatgeneralizecommonvotingrulesusingnetworkarchitectureswithfewpa-
rameters. We train each of our 21 rule-embedding pairs separately to compare their
performance,andshowhowthechoiceofembeddingmustcorrespondtothechoiceof
rule.
8Figure 2: L1 rule loss on validation set of random profiles for Plurality, Borda,
Copeland,andSchulzeperepoch.
ExperimentalSetup WetrainourPSCFsonprofileswithn=29votersandm=7
candidates.Forallexperiments,profilesaregenerateduniformlyatrandom,reflecting
theimpartialcultureassumptionBlacketal.[1958].LikeFirebanks-Quevedo[2020],
weusetheWhalruspackagetoimplementourvotingrules.2
Embeddings afford three key advantages: (1) They reduce the size of the input
layerofourneuralnet,whichisafullyconnectedlayer,andthereforegreatlyreduce
thenumberofmodelweights.Allthreeofourembeddingscompressthen×mprofile
toanm×mmatrixrepresentation,sothesameMLParchitecturecanbeusedforall
trainingruns.(2)Whenaruleispairedwithanappropriateembedding,theembedding
preservesalltheinformationnecessarytolearntheruleandremovesunnecessaryinfor-
mation.(1)and(2)meanthatwelearnPSCFsfasterandmoreaccuratelythanprevious
work.(3)Inputsizenolongerdependsonthenumberofvoters,whichlendsitselfto
better scaling. For T and T we normalize the input by dividing all elements in
RF WT
theembeddingbyn,e.g.theelementsoftheT nowrepresentthefractionofvoters
WT
whopreferonecandidatetoanother d(a,b) fora,b∈C.
n
WeemulatetheMLParchitectureofAnilandBao[2021],with5fully-connected
layersof120nodes,ReLUactivationfunctions,andaSoftmaxlayerfortheoutput.The
keydifferenceisthatournetworktakesinembeddedprofilessothesizeofourinput
2https://pypi.org/project/whalrus/
9layerism2 comparedtotheirnm2.Thisbringsourtotalnumberofmodelparameters
down to just under 50K vs. 200K. We train our models on a set of 48,000 randomly
sampled profiles in batches of size 32 for 1000 epochs, for a total of 1.5M gradient
steps.TheuseofembeddingsalsoallowsustotestourMLPmodelonlargerprofiles
withoutincreasingthesizeofthenetwork,whichAnilandBao[2021]wereunableto
dofortheirMLPmodel,andonlyprovidedfortheirmoresophisticatedarchitectures.
We trained each model on NVIDIA Volta V100 GPUs using PyTorch, with each run
taking≈1hour.WeusedtheAdamoptimizerforeachrunwithaninitiallearningrate
of0.001,tuningonplateau(patience=10,factor=0.5,min lr=0.01).Werefertothe
L1 distance between our model output and the PSCF lottery on a profile as the rule
loss.RulelossespresentedinTable2andTable3arefromatestsetof10,000random
profiles sampled independently of the training data. All of these models were trained
tominimizerulelossfortheirrespectivePSCFs.
T T T
RF WT T
Plurality 0.000706 0.154674 0.150783
Borda 0.002114 0.001468 0.065766
Copeland 0.070568 0.058405 0.000737
Schulze 0.071135 0.060596 0.044539
Simpson-Kramer 0.072062 0.056812 0.045097
IRV 0.092131 0.109611 0.079310
Black’sRule 0.029726 0.029520 0.037891
Table2:AveragerulelosstestingmodelstrainedtolearnPSCFsonuniformlyrandom
profiles(m=7,n=29).
LearnedPSCFs Figure2showsplotsofourvalidationlossesduringtraining,using
datanotusedduringtraining,toillustrateourobservations.Theplotsfortheremaining
rulescanbefoundinAppendixC.
The scoring rules, Plurality and Borda, learn very rapidly using T with rule
RF
lossesconvergingtozeroinasmallnumberofepochs,asexpectedbecauseT pre-
RF
serves all scoring rules. For plurality, we see a non-zero plateau for T and T , as
WT T
theydonotpreserveallinformationneededtolearntherule,andsothereisanon-zero
lowerboundtotheerrorrate.
OneofourmostsurprisingresultsisthatBordaappearstolearnjustaswellfrom
T asfromT .ThisraisesthequestionofwhetherT preservesBorda.Toour
WT RF WT
knowledge, there is no known explicit algorithm for computing the Borda outcome
fromaweightedtournament.WeposethesamequestionforIRVandBlack’sRulewith
T .InSocialChoicethereisthoughttobeatensionbetweenpositionalinformation,
WT
suchasthatcontainedinT ,andpairwisecomparisons.Forexample,noscoringrule
RF
canbeCondorcet-consistent.SoifBordacanbecomputedfromweightedtournament
graphs,assuggestedbyourlearningexperiments,thiswouldbeasurprisingresult.Our
searchforcounterexampleswithsmallnumbersofvotersandcandidatesdidnotyield
10anyresults,butthissearchwaslimitedbycomputationalintractability.
Challenge. Does the weighted tournament embedding preserves Borda, IRV, or
Black’srule?
Asexpected,theCopelandrulelearnsrapidlywiththeT ,convergingtonearzero
T
lossquicklyasCopelandcanbecomputedfromT .Whileanyrulethatcanbecom-
T
putedfromT canalsobecomputedfromT ,whatweseeisthattheCopelandrule
T WT
lossconvergestozeromuchmoreslowlyfortheT ,failingtoreachthesameloss
WT
as T in our experiments after 1000 epochs. We make a similar observation for the
T
Schulzerule.However,unlikeCopeland,SchulzecanbecomputedexactlyfromT
WT
butnotT .ThisiswhyweseethelosswithT plateauatanonzerovalueforSchulze
T T
inFigure2.Andyet,therulelossforCopelandwithT failstosurpassT after1000
WT T
epochs.Thishighlightsboththebenefitsofchoosingtherightembeddingfortherule,
andthatembeddingscontainingmoreinformationmayleadtoslowerlearning.Similar
observationcanbemadefortheSimpson-Kramerrule.Forseveralofourrules,when
usingT ,theruledoesnotappeartofinishlearningafter1000epochs.Ultimately,
WT
nosingleembeddingperformsbestacrossallrules.
T T T
RF WT T
Plurality 0.033898 0.173783 0.188456
Borda 0.016891 0.014817 0.081727
Copeland 0.085109 0.085285 0.000763
Schulze 0.089108 0.100582 0.149869
Simpson-Kramer 0.089382 0.100518 0.054845
IRV 0.114596 0.121245 0.094002
Black’sRule 0.042577 0.040671 0.206753
Table 3: Rule loss on models trained on random profiles (m = 7,n = 29) tested on
profileswithn=199voters.
ScalingWithNumberofVoters
Our embeddings give us the ability to work with profiles with different numbers of
voters.Althoughwetrainedourmodelsonlywithprofileswith29voters,wecantest
with larger and smaller numbers of voters to check generalizability. We test first on
profiles with 199 votes (Table 3), and then again with only 9 voters (Table 6 in Ap-
pendix D). We see that there is an increase in the loss in relative terms for all rules,
but most losses remain quite low compared to their initial losses during training. We
note that the Copeland rule with T scaled the best, with low error in absolute terms
T
across all treatments. All of the rules besides Plurality and Borda generalized better
inrelativetermswithT thandidPluralityandBorda,howeverPluralityandBorda
RF
maintainedthelowesterrorswiththatembedding.Therule-embeddingpairswiththe
highest errors initially, also tended to scale quite well in relative terms. And all rules
11performedbetterwith9votersthanwith199forallembeddings.Whenscalingto199
voters, Schulze and Black’s rule did exceptionally poorly with T . Once again, this
T
highlights the importance of choosing an embedding that fits the rule, corresponding
tothelearningobjective.Nosingleembeddingdoesbetterthantheothersforscaling
acrosstheboard.
Figure3:ValidationlossesformodelstrainedtolearnPSCFswithm=7,n=29and
retrainedtolearnParticipationwithcombinedlossonprofileswithm=7,n=9.
6 Resisting the No Show Paradox
PSCFs based on voting rules can be vulnerable to the No Show Paradox, where a
voterpreferstheoutcomeyieldedbyarulewhentheydonotvote.Thevotertherefore
has an incentive to abstain rather than report their true preference. A rule for which
this cannot occur is said to satisfy the Participation axiom. We now employ transfer
learning, taking our already trained models from Section 5 and retraining them with
a loss function that adds a term for Participation loss, which is our relaxation of the
binaryparticipationaxiomtoacontinuouslossfunction.
Foralldefinitionsbelow,letP beaprobabilitydistributionderivedfromprofile
X
XbysomePSCFf (implicit),andletP (c)betheprobabilityassignedtocandidatec.
X
Wherethespecificprofileisnotrelevant,wewilldenotesimplybyP(c)theprobability
assignedtocandidatecbyalotteryP.Wenowprovidealossfunctionthatmeasures
12howwellaPSCFsatisfiesparticipationorhowcloseaPSCFcomestosatisfyingpar-
ticipation. We use stochastic dominance to model a voter’s preference between two
lotteriesbasedontheirpreferenceorderovercandidates.
Definition 10 (Stochastic Dominance). Let σ be an ordering (or permutation) over
theset ofcandidates C,and let σ[k] bethe kth elementof σ for k ∈ [m]. Giventwo
lotteries P and Q over C, P stochastically dominates Q with respect to σ if for all
(cid:80) (cid:80)
k ∈[m], P(σ[l])≥ Q(σ[l]).
l≤k l≤k
We say that a voter’s abstention leads to an outcome (P) they prefer if the new
outcome stochastically dominates the outcome (Q) that would derive from the true
profile, with respect to the voter’s ordering of the candidates σ = x . We want our
i
PSCFtobestrategyproofwithrespecttothelimitedclassofstrategicabstentions.
Definition11(Participation). APSCFf obeysparticipationif,forallprofiles,every
voterpreferstheoutcomeunderf whentheyvotetheirtruepreferencetotheoutcome
under f when they abstain (i.e. removed). We say that a voter prefers the outcome Q
fromvotingtruthfullyoverthelotteryP fromabstainingifQstochasticallydominates
P.
Since Participation is a binary condition for a PSCF, to learn PSCFs that resist
theNoShowParadox,wedefineanon-binarylossfunctionforParticipationbasedon
stochasticdominance.
Definition12(StochasticDominanceLoss). GivenorderingσoverC,alotteryP,and
areferencelotteryQ,wesaythatthestochasticdominancelossiszeroifP stochas-
tically dominates Q. If P does not stochastically dominate the reference lottery Q,
(cid:80) (cid:80)
thenthelossisequaltoL(P|σ,Q)= max( Q(σ[l])− P(σ[l])),i.e.thelargest
k∈[m] l≤k l≤k
differencebetweenthesumsofprefixesofthelotteriesoverallprefixeswhenthedistri-
butions’supportsareorderedbyσ.
Definition13(ParticipationLoss). GivenaprofileX,LetPi bethelotteryunderf
X
whenvoteriabstainsandallothersvotetruthfully,andletQ bethelotteryunderf
X
whenvotingtruthfully.L(f,X)=maxL(Pi |σ,Q )
X X
i∈V
TheresultsinTable4aresurprising.Thesingle-winnerversionsofBorda,Plurality,
and Simpson-Kramer do not suffer from the No Show Paradox, and yet our learned
models for the PSCFs based on these rules show similar Participation losses to our
otherrules.PluralityshowedalowerinitialParticipationlosswhentrainedwithT ,
RF
but not drastically lower. This may be due to our choice of the maximum stochastic
dominance loss over all voters for a profile rather than, say, the sum of such losses
across all voters. The rest of our rules are known to suffer from the paradox Pe´rez
[2001], although the paradox does not arise frequently Brandt et al. [2019]. And it is
knownthatCondorcet-consistencyisincompatiblewithParticipationwhenthereareat
least4candidatesandatleast12votersBrandtetal.[2017].Byourmeasure,almost
alllearnedruleshavesimilarinitialParticipationlossinTable4.
13T T T
RF WT T
Plurality 0.282162 0.412889 0.411734
Borda 0.409378 0.408852 0.423503
Copeland 0.399701 0.380584 0.389514
Schulze 0.413933 0.388911 0.395796
Simpson-Kramer 0.403704 0.395422 0.393872
IRV 0.409915 0.413539 0.426163
Black’sRule 0.416672 0.415060 0.409416
Table4:ParticipationLossofmodelstrainedtolearnPSCFsonprofilesofsize(m=7,
n=29),testedon1000randomprofilesofsize(m=7,n=9).
ExperimentalSetup Retrainingusesthesamearchitecturesandsetupastheinitial
training.However,weretrainon900randomprofileswith7candidatesand9votesas
theNoShowParadoxismorelikelytooccurwithfewervoters.Ourabilitytochange
the numbers of voters, without padding the profile, is a benefit of our embeddings.
Tocomputeourloss,weaddParticipationLossandtheoriginalL1rulelossforeach
profile.Weretrainfor200totalepochspermodel.
Using fewer voters for training is also more computationally efficient, which is
importantbecausecomputinglossesbasedonnalternativeprofilesforeachprofilein-
creasestheruntimebyO(n).Thisisamajorchallengeforallinter-profileaxiomsthat
involvecounterfactualcomparisons.Theaddedcomplexityhingesonhowmanydiffer-
entprofilesmustbeconsideredtoevaluatewhetheranaxiomissatisfiedSchmidtlein
[2022],SchmidtleinandEndriss[2023]
WedidnotretrainallofourmodelsforTable5.Instead,foreachrule,weretrained
modelsusing(1)theembedding(s)knowntopreservetherule,ifany,and(2)whichever
embedding(s)performedbestinourinitialexperiment.InFigure3weplottheepoch
lossesfromanindependentvalidationsetwith100disjointrandomprofiles.Eachplot
showstheParticipationloss,ruleloss(L1),andthesumofthetwousedasthecombined
lossfunctionfortraining.AdditionalresultsareinAppendixE.
Participation-AdjustedPSCFs ThethreeruleswetrainedandretrainedusingT
RF
–Plurality,Borda,andBlack’sRule–alllearnedtominimizetheirParticipationlossef-
ficiently,withlittleornoincreaseintheruleloss,asshowninTable5.Pluralitylearned
mostefficiently,beingtheonlyexperimentinwhichtheaxiomlossdroppedbelowthe
rule loss within 200 epochs. Despite Borda having higher Participation loss initially
than we might have expected due to single-winner Borda satisfying Participation, it
learnedtoevadetheNoShowparadoxquiteeasily.AmongtherulestrainedusingT
T
andT ,Simpson-KramerminimizedtheParticipationlossmostefficientlywithT ,
WT T
which is not too surprising as single-winner Simpson-Kramer satisfies participation.
However, the rule loss does not converge to zero at the same rate, even with T . It
WT
issurprisingthatlearningissomuchpoorerforSimpson-KramerwithT thanT .
WT T
TheotherrulesretrainedwithT andT struggledtolearntosatisfyParticipation
T WT
14without increasing rule loss within 200 epochs. This may be because appearances of
the No Show Paradox are quite rare, occurring in about 4% of profiles Brandt et al.
[2019].
Rule Embedding ParticipationLoss RuleLoss
Plurality T 0.078363 0.054809
RF
Borda T 0.254161 0.029481
RF
Borda T 0.239112 0.035640
WT
Borda T 0.432263 0.061900
T
Copeland T 0.127699 0.039600
T
Schulze T 0.175672 0.089309
WT
Schulze T 0.065567 0.058519
T
Simpson-Kramer T 0.136363 0.105944
WT
Simpson-Kramer T 0.019293 0.062169
T
IRV T 0.165605 0.113929
WT
IRV T 0.229106 0.093015
T
Black’sRule T 0.193693 0.039200
RF
Black’sRule T 0.215214 0.066647
WT
Table5:ParticipationLossandRuleLoss(L1)ofselectedmodelsretrainedonprofiles
ofsize(m=7,n=9),averagedover160testprofiles.
7 Conclusions and Future Work
InthispaperwehaveshownthatnotonlycanweefficientlylearnknownPSCFsfrom
preference data, but also that we can modify these rules in order to improve them in
waysthat,todate,havenotbepossiblethroughtraditionalalgorithmicdesignmethods.
Wehavehighlightedtheimportanceofthechoiceofembeddingontheefficiencyand
qualityofthelearnedrules,findingsomesurprisingresultsincludingthatruleslikeIRV,
Borda, and Black’s Rule, which are not majoritarian rules, can be learned well from
T .Itremainstobeseenwhetherotherembeddingscanbedesigned,ofsizem×m
WT
orsmaller,thatoutperformtheembeddingswetookfromthesocialchoiceliterature.
Different embeddings may be beneficial in particular for rules whose outcomes are
NP-Hardtocomputeorothercommonaxioms.
Acknowledgments
ThisworkwasfundedinpartbyGoodLynxandIBM.Thismaterialisbaseduponwork
supportedbytheNationalScienceFoundationunderGrant#2030859totheComputing
ResearchAssociationfortheCIFellowsProject.BenAbramowitzwassupportedbythe
CIFellowsProjectandGoodLynxInc.NicholasMatteiwassupportedinpartbyNSF
Awards IIS-RI-2339880, IIS-RI-2007955, IIS-III-2107505, and IIS-RI-2134857. The
authorswouldliketothankLiamHealyforearlytinkeringandproductivediscussions
andexplorationsaroundthistopic.
15References
CemAnilandXuchanBao. Learningtoelect. AdvancesinNeuralInformationPro-
cessingSystems,34:8006–8017,2021.
Ben Armstrong and Kate Larson. Machine learning to strengthen democracy. In
NeurIPSJointWorkshoponAIforSocialGood,2019.
Kenneth Joseph Arrow et al. Social Choice and Individual Values, volume 12. Yale
UniversityPress,1963.
HarisAziz,FelixBrandt,andMarkusBrill. Thecomputationalcomplexityofrandom
serialdictatorship. EconomicsLetters,121(3):341–345,2013a.
HarisAziz,SergeGaspers,NicholasMattei,NinaNarodytska,andTobyWalsh. Ties
matter:Complexityofmanipulationwhentie-breakingwitharandomvote. InPro-
ceedingsoftheAAAIConferenceonArtificialIntelligence,pages74–80,2013b.
DuncanBlacketal. Thetheoryofcommitteesandelections. 1958.
FelixBrandt. Rollingthedice:Recentresultsinprobabilisticsocialchoice. Trendsin
computationalsocialchoice,pages3–26,2017.
FelixBrandt,MarkusBrill,andPaulHarrenstein. Extendingtournamentsolutions. In
ProceedingsoftheAAAIConferenceonArtificialIntelligence,volume28,2014.
Felix Brandt, Vincent Conitzer, Ulle Endriss, Je´roˆme Lang, and Ariel D Procaccia.
Handbookofcomputationalsocialchoice. CambridgeUniversityPress,2016.
Felix Brandt, Christian Geist, and Dominik Peters. Optimal bounds for the no-show
paradoxviasatsolving. MathematicalSocialSciences,90:18–27,2017.
FelixBrandt,JohannesHofbauer,andMartinStrobel. Exploringtheno-showparadox
forcondorcetextensionsusingehrharttheoryandcomputersimulations.InProceed-
ings of the 18th International Conference on Autonomous Agents and MultiAgent
Systems,pages520–528,2019.
Da´vidBurka,ClemensPuppe,La´szlo´ Szepesva´ry,andAttilaTasna´di. Voting:Ama-
chinelearningapproach. EuropeanJournalofOperationalResearch,299(3):1003–
1017,2022.
ZheCao,TaoQin,Tie-YanLiu,Ming-FengTsai,andHangLi. Learningtorank:from
pairwise approach to listwise approach. In Proceedings of the 24th international
conferenceonMachinelearning,pages129–136,2007.
Michael J Curry, Uro Lyi, Tom Goldstein, and John P Dickerson. Learning revenue-
maximizingauctionswithdifferentiablematching. InInternationalConferenceon
ArtificialIntelligenceandStatistics,pages6062–6073.PMLR,2022.
Paul Du¨tting, Zhe Feng, Noah Golowich, Harikrishna Narasimhan, David C Parkes,
andSaiSrivatsaRavindranath. Machinelearningforoptimaleconomicdesign. In
TheFutureofEconomicDesign,pages495–515.Springer,2019.
16UlleEndriss. Trendsincomputationalsocialchoice. Lulu.com,2017.
Daniel Firebanks-Quevedo. Machine learning? in my election? it’s more likely than
you think: Voting rules via neural networks. Oberlin College Honors Thesis 688,
2020.
David Gale and Lloyd S Shapley. College admissions and the stability of marriage.
TheAmericanMathematicalMonthly,69(1):9–15,1962.
HannaKujawska,MarijaSlavkovik,andJan-JoachimRu¨ckmann. Predictingthewin-
ners of borda, kemeny and dodgson elections with supervised machine learning.
In Multi-Agent Systems and Agreement Technologies: 17th European Conference,
EUMAS 2020, and 7th International Conference, AT 2020, Thessaloniki, Greece,
September14-15,2020,RevisedSelectedPapers17,pages440–458.Springer,2020.
Alexey Malakhov and Rakesh V Vohra. Optimal auctions for asymmetrically budget
constrainedbidders. ReviewofEconomicDesign,12(4):245–257,2008.
FarhadMohsin,AoLiu,Pin-YuChen,FrancescaRossi,andLirongXia. Learningto
designfairandprivatevotingrules. JournalofArtificialIntelligenceResearch,75:
1139–1176,2022.
Herve´ Moulin. Condorcet’s principle implies the no show paradox. Journal of Eco-
nomicTheory,45(1):53–64,1988.
GregoryPavlov. Optimalmechanismforsellingtwogoods. TheBEJournalofTheo-
reticalEconomics,11(1),2011.
Joaquı´nPe´rez. Thestrongnoshowparadoxesareacommonflawincondorcetvoting
correspondences. SocialChoiceandWelfare,18(3):601–616,2001.
NeeharPeri,MichaelCurry,SamuelDooley,andJohnDickerson. Preferencenet:En-
codinghumanpreferencesinauctiondesignwithdeeplearning. AdvancesinNeural
InformationProcessingSystems,34:17532–17542,2021.
ArielDProcaccia,AvivZohar,YoniPeleg,andJeffreySRosenschein.Thelearnability
ofvotingrules. ArtificialIntelligence,173(12-13):1133–1149,2009.
Sai Srivatsa Ravindranath, Zhe Feng, Shira Li, Jonathan Ma, Scott D Kominers,
and David C Parkes. Deep learning for two-sided matching. arXiv preprint
arXiv:2107.03427,2021.
TuomasSandholm. Automatedmechanismdesign:Anewapplicationareaforsearch
algorithms. In International Conference on Principles and Practice of Constraint
Programming,pages19–36.Springer,2003.
Marie Christin Schmidtlein. Voting by axioms. Master’s thesis. ILLC, University of
Amsterdam,2022.
17Marie Christin Schmidtlein and Ulle Endriss. Voting by axioms. In Proceedings of
the2023InternationalConferenceonAutonomousAgentsandMultiagentSystems,
pages2067–2075,2023.
AmartyaSen. CollectiveChoiceandSocialWelfare. HarvardUniversityPress,2018.
Y.ShohamandK.Leyton-Brown. MultiagentSystems:Algorithmic,Game-theoretic,
andLogicalFoundations. CambridgeUniversityPress,2008.
AlanDTaylor. SocialChoiceandtheMathematicsofManipulation. CambridgeUni-
versityPress,2005.
NicWilson.Generatingvotingrulesfromrandomrelations.InProceedingsofthe18th
International Conference on Autonomous Agents and MultiAgent Systems, pages
2267–2269,2019.
LirongXia. Designingsocialchoicemechanismsusingmachinelearning. InProceed-
ings of the 2013 international conference on Autonomous agents and multi-agent
systems,pages471–474,2013.
WilliamS.Zwicker. Introductiontothetheoryofvoting. InHandbookofComputa-
tionalSocialChoice,pages23–56.CambridgeUniversityPress,2016.doi:10.1017/
CBO9781107446984.003. URLhttps://doi.org/10.1017/CBO9781107446984.003.
18A Additional Voting Rules
Inthissectionwegivefulldefinitionsofothervotingruleswestudy.
InstantRunoffVotingisnotascoringrule,butisdefinedbyiterativelyusingplu-
ralityscores.
Definition 14 (Instant Runoff Voting (IRV)). IRV is a deterministic, iterative voting
rulethat,ineachofm−1rounds,eliminatesthecandidatewiththelowestplurality
scoreandremovesthemfromthepreferenceordersofallvotersbeforethenextround.
Whencandidatesaretiedforlowestpluralityscorewebreaktiesinlexicographically.
Therulereturnsthelotterythatassignsallprobabilitytothesinglecandidatethatwas
nevereliminated;U(W(X))where|W(X)|=1.
Black’sruleisanexampleofarulethatisnotascoringrule,tournamentrule,or
weighted-tournamentrule,butisstillCondorcet-consistent.
Definition 15 (Black’s Rule). If the profile X admits a Condorcet winner c, then let
W(X) = c. Otherwise, if there is no Condorcet winner, let W(X) be the subset of
candidateswithmaximumBordascoreB(c).TheprobabilisticBlack’srulereturnsthe
lotteryU(W(X)).
B Rule Preservation
Plurality and Borda are scoring rules, which are necessarily computable from a rank
frequency embedding. However neither rule is preserved by the tournament embed-
ding.Pluralityisknownnottobepreservedbytheweightedtournamenteither,butfor
Bordathisremainsanopenquestion.
Plurality
Pluralityisascoringrule,andthereforenecessarilycomputablefromarankfrequency
embedding.Itrequiresonlyonecolumnofinformationfromtherankfrequencymatrix,
representing how often each candidate is ranked first by a voter. By contrast, Plural-
ity is not preserved by the weighted tournament embedding, and therefore not by the
tournamentembeddingeither.
Theorem1. TheweightedtournamentembeddingdoesnotpreservePlurality.
Proof. X = (a ≻ b ≻ c),(b ≻ a ≻ c),(c ≻ a ≻ b),X = (a ≻ b ≻ c),(a ≻ b ≻
1 2
c),(c≻b≻a).
Corollary1. ThetournamentembeddingdoesnotpreservePlurality.
Borda
Theorem2. ThetournamentembeddingdoesnotpreserveBorda.
19Proof. X = (a ≻ b ≻ c),(b ≻ a ≻ c),(b ≻ c ≻ a),X = (a ≻ b ≻ c),(a ≻ b ≻
1 2
c),(a≻b≻c).
Challenge. DoestheweightedtournamentembeddingpreserveBorda?
Copeland
Copelandistheonlyprobabilisticsocialchoicefunctionweconsiderthatispreserved
by the tournament embedding, and hence by the weighted tournament as well. How-
ever,Copelandisnotpreservedbytherankfrequencyembedding.
Theorem3. TherankfrequencyembeddingdoesnotpreserveCopeland.
Proof. X = (a ≻ b ≻ c ≻ d),(b ≻ c ≻ d ≻ a),(d ≻ a ≻ b ≻ c),X = (a ≻ b ≻
1 2
c≻d),(b≻a≻d≻c),(d≻c≻b≻a).
SchulzeandSimpson-Kramerareweighted-tournamentrulesthatarenotpreserved
bythetournamentorrankfrequencyembedding.
Schulze
Theorem4. TherankfrequencyembeddingdoesnotpreserveSchulze.
Proof. X = (a ≻ b ≻ c ≻ d),(b ≻ c ≻ d ≻ a),(d ≻ a ≻ b ≻ c),X = (a ≻ b ≻
1 2
c≻d),(b≻a≻d≻c),(d≻c≻b≻a).
Theorem5. ThetournamentembeddingdoesnotpreserveSchulze.
Proof. X = (a ≻ b ≻ c ≻ d),(b ≻ c ≻ d ≻ a),(d ≻ a ≻ b ≻ c),X = (a ≻ b ≻
1 2
c≻d),(b≻c≻d≻a),(d≻a≻b≻c).
Simpson-Kramer(Maximin)
Theorem6. TherankfrequencyembeddingdoesnotpreserveSimpson-Kramer.
Proof. X = (a ≻ b ≻ c ≻ d),(b ≻ c ≻ d ≻ a),(d ≻ a ≻ b ≻ c),X = (a ≻ b ≻
1 2
c≻d),(b≻a≻d≻c),(d≻c≻b≻a).
Theorem7. ThetournamentembeddingdoesnotpreserveSimpson-Kramer.
Proof. X = (a ≻ b ≻ c ≻ d),(b ≻ c ≻ a ≻ d),(d ≻ c ≻ a ≻ b),X = (a ≻ b ≻
1 2
c≻d),(b≻c≻a≻d),(c≻a≻b≻d).
20IRV
Theorem8. TherankfrequencyembeddingdoesnotpreserveIRV.
Proof. X = (a ≻ b ≻ c ≻ d),(b ≻ c ≻ d ≻ a),(d ≻ a ≻ b ≻ c),X = (a ≻ b ≻
1 2
c≻d),(b≻a≻d≻c),(d≻c≻b≻a).
Theorem9. ThetournamentembeddingdoesnotpreserveIRV.
Proof. X = (a ≻ b ≻ c ≻ d),(b ≻ c ≻ d ≻ a),(d ≻ a ≻ c ≻ b),X = (a ≻ b ≻
1 2
c≻d),(b≻c≻d≻a),(d≻a≻b≻c).
Challenge. DoestheweightedtournamentembeddingpreserveIRV?
Black’sRule
Theorem10. TherankfrequencyembeddingdoesnotpreserveBlack’sRule.
Proof. X = (a ≻ b ≻ c ≻ d),(b ≻ c ≻ d ≻ a),(d ≻ a ≻ b ≻ c),X = (a ≻ b ≻
1 2
c≻d),(b≻a≻d≻c),(d≻c≻b≻a).
Theorem11. ThetournamentembeddingdoesnotpreserveBlack’sRule.
Proof. X = (a ≻ b ≻ c ≻ d),(b ≻ c ≻ a ≻ d),(d ≻ c ≻ a ≻ b),X = (a ≻ b ≻
1 2
c≻d),(b≻c≻a≻d),(c≻a≻b≻d).
Challenge. DoestheweightedtournamentembeddingpreserveBlack’sRule?
21C Training Loss for PSCFs
InthisAppendixwegivethegraphsofvalidationlossfortheotherrulesstudiedinthis
paper.
2223D Scaling to Fewer Voters
Thistablegivestheresultsofourscalingexperimentstoasmallernumberofvoters.
TRF TWT TT
Plurality 0.004252 0.148373 0.146005
Borda 0.004678 0.004018 0.075410
Copeland 0.070351 0.051713 0.000698
Schulze 0.080797 0.066160 0.045688
Simpson-Kramer 0.081472 0.061241 0.046492
IRV 0.095856 0.114207 0.088140
Black’sRule 0.033607 0.033087 0.044673
Table 6: Testing generalization of our models trained to learn PSCFs on uniformly
randomprofilesof7candidatesand29votersonrandomprofileswithn = 9voters.
AverageL1lossesover1,000randomprofiles.
24E Participation-Adjustment
Inthissectionwegivethevalidationlossesforlearningparticipationbyretrainingour
modelsforagivenvotingrule.
25262728