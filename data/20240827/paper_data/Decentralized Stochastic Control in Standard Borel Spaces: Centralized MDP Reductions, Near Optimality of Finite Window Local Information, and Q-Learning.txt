Decentralized Stochastic Control in Standard Borel
Spaces: Centralized MDP Reductions, Near Optimality
of Finite Window Local Information, and Q-Learning
Omar Mrani-Zentar1, and Serdar Yüksel1∗
August 27, 2024
Abstract
Decentralized stochasticcontrolproblemsareintrinsically difficulttostudybecauseoftheinapplica-
bility of standard tools from centralized control such as dynamicprogramming and their computational
complexity. The aim of this paper is to develop tools that can mollify some of these challenges. We
consider decentralized problems with Borel spaces under three different but tightly related information
structuresunderaunifiedtheme: theone-stepdelayed information sharing pattern,theK-stepperiodic
information sharing pattern, and the completely decentralized information structure where no sharing
of information occurs. We will show that the one-step delayed and K-step periodic problems can be
reducedtoacentralizedMDP,generalizingpriorresultswhichconsideredfinite,linear,orstaticmodels,
by addressing several measurability questions. The separated nature of policies underboth information
structures,evenwhenallspacesarestandardBorel,isthenestablished. Wethenprovidesufficientcondi-
tionsforthetransitionkernelsofbothcentralizedreductionstobeweak-Feller,whichfacilitatesrigorous
approximation and learning theoretic results. We will then show that for the completely decentralized
controlproblemfinitememorylocalpoliciesarenearoptimalunderajointconditionalmixingcondition.
This is achieved by obtaining a bound for finite memory policies which goes to zero as memory size
increases. We will also providea performance bound associated with a limitation of the action space of
the centralized reduction of the K-periodic problem. We will also provide a performance bound for the
K-periodicproblem,whichresultsfromreplacingthefullcommoninformationbyafiniteslidingwindow
ofinformation. Thelatterwilldependontheconditionofpredictorstabilityinexpectedtotalvariation,
which we will establish as well, and goes to zero as the window size increases. We then establish that
under the periodic information sharing pattern, a quantized Q-learning algorithm converges asymptoti-
callytowardsanearoptimalsolution. Eachoftheabove,toourknowledge,isanewcontributiontothe
literature.
1 Problem Description
Suppose there are N agents in a decentralized stochastic control model. Let X;U1,··· ,UN;Y1,··· ,YN
be locally compact subsets of standardBorel spaces. Here X denotes the state space. The action spaces for
agents 1,...,N are U1,...,UN and their measurement spaces are given by Y1,...,YN. At every time t the
state dynamics evolve as follows:
x = T(x ,u1,...,uN,v ) (1)
t+1 t t t t
∀i∈{1,..,N}: yi = Si(x ,wi) (2)
t t t
where {v } and {wi} are i.i.d noise processes for all i ∈ {1,..,N}. Additionally, T and Si are Borel
t t t t
measurable functions. At every time t, each Agent i has access to their local information
Ii =(yi ,ui ) (3)
t [0,t] [0,t−1]
as well as some common information IC. The agent applies a policy γi ={γi}∞ , such that γi is B(IC,Ii)
t t=0 t t t
measurable, with the objective of minimizing
∞
J(γ)= βtEγ[c(x ,u )] (4)
t t
t=0
X
∗1Are with the Department of Mathematics and Statistics at Queen’s University, Kingston ON, Canada.
o.mranizentar@queensu.ca corresp. yuksel@queensu.ca
1
4202
guA
52
]CO.htam[
1v82831.8042:viXrawhere β ∈(0,1) is the discount factor, γ =(γ1,...,γN) is the team policy, and c:X×U→[0,∞) is a cost
functionalwhichisassumedtobecontinuousandbounded. Werefertothesetofalladmissibleteampolicies
as Γ. We also assume that x ∼ µ and that the initial distribution µ is known to all Agents at time t = 0.
0
Next, we will describe the information structures that will be considered in this paper. In particular, under
all information structures considered the local information will remain the same as given in (3). However,
the common information will vary. Before we proceed, we will introduce some notation that will be used
throughout this paper.
1.1 Information structures
We define the variousinformationstructuresthat we will considerin this paper. In allcases,eachagenthas
accessto their ownmeasurementsandpreviousactions (3). However,the informationsharedamong agents,
i.e., the common information will vary.
I Completely decentralized information pattern: IC ={∅}
t
II One-step delayed sharing pattern:
IC ={y[1,N] ,u[1,N] }.
t [0,t−1] [0,t−1]
III K-step periodic information sharing pattern: Let t = qK +r where q and r are non-negative integers
suchthatr ≤K−1andK ∈N representsthe periodbetweensuccessiveinformationsharingbetween
the agents. Here the common information at time t is given by
IC = {y[1,N] ,u[1,N] }
t [0,qK−1] [0,qK−1]
Remark 1.1 Note that when K = 1, the K-step periodic problem simply reduces to the one step delayed
sharing problem.
2 Literature Review and Contributions
The inapplicability of tools from centralized control and the computational complexity of decentralized
stochastic control [1–5] makes arriving at numerical solutions untenable even when the dynamics of the
problem are relatively simple.
An approach for dealing with such problems is allowing for some sharing of information between the
agents ( [6], [7], [8], [9], [10]); see [11] for a systematic generalization and [12] and [4, Section 5.2] for
reviews. The benefit of this approach is that under an appropriate choice of the information structure
the problem can be reduced to a centralized MDP where the agent is a virtual coordinator that uses the
common information to design maps from the agents’ private information to their respective action spaces.
Two important special cases are the N-step delayed information sharing pattern and the K-step periodic
information sharing pattern. Under finite model or linear model assumptions, for the one-step delayed
information sharing pattern, optimality of separated policies has been shown in [6] and [7]. In [8] and [9]
optimalityofseparateddesignhasbeenshownfortheK-stepperiodicinformationsharingpatternunderthe
sameassumption. Recently[13]studiedthestandardBorelsetupforthecaseofstaticteamproblems. Inthis
paper we consider the decentralized problem in standard Borel spaces under severalinformation structures.
The studies of learning for decentralized stochastic control problems with limited or no information
sharing have focused on the development of algorithms that converge but with no performance guarantees
(see [14] for example) in part because the theoretic results on structural and rigorous approximations have
not been available. We aim to address this in our paper. By developing structural and regularityresults for
decentralizedcontrolproblems, we are able to provideconditions under whichstandardtools for centralized
control such as the DCOE (Discounted cost optimality equation) and dynamic programming can be used
to arrive at solutions analytically. Moreover, We provide approximation schemes that mitigate the compu-
tational challenges which are inherent to decentralized control problems. To arrive at our results, we show
that both the one step-delayed and K-periodic problems can be reduced to a centralized problem. For the
K-periodic problem with finite spaces centralized reduction has been established in [9]. In this paper, we
first show that a similar result holds for one-step delayed problems with standard Borel spaces. Then, we
generalize the result of [9] for the case where the spaces are standard Borel. As a result of this centralized
reduction we are able to show that optimal policies are seperable under both aformentioned information
2structures. A similar result for the case of finite spaces has been shown for the one-step delayed problem
in [6] and [7] and for the K-periodic problem it was shown in [8] and [9]. We, then, use our results to find
conditions under which the centralized reduction of the one-step delayed problem and K-periodic problem
is weak-Feller. In [15] it was shown that the fully observed reduction of centralized POMDPs (partially
observedMarkovdecision processes)is weak-Feller. The weak-Fellerproperty is important as it enables one
to establishexistence ofoptimalsolutionsanduseapproximations[16,17]aswellasQ-learningto findthose
solutions [18,19].
By first approximating the decentralized stochastic control problem using the K-periodic problem and
getting a performance bound on finite memory local policies for the latter, we are able get a performance
bound on finite memory approximations for the completely decentralized stochastic control problem. The
performance bound we obtain can be made arbitrarily small by increasing the memory size. This addresses
anopenproblemintheliteratureontheperformanceofcompletelydecentralizedlocalinformationandtheir
systematic and rigorous approximation.
To dealwith the largeamountofcommoninformationthathas to be retainedunder the K-stepperiodic
information sharing pattern, we provide a performance bound for the case where finite sliding window of
information is used instead of the full information. This bound relies on a predictor stability condition and
goes to zeroas the lengthofthe window increases. Arelatedresulthas been establishedfor POMDPs using
filterstabilityin[19]. WewillprovidesufficientconditionsforthepredictorstabilitytoholdusingDobrushin
coefficients, parallel to those reported in [20]. Finally, applying the results of [18] for Q-learning in general
Borel spaces, we will show that a Quantized Q-learning algorithm converges to a near optimal solution of
the K-step periodic information sharing problem.
2.1 Main contributions.
2.1.1 Contributions to the one-step delayed information sharing pattern
(i) Extending existing results on finite space models to standard Borel spaces, we show that, under the
one-step delayed (see Theorem 3.1 and 3.2) policies are of separated form and the problem reduces to an
equivalent centralized MDP; this generalizes the prior results which considered finite models as well as a
recent result by Saldi [13] which considers static Borel models.(ii) We, then, use this result to show that
under, some mild on the originalkerneland measurementchannels, the new centralizedMDP is weak-Feller
(Theorem 4.1). (iii) Finally, using our weak-Feller result, we will establish the almost sure convergence of
QuantizedQ-learningtonearoptimalsolutionsasthesizeofthequantizationbecomessufficientlylarge(see
Theorem 7.1).
2.1.2 Contributions to the K-step periodic information sharing pattern
(i) By using the results for the one-step delayed sharing pattern, we show that under the K-step periodic
information sharingpattern with standardBorelspaces (see Theorem 3.3 and 3.4), policies are of separated
form and the problem reduces to an equivalent centralized MDP.(ii) We, then, use this result to show that
undersomeconditionsontheoriginalkernelandtheobservationchannelsthecentralizedMDPisweak-Feller
(Theorem4.2). (iii)Underajointconditionalmixingcondition,weprovideaperformanceboundthatapplies
when the action space of the centralized MDP is reduced (see Theorem 5.1 and Corollary5.1). (iv) We will
providea finite memoryapproximationforany generalK-stepperiodic belief sharingpatternusing a sliding
windowofinformation. We,then,establish,boundsforthelossinoptimalityduetosuchapproximationsvia
apredictorstabilitycondition(seeTheorem6.2). (v)WeshowthatundersomeconditionsontheDobrushin
coefficients of the kernel and measurements channels, the predictor is exponentially stable under expected
total variation (see Theorem 6.4).(vi) Finally, we will establish the almost sure convergence of quantized
Q-learning for the K-step periodic information sharing pattern (see Theorem 7.1).
2.1.3 Contributions to the completely decentralized information pattern
Using approximationwiththe K-periodicproblemandthe resultonthe actionspacereductionofthe latter,
we will establish the near optimality of a large class of finite memory policies for the completely decentral-
ized stochastic control problem (Corollary 5.2). As a special case, we obtain the near optimality of finite
lengthslidingwindowpoliciesforsufficientlylargewindowlengths(Theorem5.2). Notethatherethesliding
windowiswithrespecttotheinformationexclusivetoeachagent(privateinformation)andnotthecommon
information.
Finally, We will apply the Q-learning algorithm introduced for the K-periodic problem to a simple ex-
ample for which rigorousconditions for convergence to a near optimal solution apply. Then, we will discuss
3some of the challenges in its implementation when approximationschemes are not used.
2.2 Notation and Preliminaries
2.2.1 Notation
(i) For any set Ω we will use the notation B(Ω) to denote the Borel sigma-algebra on Ω.(ii) For any set
X we denote the set of probabilities on X by P(X).(iii) We will denote a finite sequence {x }t=k, where
t t=l
k,l ∈ Z+ by x or x[l,k].(iv) Similarly, for a double-indexed sequence {xi} we will
[l,k] t {t∈{l,...,k},i∈{l′,...,k′}}
use the notation
x[l′,k′].(v)
Whenever the superscript of a double-indexed sequence ranges over all agents
[l,k]
(i∈{1,...,N})andwhenthere is no ambiguity,we willuse the notationx to referto the double-indexed
[l,k]
sequence {xi} . (vi) We will use C (X) to denote the set of continuous and bounded
t {t∈{l,...,k},i∈{1,...,N}} b
functions on the set X.
2.2.2 Convergence of probability measures
In this section, we will introduce three notions of convergence for sequences of probability measures that
will be useful later on: weak convergence, convergence under total variation, and convergence under the
Wasserstein metric of order one. For a complete, separable and metric space X, a sequence {µ ,n∈N}
n
∈ P(X) is said to converge to µ ∈ P(X) weakly if and only if f(x)µ (dx) → f(x)µ(dx) for every
X n X
continuous and bounded f : X → R. One important property of weak convergence is that the space of
R R
probability measures on a complete, separable, metric (Polish) space endowed with the topology of weak
convergenceis itself complete, separable,and metric. An example of such a metric is the bounded Lipschitz
metric, which is defined for µ,ν ∈P(X) as
ρ (µ,ν):= sup fdµ− fdν
BL
|fkBL≤1(cid:12)Z Z (cid:12)
(cid:12) (cid:12)
where (cid:12) (cid:12)
(cid:12) (cid:12)
|f(x)−f(y)|
kfk :=kfk +sup
BL ∞
d(x,y)
x6=y
and kfk =sup |f(x)|. An equivalent metric is given by the following
∞ z∈X
∞
ρ(µ,ν)= 2−(m+1)| g dµ− g dν|
m m
m=0 Z Z
X
where{g }issomesequenceofcontinuousandboundedfunctions thatcharacterizethe weaktopologywith
m
kg k ≤1 for all m. For probability measures µ,ν ∈P(X), the total variation metric is given by
m ∞
kµ−νk = 2 sup |µ(B)−ν(B)|
TV
B∈B(X)
= sup f(x)µ(dx)− f(x)ν(dx) ,
f:kfk∞≤1(cid:12)Z Z (cid:12)
(cid:12) (cid:12)
where the supremum is taken over all measurab(cid:12) (cid:12)le real functions f such that(cid:12) (cid:12)kfk
∞
= sup|f(x)| ≤ 1. A
x∈X
sequence µ is said to converge in total variation to µ ∈ P(X) if kµ −µk → 0. The Wasserstein order
n n TV
one metric for measures with bounded support is given by
W (µ,ν)= sup | fdµ− fdν |
1
kfkLip≤1 Z Z
|f(x)−f(y)|
Where kfk :=sup .
Lip
d(x,y)
x6=y
3 Equivalent Formulations: Centralized MDP Reductions
3.1 One-Step Delayed Sharing Pattern
In the one-step delayed sharing pattern, we have that
IC =y[1,N] ,u[1,N] .
t [0,t−1] [0,t−1]
4It was shownin [6] and[7] that optimalpolicies for the one step-delayedinformationsharing pattern, under
finite horizoncostcriteria,areseparableinthe casewhere the measurementspaces,actionspaces,andstate
spaces are all finite. In both [6] and [7], separability of policies was shown via dynamic programming. This
approach requires a continuity, and in this case a weak-Feller continuity, assumption in order for measur-
able selection to be applicable-thus allowing for the use of dynamic programming [21, Chapter 3]. This
assumption always holds in the case of finite state and action space. In this section, we will generalize the
seperability by presenting an approachthat is suitable for problems with standardBorel spaces and infinite
horizon discounted cost criteria. First, we will show that the one-step delayed problem admits a centralized
MDP reduction where the one-step predictor acts as the state. Before we proceed, we introduce a topology
on maps from private information to actions (Young topology).
Young topology on Maps as Actions. Here, we will introduce Young topology on control policies (see,
e.g. [22,23]). Suppose there exists a reference measure ψ and a measurable function hi : X×Yi → [0,∞)
such that the measurement channel, of each individual agent i, Qi satisfies:
Qi(dyi|x )= ψ(dyi)hi(x ,yi) (5)
t t t t t
Z
Forthe sakeofreadability,throughoutthe restofthe paper,wewillassumethathi ≡h foralli∈{1,...,N}
wherehisameasurablefunctionsuchthath:X×Yi →R. Alltheproofsforthemoregeneralcaseproceed
in the same manner as the ones included in this paper.
Definition 3.1 f → f under the Young topology if and only if for all i ∈ {1,...,N} and for all g ∈
n,t t
C (Yi,Ui) : g(yi,ui)ψ(dyi)fi (dui|yi)→ g(yi,ui)ψ(dyi)fi(dui|yi).
b n,t t
This topologyRleads to a convex and compaRct formulation. In particular, consider the set of probability
measures on Yi×Ui with fixed marginal ψ:
Ri = P ∈P(Yi×Ui)|P(B)= f(dui|yi)ψ(dyi), B ∈B(Yi×Ui)
ZB
(cid:8) (cid:9)
Then,everydeterministicmapfi :Yi 7→UicanbeidentifiedasanelementofthesetofextremepointsofRi:
Θi = P ∈P(Yi×Ui)|P(B)= χ ψ(dyi), g :Yi →Ui B ∈B(Yi×Ui)
{gi(yi)∈dui}
ZB
(cid:8) (cid:9)
Thus, Θi inherits the Borel measurability and topological properties of the Borel measurable set Ri [22].
Theorem 3.1 The problem (1),(2),(4) is equivalent to one where the team policy at time t is given by
(γ˜1,...,γ˜N) such that for all i, γ˜i : IC 7→fi is B(IC)-measurable and fi : yi →ui is B(Yi)-measurable and
t t t t t t t t t
represents the action of agent i at time t. Here, by equivalent, we mean that inf J(γ) = inf J(γ˜) where Γ
γ∈Γ γ˜∈Γ˜
is the space of all team policies such that at time t agent i applies a policy γi : IC ×Ii → Ui and Γ˜ is the
t t t
space of all policies of the form γ˜ as defined above.
Proof. Let {(γ1,...,γN)}∞ be a team policy as defined in Section 1. Then,
t t t=0
∞ ∞
βtE c(x ,u ) = βtE E[c(x ,u )|IC]
t t t t t
t=0 t=0
X (cid:2) (cid:3) X (cid:2) (cid:3)
∞ N
= βtE P(dx |IC)( Qi(dyi|x ))c(x ,γ1(IC,y1),...,γN(IC,yN))
t t t t t t t t t t t
t=0 Z i=1
X (cid:2) Y (cid:3)
∞ N
= βtE P(dx |IC)( Qi(dyi|x ))c(x ,γ˜1(IC)(y1),...,γ˜N(IC)(yN))
t t t t t t t t t t t
t=0 Z i=1
X (cid:2) Y (cid:3)
Next, to complete the proof, we will show that for any policy γi : IC ×Yi → Ui there exists a policy
t t
γ˜i :IC →Θi suchthatIC 7→f ∈Θi andleadstothesamecost. Conversely,foreverypolicyγ˜i thereexistsa
t t t t
policy γi thatachievesthe samecost. To dothis, itis sufficienttocheckthatthe induced strategic measures
t
(that is, probability measures on the sequence spaces of actions and measurements) are equivalent almost
surely: Pγ ti (dui t,dyi,dI tC)=Pγ˜ ti (dui t,dyi,dI tC)a.s. Toprovethis,itissufficienttocheckthatforacountable
5family of measure-determiningcontinuousandboundedfunctions g ∈C (Ui×Yi×IC)[24,Theorem3.4.5]
b t
the following holds
g(ui,yi,IC)Pγ ti (dui,dyi,dIC)= g(ui,yi,IC)Pγ˜ ti (dui,dyi,dIC) (6)
t t t t t t t t t t
Z Z
Furthermore,byStone-WeierstrassTheorem[25]itissufficienttocheckthatequation(6)holdsforfunctions
of the form g(ui,yi,IC) = H(ui,yi)G(IC) where H and G are both continuous and bounded functions.
t t t t t t
Thus, we get
H(ui,yi)G(IC)Pγ ti (dui,dyi,dIC) = H(ui,yi)G(IC)γi(dui |yi,IC)P(dyi,dIC)
t t t t t t t t t t t t t t
Z Z
Note that whenever γi is a kernel, it can be realized [26] as γi(A | dyi,dIC)= ∆(yi,IC,w¯)P(dw¯) where
t t t A t
∆ is measurable and w¯ is some random variable which is independent of yi and IC. Let γ˜i be a conditional
R t t
probability that is realized by the function ∆(.,IC,w¯). Now, by Theorem 8.5 in [27] ∆(.,IC,w¯) is measur-
t t
able. Hence, γ˜i isamapfromIC to P(Yi×Ui)whichis realizedbyameasurablefunction. Thus,itfollows
t t
that for every A ∈ B(Yi×Ui) the function γ˜i(IC)(A) is B(IC)/B(R) measurable. Hence, by Theorem 2.1
t t t
in [28] γ˜i is measurable. It then follows that inf J(γ)≥ inf J(γ˜)
t
γ∈Γ γ˜∈Γ˜
For the reverse direction, suppose that γ˜i is a transition kernel which is realized by some function
t
D(IC,w¯). Now, we will present two different argument each of which can be used to complete the proof.
t
Firstly, note that because γ˜i ∈ Ri one can write the measure induced by γ˜i on the measurement and
t t
action of agent i as
Pγ˜ ti ((ui,yi)∈.|IC) = Pγ˜ ti (dui|yi,IC)P(dyi|IC)
t t t
Z
= Pγ˜ ti (dui|yi,I tC)Q(dy ti|x t)P(dx t|I tC)
Z
Then, by letting γ ti(dui|yi,I tC) = Pγ˜ ti (dui|yi,I tC), we can see that both γ˜ ti and γ ti induce the same measure
on ui and hence inf J(γ)≤ inf J(γ˜).
t
γ∈Γ γ˜∈Γ˜
We can also present a different argument which holds given that the cost function c is bounded. Let γi
t
be aconditionalprobabilitymeasurewhichis realizedbythe function ∆(yi,IC,w¯)=D(IC,w¯)(yi). Because
t t t
the imageofD consistsentirelyofmeasurablef ∈Θi,itfollowsthat∆is measurableinits firstcomponent.
By Lusin’s theorem, for any arbitrary ǫ > 0 there exists a set K ∈ B(IC,w¯) such that the restriction of
t
D to K is continuous. Hence, we have that the restriction of ∆ to the set K ×Yi is continuous in IC,w¯
t
and measurable in its first component, it then follows by Theorem 2 in [29] or Lemma 9.2 in [30] that this
restriction is measurable. By defining ∆ to be any arbitrary value in Ui outside of K ×Yi we get that
∆ is measurable. Hence, because H and G are bounded, we have shown that for every policy γ˜ one can
construct a policy γ that achieves an arbitrarilyclose cost at time t to one incurredif the policy γ˜ was used
instead. Because c is bounded, it is easy to see that for any finite horizon cost criteria and for any policy of
the form γ˜ there a policy of the form γ that achievesan arbitrarilyclose cost. Again, because c is bounded,
one can approximate, uniformly over all policies, the infinite cost criteria using finite cost criteria. Thus, it
follows that inf J(γ) ≤ inf J(γ˜) which completes the proof. As noted in [29] continuity is crucial in order
γ∈Γ γ˜∈Γ˜
for measurability to hold. See [31] for counterexamples that hold under the continuum hypothesis. ⋄
As noted earlier, for the case of static teams, a related equivalence has been established in [13].
Theorem 3.2 Suppose the cost function c is bounded. Let Z (·)=P(x
∈·|y[1,N] ,u[1,N]
). Then (Z ,f ),
t t [0,t−1] [0,t−1] t t
where f = (f1,...,fN), forms a fully observed MDP and is equivalent to the problem given by (1, 2 4)
t t t
under an appropriate choice of the cost criteria. Note that, here, the team policy at time t consists of
γ ∈{(γ1,...γN)|∀i∈1,...,N :γi :Z 7→{fi} and γi is B(Z )-measurable}.
t t t t t t
Remark 3.1 Whilethistheoremholdsfordeterministicfunctions(f1,...,fN)weallowforrandomizedmaps
t t
(f1,...,fN). This is because our analysis later on will require that the action space be compact and hence
t t
closed. The lattercan not beguaranteedif we considerdeterministic functions. Additionally, weendow those
maps with the Young topology given by Definition 3.1.
Proof of Theorem 3.2 To prove the theorem, we first find an update equation for the belief Z =
t
P(dx |IC) then we use that to find the stochastic transition kernel for Z . Subsequently, we establish that
t t t
6(Z ,f1,...,fN) is a controlled Markov Chain. We then rewrite the cost in (4) in the terms of Z . We, then,
t t t t
conclude that the resulting problem with Z as the state is equivalent to problem (1, 2, 4). In what follows
t
we use the notation: τ(x ∈A|x ,u )=P(x ∈A|x ,u ).
t+1 t [0,t] t+1 t [0,t]
Step 1: Update equation for Z .
t
Similar to the update equation in [32], two separate cases need to be considered.
Suppose N h(x ,yi)Z (dx )6=0, then
X i=1 t t t t
R Q
Z (·) = P(x
∈·|y[1,N],u[1,N])
t+1 t+1 [0,t] [0,t]
= P(dx |x
,y[1,N],u[1,N])P(dx |y[1,N],u[1,N])
t+1 t [0,t] [0,t] t [0,t] [0,t]
Z·
= τ(dx |x
,u[1,N])P(dx |y[1,N],u[1,N]
)
t+1 t t t [0,t] [0,t−1]
Z·
τ(dx |x ,u[1,N])Z (dx ) N h(x ,yi)
= t+1 t t t t i=1 t t
Z· X N i=1h(x t,y ti)Z Qt(dx t)
=: F(Z t,u t,yR t[1,N Q])(·), (7)
where τ is the transition kernel of the system (1).
If, N h(x ,yi)Z (dx )=0, then we define Z (.)≡0
X i=1 t t t t t+1
R Q
Step 2: Stochastic Kernel. Given the update equation above, it follows that the stochastic kernel for Z
t
is given by:
P(Z ∈·|Z ,f ) = P(Z ∈·|y[1,N],Z ,f )P(dy[1,N]|Z ,f )
t+1 [0,t] [0,t] t+1 t [0,t] [0,t] t [0,t] [0,t]
Z
N
= fi(dui|yi)P(Z ∈·|y[1,N],Z ,u[1,N])P(dy[1,N]|Z )
t t t t+1 t t t t [0,t]
Z i=1
Y
N
= χ Z (dx ) Qi(dyi|x )fi(dui|yi)
{F(Zt,ut,y t[1,N])∈·} t t t t t t t
Z i=1
Y
=: η(Z ∈·|Z
,f[1,N])
t+1 t t
Step 3: Cost-equivalence
Since B(Z )⊆B(IC), one can extend the set admissible policies so that γi : Z ×IC →fi and is B(Z ,IC)
t t t t t t t t
measurable. Consider the following:
∞ ∞
βtEγ[c(x ,u )] = βtE[E[c(x ,u )|Z ,IC]]
t t t t t t
t=0 t=0
X X
∞ N
= βtE[ Z (dx ) fi(dui|yi)c(x ,u1,...,uN)]
t t t t t t t
t=0 Z i=1
X Y
∞
= βtE[c˜(Z ,f1,...,fN)]
t t t
t=0
X
where
N
c˜(Z ,f1,...,fN)= Z (dx ) fi(dui|yi)Qi(dyi|x )c(x ,u1,...,uN). (8)
t t t t t t t t t t t t
Z i=1
Y
Note that because c is bounded, it follows by Theorem D.2.1 in [33] that c˜ is measurable with respect to
Z and f1,...,fN. Because (Z ,f ) is a MDP, the desired result then follows from [34, Theorem 2] which
t t t t t
can be used to show that when the policy maps the state (a Polish space) and another Polish space onto
an action space, which is also Polish, one can construct a Borel measurable policy which only relies on the
state without any loss of optimality. Hence, it is sufficient to consider policies such that γi :Z →fi and is
t t t
B(Z ) measurable. ⋄
t
7Remark 3.2 (Belief vs. Predictor) While it is standard in the centralized setting, to express POMDPs
in termsof anMDPwiththebelief process as thestate[35,36], suchaformulation can notbeusedidentically
in this setting. This is because from the coordinator’s perspective only the common information (one-step
delayedmeasurementsandactions)isavailable. Thiswillalsohaveimplications fortheWeak-Fellerproperty.
Remark 3.3 (n-step delayed sharing pattern with n≥2) Witsenhausen [2] conjectured that policies
should be separable for the n-step delayed information sharing pattern regardless of n. [7] showed this to be
incorrect by presenting a counterexample that shows that when the information structureis two-step delayed,
policies do not exhibit a separation property. For further separation results see ( [11], [10]). In [11], a
more general setup is considered, and it is shown that optimal policies may depend only on the belief in the
state as well as the measurements of all agents and their private information conditioned on the common
information. In [10] a related separation result is given for the two-step delayed information sharing pattern.
3.2 K-step periodic information sharing pattern
It was shown in [8] (see also [9]) that optimal policies for the K-step periodic information sharing pattern,
under finite horizon cost criteria, are of separated form in the case where the measurement spaces, action
spaces, and state spaces are all finite. Similar to the argument used in [6] and [7], the authors of [8] use
dynamicprogrammingtoshowseperabilityofoptimalpolicieswhichrequiresaweak-Fellerassumption. The
latter is too restrictive for problems with standard Borel spaces. In this section, we will use an approach
similartotheoneweusedfortheone-stepdelayedpatternandtheoneusedin[9]fortheK-periodicproblem
with finite spaces. We will generalize this result to the case where all spaces are standard Borel and for the
infinitehorizondiscountedcostcriteria. Additionally,wewillshowthatthisproblemreducestoacentralized
problem.
For problem (1,2), let t = qK +r where q and r are non-negative integers such that r ≤ K −1 and
K ∈N represent the period between successive information sharing between the agents. Suppose that each
agent i now has access to
Ii = {yi ,ui ,IC} (9)
t [qK,qK+r] [qK,qK+r−1] t
IC = {y[1,N] ,u[1,N] }
t [0,qK−1] [0,qK−1]
IPi = {yi ,ui }
t [qK,qK+r] [qK,qK+r−1]
Remark 3.4 Note that here, in order to reduce notation overload, Ii is defined differently from the one-step
t
delayed case and consists of all the information available to agent i at time t including common information.
Here, each agent i at time t picks a policy γi : Ii 7→ ui such that γi is B(Ii)-measurable. The objective of
t t t t t
the agents is to minimize
∞
J(γ)= βtEγ[c(x ,u )] (10)
t t
t=K
X
In [8,9], it was shown that, when the cost criteria has finite horizon, there is no loss in optimality if the
agents replace their common information
(y[1,N] ,u[1,N]
) with π =Z =P(x
|y[1,N] ,u[1,N]
).
[0,qK−1] [0,qK−1] t qK qK [0,qK−1] [0,qK−1]
In[9],itwasshownthatwhenthestatespace,actionspace,andallobservationspacesarefinite,theproblem
canbe reducedto a Markovdecisionprocesswhere the state is replacedby the belief onthe state, giventhe
common information, at K-time periods. In what follows, we will extend this result to general spaces and
show that for the cost (4) the policies satisfy a separation property. To this end, we present an appropriate
topology on maps from histories to actions.
Topology on the actions for the K-step periodic belief sharing pattern
Assumption 3.1 For all i: Ui is finite.
Remark 3.5 While for the one step delayed case finiteness of the action space was not required, we impose
this assumption for the K-periodic information structure in order to introduce a topology on the map-valued
action spacefor theequivalent formulation that will lead tocompactness of thenewaction space. Inaddition,
this will prove helpful in establishing the weak-Feller property of the new transition kernel later on.
8N
Suppose there exists a reference measure ψ and a measurable function h : X× Yi such that the
i=1
measurement channel, of each individual agent i, Qi satisfies: [
Qi(dyi|x )= ψ(dyi)h(x ,yi) (11)
t t t t t
Z
Definition 3.2 For i∈{1,...,N} we say fi →fi if and only if µ (.)= ψ(dyi)fi (.|yi )→µ(.)=
qK,n qK n qK,n qK
ψ(dyi )fi (.|yi ) weakly.
qK qK qK R
Additionally, for r >0 we say fi →fi if and only if for all u ,...,u :
R qK+r,n qK+r qK qK+r−1
t=qK+r
µ (.)= ψ(dyi)fi (.|yi ,ui )→µ weakly. Where,
n t qK+r,n [qK,qK+r] [qK,qK+r−1]
Z t=qK
Y
µ(.)= t=qK+r ψ(dyi)fi (.|yi ,ui ).
t=qK t qK+r [qK,qK+r] [qK,qK+r−1]
R Q
Theorem 3.3 The process (π ,(a1,...,aN);q ≥ 1) where for each i: ai = (fi ,...,fi ) forms a
q q q q qK (q+1)K−1
controlled Markov decision process. Here, for all i, fi :yi 7→ui and is B(yi )-measurable and for r >0
qK qK t qK
fi :(yi ,ui )7→ui and is B(yi ,ui )-measurable.
qK+r [qK,qK+r] [qK,qK+r−1] t [qK,qK+r] [qK,qK+r−1]
Note: In the remainder of the paper we will also use the notation: a =(a1,...,aN).
q q q
Proof. To prove this theorem we first find an update equation for π then we use that to compute the
q
stochastic kernel and conclude that (π ,(a1,...,aN)) is a controlled MDP. While this theorem holds for
q q q
deterministic functions {f }, in this context, it is also useful to allow for randomized maps {f }.
qK+r qK+r
Step 1: Update equation for π
q
π = Z
q+1 (q+1)K
= F(Z
,u[1,N] ,y[1,N]
)
(q+1)K−1 (q+1)K−1 (q+1)K−1
[1,N] [1,N] [1,N] [1,N]
= F(F(Z ,u ,y ),u ,y )
(q+1)K−2 (q+1)K−2 (q+1)K−2 (q+1)K−1 (q+1)K−1
=: G(π
,u[1,N] ,y[1,N]
)
q [qK,qK+K−1] [qK,qK+K−1]
Step 2: Transition kernel
P(π ∈·|π
,a[1,N])
= P(dπ
∈·|y[1,N]
,π
,a[1,N],u[1,N]
)
q+1 [0,q] [0,q] q+1 [qK,qK+K−1] [0,q] [0,q] [qK,qK+K−1]
Z
[1,N] [1,N] [1,N]
P(dy ,du |π ,a )
[qK,qK+K−1] [qK,qK+K−1] [0,q] [0,q]
= χ
{G(πq,u [[ q1 K,N ,q] K+K−1],y [[ q1 K,N ,q] K+K−1])∈·}
Z
P(dy[1,N] ,du[1,N]
|π
,a[1,N])
[qK,qK+K−1] [qK,qK+K−1] [0,q] [0,q]
=: θ(π ∈·|π
,a[1,N])
q+1 [0,q] [0,q]
Where,
N
P(dy[1,N] ,du[1,N] |π ,a[1,N])= π (dx )( Qi(dyi |x )fi (dui |yi ))
[qK,qK+K−1] [qK,qK+K−1] [0,q] [0,q] q Kq Kq Kq qK qK Kq
Z i=1
Y
N
τ(dx |x ,u[1,N])( Qi(dyi |x )fi (dui |yi ,ui ))
Kq+1 Kq Kq Kq+1 Kq+1 qK+1 qK+1 [Kq,Kq+1] qK
i=1
Y
N
τ(dx |x ,u[1,N] )...τ(dx |x ,u[1,N] )( Qi(dyi |x )
Kq+2 Kq+1 Kq+1 qK+K−1 qK+K−2 qK+K−2 qK+K−1 qK+K−1
i=1
Y
fi (dui |yi ,ui ))
qK+K−1 qK+K−1 [Kq,Kq+K−1] [qK,qK+K−2]
Hence, θ(π ∈.|π
,a[1,N])=θ(π
∈.|π
,a[1,N]).
⋄
q+1 [0,q] [0,q] q+1 q q
9Theorem 3.4 Problem (1),(2),(9),(10) is equivalent to one where the team policy at time q is given by
(γ1,...,γN) such that for all i γi :IC 7→ai =(fi ,...,fi ) and is B(IC)-measurable.
q q q qK q qK (q+1)K−1 t
Proof. Let (γ1,...,γN) be a team policy as defined in section 3. Then,
t t
t=∞ ∞ t=(q+1)K−1
βtE[c(x ,u )]= βtE[E[c(x ,u )|IC]]
t t t t t
t=K q=1 t=qK
X X X
∞ t=(q+1)K−1 N
= βtE[ π (dx )( Qi(dyi |x )γi (dui |IC ,yi ))τ(dx |x ,u )...
q qK qK qK qK qK qK qK qK+1 qK qK
q=1 t=qK Z i=1
X X Y
N
τ(dx |x ,u )( Qi(dyi|x )γi(dui|yi ,ui ,IC))c(x ,u )]
t t−1 t−1 t t−1 t t [qK,qK+r] [qK,qK+r−1] t t t
i=1
Y
∞ t=(q+1)K−1 N
= βqKE[ π (dx ) βt−qK( Qi(dyi |x )γ˜i (IC )(yi ))τ(dx |x ,u )...
q qK qK qK qK qK qK qK+1 qK qK
q=1 Z t=qK i=1
X X Y
N
τ(dx |x ,u )( Qi(dyi|x )γ˜i(IC )(yi ,ui ))c(x ,u )]
t t−1 t−1 t t−1 t qK [qK,qK+r] [qK,qK+r−1] t t
i=1
Y
∞
= (βK)qEγ˜[c˜(π ,a1,...,aN)]
q q q
q=1
X
where,
t=(q+1)K−1 N
c˜(π ,a1,...,aN)= π (dx ) βt−qK( Qi(dyi |x )fi (dui |yi ))τ(dx |x ,u )
q q q q qK qK qK qK qK qK qK+1 qK qK
Z t=q i=1
X Y
N
...τ(dx |x ,u )( Qi(dyi|x )fi(dui|yi ,ui ))c(x ,u )]
t t−1 t−1 t t−1 t t [qK,qK+r] [qK,qK+r−1] t t
i=1
Y
Here, since c is bounded, the measurability of c˜with respect to π and a1,...,aN follows by Theorem D.2.1
q q q
in [33]. Consider the set of probability measures on IPi ×Ui with fixed marginal ψ:
t
Ri = P ∈P(IPi ×Ui)|P(B)= f(dui|IPi )ψ(dIPi ), B ∈B(IPi ×Ui)
t t t t
ZB
(cid:8) (cid:9)
Then,everydeterministicmapfi :IPi 7→UicanbeidentifiedasanelementofthesetofextremepointsofRi:
t
Θi = P ∈P(IPi ×Ui)|P(B)= χ ψ(dIPi ), g :IPi →Ui B ∈B(IPi ×Ui)
t {gi(IPi)∈dui} t t t
ZB t
(cid:8) (cid:9)
Thus, Θi inherits the Borel measurability and topological properties of the Borel measurable set Ri [22].
Next, to complete the proof, we will show that for any policy γi : IC ×IPi → Ui there exists a policy
t t t
γ˜i : IC → Θi such that IC 7→ f ∈ Θi and leads to the same cost. Conversely, for every policy γ˜i there
t t t t
exists a policy γi that achievesthe same cost. To do this, it is sufficient to check that the induced measures
t
are equivalent almost surely: Pγ ti (dui t,dI tPi ,dI tC)=Pγ˜ ti (dui t,dI tPi ,dI tC) a.s. To prove this, it is sufficient to
check that for a countable family of continuous and bounded functions g ∈C (Ui×IPi ×IC) the following
b t t
holds
g(ui,IPi ,IC)Pγ ti (dui,dIPi ,dIC)= g(ui,IPi ,IC)Pγ˜ ti (dui,dIPi ,dIC) (12)
t t t t t t t t t t t t
Z Z
Furthermore, by Stone-Weierstrass theorem it is sufficient to check that equation 12 holds for functions of
the form g(ui,IPi ,IC) = H(ui,IPi )G(IC) where H and G are both continuous and bounded functions.
t t t t t t
Thus, we get
H(ui,IPi )G(IC)Pγ ti (dui,dIPi ,dIC) = H(ui,IPi )G(IC)γi(dui |dIPi ,dIC)P(dIPi ,dIC)
t t t t t t t t t t t t t t t
Z Z
10Here, again, γi is a kernel, thus it can be realized as γi(A | dIPi ,dIC) = ∆(IPi ,IC,w¯)P(dw¯) where ∆
t t t t A t t
is measurable and w¯ is some random variable which is independent of IPi and IC. Let γ˜i be a conditional
t R t t
probability that is realized by the function ∆(.,IC,w¯). By Theorem 8.5 in [27] ∆(.,IC,w¯) is measurable.
t t
Thus, it follows that for every A∈ B(IPi ×Ui) the function γ˜i(IC)(A) is B(IC)/B(R) measurable. Hence,
t t t
by Theorem 2.1 in [28] γ˜i is measurable.
t
For the reverse,we proceed using a similar argumentto the one used for the one-step problem. Suppose
thatγ˜i isatransitionkernelwhichisrealizedby somefunction D(IC,w¯). Firstly,note thatbecauseγ˜i ∈Ri
t t t
one can write the measure induced by γ˜i on (IPi ×Ui as
t t
Pγ˜ ti ((ui,IPi )∈.|IC) = Pγ˜ ti (dui|IPi ,IC)P(dIPi |IC)
t t t
Z
Then, by letting γ ti(dui|yi,I tC)=Pγ˜ ti (dui|IPi ,I tC), we cansee thatboth γ˜ ti and γ ti induce the same measure
on ui and hence inf J(γ)≤ inf J(γ˜).
t
γ∈Γ γ˜∈Γ˜
⋄
Corollary 3.1 The controlled Markov model (π ,(a1,...,aN);q ≥ 1) defines an equivalent problem to the
q q q
problem (1,2, 9, 10) under an appropriate choice of the cost criteria, i.e, a reformulation of the cost given
in 10. Additionally, one can replace the policies {γ˜i} with policies {γi} such that γi : π 7→ ai and γi is
q q q q
B(π )-measurable.
q
Proof. It suffices to consider the following cost:
∞
J = (βK)qEγ˜[c˜(π ,a1,...,aN)] (13)
q q q
q=1
X
Since σ(π ) ⊆ σ(IC ), one can, without loss of optimality, extend the set admissible policies so that
q qK
γi : π ×IC → ai and is σ(π ,IC ) measurable. As earlier, the desired result then follows from Theo-
q q qK q q qK
rem 2 in [34]. ⋄
Remark 3.6 Whiletheone-stepdelayedpatternisaspecialcaseoftheK-periodicinformationstructure,the
one-step information structure plays a crucial role in establishing properties of the more general K-periodic
information structure. In this section, we saw that the update equation for the K-step predictor can only
be obtained through recursively applying the update equation for the one-step predictor. As will be seen in
section 6.1, this will have implications for predictor stability as well. This is because predictor stability for
the one-step problem plays an important role in the proof of predictor stability for the K-periodic problem.
Additionally, as will be shown in the next section the weak-Feller property can be established for the one-
step delayed problem under much weaker conditions than those needed for the k-periodic information sharing
patrtern.
4 Weak-Feller Property of the resulting MDPs
In this section, we will use the structural results established in section 3 as well as the topologies on the
map-valued actions introduced for the one-step delayed pattern and the K-step periodic pattern in order to
find under which conditions the kernels η and θ are weak Feller i.e. weakly continuous. The weak-Feller
property is important as it enables one to establish the existence of optimal solutions and allows one to use
analytical tools to find those solutions such as the DCOE (dicounted cost optimality equation) as well as
numerical tools such as quantized Q-learning.
4.1 Weak-Feller property for the one-step delayed sharing pattern
Theorem 4.1 Suppose X is compact and the transition kernel τ(x ∈ ·|x = x,u = u) is weakly con-
t+1 t t
tinuous in x and u. Additionally suppose h(x,u) is continuous in x (for all u: h(.,x) → R is a continuous
function). Then, the MDP (Z ,f ) introduced in Theorem 3.2 is Weak-Feller.
t t
11Here,wewillneedthefollowinglemmawhichisaweakerofversionofLemma1in[15],butwhichfollows
from its proof [15].
Lemma 4.1 Let {G (x)} bea family of uniformly bounded functions (for all A ||G (x)|| ≤C) suchthat
A A A ∞
for every {xn} such that xn →x we have sup |G (xn)−G (x)|→0 as n→∞. Then for any sequenceof
n A A A
probability measures Z such that Z →Z weakly, we have that: sup| G (x)Z (dx)−G (x)Z(dx)|→0.
n n A n A
A
Z
Proof of Theorem 4.1. Let g be a continuous and bounded function. We have
N
|E[g(z )|Zn,f ]−E[g(z )|Z ,f ]|=| g(z )χ fi (dui|yi)Qi(dyi|x )Zn(dx )−
t+1 t n,t t+1 t t t+1 {F(Z tn,ut,y t[1,N])∈.} n,t t t t t t t
Z i=1
Y
N
g(z )χ Qi(dyi|x )fi(dui|yi)Z (dx )|
t+1 {F(Zt,ut,y t[1,N])∈.} t t t t t t t
Z i=1
Y
≤Ln+Ln
1 2
Where,
N
Ln =| g(z )χ Qi(dyi|x )fi (dui|yi)Zn(dx )− g(z )
1 t+1 {F(Z tn,ut,y t[1,N])∈.} t t n,t t t t t t+1
Z i=1 Z
Y
N
χ Qi(dyi|x )fi (dui|yi)Z (dx )|
{F(Z tn,ut,y t[1,N])∈.} t t n,t t t t t
i=1
Y
and
N N N
Ln =| [g(z )χ fi (dui|yi)−g(z )χ fi(dui|yi)] Qi(dyi|x )Z (dx )|
2 t+1 {F(Z tn,ut,y t[1,N])∈.} n,t t t t+1 {F(Zt,ut,y t[1,N])∈.} t t t t t t t
Z i=1 i=1 i=1
Y Y Y
To complete the proof, we’ll show that Ln →0 and
1
Ln →0 as n→∞. Since ||g|| ≤1 we have:
2 ∞
Ln ≤ kP(y[1,N]|Zn)−P(y[1,N]|Z )k
1 t t t t TV
N N
= 2sup| ( Qi(dyi|x ))Zn(dx )− ( Qi(dyi|x ))Z(dx )|
t t t t
A ZX ZAi=1 ZX ZAi=1
Y Y
Let G (x)= N Qi(dyi|x ). Since h is continuous in x, by Scheffé’s theorem [37], we have that
A A i=1 t
sup|G (xn)−G (x)|→0. Thus, by lemma 1, Ln →0.
A A A R Q 1
The following inequality holds: Ln ≤Mn+Mn where,
2 1 2
N
Mn =| [g(z )χ fi (dui|yi)−g(z )χ
1 t+1 {F(Z tn,ut,y t[1,N])∈.} n,t t t t+1 {F(Z tn,ut,y t[1,N])∈.}
Z i=1
Y
N N
fi(dui|yi)] Qi(dyi|x )Z (dx )|
t t t t t t t
i=1 i=1
Y Y
and
N N
Mn =| [g(z )χ fi(dui|yi)−g(z )χ fi(dui|yi)]
2 t+1 {F(Z tn,ut,y t[1,N])∈.} t t t t+1 {F(Zt,ut,y t[1,N])∈.} t t t
Z i=1 i=1
Y Y
N
Qi(dyi|x )Z (dx )|
t t t t
i=1
Y
Next,we’llshowthatMnandMn convergetozero. Letǫ>0. SinceXiscompact,P(X)isweaklycompact.
1 2
Hence, by Stone-Weirstrass theorem there exists a bounded Lipschitz function g˜ such that kg−g˜k ≤ ǫ.
∞
12Thus,
N N
Mn =| [g(z )χ fi(dui|yi)−g(z )χ fi(dui|yi)]
2 t+1 {F(Z tn,ut,y t[1,N])∈.} t t t t+1 {F(Zt,ut,y t[1,N])∈.} t t t
Z i=1 i=1
Y Y
N
Qi(dyi|x )Z (dx )|
t t t t
i=1
Y
N N
≤| [g(z )χ fi(dui|yi)−g˜(z )χ fi(dui|yi)]
t+1 {F(Z tn,ut,y t[1,N])∈.} t t t t+1 {F(Z tn,ut,y t[1,N])∈.} t t t
Z i=1 i=1
Y Y
N
Qi(dyi|x )Z (dx )|+
t t t t
i=1
Y
N N
| [g˜(z )χ fi(dui|yi)−g˜(z )χ fi(dui|yi)]
t+1 {F(Z tn,ut,y t[1,N])∈.} t t t t+1 {F(Zt,ut,y t[1,N])∈.} t t t
Z i=1 i=1
Y Y
N
Qi(dyi|x )Z (dx )|+
t t t t
i=1
Y
N N
| [g˜(z )χ fi(dui|yi)−g(z )χ fi(dui|yi)]
t+1 {F(Zt,ut,y t[1,N])∈.} t t t t+1 {F(Zt,ut,y t[1,N])∈.} t t t
Z i=1 i=1
Y Y
N N
≤2ǫ+kg˜k sup | [g(z )χ fi(dui|yi)−g(z )χ fi(dui|yi)]
BL
kgkBL≤1 Z
t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
t t t t+1 {F(Zt,ut,y t[1,N])∈.}
i=1
t t t
Y Y
N
≤2ǫ+kg˜k [ρ(z (Zn,u ,y[1,N]),z (Z ,u ,y[1,N]))] Qi(dyi|x )Z (dx )fi(dui|yi)
BL t+1 t t t t+1 t t t t t t t t t t
Z i=1
Y
Next, we’ll show that ρ(z (Zn,u ,y[1,N]),z (Z ,u ,y[1,N]))
t+1 t t t t+1 t t t
→0. Let
N
αn = Zn(dx ) h(x ,yi)
t t t t
ZX i=1
Y
N
α = Z (dx ) h(x ,yi)
t t t t
ZX i=1
Y
Since X is compact and h is continuous in x, it follows that αn → α as n → ∞. Hence to show
ρ(z (Zn,u ,y[1,N]),z (Z ,u ,y[1,N]))→0, it is sufficient to show that for all g ∈C (X)
t+1 t t t t+1 t t t b
N N
| g(x )τ(dx |x ,u )Zn(dx ) h(x ,yi)−g(x )τ(dx |x ,u )Z (dx ) h(x ,yi)|
t+1 t+1 t t t t t t t+1 t+1 t t t t t t
Z i=1 i=1
Y Y
N N
=| Zn(dx ) g(x )τ(dx |x ,u) h(x ,yi)− Z (dx ) g(x )τ(dx |x ,u) h(x ,yi)|→0
t t t+1 t+1 t t t t t t+1 t+1 t t t
Z Z i=1 Z Z i=1
Y Y
The latter follows from the fact that τ is weakly continuous in x and Zn → Z weakly. Now, by DCT it
t t
follows that limsup Mn ≤2ǫ. Because ǫ was arbitrary, it then follows that lim Mn =0.
n→∞ 2 2
n→∞
Next, we will show that Mn →0. Let ǫ>0 and consider
1
N N
µ (.) = fi (dui|yi) Qi(dyi|x )Z (dx )
n n,t t t t t t t
Z.i=1 i=1
Y Y
N N
µ(.) = fi(dui|yi) Qi(dyi|x )Z (dx )
t t t t t t t
Z.i=1 i=1
Y Y
13Note that µ → µ weakly. Hence, there exists a compact set K such that for all n µ (KC) < ǫ and
n 1 n 1
µ(KC)<ǫ. Thu we get that
1
N
Mn =| [g(z )χ fi (dui|yi)−g(z )χ
1 t+1 {F(Z tn,ut,y t[1,N])∈.} n,t t t t+1 {F(Z tn,ut,y t[1,N])∈.}
Z i=1
Y
N N
fi(dui|yi)] Qi(dyi|x )Z (dx )|
t t t t t t t
i=1 i=1
Y Y
N
≤2kgk ǫ+| [g(z )χ fi (dui|yi)−g(z )χ
∞
ZK1
t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
n,t t t t+1 {F(Z tn,ut,y t[1,N])∈.}
Y
N N
fi(dui|yi)] Qi(dyi|x )Z (dx )|
t t t t t t t
i=1 i=1
Y Y
N
Considerthemeasureν ∈P(X× Yi)givenbyν(.)= N Qi(dyi|x )Z (dx ). ByLusin’stheorem,the
. i=1 t t t t
i=1
N Y R Q N
measurability of h(x,yi) implies that there exists a closed set K ∈X× Yi such that the restriction
2
i=1 i=1
of N h(x,yi) tY o K is continuous in y and ν(KC) ≤ ǫ. Hence, by restrictY ing the canonical projection of
i=1 2 2
K onto X× N Yi to K we get that there exists a compact set K such that
1Q i=1 2
Q
N N N
| [g(z )χ fi (dui|yi)−g(z )χ fi(dui|yi)] Qi(dyi|x )Z (dx )|
ZK1
t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
n,t t t t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
t t t
i=1
t t t t
Y Y Y
N N N
≤| [g(z )χ fi (dui|yi)−g(z )χ fi(dui|yi)] Qi(dyi|x )Z (dx )|
ZK
t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
n,t t t t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
t t t
i=1
t t t t
Y Y Y
+2ǫkgk
∞
Thus,
N N
Mn ≤4ǫkgk +| [g(z )χ fi (dui|yi)−g(z )χ fi(dui|yi)]
1 ∞
ZK
t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
n,t t t t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
t t t
Y Y
N
Qi(dyi|x )Z (dx )|
t t t t
i=1
Y
To proceed, we note that
N N N
| [g(z )χ fi (dui|yi)−g(z )χ fi(dui|yi)] Qi(dyi|x )Z (dx )|
ZK
t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
n,t t t t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
t t t
i=1
t t t t
Y Y Y
N N N
≤| [g(z )χ fi (dui|yi)−g(z )χ fi(dui|yi)] Qi(dyi|x )Z (dx )|
ZK
t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
n,t t t t+1 {F(Zt,ut,y t[1,N])∈.}
i=1
t t t
i=1
t t t t
Y Y Y
N N N
+| [g(z )χ fi(dui|yi)−g(z )χ fi(dui|yi)] Qi(dyi|x )Z (dx )|
ZK
t+1 {F(Zt,ut,y t[1,N])∈.}
i=1
t t t t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
t t t
i=1
t t t t
Y Y Y
The proof that the second term in the last inequality goes to zero proceeds in similar manner as the proof
that Mn →0. On the other hand, the first term in the last inequality can be written as
2
N N N
| [g(z )χ fi (dui|yi)−g(z )χ fi(dui|yi)] Qi(dyi|x )Z (dx )|
ZK
t+1 {F(Z tn,ut,y t[1,N])∈.}
i=1
n,t t t t+1 {F(Zt,ut,y t[1,N])∈.}
i=1
t t t
i=1
t t t t
Y Y Y
N N N
=| [g(F(Zn,u ,y[1,N] )) fi (dui|yi)−g(F(Z ,u ,y[1,N] )) fi(dui|yi)] Qi(dyi|x )Z (dx )|
t t t n,t t t t t t t t t t t t t
ZK i=1 i=1 i=1
Y Y Y
14=:Mn
3
Because µ → µ weakly, by the generalized DCT theorem (see theorem D.3.1 (i) in [33]), to show that
n
Mn → 0 it is sufficient to show that F(Zn,u ,y[1,N]) → F(Z ,u ,y[1,N]) continuously over (u ,y[1,N]).
3 t t t t t t t t
Let g ∈ C (X). Consider a sequence such that (un,y[1,N] ) → (u ,y[1,N] ). Over K, we have that
1 b t n,t t t
N h(x ,yi ) → N h(x ,yi). Because h is continuous in x, the last sequence converges continuously
i=1 t n,t i=1 t t
N N
oQ ver x and hence byQ the generalized DCT Zn(dx ) h(x ,yi )→ Z (dx ) h(x ,yi). Thus to show
t t t n,t t t t t
Z i=1 Z i=1
Y Y
that F(Zn,u ,y[1,N])→F(Z ,u ,y[1,N]) continuously over (u ,y[1,N]), it is sufficient to show that
t t t t t t t t
N N
| Zn(dx ) g (x )τ(dx |x ,u ) h(x ,yi )− Z (dx ) g (x )τ(dx |x ,u) h(x ,yi)|→0
t t 1 t+1 t+1 t n t n,t t t 1 t+1 t+1 t t t
Z Z i=1 Z Z i=1
Y Y
Again by the generalized DCT, it is sufficient to show that for a sequence x →x, we have that
n
N N
| g (x )τ(dx |x ,u ) h(x ,yi )− g (x )τ(dx |x ,u) h(x ,yi)|→0
1 t+1 t+1 n,t n n,t n,t 1 t+1 t+1 t t t
Z i=1 Z i=1
Y Y
To this end, note that
N N
| g (x ) h(x ,yi )τ(dx |x ,u )− g (x ) h(x ,yi)τ(dx |x ,u)|
1 t+1 n,t n,t t+1 n,t n 1 t+1 t t t+1 t
Z i=1 Z i=1
Y Y
N N
≤| g (x ) h(x ,yi )τ(dx |x ,u )− g (x ) h(x ,yi)τ(dx |x ,u )|+
1 t+1 n,t n,t t+1 n,t n 1 t+1 t t t+1 n,t n
Z i=1 Z i=1
Y Y
N N
≤| g (x ) h(x ,yi)τ(dx |x ,u )− g (x ) h(x ,yi)τ(dx |x ,u)|
1 t+1 t t t+1 n,t n 1 t+1 t t t+1 t
Z i=1 Z i=1
Y Y
N N
Since K is compact, we have that h(x ,yi )→ h(x ,yi) uniformly and hence,
n,t n,t t t
i=1 i=1
Y Y
| g (x ) N h(x ,yi )τ(dx |x ,u )− g (x ) N h(x ,yi)τ(dx |x ,u )|→0. Bythecon-
1 t+1 i=1 n,t n,t t+1 n,t n 1 t+1 i=1 t t t+1 n,t n
tinuity of τ in (x,u), we get that
R Q R Q
N N
| g (x ) h(x ,yi)τ(dx |x ,u )− g (x ) h(x ,yi)τ(dx |x ,u)|
1 t+1 t t t+1 n,t n 1 t+1 t t t+1 t
Z i=1 Z i=1
Y Y
N
= h(x ,yi)| g (x )τ(dx |x ,u )− g (x )τ(dx |x ,u)|→0
t t 1 t+1 t+1 n,t n 1 t+1 t+1 t
i=1 Z Z
Y
Thus we have that Mn → 0. This, in turn, implies that limsupMn ≤ 4ǫkgk . Because ǫ was arbitrary, it
3 1 ∞
n→∞
follows that Mn →0.
1
⋄
4.2 Weak-Feller property for the K-step delayed sharing pattern
Theorem 4.2 Suppose the state space X is compact, the transition kernel τ(x .|x =x,u =u) is con-
t+1 t t
tinuous under total variation in x and u, and h(x,y) is continuous in x. Then the MDP (πq;a ) introduced
q
in Theorem 3.3 is Weak-Feller.
Proof of Theorem Let g ∈C (P(X)).
b
E g(π )|πn,a −E[g(π )|π ,a ]
q+1 q q,n q+1 q q
(cid:12)≤V(cid:2)1n+V 2n
(cid:3) (cid:12)
(cid:12) (cid:12)
15where, Vn =|E g(π )|πn,a −E g(π )|πn,a |
1 q+1 q q,n q+1 q q
and Vn =|E g((cid:2) π )|πn,a −E(cid:3) [g(π(cid:2) )|π ,a ]|. (cid:3)
2 q+1 q q q+1 q q
(cid:2) (cid:3)
Next, we will show that Vn →0 and Vn →0 as n→∞.
1 2
Vn = g(π )θ π |πn,a − g(π )θ(π |π ,a )
2 q+1 q+1 q q q+1 q+1 q q
(cid:12)Z Z (cid:12)
(cid:12) (cid:0) (cid:1) (cid:12)
=(cid:12) | g(π )χ P(dy[1,N] (cid:12) ,du[1,N] |πn,a )−
(cid:12)
Z
q+1 {G(π qn,u [qK,qK+K−1],y [[ q1 K,N ,q] K+K−1])} [qK,qK(cid:12)+K−1] [qK,qK+K−1] q q
g(π )χ P(dy[1,N] ,du[1,N] |π ,a )|
q+1 {G(πq,u [qK,qK+K−1],y [[ q1 K,N ,q] K+K−1])} [qK,qK+K−1] [qK,qK+K−1] q q
Z
≤| g(π )χ P(dy[1,N] ,du[1,N] |πn,a )−
q+1 {G(π qn,u [qK,qK+K−1],y [[ q1 K,N ,q] K+K−1])} [qK,qK+K−1] [qK,qK+K−1] q q
Z
g(π )χ P(dy[1,N] ,du[1,N] |π ,a )|+
Z
q+1 {G(π qn,u [qK,qK+K−1],y [[ q1 K,N ,q] K+K−1])} [qK,qK+K−1] [qK,qK+K−1] q q
| g(π )χ P(dy[1,N] ,du[1,N] |π ,a )−
q+1 {G(π qn,u [qK,qK+K−1],y [[ q1 K,N ,q] K+K−1])} [qK,qK+K−1] [qK,qK+K−1] q q
Z
g(π )χ P(dy[1,N] ,du[1,N] |π ,a )|
q+1 {G(πq,u [qK,qK+K−1],y [[ q1 K,N ,q] K+K−1])} [qK,qK+K−1] [qK,qK+K−1] q q
Z
For the second term in the last inequality, we have that
| g(π )χ P(dy[1,N] ,du[1,N] |π ,a )−
q+1 {G(π qn,u [qK,qK+K−1],y [[ q1 K,N ,q] K+K−1])} [qK,qK+K−1] [qK,qK+K−1] q q
Z
g(π )χ P(dy[1,N] ,du[1,N] |π ,a )|
q+1 {G(πq,u [qK,qK+K−1],y [[ q1 K,N ,q] K+K−1])} [qK,qK+K−1] [qK,qK+K−1] q q
Z
=| g(G(πn,u ,y[1,N] ))P(dy[1,N] ,du[1,N] |π ,a )−
q [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] q q
Z
g(G(π ,u ,y[1,N] ))P(dy[1,N] ,du[1,N] |π ,a )|→0
q [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] q q
Z
The latter follows fromthe fact that G is obtained throughrecursiveapplications of the update function for
the one-steppredictor: F which was shownto be continuous in the predictor in the proof of the weak-Feller
property for the one-step problem. Thus G is continuous in the predictor and the desired result follows by
an application of DCT. Hence, in order to show that Vn →0, it is sufficient to show that
2
Vn :=| g(π )χ P(dy[1,N] ,du[1,N] |πn,a )−
3 q+1 {G(π qn,u [qK,qK+K−1],y [[ q1 K,N ,q] K+K−1])} [qK,qK+K−1] [qK,qK+K−1] q q
Z
g(π )χ P(dy[1,N] ,du[1,N] |π ,a )|→0
Z
q+1 {G(π qn,u [qK,qK+K−1],y [[ q1 K,N ,q] K+K−1])} [qK,qK+K−1] [qK,qK+K−1] q q
We have that
Vn ≤kgk ||P(dy[1,N] ,du[1,N] |πn,a )−P(dy[1,N] ,du[1,N] |π ,a )||
3 ∞ [qK,qK+K−1] [qK,qK+K−1] q q [qK,qK+K−1] [qK,qK+K−1] q q TV
N
=2kgk sup| πn(dx )[ Qi(dyi |x )fi (dui |yi ) τ(dx |x ,u )...
∞ q qK qK qK qK qK qK qK+1 qK qK
A !
Z Z i=1
Y
N
τ(dx |x ,u ) Qi dyi |x
qK+K−1 qK+K−2 qK+K−2 qK+K−1 qK+K−1
i=1
Y (cid:0) (cid:1)
fi (dui |yi ,yi )]− π (dx )
qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2] q qK
Z
N
[ Qi(dyi |x )fi (dui |yi ) τ(dx |x u )...τ(dx |x ,u )
qK qK qK qK qK qK+1 qK qK qK+K−1 qK+K−2 qK+K−2
!
Z i=1
Y
16N
Qi dyi |x fi (dui |yi ,yi )]|
qK+K−1 qK+K−1 qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qk+K−2]
i=1
Y (cid:0) (cid:1)
Since τ is continuous in x under total variation and h(x,y) is continuous in x, {G˜ (x)} , where
A A
G˜ (x)= N Qi(dyi |x )fi (dui |yi ) τ(dx |x u )...τ(dx |x ,u )
A i=1 qK qK qK qK qK qK+1 qK qK qK+K−1 qK+K−2 qK+K−2
N i=1Qi Rdy(cid:16) qi QK+K−1 |x qK+K−1 f qi K+K−1(dui qK(cid:17) +K−1|y [i qK,qK+K−1],y [i qK,qK+K−2]),satisfiestheconditionof
lemma 4.1. It, then, follows that
Q (cid:0) (cid:1)
sup πn(dx )G˜ (x)− π (dx )G˜ (x) →0
q qK A q qK A
A (cid:12)Z Z (cid:12)
(cid:12) (cid:12)
as n→0. Hence, Vn →0. Next(cid:12), we will show that Vn →0. We have th(cid:12)at
3 (cid:12) 1 (cid:12)
Vn =|E g(π )|πn,a −E g(π )|πn,a
1 q+1 q q,n q+1 q q
=| g(G(cid:2)(πn,u (cid:3),y[1,N(cid:2)] ))P(dy[1(cid:3),N] ,du[1,N] |πn,a )−
q [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] q q,n
Z
g(G(πn,u ,y[1,N] ))P(dy[1,N] ,du[1,N] |πn,a )|
q [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] q q
Z
Because X is compact, it is sufficient to check that
sup | g(y[1,N] ,u[1,N] )P(dy[1,N] ,du[1,N] |πn,a )−
[qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] q q,n
kgkBL≤1 Z
g(y[1,N] ,u[1,N] )P(dy[1,N] ,du[1,N] |πn,a )|=
[qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] q q
Z
ρ(P(dy[1,N] ,du[1,N] |πn,a ),P(dy[1,N] ,du[1,N] |πn,a ))→0
[qK,qK+K−1] [qK,qK+K−1] q q,n [qK,qK+K−1] [qK,qK+K−1] q q
Now,
sup | g(y[1,N] ,u[1,N] )P(dy[1,N] ,du[1,N] |πn,a )−
[qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] q q,n
kgkBL≤1 Z
g(y[1,N] ,u[1,N] )P(dy[1,N] ,du[1,N] |πn,a )|
[qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] [qK,qK+K−1] q q
Z
N N
= sup | gπn(dx )( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N])( ψ(dyi )
q Kq qK qK qK n,qK Kq Kq Kq+1 Kq Kq qK+1
kgkBL≤1 Z i=1 i=1
Y Y
h(x ,yi )fi (dui |yi ,yi ))...
qK+1 qK+1 n,qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
N
fi (dui |yi ,ui )τ(dx |x ,u[1,N] )
n,Kq+K−2 Kq+K−2 [qK,qK+K−2] [qK,qK+K−3] qK+K−1 qK+K−2 qK+K−2
i=1
Y
N
( ψ(dyi )h(x ,yi ))fi (dui |yi ,yi )−
qK+K−1 qK+K−1 qK+K−1 n,qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
i=1
Y
N N
gπn(dx )( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N])( ψ(dyi )
q Kq qK qK qK qK Kq Kq Kq+1 Kq Kq qK+1
Z i=1 i=1
Y Y
N
h(x ,yi ))... fi (dui |yi ,ui )
qK+1 qK+1 qK+K−2 Kq+K−2 [qK,qK+K−2] [qK,qK+K−3]
i=1
Y
N
τ(dx |x ,u[1,N] )( ψ(dyi )h(x ,yi )
qK+K−1 qK+K−2 qK+K−2 qK+K−1 qK+K−1 qK+K−1
i=1
Y
fi (dui |yi ,yi ))|
qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
N N
≤ πn(dx ) sup [| g( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N])( ψ(dyi )
q Kq qK qK qK n,qK Kq Kq Kq+1 Kq Kq qK+1
Z kgkBL≤1 Z i=1 i=1
Y Y
h(x ,yi )fi (dui |yi ,yi ))...
qK+1 qK+1 n,qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
17N
fi (dui |yi ,ui )τ(dx |x ,u[1,N] )
n,Kq+K−2 Kq+K−2 [qK,qK+K−2] [qK,qK+K−3] qK+K−1 qK+K−2 qK+K−2
i=1
Y
N
( ψ(dyi )h(x ,yi ))fi (dui |yi ,yi )− g
qK+K−1 qK+K−1 qK+K−1 n,qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
i=1 Z
Y
N N
( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N] )( ψ(dyi )
qK qK qK qK Kq Kq Kq+1 Kq Kq qK+1
i=1 i=1
Y Y
N
h(x ,yi ))... fi (dui |yi ,ui )
qK+1 qK+1 qK+K−2 Kq+K−2 [qK,qK+K−2] [qK,qK+K−3]
i=1
Y
N
τ(dx |x ,u[1,N] )( ψ(dyi )h(x ,yi )
qK+K−1 qK+K−2 qK+K−2 qK+K−1 qK+K−1 qK+K−1
i=1
Y
fi (dui |yi ,yi ))|]
qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
Because the supremum in the last inequality is taken over a compact set, it is sufficient to check that for
countably many functions g , we have that
m
N N
πn(dx )[| g ( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N])( ψ(dyi )
q Kq m qK qK qK n,qK Kq Kq Kq+1 Kq Kq qK+1
Z Z i=1 i=1
Y Y
h(x ,yi )fi (dui |yi ,yi ))...
qK+1 qK+1 n,qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
N
fi (dui |yi ,ui )τ(dx |x ,u[1,N] )
n,Kq+K−2 Kq+K−2 [qK,qK+K−2] [qK,qK+K−3] qK+K−1 qK+K−2 qK+K−2
i=1
Y
N
( ψ(dyi )h(x ,yi ))fi (dui |yi ,yi )− g
qK+K−1 qK+K−1 qK+K−1 n,qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2] m
i=1 Z
Y
N N
( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N])( ψ(dyi )
qK qK qK qK Kq Kq Kq+1 Kq Kq qK+1
i=1 i=1
Y Y
N
h(x ,yi ))... fi (dui |yi ,ui )
qK+1 qK+1 qK+K−2 Kq+K−2 [qK,qK+K−2] [qK,qK+K−3]
i=1
Y
N
τ(dx |x ,u[1,N] )( ψ(dyi )h(x ,yi )
qK+K−1 qK+K−2 qK+K−2 qK+K−1 qK+K−1 qK+K−1
i=1
Y
fi (dui |yi ,yi ))|]→0
qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
In particular, because the expression
N N
[| g ( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N])( ψ(dyi )
m qK qK qK n,qK Kq Kq Kq+1 Kq Kq qK+1
Z i=1 i=1
Y Y
h(x ,yi )fi (dui |yi ,yi ))...
qK+1 qK+1 n,qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
N
fi (dui |yi ,ui )τ(dx |x ,u[1,N] )
n,Kq+K−2 Kq+K−2 [qK,qK+K−2] [qK,qK+K−3] qK+K−1 qK+K−2 qK+K−2
i=1
Y
N
( ψ(dyi )h(x ,yi ))fi (dui |yi ,yi )− g
qK+K−1 qK+K−1 qK+K−1 n,qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2] m
i=1 Z
Y
N N
( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N])( ψ(dyi )
qK qK qK qK Kq Kq Kq+1 Kq Kq qK+1
i=1 i=1
Y Y
N
h(x ,yi ))... fi (dui |yi ,ui )
qK+1 qK+1 qK+K−2 Kq+K−2 [qK,qK+K−2] [qK,qK+K−3]
i=1
Y
18N
τ(dx |x ,u[1,N] )( ψ(dyi )h(x ,yi )
qK+K−1 qK+K−2 qK+K−2 qK+K−1 qK+K−1 qK+K−1
i=1
Y
fi (dui |yi ,yi ))|]:=E(x )
qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2] qk
is continuous in x and X is a compact set. It is sufficient to check that for any x we have E(x )→0. In
qK qk
particular, it is sufficient to show that for any x
qK
N N
sup [| g( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N])( ψ(dyi )
qK qK qK n,qK Kq Kq Kq+1 Kq Kq qK+1
kgkBL≤1 Z i=1 i=1
Y Y
h(x ,yi )fi (dui |yi ,yi ))...
qK+1 qK+1 n,qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
N
fi (dui |yi ,ui )τ(dx |x ,u[1,N] )
n,Kq+K−2 Kq+K−2 [qK,qK+K−2] [qK,qK+K−3] qK+K−1 qK+K−2 qK+K−2
i=1
Y
N
( ψ(dyi )h(x ,yi ))fi (dui |yi ,yi )− g
qK+K−1 qK+K−1 qK+K−1 n,qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
i=1 Z
Y
N N
( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N])( ψ(dyi )
qK qK qK qK Kq Kq Kq+1 Kq Kq qK+1
i=1 i=1
Y Y
N
h(x ,yi ))... fi (dui |yi ,ui )
qK+1 qK+1 qK+K−2 Kq+K−2 [qK,qK+K−2] [qK,qK+K−3]
i=1
Y
N
τ(dx |x ,u[1,N] )( ψ(dyi )h(x ,yi )
qK+K−1 qK+K−2 qK+K−2 qK+K−1 qK+K−1 qK+K−1
i=1
Y
fi (dui |yi ,yi ))|]→0
qK+K−1 qK+K−1 [qK,qK+K−1] [qK,qK+K−2]
In what follows, we will assume that K = 3 for ease of presentation. The more general case can be proved
using a similar process.
N N
sup | g( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N] )( ψ(dyi )h(x ,yi )
3q 3q 3q n,3q 3q 3q 3q+1 3q 3q 3q+1 3q+1 3q+1
kgkBL≤1 Z i=1 i=1
Y Y
N
fi (dui |yi ,ui ))τ(dx |x ,u[1,N])( ψ(dyi )h(x ,yi )
n,3q+1 3q+1 [3q,3q+1] 3q 3q+2 3q+1 3q+1 3q+2 3q+2 3q+2
i=1
Y
N
fi (dui |yi ,ui ))− g( ψ(dyi )h(x ,yi )fi (dui |yi ))τ(dx |x ,u[1,N])
n,3q+2 3q+2 [3q,3q+2] [3q,3q+1] 3q 3q 3q 3q 3q 3q 3q+1 3q 3q
Z i=1
Y
N N
( ψ(dyi )h(x ,yi )fi (dui |yi ,ui ))τ(dx |x ,u[1,N])( ψ(dyi )
3q+1 3q+1 3q+1 3q+1 3q+1 [3q,3q+1] 3q 3q+2 3q+1 3q+1 3q+2
i=1 i=1
Y Y
h(x ,yi )fi (dui |yi ,ui ))|≤Mn+Mn+Mn
3q+2 3q+2 3q+2 3q+2 [3q,3q+2] [3q,3q+1] 1 2 3
where,
N N
Mn = sup | g ψ(dyi )h(x ,yi )fi (dui |yi )τ(dx |x ,u[1,N])( ψ(dyi )h(x ,yi )
1 3q 3q 3q n,3q 3q 3q 3q+1 3q 3q 3q+1 3q+1 3q+1
kgkBL≤1 Z i=1 i=1
Y Y
N
fi (dui |yi ,ui ))τ(dx |x ,u[1,N])( ψ(dyi )h(x ,yi )
n,3q+1 3q+1 [3q,3q+1] 3q 3q+2 3q+1 3q+1 3q+2 3q+2 3q+2
i=1
Y
N
fi (dui |yi ,ui ))− g ψ(dyi )h(x ,yi )fi (dui |yi )τ(dx |x ,u[1,N])
n,3q+2 3q+2 [3q,3q+2] [3q,3q+1] 3q 3q 3q 3q,n 3q 3q 3q+1 3q 3q
Z i=1
Y
N N
( ψ(dyi )h(x ,yi )fi (dui |yi ,ui ))τ(dx |x ,u[1,N])( ψ(dyi )
3q+1 3q+1 3q+1 3q+1,n 3q+1 [3q,3q+1] 3q 3q+2 3q+1 3q+1 3q+2
i=1 i=1
Y Y
19h(x ,yi )fi (dui |yi ,ui ))|
3q+2 3q+2 3q+2 3q+2 [3q,3q+2] [3q,3q+1]
N N
Mn = sup | g ψ(dyi )h(x ,yi )fi (dui |yi )τ(dx |x ,u[1,N] )( ψ(dyi )h(x ,yi )
2 3q 3q 3q n,3q 3q 3q 3q+1 3q 3q 3q+1 3q+1 3q+1
kgkBL≤1 Z i=1 i=1
Y Y
N
fi (dui |yi ,ui ))τ(dx |x ,u[1,N])( ψ(dyi )h(x ,yi )
n,3q+1 3q+1 [3q,3q+1] 3q 3q+2 3q+1 3q+1 3q+2 3q+2 3q+2
i=1
Y
N
fi (dui |yi ,ui ))− g ψ(dyi )h(x ,yi )fi (dui |yi )τ(dx |x ,u[1,N])
3q+2 3q+2 [3q,3q+2] [3q,3q+1] 3q 3q 3q 3q,n 3q 3q 3q+1 3q 3q
Z i=1
Y
N N
( ψ(dyi )h(x ,yi )fi (dui |yi ,ui ))τ(dx |x ,u[1,N])( ψ(dyi )
3q+1 3q+1 3q+1 3q+1 3q+1 [3q,3q+1] 3q 3q+2 3q+1 3q+1 3q+2
i=1 i=1
Y Y
h(x ,yi )fi (dui |yi ,ui ))|
3q+2 3q+2 3q+2 3q+2 [3q,3q+2] [3q,3q+1]
and,
N N
Mn = sup | g ψ(dyi )h(x ,yi )fi (dui |yi )τ(dx |x ,u[1,N])( ψ(dyi )h(x ,yi )
3 3q 3q 3q n,3q 3q 3q 3q+1 3q 3q 3q+1 3q+1 3q+1
kgkBL≤1 Z i=1 i=1
Y Y
N
fi (dui |yi ,ui ))τ(dx |x ,u[1,N])( ψ(dyi )h(x ,yi )
3q+1 3q+1 [3q,3q+1] 3q 3q+2 3q+1 3q+1 3q+2 3q+2 3q+2
i=1
Y
N
fi (dui |yi ,ui ))− g ψ(dyi )h(x ,yi )fi (dui |yi )τ(dx |x ,u[1,N])
3q+2 3q+2 [3q,3q+2] [3q,3q+1] 3q 3q 3q 3q 3q 3q 3q+1 3q 3q
Z i=1
Y
N N
( ψ(dyi )h(x ,yi )fi (dui |yi ,ui ))τ(dx |x ,u[1,N])( ψ(dyi )
3q+1 3q+1 3q+1 3q+1 3q+1 [3q,3q+1] 3q 3q+2 3q+1 3q+1 3q+2
i=1 i=1
Y Y
h(x ,yi )fi (dui |yi ,ui ))|
3q+2 3q+2 3q+2 3q+2 [3q,3q+2] [3q,3q+1]
To show that Mn →0, it is sufficient to check that for all u : Mn(u )→0. Where,
1 [qk,qk+2] 1 [qk,qk+2]
N N
Mn(u ):= sup | g ψ(dyi )h(x ,yi )fi (dui |yi )τ(dx |x ,u[1,N])( ψ(dyi )h(x ,yi )
1 [qk,qk+2] 3q 3q 3q n,3q 3q 3q 3q+1 3q 3q 3q+1 3q+1 3q+1
kgkBL≤1 Z i=1 i=1
Y Y
N
fi (dui |yi ,ui ))τ(dx |x ,u[1,N] )( ψ(dyi )h(x ,yi )
n,3q+1 3q+1 [3q,3q+1] 3q 3q+2 3q+1 3q+1 3q+2 3q+2 3q+2
i=1
Y
N
fi (dui |yi ,ui ))− g ψ(dyi )h(x ,yi )fi (dui |yi )τ(dx |x ,u[1,N])
n,3q+2 3q+2 [3q,3q+2] [3q,3q+1] 3q 3q 3q 3q,n 3q 3q 3q+1 3q 3q
Z i=1
Y
N N
( ψ(dyi )h(x ,yi )fi (dui |yi ,ui ))τ(dx |x ,u[1,N])( ψ(dyi )
3q+1 3q+1 3q+1 3q+1,n 3q+1 [3q,3q+1] 3q 3q+2 3q+1 3q+1 3q+2
i=1 i=1
Y Y
h(x ,yi )fi (dui |yi ,ui ))|
3q+2 3q+2 3q+2 3q+2 [3q,3q+2] [3q,3q+1]
Note that in the expression above there is no integration with respect to the action spaces. We have that
N
Mn(u )= sup | ( ψ(dyi )ψ(dyi )ψ(dyi ))fi (dui |yi ,ui )
1 [qk,qk+2] 3q 3q+1 3q+2 n,3q+2 3q+2 [3q,3q+2] [3q,3q+1]
kgkBL≤1 Z i=1
Y
N N
g h(x ,yi )fi (dui |yi )τ(dx |x ,u[1,N])( h(x ,yi )fi (dui |yi ,ui ))
3q 3q n,3q 3q 3q 3q+1 3q 3q 3q+1 3q+1 n,3q+1 3q+1 [3q,3q+1] 3q
Z i=1 i=1
Y Y
N N
τ(dx |x ,u[1,N]) h(x ,yi )− ( ψ(dyi )ψ(dyi )ψ(dyi ))fi (dui |yi ,ui )
3q+2 3q+1 3q+1 3q+2 3q+2 3q 3q+1 3q+2 3q+2 3q+2 [3q,3q+2] [3q,3q+1]
i=1 Z i=1
Y Y
20N N
g h(x ,yi )fi (dui |yi )τ(dx |x ,u[1,N])( h(x ,yi )fi (dui |yi ,ui ))
3q 3q n,3q 3q 3q 3q+1 3q 3q 3q+1 3q+1 n,3q+1 3q+1 [3q,3q+1] 3q
Z i=1 i=1
Y Y
N
τ(dx |x ,u[1,N]) h(x ,yi )|
3q+2 3q+1 3q+1 3q+2 3q+2
i=1
Y
N
≤ sup | g( ψ(dyi )ψ(dyi )ψ(dyi ))fi (dui |yi ,ui )
3q 3q+1 3q+2 n,3q+2 3q+2 [3q,3q+2] [3q,3q+1]
kgkBL≤1 Z i=1
Y
N
− g( ψ(dyi )ψ(dyi )ψ(dyi ))fi (dui |yi ,ui )|=rho(µ ,µ)→0
3q 3q+1 3q+2 3q+2 3q+2 [3q,3q+2] [3q,3q+1] n
Z i=1
Y
Where,
N
µ (.) = ( ψ(dyi )ψ(dyi )ψ(dyi ))fi (dui |yi ,ui )
n 3q 3q+1 3q+2 n,3q+2 3q+2 [3q,3q+2] [3q,3q+1]
Z. i=1
Y
N
µ = ( ψ(dyi )ψ(dyi )ψ(dyi ))fi (dui |yi ,ui )
3q 3q+1 3q+2 3q+2 3q+2 [3q,3q+2] [3q,3q+1]
Z. i=1
Y
Thus Mn →0. The proof that Mn →0 and Mn →0 proceeds in a similar manner. ⋄
1 2 3
5 Near optimality of finite memory policies under completely de-
centralized information: Joint conditional mixing condition
Inthissection,wewillestablishthenearoptimalityoffinitememorypoliciesforthecompletelydecentralized
stochastic control problem. We will provide a performance bound for the case where the policies which rely
onlocalinformationarereplacedwithamemberofalargeclassoffinitememorypoliciesofwhichthesliding
window policies are a special case. This bound, which depends on a joint conditional mixing condition, is
then used to prove the asymptotic optimality of finite memory policies which is the main motivation of this
paper. As will be seen, establishing such a result hinges crucially on an approximation with the K-periodic
problem and by extension on the results of Section 3.2. In particular, the importance of this result for the
completely decentralized problem is that in many applications belief or information sharing in impractical
either because of physical reasons or due to very restrictive memory constraints. Hence, it is of the essence
that one arrives at practical approximation schemes that do not require sharing such as the one which we
will present in this section.
The same performance bound, which applies to the change of policies for the decentralizedproblem, can
be used to determine the performance loss for the K-step periodic sharing problem if the action space is
reduced to only consider maps that do not rely on all of the private information available. This is not,
however,applicable to the one-step delayed problem as in that case the private information only consists of
one measurement.
5.1 Fully decentralized information; near optimality of finite memory local in-
formation under joint conditional mixing
It is easy to show that one can solve the completely decentralized stochastic control problem (1, 2, 4) by
reducingitto asingletime stageK-periodicproblem. When doingso,however,achallengearisesdue tothe
fact that the latter has a very large action space. In this section, we address this problem by considering
maps that rely on more recentmeasurements. We will provide an errorbound on the use of such maps that
exhibits exponential decay of order t−m+1 when the first m measurements are not used. In particular,
we first consider the case where for some time t, each agent each agent i can only use the measurements:
yi for some 0 < m < t. We will establish an error bound when such a restriction is imposed. Then, we
[m,t]
will establish an error bound when such restrictions are imposed on the maps used at several time stages.
Finally,wewilldiscussimplicationsfortheinfinitehorizondecentralizedstochasticcontrolproblemandhow
to optimize the action space reduction given any error tolerance.
Let (f∗,...,f∗ ) denote the optimal action maps. Where, f (du|y[1,N]) = N fi(dui|yi ). We will also
0 K−1 t [0,t] i=1 t [0,t]
use the notation: Q(.|y)= N Qi(.|y).
i=1 Q
Q
21Definition: For a kernel operator K :S →P(S ) we define the Dobrushin coefficient as:
1 2
n
δ(K)=inf min(K(x,A ),K(y,A )) (14)
i i
i=1
X
where the infimum is over all x,y ∈ S and all partitions {A }n of S . An equivalent and often useful
1 i i=1 2
definition of the Dobrushin coefficient is δ(K)=1−α(K) where,
kK(µ)−K(ν)k
TV
α(K)=sup
kµ−νk
µ=6 ν TV
A crucial property of the Dobrushin coefficient is that for any two measures µ,ν ∈P(S ):
2
kK(µ)−K(ν)k ≤(1−δ(K))kµ−νk
TV TV
Nextweintroduceajointconditionalmixingconditionwhichwillbecrucialforestablishingtheresultsofthis
l N
section. Letx∈Xandletf be apolicysuchthatf :y →u. Considerthe kernelTf from ( Yi)to
[0,l] x
j=0 i=1
Y Y
N
X× Yi given by Tf(dx ,dy|x,f(y )) = τ(dx |x,f(y ))Q(dy|x ). Define δ¯= inf δ(Tf). In what
x 1 [0,l] 1 [0,l] 1 x,f x
i=1
Y
follows, we will need the following assumption
Assumption 5.1 Joint conditional mixing. Suppose δ¯>0
The following is an easy to check sufficient condition for Joint conditional mxing to hold.
N N
Assumption 5.2 . Suppose infδ(T ) > 0 where T : Ui → X × Ui and is given by T =
x x x
x
i=1 i=1
Y Y
τ(dx |x,u)Q(dy|x ).
1 1
Proposition 5.1 Suppose assumption 5.2 holds. Then, δ¯>0.
Proof.
kTf(µ)−Tf(ν)k
supα(Tf) = supsup x x TV
x kµ−νk
x,f x,f µ=6 ν TV
Fix anyµ6=ν. Letf beanydeterministicpolicy. Wedenotethe measureinducedontheactionsundersuch
a policy by µf and νf. We have that for all x∈X
kTf(µ)−Tf(ν)k kT (µf)−T (νf)k
x x TV = x x TV
kµ−νk kµf −νfk
TV TV
≤ α(T )
x
Hence supα(Tf)≤supα(T ). Thus δ¯=infδ(Tf)≥infδ(T )>0.
x x x x
x,f x x,f x
⋄
Theorem 5.1 Suppose assumption 5.1 holds and that the action space is reduced so that the maps at time t
can only depend on y . Then, the loss in optimality from such a reduction is no greater than Err(t,m):=
[m,t]
K−1βj(1−δ¯)t−m+1kck
.
j=t ∞
PRemark 5.1 Note that here only the map at time t is replaced. For all other time stages k 6=t, the agents
use the optimal map f∗.
k
Proof. Before,proceedingtotheproofinthemoregeneralcase,wefirstconsiderthecasewhereK =2. We
obtain an error bound for the expected cost at time t=1 in the case where all agents replace their optimal
maps at time t = 1 with f˜(.|y ) = f∗(du |y[1,N])P(dy |π ). One can rewrite the time t = 1 component
1 1 · 1 t [0,1] 0 0
of the one-stage cost (12) as:
R
c˜(π ,a1,...,aN)=β π (dx )Q(dy |x )τ(dx |x ,f (y ))Q(dy |x )f (du |y )c(x ,u )]
0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 [0,1] 1 1
Z
22Letν(dy )=P(dy |π ). Letµ ,µ denotetheprobabilitymeasuresinducedon(x ,u )iff∗ andf˜ areused
0 0 0 1 2 1 1 1 1
0 if (y′ )6=y
respectively. Additionally,wedenotetheDiracmeasureconcentratedaty byA (dy′ )= 0 0
0 y0 0 (1 otherwise
Then, we get
E[kµ −µ k ]= sup | π (dx )Q(dy |x )τ(dx |x ,f∗(y ))Q(dy |x )f∗(du |y )g (x ,u )−
1 2 TV 0 0 0 0 1 0 0 0 1 1 1 1 [0,1] 1 1 1
kg1(x1,u1)k∞≤1 Z
π (dx )Q(dy |x )τ(dx |x ,f∗(y ))Q(dy |x )f˜(du |y )g (x ,u )|
0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1
Z
= sup | π (dx )Q(dy |x ) A (dy′ )τ(dx |x ,f∗(y′ ))Q(dy |x )f∗(du |y′ ,y )g (x ,u )−
0 0 0 0 y0 0 1 0 0 0 1 1 1 1 0 1 1 1 1
kg1(x1,u1)k∞≤1 Z Z
π (dx )Q(dy |x ) ν(dy′ )τ(dx |x ,f∗(y′ ))Q(dy |x )f∗(du |y′,y )g (x ,u )|
0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1
Z Z
≤ sup E[ sup | A y0(dy′ 0)τ(dx 1|x 0,f 0∗(y′ 0))Q(dy 1|x 1)g 2y′ 0,y1(x 1)−
x0,y0
kg
2y′0,y1(x1)k∞≤1
Z
ν(dy′ )τ(dx |x ,f∗(y′ ))Q(dy |x )gy′ 0,y1(x )|]
0 1 0 0 0 1 1 2 1
Z
≤(1−δ¯)
Note that in the above, gy′ 0,y1(x )= f∗(du |y′,y )g (x ,u ).
2 1 1 1 0 1 1 1 1
Thus, the error due to such a changeR in actions is not greater than βkck (1−δ¯). Next, as a further illus-
∞
trative example, we consider the case where K =3.
We obtain an error bound for the expected cost at time t = 2 in the case where all agents replace their
optimal maps at time t = 2 with f˜(.|y )= f∗(du |y[1,N])P(dy ,dy |π ). One can rewrite the time t = 2
2 2 · 2 t [0,2] 0 1 0
component of the one-stage cost (12) as:
R
c˜(π ,a1,...,aN)=β2 π (dx )Q(dy |x )τ(dx |x ,f (y ))Q(dy |x )f (du |y )τ(dx |x ,f (y ))
0 0 0 0 0 0 0 1 0 0 0 1 1 1 t [0,1] 2 1 1 [0,1]
Z
Q(dy |x )f (du |y )c(x ,u )]
2 2 2 2 [0,2] 2 2
Let ν(dy ,dy ) = P(dy ,dy |π ). Let µ , µ denote the probability measures induced on (x ,u ) if
0 1 0 1 0 1 2 2 2
f∗ and f˜ are used respectively. Additionally, we denote the Dirac measure concentrated at y ,y by
2 2 0 1
0 if (y′ ,y′ )6=(y ,y )
A (dy′ ,dy′ )= 0 1 0 1
y [0,1] 0 1 (1 otherwise
Then, we get
E[kµ −µ k ]= sup | π (dx )Q(dy |x )τ(dx |x ,f∗(y ))Q(dy |x )f∗(du |y )τ(dx |x ,u )
1 2 TV 0 0 0 0 1 0 0 0 1 1 1 1 [0,1] 2 1 1
kg1(x2,u2)k∞≤1 Z
Q(dy |x )f∗(du |y )g (x ,u )− π (dx )Q(dy |x )τ(dx |x ,f∗(y ))Q(dy |x )f∗(du |y )τ(dx |x ,u )
2 2 2 2 [0,2] 1 2 2 0 0 0 0 1 0 0 0 1 1 1 1 1 2 1 1
Z
Q(dy |x )f˜(du |y )g (x ,u )|
2 2 2 2 2 1 2 2
= sup | π (dx )Q(dy |x )τ(dx |x ,f∗(y′ ))Q(dy |x ) A (dy′ ,dy′ )τ(x |x ,f∗)Q(dy |x )
0 0 0 0 1 0 0 0 1 1 y [0,1] 0 1 2 1 1 2 2
kg1(x2,u2)k∞≤1 Z Z
f∗(du |y′ ,y′ ,y )g (x ,u )− π (dx )Q(dy |x )τ(dx |x ,f∗(y′ ))Q(dy |x ) ν(dy′ ,dy′ )τ(x |x ,f∗)
2 2 0 1 2 1 2 2 0 0 0 0 1 0 0 0 1 1 0 1 2 1 1
Z Z
Q(dy |x )f∗(du |y′ ,y′ ,y )g (x ,u )|
2 2 2 2 0 1 2 1 2 2
≤ sup E[ sup | A (dy′ ,dy′ )τ(dx |x ,f∗)Q(dy |x )gy′ 0,y′ 1,y2(x )−
y [0,1] 0 1 2 1 1 2 2 2 2
x [0,1],y [0,1] kg 2y′0,y′1,y2(x2)k∞≤1 Z
ν(dy′ 0,dy′ 1)τ(dx 2|x 1,f 1∗)Q(dy 2|x 2)g 2y′ 0,y′ 1,y2(x 2)|]
Z
≤(1−δ¯)
Similarly to the case of K =2, here we have that gy′ 0,y′ 1,y2(x )= f∗(du |y′ ,y′ ,y )g (x ,u ).
2 2 2 2 0 1 2 1 2 2
R
23Thus, the error due to such a change in actions is not greater than β2kck (1−δ¯).
∞
Next, we proceed with the more general proof.
Proof of Theorem 5.1. To prove this theorem, we construct a policy, which may not be optimal,
but achieves the error bound desired. Consider f˜(.|y ) = f∗(du |y[1,N])P(dy ,...,dy |π ). For any
t [m,t] · t t [0,t] 0 m−1 0
i∈{1,...,N} andt∈{0,1,...,K−1} we havethat σ(yi ,ui ) because allthe actions aredeterministic
[0,t] [0,Rt]−1
functionsofthemeasurements. Thus,onecan,withoutlossofoptimality,onlyconsiderfunctionsfi :yi 7→
t [0,t]
ui. However,forthesakeofthisproof,weallowf tobemeasurevalued. Henceonecanrewritetheone-stage
t t
cost (12) as:
t=K−1
c˜(π ,a1,...,aN)= βt π (dx )Q(dy |x )τ(dx |x ,f (y ))...
0 0 0 0 0 0 0 1 0 0 0
t=0 Z
X
τ(dx |x ,f (y ))Q(dy |x )f (du |y )c(x ,u )]
t t−1 t−1 [0,t−1] t t−1 t t [qK,qK+r] t t
Notethatthemapattimetdoesnotshowupintheequationforc˜untilthetth term. Sowefirstconsider
the error due to that term. Let ν(dy ,...,dy )=P(dy ,...,dy |π ). Let µ , µ denote the probability
0 m−1 0 m−1 0 1 2
measures induced on (x ,u ) if f∗ and f˜ are used respectively. Additionally, we denote the Dirac measure
t t t t
0 if (y′ ,...,y′ )6=y ,...,y
concentrated at y ,...,y by A (dy′ ,...,dy′ )= 0 m−1 0 m−1
0 m−1 y0,...,ym−1 0 m−1 (1 otherwise
Then, we get
E[kµ −µ k ]= sup | π (dx )Q(dy |x )τ(dx |x ,f∗(y ))...τ(dx |x ,f∗ (y ))
1 2 TV 0 0 0 0 1 0 0 0 m−1 m−2 m−2 [0,m−2]
kg1(xt,ut)k∞≤1 Z
Q(dy |x )τ(dx |x ,f∗ (y ,...,y ))Q(dy |x )...τ(dx |x ,f∗ )Q(dy |x )f∗(du |y )g (x ,u )−
m−1 m−1 m m−1 m−1 0 m−1 m m t t−1 t−1 t t t t [0,t] 1 t t
π (dx )Q(dy |x )τ(dx |x ,f∗(y ))...τ(dx |x ,f∗ (y ))Q(dy |x )
0 0 0 0 1 0 0 0 m−1 m−2 m−2 [0,m−2] m−1 m−1
Z
τ(dx |x ,f∗ (y ,...,y ))Q(dy |x )...τ(dx |x ,f∗ )Q(dy |x )f˜(du |y )g (x ,u )|
m m−1 m−1 0 m−1 m m t t−1 t−1 t t t t [m,t] 1 t t
= sup | π (dx )Q(dy |x )τ(dx |x ,f∗(y ))...τ(dx |x ,f∗ (y ))Q(dy |x )
0 0 0 0 1 0 0 0 m−1 m−2 m−2 [0,m−2] m−1 m−1
kg1(xt,ut)k∞≤1 Z
A (dy′ ,...,dy′ )τ(dx |x ,f∗ (y′ ,...,y′ ))Q(dy |x )...τ(dx |x ,f∗ )
y0,...,ym−1 0 m−1 m m−1 m−1 0 m−1 m m t t−1 t−1
Z
Q(dy |x )f∗(du |y′ ,y )g (x ,u )− π (dx )Q(dy |x )τ(dx |x ,f∗(y ))...τ(dx |x ,f∗ (y ))
t t t t [0,m−1] [m,t] 1 t t 0 0 0 0 1 0 0 0 m−1 m−2 m−2 [0,m−2]
Z
Q(dy |x ) ν(dy′ ,...,dy′ )τ(dx |x ,f∗ (y′ ,...,y′ ))Q(dy |x )...τ(dx |x ,f∗ )
m−1 m−1 0 m−1 m m−1 m−1 0 m−1 m m t t−1 t−1
Z
Q(dy |x )f∗(du |y′ ,y )g (x ,u )|
t t t t [0,m−1] [m,t] 1 t t
≤ sup E[ sup | A (dy′,...,dy′ )τ(dx |x ,f∗ (y′,...,y′ ))Q(dy |x )...
y0,...,ym−1 0 m−1 m m−1 m−1 0 m−1 m m
{x [0,m−1],y [0,m−1]} kg2(xt)k∞≤1 ZB
τ(dx |x ,f∗ )Q(dy |x )g (x )−ν(dy′,...,dy′ )τ(dx |x ,f∗ (y′,...,y′ ))Q(dy |x )...
t t−1 t−1 t t 2 t 0 m−1 m m−1 m−1 0 m−1 m m
τ(dx |x ,f∗ )Q(dy |x )g (x )|]
t t−1 t−1 t t 2 t
≤(1−δ¯)t−m+1
Here, g is defined in a similar manner to the case of K = 2 and K = 3. By also considering the terms
2
in c˜from t+1 to K−1 and taking the expected value of the cost, the desired result follows. ⋄
Corollary 5.1 Suppose at times 0 < t < t < ... < t ≤ K −1 the map f is replaced with one that only
1 2 l tk
uses the measurements: y . Then, the loss of optimality due to such an action space reduction is no
[mk,tk]
l K−1
greater than βj(1−δ¯)tk−m+1kck .
∞
Xk=1j X=tk
Proof. The proof simply follows by using Theorem 5.1 in conjunction with the triangle inequality.
⋄
The following corollary is also another straight forward implication of theorem 5.1.
24Corollary 5.2 Suppose assumption 5.1 holds. Then, finitememory policies are nearoptimal for the infinite
horizon decentralized stochastic control problem (1, 2, 4).
Remark 5.2 A particular instance of such finite memory policies is the so called sliding window. In this
case for all t≥m the map f is replaced with one that only uses the measurements: y .
t [t−m+1,t]
Next, we propose a method for optimally reducing the size of the action space. Let ǫ denote the error
tolerance S = {s = {t }l |0 < t < t < ... < t ≤ K −1}. We denote its cardinality by |S|. Suppose for
k k=1 1 2 l
some sequences∈S the mapf is replacedwithone thatonlyuses the measurements: y . We denote
tk [mk,tk]
the induced action space by As. Consider the following boundary NLP problem:
min |As|
(m1,...,ml)
l
s.t Err(t ,m )≤ǫ
k k
k=1
X
We denote its solution by NLP(s). The optimal memory reduction is then given by argmax NLP(s).
s∈S
5.1.1 Near optimality under strictly local decentralized information
In this section, we will provide an explicit performance bound for the use of sliding finite memory policies
to solve the decentralized stochastic problem (1, 2, 4).
Theorem 5.2 Suppose assumption 5.1 holds and that we restrict our policy space so that we only consider
policies with finite memory size: m. Then, the loss in performance due to such a restriction is no greater
than
kck [β(1−δ¯)]m−1](1−[β(1−δ¯)]K−m) kck (1−δ¯)m−1[1−(1−δ¯)K−m]βK−2
∞ ∞
−
(1−β)(1−[β(1−δ¯)]) (1−β)δ¯
Proof. Letǫ>0andK belargeenoughsothatK-periodicbeliefsharingpatternproblemwithasingletime
stageissuchthatitsoptimalcostJK satisfiesJ ≤JK+ǫwhereJ denotestheoptimalcostforthedecentral-
ized problem. Additionally, we choose K lrage so that for any policy γ we have that J(γ)−JK(γ)≤ǫ. By
corollary5.2,wegetthatthereexistsapolicywithaslidingwindowofsizem: γ suththatthefollowingholds
kck [β(1−δ¯)]m−1](1−[β(1−δ¯)]K−m) kck (1−δ¯)m−1[1−(1−δ¯)K−m]βK−2
JK(γ)−JK ≤ ∞ − ∞
(1−β)(1−[β(1−δ¯)]) (1−β)δ¯
Hence, we get that
J(γ)−J = J(γ)−JK(γ)+JK(γ)−JK +JK −J
kck [β(1−δ¯)]m−1](1−[β(1−δ¯)]K−m) kck (1−δ¯)m−1[1−(1−δ¯)K−m]βK−2
∞ ∞
≤ 2ǫ+ −
(1−β)(1−[β(1−δ¯)]) (1−β)δ¯
Since ǫ is arbitrary,the desired result follows. ⋄
Note that as m→∞ the error term presented in Theorem 5.2 goes to zero.
6 Sliding memory periodic information sharing pattern and its near
optimality for K-periodic sharing problems under predictor sta-
bility
When attempting to learn the optimal solutions for the K-step periodic information sharing problem (9,10)
an issue arises due to the expanding size of the common information. In this section, we address this issue
byobtainingaperformanceboundonfinite slidingwindowofinformation. The performanceboundisfound
in terms of predictor stability which will be established in section 6.1.
We first obtain a useful supporting result. This parallels the alternative finite memory belief-MDP con-
structionin[19,Section3],whichwillthenallowustoestablisherrorboundsonslidingwindowinformation
sharing pattern.
25Theorem 6.1 Let Zˆ = (π ,IM) where IM = {y[1,N] ,a }. then, (Zˆ ,a ) forms a
q q−M q q [(q−M)K,qK−1] [(q−M),q−1] q q
controlled MDP which is equivalent to (13) under an appropriate choice of the cost criteria.
Here we endow actions with the topology introduced in Definition 3.2, probability measures with the weak
topology, and measurements with the standard topology of the measurement spaces.
Proof. We first note that
π = G(π
,u[1,N] ,y[1,N]
)
q+1−M q−M [(q−M)K,(q−M)K+K−1] [(q−M)K,(q−M)K+K−1]
=: G˜(π ,IM)
q−M q
Here, π can be expressed as just a function of (π ,IM) because the measurements needed for the
q+1−M q−M q
update are contained in IM. Additionally, because we take the map-valued actions to be deterministic,
q
u[1,N] can be generated using a which is also included in IM. It then follows that
[(q−M)K,(q−M)K+K−1] q−M q
P((π ,IM )∈.|π ,IM,a s≤q) = χ χ
q+1−M q+1 s−M s s {G˜(πq−M,I qM)∈.} {y [[ (1 q,N −M] +1)K,qK+K−1],a [q+1−M,q]}
P(dy[1,N] |π ,IM,a s≤q)
[qK,qK+K−1] q−M s s
Where,
P(dy[1,N] |π ,IM,a s≤q) = P(dy[1,N] |X ,a )P(dx |π ,IM,a s≤q)
[qK,qK+K−1] q−M s q [qK,qK+K−1] qK q qK q−M s q
Z
[1,N]
= P(dy |X ,a )π (dx )
[qK,qK+K−1] qK q q qK
Z
Here the last equality follows since, given {π ,IM,a }, one can perform Bayesianupdates to obtain π .
q−M q q q
Thus, we get
P(Zˆ ∈.|Zˆ ,a s≤q)=θ˜(Zˆ ∈.|Zˆ ,a )
q+1 s s q+1 q q
Additionally by considering,
r(Zˆ ,a )=c˜(φ(Zˆ ),a )
q q q q
where φ maps Zˆ to π throughrecursiveBayesianupdates, one obtainsthe desiredcostequivalence. ⋄Note
q q
that one can also express the cost r(Zˆ ,a ) as follows
q q
t=(q+1)K−1 N
r(Zˆ q,a q)= Pπq−M(dx qK|I qM) βt−qK( Qi(dy qi K|x qK)f qi K(dui qK|y qi K))τ(dx qK+1|x qK,u qK)
Z Z t=q i=1
X Y
N
...τ(dx |x ,u )( Qi(dyi|x )fi(dui|yi ,ui ))c(x ,u )]
t t−1 t−1 t t−1 t t [qK,qK+r] [qK,qK+r−1] t t
i=1
Y
wherePπq−M(dx qK|I qM)istheprobabilityinducedonx
qK
givenI qM andthefactthatthefilterattimeq−M
is given by π . In what follows, we will also use the notation π (π
,y[1,N] ,u[1,N]
)
q−M q q−M [(q−M)K,qK−1] [(q−M)K,qK−1]
to denote Pπq−M(dx qK|I qM). This result, similar to [19], motivates the following information structure:
Definition 6.1 The Sliding Memory periodic information sharing pattern consists of the following in-
formation structure: each Agent i at time t = qK + r has access to the common information: IC =
t
{ y[1,N] ,u[1,N] } in addition to the private information {yi ,ui }.
[(q−M)K,qK−1] [(q−M)K,qK−1] [qK,qK+r] [qK,qK+r−1]
The following is a critical supporting result.
Lemma 6.1 Let µ = P(dy | π ,IM,a ), and ν = P(dy | π∗,IM,a ) for some
[qK,qK+K−1] q−M q q [qK,qK+K−1] q q
fixed π∗ ∈P(X) such that π ≪π∗. Then, ||µ−ν|| ≤||π −π∗|| .
q−M TV q−M TV
Remark 6.1 Notethat iftheinitial distribution on x is absolutely continuouswith respecttosomemeasure
0
ζ thenthepredictor at alltimestages will beabsolutely continuouswithrespect toζ. Hence, π∗ can bechosen
withoutanyknowledge ofthetruepredictorbysimplychoosingπ∗ sothatζ ≪π∗. This willhaveimplications
for the near optimality of the sliding memory periodic information sharing pattern.
26Proof. Let f be a measurable function such that ||f|| ≤1.
∞
| fdµ− fdν| = | fP(dy[1,N] |x ,a )π (dx )− fP(dy[1,N] |x ,a )π∗(dx )|
[qK,qK+K−1] qK q q qK [qK,qK+K−1] qK q q qK
Z Z Z Z
= | π (dx ) fP(dy[1,N] |x ,a )− π∗(dx ) fP(dy[1,N] |x ,a )|
q qK [qK,qK+K−1] qK q q qK [qK,qK+K−1] qK q
Z Z Z Z
≤ ||π −π∗||
q q TV
Here, π∗ denotes the updated predictor when π∗ is used as the predictor of the state at time (q−M)K.
q
Assumption 6.1 The transition kernel θ˜is weak-Feller.
Theorem 6.2 Under assumption 6.1, any K-step periodic information sharing pattern can be approximated
by a sliding memory periodic information sharing pattern problem assuming the following predictor stability
condition holds:
L =supEγ[kπ (π,y[1,N] ,u[1,N] )−π (π∗,y[1,N] ,u[1,N] )k ]→0
q π q [(q−M)K,qK−1] [(q−M)K,qK−1] q [(q−M)K,qK−1] [(q−M)K,qK−1] TV
γ
(15)
as M →∞ for all q.
Proof. Let (Zˆ∗,a ) = ((π∗,IM),a ) be an approximation of (Zˆ ,a ) that always uses π∗ as the predictor.
q q q q q q
Here, again, π∗ ∈ P(X) and at any time stage q we have that the predictor for (Zˆ ,a ) : π ≪ π∗. We
q q q−M
denote the kernel of (Zˆ∗,a ) by θˆ. Additionally, we endow the latter with the same cost functional r and
q q
we denote its optimalcostcriteriawith initializationZˆ∗ =(π∗,IM) asJ (Zˆ∗). Additionally,we denote the
0 W
cost criteria for (Zˆ ,a ) with initialization Zˆ =(π,IM) by J(Zˆ). Note that here it is assumed that at time
q q 0
q = 0 the coordinators in both problems have access to the last MK measurement and actions in the form
of IM as well there respective predictors for the state at time t=−MK. Let β˜=βK. We write
0
J(Zˆ) = minr(Zˆ,a)+β˜ Jθ˜(Zˆ |Zˆ,a)
1
a
Z
J (Zˆ∗) = minr(Zˆ∗,a)+β˜ J θˆ(Zˆ |(π∗),IM,a)
W W 1 0
a
Z
Then,
|J −J |≤max|r(Zˆ,a)−r(Zˆ∗,a)|+β˜max|E[J |(π∗),IM,a]−E[J |(π),IM,a]|+
W W 0 W 0
a a
β˜max|E[J |(π),IM,a]−E[J|π,IM,a]|
W 0 0
a
We have that for all a
t=K−1 N
|r(Zˆ,a)−r(Zˆ∗,a)|=| Pπ(dx |IM) βt( Qi(dyi|x )fi(dui|yi))τ(dx |x ,u )...
0 0 0 0 0 0 0 1 0 0
Z Z t=0 i=1
X Y
N
τ(dx |x ,u )( Qi(dyi|x )fi(dui|yi ,ui ))c(x ,u )]− Pπ∗ (dx |IM)
t t−1 t−1 t t−1 t t [0,r] [0,r−1] t t 0 0
i=1 Z
Y
t=K−1 N
βt( Qi(dyi|x )fi(dui|yi))τ(dx |x ,u )...τ(dx |x ,u )
0 0 0 0 0 1 0 0 t t−1 t−1
Z t=0 i=1
X Y
N
( Qi(dyi|x )fi(dui|yi ,ui ))c(x ,u )]|≤Kkck kPπ(dx |IM)−Pπ∗ (dx |IM)k
t t−1 t t [0,r] [0,r−1] t t ∞ 0 0 0 0 TV
i=1
Y
=:Kkck kπ
(π,y[1,N] ,u[1,N]
)−π
(π∗,y[1,N] ,u[1,N]
)k
∞ 0 [−MK,−1] [−MK,−1] 0 [−MK,−1] [−MK,−1] TV
Similarly, we have that
|E[J |(π∗),IM,a]−E[J |(π),IM,a]|≤kJ k kP(dy |π∗,IM,a)−P(dy |π,IM,a)k
W 0 W 0 W ∞ [0,K−1] 0 [0,K−1] 0 TV
27Kkck
≤
∞
kπ
(π,y[1,N] ,u[1,N]
)−π
(π∗,y[1,N] ,u[1,N]
)k
1−β˜ 0 [−MK,−1] [−MK,−1] 0 [−MK,−1] [−MK,−1] TV
where the last inequality follows by lemma 6.1. Moreover,note that
|E[J |π,IM,a]−E[J|π,IM,a]|≤E[|J (Zˆ∗)−J(Zˆ )||π,IM,a]
W 0 0 W 1 1 0
Thus we get that
β˜Kkck
|J −J |≤L (Kkck + ∞ )+β˜maxE[|J (Zˆ∗)−J(Zˆ )||π,IM,a]
W 0 ∞ 1−β˜ a W 1 1 0
∞
Kkck
∞
≤ L
1−β˜ q
q=0
X
Where the last inequality follows by repeating the same process. ⋄
6.1 Predictor stability under expected total variation
Inthissection,weestablishexponentialpredictorstabilityinexpectedtotalvariationfortheone-stepdelayed
problemandtheK-stepperiodicproblemusingDobrushincoefficients. Asimilarresulthasbeenestablished
for centralized POMDPs in [32]. Both predictor and filter stability play an important role in establishing
robustnesstoanincorrectlydesignedpolicy[20]. Inparticular,itplaysacrucialroleinestablishingthenear
optimality of finite window policy for POMDPs [19]. Similarly, as was seen in section 6 predictor stability
for decentralizedproblems playsa crucialrolein demonstratingthe nearoptimality ofpolicies for whichthe
common information consists of a sliding window of information.
6.2 Predictor stability for the one-step delayed problem
Theorem 6.3 Consider a true prior µ and a false prior ν with µ≪ν. Then, the predictor is exponentially
stable in total variation in expectation if the following holds:
(2−δ(Q))(1−δ˜(τ))<1
where, Q(.|x )=P(y[1,N] ∈.|x ), δ(Q) is the Dobrushin coefficient of the kernel Q, and δ˜(τ) is the infimum
t t t
of the Dobrushin coefficient of the kernel τ(.|.,u) where the infimum is taken over all actions.
The following lemma will be useful in proving Theorem (6.3).
Lemma 6.2 Consider a true prior µ and a false prior ν with µ≪ν. Let F˜ denote the update equation for
the filter process {π˜ } where π˜ =P(x
|y[1,N],u[1,N]
) Then, the following holds:
t t t [0,t] [0,t−1]
Eµ[kF(µ,u ,y[1,N])−F(ν,u ,y[1,N])k ]≤(2−δ(Q))kµ−νk (16)
t t t t TV TV
Additionally,
Eµ[kF˜(µ,u ,y[1,N] )−F˜(ν,u ,y[1,N] )k ]≤(2−δ(Q))kµ−νk (17)
t t t t TV TV
Proof. Let
N
α = µ(dx ) h(x ,yi)
µ t t t
Z i=1
Y
N
α = ν(dx ) h(x ,yi)
ν t t t
Z i=1
Y
kF(µ,u ,y[1,N])−F(ν,u ,y[1,N])k =
t t t t TV
fτ(dx |x ,u[1,N])µ(dx ) N h(x ,yi) fτ(dx |x ,u[1,N])ν(dx ) N h(x ,yi)
sup | t+1 t t t i=1 t t − t+1 t t t i=1 t t |
α α
kfk∞≤1 R µ Q R ν Q
28≤T +T
1 2
Where,
fτ(dx |x ,u[1,N])µ(dx ) N h(x ,yi) fτ(dx |x ,u[1,N])ν(dx ) N h(x ,yi)
T = sup | t+1 t t t i=1 t t − t+1 t t t i=1 t t |
1
α α
kfk∞≤1 R µ Q R µ Q
and
N
α −α
T = sup | ν µ || fτ(dx |x ,u[1,N] )ν(dx ) h(x ,yi)|
2 α α t+1 t t t t t
kfk∞≤1 ν µ Z i=1
Y
Next, we consider the expectation of T and T separately.
1 2
f(x )τ(dx |x ,u[1,N])µ(dx ) N h(x ,yi)
Eµ[T ]= sup | t+1 t+1 t t t i=1 t t −
1
α
Z kfk∞≤1 R µ Q
f(x )τ(dx |x ,u[1,N])ν(dx ) N h(x ,yi) n n
t+1 t+1 t t t i=1 t t | h(x ,yi) ψ(dyi)µ(dx )
α t t t t
R µ Q i=1 i=1
Y Y
N
= sup | f(x )τ(dx |x ,u[1,N])µ(dx ) h(x ,yi)−
t+1 t+1 t t t t t
Z kfk∞≤1 Z i=1
Y
N n
f(x )τ(dx |x ,u[1,N])ν(dx ) h(x ,yi)| ψ(dyi)
t+1 t+1 t t t t t t
Z i=1 i=1
Y Y
≤kQ(µ,y)−Q(ν,y)k ≤(1−δ(Q))kµ−νk
TV TV
N n n
α −α
Eµ[T ]= sup | ν µ || fτ(dx |x ,u[1,N])ν(dx ) h(x ,yi)| h(x ,yi) ψ(dyi)µ(dx )
2 α α t+1 t t t t t t t t t
Z kfk∞≤1 ν µ Z i=1 i=1 i=1
Y Y Y
N n
α −α
= sup | ν µ || fτ(dx |x ,u[1,N])ν(dx ) h(x ,yi)| ψ(dyi)
α t+1 t t t t t t
Z kfk∞≤1 ν Z i=1 i=1
Y Y
N n
α −α
≤ sup | ν µ | ν(dx ) h(x ,yi) |f|τ(dx |x ,u[1,N]) ψ(dyi)
α t t t t+1 t t t
Z kfk∞≤1 ν Z i=1 Z i=1
Y Y
≤|α −α |≤kµ−νk
µ ν TV
It is easy to check that the update equation for the filter process is given by
τ(dx |x ,u )π˜ (dx ) N h(x ,yi )
π˜ (A)= t+1 t t t t i=1 t+1 t+1
t+1 ZA Xτ(dx t+1|x t,u t)π˜ t(dx tQ) N i=1h(x t+1,y ti +1)
Hence, the proof for inequality (17) pRroceeds in a similar manQner to that of (16).
⋄
Proof of Theorem 6.3.
Note that the expression Eµ[kπµ −πν k ] is similar to that in (16) with πµ and πν serving as the true
t+1 t+1 TV t t
and false priors respectively. It hence, follows by Lemma 6.2 that
Eµ[kπµ −πν k ]≤(2−δ(Q))kπµ−πνk
t+1 t+1 TV t t TV
It follows from the third equality in equation (7) that
kπµ −πν k =kτ(π˜µ)−τ(π˜ν)k
t+1 t+1 TV t t TV
Hence, we get
Eµ[kπµ −πν k ] ≤ (1−δ˜(τ))Eµ[kπ˜µ−π˜νk ]
t+1 t+1 TV t t TV
≤ (1−δ˜(τ))(2−δ(Q))kπ˜µ −π˜ν k
t−1 t−1 TV
⋄
Remark: It is important to note that the previous inequality is independent of policy hence we obtain a
bound that is uniform over all policies.
296.3 Predictor stability for the K-periodic information sharing pattern problem
Theorem 6.4 Consideratruepriorµandafalsepriorν withµ≪ν. Then,thepredictorfortheK-periodic
sharing pattern theorem is exponentially stable in total variation in expectation if the following holds:
(2−δ(Q))(1−δ˜(τ))<1
Proof. Since the predictor update for the K-periodic problem is obtained by applying the Bayesianupdate
for the one step delayed problem K-times, the desired result follows from a direct application of Theorem
6.3.
⋄
Note thathereonceagain,the boundobtainedisindependent ofpolicy thusallowingus toobtainauniform
bound for L as defined in (15).
q
7 Q-learning: Convergence and Near Optimality
Given the regularity results obtained earlier, in this section we provide and execute a learning algorithm,
building on [18] for weak Feller MDPs. A related learning algorithm has been studied in [14] where the
authors provide a MARL (Multi-agent reinforcement learning) algorithm for the case where the agents all
have finite memory and policies are restricted to a parametric class which may not include all admissible
policies. The authors show that the algorithm converges in finite time and numerically demonstrated its
performance. In our paper, we rigorously establish convergence to near optimality and we allow for much
more general setups.
7.1 Description of the quantization procedure and the Q-learning algorithm
Suppose for some n ∈ N we quantize the space of predictors P(X) into multiple bins B ,...,B such that
1 m
1
sup W (π,π )≤ for all i∈{1,...,m}. Where, π represents the center of the bin B . Additionally,
1 i i i
n
π∈Bi
with m B = P(X), we apply policies that are constant over each bin. When the MDP transitions to a
i=1 i
new state, it is approximated by the center of the bin to which it is the closest.
S
Assumption 7.1 For all (π,a) and for all k ≥1, we have
i α (π,a)=0 unless (π,a)=(π ,a ).
k k k
1
ii α (π,a)=
k k
1+ χ
l=0 (πl,al)=(π,a)
Consider the folloPwing Q-learning algorithms
Algorithm 1: Quantized Q-learning
Arbitrarily initialize Q
0
Initialize π ∼ν
0
for t=0,1,...,T
Generate an action according to the exploration policy γ: a ∼γ(.|π )
t t
Generate the next state: π ∼θ(.|π ,a )
t+1 t t
Quantize the state: π = argmin kπ −B k
t+1 t+1 m
{π∈{B1,...,Bm}}
for all (π,a)
if (π,a)=(π ,a )
t t
Q (π,a)=(1− α (π,a))Q (π,a)+α (π,a) c˜(π,a)+β˜minQ (π ,v)
t+1 t t t t t+1
v
(cid:16) (cid:17)
else Q (π,a)=Q (π,a)
t+1 t+1
end
30end
return Q .
T
7.2 Convergence of the quantized Q-learning algorithm
Assumption 7.2 The state space X is compact. Additionally, c(x,u) is continuous and bounded. Further-
more, the kernel is weakly continuous.
Assumption 7.3 Assume that the exploration policy induces a unique invariant probability measure and
that the initialization ν is in the support of the invariant probability measure.
Theorem 7.1 Consider the MDP (π ,a ). Then, under assumption 7.2 and 7.3, Quantized Q-learning de-
t t
scribed in Algorithm 1 converges almost surely asymptotically to Q∗ such that minQ∗ is a near optimal value
a
functionas thestepsizeofthequantization(n)becomessufficientlylarge. Additionally, anearoptimal policy
can be obtained by argminQ∗.
a
Proof.: Since the state space, and the action space are compact, c˜is continuous and bounded, and θ is
weakly continuous,it follows from( [18]Theorem7)and( [17] Theorem4.3), thatthe Q-learningalgorithm
described above converges asymptotically to an optimal solution.
Remark 7.1 It is important to note that choice of the initialization in Algorithm 1 has a significant impact
on the convergence of the Q-learning algorithm. This is because convergence is only guaranteed for the
quantized states that are visited infinitely often under the exploration policy. A sufficient condition for the
Q-learning to converge for all the states visited during the Q-learning process is that the initialization ν be
within the support of the invariant probability measure induced by the exploration policy and that all the
bin boundaries have measure zero under the invariant probability measure (see for example Theorem 5.1
in [38]). An important benefit of the sliding window approximation introduced in section 6 is that apriori
knowledge of the support of the invariant probability measure induced by the exploration policy is not needed
to determine an appropriate initialization as long as under such policy all possible values of measurements
occur infinitely often in the case where the measurement spaces are finite. For the more general case, because
the measurements now act as the state, one can follow the state quantization procedure described in [18] as
long as the measurement spaces are compact.
7.3 Example
0.5 0.5
Consider X={0,1,2},U1 =U2 =Y1 =Y2 ={0,1}. Q1 =Q2 = 0 1 .
 
0 1
0 0.5 0.5  
If u1 6=u2, then τ =[111]. If u1 =u2, then τ = 0.5 0 0.5 . c(x,u ,u )=(x−u −u )2+u2+u2.
t t 333 t t   1 2 1 2 1 2
0.5 0.5 0
β =0.01 and K =2.  
7.3.1 Results
Here we provide a table that shows some of the bin centers used to quantize the predictor, the optimal cost
derivedthroughQ-learning,the optimalcost derivedthroughempiricalvalue iteration[39], andthe average
cost obtained by applying the optimal policy derived from the Q matrix for 100000simulations. For a PAC
performance bound of empirical value iteration based on sample size and number of iterations see [39].
Remark 7.2 It is important to note that a significant challenge, when implementing Q-learning for the
K-step periodic information sharing pattern, is that the dimension of the action space is very large. In fact,
N
even in the simple case when K =2, we get that the dimension of the action space is
|Ui||Yi|2+|Yi|.
This
i=1
Y
is a computationally demanding problem even when all the parameters of the original problem are relatively
simple.
31Bin Center J∗ J∗ J∗
Sim Q EVI
[0.4 0.1 0.5] 2.1188 2.1835 2.1835
[0.41176 0.23529 0.35294] 2.0676 2.037 2.037
[0.41667 0.25 0.33333] 2.0169 2.0176 2.0176
[0.42105 0.21053 0.36842] 2.1195 2.0528 2.0528
[0.42105 0.26316 0.31579] 1.9679 2.0002 2.0002
[0.42857 0.21429 0.35714] 2.0956 2.0419 2.0419
[0.42857 0.2381 0.33333] 2.0123 2.0181 2.0181
[0.4375 0.4375 0.125] 1.5825 1.6565 1.6565
8 Conclusion
In this paper, we studied decentralized stochastic control problems with standard Borel spaces under three
informationstructures: Completelydecentralizedinformationstructure,one-stepdelayedinformationstruc-
ture, and K-periodic sharing information structure. For the one step delayed pattern and the K-periodic
pattern we showedthat they admit a centralizedMDP reduction. Then, we showed that under some condi-
tionsthetransitionkernel,fortheMDPreductionresultingfrombothinformationstructures,isweak-Feller.
Then, we proved finite memory policies are near optimal for all information structures. For the completely
decentralized problem this was done through approximation with the K-periodic problem. For the latter,
we also provideda bound in lossof optimality that occurswhen the actionspace is reduced. Finally, for the
one-step and K-periodic problems, we proved the asymptotic convergence of quantized Q-learning to near
optimalsolutionsas the stepsize ofthe quantizationincreases,andwe demonstratedhow the algorithmcan
be employed through an example.
References
[1] D. S. Bernstein, R. Givan, N. Immerman, and S. Zilberstein, “The complexity of decentralized control
of markov decision processes,” Mathematics of operations research, vol. 27, no. 4, pp. 819–840,2002.
[2] H. S. Witsenhausen, “Separation of estimation and control for discrete time systems,” Proceedings of
the IEEE, vol. 59, pp. 1557–1566,1971.
[3] H.S.Witsenhausen, “A counterexample in stochastic optimum control,” SIAM J. Control, 1968.
[4] S.YükselandT.Başar,Stochastic Teams, Games, andControl underInformation Constraints. Cham:
Springer, 2024.
[5] A.A.Malikopoulos,“Onteamdecisionproblemswithnonclassicalinformationstructures,” IEEETrans-
actions on Automatic Control, vol. 68, no. 7, pp. 3915–3930,2022.
[6] T.Yoshikawa,“Dynamicprogrammingapproachtodecentralizedcontrolproblems,” IEEE Transactions
on Automatic Control, vol. 20, pp. 796–797,1975.
[7] P. Varaiya and J. Walrand, “On delayed-sharing patterns,” IEEE Transactions on Automatic Control,
vol. 23, pp. 443–445,June 1978.
[8] J. Ooi, S. Verbout, J. Ludwig, and G. Wornell, “A separation theorem for periodic sharing information
patterns in decentralized control,” IEEE Transactions on Automatic Control, vol. 42, pp. 1546–1550,
November 1997.
[9] S. Yüksel, “Stochastic nestedness and the belief sharing information pattern,” IEEE Transactions on
Automatic Control, vol. 54, pp. 2773–2786,December 2009.
[10] B. Kurtaran, “Corrections and extensions to decentralized control with delayed sharing information
pattern,” IEEE Transactions on Automatic Control, vol. 24, pp. 656–657,August 1979.
[11] A. Nayyar,A. Mahajan, and D. Teneketzis, “Decentralizedstochastic control with partial history shar-
ing: A common information approach,” IEEE Transactions on Automatic Control, vol. 58, pp. 1644–
1658, 2013.
[12] ——,“Thecommon-informationapproachtodecentralizedstochasticcontrol,” inInformationandCon-
trol in Networks, Editors: G. Como, B. Bernhardsson, A. Rantzer. Springer, 2013.
32[13] N. Saldi, “Common information approach for static team problems with polish spaces and existence of
optimal policies,” arXiv preprint arXiv:2309.07571, 2023.
[14] W. Mao, K. Zhang, Z. Yang, and T. Başar, “Decentralized learning of finite-memory policies in dec-
pomdps,” IFAC-PapersOnLine, vol. 56, no. 2, pp. 2601–2607,2023.
[15] A.Kara,N.Saldi,andS.Yüksel,“WeakFellerpropertyofnon-linearfilters,” Systems&ControlLetters,
vol. 134, pp. 104–512,2019.
[16] N. Saldi, S. Yüksel, and T. Linder, “On the asymptotic optimality of finite approximations to Markov
decision processeswith Borelspaces,” Mathematics of Operations Research, vol.42, no. 4, pp. 945–978,
2017.
[17] N. Saldi, T. Linder, and S. Yüksel, Finite Approximations in Discrete-Time Stochastic Control: Quan-
tized Models and Asymptotic Optimality. Cham: Springer, 2018.
[18] A. Kara, N. Saldi, and S. Yüksel, “Q-learning for MDPs with general spaces: Convergence and near
optimality via quantization under weak continuity,” Journal of Machine Learning Research, 2023, pp.
1–34, 2023.
[19] A. Kara and S. Yüksel, “Convergence of finite memory Q-learning for POMDPs and near optimal-
ity of learned policies under filter stability,” Mathematics of Operations Research, vol. 48, no. 4, p.
2066âĂŞ2093,2023.
[20] C.McDonald and S.Yüksel, “Robustness to incorrect priors and controlled filter stability in partially
observed stochastic control,” SIAM J. on Control and Optimization, 2022.
[21] O. Hernández-Lerma and J. B. Lasserre, Discrete-Time Markov Control Processes: Basic Optimality
Criteria. Springer, 1996.
[22] V. S. Borkar, “White-noise representations in stochastic realization theory,” SIAM J. on Control and
Optimization, vol. 31, pp. 1093–1102,1993.
[23] S. Yüksel, “On Borkar and Young relaxed control topologies and continuous dependence of invariant
measuresoncontrolpolicy,” SIAM Journal on Control and Optimization, vol.62,no.4, pp. 2367–2386,
2024.
[24] S. N. Ethier and T. G. Kurtz, Markov Processes: Characterization and Convergence. John Wiley &
Sons, 2009, vol. 282.
[25] L.D.Branges,“Thestoneweierstrasstheorem,” Proceedings of theAmerican Mathematical Society,1959.
[26] V. S. Borkar, “White-noise representations in stochastic realization theory,” SIAM J. Control Optim.,
vol. 31, no. 5, pp. 1093–1102,1993.
[27] W. Rudin, Real and Complex Analysis, 3rd ed. New York: McGraw-Hill, 1987.
[28] L. Dubins and D. Freedman, “Measurable sets of measures,” Pacific J. Math., vol. 14, pp. 1211–1222,
1964.
[29] K.Gowrisankaran, “Measurability of functions in product spaces,” Proceedings of the American Mathe-
matical Society, 1972.
[30] G.W.Mackey, “Induced representations of locally compact groups i,” Annals of Mathematics, 1952.
[31] Z. Grande, “Deux exemples de fonctions non mesurables,” Colloquim Mathematicum, 1979.
[32] C. McDonald and S. Yüksel, “Exponential filter stability via Dobrushin’s coefficient,” Electronic Com-
munications in Probability, vol. 25, 2020.
[33] S. Yüksel, Optimization and control of stochastic systems. Queen’s University, 2024. [Online].
Available: https://mast.queensu.ca/~yuksel/LectureNotesOnStochasticOptControl.pdf
[34] D. Blackwell and C. Ryll-Nadrzewski, “Non-existence of everywhere proper conditional distributions,”
Annals of Mathematical Statistics, vol. 34, pp. 223–225,1963.
[35] A. Yushkevich, “Reduction of a controlled Markov model with incomplete data to a problem with
complete information in the case of Borel state and control spaces,” Theory Prob. Appl., vol. 21, pp.
153–158,1976.
33[36] D.Rhenius,“IncompleteinformationinMarkoviandecisionmodels,” Ann.Statist.,vol.2,pp.1327–1334,
1974.
[37] P. Billingsley, Probability and Measure. New York: Wiley, 1995.
[38] L.Cregg, F.Alajaji, and S.Yüksel, “Reinforcement learning for optimal transmission of markov sources:
Belief quantization vs sliding finite window codes,” arXiv preprint arXiv:2310.06742, 2024.
[39] R. W.B. Haskell and D.Kalathil, “Empirical value iteration for approximate dynamic programming,”
American Control Conference (ACC), 2014.
34