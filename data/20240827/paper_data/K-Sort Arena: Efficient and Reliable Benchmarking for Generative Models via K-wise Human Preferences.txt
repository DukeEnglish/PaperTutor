K-Sort Arena: Efficient and Reliable Benchmarking for Generative Models via
K-wise Human Preferences
ZhikaiLi1,*,XuewenLiu1,∗,DongrongFu2,JianquanLi1,QingyiGu1,†,KurtKeutzer2,ZhenDong2,†
1InstituteofAutomation,ChineseAcademyofSciences 2UniversityofCalifornia,Berkeley
lizhikai2020@ia.ac.cn, zhendong@berkeley.edu
Project:https://huggingface.co/spaces/ksort/K-Sort-Arena
Abstract Chatbot Arena K‐Sort Arena
(Texts) (Images or Videos)
The rapid advancementof visual generative models ne- One-on-One Free-for-All
cessitatesefficientandreliableevaluationmethods. Arena A B
platform, whichgathersuservotesonmodelcomparisons, A B
C D
can rank models with human preferences. However, tradi-
tionalArenamethods, whileestablished, requireanexces-
A>B A>C>B>D
sive number of comparisons for ranking to converge and
arevulnerabletopreferencenoiseinvoting,suggestingthe
Figure1. ComparisonbetweenK-SortArenaandChatbotArena
needforbetterapproachestailoredtocontemporaryevalu-
[10]. K-Sort Arena employs K-wise comparisons (K>2) to get
ationchallenges. Inthispaper,weintroduceK-SortArena,
richerinformationfromuservotes. Notably,itintroducesproba-
an efficient and reliable platform based on a key insight:
bilistic modeling and an effective matchmaking strategy, signifi-
images and videos possess higher perceptual intuitiveness cantlyimprovingefficiencyandreliability.
than texts, enabling rapid evaluation of multiple samples
simultaneously. Consequently, K-Sort Arena employs K-
wisecomparisons,allowingKmodelstoengageinfree-for- 53]andtext-to-video[11,13,16,54]generation.Suchgreat
allcompetitions,whichyieldmuchricherinformationthan progress has attracted more and more researchers, leading
pairwisecomparisons.Toenhancetherobustnessofthesys- toacontinuousproliferationofnewmodels. Therefore,an
tem, we leverage probabilistic modeling and Bayesian up- efficientandreliableevaluationofthemodels’capabilities
datingtechniques. Weproposeanexploration-exploitation- isurgentlydesired.However,traditionalevaluationmetrics,
based matchmaking strategy to facilitate more informative suchasIS[44],FID[19],FVD[48],etc.,fallshortinpro-
comparisons. In our experiments, K-Sort Arena exhibits viding a fair and comprehensive evaluation, especially not
16.3×fasterconvergencecomparedtothewidelyusedELO reflectinghumanpreferencesintherealworld.
algorithm. Tofurthervalidatethesuperiorityandobtaina Tothisend,ChatbotArena[10]isproposedasaplatform
comprehensiveleaderboard,wecollecthumanfeedbackvia developedforevaluatinglargelanguagemodels(LLMs). It
crowdsourced evaluations of numerous cutting-edge text- constructs randomized, anonymous pairwise comparisons
to-image and text-to-video models. Thanks to its high ef- of models and collects user judgments of their outputs,
ficiency,K-SortArenacancontinuouslyincorporateemerg- therebyforminganoverallrankingofmodels’capabilities.
ingmodelsandupdatetheleaderboardwithminimalvotes. Despite the great progress, Chatbot Arena still faces chal-
Ourprojecthasundergoneseveralmonthsofinternaltest- lenges regarding efficiency and accuracy: (i) The ineffi-
ingandisnowavailableatK-SortArena. ciencyofChatbotArenastemsprimarilyfromtwoinherent
mechanisms:pairwisecomparisonsandrandomizedmatch-
ing. Byallowingonlytwomodelstobecomparedatatime
1.Introduction and potentially matching models of vastly different ranks,
the system often yields minimal information per compar-
Visual generation models have made significant advance-
ison. This inefficiency necessitates an excessive number
ments, excelling in tasks such as text-to-image [5, 40, 43,
of comparisons to achieve a stable ranking, resulting in a
significantwasteofvaluablehumaneffortinvoting. More
*EqualContribution
†CorrespondingAuthor importantly, as a massive number of new models contin-
1
4202
guA
62
]IA.sc[
1v86441.8042:viXraStep 1: Probabilistic modeling Step 2: Exploration-exploitation based matchmaking
Skill uncertainty Specify pivot model Select K-1 opponents
Exploitation
Balanced
- + &
participation
Exploration
Prefe 𝜇𝜇re𝑖𝑖n 3c 𝜎𝜎e𝑖𝑖 noise 𝜇𝜇𝑖𝑖 𝜇𝜇𝑖𝑖 3𝜎𝜎𝑖𝑖
Step 5: Leaderboard Step 4: Bayesian updating Step 3: K-groupwise comparison
Conservative score
Free-for-all
（anonymous）
Estimation bias
… - + Uncertainty User voting A>C>B>D
1 2 3
𝜇𝜇�𝑖𝑖 3𝜎𝜎�𝑖𝑖 𝜇𝜇�𝑖𝑖 𝜇𝜇�𝑖𝑖 3𝜎𝜎�𝑖𝑖
𝑁𝑁
Figure 2. Overview of the proposed K-Sort Arena. K-wise comparisons (K>2) and the advanced matching strategy can significantly
accelerate ranking convergence, achieving stable ranking with minimal user votes. Probabilistic modeling and Bayesian updating can
enhancetherobustnessofmodelcapabilityrepresentation,thusresultingingreaterefficiencyandreliability.
uously emerge, this inefficiency prevents the rapid evalu- the ELO system in Chatbot Arena and exhibits greater ro-
ation of new models’ capabilities and the timely updating bustnesstopreferencenoise.Ononehand,itcanupdatethe
of the leaderboard, causing a lagged response to the latest leaderboard accurately and quickly with a minimum num-
advances. (ii) In user voting, preference noise and subjec- berofvotes,whichcaneffectivelycopewithmodelprolif-
tivebiasareinherent, leadingtooccasionalunjustifiedrat- eration; on theother hand, it is morestable andreliable in
ings.Pairwisecomparisonsaresensitivetothisissue,which long-term evaluations, obtaining more trustworthy evalua-
could introduce bias into the relative rankings. This is es- tionswiththesamenumberofvotes.
pecially problematic when the leaderboard is updated fre-
K-Sort Arena has served to evaluate dozens of state-
quentlyandthenumberofvotesissmall.
of-the-artvisualgenerationmodels,includingbothtext-to-
To address the above issues, we propose K-Sort Arena,
imageandtext-to-videomodels. Bystatisticallyorganizing
anovelbenchmarkingplatformforvisualgenerationmod-
userfeedbackfromcrowdsourcedquestions,K-SortArena
els. K-Sort Arena offers better efficiency and reliabil-
effectively builds comprehensive model leaderboards. To
ity. Specifically, K-Sort Arena employs K-wise compar-
aptly reflect the diverse real-world applications, users are
isons (K>2), allowing K models to participate in free-for-
freetochoosepromptssampledfromopen-sourcedatasets
allbattles,whichprovidesgreaterinformationbenefitsthan
or to create fresh prompts. Moreover, K-Sort Arena sup-
pairwise comparisons, as shown in Figure 1. This ap-
ports multiple voting modes and user interactions. Users
proachisbasedonapracticalbiologicalprinciple: images
caneitherselectthebestoutputfromafree-for-allcompar-
and videos have higher perceptual intuitiveness compared
isonorranktheKoutputsinstead. Thisflexibilityensuresa
to texts, enabling rapid evaluation of multiple samples at
faster,moreuser-friendly,andversatileevaluationprocess.
once. To ensure the robustness of ranking, we introduce
Overall,ourcontributionscanbesummarizedasfollows:
probabilistic modeling of the models’ capabilities, as well
as a Bayesian score updating strategy applied after free- • WeintroduceK-SortArena,anefficientandreliableplat-
for-all battles among K models, which can dilute the ad- formforevaluatingvisualgenerationmodels. Itcancon-
verseeffectsofpreferencenoise. Furthermore,wepropose tinuously monitor new models and quickly update the
anexploration-exploitation-basedmodelmatchingstrategy, leaderboardwithminimalvotes.
which facilitates matchmaking among models with com- • We propose K-wise comparisons to obtain richer feed-
parable strength while also incorporating under-explored backinformationandsavehumaneffortsinevaluation.
models, thereby maximizing the expected benefit of each • We devise an exploration-exploitation-based matchmak-
comparison. TheoverviewispresentedinFigure2. ing strategy with probabilistic capability modeling and
TodemonstratethesuperiorityofK-SortArena,inSec- Bayesianupdatingmechanisms.
tion 4, we design experiments to simulate the scenarios of • Ablation study shows that compared to traditional ELO
model comparisons and user voting. Encouragingly, K- algorithms, K-Sort Arena can achieve 16.3× faster con-
Sort Arena shows 16.3× faster ranking convergence than vergenceandgreaterrobustnessagainstpreferencenoise.
22.RelatedWork two models to continuously calibrate the capability scores
of each model, resulting in an overall ranking of model
2.1.VisualGenerationEvaluation
capabilities. It also inspires WildVision’s efforts to rank
Text-to-Image Benchmarks Various metrics have been vision-language models [36]. However, these Arena algo-
proposed to assess the performance of text-to-image mod- rithms require excessive comparisons to achieve a stable
els [25, 56]. IS [44], FID [19], sFID [44], and KID ranking and are susceptible to preference noise in voting.
[7] calculate the distance between the real and generated As our concurrent work, GenAI Arena [23] replicates the
data distributions using logits or features from Inception- above workflow to visual generative models and thus has
Net [47]. CLIPScore [18] computes the cosine similarity thesameissues. Consequently, thecoverageoftheleader-
between two embeddings from CLIP [41], measuring the boardislimitedtoafewmodels. Incontrast,K-SortArena
alignmentoftextsandimages. Therearealsoseveralvari- capitalizesontheintuitiveadvantageofvisualinformation
ants of CLIPScore, such as AS [46] and HPS [51], which over texts, incorporating more robust modeling methods
aim to enhance evaluation quality. Similarly, BLIPScore and more effective matchmaking strategies, which shows
[6]andImageReward[52]aremetricscalculatedbasedon greatpotentialinlarge-scalemodelevaluations.
BLIP [26]. Beyond traditional metrics, recent works in-
troduce large multimodal models as judgment assistants. 3.Methodology
For instance, T2I-CompBench [21] and X-IQE [9] utilize
In this section, we describe how to perform robust proba-
the Chain of Thought to enable MiniGPT-4 [57] to pro-
bilisticmodelingandBayesianupdatingofmodelcapabil-
duceself-consistentevaluations.VQAScore[33]employsa
ities in free-for-all comparisons of K models, and how to
visual-question-answering(VQA)modeltogeneratealign-
schedulematchestoacceleraterankingconvergence.
mentscoresbycalculatingtheaccuracyofansweringsim-
ple questions. TIFA [20] also uses VQA to measure the 3.1.K-wiseComparison
faithfulnessofgeneratedimagestotextinputs.
ThepairwisecomparisonemployedbyChatbotArenaeval-
Text-to-Video Benchmarks Metrics for assessing text-to-
uatesonlytwomodelsperroundandisinefficient. Incon-
video models have also been broadly investigated [31, 49,
trast, K-Sort Arena evaluates K models (K>2) simultane-
50]. FVD[48]isusedtomeasurethediscrepancybetween
ously,whichnaturallyprovidesmoreinformationandthus
therealandsynthesizedvideos. CLIPSIM[42]isextended
improvestheefficiencyoftheoverallranking. Incoordina-
toevaluatethealignmentoftextsandvideosbymeasuring
tion with K-wise comparisons, the modeling and updating
the similarity of multiple frames with texts. VBench [22]
ofmodelcapabilitiesaredetailedbelow.
and FETV [35] decompose the evaluation of video quality
intomultipledimensionsforfine-grainedevaluation. Eval- Probabilistic Capability Modeling Individual numerical
Crafter [34] selects multiple objective metrics, which are modeling, asintheELOsystem[12], providesonlyacer-
expected to summarize real-world situations, to assess the tainvalueoftheestimateandthuscannotensurereliability.
synthesizedvideoqualityinvariousaspects. Instead, by using probability distributions to represent ca-
pabilities,itispossibletocaptureandquantifytheinherent
Despitethegreatadvances,theabovestaticmetricsstill
uncertainty and hence become more flexible and adaptive.
suffersignificantflawsinexpressinghumanpreferencesin
This idea can be seen in popular ranking systems such as
therealworld. Theycannotprovidecomprehensiveevalu-
Glicko [14] and TrueSkill [17]. Our approach, while in-
ations, especiallyinaspectssuchasvisualaesthetics. Fur-
spired by them, incorporates further improvements to en-
thermore,withtherapidemergenceofdiversetaskssuchas
hanceefficiencyandreliability. Formally,werepresentthe
imageediting[2],imagecaptioning[26],videoediting[38],
capabilityθofeachmodelasanormaldistribution:
video captioning [55], etc., static metrics are increasingly
inadequate in capturing the nuanced performance across
θ ∼N(µ ,σ2) (1)
thesevariedandevolvingdomains. i i i
whereµ andσ denotethei-thmodel’sexpectedscoreand
2.2.ArenaEvaluationwithHumanPreferences i i
uncertainty,respectively. Here,i=1,2,··· ,N,andN are
Toaddressthelimitationsofstaticmetrics,DynaBench[24] thetotalnumberofmodels. Aspreviouslymentioned,user
suggests implementing a live benchmark system that in- votinginevitablyhaspreferencenoise,whichisorthogonal
tegrates a human-in-the-loop approach, thus allowing for to the uncertainty σ of the model’s performance. There-
more dynamic and adaptive evaluation. Building on this fore, we introduce an additional stochastic variable β over
idea,ChatbotArena[10]isdevelopedasaplatformspecif- themodel’scapabilityθsuchthatthemodel’sactualperfor-
ically for LLMs. It constructs model arenas that allow mancejudgedbyhumanevaluationis:
LLMs to make randomized, anonymous pairwise compar-
isons. Usersarerequiredtojudgeandscoretheoutputsof X ∼N(θ ,β2) (2)
i i i
3To build a leaderboard, we use the conservative score where V(x) = ϕ(x)/Φ(x) and c2 = (cid:80)(cid:0) β2+σ2(cid:1) . The
ij i i
[39]toestimatethemodel’scapability,asdefinedbelow: derivation of the above equation is detailed in Appendix
A.2. Here, µˆ is the updated mean µ value. Similarly,
1 1
S(n) =µ(n)−η·σ(n) (3) theupdatingprocessofthevarianceσ2 isgivenbythefol-
i i i 1
lowingequation:
where η is a coefficient with a typical value of 3.0, S(n),
i
µ( in) and σ i(n) are the values after n comparisons and up- σˆ 12 =Var[θ 1|D]=E[θ 12|D]−(E[θ 1|D])2
fd oa lt le os w. F Eo qr .e 9a ac nh du Ep qd .at 1e 0o sf pµ ecj i ifia en dd aσ sij f, oj llo= ws1 .,2,··· ,N, we =σ 12·(cid:32) 1−
(cid:80)
(βσ 212
+σ2)
·W(cid:32) (cid:112)(cid:80)µ 1 (β− 2µ +2 σ2)(cid:33)(cid:33)
Bayesian Capability Updating Based on probabilistic i i i i
modeling, we implement the updating process using =σ2·(cid:18)
1−
σ 12 ·W(cid:18) µ 1−µ 2(cid:19)(cid:19)
Bayesianinferencewithobservedmatchresults. Webegin 1 c2 c
12 12
bydiscussingthecaseoftwomodelsandthengeneralizeto (8)
the free-for-all comparison of K models. Assuming in the whereW(x)=V(x)(V(x)+x).
current comparison there are two models M and M , the TheaboveprocedureaccomplishesBayesianupdatingof
1 2
likelihoodestimateofobservationDthatM winsM is: the two models after comparing them, and as the number
1 2
of comparisons increases, µ gets closer to the true value
(cid:32) (cid:33)
θ −θ and σ tightens up, resulting in a high-confidence capacity
P(D|θ ,θ )=P (X >X )=Φ 1 2 (4)
1 2 1 2 (cid:112) β2+β2 estimate [4]. We generalize it to a free-for-all comparison
1 2
ofKmodels,andthecapacityupdatingformulasforthei-th
Here, Φ(x) is the cumulative distribution function of stan- modelareasfollows:
(cid:82)x
dard normal distribution, i.e., Φ(x) = ϕ(u)du, and
−∞ (cid:32) (cid:18) (cid:19)
ϕ(x) is the probability density function of standard nor- µˆ =µ +σ2· (cid:88) 1 ·V µ i−µ q
mal distribution, i.e., ϕ(x) = √1 e−x2/2. Then, based on i i i c iq c iq
2π q:rq>rq
(9)
Bayes’theorem,wecanderivethejointposteriordensityof (cid:18) (cid:19)(cid:33)
(θ 1,θ 2)givenobservationDasfollows: + (cid:88) −1 ·V µ q−µ i
c c
iq iq
P(θ ,θ |D)∝P(θ )P(θ )P(D|θ ,θ )
q:ri<rq
1 2 1 2 1 2
=ϕ(cid:18) θ 1−µ 1(cid:19) ϕ(cid:18) θ 2−µ 2(cid:19) Φ(cid:32) θ 1−θ
2
(cid:33) (5)
σˆ2
=σ2·(cid:32) 1−(cid:32) (cid:88) σ i2 ·W(cid:18) µ i−µ q(cid:19)
σ 1 σ 2 (cid:112) β 12+β 22 i i q:ri>rq c2 iq c iq
(10)
Themarginalposteriordensityofθ 1canbesubsequently
+
(cid:88) σ i2 ·W(cid:18) µ q−µ i(cid:19)(cid:33)(cid:33)
obtainedbythefollowingequation: c2 c
q:ri<rq iq iq
(cid:90) ∞
Thanks to the probabilistic modeling and Bayesian up-
P (θ |D)= P (θ ,θ |D)dθ
1 1 2 2
dating employed in K-wise comparison, the model’s capa-
−∞
(cid:18) (cid:19) (cid:32) (cid:33) (6) bilitiescanberepresentedwithhighrobustness,therebyfa-
θ −µ θ −µ
∝ϕ 1 1 Φ 1 2 cilitatingstableandaccurateranking. Additionally,itisim-
(cid:112)
σ 1 β 12+β 22+σ 22 portant to note that K-wise comparison offers an inherent
advantageintermsofefficiency. Generallyspeaking, aK-
The derivation of the above equation is detailed in Ap-
wisecomparisoncanbeviewedasC2 = K(K−1) pairwise
pendixA.1. Withthemarginalposteriordensity,theposte- K 2
comparisons.Assumingthateachpairwisecomparisonpro-
riormeanofθ canbecalculatedasfollows:
1
videsacertainrankingbenefit, andthisbenefitisadditive,
(cid:82)∞
θ P(θ |D)dθ wecanclaimthatthetotalnumberofcomparisonsrequired
µˆ =E[θ |D]= −∞ 1 1 1
1 1 (cid:82)∞ issignificantlylessthanthatforpairwisecomparisons.
P(θ |D)dθ
−∞ 1 1
(cid:32) (cid:33)
3.2.Exploration-ExploitationBasedMatchmaking
ϕ µ1−µ2
σ2
(cid:113)(cid:80)(β2+σ2)
Effectivemodelmatchmakingsignificantlyimpactstheef-
=µ + 1 i i (7)
1 (cid:112)(cid:80) (β2+σ2) (cid:32) (cid:33) ficiency of ranking convergence. Here we first examine
i i Φ µ1−µ2 matchmakingmethodsusedinnotablerankingsystems.For
(cid:113)(cid:80)(β
i2+σ i2)
instance, the ELO system [12], employed by traditional
σ2 (cid:18) µ −µ (cid:19) Arena, uses completely random matching. This can re-
=µ + 1 ·V 1 2
1 c c sult in pairing the lowest-ranked player with the highest-
12 12
4ranked one, even after numerous comparisons when rank- where X k =X k−1−{X q∗ k−1},
(13)
ings are nearly stable. Such matchups provide minimal X ={X }N , X∗ =X
newinformation,oftenleadingtoinefficientuseofevalua- 0 q q=1 q0 i
tionresourcesandslowerrankingconvergence. Toaddress
The above procedure accomplishes the effective selec-
the above issue, TrueSkill system [17] focuses on match-
tion of its opponents after specifying the pivot player X .
i
ingplayerswhosestrengthsareasequalaspossible. How-
In our algorithm, instead of random selection, we specify
ever,itisonlyeffectiveforassessingtheabilityofindivid-
X undertheguidanceofequalizingthenumberofcompar-
i
ualplayers,becauseeachplayer’sopponentsarelimitedtoa
isonstopromotebalancedparticipationincomparisonsby
small,localizedgroupofcandidates. Thislimitationmeans
eachplayer,whichisformulatedasfollows:
that it lacks a comprehensive understanding of the overall
poolofplayers,makingitlessusefulfortheoverallranking
N
ofalargenumberofplayers. X =arg min (cid:88) n (14)
i iq
To this end, we propose an exploration-exploitation- Xi∈X0q=1,q̸=i
based matchmaking strategy, which promotes valuable
comparisonsandthusachievesefficientmodelrankingwith
In the following, we present the advantages of the pro-
fewercomparisons. Specifically,wemodeltheselectionof
posed specification policy of the pivot player X in a
i
players as a multi-armed bandit problem, where each pair
scenario-by-scenariomanner.
of players is viewed as an arm. The objective is to max-
• Scenario 1: Ranking many models from scratch. In
imize the overall benefit after n comparisons, i.e., to pro-
eachroundofcomparisons,weselectthemodelwiththe
vide the most information for the overall ranking after n
fewestcomparisonsasthepivot. Thispromotesbalanced
comparisons. Notably,ourapproachemphasizesmaximiz-
participationacrossallmodels,preventinginsufficientor
ingglobalgains,offeringabroaderperspectivecomparedto
excessive evaluation of certain models. Such equaliza-
TrueSkill,whichfocusesonshort-termbenefitsfromanin-
tionfromaglobalperspectiveisalsoanimportantfactor
dividualplayer’sviewpoint. Tosolvethemulti-armedban-
inpromotingrapidconvergenceoftheoverallranking.
ditproblem,weapplytheUpperConfidenceBound(UCB)
• Scenario 2: Adding new models to an existing rank-
algorithm. The UCB algorithm performs exploration with
ing. Our algorithm facilitates new models to participate
the most optimistic attitude given the current exploitation,
incomparisonsaspivotsfrequentlyintheearlyroundsso
whichisformulatedasfollows:
that they can quickly catch up with the number of com-
(cid:115) parisonsofoldmodels. Hence, withaneffectivematch-
lnn
U(n)(X ,X )=|S(n)−S(n)|+α· (11) makingstrategy,wecanefficientlyevaluatenewmodels’
i q i q n
iq capabilities, allowing us to showcase the latest progress
intheleaderboardinrealtime.
where |S(n) − S(n)| indicates the absolute difference in
i q
scoresbetweenthei-thmodelandq-thmodelafterncom-
4.Experiments
parisons,n denotesthenumberofcomparisonsthathave
iq
been made between the two models, and α is a balancing In this section, we design experiments that simulate user
coefficient with a typical value of 1.0. Eq. 11 realizes the votinganddifferentrankingscenarios,toverifythevalidity
trade-off between exploration and exploitation, where the ofeachproposedcomponentinK-SortArena.
first part is exploitation and the second part is exploration.
ExperimentalSetupInSections4.2,4.3,and4.4,wecon-
Inexploitationphase,weprioritizeselectingplayersofsim-
duct experiments to rank 50 models from scratch. In Sec-
ilarskilllevelstocreatevaluablecomparisons,whileinthe
tion4.5,weperformexperimentsbyaddinganewmodelto
explorationphase,weencourageplayerswhohavenotbeen
an existing ranking of 50 models. To simulate user voting
sufficiently evaluated to participate in matches to ensure a
onmodelcomparisons, weassignapresetout-of-orderla-
comprehensive assessment. We theoretically prove its ad-
bel to each model to indicate its ground-truth ability. The
vantageoverrandomselection(detailsinAppendixB).
resultofaspecificcomparisondependsontheperformance
Consequently, for a pre-specified player X , designated
i ofmodels,whicharedeterminedbytheirground-truthabil-
asthepivot,wecanachievegroupingbygreedilyselecting
itiesandthepreferencenoise. Notethatthispresetlabelis
itsK-1opponentsbasedontheirUpperConfidenceBound
usedsolelyforevaluatingthecomparisonresultsandisnot
(UCB)scores,asfollows::
involved in any other part of the ranking process, such as
modelcapabilitymodelingandupdating. Finally,wecalcu-
K−1(cid:26) (cid:27)
{X∗ ,··· ,X∗ }= (cid:91) arg max {U(X ,X )} latetheMeanSquaredError(MSE)oftherankedpositions
q1 qK−1
k=1
Xq∈Xk
i q
againstthepresetlabelstoevaluatetheconvergencespeed
(12) andaccuracy.
5Table1.NumberofcomparisonsrequiredforELOsystemandK- ourprobabilisticmodelingprovidesrapidconvergenceafter
SortArenatoreachconvergence. about1500comparisons.
Figure 3b illustrates the case of voting with preference
Method K Modeling Matchmaking Comparisons noise. In Figure 3a, comparison results are directly deter-
ELOSystem 2 Numerical Random 11692 minedbythepresetlabels, whereasinFigure3bweintro-
K-SortArena 4 Probabilistic UCB 716(↓16.3×) ducea5%chanceofinconsistencybetweenthecomparison
results and the labels. As observed, numerical modeling
stillfailstoconverge,whileprobabilisticmodeling,despite
4.1.K-SortArenavs. ELO-basedArena
convergingslightlyslowerduetonoiseeffects,managesto
Table1showsthenumberofcomparisonsrequiredforELO convergeafterapproximately2000comparisons. Thisfully
system and K-Sort Arena to reach convergence, i.e., MSE demonstratesthehighrobustnessofprobabilisticmodeling,
becomes consistently zero. Encouragingly, with the ad- offeringastrongassuranceofthereliabilityofevaluations.
vancedmodelingmethodandmatchmakingstrategy,K-Sort
4.3.K-wisevs. PairwiseComparison
Arena is 16.3 times more efficient than ELO system, dra-
matically reducing the number of user votes required. Be- Next,weverifytheeffectofdifferentKvalues(K∈[2,4,6])
lowwewillverifytheadvantagesofeachcomponent. onrankingconvergence.Allthreesetsofexperimentsadopt
UCB matchmaking strategy, and the experimental results
4.2.Probabilisticvs. NumericalModeling areshowninFigure4. WhenKisincreasedto4,multiple
models engage in free-for-all comparisons in each round,
Webeginbyverifyingtheadvantagesofprobabilisticmod-
which yields richer information than the case of K=2, re-
eling over numerical modeling employed in ELO systems,
sultinginfasterconvergence(approximatelytwiceasfast).
as shown in Figure 3a. Since the ELO system is designed
For K=6, while MSE decreases more rapidly in the early
forpairwisecomparisons,wefixKinK-SortArenato2in
stages, small fluctuations occur in the later stages before
this experiment for fairness. Remarkably, numerical mod-
final convergence, resulting in less pronounced efficiency
elingexhibitsviolentoscillationandfailstoconvergeeven
gains. Therefore,K=4isconsideredasatrade-offchoice.
after 3000 comparisons. This outcome highlights the un-
reliability of the existing Arena platform, despite the large
numberofvotesthathavebeencollected. Onthecontrary, K=2, UCB matchmaking
450 K=4, UCB matchmaking
K=6, UCB matchmaking
600 300 K=2, Numerical (ELO)
K=2, Probabilistic (Ours)
150
400
0
200 0 600 1200 1800
Number of Comparisons
Figure4. ComparisonofdifferentKvalueswhenapplyingUCB
0 matchmaking. K∈[2,4,6]. As K increases, the convergence be-
0 1000 2000 3000
Number of Comparisons comesfasterandmorestable.
(a)Casewithoutpreferencenoise.
600 K=2, Numerical, 5% Noise (ELO)
4.4.UCBvs. TraditionalMatchmaking
K=2, Probabilistic, 5% Noise (Ours)
400 In this section, we demonstrate the advantages of the pro-
posed UCB matchmaking strategy. The comparison meth-
ods include random matchmaking in the ELO system and
200
skill-based matchmaking in the TrueSkill system. The ex-
perimentalresultsarepresentedinFigure5. Sincerandom
0
matchingcanpotentiallyresultinlow-informationcompar-
0 1000 2000 3000
Number of Comparisons isons, such as pairing the highest-ranked player with the
(b)Casewithpreferencenoise.
lowest-rankedone,itcontinuestooscillateafter3,000com-
Figure 3. Comparison of numerical modeling (ELO [12]) and parisons. The goal of skill-based matchmaking is that the
probabilistic modeling (ours) at K=2, separately with and with- skills of players in the comparison are as equal as possi-
outpreferencenoise.Probabilisticmodelingcanconvergequickly, ble. This may promote interesting matches for an individ-
whilenumericalmodelingstaysoscillatingandfailstoconverge. ual player, but it ignores exploration and thus fails to en-
6
)ESM(
rorrE
derauqS
naeM
)ESM(
rorrE
derauqS
naeM
)ESM(
rorrE
derauqS
naeM5.K-SortArenaPlatform
600 K=4, Random matchmaking (ELO)
K=4, Skill matchmaking (TrueSkill)
In this section, we build an open and live evaluation plat-
K=4, UCB matchmaking (Ours)
400 form with human-computer interactions in Huggingface
Space,whichintegratestheproposedalgorithmstoimprove
200 efficiencyandreliability. Onthisplatform,userscaninput
a prompt and receive outputs from K anonymous genera-
tive models. Users then cast a ranked vote for these mod-
0
0 1000 2000 3000 els based on their preferred responses, and these votes are
Number of Comparisons
savedforupdatingtheleaderboard. K-SortArenaplatform
Figure 5. Comparison of different matchmaking strategies at hasthefollowinghighlights:
K=4, including random (ELO [12]), Skill (TrueSkill [17]), and
• Open-source platform: K-Sort Arena platform is open-
UCB (ours). The proposed exploitation-exploration based strat-
source, open-access, and non-profit, fostering collabora-
egyachievesthefastestconvergence.
tionandsharinginthecommunity.
• Extensive model coverage: It covers a comprehensive
range of models, including numerous open-source and
sure convergence and stability of the overall ranking from
closed-sourcemodelsacrossvarioustypesandversions.
a global perspective. Fortunately, our UCB matchmaking
• Real-time update: It continuously adds new models,
strategy addresses this issue by balancing exploitation and
completesitsevaluationwithminimalvotes,andupdates
exploration, achieving ranking convergence with minimal
theleaderboardinreal-time.
comparisons.
• Robust evaluation: Bayesian modeling and anonymous
4.5.Specifiedvs. RandomPivot comparisons reduce preference noise and model preju-
dice,makingtheleaderboardreliableandauthoritative.
Here,wefocusonthecaseofaddinganewmodeltoanex-
• User-friendlyinteraction: Itsupportsvariouspromptin-
isting ranking and verify the effectiveness of the proposed
putmodes,votingmodes,anduserinteractionstyles,of-
pivot specification method. We initialize the new model’s
feringusersahighdegreeofflexibility.
rankingat51andsetitsactuallabelto31.Theexperimental
5.1.CoveredTasksandModels
resultsarepresentedinFigure6. Whenboththepivotand
itsopponentsareselectedrandomly,thenewmodelareless
K-Sort Arena is dedicated to evaluating visual generation
likely to be selected. When the pivot is chosen randomly
tasks with human preferences, with a particular focus on
andUCBisusedformatchingopponents,theefficiencyim-
text-to-imageandtext-to-videotasks. Toensureacompre-
proves. Thisimprovementisduetotheexplorationtermin
hensiveandthoroughevaluation,westrivetocoverasmany
Eq. 11,thenewmodel’ssmalln increasesitsprobability
iq mainstreammodelsaspossible,includingbothopen-source
of being selected as an opponent. Furthermore, when em-
and closed-source models, as well as multiple versions of
ployingourbalance-guidedspecificationmethod,sincethe
a single model, if available. Currently, K-Sort Arena has
newmodelnaturallyparticipatesintheminimalnumberof
servedtoevaluatedozensofstate-of-the-artmodels. Ade-
comparisons,itisalwaysselectedasthepivotintheinitial
tailedlistofmodelsispresentedinAppendixC.
period.Notably,onlyroughly30comparisonsareneededto
determine the new model’s ranking, which provides a pre- 5.2.PlatformConstruction
requisiteforrapidleaderboardupdating.
K-SortArenaplatformisdesignedusingGradioandhosted
in Huggface Space. Model inference is performed on Ze-
roGPUCloudorReplicateAPIcalls.
60 Random pivot, Random matching InterfaceOverviewTheinterfacefeaturestwomainfunc-
Random pivot, UCB matching
tionalities: leaderboard display and user voting for model
Specified pivot, UCB matching (Ours)
50 battles. When participating in voting, after the user enters
theprompt,theinterfacecandisplay4generatedimagesor
40 videosfromtheanonymousmodels,i.e.,K =4istakenas
default. TheinterfacelayoutisillustratedinAppendixE.
30 PromptInputModeToaptlyreflectdiversereal-worldap-
0 50 100 150 plications,K-SortArenasupportstwopromptinputmodes.
Number of Comparisons
• Ready-made prompts: Users have the option to ran-
Figure6. Comparisonofdifferentmatchmakingstrategieswhen domly extract pre-designed prompts from our extensive
addinganewmodel.Thepivotspecificationmethod,coupledwith data pool for input into the models. This feature elimi-
UCBopponentmatching,enablesthefastestconvergence. natestheneedforuserstospendtimecreatingtheirown
7
)ESM(
rorrE
derauqS
naeM
ledoM
weN
fo
knaRprompts,therebysignificantlyimprovingtheefficiencyof
Sora
theirinteractions. Atpresent,thedatapoolcontains5000
Runway-Gen3
representativeprompts, whicharesampledfrompopular
Runway-Gen2
datasetssuchasMSCOCO[32]andWebVid[3].
Pika-v1.0
• Custom prompts: Users are also free to create fresh in-
put prompts, allowing them to tailor and customize the Pika-beta
generatedcontenttomeettheirspecificneeds. LaVie
Voting Mode K-Sort Arena supports two voting modes OpenSora
forK-wisefree-for-allcomparisons,calledBestModeand VideoCrafter2
Rank Mode. In Best Mode, users compare the outputs of StableVideoDiffusion
Kmodelsandvoteforthemostpreferredanswer. Forusers AnimateDiff
whoareunsure,atieoptionisalsoavailable.InRankMode, Zeroscope-v2-xl
users can rank the outputs of K models, providing a more 20 30 40
Conservative Score
fine-grainedcomparison(tieisalsoavailable).
• BestMode:Inthismode,theuseronlyneedstoselectthe Figure8. Leaderboardoftext-to-videomodels,whichareranked
byconservativescoreS. Wealsoshowµandσ foreachmodel.
bestmodel,makingoneK-wisecomparisontheoretically
The data is as of Aug 2024. Note that the comparisons of Sora
equivalent to K −1 pairwise comparisons. Since it re-
onlytakeSora’sofficialsamplesduetothelackofavailableAPI.
quiresonlyonemouseclick,asinpairwisecomparisons,
itisK−1timesmoreefficient.
• RankMode: Inthismode,theuserprovidesfeedbackby lected over 1,000 high-quality votes. All voters are pro-
rankingtheKmodels.OneK-wisecomparisonistheoret- fessors and graduate students in the field of visual gen-
icallyequivalentto K(K−1) pairwisecomparisons. Since eration. To ensure high quality and mitigate preference
2
it requires clicking on the rank of each model, i.e., K noise, we organize pre-voting training and provide eval-
clicks,itis K−1 timesmoreefficient. uation guidelines. Specifically, for text-to-image models,
2
theevaluationcriteriaconsistofAlignment(50%)andAes-
5.3.LeaderboardBuilding
thetics (50%). Alignment encompasses entity, style, and
othermatchingaspects,whileAestheticsincludesphotore-
CrowdsourcedVotingOurprojecthasbeenundergoingin-
alism,lightandshadowrendering,andtheabsenceofarti-
ternaltestingforseveralmonths,duringwhichwehavecol-
facts.Text-to-videomodelsaresimilarlyevaluatedbasedon
Alignment(50%)andAesthetics(50%). Alignmentisbro-
ken down into video content matching, movement match-
Midjourney-v6.0 ing,andinter-frameconsistency.Aestheticscomprisespho-
FLUX.1-pro
Midjourney-v5.0 torealism,physicalcorrectness,andtheabsenceofartifacts.
FLUX.1-dev
FLUX.1-schnell Leaderboard Showcase The leaderboard of text-to-image
SD-v3.0
modelsisillustratedinFigure7. Wecanobservethatpro-
Dalle-3
Pixart-Sigma prietary models like MidJourney and Dalle dominate the
Proteus-v0.2
Open-Dalle-v1.1 top of the charts. Among open-source models, FLUX.1
Dreamshaper-xl
Deepfloyd-IF and SD-v3.0 stand out with impressive performance. The
Realvisxl-v3.0
Realvisxl-v2.0 leaderboardoftext-to-videomodelsisinFigure8.
Kandinsky-v2.2
Dalle-2 6.Conclusion
Kandinsky-v2.0
Playground-v2.5
SDXL-turbo In this paper, we introduce K-Sort Arena, a benchmark-
Playground-v2.0
Openjourney-v4 ing platform for visual generation models. K-Sort Arena
SDXL employs K-wise comparisons (K>2), allowing K models
LCM-v1.5
SD-v2.1 to play free-for-all games, along with probabilistic model-
SD-v1.5
SD-turbo ing and Bayesian updating to improve efficiency and ro-
SSD-1b
SDXL-Lightning bustness. Furthermore, an exploration-exploitation based
Stable-cascade
matchmaking strategy is proposed to facilitate valuable
SDXL-Deepcache
comparisons, which further accelerates convergence. We
16 24 32
Conservative Score validatethesuperiorityoftheproposedalgorithmsviamul-
tiplesimulatedexperiments. Todate,K-SortArenahascol-
Figure7. Leaderboardoftext-to-imagemodels,whichareranked
byconservativescoreS. Wealsoshowµandσ foreachmodel. lectedextensivehigh-qualityvotestobuildcomprehensive
ThedataisasofAug2024. leaderboardsforimageandvideogeneration.
8References [14] MarkEGlickman.Theglickosystem.BostonUniversity,16
(8):9,1995. 3
[1] PeterAuer,NicoloCesa-Bianchi,andPaulFischer. Finite-
[15] Song Han, Huizi Mao, and William J Dally. Deep com-
time analysis of the multiarmed bandit problem. Machine
pression: Compressingdeepneuralnetworkswithpruning,
learning,47:235–256,2002. 2
trained quantization and huffman coding. arXiv preprint
[2] Jinbin Bai, Zhen Dong, Aosong Feng, Xiao Zhang, Tian
arXiv:1510.00149,2015. 2
Ye, Kaicheng Zhou, and Mike Zheng Shou. Integrat-
[16] Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, and
ing view conditions for image synthesis. arXiv preprint
QifengChen.Latentvideodiffusionmodelsforhigh-fidelity
arXiv:2310.16002,2023. 3
long video generation. arXiv preprint arXiv:2211.13221,
[3] Max Bain, Arsha Nagrani, Gu¨l Varol, and Andrew Zisser-
2022. 1
man. Frozenintime: Ajointvideoandimageencoderfor
[17] RalfHerbrich,TomMinka,andThoreGraepel. Trueskill™:
end-to-endretrieval. InProceedingsoftheIEEE/CVFinter-
abayesianskillratingsystem. Advancesinneuralinforma-
nationalconferenceoncomputervision, pages1728–1738,
tionprocessingsystems,19,2006. 3,5,7
2021. 8
[18] JackHessel,AriHoltzman,MaxwellForbes,RonanLeBras,
[4] JamesLBeckandLambrosSKatafygiotis. Updatingmod-
andYejinChoi. Clipscore:Areference-freeevaluationmet-
elsandtheiruncertainties.i:Bayesianstatisticalframework.
ricforimagecaptioning. arXivpreprintarXiv:2104.08718,
Journal of Engineering Mechanics, 124(4):455–461, 1998.
2021. 3
4
[19] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner,
[5] James Betker, Gabriel Goh, Li Jing, Tim Brooks, Jianfeng
Bernhard Nessler, and Sepp Hochreiter. Gans trained by a
Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce
twotime-scaleupdateruleconvergetoalocalnashequilib-
Lee, Yufei Guo, et al. Improving image generation with rium. Advances in neural information processing systems,
better captions. Computer Science. https://cdn. openai.
30,2017. 1,3
com/papers/dall-e-3.pdf,2(3):8,2023. 1
[20] Yushi Hu, Benlin Liu, Jungo Kasai, Yizhong Wang, Mari
[6] Simone Bianco, Luigi Celona, Marco Donzella, and Paolo Ostendorf,RanjayKrishna,andNoahASmith. Tifa: Accu-
Napoletano. Improving image captioning descriptive- rate and interpretable text-to-image faithfulness evaluation
ness by ranking and llm-based fusion. arXiv preprint withquestionanswering. InProceedingsoftheIEEE/CVF
arXiv:2306.11593,2023. 3 InternationalConferenceonComputerVision,pages20406–
[7] MikołajBin´kowski,DanicaJSutherland,MichaelArbel,and 20417,2023. 3
Arthur Gretton. Demystifying mmd gans. arXiv preprint [21] Kaiyi Huang, Kaiyue Sun, Enze Xie, Zhenguo Li, and
arXiv:1801.01401,2018. 3 Xihui Liu. T2i-compbench: A comprehensive bench-
[8] ThibaultCastells,Hyoung-KyuSong,Bo-KyeongKim,and mark for open-world compositional text-to-image genera-
ShinkookChoi. Ld-pruner:Efficientpruningoflatentdiffu- tion. Advances in Neural Information Processing Systems,
sionmodelsusingtask-agnosticinsights. InProceedingsof 36:78723–78747,2023. 3
theIEEE/CVFConferenceonComputerVisionandPattern [22] ZiqiHuang,YinanHe,JiashuoYu,FanZhang,ChenyangSi,
Recognition,pages821–830,2024. 2 YumingJiang,YuanhanZhang,TianxingWu,QingyangJin,
[9] Yixiong Chen, Li Liu, and Chris Ding. X-iqe: explain- NattapolChanpaisit,etal. Vbench: Comprehensivebench-
able image quality evaluation for text-to-image genera- marksuiteforvideogenerativemodels. InProceedingsof
tion with visual large language models. arXiv preprint theIEEE/CVFConferenceonComputerVisionandPattern
arXiv:2305.10843,2023. 3 Recognition,pages21807–21818,2024. 3
[10] Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anasta- [23] Dongfu Jiang, Max Ku, Tianle Li, Yuansheng Ni, Shizhuo
sios Nikolas Angelopoulos, Tianle Li, Dacheng Li, Hao Sun,RongqiFan,andWenhuChen. Genaiarena: Anopen
Zhang, BanghuaZhu, MichaelJordan, JosephEGonzalez, evaluation platform for generative models. arXiv preprint
etal.Chatbotarena:Anopenplatformforevaluatingllmsby arXiv:2406.04485,2024. 3
humanpreference. arXivpreprintarXiv:2403.04132,2024. [24] Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik,
1,3 Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha
[11] Joseph Cho, Fachrina Dewi Puspitasari, Sheng Zheng, Prasad, Amanpreet Singh, Pratik Ringshia, et al. Dyn-
JingyaoZheng, Lik-Hang Lee, Tae-Ho Kim, Choong Seon abench: Rethinking benchmarking in nlp. arXiv preprint
Hong,andChaoningZhang. Soraasanagiworldmodel? a arXiv:2104.14337,2021. 3
completesurveyontext-to-videogeneration. arXivpreprint [25] Tony Lee, Michihiro Yasunaga, Chenlin Meng, Yifan Mai,
arXiv:2403.05131,2024. 1 Joon Sung Park, Agrim Gupta, Yunzhi Zhang, Deepak
[12] ArpadEElo. Theproposeduscfratingsystem,itsdevelop- Narayanan,HannahTeufel,MarcoBellagente,etal. Holis-
ment, theory, and applications. Chess life, 22(8):242–247, ticevaluationoftext-to-imagemodels. AdvancesinNeural
1967. 3,4,6,7 InformationProcessingSystems,36,2024. 3
[13] Patrick Esser, Johnathan Chiu, Parmida Atighehchian, [26] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi.
Jonathan Granskog, and Anastasis Germanidis. Structure Blip: Bootstrappinglanguage-imagepre-trainingforunified
and content-guided video synthesis with diffusion models. vision-language understanding and generation. In Interna-
In Proceedings of the IEEE/CVF International Conference tionalconferenceonmachinelearning,pages12888–12900.
onComputerVision,pages7346–7356,2023. 1 PMLR,2022. 3
9[27] Xiuyu Li, Yijiang Liu, Long Lian, Huanrui Yang, Zhen simple probability inference task. Journal of experimental
Dong, Daniel Kang, Shanghang Zhang, and Kurt Keutzer. psychology,72(3):346,1966. 4
Q-diffusion: Quantizing diffusion models. In Proceedings [40] Dustin Podell, Zion English, Kyle Lacey, Andreas
oftheIEEE/CVFInternationalConferenceonComputerVi- Blattmann, Tim Dockhorn, Jonas Mu¨ller, Joe Penna, and
sion,pages17535–17545,2023. 2 Robin Rombach. Sdxl: Improving latent diffusion mod-
[28] Zhikai Li and Qingyi Gu. I-vit: Integer-only quantization els for high-resolution image synthesis. arXiv preprint
for efficient vision transformer inference. In Proceedings arXiv:2307.01952,2023. 1
oftheIEEE/CVFInternationalConferenceonComputerVi- [41] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
sion,pages17065–17075,2023. Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,
[29] Zhikai Li, Liping Ma, Mengjuan Chen, Junrui Xiao, and AmandaAskell,PamelaMishkin,JackClark,etal.Learning
QingyiGu. Patchsimilarityawaredata-freequantizationfor transferable visual models from natural language supervi-
vision transformers. In European conference on computer sion.InInternationalconferenceonmachinelearning,pages
vision,pages154–170.Springer,2022. 8748–8763.PMLR,2021. 3
[30] ZhikaiLi,JunruiXiao,LianweiYang,andQingyiGu.Repq- [42] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
vit: Scale reparameterization for post-training quantization Ramesh, Gabriel Goh, Sandhini Agarwal, et al. Learning
ofvisiontransformers. InProceedingsoftheIEEE/CVFIn- transferable visual models from natural language supervi-
ternational Conference on Computer Vision, pages 17227– sion.InInternationalconferenceonmachinelearning,pages
17236,2023. 2 8748–8763.PMLR,2021. 3
[31] Mingxiang Liao, Hannan Lu, Xinyu Zhang, Fang Wan, [43] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Tianyu Wang, Yuzhong Zhao, Wangmeng Zuo, Qixiang Patrick Esser, and Bjo¨rn Ommer. High-resolution image
Ye, and Jingdong Wang. Evaluation of text-to-video gen- synthesis with latent diffusion models. In Proceedings of
eration models: A dynamics perspective. arXiv preprint the IEEE/CVF conference on computer vision and pattern
arXiv:2407.01094,2024. 3 recognition,pages10684–10695,2022. 1
[32] Tsung-YiLin,MichaelMaire,SergeBelongie,JamesHays, [44] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki
PietroPerona,DevaRamanan,PiotrDolla´r,andCLawrence Cheung,AlecRadford,andXiChen. Improvedtechniques
Zitnick. Microsoft coco: Common objects in context. In fortraininggans.Advancesinneuralinformationprocessing
ComputerVision–ECCV2014: 13thEuropeanConference, systems,29,2016. 1,3
Zurich, Switzerland, September 6-12, 2014, Proceedings, [45] AxelSauer,DominikLorenz,AndreasBlattmann,andRobin
PartV13,pages740–755.Springer,2014. 8 Rombach. Adversarialdiffusiondistillation. arXivpreprint
[33] Zhiqiu Lin, Deepak Pathak, Baiqi Li, Jiayao Li, Xide Xia, arXiv:2311.17042,2023. 2
Graham Neubig, Pengchuan Zhang, and Deva Ramanan. [46] Christoph Schuhmann. CLIP+MLP Aesthetic
Evaluatingtext-to-visualgenerationwithimage-to-textgen- Score Predictor. https://github.com/
eration. arXivpreprintarXiv:2404.01291,2024. 3 christophschuhmann/improved-aesthetic-
[34] YaofangLiu,XiaodongCun,XueboLiu,XintaoWang,Yong predictor,2022. 3
Zhang, Haoxin Chen, Yang Liu, Tieyong Zeng, Raymond [47] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon
Chan,andYingShan. Evalcrafter: Benchmarkingandeval- Shlens, andZbigniewWojna. Rethinkingtheinceptionar-
uating large video generation models. In Proceedings of chitectureforcomputervision. InProceedingsoftheIEEE
theIEEE/CVFConferenceonComputerVisionandPattern Conference on Computer Vision and Pattern Recognition
Recognition,pages22139–22149,2024. 3 (CVPR),2016. 3
[35] YuanxinLiu,LeiLi,ShuhuaiRen,RundongGao,Shicheng [48] Thomas Unterthiner, Sjoerd Van Steenkiste, Karol Kurach,
Li, Sishuo Chen, Xu Sun, and Lu Hou. Fetv: A bench- RaphaelMarinier,MarcinMichalski,andSylvainGelly.To-
mark for fine-grained evaluation of open-domain text-to- wardsaccurategenerativemodelsofvideo:Anewmetric&
videogeneration. AdvancesinNeuralInformationProcess- challenges. arXivpreprintarXiv:1812.01717,2018. 1,3
ingSystems,36,2024. 3 [49] Jay Zhangjie Wu, Xiuyu Li, Difei Gao, Zhen Dong, Jin-
[36] YujieLu,DongfuJiang,WenhuChen,WilliamYangWang, binBai, AishaniSingh, XiaoyuXiang, YouzengLi, Zuwei
Yejin Choi, and Bill Yuchen Lin. Wildvision: Evaluating Huang,YuanxiSun,etal. Cvpr2023textguidedvideoedit-
vision-languagemodelsinthewildwithhumanpreferences. ingcompetition. arXivpreprintarXiv:2310.16003,2023. 3
arXivpreprintarXiv:2406.11069,2024. 3 [50] JayZhangjieWu,GuianFang,HaoningWu,XintaoWang,
[37] Simian Luo, Yiqin Tan, LongboHuang, Jian Li, andHang Yixiao Ge, Xiaodong Cun, David Junhao Zhang, Jia-Wei
Zhao. Latent consistency models: Synthesizing high- Liu,YuchaoGu,RuiZhao,etal. Towardsabettermetricfor
resolution images with few-step inference. arXiv preprint text-to-videogeneration. arXivpreprintarXiv:2401.07781,
arXiv:2310.04378,2023. 2 2024. 3
[38] ZeMa,DaquanZhou,Chun-HsiaoYeh,Xue-SheWang,Xi- [51] XiaoshiWu,KeqiangSun,FengZhu,RuiZhao,andHong-
uyuLi,HuanruiYang,ZhenDong,KurtKeutzer,andJiashi sheng Li. Human preference score: Better aligning text-
Feng. Magic-me: Identity-specificvideocustomizeddiffu- to-image models with human preference. In Proceedings
sion. arXivpreprintarXiv:2402.09368,2024. 3 oftheIEEE/CVFInternationalConferenceonComputerVi-
[39] LawrenceDPhillipsandWardEdwards. Conservatismina sion,pages2096–2105,2023. 3
10[52] Jiazheng Xu, Xiao Liu, Yuchen Wu, Yuxuan Tong, Qinkai
Li, Ming Ding, Jie Tang, and Yuxiao Dong. Imagere-
ward: Learningandevaluatinghumanpreferencesfortext-
to-imagegeneration. AdvancesinNeuralInformationPro-
cessingSystems,36,2024. 3
[53] Chenshuang Zhang, Chaoning Zhang, Mengchun Zhang,
andInSoKweon. Text-to-imagediffusionmodelsingener-
ativeai: Asurvey. arXivpreprintarXiv:2303.07909,2023.
1
[54] Daquan Zhou, Weimin Wang, Hanshu Yan, Weiwei Lv,
Yizhe Zhu, and Jiashi Feng. Magicvideo: Efficient video
generation with latent diffusion models. arXiv preprint
arXiv:2211.11018,2022. 1
[55] Xingyi Zhou, Anurag Arnab, Shyamal Buch, Shen Yan,
AustinMyers,XuehanXiong,ArshaNagrani,andCordelia
Schmid. Streamingdensevideocaptioning. InProceedings
oftheIEEE/CVFConferenceonComputerVisionandPat-
ternRecognition,pages18243–18252,2024. 3
[56] YutongZhouandNobutakaShimada. Vision+languageap-
plications:Asurvey. InProceedingsoftheIEEE/CVFCon-
ferenceonComputerVisionandPatternRecognition,pages
826–842,2023. 3
[57] Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mo-
hamed Elhoseiny. Minigpt-4: Enhancing vision-language
understandingwithadvancedlargelanguagemodels. arXiv
preprintarXiv:2304.10592,2023. 3
11K-Sort Arena: Efficient and Reliable Benchmarking for Generative Models via
K-wise Human Preferences
Supplementary Material
A.DerivationofBayesianUpdating A.2.DerivationofEq. 7inPaper
Inthissection,weprovideamoredetailedderivationofthe (cid:82)∞ θ P(θ |D)dθ
formulasinSection3.1tofurtherclarifythetheoreticalun- µˆ 1 =E[θ 1|D]= (cid:82)−∞ ∞ 1 1 1
P(θ |D)dθ
derpinnings. −∞ 1 1
(cid:16) (cid:17) (cid:18) (cid:19)
A.1.DerivationofEq. 6inPaper (cid:82) −∞ ∞θ 1ϕ θ1 σ− 1µ1 Φ √ βθ 21 +− βµ 22
+σ2
dθ 1 (19)
(cid:90) ∞ = (cid:16) (cid:17) (cid:18) 1 2 2 (cid:19)
P (θ 1|D)= −∞P (θ 1,θ 2|D)dθ 2 (cid:82) −∞ ∞ϕ θ1 σ− 1µ1 Φ √ βθ 121 +− βµ 222
+σ 22
dθ 1
∝(cid:90) ∞ ϕ(cid:18) θ 1−µ 1(cid:19) ϕ(cid:18) θ 2−µ 2(cid:19) Φ(cid:32) θ 1−θ 2 (cid:33) dθ WebeginwiththederivationofthenumeratorofEq. 19.
−∞ σ 1 σ 2 (cid:112) β 12+β 22 2 Again,wewriteΦ(x)asanintegralofϕ(x),asfollows:
(cid:18) θ −µ (cid:19)(cid:90) ∞ (cid:18) θ −µ (cid:19) (cid:32) θ −θ (cid:33) (cid:32) (cid:33)
∝ϕ 1 1 ϕ 2 2 Φ 1 2 dθ θ −µ
σ 1 −∞ σ 2 (cid:112) β 12+β 22 2 Φ (cid:112) β21 +β22 +σ2
(15) 1 2 2 (20)
Nowlet’sfocusontheintegralpart. WefirstwriteΦ(x) (cid:90) θ1 1 − (y−µ2)2
asanintegralofϕ(x),asfollows:
=
(cid:112)
2π(β2+β2+σ2)e 2(β12+β22+σ22)dy
−∞ 1 2 2
(cid:32) (cid:33)
θ −θ
Φ 1 2 dθ Thecomputationoftheintegralsisanalogoustothepro-
(cid:112) 2
β2+β2
1 2 (16) cedure described in Eq. 17, which requires reordering the
(cid:90) θ1 1 − (y−θ2)2 integralsandperformingthenecessaryconvolutions. Here,
= (cid:112) e 2(β12+β22)dydθ 2 we omit the repetitive steps and directly show the final re-
2π(β2+β2)
−∞ 1 2 sultasfollows:
Forsimplicity,letβ2 =β2+β2,andtheintegralpartis
1 2  (cid:18) (cid:19)
asfollows: (cid:32) (cid:33) ϕ √µ1−µ2
(cid:90) −∞ ∞ϕ(cid:18) θ 2 σ− 2µ 2(cid:19)(cid:90) −θ ∞1 (cid:112) 21 πβ2e−(y− 2βθ 22)2 dydθ 2 Φ (cid:112)µ β1 2− +µ σ2 2   µ 1+ (cid:112) β2σ 12 +σ2 Φ(cid:18) √µβ 12 −+ µσ 22 (cid:19)  
β2+σ2
=(cid:90) −θ ∞1 (cid:32) (cid:90) −∞ ∞ϕ(cid:18) θ 2 σ− 2µ 2(cid:19)
(cid:112)
21 πβ2e−(y− 2βθ 22)2 dθ 2(cid:33) dy
where σ2 = σ 12 +σ 22 and β2 = β 12 +β 22.
Similarly,(2 th1 e)
derivationresultforthedenominatorofEq.19isasfollows:
(cid:90) θ1 (cid:18) (cid:18) θ −µ (cid:19) (cid:18) y−θ (cid:19)(cid:19)
= ϕ 2 2 ∗ϕ 2 dy (cid:32) (cid:33)
(cid:90)− θ∞
1
(cid:32) (cid:32) yσ −2
µ
(cid:33)(cid:33) β Φ (cid:112)µ β1 2− +µ σ2
2
(22)
= ϕ 2 dy
(cid:112)
σ2+β2
−∞
Thus, bringing the numerator and denominator results
(cid:32) (cid:33)
=Φ θ 1−µ 2 intoEq. 19,wehavethefollowing:
(cid:112)
β2+β2+σ2
1 2 2
(17) µˆ 1 =E[θ 1|D]
Where “∗” denotes the convolution of two Gaussian func- (cid:82)∞ θ P(θ |D)dθ
tions. Finally, Bringing the above result into Eq. 15, we = (cid:82)−∞ ∞ 1 1 1
P(θ |D)dθ
have: −∞ 1 1
(cid:32) (cid:33)
(cid:90) ∞ (23)
P (θ 1|D)= P (θ 1,θ 2|D)dθ
2 σ2
ϕ (cid:113)(cid:80)µ (1 β− 2µ +2
σ2)
− (cid:18)∞ θ −µ (cid:19) (cid:32) θ −µ (cid:33) (18) =µ 1+ (cid:112)(cid:80) (β1 2+σ2) (cid:32) i i (cid:33)
∝ϕ 1 1 Φ 1 2 i i Φ µ1−µ2
σ 1 (cid:112) β 12+β 22+σ 22 (cid:113)(cid:80)(β i2+σ i2)
1B.ProofoftheoreticaladvantagesofUCB Table2. Listoftext-to-imagemodelsinK-SortArena(innopar-
ticularorder).Here,weshowthenameandlicenseofeachmodel.
ThecumulativeregretoftheUCBpolicygrowslogarithmi-
cally with the number of comparisons n, R n = O(logn), Task Model License Organization
providing better long-term performance compared to the
Dalle-3 Commercial OpenAI
lineargrowthofcumulativeregret,R
n
=O(n),oftheran-
Dalle-2 Commercial OpenAI
domselectionpolicy. Midjourney-v6.0 Commercial Midjourney
Proof: For all K>1, if policy UCB is run on K machines Midjourney-v5.0 Commercial Midjourney
FLUX.1-pro Opensource BlackForestLabs
havingarbitraryrewarddistributionsP ···P withsupport
1 k FLUX.1-dev Opensource BlackForestLabs
in[0,1],thenitsexpectedregretafternplaysisboundedby: FLUX.1-schnell Opensource BlackForestLabs
SD-v3.0 Opensource StabilityAI
   
(cid:88)
(cid:18) lnn(cid:19) (cid:18) π2(cid:19) (cid:88)K SD-v2.1 Opensource StabilityAI
R nUCB ≤8
∆ i
+ 1+
3
 ∆ j SS DD -- tv u1 rb.5
o
O Op pe en ns so ou ur rc ce
e
SS tt aa bb ii ll ii tt yy AA II
i:µi<µ∗ j=1
SDXL Opensource StabilityAI
(24)
SDXL-turbo Opensource StabilityAI
whereµ 1···µ k aretheexpectedvaluesofP 1···P k,µ∗ is Stable-cascade Opensource StabilityAI
themaximumexpectedvalue,and∆ =µ∗−µ forsubop- SDXL-Lightning Opensource ByteDance
i i Text2Image
SDXL-Deepcache Opensource NUS
timalselections. Pleasereferto[1]foradetailedderivation
Kandinsky-v2.2 Opensource AI-Forever
oftheaboveequation. Kandinsky-v2.0 Opensource AI-Forever
When adopting random selection, i.e., choosing an arm Proteus-v0.2 Opensource DataAutoGPT3
uniformlyatrandomateachplay,theexpectedregretafter Playground-v2.5 Opensource PlaygroundAI
Playground-v2.0 Opensource PlaygroundAI
nplaysis:
Dreamshaper-xl Opensource Lykon
(cid:32) K (cid:33) Openjourney-v4 Opensource Prompthero
1 (cid:88) LCM-v1.5 Opensource Tsinghua
R nRand =n· µ∗− K µ i (25) Realvisxl-v3.0 Opensource RealisticVision
i=1 Realvisxl-v2.0 Opensource RealisticVision
Pixart-Sigma Opensource PixArt-Alpha
In the RUCB bound in Eq. 24, the first component is a SSD-1b Opensource Segmind
n
logarithmic term, and the second component is a constant Open-Dalle-v1.1 Opensource DataAutoGPT3
Deepfloyd-IF Opensource DeepFloyd
term and independent of n, thus RUCB has a logarithmic
n
growth O(logn). In Eq. 25, RRand has a linear growth
n
O(n). ThisindicatesthatUCBcanmakesbetterselections
over time, thus achieving a significantly lower cumulative Table3. Listoftext-to-videomodelsinK-SortArena(innopar-
regretcomparedtorandomselection. ticularorder).Here,weshowthenameandlicenseofeachmodel.
In our K-Sort Arena system, the lower regret of the
applied UCB policy indicates that it makes higher-reward Task Model License Organization
playergroupings.Thisyieldsmorerankingbenefitsinasin- Sora Commercial OpenAI
glecomparison,thusallowingthesystemtoconvergemore Runway-Gen3 Commercial Runway
Runway-Gen2 Commercial Runway
quicklywithfewercomparisons.
Pika-v1.0 Commercial Pika
Pika-beta Commercial Pika
C.ListofEvaluatedModels Text2Video OpenSora Opensource HPC-AI
VideoCrafter2 Opensource Tencent
Thelistsoftext-to-imageandtext-to-videomodelscovered StableVideoDiffusion Opensource StabilityAI
byK-SortArenaareshowninTable2andTable3,respec- Zeroscope-v2-xl Opensource Cerspense
LaVie Opensource ShanghaiAILab
tively. Thedataisinnoparticularorder. Wewillcontinue
Animate-Diff Opensource CUHKetc.
to add new models. In the future, besides distilled mod-
els[37,45],wealsoplantoincludetheevaluationofmod-
els that are compressed through quantization [27–30] and
pruning[8,15].
pairwise comparisons. This means our voting process can
D.AnalysisofVotes beapproximatelyconvertedtoover6,000pairwisecompar-
isons. Figure 9 illustrates the number of comparisons in
After several months of internal testing, we have collected whicheachmodelisinvolved,withthedatarepresentingthe
over 1,000 votes from experts in the field of visual gener- number of pairwise comparisons after conversion. Thanks
ation. Note that in each vote, four models participate in a to the UCB algorithm and the pivot specification strategy,
free-for-allcomparison,whichisequivalentto K(K−1) =6 allmodelsarefullyandbalancedevaluated.
2
2450
300
150
0
0 6 12 18 24
Model ID
Figure 9. The number of comparisons in which each model is
involved. ModelIDsarealignedwiththeorderinTable2. The
dataisasofAug2024.
E.InterfaceLayout
K-Sort Arena is served by Huggingface Space, and we
carefully design the interface based on gradio to achieve a
proper layout and user-friendly interaction. The interface
layoutisshowninFigure10. First, wedescribetheinitial
interfacebeforemodelrunning,whichisdividedintothree
mainregions.
• Region⃝1 describesthebackgroundoftheprojectandthe
evaluationrules,andservesasaguideforuserstovote.
• Region ⃝2 is the prompt input window, which allows
users to enter their own prompts or click “Random
Prompt”torandomlyselectfromthedatapool.
• Region ⃝3 is some completed samples, including the
prompt-imagesamplepairs,whichallowuserstoquickly
completeanexperiencewithoutrunningthemodel.
Afterfinishingthemodelrunning,theinterfaceautomat-
icallyjumpstothevotinginterface. Itsupportstwovoting
modes,anduserscanclick“Mode”toswitchbetweenthem.
• In Rank Mode, there are 4 buttons below each image to
indicateitsrank. Wheneverauserclicksonit,theimage
isretouchedwithresponsivebordersandmarkup.
• InBestMode,userscanchoosethebestmodeloratie.
F.Acknowledgement
We would like to express our gratitude to all those who
contributedtheirtime,expertise,andinsightsduringthein-
ternal testing phase. Listed in no particular order: Collov
Labs; Daquan from NUS; Yang Zhou from CMU; Vijay
Anand from Texas A&M University; Ying Li, Chun-Kai
Fan,MenghangDongandAosongChengfromPekingUni-
versity HMI Lab; Yinglong from Meituan; Yinsheng Li
fromShao’sLab;MingfeiGuofromStanford;andChenyue
Cai from Princeton. We are profoundly grateful for their
commitment and the unique perspectives they brought to
thisproject.
3
snosirapmoc
fo
rebmuN①
②
③
(a)Displayoftheinitialinterface.
(b)Displayofthevotinginterface.
Figure10.InterfaceofK-SortArenaservedbyHuggingfaceSpace.
4