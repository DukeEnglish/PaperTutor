Explicit Inductive Inference using Large Language Models
TianyangLiu TianyiLi LiangCheng MarkSteedman
UniversityofEdinburgh
T.Liu-47@sms.ed.ac.uk tianyi.li@ed.ac.uk
L.Cheng-13@sms.ed.ac.uk m.steedman@ed.ac.uk
Abstract
LargeLanguageModels(LLMs)arereported
to hold undesirable attestation bias on infer-
encetasks: whenaskedtopredictifapremise
P entails a hypothesis H, instead of consid-
eringH’sconditionaltruthfulnessentailedby
P,LLMstendtousetheout-of-contexttruth
label of H as a fragile proxy. In this paper,
weproposeapipelinethatexploitsthisbiasto
do explicit inductive inference. Our pipeline
usesanLLMtotransformapremiseintoaset
ofattestedalternatives,andthenaggregatean-
swersofthederivednewentailmentinquiries Figure 1: An example of the explicit inductive infer-
tosupporttheoriginalinferenceprediction. On ence pipeline. While direct entailment inquiry gets a
adirectionalpredicateentailmentbenchmark, wronganswer,itcanbecorrectedbyreasoningonmore
we demonstrate that by applying this simple alternativeexamples.
pipeline, we can improve the overall perfor-
cantperformancedropwhentheentailmentlabels
manceofLLMsoninferenceandsubstantially
alleviatetheimpactoftheirattestationbias.1 disagreewiththeattestationlabelofhypothesisH.
AlthoughthisisasevereproblemlimitingLLMs’
1 Introduction performanceonnon-attestedinferences,weargue
that with careful design, this bias can instead be
Large Language Models (LLMs) are claimed to
exploitedtoimproveLLMperformanceoninfer-
possessimplicitinductivereasoningabilitythrough
encetasks. Wenoticeastatisticallytrueconclusion:
pre-training: fromthemassiveexamplestheymem- Given an entailment inquiry P |= H, the attesta-
orized,theydrawinferencerulesandencodethem tionbiasisharmfulonlywhenthepremiseP isnot
latently so that they can apply these rules to do attested. IfwecontrolP toalwaysbeattested,then
reasoningattesttime. P |= H will naturally share the same truth label
However,recentlyMcKennaetal.(2023a)has withH onadistributionalbasis, whichdissolves
pointedoutthatLLMsareseverelyaffectedbyan thenegativeeffectsofLLMs’attestationbias.
attestation bias when performing inference tasks.
Applyingthisidea,weproposeasimpleyetef-
Given the question of whether premise P entails
fectiveExplicitInductiveInferencepipelinewith
hypothesisH withfew-shotexamples,anLLM’s
LLMs. AsillustratedinFigure1,thecoreideais
predictionisdeeplyboundtothehypothesis’out-
totransformapremiseintoasetofattestedalterna-
of-context truthfulness, instead of its conditional
tivesbyreplacingthearguments,andtoaggregate
truthfulness entailed by the premise. When the
theLLM’spredictionsonthesederivedinquiriesto
hypothesisH isattestedinanLLM’sworldknowl-
supportansweringtheoriginalquestion.
edge(theLLMbelievesH tobetrue),theLLMis
We test our pipeline with two LLMs on
likelytopredicttheentailmenttobetrue,regardless
Levy/Holt(LevyandDagan,2016;Holt,2019),a
ofthepremise. Asaresult,LLMssufferasignifi-
difficultdirectionalpredicateinferencedataset,and
furtheranalyzetheinfluenceofourpipelineagainst
1Codesanddataofthispaperareavailableathttps://
github.com/waterltyang/EIDI themodels’attestationbias. Theresultsshowthat
4202
guA
62
]LC.sc[
1v76441.8042:viXraourpipelinecanimprovenotonlyLLM’soverall Thegoalistopredictwhetherthepremisetriple
performanceonpredicateinference,butalsotheir entailsthehypothesistriple,namelythetruthlabel
robustnessagainsttheattestationbias. of(s,p,o) |= (s,h,o). TouseanLLMtopredict
Tosummarizeourcontribution,weproposean entailments,eachinputtriplepairwillbewrapped
easy-to-use inference pipeline that 1) improves into a prompt. We mark them as Q[(s,p,o) |=
LLMs’performanceonpredicateinference,2)sub- (s,h,o)]andcallthementailmentinquiries.
stantiallyalleviatesnegativeeffectsoftheLLMs’
3.2 ExploittheAttestationBias
attestationbias,and3)usesLLMs’owngeneration
capabilitywithoutrequiringexternalknowledge. AsstatedinSection1,theattestationbiasofLLMs
canbelessdetrimentalifthepremiseP isattested
2 RelatedWork
inanentailmentinquiry,becausethetruthlabelof
P |= H wouldlikelybethesameastheattestation
LLMs accumulate a bias towards factual knowl-
label of H. Besides this, two more insights are
edgebyencodingmassivefactsduringpre-training
guidingourpipelinedesign:
(Robertsetal.,2020;Carlinietal.,2022;Yanetal.,
1) The label of a predicate entailment inquiry
2022). Recently,McKennaetal.(2023a)pointed
does not change when the argument entities are
out that LLMs suffer from an attestation bias on
replaced, aslongasthesubstitutionentitieskeep
inferencetasksasaresult. Notethattheeffectof
thesamesemantictypelabels.
attestationbiasissimilartothatofthehypothesis-
2)Factual̸=Attested. Factualknowledgefrom
only baseline (Poliak et al., 2018), but while the
external sources may not be confirmed by LLMs
formerisabiasfrompre-training,thelatterorigi-
for being longtail, absent in pre-training data, or
natesfromdatasetartifactsinsupervisedlearning.
conflicted with out-of-date records. Facts gener-
Inothertasks,previousworkhasmitigatedthe
atedbyLLMs,ontheotherhand,arehighlylikely
biastowardsattestationbyintroducingcounterfac-
to be recognizable by themselves. Even halluci-
tual examples (Wang et al., 2022b; Zhou et al.,
natedgenerationsareacceptablesincetheyarestill
2023; Wang et al., 2023) or replacing argument
attestedifnotfactual.
entities with their type labels (Zhou et al., 2024).
Based on these understandings, we propose
Inthispaper,wegoonestepfurthertoshowthatin
the Explicit InDuctive Inference (EIDI) pipeline.
aninferencetask,weshouldinsteadencouragethe
Given an entailment inquiry P |= H, our EIDI
modelstogeneratefactualalternativeexamples.
pipeline first transforms P into a set of different
The idea of aggregating multiple versions of
attestedpremisesP′sbyreplacingthearguments
LLMs’ outputs has been explored in prior work.
ofP. ThenthecorrespondingsetofH′sisderived,
Wangetal.(2022a)encourageLLMstogenerate
sothatwenowhavealistofalternativeinquiries
multiple reasoning paths for one question, while
P′ |= H′. Finally, we explicitly do an inductive
Zhouetal.(2022)embodyonequestionwithmul-
inferenceonthesenewinquiriesbydrawingacon-
tipleprompts. Incontrast,ourmethodcreatesse-
cluded entailment prediction from an LLM’s an-
mantically different alternative questions, which
swerstothesealternativeinquiries.
serveasextraevidenceforanoriginalinquiry.
ItisworthmentioningthatgivenP istrue,logi-
3 ExplicitInductiveInference cally,H isalwaystrueifP |= H butnotviceversa.
WecanonlystatisticallyconjectureP |= H ifwe
3.1 TaskandDefinition
observe a high probability of H being true (pre-
Thetaskofthisworkistodeterminetheentailment dictedbytheLLMaccordingtothebias). There-
relationbetweentwobinarypredicateswhereboth fore, weencouragethetransformationmoduleto
predicatesarecontextualizedwiththesamepairof generateavarietyofdifferentalternativepremise
entities. Theinputwillbeintheformoftwotriples triples, so that a more reliable conclusion can be
(s,p,o)−(s,h,o)wheresisthesubjectentity,o drawnwhenweaggregatethepredictions.
istheobjectentity,pisthepremisepredicate,and
3.3 ExplicitInductiveInferencePipeline
histhehypothesispredicate. Therearealsocases
in the form of (s,p,o)−(o,h,s) where the two Typing Whilethelabelof(medicineX,kills,dis-
entitiesareswappedinpositionliketheexamplein easeY)|=(medicineX,isacureof,diseaseY)is
Figure1. Withoutlossofgenerality,wedescribe True,onecannotthereforededucethat(PersonX,
ourmethodwithinputsintheformerformat. kills,animalY)|=(PersonX,isacureof,AnimalY).Topreventtheseerrorsincitedbytheambiguity reportresultsonboththedirectionaltestsetandits
ofpredicates,foreachpremisetriple(s,p,o),we twosubsetsinSection5.
querytheLLMtoobtaintheentitytypelabelofthe
subjectandobjectt andt . Herewedonotprede- 4.2 LLMs
s o
fineavocabularyforpossibletypelabelssincethe
WetestourmethodwithtwoLLMs,GPT-3.5and
purposeisonlytodisambiguate.
Llama3. GPT-3.5(OpenAI,2023)isasetofpow-
erfulclosed-sourcecommercialLLMs. Wechoose
Transformation With these assigned type la-
theGPT-3.5-Turboversionforitswidespreaduse
bels we query the LLM to generate alternative
intheresearchcommunity. Llama3(Meta,2024)
arguments for the premise predicate. From one
is a SOTA open-source LLM, where we choose
typed premise triple (s,t ,p,o,t ), we encour-
s o
thelargestLlama3-70B-instructversionforitsop-
age the LLM to generate a list of new attested
timizedcapacity. Throughoutourexperiments,we
triples (s ,p,o ),...,(s ,p,o ) where the substi-
1 1 n n
usegreedydecodingforreproducibleresults.
tution entities keep the original types, i.e. any
Our pilot studies on the development set indi-
s still has type t and any o still has type t .
i s i o
catethataddingfew-shotexamplesinthepredic-
Thesennewpremisetripleswillthenbeexpanded
tionmodulemayaddextrabiastothemodel,and
to n new entailment inqueries Q[(s ,p,o ) |=
1 1
thereforeintroduceunnecessaryconsiderationson
(s ,h,o )],...,Q[(s ,p,o ) |= (s ,h,o )].
1 1 n n n n
findingproperexamplesundereachsetting. Hence
Prediction Atthispoint,weinputeachderived we choose zero-shot prompts for the prediction
entailment inquiry Q[(s ,p,o ) |= (s ,h,o )] to moduleandone-shotpromptsforthetransforma-
i i i i
theLLMtogettheirresponseandcorresponding tionmodulewheretheonlyexampleistheoriginal
probabilityscore. Thenwetaketheaveragescore premise. Discussiononpromptselectionandalist
ofthesendifferentscoresasourexplicitinductive ofallpromptsweuseareincludedinAppendixA.
scorefortheoriginalentailmentinquiry.
4.3 BaselinesandMetric
4 ExperimentalSetup
WecompareEIDIagainsttwobaselines. Wecon-
structMCQ baselinebydirectlywrappingthe
entity
4.1 Datasets
originalpremiseandhypothesiswiththeMultipe-
We test our pipeline on the Levy/Holt dataset Choice Question prompt used in our prediction
(Levy and Dagan, 2016; Holt, 2019), a predicate module, and passing it to the LLM to get an en-
entailment dataset where each entry consists of tailment prediction. MCQ baseline is set up
type
two triples in the form of (s,p,o) − (s,h,o) or inthesamewaywheretheonlydifferenceisthat
(s,p,o) − (o,h,s), and a following label shows wefirstreplacetheargumentsofthepredicatesby
whether the premise triple entails the hypothesis theirentitytypes. Tokeepourselvesalignedwith
triple. Weusethedirectionalportionofthisdataset previouswork,weusethe48FIGERtypes(Ling
followingpriorwork(McKennaetal.,2023b;Chen andWeld,2012)asinMcKennaetal.(2023a)for
etal.,2022;Lietal.,2022),asitisachallenging thismeasure,insteadoftheLLM-generatedtypes
test focused on the understanding of entailment inSection3.3.
beyondbi-directionalsimilarity. Wedrawtheprecision-recallcurveforEIDIand
Following McKenna et al. (2023a), we further eachbaselinebyinspectingthefinaloutputtoken
analyzehowtheLLMs’attestationbiasisdigested probability of the model’s response. As a result
inourmethod. WesplittheLevy/Holtdatasetac- ofthemultiple-choicepromptdesign,returnedan-
cording to whether the label of P |= H agrees swersalwaysstartwithachoicemarkwhereAis
with the attestation label (obtained by querying for entailment and B is for non-entailment. For
the LLM) of H for each entry. For the 1784 en- baselinemethods,wescorethatonetoken’sprob-
tries in the full directional test set, this yields an ability. For our EIDI pipeline, we calculate the
attestation-consistentsubsetof956entriesandan averagescoreofthek outputtokens’probabilities.
attestation-adversarialsubsetof828entries.2 We Following Li et al. (2022); McKenna et al.
(2023a), we calculate the normalized area-under-
2Thesubstantialsizeoftheattestation-adversarialsubset
curve (AUC ) as an indicator of the model’s
demonstratesthedetrimentaleffectofattestationbiasinreal norm
datasets. performance. This measure describes how muchModel Model Pipeline cons. adv. diff.
Pipeline GPT-3.5 Llama3 GPT-3.5 MCQ 82.04 0.00 -82.04
entity
MCQ 69.40 0.48 -68.92
MCQ 23.85 36.66 type
entity
EIDI 56.14 9.97 -46.17
MCQ 25.88 35.13 all
type
EIDI 53.73 8.95 -44.78
EIDI 35.52 50.89 1
all
Llama3 MCQ 81.08 0.01 -81.07
EIDI 31.16 41.85 entity
1
MCQ 70.25 2.41 -67.84
EIDI 32.10 46.75 type
2
EIDI 69.59 23.83 -45.76
EIDI 33.41 49.61 all
5
EIDI 63.98 15.66 -48.32
1
Table1: OverallnormalizedArea-Under-the-Curve(%)
Table 2: AUC (%) on the attestation-bias-split
ofourEIDIpipelineandthetwobaselinesonthefull norm
datasets. The diff. column marks the difference be-
Levy/Holt directional test set. EIDI inspects only i
i
tweenresultsontheattestation-consistent(cons.) and
alternativeinquiries,andEIDI considersallexamples
all
attestation-adversarial(adv.) subsets.
obtainedinthetransformationstep.
biasbyover20%fromtheMCQ baseline,and
betteramodelisoveradegeneratebaselinereturn- type
over35%fromtheMCQ baselineinaverage.
ingpositiveanswerstoeverydataentry. entity
With both LLMs, we observe an AUC of
norm
5 ResultsandDiscussion near0%inthetwobaselinesettings,demonstrating
the extreme inability of the LLMs to capture the
5.1 Overallperformance essential entailment signal against the attestation
biasinazero-shotsetting.
Table1showstheperformanceofeachmodelon
InterestingresultsappearagainundertheEIDI
thedirectionalLevy/Holttestset. WithbothLLMs, 1
setting. OnGPT-3.5-turbo,itslightlyoutperforms
our EIDI pipeline gains a significant improve-
all
theEIDI setting. Butthisonlyhappensbecause
mentoverthetwobaselinemethods. all
EIDI setting is doing better on the attestation-
Thetypicalvalueofthesizeoftotalgenerated all
consistent subset, which implies that EIDI set-
examplesnis10fortheEIDI setting. Itcanbe all
all
tingisstillthechoiceforbestperformance,while
observed that the performance of EIDI steadily
i
EIDI isalsoastrongcandidateforscenarioswith
increasesalongwithi,confirmingourhypothesis 1
limitedcompute.
thatwithattestedP′s,themorecasesofalternative
P′ |= H′ generated,themorereliableourpipeline These results suggest that our pipeline can be
usedtoimproveLLMs’generalinferenceperfor-
is. The complete results of all EIDI settings are
i
mance,andespeciallyinattestation-adversarialsce-
showninAppendixB.
narios, e.g. If lions are fed on hay, then lions eat
Aninterestingobservationliesbetweentheper-
hay. AsareplacementtoLLM’sdirectinference
formance of the EIDI setting and the baselines,
1
prediction,EIDIpipelinecanbeeasilypluggedinto
which shows that replacing the original inquiry
frameworkswithLLMstodovariousdownstream
withevenoneself-generatedexamplecanimprove
taskslikequestionansweringandKGcompletion.
theLLMs’predicateinferenceperformance. The
difference between EIDI and MCQ baseline
1 type 6 Conclusions
alsohighlightstheimportanceofinstantiatingat-
tested triples. Since the effect of the attestation
Weproposeanexplicitinductivepipelineexploit-
bias is already excluded from the results of the
ingtheattestationbiasofLLMstodomorerobust
MCQ ,thisprovesthattheEIDIpipelineistak-
type predicate inference. With experiments on the di-
ingadvantageoffurtherexploitingthebias.
rectionalLevy/Holtdatasetanditsattestation-bias-
splitsubsets,wehaveshownthatourbaselinegains
5.2 Againstthebias
asignificantimprovementoverLLM’sprimaryin-
Table2comparestheperformanceofeachmethod ferenceperformance,andsubstantiallyreducesthe
on attestation-consistent (cons.) and attestation- performancelosscausedbyLLMs’attestationbias.
adversarial (adv.) subsets. Measured by the dif- Without external knowledge, EIDI use LLMs’
ferenceofAUC betweenthetwosubsets,our owngenerationtoexploittheirattestationbias. Our
norm
pipeline reduces the effect of LLMs’ attestation results suggest that although biases of LLMs areusually undesirable obstacles, in some scenarios poorlearnersofdirectionalinference. InFindings
they may be tapped for good with careful design. of the Association for Computational Linguistics:
EMNLP2022, pages903–921, AbuDhabi, United
Weadvocateforsimilarideastobeappliedtoother
ArabEmirates.AssociationforComputationalLin-
taskstoimproveLLMperformanceinfuturework.
guistics.
Limitations XiaoLingandDanielWeld.2012. Fine-grainedentity
recognition. InProceedingsoftheAAAIConference
In this paper, we demonstrated the performance onArtificialIntelligence,volume26,pages94–100.
of our pipeline by comparing it to two baselines.
NickMcKenna,TianyiLi,LiangCheng,Mohammad
Althoughweintendtoexcludepromptengineering
Hosseini,MarkJohnson,andMarkSteedman.2023a.
factors from our analysis, it has been widely ac- Sourcesofhallucinationbylargelanguagemodels
ceptedthatincludingfew-shotexamplesandother on inference tasks. In Findings of the Association
prompting techniques can guide LLMs to output
forComputationalLinguistics: EMNLP2023,pages
2758–2774, Singapore. Association for Computa-
better answers. Therefore there could be further
tionalLinguistics.
studiesonevaluatingtheeffectsofusingdifferent
promptsintheEIDIpipeline. Nick McKenna, Tianyi Li, Mark Johnson, and Mark
Steedman.2023b. Smoothingentailmentgraphswith
Generatingalternativeinquiriesandrespectively
languagemodels. InProceedingsofthe13thInter-
doinginferencesonthemcanbecomputationally
nationalJointConferenceonNaturalLanguagePro-
expensivecomparedtoonlyonedeterminationin cessingandthe3rdConferenceoftheAsia-Pacific
baselinesettings. Asaresult,downstreamapplica- Chapter of the Association for Computational Lin-
guistics (Volume 1: Long Papers), pages 551–563,
tionsmayfindatrade-offbetweencomputational
NusaDua,Bali.AssociationforComputationalLin-
efficiencyandbetterinferenceperformance.
guistics.
Wealsotestedourpipelineagainstthefrequency
biasthatMcKennaetal.(2023a)pointedout,and Meta.2024. Llama3.
the results show that the EIDI pipeline amplifies
OpenAI.2023. Openai.
thisbiascomparedtothebaselinesduetoitschoice
Adam Poliak, Jason Naradowsky, Aparajita Haldar,
ofpopularentities. Wearguethatthisreaffirmsthe
RachelRudinger,andBenjaminVanDurme.2018.
challenge in achieving Pareto improvements on
Hypothesisonlybaselinesinnaturallanguageinfer-
LLM robustness against biases, and leave those ence. In Proceedings of the Seventh Joint Confer-
resultsanddiscussionstoAppendixC. enceonLexicalandComputationalSemantics,pages
180–191,NewOrleans,Louisiana.Associationfor
ComputationalLinguistics.
References
AdamRoberts,ColinRaffel,andNoamShazeer.2020.
NicholasCarlini,DaphneIppolito,MatthewJagielski, Howmuchknowledgecanyoupackintotheparam-
KatherineLee,FlorianTramer,andChiyuanZhang. eters of a language model? In Proceedings of the
2022. Quantifyingmemorizationacrossneurallan- 2020ConferenceonEmpiricalMethodsinNatural
guagemodels. arXivpreprintarXiv:2202.07646. LanguageProcessing(EMNLP),pages5418–5426,
Online.AssociationforComputationalLinguistics.
ZhibinChen,YansongFeng,andDongyanZhao.2022.
Entailment graph learning with textual entailment Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou,
andsofttransitivity. InProceedingsofthe60thAn- and Muhao Chen. 2023. A causal view of entity
nualMeetingoftheAssociationforComputational biasin(large)languagemodels. InFindingsofthe
Linguistics (Volume 1: Long Papers), pages 5899– AssociationforComputationalLinguistics: EMNLP
5910,Dublin,Ireland.AssociationforComputational 2023,pages15173–15184,Singapore.Association
Linguistics. forComputationalLinguistics.
XavierHolt.2019. Probabilisticmodelsofrelational Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc
implication. Preprint,arXiv:1907.12048. Le,EdChi,SharanNarang,AakankshaChowdhery,
andDennyZhou.2022a. Self-consistencyimproves
Omer Levy and Ido Dagan. 2016. Annotating rela- chainofthoughtreasoninginlanguagemodels. arXiv
tioninferenceincontextviaquestionanswering. In preprintarXiv:2203.11171.
Proceedings of the54th Annual Meeting of the As-
sociationforComputationalLinguistics(Volume2: Yiwei Wang, Muhao Chen, Wenxuan Zhou, Yujun
ShortPapers),pages249–255,Berlin,Germany.As- Cai, Yuxuan Liang, Dayiheng Liu, Baosong Yang,
sociationforComputationalLinguistics. JunchengLiu,andBryanHooi.2022b. Shouldwe
relyonentitymentionsforrelationextraction? debi-
TianyiLi,MohammadJavadHosseini,SabineWeber, asingrelationextractionwithcounterfactualanalysis.
and Mark Steedman. 2022. Language models are InProceedingsofthe2022ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-
tionalLinguistics: HumanLanguageTechnologies,
pages3071–3081,Seattle,UnitedStates.Association
forComputationalLinguistics.
Jun Yan, Yang Xiao, Sagnik Mukherjee, Bill Yuchen
Lin, Robin Jia, and Xiang Ren. 2022. On the ro-
bustnessofreadingcomprehensionmodelstoentity
renaming. In Proceedings of the 2022 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies,pages508–520,Seattle,UnitedStates.
AssociationforComputationalLinguistics.
Ben Zhou, Hongming Zhang, Sihao Chen, Dian Yu,
HongweiWang,BaolinPeng,DanRoth,andDong
Yu. 2024. Conceptual and unbiased reasoning in
languagemodels. arXivpreprintarXiv:2404.00205.
ChuntingZhou,JunxianHe,XuezheMa,TaylorBerg-
Kirkpatrick,andGrahamNeubig.2022. Promptcon-
sistencyforzero-shottaskgeneralization. InFind-
ingsoftheAssociationforComputationalLinguistics:
EMNLP2022,pages2613–2626,AbuDhabi,United
ArabEmirates.AssociationforComputationalLin-
guistics.
Wenxuan Zhou, Sheng Zhang, Hoifung Poon, and
Muhao Chen. 2023. Context-faithful prompting
for large language models. In Findings of the As-
sociation for Computational Linguistics: EMNLP
2023,pages14544–14556,Singapore.Association
forComputationalLinguistics.A PromptsSelection
Model
Here we list all the prompts that we use in our Pipeline GPT-3.5 Llama3
experiments.
MCQ 23.85 36.66
entity
MCQ 25.88 35.13
Typing Thepurposeofthismoduleisonlytodis- type
ambiguatethepredicates,thereforenovocabulary EIDI 31.16 41.85
1
ofallowedtypelabelsispredefined. EIDI 32.10 46.75
2
EIDI 31.47 47.52
3
Typetheentitiesinthefollowingtriples: EIDI 32.05 48.60
4
EIDI 33.54 49.61
Hitler|wasbornin|Poland->aperson| 5
EIDI 33.41 50.42
wasbornin|acountry 6
EIDI 34.68 50.13
7
Hogs|eats|Corn->ananimal|eats|a
EIDI 34.76 50.36
8
food
EIDI 35.28 50.39
9
Aspirin|mayreducetheriskof|Cancer EIDI 10 35.52 50.01
->amedicine|mayreducetheriskof|a EIDI 11 - 50.52
disease EIDI 12 - 50.89
{s}|{p}|{o}->
Table3: AUC (%)ofallEIDI settings.
norm i
Transformation Although we use the word
’fact’, the generated triples are always attested C FrequencyBias
ratherthanfactual.
Wealsotestedourpipelineonthefrequencybias
Write{n+1}factsintheformof"{t } using the same dataset split measure as that for
s
|{p}|{t }." attestation bias. The dataset that we use is from
o
McKenna et al. (2023a)’s work, where we have
-{s}|{p}|{o}.
972entriesoffrequency-consistentinputand220
- entriesoffrequency-adversarialinput.
Comparedtobaselines,theEIDIpipelineintro-
Prediction This is also used for the two base-
ducesextrafrequencybias. Thisisexpectedsince
lines.
ourtransformationmoduleisnotdesignedtoalter
the relative frequency of the predicates, and may
Question:If {s} {p} {o}, then {s} {h}
haveamplifiedthefrequencybiasbytakingpopular
{o}. Isthattrueorfalse?
alternativeentitiesgeneratedbytheLLMs. Thisre-
Choices: sultreaffirmsthechallengingnatureofdirectional
inferenceandthedifficultyinimprovingrobustness
A)True
againstmultiplebiasesatonce.
B)False
Answer: Model Pipeline cons. adv. diff.
GPT-3.5 MCQ 20.58 29.38 +8.80
entity
For prediction module, when an instruction is
MCQ 24.49 32.93 +8.44
type
required,weusethefollowingone:
EIDI 40.66 20.83 -19.83
all
EIDI 33.94 18.83 -15.11
1
Only return one mark A, B or C to an-
Llama3 MCQ 33.30 47.87 +14.57
swerthequestion. entity
MCQ 31.47 47.19 +15.72
type
B ResultsonallEIDI Settings EIDI all 51.97 42.27 -9.70
i
EIDI 39.78 35.32 -4.46
1
Table 3 shows the performance of all EIDI set-
i
tings. Best performences are reached when all Table 4: Normalized area-under-curve(%) on the
transformedalternativeinquiriesareconsidered. frequency-bias-splitdatasets.D ComputationalCost
Our experiments on Llama3-70B-Instruct are ap-
plied on two A6000 GPUs. For 1784 entries and
10 alternative inquiries for each entry, the typing
module takes about 3 GPU hour, the transforma-
tionmoduletakesabout100GPUhours, andthe
predictionmoduletakesabout6GPUhours.