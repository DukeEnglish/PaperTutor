The Complexity of Sequential Prediction in Dynamical Systems
Vinod Raman∗, Unique Subedi∗, and Ambuj Tewari
Department of Statistics, University of Michigan
{vkraman, subedi, tewaria}@umich.edu
Abstract
We study the problem of learning to predict the next state of a dynamical system
when the underlying evolution function is unknown. Unlike previous work, we place no
parametricassumptionsonthedynamicalsystem, andstudytheproblemfromalearning
theoryperspective. Wedefinenewcombinatorialmeasuresanddimensionsandshowthat
theyquantifytheoptimalmistakeandregretboundsintherealizableandagnosticsetting
respectively.
1 Introduction
A discrete-time dynamical system is a mathematical model that describes the evolution of
a system over discrete time steps. Formally, a discrete-time dynamical system is a tuple
(N,X,f), where N is the set of natural numbers that denote the timesteps, X is a non-empty
set called the state space, and f : X → X is a deterministic map that describes the evolution
of the state. Dynamical systems have been widely used in practice due to their ability to
accurately model natural phenomena. For instance, boolean networks are an important class
of discrete-time, discrete-space dynamical systems with widespread applicability to genetic
modeling [Kauffman, 1969, Shmulevich et al., 2002]. In a boolean network, the state space
is X = {0,1}n with |X||X| = (2n)2n possible evolution functions. For genetic modeling,
n is taken to be the number of genes and x ∈ X indicates the expression of all n genes
under consideration. As an example, “1” could represent the gene with a high concentration
of a certain protein, and “0” could represent the gene with a low concentration. With such
formulation,onecanstudyhowthestateofthesegenesevolvesovertimeundercertainmedical
interventions. Beyond genetics, dynamical systems have been used in control [Li et al., 2019],
computervision[Dorettoetal.,2003], andnaturallanguageprocessing[Sutskeveretal.,2014,
Belanger and Kakade, 2015].
In this work, we consider the problem of predicting the next state of a dynamical system
whentheunderlyingevolutionfunctionisunknown[Ghaietal.,2020]. Tocapturethesequen-
tial nature of dynamical systems, we consider the model where the learner plays a sequential
game with nature over T rounds. At the beginning of the game, nature reveals the initial
state x ∈ X. In each round t ∈ [T], the learner makes its prediction of the next state xˆ ∈ X,
0 t
nature reveals the true next state x ∈ X, and the learner suffers loss 1{xˆ ̸= x }. Given an
t t t
evolution class F ⊆ XX, the goal of the learner is to output predictions of the next state such
that its regret, the difference between its cumulative mistakes and the cumulative mistakes of
the best-fixed evolution in hindsight (defined formally in Section 2.2), is small. The class F
∗Equal contribution
1
4202
beF
9
]GL.sc[
1v41660.2042:viXrais said to be learnable if there exists a learning algorithm whose regret is a sublinear function
of the time horizon T.
Although we allow the state space X to be arbitrary, we only consider the 0-1 loss, which
may be more appropriate for discrete-space dynamical systems. However, even discrete-space
dynamical systems can be very expressive, capturing complex natural processes [Hoekstra
etal.,2010]. Oneimportantexampleofsuchdynamicalsystemsiscellularautomata[Wolfram,
1986]. Ad-dimensionalboolean cellularautomataisdefinedonastatespaceX =
{0,1}Zd,
the
set of {0,1}-valued d-dimensional square grids defined using d-dimensional integer lattices.
Square grids are called the cells and the boolean values in the cells are referred to as automa-
ton. Theevolutionfunctionf isdefinedusingalocalupdatingrule h : {0,1}×{0,1}n → {0,1},
where the automaton of the cell at time t+1 depends on the automaton of the cell as well as
the automata of all the neighboring cells at time t. Here, n is the number of neighboring cells.
Since n = 3d−1, there are 23d possible local updating rules and thus evolution functions for
d-dimensional boolean cellular automata. Since the pioneering work of [von Neumann, 1966],
who used it to model biological self-reproduction, cellular automata have been widely used in
complex systems modeling [Batty, 2005, Barberousse and Imbert, 2013, Xiao et al., 2011].
Given any learning problem (X,F), we aim to find necessary and sufficient conditions for
the learnability of F while also quantifying the minimax rates under two notions of expected
regret: Markovian and Flow regret. To that end, our main contributions are summarized
below.
(i) We provide a qualitative and sharp quantitative characterization of learnability in the
realizable setting, when there exists an evolution function in the class F that generates
thesequenceofstates. Ourcharacterizationisintermsoftwonewcombinatorialobjects:
the Evolution complexity and Evolution dimension. We use these complexity measures
tocomputetheminimaxexpectedmistakesforthreeclassesoflineardynamicalsystems.
(ii) We show that all rates are possible for the minimax expected mistakes when learning
dynamical systems in the realizable setting. This is in contrast to online multiclass clas-
sification where only two rates are possible. Nevertheless, we show that a combinatorial
parameter termed the Branching dimension characterizes constant minimax expected
mistakes.
(iii) In the agnostic setting under Markovian regret, we show that the Littlestone dimension
provides a characterization of learnability. As a corollary, we establish a separation
between realizable and agnostic learnability under Markovian regret.
(iv) We show that the separation between realizable and agnostic learnability continues
to hold when considering Flow regret. However, if the evolution class has uniformly
bounded projections, then we show that realizable and agnostic learnability under Flow
regret are equivalent.
For(i),ourboundsontheminimaxexpectedmistakesintermsoftheEvolutioncomplexity
are constructive. For the upperbound, we construct a minimax optimal algorithm. For the
lowerbound,weconstructahardtrajectory. For(ii),givenanyrate,weconstructanevolution
class whose minimax expected mistakes matches this rate. To prove (iii), our bounds on
the minimax expected regret are also constructive. For the upperbound, we show that the
Littlestonedimensionissufficientbyreducinglearningdynamicalsystemstoonlinemulticlass
classification. To show that the Littlestone dimension is necessary, we also construct a hard
trajectory. To establish the separation between realizable and agnostic learnability, we give a
classthatislearnableintherealizablesettingbutnotintheagnosticsettingunderMarkovian
regret.
21.1 Related Works
There hasbeena longline ofwork studyingpredictionand regretminimization whenlearning
unknowndynamicalsystems[Hazanetal.,2017,2018,Ghaietal.,2020,Lee,2022,Rashidine-
jad et al., 2020, Kozdoba et al., 2019, Tsiamis and Pappas, 2022, Lale et al., 2020]. However,
these works focus on prediction for fully/partially-observed linear dynamical systems under
various data-generating processes. Moreover, there is also a line of work on regret minimiza-
tionforlineardynamicalsystemsforonlinecontrolproblems[Abbasi-YadkoriandSzepesv´ari,
2011, Cohen et al., 2018, Agarwal et al., 2019]. For non-linear dynamical systems, there has
been some applied work studying data-driven approaches to prediction [Wang et al., 2016,
Korda and Mezi´c, 2018, Ghadami and Epureanu, 2022]. Regret minimization for non-linear
dynamical systems has mainly been studied in the context of control [Kakade et al., 2020,
Muthirayan and Khargonekar, 2021].
Another important line of work is that of system identification and parameter estimation
[˚Astr¨om and Eykhoff, 1971, Ljung, 1999]. Here, the goal is to recover and estimate the
parameters of the underlying evolution function from the observed sequence of states. There
is a long history of work studying system identification in both the batch [Campi and Weyer,
2002,VidyasagarandKarandikar,2006,Fosteretal.,2020,SattarandOymak,2022,Bahmani
and Romberg, 2020] and streaming settings [Kowshik et al., 2021a,b, Giannakis et al., 2023,
Jain et al., 2021]. Several works have also considered the problem of learning the unknown
evolution rule of dynamical systems defined over discrete state spaces. For example, Wulff
and Hertz [1992] train a neural network on a sequence of observed states to approximate the
unknown evolution rule of a cellular automaton. Grattarola et al. [2021] extend this work
to learning the unknown evolution rule of a graph cellular automaton, a generalization of
a regular cellular automaton, using graph neural networks. [Qiu et al., Rosenkrantz et al.,
2022]alsoconsidertheproblemofPAClearningadiscrete-time,finite-spacedynamicalsystem
defined over a (un)directed graph.
A related direction to our work is online learning for time series forecasting, where autore-
gressive models are used to predict the next state [Anava et al., 2013, 2015, Liu et al., 2016,
Yangetal.,2018]. Finally,thereisarichhistoryofcharacterizinglearnabilityintermsofcom-
plexity measures and combinatorial dimensions in learning theory [Vapnik and Chervonenkis,
1971, Littlestone, 1987, Natarajan, 1989, Kearns and Schapire, 1994, Bartlett and Mendelson,
2002, Daniely et al., 2011, Daniely and Shalev-Shwartz, 2014, Rakhlin et al., 2015].
2 Preliminaries
2.1 Discrete-time Dynamical Systems
A discrete-time dynamical system is a tuple (N,X,f), where N is the set of natural numbers
denoting the time steps, X is a non-empty set called the state space, and f : X → X is a
deterministic map that defines the evolution of the dynamical system. That is, the (t+1)-th
iterateofthedynamicscanbeexpressedintermsoft-thiterateusingtherelationx = f(x ).
t+1 t
Define ft to be the t-fold composition of f. That is, f2 = f ◦f, f3 = f ◦f ◦f, and so forth.
Given an initial state x 0 ∈ X, the sequence {ft(x 0)} t∈N is called the flow of the dynamical
system through x . Finally, let F ⊆ XX denote a class of evolution functions on the state
0
space X and F(x) = {f(x) | f ∈ F} ⊆ X to be the projection of F onto x ∈ X.
2.2 Learning-to-Predict in Dynamical Systems
When learning-to-predict in dynamical systems, nature plays a sequential game with the
learner over T rounds. At the beginning of the game, nature reveals the initial state x ∈ X.
0
3Figure 1: Shattered Trajectory (left) and Littlestone (right) trees of depth 2.
In each round t ∈ [T], the learner A uses the observed sequence of states x := (x ,...,x )
<t 0 t−1
to predict the next state A(x ) ∈ X. Nature then reveals the true state x ∈ X, and the
<t t
learner suffers the loss 1{A(x ) ̸= x }. Given a class of evolution functions F ⊆ XX, the
<t t
goal of the learner is to make predictions such that its regret, defined as a difference between
cumulative loss of the learner and the best possible cumulative loss over evolution functions
in F, is small.
Formally, given F ⊆ XX, the expected Markovian regret of an algorithm A is defined as
(cid:34) T (cid:35) T
(cid:88) (cid:88)
RMK(T,F) := sup E 1{A(x ) ̸= x } − inf 1{f(x ) ̸= x }, (1)
A <t t t−1 t
(x0,x1,...,xT)
t=1
f∈F
t=1
where the expectation is taken with respect to the randomness of the learner A. Given this
definition of regret, we define agnostic learnability of an evolution class.
Definition 1 (Agnostic Learnability under Markovian Regret). An evolution class F ⊆ XX
is learnable in the agnostic setting if and only if inf RMK‘(T,F) = o(T).
A A
A sequence of states x ,x ,...,x is said to be realizable by F if there exists an evolution
0 1 T
function f ∈ F such that f(x ) = x for all t ∈ [T]. In the realizable setting, the cumulative
t−1 t
loss of the best-fixed function is 0, and the goal of the learner is to minimize its expected
cumulative mistakes
(cid:34) T (cid:35)
(cid:88)
M (T,F) := sup sup E 1{A(x ) ̸= f(x )} .
A <t t−1
x0 f∈F
t=1
Analogously, we define the realizable learnability of F.
Definition 2 (Realizable Learnability). An evolution class F ⊆ XX is learnable in the real-
izable setting if and only if inf M (T,F) = o(T).
A A
2.3 Complexity Measures
In sequential learning tasks, complexity measures are often defined in terms of trees, a basic
unit that captures temporal dependence. In this paper, we use complete binary trees to
define a new combinatorial object called a trajectory tree. In the remainder of this section
and Section 2.4, we use trajectory trees to define complexity measures and combinatorial
dimensions for evolution classes.
4Definition 3 (Trajectory tree). A trajectory tree of depth d is a complete binary tree of depth
d where internal nodes are labeled by states in X.
See Figure 1 for an example of a trajectory tree. Given a trajectory tree T of depth d,
a root-to-leaf path down T is defined by a string σ ∈ {−1,1}d indicating whether to go left
(σ = −1) or to go right (σ = +1) at each depth t ∈ [d]. A path σ ∈ {−1,1}d down T gives a
t i
trajectory{x }d , wherex denotestheinstancelabelingtherootnodeandx istheinstance
t t=0 0 t
labeling the edge following the prefix (σ ,...,σ ) down the tree. A path σ ∈ {−1,1}d down T
1 t
is shattered by F if there exists a f ∈ F such that f(x ) = x for all t ∈ [d], where {x }d
t−1 t t t=0
is the corresponding trajectory obtained by traversing T according to σ. If every path down
T is shattered by F, we say that T is shattered by F.
To make this more rigorous, we define a trajectory tree T of depth d as a sequence
(T ,T ,...,T ) of node-labeling functions T : {−1,1}t → X, which provide the labels for each
0 1 d t
internalnode. Then, T (σ ,...,σ )givesthelabelofthenodebyfollowingtheprefix(σ ,...,σ )
t 1 t 1 t
andT denotestheinstancelabelingtherootnode. Forbrevity,wedefineσ = (σ ,...,σ )and
0 ≤t 1 t
write T (σ ,...,σ ) = T (σ ). Analogously, we let σ = (σ ,...,σ ). Using this notation, a
t 1 t t ≤t <t 1 t−1
trajectory tree T of depth d is shattered by the evolution function class F if ∀σ ∈ {−1,1}d,
there exists a f ∈ F such that f (T (σ )) = T (σ ) for all t ∈ [d]. Moreover, we use this
σ σ t−1 <t t ≤t
notation to define the Branching factor of a trajectory tree.
Definition 4 (Branching factor). The Branching factor of a trajectory tree T of depth d is
d
B(T) := min (cid:88) 1{T ((σ ,−1)) ̸= T (cid:0) (σ ,+1)(cid:1) }.
t <t t <t
σ∈{−1,1}d
t=1
Thebranchingfactorofapathσ ∈ {−1,1}d capturesthedistinctnessofstateslabelingthe
two children of internal nodes in this path. In particular, it counts the number of nodes in the
path whose two children are labeled by distinct states. The branching factor of a trajectory
tree is just the smallest branching factor across all paths. Using the notion of shattering
and Definition 4, we define a new complexity measure, termed the Evolution complexity, of a
function class F.
Definition 5 (Evolution complexity). Let S(F,d) be the set of all trajectory trees of depth
d ∈ N shattered by F. Then, the Evolution complexity of F at depth d is defined as C (F) :=
d
sup B(T).
T∈S(F,d)
In Section 3, we show that the Evolution complexity exactly (up to a factor of 2) captures
the minimax expected mistakes in the realizable setting. We note that there is an existing
notion of complexity for dynamical systems, termed topological entropy, that quantifies the
complexity of a particular evolution function f ∈ F [Adler et al., 1965]. However, topological
entropy does not characterize learnability as F = {f} is trivially learnable when f has infinite
topological entropy.
2.4 Combinatorial dimensions
In addition to complexity measures, combinatorial dimensions play an important role in pro-
viding crisp quantitative characterizations of learnability. For example, the Daniely Shalev-
Shwartz dimension (DSdim), originally proposed by Daniely and Shalev-Shwartz [2014] and
formally defined in Appendix A , was recently shown by Brukhim et al. [2022] to provide a
tight quantitative characterization of multiclass PAC learnability. In Section 3.3, we use the
DSdimtorelatetherealizablelearnabilityofdynamicalsystemstomulticlassPAClearnability
of F.
5Analogously, for online multiclass classification, the Littlestone dimension (Ldim), origi-
nally proposed by Littlestone [1987] for binary classification and later extended to multiclass
classification by Daniely et al. [2011], provides a tight quantitative characterization of learn-
ability [Hanneke et al., 2023]. We also define the Littlestone dimension in Appendix A.
In this tradition, we are interested in identifying combinatorial dimensions that provide
both qualitative and quantitative characterizations of the learnability of dynamical systems.
In Section 4, we show that the Littlestone dimension of F characterizes agnostic learnability
of dynamical systems. On the other hand, in Section 3, we show that a new scale-sensitive
dimension, termed the Evolution dimension, characterizes the realizable learnability of dy-
namical systems.
Definition 6 (Evolution dimension). The evolution dimension of F at scale γ > 0, denoted
E (F), is the largest d ∈ N such that there exists a trajectory tree T of depth d shattered by
γ
F with B(T) ≥ γd. If this is true arbitrarily large depths d ∈ N, we say E (F) = ∞.
γ
3 Realizable Learnability
3.1 Characterizations of Realizable Learnability
In this section, we provide qualitative and quantitative characterizations of realizable learn-
ability in terms of the Evolution complexity and dimension. Our main result in this section
is Theorem 3.1, which provides bounds on the minimax expected number of mistakes.
Theorem 3.1 (Minimax Expected Mistakes). For any F ⊆ XX,
(i) 1 C (F) ≤ inf M (T,F) ≤ C (F).
2 T A A T
(cid:110) (cid:111)
(ii) sup γE (F)−max{E (F)−T,0} ≤ C (F) ≤ inf {γmax{E (F),T}+γ}.
γ>0 γ γ T γ>0 γ
Moreover, the upperbound in (i) is achieved constructively by a deterministic learner.
The factor of 1 in the lowerbound of part (i) is due to randomized learners, and one can
2
get inf M (T,F) = C (F). In (ii), for all γ > 0 such that E (F) ≤ T, we obtain
DeterministicA A T γ
the bound γE (F) ≤ C (F). We prove parts (i) of Theorem 3.1 using constructive arguments
γ T
below. Part (ii) is proven via non-constructive arguments in Appendix B.
Proof. (of lowerbound in (i) of Theorem 3.1). Let F ⊆ XX be any evolution class and
T ∈ N be the time horizon. Let A be any randomized learner. Our goal will be to construct
a hard realizable trajectory {x }T such that A’s expected number of mistakes is at least
t t=0
CT(F)
. Without loss of generality, suppose d := C (F) > 0 as otherwise the lowerbound holds
2 T
trivially. Then, by definition of the Evolution complexity, there exists a trajectory tree T of
depth T shattered by F with branching factor at least d. This means that for every path
σ ∈ {−1,1}T down T, we have (cid:80)T 1{T ((σ ,−1)) ̸= T ((σ ,+1))} ≥ d.
t=1 t <t t <t
Let σ ∼ {−1,1}T denote a random path down T and consider the trajectory T ∪
0
{T (σ )}T . Define T (σ ) := (T ,T (σ ),...,T (σ )). Then, observe that
t ≤t t=1 <t <t 0 1 1 t−1 <t
6(cid:34) T (cid:35) T
E (cid:88) 1{A(T (σ )) ̸= T (σ )} = (cid:88) E(cid:104) E(cid:104) 1(cid:8) A(cid:0) T (σ )(cid:1) ̸= T (cid:0) (σ ,σ )(cid:1)(cid:9) (cid:12) (cid:12)σ (cid:105)(cid:105)
<t <t t ≤t <t <t t <t t (cid:12) <t
t=1 t=1
T
≥ 1 (cid:88) E(cid:104) E(cid:104) 1(cid:8) T (cid:0) (σ ,−1)(cid:1) ̸= T (cid:0) (σ ,+1)(cid:1)(cid:9) (cid:12) (cid:12)σ (cid:105)(cid:105)
2 t <t t <t (cid:12) <t
t=1
(cid:34) T (cid:35)
= 1 E (cid:88) 1(cid:8) T ((σ ,−1)) ̸= T (cid:0) (σ ,+1)(cid:1)(cid:9) ≥ d
t <t t <t
2 2
t=1
where the first inequality follows from the fact that σ ∼ {−1,1}.
t
Proof. (of upperbound in (i) of Theorem 3.1). Let F ⊆ XX be any evolution function class
and let T ∈ N be the time horizon. Our goal will be to construct a deterministic learner A
such that for any realizable trajectory {x }T , A makes at most C (F) mistakes. To that
t t=0 T
end, it will be useful to define an instance-dependent version of the evolution complexity.
Given a state x ∈ X, we say T is a trajectory tree rooted at x if the root node is labeled
by x. For an initial state x ∈ X and evolution class V ⊆ F, let
0
C (V,x ) := sup{B(T) | T ∈ S(V,T) and T rooted at x }
T 0 0
denoteaninstance-dependentEvolutioncomplexityofV,whereS(V,T)issetofalltrajectory
trees of depth T shattered by V. Note that C (V) = sup C (V,x ). A is a version-space
T x0∈X T 0
algorithm that uses the instance-dependent Evolution complexity to make its prediction such
that whenever A errs, the instance-dependent Evolution complexity decreases. In this way,
C (V,x ) acts as a potential function. Algorithm 1 formalizes this idea.
T 0
Algorithm 1 Deterministic Realizable Algorithm
Input: Initial state x ∈ X
0
1 Let V 1 = F
2 for t = 1,...,T do
3 For x ∈ X, define V tx = {f ∈ V t : f(x t−1) = x}.
4 if {f(x t−1) : f ∈ V t} = {x} then
5 Predict xˆ t = x.
6 else
7 Predict xˆ t ∈ argmax x∈X C T−t(V tx,x).
8 Receive x t and update V t+1 ← V txt.
9 end
WenowshowthatAlgorithm1makesatmostC (F)mistakesonanyrealizabletrajectory.
T
Let {x }T denote the realizable trajectory to be observed. It suffices to show that
t t=0
C (V ,x ) ≤ C (V ,x )−1{x ̸= xˆ } (2)
T−t t+1 t T−t+1 t t−1 t t
for all t ∈ [T]. To see why this is true, note that (2) implies
T T T
(cid:88) (cid:88) (cid:88)
C (V ,x ) ≤ C (V ,x )− 1{x ̸= xˆ }.
T−t t+1 t T−t+1 t t−1 t t
t=1 t=1 t=1
Rearranging, we get that
7T T T
(cid:88) (cid:88) (cid:88)
1{x ̸= xˆ } ≤ C (V ,x )− C (V ,x )
t t T−t+1 t t−1 T−t t+1 t
t=1 t=1 t=1
T
(cid:88)(cid:16) (cid:17)
= C (V ,x )−C (V ,x )
T−t+1 t t−1 T−t t+1 t
t=1
= C (V ,x )−C (V ,x ) ≤ C (F).
T 1 0 0 T+1 T T
as needed. To prove (2), we need to consider three cases: (a) C (V ,x ) > 0 and
T−t+1 t t−1
xˆ ̸= x , (b) C (V ,x ) > 0 and xˆ = x , and (c) C (V ,x ) = 0.
t t T−t+1 t t−1 t t T−t+1 t t−1
Starting with (a), let t ∈ [T] such that C (V ,x ) > 0 and xˆ ̸= x . We need
T−t+1 t t−1 t t
to show that C (V ,x ) < C (V ,x ). Suppose for the sake of contradiction that
T−t t+1 t T−t+1 t t−1
C (V ,x ) ≥ C (V ,x ) := d. Then,bythepredictionrule,wehavethatC (Vxˆt,xˆ ) ≥
T−t t+1 t T−t+1 t t−1 T−t t t
C (Vxt,x ) ≥ d. Bydefinitionoftheinstance-dependentEvolutioncomplexity,weareguar-
T−t t t
anteed the existence of a trajectory tree T of depth T −t, rooted at x , shattered by Vxt
xt t t
with branching factor at least d and a tree T of depth T − t, rooted at xˆ , shattered by
xˆt t
Vxˆt with branching factor at least d. Consider a binary tree T whose root node v is labeled
t
by x and left and right subtrees are T and T respectively. Then, observe that T is a
t−1 xt xˆt
trajectory tree of depth T −t+1, rooted at x , shattered by V with branching factor at
t−1 t
least d+1 (because x ̸= xˆ ). This contradicts our assumption that C (V ,x ) = d.
t t T−t+1 t t−1
Thus, we must have C (V ,x ) < C (V ,x ).
T−t t+1 t T−t+1 t t−1
Moving to (b), let t ∈ [T] be such that xˆ = x . Then, we need to show that d :=
t t
C (V ,x ) ≤ C (V ,x ). If d = 0, the inequality holds trivially. Thus, assume d > 0.
T−t t+1 t T−t+1 t t−1
Then, by definition, there exists a trajectory tree T of depth T −t, rooted at x , shattered by
t
V with branching factor at least d. Consider a binary tree T˜ whose root node v is labeled
t+1
by x and left and right subtrees are both T. Then since V = Vxt ⊆ V , we have that T˜
t−1 t+1 t t
is a trajectory tree of depth T −t+1, rooted at x , shattered by V with branching factor
t−1 t
at least d. Thus, we must have C (V ,x ) ≥ d.
T−t+1 t t−1
Finally for (c), let t ∈ [T] be such that C (V ,x ) = 0. Using the same logic as (b),
T−t+1 t t−1
C (V ,x ) = 0. Thus, to prove that (2) holds, it suffices to show that x = xˆ . To do so,
T−t t+1 t t t
we will show that the projection size |{f(x ) : f ∈ V }| = 1. Thus, Algorithm 1 does not
t−1 t
make a mistake. Suppose for the sake of contradiction that |{f(x ) : f ∈ V }| ≥ 2. Then,
t−1 t
there exists two functions f ,f ∈ V such that f (x ) ̸= f (x ). Consider a binary tree
1 2 t 1 t−1 2 t−1
T of depth T −t+1 where the root node is labeled by x , and its left and right child by
t−1
f (x ) and f (x ) respectively. Label all remaining internal nodes in the left subtree of
1 t−1 2 t−1
the root node such that every path is shattered by f . Likewise, for the right subtree of the
1
root node, label every internal node such that every path is shattered by f . Following this
2
procedure, T is a trajectory tree of depth T − t + 1, rooted at x , shattered by V with
t−1 t
branching factor at least 1 (because f (x ) ̸= f (x )). Thus, C (V ,x ) ≥ 1, which
1 t−1 2 t−1 T−t+1 t t−1
is a contradiction.
While Theorem 3.1 shows that the finiteness of E (F) for every γ > 0 is sufficient for
γ
realizable learnability, it is not clear from the lowerbound that it is necessary. Theorem 3.2,
whoseproofisinAppendixC,resolvesthisgapbyshowingthatindeedthefinitenessofE (F)
γ
for every γ > 0 is both necessary and sufficient for realizable learnability, thus providing a
qualitative characterization.
Theorem 3.2 (Qualitative characterization of Realizable Learnability). For every F ⊆ XX,
the following statements are equivalent.
(i) F is learnable in the realizable setting.
8(ii) C (F) = o(T).
T
(iii) E (F) is finite for every γ > 0.
γ
3.2 Minimax Rates in the Realizable Setting
While Theorems 3.1 and 3.2 provide a quantitative and qualitative characterization of re-
alizable learnability, they do not shed light on how inf M (F,T) may depend on the time
A A
horizon T. In online classification with the 0-1 loss, the seminal work by Littlestone [1987]
and Daniely et al. [2011] show that only two rates are possible: Θ(T) and Θ(1). That is,
if a hypothesis class is online learnable in the realizable setting, then it is learnable with a
constant mistake bound (i.e. the Littlestone dimension). Perhaps surprisingly, this is not the
case for learning dynamical systems in a strong sense: every rate is possible.
Theorem3.3. ForeveryS ⊂ N∪{0}, thereexistsF ⊆ ZZ suchthatC (F ) = sup |S∩
S T S n∈N∪{0}
{n,n+1,...,n+T −1}|.
Theorem 3.3, proved in Appendix D, along with Theorem 3.1 implies that any minimax
rate in the realizable setting is possible. As an example, suppose we would like to achieve
the rate Θ(Tα) for some α < 1. Then, picking S = {⌊tα1 ⌋ : t ∈ N ∪ {0}} suffices since
sup x∈N∪{0}|S ∩{n,n+1,...,n+T −1}| = |{⌊tα1 ⌋ : t ∈ N∪{0}}∩{0,1,...,T −1}| = Θ(Tα).
Likewise, one can get logarithmic rates by picking S = {2t : t ∈ N∪{0}} and constant rates
by picking S ⊂ N∪{0} such that |S| < ∞.
InlightofTheorem3.3andthefactthatonlyconstantmistakeboundsarepossibleforon-
linemulticlassclassification,itisnaturaltoaskwhen onecanachieveconstantmistakebounds
for learning dynamical systems. To answer this question, we introduce a new combinatorial
dimension termed the Branching dimension.
Definition 7 (Branching dimension). The Branching dimension, denoted dim(F), is the
smallest natural number d ∈ N such that for every shattered trajectory tree T, we have B(T) ≤
d. If for every d ∈ N, there exists a shattered trajectory tree T with B(T) > d, we say
dim(F) = ∞.
Theorem3.4,provedvianon-constructiveargumentsinAppendixE,showsthatinf M (T,F) =
A A
Θ(1) if and and only if dim(F) < ∞.
Theorem 3.4 (Constant Minimax Expected Mistakes). For any F ⊆ XX, we have
(i) inf M (T,F) ≤ dim(F).
A A
(ii) If dim(F) = ∞, then inf M (T,F) = ω(1)1.
A A
3.3 Relations to PAC and Online Multiclass Classification
In this section, we study the relationship between realizable learnability of dynamical systems
to realizable learnability in the well-known PAC and online classification settings. Our main
result relates the evolution complexity and dimension to the DS and Littlestone dimensions.
Theorem 3.5 (Relations to the DS and Littlestone dimension). The following statements
are true.
(i) There exists F ⊆ XX such that DS(F) = ∞ but C (F) = Θ(log(T)).
T
1Recall that f(n)=ω(1) if for all k>0, there exists n , such that for all n>n we have f(n)>k.
k k
9(ii) There exists F ⊆ XX such that DS(F) = 1 but C (F) = T.
T
(iii) For any F ⊆ XX, we have that C (F) ≤ L(F).
T
(iv) There exists F ⊆ XX such that L(F) = ∞ but C (F) = 1.
T
The proof of Theorem 3.5 is in Appendix F. Parts (i) and (ii) show that the finiteness of
the DSdim is neither necessary nor sufficient for learning dynamical systems in the realizable
setting. On the other hand, parts (iii) and (iv) show that finite Ldim is sufficient but not
necessaryforlearningdynamicalsystemsintherealizablesetting. Overall,learningdynamical
systemsisalwayseasierthanonlinemulticlassclassification,butcanbebotheasierandharder
than multiclass PAC classification. The proof of (i), (ii), and (iv) are combinatorial in nature,
while the proof of (iii) involves reducing learning-to-predict in dynamical systems to online
multiclass classification.
3.4 Examples
In this section, we establish the minimax rates for discrete linear systems and linear Boolean
networks. Theorem 3.6 provides bounds on the Evolution complexity for discrete linear sys-
tems.
Theorem 3.6 (Discrete Linear Systems). Let X = Zn and r < n. For F = {x (cid:55)→ Wx : W ∈
Zn×n, rank(W) ≤ r} and T > r, we have C (F) = r+1.
T
The proof of the upperbound in Theorem 3.6 uses the fact that given any initial state, the
streamgeneratedbyanyf ∈ F canhaveatmostr otherstateswhicharelinearlyindependent
of previous states. As for the lowerbound, we show how to construct a hard stream for every
deterministic learner. Theorem 3.7, whose proof is in Appendix G.2, provides bounds on the
Evolution complexity for two natural families of Boolean networks.
Theorem 3.7 (Linear Boolean Networks). Let X = {0,1}n and T ≥ n.
(i) For F = {x (cid:55)→ Wx(mod 2) : W ∈ Zn×n}, we have C (F) = n.
T
(ii) For F = {x (cid:55)→ 1{Wx > 0} : W ∈ {0,1}n×n}, we have n ≤ C (F) ≤ n2.
T
ThresholdedBooleannetworkshavebeenusedtomodelgeneticregulatorydynamics[Men-
doza and Alvarez-Buylla, 1998] and social networks [Kempe et al., 2003]. Modulo Boolean
networks have been studied by Chandrasekhar et al. [2023] in the context of stability. Simi-
lar to Theorem 3.6, the proof of (i) in Theorem 3.7 uses the fact that any realizable stream
can have at most n−1 states (excluding the initial state) that are linearly independent of
all preceeding states. To prove the upperbound in (ii), we bound the Ldim of F. For the
lowerbound, we construct a hard stream such that every deterministic learner makes at least
n mistakes. We conjecture that the upperbound in Theorem 3.7 (ii) can be reduced to O(n),
but we leave this as an interesting open question.
4 Agnostic Learnability under Markovian Regret
In this section, we go beyond the realizable setting and consider the case where nature may
reveal a trajectory that is not consistent with any evolution function in the class. Our main
result in this section establishes bounds on the minimax expected Markovian regret.
10Theorem 4.1 (Minimax Expected Markovian Regret). For any F ⊆ XX,
(cid:40) √ (cid:41)
L(F) T (cid:112)
max , √ ≤ inf RMK(T,F) ≤ L(F)+ T L(F)logT.
18 16 3 A A
Theorem 4.1 shows that the finiteness of the Littlestone dimension of F is both necessary
and sufficient for agnostic learnability. This is in contrast to Theorem 3.5, which shows that
the finiteness of the Littlestone dimension of F is sufficient but not necessary for realizable
learnability. Thus, Theorem 4.1 and 3.5 imply that realizable and agnostic learnability are
not equivalent.
Corollary 4.2 (Realizable Learnability ̸≡ Agnostic Learnability under Markovian Regret).
There exists a class F ⊆ XX such that F is learnable in the realizable setting but not in the
agnostic setting under Markovian regret.
OnesuchclassexhibitingtheseparationisthethresholdsF = {x (cid:55)→ 1{x ≥ a} : a ∈ (0,1)}
used in the proof of part (iv) in Theorem 3.5. Beyond the qualitative separation of realizable
and agnostic learnability under Markovian regret, we also observe a quantitative separation
in terms of possible minimax rates. Recall that Theorem 3.3 shows that every rate is possible
in the realizable setting. However, Theorem 4.1 shows that only two types of rates are
√
possible in the agnostic setting: Θ(T) whenever L(F) = ∞ and Θ˜( T) whenever L(F) < ∞.
√ √
More precisely, when T ≥ L(F), we have a lowerbound of Ω( T) and an upperbound
(cid:112)
of O( TL(F)logT) in Theorem 4.1. This raises the natural question of what the right
minimax rate is. In Appendix I, we provide an evolution class and establish a lowerbound of
√
(cid:112)
Ω( TL(F)), showing that the upperbound is tight up to logT.
Our proof of the upperbound in Theorem 4.1 reduces learning dynamical systems to
online multiclass classification and uses a result due to Hanneke et al. [2023]. To prove
the lowerbound
L(F)
, we construct a hard stream by carefully sampling a random path down
18 √
a Littlestone tree of depth L(F). To prove the lowerbound of √T , we construct a hard
16 3
randomized stream using just two different evolution functions in F. The full proof is in
Appendix H.
5 Agnostic Learnability under Flow Regret
The necessity of the Littlestone dimension for agnostic learnability under Markovian regret
is quite restrictive. One can verify that even for simple (but unnatural) classes like one
dimensional thresholds F = {x (cid:55)→ 1{x ≤ a} : a ∈ (0,1)]}, we have that L(F) = ∞ while
C (F) = 1. Indeed, the intuition in the lowerbound of Theorem 5.1 is that, in the agnostic
T
setting, the adversary can force the learner to play an online multiclass classification game by
“givingup”everyotherround. SincetheLdimisnecessaryforonlinemulticlassclassification,
it is not surprising that it is also necessary for learning dynamical systems in the agnostic
setting.
The main reason behind the equivalence of online multiclass classification and learning
dynamical systems in the agnostic setting is the definition of Markovian regret. In particu-
lar, the evaluation of the “best-fixed evolution function in hindsight” does not penalize the
evolution function beyond a one-step prediction error. From this perspective, perhaps a more
naturaldefinitionofexpectedregretintheagnosticsettingistocomparethepredictionofthe
learner to the prediction of the best-fixed trajectory generated by functions in our evolution
11class. More rigorously, define
(cid:34) T (cid:35) T
(cid:16) (cid:88) (cid:88) (cid:17)
RFL(T,F) := sup E 1{A(x ) ̸= x } − inf 1{ft(x ) ̸= x } . (3)
A <t t 0 t
(x0,x1,...,xT)
t=1
f∈F
t=1
as the expected Flow regret. An analogous definition of agnostic learnability follows.
Definition 8 (Agnostic Learnability under Flow Regret). An evolution class F ⊆ XX is
learnable in the agnostic setting under Flow regret if and only if inf RFL(T,F) = o(T).
A A
WhichevolutionclassesF ⊆ XX areagnosticlearnableunderFlowregret? Isthefiniteness
of Ldim still necessary? Theorem 5.1, whose proof can be found in Appendix J, provides
partial answers to these question by bounding the minimax expected Flow regret for classes
where sup |F(x)| is uniformly bounded.
x∈X
Theorem 5.1 (Minimax Expected Flow Regret). For any ordered set X and F ⊆ XX,
(cid:115)
C (F) (cid:16)T K (cid:17)
T ≤ infRFL(T,F) ≤ C (F)+ C (F)T ln F .
2 A A T T C T(F)
where K = sup |F(x)|. Moreover, both the lower- and upperbound can be tight.
F x∈X
Note that the upperbound becomes vacuous when sup |F(x)| = ∞. We leave it as an
x∈X
openquestiontofindtherightcharacterizationunderFlowregret. Unlikeagnosticlearnability
under Markovian regret, the finitness of the Ldim is not necessary for agnostic learnability
under Flow regret. Indeed, while the class of one-dimensional thresholds is not agnostic
learnable under Markovian regret, it is agnostic learnable under Flow regret. In fact, a
separation between agnostic learnability for Markovian and Flow regret can be exhibited by
any class F for which sup |F(x)| < ∞, L(F) = ∞, and C (F) = o(T).
x∈X T
Theorem 5.1 shows that realizable and agnostic learnability under Flow regret are equiv-
alent as long as sup |F(x)| < ∞. A natural question to ask is whether this is also true
x∈X
when sup |F(x)| = ∞. Unfortunately, Theorem 5.2 shows that when the projection sizes
x∈X
are not uniformly bounded, realizable and agnostic learnability under Flow regret are not
equivalent.
Theorem 5.2 (Realizable learnability ̸≡ Agnostic Learnability under Flow Regret). There
exists an ordered set X and F ⊆ XX such that
(i) inf M (T,F) ≤ 3.
A A
(ii) inf RFL(T,F) ≥ T.
A A 6
To prove Theorem 5.2, we construct a class F ⊆ XX such that on large subset of states in
X′ ⊂ X, every function f ∈ F effectively reveals its identity. The full proof of Theorem 5.2
can be found in Appendix K.
6 Discussion and Future directions
Inthiswork,westudiedtheproblemoflearning-to-predictindiscrete-timedynamicalsystems
under the 0-1 loss. A natural extension is to consider continuous state spaces with real-valued
losses. Forexample,onecantakeX tobeaboundedsubsetofaHilbertspaceandconsiderthe
squared norm as the loss function. Another natural extension is to consider learnability under
partial observability, where the learner only observes some transformation ϕ(x ) instead of
t
12the true state x . Such feedback model is standard in prediction for linear dynamical systems
t
[Hazan et al., 2018]. It is also natural to study the learnability of function classes where the
output of the evolution rules f : Xp → X, depend on the previous p > 1 states (e.g. the
p-th order VAR model). Lastly, the learning algorithms in this work are improper: they use
evolution functions that may not lie in F to make predictions. This might be undesirable
as improper learning algorithms may be incompatible with downstream system identification
and control tasks. To this end, characterizing proper learnability of dynamical systems is an
important future direction.
Acknowledgements
We thank Chinmaya Kaushik for pointing out a technical result, which helped us to prove
Theorem 3.6.
References
Yasin Abbasi-Yadkori and Csaba Szepesv´ari. Regret bounds for the adaptive control of linear
quadraticsystems. InProceedings of the 24th Annual Conference on Learning Theory,pages
1–26. JMLR Workshop and Conference Proceedings, 2011.
Roy L Adler, Alan G Konheim, and M Harry McAndrew. Topological entropy. Transactions
of the American Mathematical Society, 114(2):309–319, 1965.
Naman Agarwal, Brian Bullins, Elad Hazan, Sham Kakade, and Karan Singh. Online control
with adversarial disturbances. In International Conference on Machine Learning, pages
111–119. PMLR, 2019.
Oren Anava, Elad Hazan, Shie Mannor, and Ohad Shamir. Online learning for time series
prediction. In Conference on learning theory, pages 172–184. PMLR, 2013.
Oren Anava, Elad Hazan, and Assaf Zeevi. Online time series prediction with missing data.
In International conference on machine learning, pages 2191–2199. PMLR, 2015.
Karl Johan ˚Astr¨om and Peter Eykhoff. System identification—a survey. Automatica, 7(2):
123–162, 1971.
Sohail Bahmani and Justin Romberg. Convex programming for estimation in nonlinear re-
current models. The Journal of Machine Learning Research, 21(1):9563–9582, 2020.
Anouk Barberousse and Cyrille Imbert. New mathematics for old physics: The case of lat-
tice fluids. Studies in History and Philosophy of Science Part B: Studies in History and
Philosophy of Modern Physics, 44(3):231–241, 2013.
PeterLBartlettandShaharMendelson. Rademacherandgaussiancomplexities: Riskbounds
and structural results. Journal of Machine Learning Research, 3(Nov):463–482, 2002.
MichaelBatty. Agents,cells,andcities: newrepresentationalmodelsforsimulatingmultiscale
urban dynamics. Environment and Planning A, 37(8):1373–1394, 2005.
DavidBelangerandShamKakade. Alineardynamicalsystemmodelfortext. InInternational
Conference on Machine Learning, pages 833–842. PMLR, 2015.
Nataly Brukhim, Daniel Carmon, Irit Dinur, Shay Moran, and Amir Yehudayoff. A charac-
terization of multiclass learnability, 2022. URL https://arxiv.org/abs/2203.01550.
13Marco C Campi and Erik Weyer. Finite sample properties of system identification methods.
IEEE Transactions on Automatic Control, 47(8):1329–1334, 2002.
NicoloCesa-BianchiandG´aborLugosi.Prediction, learning, andgames.Cambridgeuniversity
press, 2006.
Karthik Chandrasekhar, Claus Kadelka, Reinhard Laubenbacher, and David Murrugarra.
Stability of linear boolean networks. Physica D: Nonlinear Phenomena, 451:133775, 2023.
Alon Cohen, Avinatan Hasidim, Tomer Koren, Nevena Lazic, Yishay Mansour, and Kunal
Talwar. Online linear quadratic control. In International Conference on Machine Learning,
pages 1029–1038. PMLR, 2018.
Amit Daniely and Shai Shalev-Shwartz. Optimal learners for multiclass problems. In Con-
ference on Learning Theory, pages 287–316. PMLR, 2014.
AmitDaniely,SivanSabato,ShaiBen-David,andShaiShalev-Shwartz. Multiclasslearnability
and the erm principle. In Sham M. Kakade and Ulrike von Luxburg, editors, Proceedings
of the 24th Annual Conference on Learning Theory, volume 19 of Proceedings of Machine
Learning Research, pages 207–232, Budapest, Hungary, 09–11 Jun 2011. PMLR.
Gianfranco Doretto, Alessandro Chiuso, Ying Nian Wu, and Stefano Soatto. Dynamic tex-
tures. International journal of computer vision, 51:91–109, 2003.
Dylan Foster, Tuhin Sarkar, and Alexander Rakhlin. Learning nonlinear dynamical systems
from a single trajectory. In Learning for Dynamics and Control, pages 851–861. PMLR,
2020.
AminGhadamiandBogdanIEpureanu. Data-drivenpredictionindynamicalsystems: recent
developments. PhilosophicalTransactionsoftheRoyalSocietyA,380(2229):20210213,2022.
Udaya Ghai, Holden Lee, Karan Singh, Cyril Zhang, and Yi Zhang. No-regret prediction in
marginally stable systems. In Conference on Learning Theory, pages 1714–1757. PMLR,
2020.
DimitriosGiannakis, AmeliaHenriksen, JoelATropp, andRachelWard. Learningtoforecast
dynamical systems from streaming data. SIAM Journal on Applied Dynamical Systems, 22
(2):527–558, 2023.
Daniele Grattarola, Lorenzo Livi, and Cesare Alippi. Learning graph cellular automata.
Advances in Neural Information Processing Systems, 34:20983–20994, 2021.
Steve Hanneke, Shay Moran, Vinod Raman, Unique Subedi, and Ambuj Tewari. Multiclass
online learning and uniform convergence. Proceedings of the 36th Annual Conference on
Learning Theory (COLT), 2023.
Elad Hazan, Karan Singh, and Cyril Zhang. Learning linear dynamical systems via spectral
filtering. Advances in Neural Information Processing Systems, 30, 2017.
Elad Hazan, Holden Lee, Karan Singh, Cyril Zhang, and Yi Zhang. Spectral filtering for
general linear dynamical systems. Advances in Neural Information Processing Systems, 31,
2018.
Alfons G Hoekstra, Jiri Kroc, and Peter MA Sloot. Simulating complex systems by cellular
automata. Springer, 2010.
14Prateek Jain, Suhas S Kowshik, Dheeraj Nagaraj, and Praneeth Netrapalli. Streaming linear
systemidentificationwithreverseexperiencereplay. arXiv preprint arXiv:2103.05896,2021.
ShamKakade,AkshayKrishnamurthy,KendallLowrey,MotoyaOhnishi,andWenSun. Infor-
mationtheoreticregretboundsforonlinenonlinearcontrol. AdvancesinNeuralInformation
Processing Systems, 33:15312–15325, 2020.
StuartKauffman. Homeostasisanddifferentiationinrandomgeneticcontrolnetworks. Nature,
224(5215):177–178, 1969.
Michael J Kearns and Robert E Schapire. Efficient distribution-free learning of probabilistic
concepts. Journal of Computer and System Sciences, 48(3):464–497, 1994.
David Kempe, Jon Kleinberg, and E´va Tardos. Maximizing the spread of influence through
a social network. In Proceedings of the ninth ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 137–146, 2003.
Milan Korda and Igor Mezi´c. Linear predictors for nonlinear dynamical systems: Koopman
operator meets model predictive control. Automatica, 93:149–160, 2018.
SuhasKowshik,DheerajNagaraj,PrateekJain,andPraneethNetrapalli. Near-optimaloffline
and streaming algorithms for learning non-linear dynamical systems. Advances in Neural
Information Processing Systems, 34:8518–8531, 2021a.
Suhas Kowshik, Dheeraj Nagaraj, Prateek Jain, and Praneeth Netrapalli. Streaming lin-
ear system identification with reverse experience replay. Advances in Neural Information
Processing Systems, 34:30140–30152, 2021b.
Mark Kozdoba, Jakub Marecek, Tigran Tchrakian, and Shie Mannor. On-line learning of
linear dynamical systems: Exponential forgetting in kalman filters. In Proceedings of the
AAAI Conference on Artificial Intelligence, volume 33, pages 4098–4105, 2019.
Sahin Lale, Kamyar Azizzadenesheli, Babak Hassibi, and Anima Anandkumar. Logarith-
mic regret bound in partially observable linear dynamical systems. Advances in Neural
Information Processing Systems, 33:20876–20888, 2020.
Holden Lee. Improved rates for prediction and identification of partially observed linear
dynamical systems. In International Conference on Algorithmic Learning Theory, pages
668–698. PMLR, 2022.
Yingying Li, Xin Chen, and Na Li. Online optimal control with linear dynamics and predic-
tions: Algorithmsandregretanalysis. Advances in Neural Information Processing Systems,
32, 2019.
Nick Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold
algorithm. Machine Learning, 2:285–318, 1987.
Chenghao Liu, Steven CH Hoi, Peilin Zhao, and Jianling Sun. Online arima algorithms for
time series prediction. In Proceedings of the AAAI conference on artificial intelligence,
volume 30, 2016.
Lennart Ljung. System identification: theory for the user. PTR Prentice Hall, Upper Saddle
River, NJ, 28:540, 1999.
15Luis Mendoza and Elena R Alvarez-Buylla. Dynamics of the genetic regulatory network
forarabidopsisthalianaflowermorphogenesis. Journal of theoretical biology, 193(2):307–319,
1998.
Deepan Muthirayan and Pramod P Khargonekar. Online learning robust control of nonlinear
dynamical systems. arXiv preprint arXiv:2106.04092, 2021.
B. K. Natarajan. On learning sets and functions. Mach. Learn., 4(1):67–97, oct 1989.
ISSN 0885-6125. doi: 10.1023/A:1022605311895. URL https://doi.org/10.1023/A:
1022605311895.
Zirou Qiu, Abhijin Adiga, Madhav V Marathe, SS Ravi, Daniel J Rosenkrantz, Richard E
Stearns, and Anil Vullikanti. Learning the topology and behavior of discrete dynamical
systems.
Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning via sequential
complexities. J. Mach. Learn. Res., 16(1):155–186, 2015.
Paria Rashidinejad, Jiantao Jiao, and Stuart Russell. Slip: Learning to predict in unknown
dynamical systems with long-term memory. Advances in Neural Information Processing
Systems, 33:5716–5728, 2020.
DanielJRosenkrantz, AbhijinAdiga, MadhavMarathe, ZirouQiu, SSRavi, RichardStearns,
andAnilVullikanti. Efficientlylearningthetopologyandbehaviorofanetworkeddynamical
system via active queries. In International Conference on Machine Learning, pages 18796–
18808. PMLR, 2022.
Yahya Sattar and Samet Oymak. Non-asymptotic and accurate learning of nonlinear dynam-
ical systems. The Journal of Machine Learning Research, 23(1):6248–6296, 2022.
Shai Shalev-Shwartz and Shai Ben-David. Understanding Machine Learning: From Theory
to Algorithms. Cambridge University Press, USA, 2014.
IlyaShmulevich,EdwardRDougherty,andWeiZhang. Frombooleantoprobabilisticboolean
networks as models of genetic regulatory networks. Proceedings of the IEEE, 90(11):1778–
1792, 2002.
Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural
networks. Advances in neural information processing systems, 27, 2014.
AnastasiosTsiamisandGeorgeJPappas. Onlinelearningofthekalmanfilterwithlogarithmic
regret. IEEE Transactions on Automatic Control, 68(5):2774–2789, 2022.
Vladimir Naumovich Vapnik and Aleksei Yakovlevich Chervonenkis. On uniform convergence
of the frequencies of events to their probabilities. Teoriya Veroyatnostei i ee Primeneniya,
16(2):264–279, 1971.
Mathukumalli Vidyasagar and Rajeeva L Karandikar. A learning theory approach to system
identification and stochastic adaptive control. Probabilistic and randomized methods for
design under uncertainty, pages 265–302, 2006.
John von Neumann. Theory of self-reproducing automata. IEEE Transactions on Neural
Networks, 5(1):3–14, 1966.
Wen-Xu Wang, Ying-Cheng Lai, and Celso Grebogi. Data-based identification and prediction
of nonlinear and complex dynamical systems. Physics Reports, 644:1–76, 2016.
16Stephen Wolfram. Theory and applications of cellular automata. World Scientific, 1986.
NWulffandJAHertz. Learningcellularautomatondynamicswithneuralnetworks. Advances
in Neural Information Processing Systems, 5, 1992.
Xuan Xiao, Pu Wang, and Kuo-Chen Chou. Cellular automata and its applications in protein
bioinformatics. Current Protein and Peptide Science, 12(6):508–519, 2011.
Haimin Yang, Zhisong Pan, Qing Tao, and Junyang Qiu. Online learning for vector autore-
gressive moving-average time series prediction. Neurocomputing, 315:9–17, 2018.
17A Combinatorial dimensions
Definition 9 (DS dimension [Daniely and Shalev-Shwartz, 2014]). We say that A ⊆ X is
DS-shattered by F if there exists a finite H ⊂ F such that for every x ∈ A and h ∈ H, there
exists a g ∈ H such that g(x) ̸= h(x) and g(z) = h(z) for all z ∈ A\{x}. The DS dimension
of F, denoted DS(F), is the largest d ∈ N such that there exists a shattered set A ⊂ X with
cardinality d. If there are arbitrarily large sets A ⊆ X that are shattered by F, then we say
that DS(F) = ∞.
Definition 10 (Littlestone dimension [Littlestone, 1987, Daniely et al., 2011]). Let T be a
complete binary tree of depth d whose internal nodes are labeled by a sequence (T ,...,T )
0 d−1
of node-labeling functions T : {−1,1}t−1 → X. The tree T is shattered by F ⊆ XX if
t−1
there exists a sequence (Y ,...,Y ) of edge-labeling functions Y : {−1,1}t → X such that for
1 d t
every path σ = (σ ,...,σ ) ∈ {−1,1}d, there exists a function f ∈ F such that for all t ∈ [d],
1 d σ
f (T (σ )) = Y (σ ) and Y ((σ ,−1)) ̸= Y ((σ ,+1)). The Littlestone dimension of F,
σ t−1 <t t ≤t t <t t <t
denoted L(F), is the maximal depth of a tree T that is shattered by F. If there exists shattered
trees of arbitrarily large depth, we say L(F) = ∞.
B Proof of Theorem 3.1
Proof. (of lowerbound in (ii) of Theorem 3.1) Fix time horizon T ∈ N and scale γ > 0. By
definition of E (F), there exists a trajectory tree T of depth E (F) such that B(T) ≥ γE (F).
γ γ γ
LetT′denotethetrajectorytreeafterremovingthelastmax{E (F)−T,0}levelsfromT. Note
γ
thatthedepthofT′ isexactlyT anditsbranchingfactorB(T′) ≥ γE (F)−max{E (F)−T,0}.
γ γ
Thus, it must be the case that C (F) ≥ γE (F)−max{E (F)−T,0}. Since γ was chosen
T γ γ
arbitrarily, this completes the proof.
Proof. (of upperbound in (ii) of Theorem 3.1). Fix a γ > 0. Using Definition 6, we first
establish two facts: (1) B(T) < γ(E (F)+1) for every shattered trajectory tree T of depth
γ
d ≤ E (F) and (2) B(T) < γd for every shattered trajectory tree T of depth d > E (F). To
γ γ
see fact (1), if there exists a shattered trajectory tree T of depth ≤ E (F) := d such that
γ
B(T) ≥ γ(E (F) + 1), one can extend this tree to obtain a shattered trajectory tree T′ of
γ
depth d+1 with B(T′) ≥ γ(d+1). This would imply that E (F) = d+1, a contradiction.
γ
Fact (2) follows by a similar reasoning. If there exists a shattered trajectory tree T of depth
d > E (F) such that B(T) ≥ γd, then E (F) ≥ d, leading to a contradiction.
γ γ
Finally, to prove the upperbound in (ii) in Theorem 3.1, we can use facts (1) and (2) to
write
C (F) = C (F)1{T ≤ E (F)}+C (F)1{T > E (F)}
T T γ T γ
≤ γ(E (F)+1)1{T ≤ E (F)}+γT1{T > E (F)}
γ γ γ
≤ γmax{E (F),T}+γ,
γ
Taking the infimum with respect to γ > 0 completes the proof.
C Proof of Theorem 3.2
The equivalence between statements (1) and (2) follows directly from the quantitative bounds
in Theorem 3.1. Thus, we only focus on proving the equivalence between statements (2) and
(3). The direction (3) =⇒ (2) follows from upperbound (iv) in Theorem 3.1 and the fact
that inf {γmax{E (F),T}+γ} = o(T). To see the later, observe that if E (F) < ∞ for
γ>0 γ γ
every γ > 0, then
18inf {γmax{E (F),T}+γ} (cid:110) γmax{E (F),T}+γ(cid:111)
γ>0 γ γ
lim ≤ inf lim = inf γ = 0
T→∞ T γ>0 T→∞ T γ>0
We now prove (2) =⇒ (3). Suppose (2) is true, then by definition of o(·), for every ε > 0,
there exists a T ∈ N such that for all T > T , we have that C (F) < εT. If C (F) < εT for
ε ε T T
all T > T , then B(T) < εT for every shattered trajectory tree T of depth T > T . Thus, it
ε ε
must be the case that E (F) ≤ T < ∞.
ε ε
D Proof of Theorem 3.3
Let S ⊂ N ∪ {0} be an arbitrary subset of the extended natural numbers. For every σ ∈
{−1,1}N∪{0},
define the evolution function
(cid:16) (cid:17)
f (x) = σ 1{|x| ∈ S}+1{|x| ∈/ S} (|x|+1)
σ |x|
(cid:110) (cid:111)
and consider the class F = f : σ ∈
{−1,1}N∪{0}
. By construction, functions in F only
S σ S
disagree on states in S and their negation. Moreover, given any initial state x ∈ Z and a
0
time horizon T ∈ N, the trajectory of any evolution in F is ε (|x |+1),...,ε (|x |+T) for
1 0 T 0
some ε ∈ {−1,1}T.
We now show that C (F) ≤ sup |S∩{|x |,...,|x |+T −1}|. Let T be any trajectory
T x0∈Z 0 0
tree of depth T shattered by F. It suffices to show that B(T) ≤ |S ∩{|T |,...,|T |+T −1}|.
0 0
Fix any path ε ∈ {−1,1}T down T and consider the sequence of states T ,...,T (ε ). Note
0 T ≤T
that T ((ε ,−1)) ̸= T ((ε ,+1)) only if |T (ε )| ∈ S. Thus,
t <t t <t t−1 <t
T T
(cid:88) 1{T ((ε ,−1)) ̸= T (cid:0) (ε ,+1)(cid:1) } ≤ (cid:88) 1{|T (ε )| ∈ S}
t <t t <t t−1 <t
t=1 t=1
T−1
(cid:88)
= 1{|T (ε )| ∈ S}
t ≤t
t=0
T−1
(cid:88)
= 1{|T | ∈ S}+ 1{|T (ε )| ∈ S}
0 t ≤t
t=1
Moreover, since the path ε is shattered by F , it must be the case that for every t ∈ [T],
S
we have that |T (ε )| = |T |+t. Thus,
t ≤t 0
T T−1
(cid:88) 1{T ((ε ,−1)) ̸= T (cid:0) (ε ,+1)(cid:1) } ≤ 1{|T | ∈ S}+ (cid:88) 1{|T (ε )| ∈ S}
t <t t <t 0 t ≤t
t=1 t=1
T−1
(cid:88)
= 1{|T |+t ∈ S}
0
t=0
= |S ∩{|T |,...,|T |+T −1}|,
0 0
TakingthesupremumofbothsideswithrespecttoT completestheproofoftheupperbound.
0
To prove the lowerbound, fix x ∈ Z and consider the following trajectory tree Tx of depth
T. Let Tx = x. For every path ε ∈ {−1,1}T and t ∈ [T], let
0
19(cid:40)
ε (|Tx|+t), if|Tx|+t−1 ∈ S.
Tx(ε ) = t 0 0
t ≤t |Tx|+t if |Tx|+t−1 ∈/ S.
0 0
Note |Tx(ε )| = |Tx|+t for all t ∈ [T]. Moreover, for every path ε ∈ {−1,1}T, there
t ≤t 0
existsafunctionσ ∈
{−1,1}N∪{0}
suchthatσ = ε andσ = ε forallt ∈ [T−1].
|Tx| 1 |Tx(ε )| t+1
0 t ≤t
Thus, the function f ∈ F shatters the path ε and the tree Tx is shattered by F . We claim
σ S S
thatB(Tx) = |S∩{|Tx|,...,|Tx|+T−1}.Toseethis,observethatforeverypathε ∈ {−1,1}T,
0 0
we have
T T
(cid:88) 1{Tx((ε ,−1)) ̸= Tx(cid:0) (ε ,+1)(cid:1) } = (cid:88) 1{|Tx|+t−1 ∈ S}
t <t t <t 0
t=1 t=1
= |S ∩{|x |,...,|x |+T −1}|.
0 0
Thus, B(Tx) = |S ∩ {|x |,...,|x | + T − 1}| and C (F) ≥ sup B(Tx) = sup |S ∩
0 0 T x∈Z x∈Z
{|x|,...,|x|+T −1}|. This completes the proof.
E Proof of Theorem 3.4
The proof of (i) follows from Theorem 3.1 and the fact that C (F) ≤ dim(F). To prove
T
(ii), observe that by Theorem 3.1, it suffices to show that when dim(F) = ∞, we have that
C (F) = ω(1). If dim(F) = ∞, then for every d ∈ N, there exists a shattered trajectory tree
T
T such that B(T) > d. Thus, for every d ∈ N, there exists a depth d′ ∈ N, such that for every
T ≥ d′, there exists a shattered tree T of depth T with B(T) > d. In other words, for every
d ∈ N, there exists a d′ ∈ N such that for all T ≥ d′ we have that C (F) > d. By definition
T
of ω(·), this means that C (F) = ω(1) as needed.
T
F Proof of Theorem 3.5
Proof. (of (i) in Theorem 3.5) To prove (i), pick S = {2t : t ∈ N ∪ {0}} and consider the
function class F from Theorem 3.3. It is not too hard to see that C (F) = Θ(log(T)). In
S T
addition, one can verify that every finite subset of S is a shattered set according to Definition
9. Indeed, consider any finite subset A ⊂ S. For every i ∈ [|A|], let A denote the i’th element
i
of A after sorting A in increasing order. Then, observe that by the construction of F , for
S
every sequence ε ∈ {−1,1}|A|, there exists a function f ∈ F such that f (A ) = ε (A +1)
ε S ε i i i
for every i ∈ [|A|]. By letting H = {f : ε ∈ {−1,1}|A|} in Definition 9, one can verify that
ε
|H| = 2|A| < ∞, and for every x ∈ A and h ∈ H, there exists a g ∈ H such that h(x) = −g(x)
and h(z) = g(z) for all z ∈ A\{x}. Thus, F shatters A ⊂ S. Since finite subsets of S can
S
be arbitrary large, we have that DS(F) = ∞.
Proof. (of (ii) in in Theorem 3.5) To prove (ii), let X = N∪{⋆} and consider the following
evolution function class. For every σ ∈ {−1,1}N , define a sequence a : N → N recursively
σ
such that a (1) = 1 and a (n) = 2a (n−1)+ 1+σn−1 for n ≥ 2. Equivalently, we can define
σ σ σ 2
(cid:16) (cid:17)
the sequence a explicitly by a (1) = 1 and a (n) = 2n−1 +(cid:80)n−1 1+σi 2n−(i+1) for n ≥ 2.
σ σ σ i=1 2
Let S := (cid:83) {a (n)} and note that S = {2n−1,...,2n −1} for every n ≥ 1 and S ∩S = ∅
n σ σ n n r
for all n ̸= r. We establish some important properties about these sequences.
(1) The sequence a is strictly monotonically increasing in its input, and hence invertible.
σ
Accordingly, given a sequence a and an element x ∈ im(a ), let a−1(x) denote the
σ σ σ
index n ∈ N such that a (n) = x.
σ
20(2) For every σ ,σ , if a (n) = a (r), then n = r since S ∩S = ∅ for all n ̸= r.
1 2 σ1 σ2 n r
(3) The value of a (n) depends only on the prefix (σ ,...,σ ). Hence, two strings σ ,σ
σ 1 n−1 1 2
that share the same prefix up to and including index d will have the property that
a (n) = a (n) for all n ≤ d+1.
σ1 σ2
(4) If a (d) = a (d), then a (i) = a (i) for all i ≤ d. This follows by induction. For
σ1 σ2 σ1 σ2
the base case, consider i = d−1. If a (i) ̸= a (i), then a (d) = 2a (i)+
1+σ1,i
̸=
σ1 σ2 σ1 σ1 2
2a (i)+
1+σ2,i
= a (d) for any value of σ and σ . For the induction step, suppose
σ2 2 σ2 1,i 2,i
a (i) = a (i) for some 2 ≤ i < d. Then, if a (i − 1) ̸= a (i − 1), we have that
σ1 σ2 σ1 σ2
a (i) = 2a (i−1)+
1+σ1,i−1
̸= 2a (i−1)+
1+σ2,i−1
= a (i) for any value of σ
σ1 σ1 2 σ2 2 σ2 1,i−1
and σ .
2,i−1
N
We now construct a function class. For every σ ∈ {−1,1} , define the evolution function
(cid:16) (cid:17)
f (x) = ⋆1{x ∈/ im(a )}+a a−1(x)+1 1{x ∈ im(a )}.
σ σ σ σ σ
At a high-level, the evolution function f maps every state in X \im(a ) to ⋆ and every state
σ σ
in im(a ) to the next element in the sequence corresponding to a .
σ σ
N
Consider the function class F = {f : σ ∈ {−1,1} }. We now claim that E (F) = ∞.
σ 1
To see this, fix a depth d ∈ N, and consider the following trajectory tree T of depth d.
Let the root node be labeled by 1, that is T = 1. For all t ∈ [d] and ε ∈ {−1,1}t, let
0
T (ε) = a (t+1)whereε˜denotesanarbitraryextensionofεoverN. Notethatthecompletion
t ε˜
N
can be arbitrary because the value of a (t+1) for any σ ∈ {−1,1} depends only on the
σ
prefix(σ ,...,σ ). OnecanverifythatsuchatreeT isacompletebinarytreeofdepthdwhere
1 t
the root node is labeled with 1 and the internal nodes on depth i ≥ 1 are labeled from left to
right by 2i,2i +1,...,2i+1 −1. Thus, it is clear that B(T) = d since for every internal node
including the root, its two children are labeled by differing states. In addition, observe that
for every path ε ∈ {−1,1}d down T, the function f ∈ F shatters the associated sequence
ε˜
of states, where ε˜ again is an arbitrary completion of ε over N. Indeed, fix a ε ∈ {−1,1}d,
N
a completion ε˜∈ {−1,1} , and consider any t ∈ [d]. Then, by definition of T, we have that
T (ε ) = a (t) and T (ε ) = a (t+1). Consider the function f ∈ F. By definition of
t−1 <t ε˜ t ≤t ε˜ ε˜
f , we have that f (a (t)) = a (t + 1), which implies that f (T (ε )) = T (ε ). Since
ε˜ ε˜ ε˜ ε˜ ε˜ t−1 <t t ≤t
t ∈ [d] was arbitrary, this is true for every t ∈ [d], and thus f shatters the path ε down T
ε˜
as claimed. Since ε ∈ {−1,1}d was also arbitrary, we have that the entire tree T is shattered
by F. Finally, since d ∈ N was arbitrary, this is true for arbitrarily large depths. Thus,
E (F) = ∞.
1
We now show that DS(F) = 1 by proving that F cannot DS-shatter any two instances
x ,x ∈ X. Our proof will be in cases. First, observe that if either x = ⋆ or x = ⋆, then
1 2 1 2
(x ,x ) cannot be shattered since all functions in F will output ⋆ on either x or x . Thus,
1 2 1 2
without loss of generality, suppose both x ,x ∈ N and x < x . Consider any finite subset
1 2 1 2
H ⊂ F and suppose there exists a function h ∈ H such that h(x ) ̸= ⋆. Then, in order to
2
shatter (x ,x ), there must exist a function g ∈ H such that h(x ) ̸= g(x ) but h(x ) = g(x ).
1 2 1 1 2 2
However, if h(x ) = g(x ) ̸= ⋆, then it must be the case that h(x ) = g(x ). To see why,
2 2 1 1
fix an instance x ∈ N, and suppose f (x) = f (x) ̸= ⋆. Then, by properties (2) and (4)
σ1 σ2
above, it must be the case that a−1(x) = a−1(x) = c and a (i) = a (i) for all i ≤ c.
σ1 σ2 σ1 σ2
Thus, if x < x and f (x ) = f (x ) ̸= ⋆, we must have that f (x ) = f (x ) because
1 2 σ1 2 σ2 2 σ1 1 σ2 1
either x ∈/ im(a )∪im(a ) or a−1(x ) < a−1(x ) = a−1(x ). Thus, if H were to satisfy
1 σ1 σ2 σ1 1 σ1 2 σ2 2
the property in Definition 9, there cannot exist a hypothesis h ∈ H such that h(x ) ̸= ⋆.
2
However, if for every h ∈ H, we have that h(x ) = ⋆, then for every h ∈ H, there cannot
2
exist a g ∈ H such that h(x ) = g(x ) and h(x ) ̸= g(x ). Therefore, the two points (x ,x )
1 1 2 2 1 2
21cannot be shattered. Since (x ,x ) and H ⊂ F were arbitrary, this is true for all such points,
1 2
implying that DS(F) ≤ 1. Since |F| ≥ 2, we have also that DS(F) ≥ 1, completing the proof
that DS(F) = 1.
Proof. (of (iii) in Theorem 3.5) To prove part (iii) of Theorem 3.5, we reduce learning dy-
namical systems to online multiclass classification. Let F ⊆ XX and B be any (potentially
randomized)onlinelearnerforF foronlinemulticlassclassificationwithexpectedregretbound
R. We will construct a learner A that uses B as a subroutine such that M (T,F) ≤ R.
A
To that end, let (x ,x ,...,x ) be the realizable stream to be observed by the learner and
0 1 T
consider the following learning algorithm A which makes the same predictions as B while
simulating the stream of labeled instance (x ,x ),...,(x ,x ) to B.
0 1 T−1 T
Algorithm 2 Learning algorithm A.
Input: Online multiclass learner B, initial state x .
0
1 for t = 1,...,T do
2 Pass x t−1 to B and receive prediction zˆ t.
3 Predict xˆ t = zˆ t.
4 Receive next state x t and update B using labeled instance (x t−1,x t).
5 end
Then, observe that
(cid:34) T (cid:35) (cid:34) T (cid:35) T
E (cid:88) 1{xˆ ̸= x } = E (cid:88) 1{zˆ ̸= x } ( ≤i) inf (cid:88) 1{f(x ) ̸= x }+R ( =ii) R (4)
t t t t t−1 t
f∈F
t=1 t=1 t=1
where(i)followsfromtheexpectedregretguaranteeofB and(ii)followsfromthefactthat
the stream of states is realizable. Thus, inf M (T,F) ≤ R. Since B is always guaranteed to
A A
observe a realizable sequence oflabeled instances, pickingthe SOA [Littlestone, 1987, Daniely
et al., 2011] gives that R = L(F). Since the SOA is deterministic, this choice of B implies
that A is deterministic. Part (i) then follows from that the fact that for any deterministic
learner A we have M (T,F) ≥ C (F).
A T
Proof. (of (iv) in Theorem 3.5) To prove part (iv), let X = [0,1] and consider the class of
thresholds F = {x (cid:55)→ 1{x ≥ a} : a ∈ (0,1)}. It is well known that L(F) = ∞. On the
other hand, note that dim(F) = 1 since F(1) = {1}, F(0) = {0}, and F(x) = {0,1} for all
x ∈ (0,1).
G Discrete Linear Systems and Linear Boolean Networks
G.1 Discrete Linear Systems
Proof. (of Theorem 3.6) We first prove the lowerbound. It suffices to show that
inf M (T,F) ≥ r+1.
A
DeterministicA
Let A be any deterministic algorithm and {e ,e ,...,e } be arbitrary r + 1 standard
0 1 r
basis on Rn. This set exists because n ≥ r + 1. Consider a stream such that x = e ,
0 0
x = {−e ,e }\A(x ) for all t ∈ [r], and x = {−e ,e }\A(x ). Here, ∀t ∈ [r], we
t t t <t r+1 1 1 <r+1
choosex tobeanelementoftheset{−e ,e }otherthanA’spredictiononroundt. Similarly,
t t t
x is chosen among {−e ,e }. We can define a stream using A because such a stream can
r+1 1 1
22be simulated before the game starts as A is deterministic. Let {σ }r+1 ∈ {−1,1}r+2 such
t t=0
that (x ,...,x ) = (σ e ,σ e ,σ e ,...,σ e ,σ e ). Consider the integer-valued matrix
0 r+1 0 0 1 1 2 2 r r r+1 1
W⋆ = (cid:80)r σ σ e ⊗e +σ σ e ⊗e . For r+2 ≤ t ≤ T, one can define the stream to
t=1 t−1 t t t−1 r r+1 1 r
be x = W⋆x . Note that the image(W⋆) ⊆ span({e ,...,e }). Thus, rank(W⋆) ≤ r and
t t−1 1 r
W⋆ ∈ F. Finally, since W⋆ satisfies W⋆(σ e ) = σ e for t ∈ [r], W⋆(σ e ) = σ e , and
t−1 t−1 t t r r r+1 1
W⋆x = x for t ≥ r+2, the stream is realizable. By the definition of the stream, A makes
t−1 t
mistakes on all rounds t ∈ {1,...,r+1}. Thus, we have M (T,F) ≥ r+1.
A
To prove the upperbound, fix T ∈ N and suppose that T ≥ r +1 (otherwise C (F) ≤
T
T ≤ r +1). Consider a trajectory tree T of depth T shattered by F. We first show that,
for any path σ ∈ {−1,1}T down T and t ∈ [T − 1], if T ((σ ,−1)) ̸= T ((σ ,+1)),
t+1 ≤t t+1 ≤t
then T (σ ) ∈/ span({T ,T (σ ),...,T (σ }). To prove the contraposition of this state-
t ≤t 0 1 ≤1 t−1 ≤t−1
ment, suppose T (σ ) ∈ span({T ,T (σ ),...,T (σ }). Then, there exists constants
t ≤t 0 1 ≤1 t−1 ≤t−1
a ,...,a ∈ Z such that a T + ...,+a T (σ ) = T (σ ). Thus, every matrix W
0 t−1 0 0 t−1 t−1 ≤t−1 t ≤t
consistent with the sequence T ,T (σ ),...,T (σ ) satisfies WT (σ ) = W(a T +
0 1 ≤1 t−1 ≤t−1 t ≤t 0 0
...,+a T (σ )) = a T (σ ) + ...,+a T (σ ). This implies that the path σ
t−1 t−1 ≤t−1 0 1 ≤1 t−1 t ≤t ≤t+1
is shattered only if T ((σ ,−1)) = T ((σ ,+1)).
t+1 ≤t t+1 ≤t
Next, we show that the branching factor ofeverypath inT can be at mostr+1. Suppose,
for the sake of contradiction, there exists a path σ ∈ {−1,1}T whose branching factor is k >
r+1. We are guaranteed an increasing sequence of time points t ,t ,...,t in {0,...,T −1}
1 2 k
such that T ((σ ,−1)) ̸= T ((σ ,+1)) for all i ∈ [k]. Since t ≥ 1, by our argument
ti+1 ≤ti ti+1 ≤ti 2
above, we are guaranteed that T (σ ) ∈/ span({T ,...,T (σ )}) for all i ∈ {2,...,k}.
ti ≤ti 0 ti−1 ≤ti−1
This further implies that the set S := {T (σ ),...,T (σ )} is a linearly independent
t2 ≤t2 t
k
≤t
k
set. Note that |S| = k − 1 > r. Let W be the matrix such that the associated function
σ
f ∈ F shatters this path σ. By the definition of the tree, we must have that S ⊆ image(W ).
σ σ
Since rank(W ) ≤ r, the set image(W ) must be a subset of a vectorspace of dimension ≤ r.
σ σ
However, this contradicts the fact that S contains at least r+1 linearly independent vectors
in Rn. Thus, the branching factor of every path in T is at most r+1 and B(T) ≤ r+1. Since
T is arbitrary, we have C (F) ≤ r+1.
T
G.2 Linear Boolean Networks
Proof. (of (i) in Theorem 3.7) We claim that it is without loss of generality to consider the
function class G = {x (cid:55)→ Mx(mod 2) : M ∈ {0,1}n×n} ⊂ F. Indeed, for every f ∈ F,
there exists a g ∈ G such that f(x) = g(x) for all x ∈ X. To see this, let W ∈ Zn×n be such
that f(x) = Wx(mod 2) and fix some x ∈ {0,1}n. Then, observe that f(x) = Wx(mod 2) =
(W(mod 2)x)(mod 2) = Mx(mod 2) where M = W(mod 2) ∈ {0,1}n×n. Thus the function
g ∈ G parameterized by M matches f everywhere on X. We now prove that C (G) = n. In
T
the lowerbound, we will use the fact that for a system of n linearly independent equations
with n free variables defined over the integers modulo 2, there exists a unique solution.
Starting with the upperbound, fix T ∈ N and suppose that T ≥ n (as otherwise C (G) ≤
T
T ≤ n). Consider a trajectory tree T of depth T shattered by G. Let σ ∈ {−1,1}T denote
an arbitrary path down T. We first claim that for t ≥ 1 if T (σ ) is linearly dependent mod-
t ≤t
ulo 2 on the preceding sequence of states T ,T (σ ),...,T (σ ), then T ((σ ,−1)) =
0 1 ≤1 t−1 <t t+1 ≤t
T ((σ ,+1)). To see this, suppose that T (σ ) is linearly dependent modulo 2 on the pre-
t+1 ≤t t ≤t
ceding sequence of states T ,T (σ ),...,T (σ ). Then, there exists constants a ,...,a ∈
0 1 ≤1 t−1 <t 0 t−1
{0,1}suchthata T +...+a T (σ )(mod 2) = T (σ ).Thus,everyfunctiong ∈ G consis-
0 0 t−1 t−1 <t t ≤t
tent with the sequence T ,T (σ ),...,T (σ ) outputs a T (σ )+...+a T (σ )(mod 2)
0 1 ≤1 t−1 <t 0 1 ≤1 t−1 t ≤t
onT (σ ),implyingthatthepaths(σ ,−1)and(σ ,+1)areshatteredonlyifT ((σ ,−1)) =
t ≤t ≤t ≤t t+1 ≤t
T ((σ ,+1)) = a T (σ ) + ... + a T (σ )(mod 2). As a consequence, for t ≥ 1, if
t+1 ≤t 0 1 ≤1 t−1 t ≤t
T ((σ ,−1)) ̸= T ((σ ,+1)),thenT (σ )islinearlyindependentmodulo2ofitspreced-
t+1 ≤t t+1 ≤t t ≤t
23ingstates. Next, weclaimthattherecanbeatmostn−1timepointst ,...,t ∈ [T−1]such
1 n−1
thatT (σ )islinearlyindependentofitspreceedingsequenceofstatesT ,T (σ ),...,T (σ ).
ti ≤ti 0 1 ≤1 ti−1 <ti
Indeed, suppose for sake of contradiction there exists n timepoints t ,...,t ∈ [T −1] such
1 n
that T (σ ) is linearly independent of its preceeding states. Then, note that the following
ti ≤ti
set of n+1 states {T ,T (σ ),...,T (σ )} are linearly independent modulo 2. This is a
0 t1 ≤t1 tn ≤tn
contradiction since X is n-dimensional. Combining the two claims, we get that
T T
(cid:88) 1{T ((σ ,−1)) ̸= T (cid:0) (σ ,+1)(cid:1) } ≤ 1+(cid:88) 1{T ((σ ,−1)) ̸= T (cid:0) (σ ,+1)(cid:1) }
t <t t <t t <t t <t
t=1 t=2
T−1
(cid:88)
≤ 1+ 1{T (σ ) linearly indep. of preceeding states}
t ≤t
t=1
≤ 1+n−1 = n.
Since σ ∈ {−1,1}T is arbitrary, we get that B(T) ≤ n. Finally, since T is arbitrary, we
have that C (F) ≤ n which completes the proof of the upperbound.
T
Toprovethelowerbound,letAbeanydeterministicalgorithm. LetE = {e ,...,e } ⊂ X
0 n−1
be the standard basis over Rn. Consider the stream where we pick x = e , for all t ∈ [n−2],
0 0
we pick x ∈ E\{x ,...,x ,A(x )}. Let e = E\{x ,...,x } be the remaining basis. Pick
t 0 t−1 <t 0 n−2
x ∈ {e,e+e }\{A(x )}. Finally, pick x ̸= A(x ). We can define a stream using A
n−1 0 <n−1 n <n
because it is deterministic and thus can be simulated before the game begins. Next, we show
that x ,...,x is a realizable stream. This follows from the fact that x ,...,x are linearly
0 n 0 n−1
independent by definition, and thus there exists a function g ∈ G such that g(x ) = x for
t−1 t
all t ∈ [n]. Moreover, by definition of the stream, A makes a mistake in every round. Thus,
M (T,F) ≥ n. Using the fact that M (T,F) ≤ C (F) completes the proof.
A A T
Proof. (of (ii) in Theorem 3.7) Starting with the lowerbound, it suffices to show that
inf M (T,F) ≥ n.
A
DeterministicA
Let A be any deterministic algorithm and {e ,...,e } be the standard basis on Rn. Consider
1 n
a stream such that x = e +e +...+e , then x = x −e for some i ∈ [n] such that
0 1 2 n 1 0 i1 1
x ̸= A(x ), and for all t ∈ {2,...,n−1},
1 0
x = x −(e +...+e ) such that e ∈/ {e ,...,e } and x ̸= A(x ).
t 0 i1 it it i1 it−1 t <t
Define e = x −(e +...+e ). Note that x = e . Finally, we choose x ∈ {e ,0}
in 0 i1 in−1 n−1 in n in
such that x ∈/ A(x ). Here, ∀t ∈ [n−2], we choose x by subtracting a basis e , which
n <n−1 t it
has not been subtracted before, from x such that x is other than what A would have
t−1 t
predicted on round t. Finally, for x , we either choose it to be equal to x = e again or 0
n n−1 in
while ensuring that x ̸= A(x ). We can define a stream using A because such a stream
n <n−1
can be simulated before the game starts as A is deterministic.
Next, we show that (x ,...,x ) is a realizable stream. Indeed, the boolean matrix
0 n
n
(cid:88)
W⋆ = e ⊗(e +...+e ) +x ⊗e .
i
k
i1 i
k−1
n in
k=2
24satisfies 1{W⋆x > 0} = x for all t ∈ [n]. For t = 1, we have
t−1 t
(cid:32) n (cid:33)
W⋆x = (cid:88) e (cid:10) e +...+e ,x (cid:11) +x
0 i
k
i1 i
k−1
0 n
k=2
n
(cid:88)
= (k−1)e +x
i n
k
k=2
= (k−1)(x −e )+x
0 i1 n
Thus, 1{W⋆x > 0} = x −e = x . For t ∈ {2,...,n−1}, we have
0 0 i1 1
(cid:32) n (cid:33)
W⋆x = (cid:88) e (cid:10) e +...+e ,x −(cid:0) e +...+e (cid:1)(cid:11) +x
t−1 i
k
i1 i
k−1
0 i1 it−1 n
k=2
n
(cid:88) (cid:10) (cid:11)
= e e +...+e ,e +...+e +x
i
k
i1 i
k−1
it in n
k=2
n
(cid:88)
= (k−t)e +x .
i n
k
k=t+1
So, we obtain 1{W⋆x > 0} = x −(e +...+e ) > 0 = x . Finally, since x = e
t−1 0 i1 it t n−1 in
and W⋆e = x , we have 1{W⋆x > 0} = x . By the definition of the stream, A makes
in n n−1 n
mistakes in every round on this stream. Thus, M (T,F) ≥ n.
A
As for the upperbound, since |{0,1}n×n| = 2n2, we have L(F) ≤ log(2n2) = n2. Thus, by
Theorem 3.5 (iii), we must have C (F) ≤ n2.
T
H Proof of Theorem 4.1
Proof. (of upperbound in Theorem 4.1) Let (x ,x ,...,x ) be the stream to be observed by
0 1 T
the learner. Given a multiclass classification learner B for F, consider the algorithm A as
defined in Algorithm F. Here, A makes the same predictions as B while simulating the stream
oflabeledinstance(x ,x ),...,(x ,x )toB. Usingthebound(i)inEquation(4),weobtain
0 1 T−1 T
(cid:34) T (cid:35) T
(cid:88) (cid:88)
E 1{xˆ ̸= x } ≤ inf 1{f(x ) ̸= x }+R,
t t t−1 t
f∈F
t=1 t=1
where expectation is taken with respect to the randomness of B and R is the expected regret
of the B. This shows that RMK(T,F) ≤ R. Taking B to be A defined in [Hanneke et al.,
A AG
(cid:112)
2023, Section 3], Theorem 4 in [Hanneke et al., 2023] implies that R ≤ L(F)+ T L(F)logT,
matching the claimed upperbound in Theorem 4.1.
Proof. (of lowerbound of
L(F)
in Theorem 4.1) Define d := L(F) and let T be the Littlestone
18
tree of depth d shattered by F. Let (T ,...,T ) be the sequence of node-labeling functions
0 d−1
and (Y ,...,Y ) be the sequence of edge labeling functions of the shattered tree T. To
1 d
construct a stream, take r = ⌊d+2⌋ and define a random sequence {n }r such that
3 i i=1
n = 1, n ∼ Unif({3i−1,3i,3i+1}) for all i ∈ [r−1].
1 i+1
Note that n ≤ 3(r−1)+1 = 3r−2 ≤ d. Next, pick a random path (σ ,...,σ ) down the
r 1 d
tree such that σ ∼ Unif{−1,1}. Let x = T be the initial state and consider the stream
i 0 0
Y (σ ),T (σ ),Y (σ ),...,T (σ ),Y (σ ).
n1 ≤n1 n2−1 <n2 n2 ≤n2 nr−1 <nr nr ≤nr
25For any randomized algorithm A, let A denote its prediction on round t. Then, its
t
expected cumulative loss on this stream is
(cid:34) r r (cid:35)
(cid:88) (cid:88)
E 1{A ̸= Y (σ )}+ 1{A ̸= T (σ )} ,
t nt ≤nt t nt−1 <nt
t=1 t=2
where the expectation is taken with respect to A, σ, and n ’s. Note that
t
1
E[1{A ̸= Y (σ )}] ≥ .
t nt ≤nt
2
where the inequality holds because conditioned on the history up to time point t−1, the state
Y (σ ) is chosen uniformly at random between Y ((σ ,−1)) and Y ((σ ,+1)). So,
nt ≤nt nt <nt nt <nt
the algorithm cannot do better than random guessing. Similarly, given a path σ, the state
T (σ ) is selected uniformly from the set
nt−1 <nt
{T (σ ) : m = 3(t−1)−1,3(t−1),3(t−1)+1}.
m−1 <m
Sinceeachnodealongapathmusthavedistinctelements,theaforementionedsetmustcontain
3 elements. Thus, we have
2
E[1{A ̸= T (σ )}] ≥ .
t nt−1 <nt
3
Overall, the total expected cumulative loss of A is
r r
(cid:88) 1 (cid:88) 2 r 2(r−1) 7r−4
≥ + ≥ + = .
2 3 2 3 6
t=1 t=2
To upperbound the loss of the best-fixed competitor, let f ∈ F denote the function that
σ
shattersthepathσinthetreeT. Then,bydefinitionofshattering,wehavef (T (σ )) =
σ nt−1 <nt
Y (σ ). Thus, the cumulative loss of f is
nt ≤nt σ
(cid:34) r r (cid:35)
(cid:88) (cid:88)
E 1{f (T (σ )) ̸= Y (σ )}+ 1{f (Y (σ )) ̸= T (σ )}
σ nt−1 <nt nt ≤nt σ nt−1 ≤nt−1 nt−1 <nt
t=1 t=2
r
(cid:88)
≤ 0+ 1 = r−1.
t=2
Hence, combining everything and plugging the value of r, the regret of A is
7r−4 7r−4−6r+6 r+2 (d+2)/3−1+2 d
RMK(T,F) ≥ −(r−1) = = ≥ ≥ .
A 6 6 6 6 18
This completes our proof.
√
Proof. (oflowerboundof √T inTheorem4.1)Letf −1andf +1beanytwodistinctfunctionsin
16 3
F and x¯ ∈ X be the point where they differ. That is, f (x¯ ) ̸= f (x¯ ). Define S ⊂ X such
0 −1 0 +1 0
that f (x) = f (x) for all x ∈ S. Moreover, define S = {x ∈ S | f (x) = f (x) = x¯ }.
−1 +1 0 −1 +1 0
Let (σ ,...,σ ) be a sequence such that σ ∼ Uniform{−1,1}. Consider a random stream
1 T t
with initial state x = x¯ and for all t ∈ [T],
0 0
x = x¯ 1{x ∈ S }+Uniform({x¯ ,f (x )})1{x ∈ S\S }+f (x )1{x ∈/ S}.
t 0 t−1 0 0 σt t−1 t−1 0 σt t−1 t−1
26For any algorithm A, its expected cumulative loss is
(cid:34) T (cid:35) (cid:34) T (cid:35) (cid:34) T (cid:35)
(cid:88) (cid:88) (cid:88)
E 1{A(x ) ̸= x } = E 1{A(x ) ̸= x }1{x ∈ S } +E 1{A(x ) ̸= x }1{x ∈/ S }
<t t <t t t−1 0 <t t t−1 0
t=1 t=1 t=1
(cid:34) T (cid:35)
≥ 0 + E (cid:88) E(cid:2)1{A(x ) ̸= x } | x ,A(cid:3)1{x ∈/ S }
<t t <t t−1 0
t=1
(cid:34) T (cid:35)
1 (cid:88)
≥ E 1{x ∈/ S } ,
t−1 0
2
t=1
where the final step follows because when x ∈/ S , the state x is sampled uniformly at
t−1 0 t
random between two states. So, the expected loss of algorithm in this round is ≥ 1.
2
To upperbound the cumulative loss of the best-fixed function in hindsight, define σ =
(cid:16) (cid:17)
sign (cid:80)T σ 1{x ∈/ S} . Note that
t=1 t t−1
(cid:34) T (cid:35)
(cid:88)
E inf 1{f(x ) ̸= x }
t−1 t
f∈F
t=1
(cid:34) T (cid:35)
(cid:88)
≤ E 1{f (x ) ̸= x }
σ t−1 t
t=1
(cid:34) T (cid:35) (cid:34) T (cid:35)
(cid:88) (cid:88)
= 0+E 1{f (x ) ̸= x }1{x ∈ S\S } +E 1{f (x ) ̸= f (x )}1{x ∈/ S}
σ t−1 t t−1 0 σ t−1 σt t−1 t−1
t=1 t=1
(cid:34) T (cid:35) (cid:34) T (cid:35)
1 (cid:88) (cid:88)
≤ E 1{x ∈ S\S } +E 1{f (x ) ̸= f (x )}1{x ∈/ S} ,
2
t−1 0 σ t−1 σt t−1 t−1
t=1 t=1
where the final step follows because conditioned on the event that x ∈ S\S , the state x
t−1 0 t
is ∼ Uniform({x¯ ,f (x )}). Since f (x ) = f (x ) whenever x ∈ S, the expected
0 σt t−1 σ t−1 σt t−1 t−1
loss of f on round t is equal to the conditional probability that x = x , which is ≤ 1/2.
σ t 0
Moreover, using the fact that 1{f (x ) ̸= f (x )} ≤ 1{σ ̸= σ }, we have
σ t−1 σt t−1 t
(cid:34) T (cid:35) (cid:34) T (cid:35) (cid:34) T (cid:35)
(cid:88) 1 (cid:88) (cid:88)
E inf 1{f(x ) ̸= x } ≤ E 1{x ∈ S\S } +E 1{σ ̸= σ }1{x ∈/ S}
t−1 t t−1 0 t t−1
f∈F 2
t=1 t=1 t=1
(cid:34) T (cid:35) (cid:34) T (cid:35)
= 1 E (cid:88) 1{x ∈ S\S } +E (cid:88) 1−σσ t1{x ∈/ S}
t−1 0 t−1
2 2
t=1 t=1
(cid:34) T (cid:35) (cid:34) T (cid:35)
1 (cid:88) 1 (cid:88)
= E 1{x ∈/ S } − E σ σ 1{x ∈/ S}
t−1 0 t t−1
2 2
t=1 t=1
(cid:34) T (cid:35) (cid:34)(cid:12) T (cid:12)(cid:35)
1 (cid:88) 1 (cid:12)(cid:88) (cid:12)
= E 1{x ∈/ S } − E (cid:12) σ 1{x ∈/ S}(cid:12) ,
2 t−1 0 2 (cid:12) t t−1 (cid:12)
(cid:12) (cid:12)
t=1 t=1
where the final equality follows from the definition of σ. Thus, the regret of A is
(cid:34) T (cid:35) (cid:34) T (cid:35) (cid:34)(cid:12) T (cid:12)(cid:35)
(cid:88) (cid:88) 1 (cid:12)(cid:88) (cid:12)
RMK(T,F) = E 1{A(x ) ̸= x } −E inf 1{f(x ) ̸= x } ≥ E (cid:12) σ 1{x ∈/ S}(cid:12) .
A <t t f∈F t−1 t 2 (cid:12) (cid:12) t t−1 (cid:12) (cid:12)
t=1 t=1 t=1
We now lowerbound the Rademacher sum above by closely following the proof of Khinchine’s
inequality [Cesa-Bianchi and Lugosi, 2006, Lemma 8.1].
27ForanyrandomvariableY withthefinite-fourthmoment, asimpleapplicationofHolder’s
inequality implies that
(E[Y2])3/2
E[|Y|] ≥ .
(E[Y4])1/2
We apply this inequality to Y := (cid:80)T σ 1{x ∈/ S}. Since Y2 = (cid:80)T 1{x ∈/ S} +
t=1 t t−1 t=1 t−1
2(cid:80) σ σ 1{x ,x ∈/ S}, we have
i<j i j i−1 j−1
 
(cid:34) T (cid:35) (cid:34) T (cid:35)
(cid:88) (cid:88) (cid:88)
E[Y2] = E 1{x t−1 ∈/ S} +2E  E[σ j | σ <j,x <j] σ i1{x i−1,x j−1 ∈/ S} = E 1{x t−1 ∈/ S} ,
t=1 i<j t=1
where the final equality follows because σ is still a Rademacher random variable conditioned
j
on the past and E[σ | σ ,x ] = 0. Furthermore, note that
j <j <j
(cid:34) (cid:88)T (cid:35) ⌊T (cid:88)2⌋−1
E 1{x ∈/ S} ≥ E[1{x ∈/ S}]+ E[1{x ∈/ S}+1{x ∈/ S}]
t−1 0 2r−1 2r
t=1 r=1
⌊T⌋−1
(cid:88)2 1
≥ 1+
2
r=1
(cid:18)(cid:22) (cid:23) (cid:19)
1 T
= +1
2 2
T
≥ .
4
Here,thesecondinequalityaboveuses(i)x = x¯ ∈/ S and(ii)E[1{x ∈/ S}+1{x ∈/ S}] ≥
0 0 2r−1 2r
1 for all r ≥ 1. To see (ii), one can consider two cases. First, if x ∈/ S, then the inequality
2 2r−1
is trivially true. On the other hand, x ∈ S, then x = x¯ ∈/ S with probability 1/2.
2r−1 2r 0
Thus, we have E[Y2] ≥ T.
4
Similarly, for the fourth moment of Y, all the cross-term vanishes and we are left with the
terms with fourth power and symmetric second powers.
 
(cid:34) T (cid:35) (cid:18) (cid:19)
(cid:88) 4 (cid:88)
E[Y4] = E 1{x t−1 ∈/ S} + E  1{x i−1 ∈/ S}1{x j−1 ∈/ S}
2
t=1 i<j
(cid:18) (cid:19)
4 T(T −1)
≤ T +
2 2
≤ T +3T(T −1)
≤ 3T2.
The lower bound on the second moment of Y and the upperbound on the fourth moment of
Y collectively implies that
√
(E[Y2])3/2 (T/4)3/2 T
E[|Y|] ≥ ≥ = √ .
(E[Y4])1/2 (3T2)1/2 8 3
Finally, combining everything, we obtain
(cid:34)(cid:12)
T
(cid:12)(cid:35) √
1 (cid:12)(cid:88) (cid:12) 1 T
RMK(T,F) ≥ E (cid:12) σ 1{x ∈/ S}(cid:12) = E[|Y|] = √ .
A 2 (cid:12) (cid:12) t t−1 (cid:12) (cid:12) 2 16 3
t=1
This completes our proof.
28I Tightness of Upperbound in Theorem 4.1
Fix d ∈ N and let X = {1,2,...,d}∪{±(d+1),±(d+2),...,±2d}. For every σ ∈ {−1,1}d,
define a function f : X → X such that
σ
f (x) = σ (d+x)1{x ∈ [d]}+(|x|−d)1{x ∈/ [d]}.
σ x
Consider F = {f : σ ∈ {−1,1}d}. It is not too hard to see that L(F) = d. The fact that
σ
L(F) ≤ d is trivial because any Littlesone tree can only have {1,2,...,d} in the internal
nodes. This is because all functions output the same state in the domain X\[d]. Since the
internal nodes in any given path of the Littlestone tree need to be different, the depth of any
shattered tree is ≤ d. To see why L(F) ≥ d, consider a complete binary tree T of depth d
with all the internal nodes in level i ∈ [d] containing the element i. Let −(d+i) and (d+i)
label the left and right outgoing edges respectively of every node in level i. Note that T is
shattered by F as for any path ε ∈ {−1,1}d down the tree T, there exists a f ∈ F such that
ε
f (i) = ε (d+i) for all i ∈ [d]. Thus, we have shown that L(F) = d.
ε i
(cid:112)
Wenowshowthatinf RMK(T,F) = Ω( TL(F)),provingthattheupperboundinTheorem
√ A A
4.1 is tight up to logT. For a k ∈ N, pick T = 2kd − 1. Draw ε ∈ {−1,+1}T where
ε ∼ Uniform({−1,1}) and consider a stream
i
x = i, x = ε (d+i)1{x = i}+i1{x ̸= i} ∀i ∈ [d] and t ∈ {2k(i−1)+1,...,2ki−1}.
2k(i−1) t t t−1 t−1
Note that x = 1 is the initial state and there are T = 2kd−1 more states in this stream.
0
For any algorithm A, its expected cumulative loss is
 
(cid:34) T (cid:35) d 2ki−1 d 2ki−1
(cid:88) (cid:88) (cid:88) 1 (cid:88) (cid:88)
E 1{A(x <t) ̸= x t} ≥ E  1{A(x <t) ̸= x t} ≥ 1{x t−1 = i}.
2
t=1 i=1t=2k(i−1)+1 i=1t=2k(i−1)+1
Here, the first inequality is true because we just rewrite the sum without including the rounds
t = 2k,4k,6k,...,2(d−1)k. The second inequality holds because x is sampled uniformly
t
at random between −(d + i) and d + i whenever x = i, and the algorithm cannot do
t−1
better than guessing on these rounds. Note that there is no expectation following the second
inequality because the event x = i is deterministic.
t−1
Toupperboundthelossofthebestfunctioninhindsight,defineε¯ = sign(cid:0)(cid:80)2ki−1 ε 1{x =
i t=2k(i−1)+1 t t−1
(cid:1)
i} and consider f where ε¯= (ε¯ ,...,ε¯ ). Then,
ε¯ 1 d
(cid:34) T (cid:35) (cid:34) T (cid:35)
(cid:88) (cid:88)
E inf 1{f(x ) ̸= x } ≤ E 1{f (x ) ̸= x }
t−1 t ε¯ t−1 t
f∈F
t=1 t=1
 
d 2ki−1
(cid:88) (cid:88)
≤ (d−1)+E  1{f ε¯(x t−1) ̸= x t}
i=1t=2k(i−1)+1
 
d 2ki−1
(cid:88) (cid:88)
= (d−1)+E  1{f ε¯(x t−1) ̸= x t}1{x t−1 = i}.
i=1t=2k(i−1)+1
Here, the second inequality holds because we trivially upperbound the losses on rounds
t = 2k,4k,...,2(d − 1)k by 1. And the final equality follows because f (x ) = i =
ε¯ t−1
x whenever x ̸= i for 2k(i − 1) + 1 ≤ t ≤ 2ki − 1. Moreover, when x = i, we have
t t−1 t−1
f (x ) = ε¯(d+i) and x = ε (d+i). This implies that 1{f (x ) ̸= x }1{x = i} =
ε¯ t−1 i t t ε¯ t−1 t t−1
291{ε¯ ̸= ε }1{x = i}. Thus, we can write
i t t−1
(cid:34) T (cid:35)
(cid:88)
E inf 1{f(x ) ̸= x }
t−1 t
f∈F
t=1
 
d 2ki−1
(cid:88) (cid:88)
≤ (d−1)+E  1{ε¯ i ̸= ε t}1{x t−1 = i}
i=1t=2k(i−1)+1
 
d 2ki−1
= (d−1)+E (cid:88) (cid:88) 1−ε¯ iε t 1{x
t−1
= i}
2
i=1t=2k(i−1)+1
 
d 2ki−1 d 2ki−1
(cid:88) (cid:88) 1 1 (cid:88) (cid:88)
= (d−1)+ 1{x t−1 = i}− E  ε¯ i ε t1{x t−1 = i}
2 2
i=1t=2k(i−1)+1 i=1 t=2k(i−1)+1
 (cid:12) (cid:12)
d 2ki−1 d (cid:12) 2ki−1 (cid:12)
= (d−1)+(cid:88) (cid:88) 1 1{x t−1 = i}− 1 E (cid:88)(cid:12) (cid:12) (cid:88) ε t1{x t−1 = i}(cid:12) (cid:12)
2 2 (cid:12) (cid:12)
i=1t=2k(i−1)+1 i=1(cid:12)t=2k(i−1)+1 (cid:12)
Thus, the expected regret of A is
(cid:34) T (cid:35) (cid:34) T (cid:35)
(cid:88) (cid:88)
RMK(T,F) = E 1{A(x ) ̸= x } −E inf 1{f(x ) ̸= x }
A <t t t−1 t
f∈F
t=1 t=1
 (cid:12) (cid:12)
d (cid:12) 2ki−1 (cid:12)
≥ 1 E (cid:88)(cid:12) (cid:12) (cid:88) ε t1{x t−1 = i}(cid:12) (cid:12)−(d−1)
2 (cid:12) (cid:12)
i=1(cid:12)t=2k(i−1)+1 (cid:12)
d (cid:114)
1 (cid:88) |{2k(i−1)+1 ≤ t ≤ 2ki−1 : x t−1 = i}|
≥ −(d−1)
2 2
i=1
d (cid:114)
1 (cid:88) k
= −(d−1).
2 2
i=1
where the second inequality follows due to Khinchine’s inequality [Cesa-Bianchi and Lugosi,
2006, Lemma 8.2]. The final equality holds because in each block of 2k rounds from t =
2k(i−1)+1 to t = 2ki−1, we have x = i in exactly k of those rounds. Using T = 2kd−1,
t−1 √
we further obtain RMK(T,F) ≥
1(cid:112)
(T +1)d−(d−1) = Ω( Td) for T ≫ d. This establishes
A 4 √
our claim that the upperbound in Theorem 4.1 is tight up to logT.
J Proof of Theorem 5.1
ThelowerboundinTheorem5.1followsdirectlyfromthelowerboundintherealizablesetting.
Accordingly, we only prove the upperbound. Let K := sup |F(x)|.
x∈X
Proof. (of the upperbound in Theorem 5.1) Let {x }T be the trajectory to be observed
t t=0
by the learner and f⋆ ∈ argmin (cid:80)T 1{x ̸= ft(x )} the optimal evolution function in
f∈F t=1 t 0
hindsight. Given the time horizon T, let L = {L ⊂ [T] : |L| ≤ C (F)} denote the set of all
T T
possible subsets of [T] with size at most C (F). For every L ∈ L , let ϕ : L → [K] denote
T T
a function mapping time points in L to an integer in [K]. On time point t ∈ L, we should
think of ϕ(t) as an index into the set F(x ). To that end, for an index i ∈ [|F(x)|], let
t−1
F (x) denote the i-th element of the list obtained after sorting F(x) in its natural order. Let
i
30Φ = [K]L denote all such functions ϕ. For each L ∈ L and ϕ ∈ Φ , define an expert E .
L T L L,ϕ
On time point t ∈ [T], the prediction of expert E is defined recursively by
L,ϕ
(cid:40) A(cid:0)
x ,t|{E (x
,i)}t−1(cid:1)
, if t ∈/ L
E (x ,t) = 0 L,ϕ 0 i=1
L,ϕ 0
F (E (x ,t−1)), otherwise
ϕ(t) L,ϕ 0
where E (x ,0) = x and
A(cid:0)
x ,t|{E (x
,i)}t−1(cid:1)
denotes the prediction of Algorithm
L,ϕ 0 0 0 L,ϕ 0 i=1
1 on timepoint t after running and updating on the trajectory {E (x ,i)}t−1. Let E =
L,ϕ 0 i=1
(cid:83) (cid:83)
E denote the set of all experts parameterized by L ∈ L and ϕ ∈ Φ .
L∈LT ϕ∈ΦL L,ϕ T L
We claim that there exists an expert E such that E (x ,t) = f⋆,t(x ) for all
L⋆,ϕ⋆ L⋆,ϕ⋆ 0 0
t ∈ [T]. To see this, consider the hypothetical trajectory S⋆ = {f⋆,t(x )}T generated by f⋆.
0 t=1
Let L⋆ = {t ,t ,...} be the indices on which Algorithm 1 would have made a mistake had
1 2
it run and updated on S⋆. By the guarantee of Algorithm 1, we know that |L⋆| ≤ C (F).
T
Moreover, there exists a ϕ⋆ ∈ Φ such that F (f⋆,i−1(x )) = f⋆,i(x ) for all i ∈ L⋆.
L⋆ ϕ⋆(i) 0 0
By construction of E, there exists an expert E parameterized by L⋆ and ϕ⋆. We claim
L⋆,ϕ⋆
that E (x ,t) = f⋆,t(x ) for all t ∈ [T]. This follows by strong induction on t ∈ [T].
L⋆,ϕ⋆ 0 0
For the base case t = 1, there are two subcases to consider. If 1 ∈ L⋆, then we have that
E (x ,1) = F (E (x ,0)) = F (x ) = f⋆,1(x ). If 1 ∈/ L⋆, then E (x ,1) =
L⋆,ϕ⋆ 0 ϕ⋆(1) L⋆,ϕ⋆ 0 ϕ⋆(1) 0 0 L⋆,ϕ⋆ 0
A(x ,1|{}) = f⋆,1(x ), where the last equality follows by definition of L⋆. Now for the
0 0
induction step, suppose that E (x ,i) = f⋆,i(x ) for all i ≤ t. Then, if t+1 ∈ L⋆, we have
L⋆,ϕ⋆ 0 0
that E (x ,t + 1) = F (E (x ,t)) = F (f⋆,t(x )) = f⋆,t+1(x ). If t + 1 ∈/
L⋆,ϕ⋆ 0 ϕ⋆(t+1) L⋆,ϕ⋆ 0 ϕ⋆(t+1) 0 0
L⋆, then E (x ,t + 1) = A(cid:0) x ,t+1|{E (x ,i)}t (cid:1) = A(cid:0) x ,t+1|{f⋆,i(x )}t (cid:1) =
L⋆,ϕ⋆ 0 0 L⋆,ϕ⋆ 0 i=1 0 0 i=1
f⋆,t+1(x ), where the last equality again is due to the definition of L⋆.
0
Now, consider the learner that runs the celebrated Randomized Exponential Weights Al-
(cid:113)
2ln(|E|)
gorithm,denotedhereinafterbyP,usingthesetofexpertsE withlearningrateη = .
T
By Theorem 21.11 of Shalev-Shwartz and Ben-David [2014], we have that
(cid:34) T (cid:35) T
(cid:88) (cid:88) (cid:112)
E 1{P(x ,t) ̸= x } ≤ inf 1{E(x ,t) ̸= x }+ 2T ln(|E|)
0 t 0 t
E∈E
t=1 t=1
(cid:115)
T
(cid:88) (cid:16) KT (cid:17)
≤ inf 1{E(x ,t) ̸= x }+ 2C (F)T ln
0 t T
E∈E C T(F)
t=1
(cid:115)
T
(cid:88) (cid:16) KT (cid:17)
≤ 1{E (x ,t) ̸= x }+ 2C (F)T ln
L⋆,ϕ⋆ 0 t T
C (F)
T
t=1
(cid:115)
T
(cid:88) (cid:16) KT (cid:17)
= 1{f⋆,t(x ) ̸= x }+ 2C (F)T ln
0 t T
C (F)
T
t=1
where the second inequality follows because |E| = (cid:80)CT(F) Ki(cid:0)T(cid:1) ≤
(cid:16)
KT
(cid:17)CT(F)
. This
i=0 i CT(F)
completes the proof as P achieves the stated upperbound on expected regret.
The next two examples show that both the lower- and upperbounds in Theorem 5.1 can
be tight.
J.1 Tightness of Lowerbound in Theorem 5.1
Let X = Z and fix p ∈ N. For every σ ∈ {−1,1}N∪{0}, define the evolution function
f (x) = (σ 1{|x| ≤ p−1}+1{|x| ≥ p})(|x|+1)
σ |x|
31(cid:110) (cid:111)
and consider the class F = f : σ ∈
{−1,1}N∪{0}
. By construction of F, branching only
σ
occurs on states in {0,1,...,p − 1} and their negation. Moreover, given any initial state
x ∈ X and a time horizon T ∈ N, the trajectory of any evolution in F is some signed
0
version of the sequence |x |+1,...,|x |+T. From Theorem 3.3, its not too hard to see that
0 0
C (F) = min{p,T}. We now show that inf RFL(T,F) ≤ CT(F) . Consider the learner A
T A A 2
which, given initial state x , checks whether |x | ≤ p − 1. If |x | ≤ p − 1, the learner A
0 0 0
samples a random sequence ε ∼ {−1,1}p−|x0| and plays ε t(|x 0|+t) for t ≤ p−|x 0| and |x 0|+t
in all future rounds t > p−|x |. If |x | > p−1, the learner A plays |x |+t for all t ≥ 1.
0 0 0
Let {x }T be the trajectory to be observed by the learner. If |x | > p−1, then observe
t t=0 0
that
(cid:34) T T (cid:35)
(cid:88) (cid:88)
RFL(T,F) = E 1{A(x ) ̸= x }− inf 1{ft(x ) ̸= x }
A <t t 0 t
f∈F
t=1 t=1
(cid:34) T T (cid:35)
(cid:88) (cid:88)
= E 1{|x |+t ̸= x }− inf 1{|x |+t ̸= x } = 0
0 t 0 t
f∈F
t=1 t=1
On the other hand, if |x | ≤ p−1, we can write the learner’s expected loss as
0
 
(cid:34) T (cid:35) p−|x0| T
(cid:88) (cid:88) (cid:88)
E 1{A(x <t) ̸= x t} = E  1{ε t(|x 0|+t) ̸= x t}+ 1{|x 0|+t ̸= x t}.
t=1 t=1 t=p−|x0|+1
Similarly, we can write the cumulative loss of the competitor term as:
T p−|x0| T
(cid:88) (cid:88) (cid:88)
inf 1{ft(x ) ̸= x } = inf 1{ft(x ) ̸= x }+ 1{|x |+t ̸= x }.
0 t 0 t 0 t
f∈F f∈F
t=1 t=1 t=p−|x0|+1
Let f = argmin
(cid:80)p−|x0|1{ft(x
) ̸= x }. Combining both bounds, we get that:
σ f∈F t=1 0 t
(cid:34) T T (cid:35)
(cid:88) (cid:88)
RFL(T,F) = E 1{A(x ) ̸= x }− inf 1{ft(x ) ̸= x }
A <t t 0 t
f∈F
t=1 t=1
 
p−|x0|
(cid:88)
≤ E  1{ε t(|x 0|+t) ̸= x t}−1{f σt(x 0) ̸= x t}
t=1
 
p−|x0|
(cid:88)
≤ E  1{ε t(|x 0|+t) ̸= f σt(x 0)}
t=1
 
= E
p− (cid:88)|x0|
1{ε t(|x 0|+t) ̸= σ |x0|+t−1(|x 0|+t)} =
p− 2|x 0|
,
t=1
where in the last equality we used the fact that ε ∼ Unif(−1,1). Thus, the expected regret of
t
such an learner A is at most min{max{p−|x0|,0},T} . Taking x = 0, gives that inf RFL(T,F) ≤
2 0 A A
CT(F)
.
2
32J.2 Tightness of Upperbound in Theorem 5.1
Let X = Z and fix p ∈ N. Let G = {(0,s ,...,s ) : s < s < ... < s ∈ N} be the set of all
1 p 1 2 p
ordered tuples of extended natural numbers with size p+1. For any S ∈ G and x ∈ N∪{0},
let S = max{s ∈ S : s ≤ x} be the largest element in S smaller than x. Note that S = 0
x 0
for all S ∈ G. For every σ ∈
{−1,1}N∪{0}
and S ∈ G, consider the evolution function:
f (x) = σ (|x|+1).
σ,S S
|x|
Given any initial state x ∈ X and time horizon T ∈ N, the trajectory {ft (x )}T is
0 σ,S 0 t=1
some signed version of the sequence (|x |+1,...,|x |+T), where the signs depend on S and
0 0
σ. More importantly, the trajectory {ft (x )}T switches signs at most p+1 times. Finally,
σ,S 0 t=1
consider the evolution class F = {f : σ ∈
{−1,1}N∪{0},S
∈ G}. Since the trajectory of
σ,S
any evolution f ∈ F can switch signs at most p+1 times, it follows that C (F) ≤ p+1.
T
Moreover, by considering a trajectory tree with the root node labeled by 0 and the set of
evolutions parameterized by the tuple (0,1,...,p) ∈ G, its not hard to see that C (F) ≥ p+1.
T
Thus, C (F) = p+1.
T
(cid:113)
We now claim that inf RFL(T,F) ≥ CT(F)T , which shows that the upperbound in
A A 8
Theorem 5.1 is tight up to a logarithmic factor in T since sup |F(x)| = 2. Consider
x∈X
(cid:16) (cid:17)
T = k(p + 1) for some odd k ∈ N. For ε ∈ {−1,1}T, define ε˜ = sign (cid:80)ik ε
i t=(i−1)k+1 t
for all i ∈ {1,2,...,p+1}. The game proceeds as follows. The adversary samples a string
ε ∈ {−1,1}T uniformlyatrandomandconstructstherandomtrajectory{x }T wherex = 0
t t=0 0
is the initial state and x = ε t for all t ≥ 1. The adversary then passes {x }T to the learner.
t t t t=0
Let A be any randomized learner. Then, for each block i ∈ [p+1], we have that
 
ik ik
(cid:88) (cid:88) 1 k
E  1{A(x <t) ̸= x t} ≥ = ,
2 2
t=(i−1)k+1 t=(i−1)k+1
where the inequality follows from the fact that x is chosen uniformly at random between
t
t and −t. Let f ∈ F be the function in F such that S = (0,k,2k,...,(p+1)k) and σ = ε˜
σ,S S i
|x|
for all (i−1)k ≤ |x| ≤ ik−1 and i ∈ {1,...,p+1}. For each block i ∈ [p+1], we have
   
ik ik
(cid:88) (cid:88)
E  1{f σt ,S(0) ̸= x t} = E  1{σ S |t−1|t ̸= ε tt}
t=(i−1)k+1 t=(i−1)k+1
 
ik
(cid:88)
= E  1{ε˜ i ̸= ε t}
t=(i−1)k+1
 
ik
k 1 (cid:88)
= − E  ε˜ iε t
2 2
t=(i−1)k+1
 
ik
k 1 (cid:12) (cid:88) (cid:12)
= 2 − 2E (cid:12) (cid:12) ε t(cid:12) (cid:12)
t=(i−1)k+1
(cid:114)
k k
≤ − ,
2 8
where the final step follows upon using Khinchine’s inequality [Cesa-Bianchi and Lugosi,
2006]. Combining these two bounds above, we obtain,
33 
ik ik (cid:114)
(cid:88) (cid:88) k
E  1{A(x <t) ̸= x t}− 1{f σt ,S(0) ̸= x t} ≥ 8.
t=(i−1)k+1 t=(i−1)k+1
Summing this inequality over p+1 blocks, we obtain
(cid:34) T T (cid:35) (cid:34) T T (cid:35)
(cid:88) (cid:88) (cid:88) (cid:88)
E 1{A(x ) ̸= x }− inf 1{ft(x ) ̸= x } ≥ E 1{A(x ) ̸= x }− 1{ft (x ) ̸= x }
<t t 0 t <t t σ,S 0 t
f∈F
t=1 t=1 t=1 t=1
(cid:114) (cid:114)
k C (F)T
T
≥ (p+1) = ,
8 8
which completes our proof.
K Proof of Lemma 5.2
Our proof of Theorem 5.2 is constructive. That is, we provide an evolution function class and
show that there exists a deterministic algorithm with a mistake bound of 3 in the realizable
setting. As for the agnostic setting, we use the probabilistic method to argue the existence of
a hard stream such that every algorithm incurs T/6 regret.
Let X = {−1,1}N ×Z. For every σ ∈ {−1,1}N , define an evolution function
f ((θ,z)) = (σ,σ (|z|+1)) 1{|z|+1 = 0(mod 3)}+(1,σ (|z|+1)) 1{|z|+1 ̸= 0(mod 3)},
σ |z|+1 |z|+1
where θ ∈ {−1,1}N ,z ∈ Z, and 1 := (1,1,...,1,1) is the string of all ones. Consider the
(cid:110) (cid:111)
N
evolution function class F = f : σ ∈ {−1,1} .
σ
To prove (i), it suffices to note that for any initial state (θ ,z ) and f ∈ F, the realizable
0 0 σ
stream {ft((θ ,z ))}T must reveal σ within the first three rounds t ∈ {1,2,3}. A determin-
σ 0 0 t=1
istic algorithm A that plays arbitrarily in the beginning and ft((θ ,z )) for all t ≥ 4 makes
σ 0 0
no more than 3 mistakes.
To prove (ii), consider a random trajectory such that x = (1,0) is the initial state
0
and {x }T = {(1,ε t)}T , where ε ∼ Uniform({−1,1}). Since the stream is generated
t t=1 t t=1 t
uniformly at random, for any algorithm A, we must have
(cid:34) T (cid:35)
(cid:88) T
E 1{A(x ) ̸= (1,ε t)} ≥ .
<t t
2
t=1
N
Next, let ε ∈ {−1,1} be any completion of (ε ,...,ε ) and consider the function f ∈ F.
1 T ε
Note that, for every t ∈ [T], we have f (1,ε (t − 1)) = (1,ε t) if t ̸= 0(mod 3) and
ε t−1 t
f (1,ε (t−1)) = (ε,ε t) ̸= (1,ε t) if t = 0 (mod)3. Moreover, it is not too hard to see that
ε t−1 t t
ft((1,0)) = (ε,ε t) 1{t = 0(mod 3)}+(1,ε t) 1{t ̸= 0(mod 3)}.
ε t t
Since the functions f ∈ F ignore the first argument of the tuple, we have ft((1,0)) =
ε
34f (ft−1(1,0)) = f ((1,ε (t−1))). So, using the equality established above, we obtain
ε ε ε t−1
T T
(cid:88) (cid:88)
inf 1{ft(x ) ̸= x } ≤ 1{ft(x ) ̸= x }
0 t ε 0 t
f∈F
t=1 t=1
T
(cid:88)
≤ 1{ft((1,0)) ̸= (1,ε t)}
ε t
t=1
T
(cid:88)
= 1{f ((1,ε (t−1))) ̸= (1,ε t)}
ε t−1 t
t=1
T
(cid:88) T
= 1{t = 0(mod 3)} ≤ .
3
t=1
Therefore, we have RFL(T,F) ≥ T − T ≥ T.
A 2 3 6
35