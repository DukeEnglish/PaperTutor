RQP-SGD: DIFFERENTIAL PRIVATE MACHINE LEARNING
THROUGH NOISY SGD AND RANDOMIZED QUANTIZATION ∗
CeFeng,ParvVenkitasubramaniam
DepartmentofElectricalandComputerEngineering
LehighUniversity
City
{cef419, pav309}@lehigh.edu
ABSTRACT
TheriseofIoTdeviceshaspromptedthedemandfordeployingmachinelearningat-the-edgewith
real-time, efficient, and secure data processing. In this context, implementing machine learning
(ML)modelswithreal-valuedweightparameterscanprovetobeimpracticalparticularlyforlarge
models,andthereisaneedtotrainmodelswithquantizeddiscreteweights. Atthesametime,these
low-dimensionalmodelsalsoneedtopreserveprivacyoftheunderlyingdataset. Inthiswork,we
presentRQP-SGD,anewapproachforprivacy-preservingquantizationtotrainmachinelearning
modelsforlow-memoryML-at-the-edge. Thisapproachcombinesdifferentiallyprivatestochastic
gradientdescent(DP-SGD)withrandomizedquantization,providingameasurableprivacyguarantee
in machine learning. In particular, we study the utility convergence of implementing RQP-SGD
onMLtaskswithconvexobjectivesandquantizationconstraintsanddemonstrateitsefficacyover
deterministicquantization. Throughexperimentsconductedontwodatasets,weshowthepractical
effectivenessofRQP-SGD.
1 Introduction
AsIoTdevicesproliferateacrossindustries,thereisanincreasingdemandtoprocessdataclosertothesource[1,2],
enablingreal-timeinsightsanddecision-making. Thereisnowagrowingneedformachinelearning(ML)at-the-edge,
whereMLmodelsaredeployeddirectlyontoIoTdevicesorgateways,enablingthemtoperformdataanalysisand
makepredictionslocally,withouttheneedtotransmitrawdatatocentralizedservers. Thisapproachnotonlyreduces
latencyandconservesnetworkresourcesbutcanalsoenhanceprivacyandsecurity.
AlthoughMLalgorithmshaveshowntremendoussuccessinvariousdomains,MLattheedgebringsuniqueconstraints
inthelimiteddimensionalityofthemodelslearned,andtheneedforstrongprivacyguarantees,particularlyforIoT
deployedinsensitiveapplicationssuchashealthmonitoringandenergymanagement. Theobjectiveofthisworkisto
proposeajointprivacy-preservingquantizationapproachtotrainneuralnetworksforML-at-the-edgeIoTapplications.
Past studies [3–6] propose different approaches to guaranteeing privacy in ML, notably through the concept of
differential privacy [7] - a widely accepted quantitative measure of privacy. Specifically, these methods rely on a
noisytrainingapproachknownasDifferentiallyPrivateStochasticGradientDescent(DP-SGD).DP-SGD[8]directly
perturbsthegradientateachdescentupdatewithrandomnoisedrawnfromtheGaussiandistribution,resultingina
significantimpactonutility. Severalrecentpapersproposenoisereductionmethodsforthedifferentiallyprivatenoise
addedtothereducedgradient. Forinstance,recentstudiesby[4,9,10]haveexploredmethodsforapplyingDP-SGD
togradientsinareduceddimensionalspace. Anotherwork[11]performsdifferentiallyprivateperturbationsinthe
spectraldomainandintroducesfilteringfornoisereduction.
In this work, we propose Randomized Quantization Projection-Stochastic Gradient Descent (RQP-SGD), a new
approachtoachievingdifferentialprivacyinMLwhenweightsneedtobediscretized. Ourworkismotivatedbythe
knowledgethatquantizationisaprocessofremovingredundantinformationbyconvertingmodelparametersfrom
∗Thisworkisacceptedbythe5thAAAIWorkshoponPrivacy-PreservingArtificialIntelligence.
4202
beF
9
]GL.sc[
1v60660.2042:viXrahigh-precisiontolow-precisionrepresentations. Sinceprivacyalsorequirestheremovalofsensitiveinformation,our
approachexploitsthesynergiesbetweenthesetwoprocesses. Furthermore,quantizationeffectivelyreducesthememory
andcomputationcostsofdeployingMLmodels,thuscateringtothespecificapplicationinconsideration. Inthiswork,
ourapproachistodevelopandanalyzearandomizedquantizationapproachinthetrainingofMLmodelsthatcan
providemeasurabledifferentialprivacy. Astudy[12]introducedarandomizedrequantizationtechnique,primarily
usedasacompressionmechanisminIoTsystemsandsensornetworks. Thistechniquesimultaneouslyachieveslocal
differentialprivacyandcompression. However,italsohighlightsanotabletrade-offbetweenprivacy,compression,and
utility,aconsequenceoftheinformationlossinherentinquantization. Ourresearchextendstheparadigmofrandomized
quantizationtothedomainofmachinelearning,adaptingitintoaprojectedstochasticgradientdescent(Proj-SGD).
Wefurthershowthatourproposedapproachachievesabetterutility-privacytrade-offthandeterministicquantization
throughtheoreticalanalysisandexperimentalvalidation.
MainContributionThemaincontributionsofthepaperareasfollows:
• WeproposeRQP-SGD,arandomizedquantizationprojectionbasedSGDinMLwithadifferentialprivacy
guarantee.
• We theoretically study the utility-privacy trade-off of RQP-SGD for ML with convex and bounded loss
functions.
• Through experiments on two classification datasets: MNIST and Breast Cancer Wisconsin (Diagnostic)
dataset [13], the latter being a dataset collected from IoT devices, we demonstrate that RQP-SGD can
achievebetterutilityperformancethanimplementingDP-SGDinmachinelearningwithquantizedparameters.
Significantly, RQP-SGD achieves a 35% higher accuracy on the Diagnostic dataset while maintaining a
(1.0,0)-DP,therebyvalidatingitscompatibilityandefficacyfordeploymentinIoTsystems.
• We conduct a comprehensive experimental analysis of how various RQP parameters influence the utility-
privacy balance. This includes examining the effects of quantization-induced randomness, noise scale in
gradientupdates, andquantizationbitgranularity. Ourfindingshighlightthatwhilequantization-induced
randomnesscanenhanceutility,excessiverandomnessmayhaveadetrimentaleffectonutility.
1.1 RelatedWork
The subject of differential privacy in ML has attracted significant scientific interest in recent years. Specifically,
it has been used in support vector machine [14], linear/logistic regression [15,16] and risk minimization [17–20].
DP-SGD[3,8]asmentionedearlierperturbsthegradientateachSGDupdate.
QuantizationinMLiscategorizedintotwotypes: post-trainingquantization(PTQ)[21–23],andquantizationaware
training(QAT)[24–26]. Ourworkfitsintothelattercategory,modelingthequantizedMLasaquantization-constrained
optimizationproblem[27].
Differentiallyprivatequantizationschemeinreleasingdatahasbeenstudiedin[12,28]. Wenoteanotherapplication
ofdifferentialprivacyandquantizationinMLisfederatedlearning. Inrecentyears,there’sbeenagrowingbodyof
research[29–31]thataimstostudyprivacy-communicationtrade-offinfederatedlearning. Themainobjectiveof
privateandefficientfederatedlearningistransferringprivate,low-bandwidthgradientvectorstotheserver.
2 Preliminary
DifferentialPrivacy(DP) Differentialprivacy[7]isaquantitativedefinitionofprivacy,initiallydesignedinthe
contextofdatabases. Specifically,itensuresthatwhetherornotanindividual’sdataisincludedinadatasetdoesnot
significantlyaffecttheanalysisresultsonthatdataset. ArandomizedmechanismM:D (cid:55)→Rsatisfies(ϵ,δ)-DPiffor
anytwoadjacentsetsd,d′ ∈DandallpossibleoutputsOofM,itholdsthat
Pr[M(d)∈O]⩽eϵPr[M(d′)∈O]+δ
Aprevalentapproachinapplyingdifferentialprivacytoareal-valuedfunctionf : D (cid:55)→ Rinvolvestheadditionof
noisethatiscarefullycalibratedtofunction’ssensitivityS . Thesensitivity,S ,isdefinedasthemaximumpossible
f f
difference|f(d)−f(d′)|betweentheoutputsoff foranytwoadjacentinputsdandd′. Acommonexampleisthe
Gaussianmechanism,whichinvolvesaddingnoiseperturbedbyaGaussiandistributiondirectlytotheoutputofthe
functionf. Thisprocesscanbeformulatedas:
Gauss(f,d,σ)=f(d)+N(0,S2σ2)
f
whereN(0,S2σ2)istheGaussiandistributionwithzeromeanandvarianceS2σ2. TheGaussianmechanismachieves
f f
(cid:112)
(ϵ,δ)-DPwhenσ = 2log(1.25/δ)/ϵ[32].
2MachineLearningAsEmpiricalRiskMinimization Inthispaper,weframethetrainingofamachinelearning
(ML)modelasempiricalriskminimization(ERM),utilizingadatasetS ={(x ,y )∈X ×Y):i=1,2,··· ,n}ofn
i i
data-labelpairs. TheMLmodelisdenotedbyapredictorf : X ×W (cid:55)→Y featuredbyasetofparametersw ∈W.
Thequalityofthepredictorontrainingdataisquantifiedthroughanon-negativelossfunctionl:Y ×Y (cid:55)→R. Weaim
tochooseoptimalwthatminimizestheempiricalloss:
n
min Lˆ(w;S):= 1 (cid:88) l(f(x ;w),y ) (1)
w∈W n i i
i=1
StochasticGradientDescent(SGD)isawidelyusedoptimizationmethodinmachinelearning. Ateachiteration,SGD
selectsamini-batchconsistingofmtrainingsamplesandcomputesthestochasticgradient(cid:80)m
∇l(f(w ;x );y ).
j=1 t j j
Thisgradientservesasanestimationofthegradientderivedfromtheentiretrainingdataset.Thistechniqueincrementally
adjustsmodelparametersbythestochasticgradient,effectivelyguidingthemodeltowardsoptimalperformance.
Differential Privacy in Machine Learning In the realm of machine learning, the ability of models to discern
intricatepatternsfromtrainingdatasetsbringsforthsignificantprivacyconcerns,particularlyregardingtheinadvertent
memorization and subsequent exposure of individual data points. This issue becomes more pronounced with the
adventofsophisticatedtechniquessuchasmodelinversionandmembershipinferenceattacks,whichcanexploitthese
vulnerabilitiestoinfringeuponindividualprivacy.
In addressing the privacy concerns inherent in machine learning, the framework of differential privacy (DP) has
emergedasaformalizedmethodology. Itisintricatelydesignedtoquantifyandattenuatetherisksassociatedwiththe
disseminationofinformationextractedfromsensitivedatasets. Itensuresthatmachinelearningmodeloutputsare
carefullycalibratedtopreventtheinferenceofsensitiveinformationaboutanyparticularindividual.
Mathematically, for the machine learning predictor denoted as f, it satisfies (ϵ,δ)-DP if for any two adjacent sets
x,x′ ∈X,thefollowingholds:
Pr[f(w;x)]≤eϵPr[f(w;x′)]+δ (2)
Thisformulaisfoundationaltotheprincipleofdifferentialprivacyinmachinelearning. Itisdesignedtocontrolthe
probabilitydistributionofoutcomesfromtheprivatemachinelearningmodelinamannerthatisminimallyinfluenced
bythepresenceorabsenceofanyindividualdatawithinthetrainingdataset.
A prevalent technique to attain differential privacy in machine learning is differentially private stochastic gradient
descent (DP-SGD). DP-SGD modifies the standard SGD update rule to incorporate the Gaussian mechanism, as
describedbythefollowingformulation:
m
1 (cid:88)
w =w −η· [ ∇l(f(w ;x );y )+G ] (3)
t+1 t m t j j t
j=1
wherew denotestheupdatedmodelparameters,ηisthestepsize,andthegradient∇l(f(w ;x );y )iscalculated
t+1 t j j
ateacht-thiterationusingthedatapair(x ,y ). ThekeytoDP-SGDistoaddGaussiannoisevectorG whichis
j j t
calibratedtothesensitivityof∇l(f(w ;x );y ). Theinclusionofthisnoisygradient,processedthroughtheGaussian
t j j
mechanism, ensures the privatization of the gradient. The gradient descent serves as the post-processing, which
inherentlypreservesthedifferentialprivacy.
However,thesetechniquestypicallypresumethatthemodelweightsarereal-valued. Ourresearchpivotsfromthisnorm
byaimingtoachieveDPwithquantizedweights,essentialinresource-constrainedenvironmentswheremodelsizeand
computationalefficiencyarecritical. Thispursuitaddressestheneedforprivacy-preservingmodelsinenvironments
whereresourcesarelimitedandhencequantizationisessentialforreducingcomputationaldemandsandmodelsize.
QuantizedMLoptimization Inthecontextofquantizedmachinelearningmodels,theparametersarerestrictedtoa
discretesetwithintheparameterspace. ThisapproachtotrainingquantizedMLmodelsformulatestheoptimization
problemasfollows:
min Lˆ(w;S) s.t. w ∈Q (4)
w∈W
where Q ⊆ Rd represents a discrete, non-convex quantization set. Given that (4) is an integer optimization with
non-linearconstraints,itnecessitatesrelaxationtoaformamenabletosolutionviaprojectedSGD(Proj-SGD)[33,34]:
(cid:40) v =w −η∇l(f(w ;·);·)
t+1 t t
(5)
w =Proj (v )
t+1 Q t+1
where ∇l(f(w ;·);·) is the sampled mini-batch gradient at the t-th iteration, η is the step size, and Proj (v) =
t Q
argmin ∥u−v∥isaprojectionthatprojectsvontothequantizationset.
u∈Q
33 Method
ProblemSetting Ourgoalistodevelopadifferentiallyprivateoptimizationsolutionto(4). Morespecifically,weaim
tosolvethefollowingERMproblem:
min Lˆ(w;S):= 1 (cid:80)n l(f(x ;w),y )
w∈W n i=1 i i
(cid:40) w ∈Q (6)
s.t.
Pr[f(w;x)]≤eϵPr[f(w;x′)]+δ
wherex,x′aretwoadjacentsubsetofX. Inthiswork,weincorporatetwokeyassumptions:
• TheparameterspaceW ⊂Rdisaclosed,convexsetboundedbyM: ∥w∥≤M,andthequantizationsetQis
adiscretesubsetofW.
• Foralldata-labelpair(x ,y )∈S,thelossfunction,l(f(x ;w),y ),isaconvexandρ-Lipschitzwithrespect
i i i i
tow,forexample,binarycross-entropylossinLogisticregression,andhingelossinSVMclassification.
Aconventionalapproachtosolving(6)isadaptingDP-SGD(3)totheProj-SGD(5):

v =w −η·
1[(cid:80)m
∇l(f(w ;x );y )+G ]
 t+1 t m j=1 t j j t
(7)
 w =Proj (v )
t+1 Q t+1
Here, G ∼ N(0,σ2I )) represents noise independently drawn at each SGD update. This adaptation of DP-SGD
t d
toProj-SGDpresentscertainlimitations: First,thedeterministicnatureoftheprojectionstep,althoughservingasa
post-processingphaseofDP-SGD,doesnotcontributeadditionalprivacysafeguards. Instead,itinducesa"projection
error", aconsequenceofaligningmodelparameterswiththenearestpointinQ. Second, astricterprivacybudget
necessitatesscalingupthenoise,whichinturnleadstoanincreasednoiseerror.
Toaddresstheselimitations,weproposerandomizedprojection(RP),anovelmethodologythatintegratesstochastic
elementsintotheprojectionphase. Thecruxofthismethodliesinleveragingtheprojectionphaseasamechanismto
bolsterprivacyprotection. Byinjectingcontrolledrandomnessintotheprojection,wetargetachievingthedesignated
privacybudgetwhileconcurrentlyloweringthenoiseerror.
RandomizedProjection Inrandomizedprojection,weconsiderb-bitquantizedparameterswithuniformlydistributed
levels
Q ={Q ,Q ,··· ,Q }
M,b 0 1 2b−1
whereQ denotestheb-bituniformquantizationsetwithquantizationboundM ∈R+,andeachquantizationlevel
M,b
isgivenby
2M
Q =−M + ·i (8)
i 2b−1
Randomizedprojectionisavariantoftheclassicalprojectionofunquantizedinputsontothequantizationset. Formally,
theclassicalprojectionofinputQ ontoQ is
in M,b
ProjD (Q )=argmin∥⌊Q ,M⌉−Q∥ (9)
QM,b in in 2
Q∈Q
where⌊·,M⌉denotesclippingfunctionthatclipstheparametersinto[−M,M]. Incontrasttoclassicalprojection,
randomizedprojection(outlinedinAlgorithm1)addsrandomnessbyusingacoefficientq ∈(0,1),enhancingprivacy
bymakingtheinputvaluelessdeduciblefromitsdeterministicprojection.
3.1 RQP-SGD
Based uponrandomized projection, we propose an iterative SGD methodfor solving (6), termed RQP-SGD. This
methodiscomprehensivelydetailedinAlgorithm2. RQP-SGDisanadaptationofDP-SGDintoavariantofProj-SGD
thatincorporatestherandomizedprojectioninplaceofthedeterministicone.
4Algorithm1RandomizedProjection
Require: k-bituniformquantizationsetQ ,randomnesscoefficientsq ∈[ 1 ,1),quantizationinputQ
M,b 2b−1 in
1: FindQ∗ =ProjD QM,b(Q in)using(9)
2: ProjectQ inontoQ M,brandomly:
(cid:26) Q∗ withprobabilityq
ProjR QM,b(Q in)=
Q forQ∈Qu\{Q∗}withprobability 1−q
2b−1
3: ReturnOutputofProjR QM,b(Q in)
Algorithm2RQP-SGD
Require: Trainingdataset: S ={(x ,y )∈X ×Y):i=1,2,··· ,n},ρ-Lipschitz,convexlossfunctionl,convex
i i
setW ⊆Rd,stepsizeη,mini-batchsizem,numberofiterationsT,QuantizationsetQ ,projectionrandomness
M,b
coefficientq.
1: Choosearbitraryinitialpointw 0 ∈W.
2: fort=0toT −1do
3: SampleabatchB t ={(x j,y j)}m j=1 ←S uniformlywithreplacement.
4: v t+1 =w t−η·
m1[(cid:80)m
j=1∇l(f(w t;x j);y j)+G t)]
whereG ∼N(0,σ2I )drawnindependentlyeachiteration.
t d
5: w t+1 :=ProjR QM,b(v t+1)whereProjR QM,b denotestherandomprojectionontoQ r.
6: endfor
7: ReturnW T.
PrivacyofRQP-SGD TheessenceofRQP-SGDliesinitsstrategyforprivacyenhancement. Instep4ofAlgorithm
2,itupholdsDPbyincorporatingaGaussiannoisevector,whichisintegraltoDP-SGD.Subsequently,step5amplifies
privacyprotectionviarandomizedprojections. Thisdual-prongedmethod,whicheffectivelycombinesDP-SGDand
randomizedprojection,isdesignedtoachievethedesiredprivacybudget. Itsimultaneouslyaimstomitigatetheadverse
effectsofnoiseonthemodel’saccuracyandperformance,therebyaddressingtheinherentlimitationsofescalatednoise
levelsintraditionalDP-SGDapplications. ThedifferentialprivacyguaranteeofRQP-SGDisrigorouslyestablishedin
Theorem1.
Theorem1. Foranyϵ > 0,thereexistsmini-batchsamplingrate m,trainingiterationsT,quantizationbitband
n
randomnesscoefficientp,noisescaleσsuchthatAlgorithm2achieves(ϵ,0)-DP.
Proof. ThekeytotheproofisdeterminingthedifferentialprivacybudgetforeachupdateintheRQP-SGDprocess.
Thistotalbudgetisthenassembledusingacompositionmethod. IneachupdateofRQP-SGD,thegradientiscalculated
fromamini-batchdatasetB = {(x ,y )}m , whichisuniformlysampledfromthetrainingdatasetS. Theterm
t j j j=1
f (w ;B )representsthestandardSGDupdateemployingthestochasticmini-batchB ,whichisdefinedas
sgd t t t
m
1 (cid:88)
f (w ;B )=w −η· ∇l(f(w ;x );y )
sgd t t t m t j j
j=1
Incontrasttof (w ;B ),step4ofAlgorithm2,denotesasf (w ;B ),addsnoisedrawnfromnormaldistribution.
sgd t t v t t
Thenoiseisscaledaccordingly,leadingtotheformula:
η
f (w ;B )=f (w ;B )+ ·N(0,σ2I )
v t t sgd t t m d
ThemechanismMt (w ,B )denotesthedifferentialprivatemechanismusedineachRQP-SGDupdatewiththe
RQP t t
mini-batchB . ForanyquantizationlevelQ ∈Q ,theprobabilitycanbeexpressedas
t i M,b
Pr{Mt (w ,B )=Q }=(cid:82) Pr{ProjR (v )=Q }·Pr{f (w ;B )=v }dv
RQP t t i QM,b t+1 i v t t t+1 t+1
ThisequationcombinestheprobabilitiesrelatedtotheprojectionProjR (v )achievingaparticularquantization
QM,b t+1
levelQ withthoseofthefunctionf (w ;B )beingequaltov .
i v t t t+1
5• Randomizedprojection:
Fortheprojectioninputv ,leti∗ =argmin ∥Q −v ∥2,theprobabilityofProjR (v )equalingto
t+1 i i t+1 QM,b t+1
Q isgivenby
i∗
Pr{ProjR (v )=Q }=q·Pr{Q− ≤v <Q+}
QM,b t+1 i∗ i∗ t+1 i∗
whereQ− =Q − M andQ+ =Q + M .
i∗ i∗ 2b−1 i∗ i∗ 2b−1
ForanyQ ∈Q butnotequaltoQ ,theprobabilityis
j M,b i∗
1−q
Pr{ProjR (v )=Q }= ·Pr{Q− ≤v <Q+}
QM,b t+1 j 2b−1 j t+1 j
whereQ− =Q − M andQ+ =Q + M .
j j 2b−1 j j 2b−1
• Distributionoff (w ;B ):
v t t
Thefunctionf (w ;B )introducesnoisetof (w ;B ). Thisimpliesthatv adherestoanormaldistribu-
v t t sgd t t t+1
tionN(f (w ;B ),(ησ)2).
sgd t t m
Based on the probability distributions of randomized projection and f (w ;B ), the probability distribution of
v t t
Mt (w ,B )foranyQ ∈Q canbeformulatedasfollows:
RQP t t i M,b
Pr{Mt (w ,B )=Q }
RQP t t i
= q·[Φ(Q+ i−fsgd(wt;Bt))−Φ(Q− i −fsgd(wt;Bt))]+ 1−q ·[Φ(Q+ i−fsgd(wt;Bt))−Φ(Q− i −fsgd(wt;Bt))]
σl σl 2b σl σl
= 2bq−1[Φ(Q+ i−fsgd(wt;Bt))−Φ(Q− i −fsgd(wt;Bt))]+ 1−q
2b−1 σl σl 2b−1
where Q− = Q − M , Q+ = Q + M , and σ = ησ. The next step involves finding the upper bound
i i 2b−1 i i 2b−1 l m
of logPr{Mt RQP(wt,Bt)=Qi} for any two adjacent sets B ,B′ ∈ S. The upper bound of this logarithmic ratio
Pr{Mt RQP(wt,B t′)=Qi} t t
is synonymous with the definition of the ∞-th order of Rényi divergence [35]. Specifically, for two probability
distributionsP andP definedoverR,the∞-thorderofRényidivergence[35]isgivenas
1 2
P (d)
D (P ∥P )=logsup 1
∞ 1 2 P (d)
d∈D 2
Utilizingthisdefinition,thefollowingrelationcanbeestablishedfortheRQP-SGDupdate:
sup
logPr{Mt RQP(wt,Bt)=Qi}
Qi∈QM,b
Pr{Mt RQP(wt,B t′)=Qi}
= D (Pr{Mt (w ,B )=Q }∥Pr{Mt (w ,B′)=Q })
∞ RQP t t i RQP t t i
= max{log
2 2b bq −− 11[Φ+(f(Bt))−Φ−(f(Bt))]+ 21 b− −q
1}
2 2b bq −− 11[Φ+(f(B t′))−Φ−(f(B t′))]+ 21 b− −q
1
(10)
where Φ +(f(B t))=Φ(Q+ i−fsg σd l(wt;Bt))
Φ −(f(B t))=Φ(Q− i −fsg σd l(wt;Bt))
Φ +(f(B t′))=Φ(Q+ i−fsg σd l(wt;B t′))
Φ +(f(B t′))=Φ(Q− i −fsg σd l(wt;B t′))
GiventhatRényidivergenceisquasi-convex[35],(10)achievesitsmaximumattheextremepoints.
Thelossfunctionl(f(w ;·);·)isρ-Lipschitzwithrespecttow ,accordingtoLemma14.7in[36]. Thismeansforany
t t
data-labelpair(x ,y )∈S,thenormofthegradientisboundedbyρ: ∥∇l(f(w ;x );y ∥≤ρ. Withtheassumption
i i t i i
thatw isboundedbyM,foranytwoadjacentB ,B′ ∈S,themaximumdifferenceoff (w ;·)isconstrainedbyC:
t t t sgd t
max∥f (w ;B )−f (w ;B )∥≤C whereC =M −ηρ. Incorporatingtheextremevalueoff (w ;B )into
sgd t t sgd t t sgd t t
(10),thefollowinginequalityisobtained:
Pr{Mt (w ,B )=Q }
log RQP t t i ≤ϵ
Pr{Mt (w ,B′)=Q } t
RQP t t i
62bq−1[2Φ(a1)−1]+1−q
whereϵ = log 2b−1 σl 2b−1 ,a = M ,a = M + M +C,anda = M − M +C. Thisshows
t 2bq−1[Φ(a2)−Φ(a3)]+1−q 1 2b−1 2 2b−1 3 2b−1
2b−1 σl σl 2b−1
thateachRQP-SGDupdateis(ϵ ,0)-DPwithrespecttothestochasticmini-batchB .
t t
ConsideringthatRQP-SGDperformsatotalofT iterations,witheachiterationinvolvingtheuniformsamplingofa
stochasticmini-batchwithreplacement,thetotalprivacybudgetcanbecomposed. ByleveragingtheDPcomposition
theorem[32]andamplificationofDPviasubsampling[37],theoverallprivacybudgetforRQP-SGDisestablishedas
(Tmϵ ,0)-DP.
n t
Utility of RQP-SGD In Theorem 2, we provide the utility guarantee of Algorithm 2 based on the convergence
analysisofthestochasticoraclemodel(see[34,36])withconvexloss. Comparedtotheutilityanalysisin[36],the
RQP-SGDleadstotwoadditionalerrors: Quantizationerror(E )andnoiseerror(E ). Theformerispredominantly
Q N
influencedbythequantizationbits(b)andtherandomnesscoefficient(q),whereasmallervalueofqinduceshigher
randomnessinquantization,subsequentlyincreasingE . However,thisincreaseunderafixedprivacybudgetcan
Q
reducetherelianceonaddednoiseofdifferentialprivacy,therebypotentiallydecreasingE . Thispresentsadelicate
N
trade-offinRQP-SGD:optimizingthevalueofq becomescrucialinbalancingthequantizationandnoiseerrorsto
achieveeffectiveperformancewithintheconstraintsofthegivenprivacybudget.
Theorem2. LetW¯ = 1 (cid:80)T w . SupposetheparametersetW isconvexandM-bounded,andthequantizationset
T T t=1 t
Q isgeneratedbyarandomizedquantizerwithprobabilityqandb-bit. Foranyη >0,theexcessempiricallossof
p
A satisfies
ProjNSGD
(cid:104) (cid:105)
E Lˆ(w¯ T;S) − wm ∈i Wn Lˆ(w;S)≤ 2M ηT2 +E Q+ η 2ρ2 +E N (11)
whereE =dM2[ q + 2b+1(2b+1−1)(1−q)]denotesthequantizationerrorandE =ησ2ddenotesthenoise
Q (2b−1)2 3(2b−1)2 N
error.
Proof. The key to the proof is determining the boundary of the randomized projection. The projection process
w =ProjR (v )involvestherandomizedprojectionofw˜ ontoQ . Fortheprojection,wehave:
t+1 QM,b t+1 t+1 M,b
2b−1
E (cid:2) ∥v −w ∥2(cid:3) ≤ d( M )2·q+d (cid:80) ( 2M i)2 1−q
t+1 t+1 2b−1 2b−1 2b−1
w∈QM,b i=1
(cid:104) (cid:105)
≤ dM2 q + 2b+1(2b+1−1)(1−q)]
(2b−1)2 3(2b−1)2
Bythetriangleinequality,foru∈W,
∥w −u∥2 ≤∥w −v ∥2+∥v −u∥2
t+1 t+1 t+1 t+1
(cid:104) (cid:105)
LetE =dM2 q + 2b+1(2b+1−1)(1−q)] ,wecanderivethefollowinginequalityfromthepreviousprinciples:
Q (2b−1)2 3(2b−1)2
∥v −u∥2−∥w −u∥2 ≥−E (12)
t+1 t+1 Q
Wenextanalyzetheexcessempiricallossundertheassumptionthatthelossfunctionisρ-LipschitzandconvexoverW.
AccordingtoLemma14.7in[36],forallw ∈W andgradient∇∈ ∂l,thenormofthegradientisbounded: ∥∇∥≤ρ.
∂w
Letw∗ betheoptimalparameterintheparameterspaceW,definedasw∗ = min Lˆ(w;S). Giventhatw isthe
t+1
w∈W
projectionofv andw∗ ∈W,thefollowinginequalityisobtained:
t+1
∥w −w∗∥2−∥w −w∗∥2
t t+1
≥ ∥w −w∗∥2−∥v −w∗∥2−E
t t+1 Q
≥ 2η⟨w −w∗,∇⟩−η2∥∇∥2−η2∥G ∥2−E
t t Q
Takingexpectationofbothsides,rearranging,andusingthefactthatE[∥∇∥2]≤ρ2andE[∥G ∥2]=dσ2,wehave:
t
⟨w −w∗,∇ ⟩≤ 1 E[∥w −w∗∥2−∥w −w∗∥2]+ ηρ2+E +ησ2d
t t 2η t t+1 2 Q
7(cid:104) (cid:105)
Giventheconvexityofthelossfunctionl,wecanfurtherderivetheboundofE Lˆ(w¯ ;S) − min Lˆ(w;S):
T
w∈W
(cid:104) (cid:105)
E Lˆ(w¯ ;S) − min Lˆ(w;S)≤ M2 +E + ηρ2 +ησ2d
T w∈W 2ηT Q 2
ThisisachievedthroughtheanalyticalmethodsusedforSGDappliedtoConvex-Lipschitz-Boundedfunctions[36].
Theorem2showstheconvergenceorderforE isO(dM2[ q +(1−q)]),highlightingtheinfluenceofthecoefficient
Q 2b−1
qontheutilitybound.
RQPvsProj-DP-SGD WeemploytheutilityboundformallycharacterizedinTheorem2asabasistocompare
RQP-SGDagainsttheadaptionofDP-SGDtoP-SGD(Proj-DP-SGD),whichservesasabaseline. Thisbaselinetreats
privatizationandquantizationasdistinctprocesses. Ournumericalanalysis,illustratedinFigure1,assessesRQP-SGD
underastrict(ϵ,0)-DPsetting,contrastingitwithProj-DP-SGDunderaslightlymorerelaxed(ϵ,10−7)-DP.Resultsin
Figure1brevealthatRQP-SGDhaslowerutilityboundsthanProj-DP-SGDatequivalentprivacylevels. However,as
showninFigure1a,alowerprojectionrandomnesscoefficientinRQP-SGD,whichaddsmorerandomness,canresult
inahigherutilitybound,indicatingacriticalbalancebetweenutilityboundandprivacyintheseSGDframeworks.
(a)q=0.90 (b)q=0.95
Figure1: Noisescale(σ)andprojectionrandomnesscoefficient(q)trade-offofRQP-SGD(blue)andProj-DP-SGD.
Parametersettings: b=4,M =0.3,ρ=0.45,T =445,m = 1 .
n 445
4 Experiments
Setup We applied RQP-SGD to classification tasks using the Diagnostic [13] and MNIST datasets [38]. The
Diagnosticdataset,with56930-dimensionalinstances,wassplitinto80%trainingand20%testing. MNISTcontains
70,00028x28pixelgrayscaleimagesofhandwrittendigits,splitinto60,000fortrainingand10,000fortesting.
(a)4-bitwith(0.5,0)-DP (b)3-bitwith(0.5,0)-DP (c)4-bitwith(1.0,0)-DP (d)3-bitwith(1.0,0)-DP
Figure2: Noisescale(σ)andprojectionrandomnesscoefficient(q)trade-off. Testaccuracyvaluesarethemedianover
10runs.
8TrainingDetails Weusedlogisticregression(LogRes)[39]andlinearsupportvectormachine(SVM)[40]classifiers
ontheDiagnosticdataset,implementingDP-SGD,theadaptionofDP-SGDtoP-SGD(Proj-DP-SGD),andRQP-SGD
withamini-batchsizeof10,stepsizeof1,and46trainingiterations. FortheMNISTdataset,weimplementedLogReg
classifierwithamini-batchsizeof64,stepsizeof1.0,and938trainingiterations. Foralllearningalgorithms,we
employedthegradientclippingtechniquewithl normof0.45. ForRQP-SGDandProj-DP-SGD,weset[−0.3,0.3]as
2
theparameterspaceboundandset4asthequantizationbit.
Results Weset(1.0,10−7)astheprivacybudgetofDP-SGDandProj-DP-SGD,andset(1.0,0)astheprivacybudget
ofRQP-SGD.WereportthetestaccuracyoftheresultingMLmodelsinTable1. ItclearlydemonstratesthatRQP-SGD
achievesbetterutilityperformancethanProj-DP-SGD.Especially,theSVMclassifierusingRQP-SGDleadsto35.84%
mediantestaccuracygainamongtheDP-SGDwithdeterministicprojectionontheDiagnosticdataset.
Table1: Testaccuracy(%)ofLogisticregressionclassifierswithDP-SGD,Proj-DP-SGD,andA . Wereport
RQP-SGD
medianandstandarddeviationvaluesover10runs.
Diagnostic Diagnostic MNIST
(LogRegClassifier) (SVMClassifier) (LogRegClassifier)
Non-Private 97.37%(0.56%) 98.68%(0.68%) 87.25%(0.07%)
DP-SGD 96.92%(1.80%) 96.49%(1.24%) 86.02%(0.33%)
Proj-DP-SGD 94.30%(1.41%) 69.74%(18.37%) 84.32%(0.29%)
RQP-SGD 95.18%(1.42%) 94.74%(1.53%) 84.81%(0.30%)
ImpactofNoiseScaleandProjectionRandomness TobetterunderstandthePrivacy-Utilitytrade-off,weadjusted
noisescaleswhilemaintainingafixedprivacybudgetandquantizationbits. Thequantizationrandomnesscoefficient
(q)iscalculatedbyTheorem1. AspresentedinFig. 2,thequantizationrandomnesscoefficient-noisescalecurve
(shownintheblueline)illustratesthatdecreasingquantizationprobabilitycanenhanceprivacywhileallowingless
noise. Ontheutilityfront(representedbytheredline),alowerprojectionrandomnesscoefficient(q)leadstodegraded
testaccuracy. Forinstance,whentheprojectionrandomnesscoefficient(q)is0.3,thetestaccuracydecreasestoaround
62.5%. Theutilitydropisattributedmoretotherandomnessfromquantizationthanfromnoiseaddition. Fromour
observation,thestandarddeviationoftestaccuracyishigherwhentheprojectionrandomnesscoefficient(q)islower.
Thisfurtherillustratestheimpactoftheprojectionrandomnesscoefficient(q)onutility.
ImpactofQuantizationBit Wealsoextendourexperimentswithdifferentquantizationbitstoexploretheimpactof
thequantizationbits. Basedonourobservation,thetestaccuracydoesnotincreaseasincreasingthequantizationbits.
Thisisbecausethehigherthequantizationbits,thelessrandomnessisprovidedbyquantization. Tomaintainthesame
privacylevel,therandomnesscoefficient(q)islowerwhichresultsinhigherutilityloss.
5 Conclusion
Inthiswork,weproposeRQP-SGD,anewapproachtoprovidingdifferentialprivacyinMLwithquantizedcompu-
tationalmodels. RQP-SGDcombinesdifferentiallyprivatenoiseadditionwithrandomizedquantizationprojection,
whichintroducesadditionalrandomnessthatenablesthereductionofnoisetoimproveutility. Wetheoreticallyanalyze
thefeasibilityofRQP-SGDinthetrainingofMLmodelswithconvexobjectivesandvalidatetheeffectivenessof
RQP-SGDthroughexperimentsonrealdatasets.
TherearescopesforfurtherresearchonRQP-SGD.First,theutilityperformanceofRQP-SGDishighlysensitiveto
theprojectionrandomness,RQP-SGDtrainingwithlowquantizationprobabilityisstillchallenging,duetothehigh
randomness. Acomprehensivestudyofintroducingrandomnesswouldbeapromisingavenueforfutureresearch.
Second, there are other ML problems, such as non-convex optimization and training neural networks, that can be
exploredforfurtheranalysis.
6 Acknowledgments
ThisresearchisfundedinpartbyLehighCOREgrantCNV-S00009854,andtheCIF1617889grantfromtheNational
ScienceFoundation.
9References
[1] CeFengandParvVenkitasubramaniam. Inferentialseparationforprivacy: Irrelevantstatisticsandquantization.
IEEETransactionsonInformationForensicsandSecurity,17:2241–2255,2022.
[2] DanWang,JuRen,ZhiboWang,YaoxueZhang,andXueminShermanShen. Privstream: Aprivacy-preserving
inferenceframeworkoniotstreamingdataattheedge. InformationFusion,80:282–294,2022.
[3] LeiYu,LingLiu,CaltonPu,MehmetEmreGursoy,andStaceyTruex. Differentiallyprivatemodelpublishingfor
deeplearning. In2019IEEESymposiumonSecurityandPrivacy(SP),pages332–349,2019.
[4] Da Yu, Huishuai Zhang, Wei Chen, Jian Yin, and Tie-Yan Liu. Large scale private learning via low-rank
reparametrization. InInternationalConferenceonMachineLearning,pages12208–12218.PMLR,2021.
[5] NicolasPapernot,AbhradeepThakurta,ShuangSong,SteveChien,andÚlfarErlingsson. Temperedsigmoid
activations for deep learning with differential privacy. In Proceedings of the AAAI Conference on Artificial
Intelligence,volume35,pages9312–9321,2021.
[6] GalenAndrew,OmThakkar,BrendanMcMahan,andSwaroopRamaswamy. Differentiallyprivatelearningwith
adaptiveclipping. AdvancesinNeuralInformationProcessingSystems,34:17455–17466,2021.
[7] CynthiaDwork. Differentialprivacy. InInternationalcolloquiumonautomata,languages,andprogramming,
pages1–12.Springer,2006.
[8] MartinAbadi,AndyChu,IanGoodfellow,HBrendanMcMahan,IlyaMironov,KunalTalwar,andLiZhang.
Deeplearningwithdifferentialprivacy. InProceedingsofthe2016ACMSIGSACconferenceoncomputerand
communicationssecurity,pages308–318,2016.
[9] DaYu,HuishuaiZhang,WeiChen,andTie-YanLiu. Donotletprivacyoverbillutility: Gradientembedding
perturbationforprivatelearning. InInternationalConferenceonLearningRepresentations,2021.
[10] MiladNasr,RezaShokri,etal. Improvingdeeplearningwithdifferentialprivacyusinggradientencodingand
denoising. arXivpreprintarXiv:2007.11524,2020.
[11] CeFeng,NuoXu,WujieWen,ParvVenkitasubramaniam,andCaiwenDing. Spectral-dp: Differentiallyprivate
deeplearningthroughspectralperturbationandfiltering. In2023IEEESymposiumonSecurityandPrivacy(SP),
pages1944–1960.IEEEComputerSociety,2023.
[12] SijieXiong,AnandDSarwate,andNarayanBMandayam. Randomizedrequantizationwithlocaldifferential
privacy. In2016IEEEInternationalConferenceonAcoustics,SpeechandSignalProcessing(ICASSP),pages
2189–2193.IEEE,2016.
[13] WilliamWolberg, OlviMangasarian, NickStreet, andW.Street. Breastcancerwisconsin(diagnostic). UCI
MachineLearningRepository,1995. DOI:https://doi.org/10.24432/C5DW2B.
[14] HaoranLi,LiXiong,LucilaOhno-Machado,XiaoqianJiang,etal. Privacypreservingrbfkernelsupportvector
machine. BioMedresearchinternational,2014,2014.
[15] JunZhang,ZhenjieZhang,XiaokuiXiao,YinYang,andMarianneWinslett. Functionalmechanism: Regression
analysisunderdifferentialprivacy. ProceedingsoftheVLDBEndowment,5(11),2012.
[16] KamalikaChaudhuriandClaireMonteleoni. Privacy-preservinglogisticregression. Advancesinneuralinforma-
tionprocessingsystems,21,2008.
[17] RaefBassily,AdamSmith,andAbhradeepThakurta. Privateempiricalriskminimization: Efficientalgorithms
andtighterrorbounds. In2014IEEE55thannualsymposiumonfoundationsofcomputerscience,pages464–473.
IEEE,2014.
[18] KamalikaChaudhuri,ClaireMonteleoni,andAnandDSarwate. Differentiallyprivateempiricalriskminimization.
JournalofMachineLearningResearch,12(3),2011.
[19] ShivaPrasadKasiviswanathanandHongxiaJin.Efficientprivateempiricalriskminimizationforhigh-dimensional
learning. InInternationalConferenceonMachineLearning,pages488–497.PMLR,2016.
[20] RaefBassily,VitalyFeldman,KunalTalwar,andAbhradeepGuhaThakurta.Privatestochasticconvexoptimization
withoptimalrates. Advancesinneuralinformationprocessingsystems,32,2019.
[21] SrivatsanKrishnan,SharadChitlangia,MaximilianLam,ZishenWan,AleksandraFaust,andVijayJanapaReddi.
Quantizedreinforcementlearning(quarl). 2019.
[22] MarkusNagel,RanaAliAmjad,MartVanBaalen,ChristosLouizos,andTijmenBlankevoort. Upordown?
adaptive rounding for post-training quantization. In International Conference on Machine Learning, pages
7197–7206.PMLR,2020.
10[23] YuryNahshan,BrianChmiel,ChaimBaskin,EvgeniiZheltonozhskii,RonBanner,AlexMBronstein,andAvi
Mendelson. Lossawarepost-trainingquantization. MachineLearning,110(11-12):3245–3262,2021.
[24] MarkusNagel,MariosFournarakis,YelyseiBondarenko,andTijmenBlankevoort. Overcomingoscillationsin
quantization-awaretraining. InInternationalConferenceonMachineLearning,pages16318–16330.PMLR,
2022.
[25] CharbelSakr,SteveDai,RanghaVenkatesan,BrianZimmer,WilliamDally,andBrucekKhailany. Optimalclip-
pingandmagnitude-awaredifferentiationforimprovedquantization-awaretraining. InInternationalConference
onMachineLearning,pages19123–19138.PMLR,2022.
[26] MatthieuCourbariaux,YoshuaBengio,andJean-PierreDavid. Binaryconnect: Trainingdeepneuralnetworks
withbinaryweightsduringpropagations. Advancesinneuralinformationprocessingsystems,28,2015.
[27] YuBai,Yu-XiangWang,andEdoLiberty. Proxquant: Quantizedneuralnetworksviaproximaloperators. arXiv
preprintarXiv:1810.00861,2018.
[28] RuochiZhangandParvVenkitasubramaniam. Optimallocaldifferentiallyprivatequantization. IEEETransactions
onSignalProcessing,68:6509–6520,2020.
[29] NatalieLang,EladSofer,TomerShaked,andNirShlezinger. Jointprivacyenhancementandquantizationin
federatedlearning. IEEETransactionsonSignalProcessing,71:295–310,2023.
[30] SabaAmiri,AdamBelloum,SanderKlous,andLeonGommans. Compressivedifferentiallyprivatefederated
learningthroughuniversalvectorquantization. InAAAIWorkshoponPrivacy-PreservingArtificialIntelligence,
pages2–9,2021.
[31] VenkataGandikota,DanielKane,RajKumarMaity,andAryaMazumdar. vqsgd: Vectorquantizedstochastic
gradientdescent. InInternationalConferenceonArtificialIntelligenceandStatistics,pages2197–2205.PMLR,
2021.
[32] CynthiaDwork,AaronRoth,etal. Thealgorithmicfoundationsofdifferentialprivacy. FoundationsandTrends®
inTheoreticalComputerScience,9(3–4):211–407,2014.
[33] Penghang Yin, Shuai Zhang, Jiancheng Lyu, Stanley Osher, Yingyong Qi, and Jack Xin. Binaryrelax: A
relaxationapproachfortrainingdeepneuralnetworkswithquantizedweights. SIAMJournalonImagingSciences,
11(4):2205–2223,2018.
[34] HaoLi,SohamDe,ZhengXu,ChristophStuder,HananSamet,andTomGoldstein. Trainingquantizednets: A
deeperunderstanding. AdvancesinNeuralInformationProcessingSystems,30,2017.
[35] TimVanErvenandPeterHarremos. Rényidivergenceandkullback-leiblerdivergence. IEEETransactionson
InformationTheory,60(7):3797–3820,2014.
[36] ShaiShalev-ShwartzandShaiBen-David. Understandingmachinelearning: Fromtheorytoalgorithms. Cam-
bridgeuniversitypress,2014.
[37] Borja Balle, Gilles Barthe, and Marco Gaboardi. Privacy amplification by subsampling: Tight analyses via
couplingsanddivergences. Advancesinneuralinformationprocessingsystems,31,2018.
[38] YannLeCun,LéonBottou,YoshuaBengio,andPatrickHaffner. Gradient-basedlearningappliedtodocument
recognition. ProceedingsoftheIEEE,86(11):2278–2324,1998.
[39] RaymondEWright. Logisticregression. 1995.
[40] MartiA.Hearst,SusanTDumais,EdgarOsuna,JohnPlatt,andBernhardScholkopf. Supportvectormachines.
IEEEIntelligentSystemsandtheirapplications,13(4):18–28,1998.
11