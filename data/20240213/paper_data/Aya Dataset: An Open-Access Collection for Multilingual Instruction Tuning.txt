Aya Dataset: An Open-Access Collection
for Multilingual Instruction Tuning
Shivalika
Singh‚ô¶1,
Freddie
Vargus‚ô¶1,
Daniel
D‚Äôsouza‚ô¶1,
B√∂rje F.
Karlsson‚ô¶2,
Abinaya Mahendiran‚ô¶1, Wei-Yin Ko‚ô¶3, Herumb Shandilya‚ô¶1, Jay Patel4,
Deividas Mataciunas1, Laura O‚ÄôMahony5, Mike Zhang6, Ramith Hettiarachchi7,
Joseph Wilson8, Marina Machado3, Luisa Souza Moura3, Dominik Krzemi≈Ñski1,
Hakimeh Fadaei1, Irem Erg√ºn3, Ifeoma Okoh1, Aisha Alaagib1,
Oshan Mudannayake1, Zaid Alyafeai9, Vu Minh Chien1, Sebastian Ruder3,
Surya Guthikonda1, Emad A. Alghamdi10, Sebastian Gehrmann11,
Niklas Muennighoff1, Max Bartolo3, Julia Kreutzer12, Ahmet √úst√ºn12,
Marzieh Fadaee12, and Sara Hooker12
1Cohere For AI Community, 2Beijing Academy of Artificial Intelligence, 3Cohere, 4Binghamton University,
5University of Limerick, 6IT University of Copenhagen, 7MIT, 8University of Toronto, 9King Fahd University of
Petroleum and Minerals, 10King Abdulaziz University, ASAS.AI, 11Bloomberg LP, 12Cohere For AI
Corresponding authors: Shivalika Singh <shivalikasingh95@gmail.com>, Marzieh Fadaee <marzieh@cohere.com>,
Sara Hooker <sarahooker@cohere.com>
Abstract
Datasets are foundational to many breakthroughs in modern artificial intelligence. Many recent
achievements in the space of natural language processing (NLP) can be attributed to the fine-
tuning of pre-trained models on a diverse set of tasks that enables a large language model (LLM)
to respond to instructions. Instruction fine-tuning (IFT) requires specifically constructed and an-
notated datasets. However, existing datasets are almost all in the English language. In this work,
our primary goal is to bridge the language gap by building a human-curated instruction-following
dataset spanning 65 languages. We worked with fluent speakers of languages from around the world
to collect natural instances of instructions and completions. Furthermore, we create the most ex-
tensive multilingual collection to date, comprising 513 million instances through templating and
translating existing datasets across 114 languages. In total, we contribute four key resources: we
developandopen-sourcetheAya Annotation Platform,theAya Dataset,theAya Collection,
and the Aya Evaluation Suite. The Aya initiative also serves as a valuable case study in partic-
ipatory research, involving collaborators from 119 countries. We see this as a valuable framework
for future research collaborations that aim to bridge gaps in resources.
1 Introduction
Datasets are static representations of the world, far from the rich, ever-evolving environment we
navigate as humans. Yet, these frozen snapshots in time are the foundation upon which progress in
AIhasbeenbuilt. Manyrecentbreakthroughsinlanguagemodelingcanbeattributedtofine-tuning
‚ô¶First authors.
Released as a preprint on February 12, 2024 1
4202
beF
9
]LC.sc[
1v91660.2042:viXraüìö
Prompt 65 Completion Text Classification Natural Language Generation
"‡∂ï" ‡∑ô‡∂±"% ‡∑ô‡∂±&‡∂∫ ‡∂ª‡∂ü‡∑è‡∂Ω‡∑è" ‡∂∫‡∂± ,‡∂≠‡∂∫ ‡∂á/‡∑Ö1 6‡∂Ç‡∑Ñ‡∂Ω "‡∂ï" ‡∑ô‡∂±"% ‡∑ô‡∂±&‡∂∫ ‡∂ª‡∂ü‡∑è‡∂Ω‡∑è" ‡∂∫‡∂± ,‡∂≠‡∂∫ ‡∂á/‡∑Ö1 ‡∑Ä3‡∑ô3 Prompt Prompt
9:‡∂¥‡∂ß‡∂∫ E‡∂∏F ‡∂Ø? sin " ‡∑ô‡∑ô ?4 ‡∂±‡∂õ ‡∑è‡∂ª‡∑è‡∑Ä 1" ‡∂± ‡∂± ‡∂∏% ‡∑Ñ 6 ‡∂≠‡∂Ç ‡∑è‡∑Ñ @‡∂Ω 6 9 3: ‡∂ú‡∂¥ ‡∑è‡∂ß ‡∂∫‡∑ô ‡∂±= ‡∑è ‡∂∫ ‡∂ö. ‡∂ª‡∑ô ‡∂±‡∂∏ ‡∂∏ ‡∂Ω ‡∂Ø, ,‡∂≠ ‡∂∫‡∂∫ D 6 .6‡∂ª C eil ta hs es ri f py oth sie ti vse en , nti em ge an tit v o ef , oth re n f eo ull to raw l i \n ng {{ tt ww ee ee tt } w }ith W of h tha et i fs o t lh loe w c io nr gre ss ep no ten nd cin eg : {t {r sa on us rl ca eti }o }n in {{target_lang}}
Qual √© a origem do xaxado? O xaxado tem origens associadas ao Completion Completion
Canga√ßo, onde cangaceiros, normalmente I would classify the given tweet as: {{label}} The translation to {{target_lang}} is: \n{{target}}
h ceo lm ebe rn as √ß, √µd ea sn . √ß Ca ov mam a c eo nm tra r difl ae ds ee m m ulheres nos 101+2 Translated Text Classification datasets 101 +8 Translated NL Generation datasets
grupos, a participa√ß√£o feminina na dan√ßa 11 IndicSentiment-inst
por tamb√©m se expandiu. 44 Xlel_wd-inst
7 IndicXParaphrase-inst
ÿüÿ™ÿ≥ÿß ŸáÿØÿ¥ ÿØŸÜŸàÿßŸÖÿØ Ÿáÿ® €åÿß Ÿáÿ±ÿßÿ¥ÿß €åŸÜÿßÿ±€åÿß ÿ±€åÿ∑ÿßÿ≥ÿß ÿ±ÿØ ÿß€åÿ¢ ŸÜÿ¢ ÿ™ÿ±Ÿáÿ¥ .ÿØÿ±ÿßÿØ €åÿß Ÿá⁄ò€åŸà Ÿáÿß⁄Ø€åÿßÿ¨ ŸÜÿßÿ±€åÿß ÿ±€åÿ∑ÿßÿ≥ÿß ÿ±ÿØ ÿØŸÜŸàÿßŸÖÿØ 13 NTX-LLM-inst
€åÿßŸá ÿ™€åÿµÿÆÿ¥ ÿ≤ÿß ŸÜŸàÿØ€åÿ±ŸÅ Ÿá⁄© ÿ™ÿ≥ÿß ŸÜ€åÿß ÿ±ÿØ ÿ≤€å⁄Ü ÿ±Ÿá ÿ≤ÿß ÿ¥€åÿ® 5 XWikis-inst
ÿØŸÜÿ® Ÿáÿ® €åÿ±ÿßÿ∫ ÿ±ÿØ ÿßÿ¨ŸÜÿ¢ ÿ±ÿØ ÿßÿ± ⁄©ÿßÿ≠ÿ∂ ÿåŸÜÿßÿ±€åÿß €åÿ±€åÿ∑ÿßÿ≥ÿß 11 UNER_LLM-inst
Ÿá⁄© ŸÜÿßŸÖÿ≤ŸÑÿßÿ±ÿÆÿ¢ ÿßÿ™ ÿ™ÿ≥ €åŸÜÿßÿØŸÜÿ≤ ÿßÿ¨ŸÜÿ¢ ⁄©ÿßÿ≠ÿ∂ Ÿà ÿ™ÿ≥ÿß ŸáÿØ€åÿ¥⁄© 10 NusaX-senti-inst 3 Indo-stories-instruct
ÿ™ÿ≥ÿØ Ÿáÿ® ŸÖÿßÿ¨ŸÜÿßÿ±ÿ≥ Ÿà ÿØŸÜ⁄© ÿ≤ÿßÿ∫ÿ¢ ŸÇŸÑÿÆ ÿ™ŸÜÿ¥⁄© Ÿà ÿØŸÑÿ≥⁄Øÿ® ÿØŸÜÿ® 2 Lijnews-instruct
pes ÿØŸàÿ¥ Ÿáÿ™ÿ¥⁄© Ÿæÿ≥ÿßÿ¥ÿ±⁄Ø 10 Masakhanews-inst
2 SCB-MT-2020-prompt
‡∞¨‡∞ü#$%& ‚Äô‡∞¶ )‡∞Ø‡∞°‡∞Ç ‡∞Ö‡∞Ç- ‡∞è\]? ‡∞¨‡∞ü#$%& ‚Äô‡∞¶ )‡∞Ø‡∞ü‡∞Æ‡∞Ç- .‡∞Ç‡∞¶/ 0‡∞™‡∞ü‡∞Ç ‡∞Ö. 9 AfriSenti-inst
‡∞Ö‡∞∞4‡∞Ç. ‡∞â6: "78 9‡∞Ç‡∞ó‡∞§‡∞®‡∞Ç =>8. ?@ 78 1 Urdu-News-Category-Class 2 Seed-instruct-lij
ABC‡∞®‡∞ÇD‡∞® ‡∞Ü FGH 6I@. ‡∞¨‡∞ü#$%& 1 Wiki-split-inst
‚ÄôJK‡∞®LM ‡∞Ü .‡∞Ç‡∞¶ 78 N ‚Äô‡∞¶ )K ‡∞®@O PQ 1 IMDB-Dutch-instruct
7.RSL TUV ‡∞áXY‡∞ÇI8" 1 Persian-instruct-pn
tel 1 Scirepeval-biomimicry-inst
1 Arpa-instruct
Berikan jawapan untuk teka-teki berikut: Jawapannya ialah Microsoft kerana "Microsoft Question Answering
Apakah jenama tingkap yang paling ramai Windows" (perkataan "window" bermaksud 1 Turku-paraphrase-inst
orang guna? tingkap dalam bahasa Inggeris) ialah salah
satu sistem operasi yang banyak digunakan Prompt 1 FarsTail-Instruct
oleh ramai orang di seluruh dunia. What category does this question come from:
msa {{question['text']}}? 1 TamilStories
Completion 1 Joke-explaination-inst
Inis dom faoi Baile √Åtha Cliath. Is √© Baile √Åtha Cliath, n√≥ Dublin i mB√©arla, This question can come from category:
pr√≠omhchathair na h√âireann agus √© ar an {{document[‚Äòkind']}}. 1 Thirukkural-instruct
gcathair is m√≥ sa t√≠r freisin. T√° s√© suite in
oirthear na t√≠re, cois Life agus ar imeall Mhuir 101 +9 Translated QA datasets 1 News-summary-instruct
√âireann. T√° breis is 1.6 milli√∫n duine ina gc√≥na√≠ 16 X-CSQA-inst 1 Hindi-article-{task}
i m√≥rcheantar Bhaile √Åtha Cliath agus deirtear
go dtiocfaidh borradh agus f√°s ar an daonra sa 12 AfriQA-inst 1 SODA-inst
gle todhcha√≠.
9 Mintaka-inst 1 Urdu-News-Gen-{task}
Maxaa waaye shay ay Soomaali badan cunaan Shay ay Soomaali badan cunaan maalin walba
maalin walba oo dadk qaar ay ku adagtahay oo dadk qaar ay ku adagtahay la'aantiisa in ay 1 TeluguRiddles 1 UA-Gec-inst
la'aantiisa in ay cuntada cunaan? cuntada cunaan waa Mooska. Mooska dad
badan oo Soomali ah way jecelyihiin, wuxuuna 1 LLM-Japanese-vanilla-inst 1 Telugu-{task}
ka mid yahay waxyaabaha dalka uu ku caan
som baxay in uu dhoofiyo. 1 Amharic QA 1 Thai-{task}-inst/prompt
101 dolly_machine_translated 7 aya_human_annotated 6 dolly-human-edited
Figure 1: Aya Dataset, Aya Collection & Aya Evaluation Suite. On the left, we show
examplesofcontributionsintheAyaDataset. Theseareoriginalhuman-curatedprompt-completion
pairs written by fluent speakers of 65 languages. On the right, we have the Aya Collection, an
aggregation of 44 monolingual and multilingual templated instruction datasets and 19 translated
datasets ranging over 114 languages and three main tasks: Text Classification, Natural Language
Generation, and Question Answering. The bottom block showcases the Aya Evaluation Suite for
multilingual open-ended generation. This collection consists of original annotation and post-edits of
translations covering several languages, and translation of high-quality and universal prompts into
101 languages. We indicate the number of languages in a dataset with the value in the blue ovals
in the figure. (Translated datasets have been visually merged due to space constraints).
pre-trained models on a diverse set of tasks that enable a Large Language Model (LLM) to follow
instructions [McCann et al., 2018; Sanh et al., 2022; Wei et al., 2022a; Muennighoff et al., 2023c;
Longpre et al., 2023a]. Instruction fine-tuning (IFT) leverages the precept that Natural Language
Processing (NLP) tasks can be described via natural language instructions, such as ‚ÄúWhat were
the reviews like for the Barbie movie?" or ‚ÄúWrite a recipe from the following list of ingredients."
This process requires prompts to be paired with expected completions [Ziegler et al., 2020; Ouyang
et al., 2022] aiming to capture the variety of ways an LLM can be used in downstream tasks. Yet,
the very act of curating data imparts a viewpoint about what distributions we want our model to
representandwhatisforgotten. So, what do these widely used datasets tell us about the assumptions
underlying these breakthroughs?
2More than 7,000 languages1 are spoken around the world today, with a considerable number facing
thechallenges ofbeinglow-resourced, under-represented, ordisappearing [Maxwell& Hughes,2006;
Simons, 2019; Moran & Chiarcos, 2020; Secretariat, 2022; Gao & Liu, 2023; Ilhomovna & Yulda-
sheva, 2023; Marivate et al., 2020]. In contrast, the most widely used datasets and breakthroughs
in NLP have coalesced around a few data-rich languages [Longpre et al., 2023b; Taori et al., 2023;
Chung et al., 2022; Fan et al., 2021; Dodge et al., 2021; Lucy et al., 2024]. IFT datasets are no
exception; the creation of these datasets has almost entirely focused on English. Furthermore, the
vast majority of the creators of these works originate from a few countries [Longpre et al., 2023b;
Zhang et al., 2022].
Thefactorsunderlyingtheconstructionofthedatasetsimpacthowmodelsperformforusersaround
theworld. Modelsperformbetteronthedistributiontheyaretrainedtomimic[Kunchukuttanetal.,
2021]. This often introduces known biases towards languages [Schwartz et al., 2022; Kotek et al.,
2023;Khandelwaletal.,2023;Vashishthaetal.,2023;Khondakeretal.,2023]anddialects[J√∏rgensen
etal.,2015;Blodgettetal.,2016;Zampierietal.,2017;Sunetal.,2023]notincludedduringtraining
and introduces critical security flaws [Yong et al., 2023a; Nasr et al., 2023; Li et al., 2023b; Lukas
et al., 2023; Deng et al., 2023].
Datasets aren‚Äôt simply raw materials that fuel breakthroughs but also make the poor poorer and
the rich richer [Held et al., 2023; Durmus et al., 2023; Robinson et al., 2023]. Disparities in the
access to technological resources predates the advent of LLMs [Garrette et al., 2013]. However, as
LLMs become more sophisticated and widely available, non-English languages will remain under-
representedandwilllikelybecomemoreso. Theimbalancebetweenlanguageshascreatedagrowing
divide in the cost of using this technology as marginalized languages require more tokens and
incur higher latency for generations [Ji et al., 2023b; Cui et al., 2023], consigning speakers of low-
performing languages to lower quality technology [Held et al., 2023; Durmus et al., 2023; Nicholas &
Bhatia, 2023; Ojo et al., 2023]. Often, speakers of low-resource languages do not have the resources
to improve NLP technology for their language, facing a low-resource double bind with limited access
to both compute and data [Ahia et al., 2021].
In this work, our goal is to reduce this linguistic inequality. Efforts that aim to improve
multilingual performance have often focused on improving data coverage [Chen et al., 2023b]. How-
ever, most of the limited effort to date has focused on multilingual pre-training [Scao et al., 2022a;
Wei et al., 2023; Lample & Conneau, 2019] with even less work centered on imparting instruction
followingabilities. ApproachesthathavetriedtotranslateEnglishinstruct-styledatasetsintoother
languages often suffer from translation biases [Vanmassenhove et al., 2021; Hartung et al., 2023;
Savoldi et al., 2021; Muennighoff et al., 2023c] or fail to reflect cultural context appropriately [Wang
et al., 2022a; Ji et al., 2023a; Pudjiati et al., 2022]. Automatic curation of multilingual datasets
is a logical ‚Äîand sometimes necessary‚Äî approach but often suffers from noise and biases. This
makes it difficult to validate the quality of the created datasets [Kreutzer et al., 2022; Luccioni
& Viviano, 2021; Ferrara, 2023; Caswell et al., 2020] or requires the curation of manual templates
which often result in low instruction and completion diversity [Muennighoff et al., 2023c] critical
for model performance [Naik et al., 2023; Chung et al., 2023; Li et al., 2023e; Lahoti et al., 2023].
In contrast, a key aspect of our work focused on harder-to-obtain human-curated data
from fluent speakers of a language. This curation process has received far less attention due to
1https://www.ethnologue.com/
3Dataset #Instances#Langs %English Generationmethod Permissive
license
Llama2 IFT data [Touvron NA 27 90% Human-annotationsSFTdatasets ‚úó
etal.,2023]
Alpaca[Taorietal.,2023] 52K 1 100% SyntheticdatagenerationIFTdatasets ‚âà
P3[Sanhetal.,2022] 12M 1 100% TemplategenerationgivenappliedtoEn- ‚úì
glishdatasets
Flan 2022 [Longpre et al., 15M 60 100% Template generation applied to English ‚úì
2023a] datasets
xP3[Muennighoffetal.,2023c] 81M 46 39% Template generation applied to English ‚úì
datasets
Sweinstruct [Holmstr√∂m & 68K 1 0% MachinetranslationEnglishIFTdatasets ‚âà
Doostmohammadi,2023]
Okapi[DacLaietal.,2023] 158K 26 45% MachinetranslationEnglishIFTdatasets ‚úì
Bactrian-X[Lietal.,2023a] 3.4M 52 2% Machine translation + synthetic data ‚âà
generation
AyaDataset 204K 65 2% OriginalIFTHuman-annotations ‚úì
AyaCollection 513M 114 3.5% TemplateGenerationandtranslatingex- ‚úì
istingdatasets
‚úì
Table 1: Comparison of different instruction-tuning datasets. represents permissive licenses that
allow commercial use while ‚âà represents restrictive licenses that do not allow commercial use.
‚úó
represents non availability of license.
lack of access to fluent speakers, especially in low-resource languages [Joshi et al., 2019]. We chose
to close this gap by conducting a year-long participatory research initiative that involved working
with fluent speakers of languages from around the world to collect human-curated instances of
instructions and completions. By leveraging best practices from open-source and crowd-sourced
science projects [Franzoni & Sauermann, 2014; Beck et al., 2022; Lenart-Gansiniec et al., 2023], we
built a simple and intuitive user interface, the Aya Annotation Platform2 (Aya UI) which served as
thecentralplatformforcontributorstojointheAya3 4 project. Intotal, wehad2,997collaborators
spread across 119 countries around the world. Their collective efforts resulted in the Aya dataset
which is the largest human-curated multilingual instruction-finetuned dataset to date, containing
204,114 high-quality annotations in 65 languages.
Additionally, we release and transform 44 pre-existing datasets into sets of instruction-completion
pairsbycraftingdiversetemplatesmanually,relyingonfluentspeakersforeachlanguage. Wefurther
expand this collection by translating datasets from English into 101 languages. We refer to this
expanded collection of 513 million instances covering 114 languages in total as the Aya collection,
which to date, is the most extensive collection of multilingual instruction-finetuning (IFT) data.
Overall,Ayacontributesfourkeyresources: Aya Annotation Platform(AyaUI);Aya Dataset;
Aya Collection, and Aya Evaluation Suite. Figure 1 shows a visual representation of the Aya
Dataset and Collection. Below, we briefly describe these core contributions:
1. Aya Annotation Platform(Aya UI): We built a robust annotation tool to facilitate the
collection of high-quality multilingual data in an instruction-style format supporting 182 lan-
guages,includingdialects. Overeightmonths,wehadatotalof2,997registeredusersspanning
2This platform is accessible at: https://aya.for.ai
3The word Aya has its origins in the Akan (Twi) language and is translated as ‚Äúfern‚Äù in English [Willis, 1998].
4Aya represents endurance, resourcefulness, and defiance ‚Äì like a fern growing in barren conditions.
4119 countries and 134 languages, including dialects.
2. Aya Dataset: We created the largest human-annotated multilingual instruction finetuning
dataset to date, consisting of over 204K instances that cover 65 languages. We include a data
card [Pushkarna et al., 2022] for the Aya Dataset in Appendix J.
3. Aya Collection: We collected instruction-style templates from fluent speakers and applied
them to a curated list of 44 datasets, including tasks such as Text Classification, Text Gen-
eration, Machine Translation, Paraphrasing, and Open-domain Question Answering. Some of
these datasets also include equivalent multilingual versions produced through translation. We
release 513M instances that cover 114 languages. These contributions are made available as
an open-source collection. We include a data card for the Aya Collection in Appendix J.
4. Aya Evaluation Suite: We curate and release a diverse evaluation suite for multilingual
open-ended generation quality. It consists of 250 human-written prompts for each of 7 lan-
guages, 200 automatically translated but human-selected prompts for 101 languages (114
dialects), and human-edited prompts of the latter for 6 languages, and the English originals.
The first set represents culturally-grounded and original prompts, while the translated and
post-edited prompts are sourced from English Dolly [Conover et al., 2023] and selected for
their cross-cultural relevance. We include a data card for the Aya Collection in Appendix J.
By fully open sourcing the Aya Dataset, Aya Collection and Aya Evaluation Suite with a per-
missive Apache 2.0 License5 as well as the code for our annotation platform, we hope to empower
researchers and practitioners to further advance multilingual models and applications. All datasets
are accessible for download.678
Paper Organization Section 2 discusses the design and development of the Aya Annotation
Platform, as well as the preparation of the Aya Dataset, and Section 3 presents a detailed analysis
of the Aya Dataset. Section 4 and Section 5 contain discussion and analysis of the Aya Collection.
Section 6 describes the details of the evaluation suite curated in this project. In Section 7, we
describe our approach to participatory research. In Section 8, we review the existing literature, and
in Section 9 we discuss the limitations of our work. Section 10 concludes the paper.
2 Aya Annotation Platform & Aya Dataset
2.1 Aya Annotation Platform
The goal of the Aya project is to facilitate annotations to a crowd-sourced dataset by individuals
fluent in different languages. Inputs from fluent speakers of each language ensure that the dataset
is more likely to be organic, fluent, and representative of the speakers‚Äô cultures. Including fluent
and native speakers from various regions poses significant logistical challenges involving meticulous
data selection, quality control measures, and custom annotation tools. We developed the Aya
Annotation Platform to streamline the data collection process worldwide, accommodating a large
number of decentralized contributors across multiple languages.
5https://www.apache.org/licenses/LICENSE-2.0
6https://hf.co/datasets/CohereForAI/aya_dataset
7https://hf.co/datasets/CohereForAI/aya_collection
8https://hf.co/datasets/CohereForAI/aya_evaluation_suite
5Registered Users
350
310
270
230
200
160
120
80
40
0
Figure 2: Geographical distribution of the users registered on the Aya platform.
UserInterfaces(UIs)playapivotalroleinthecontextofNLPdatacollection,servingastheprimary
pointofinteractionbetweenhumanannotatorsandthedatacollectionprocess. TheAyaAnnotation
Platform9 had to accommodate users in 119 countries collecting data across 134 languages. We
designed the platform with a few key principles in mind, such as accessibility and ease of use for
users who were unfamiliar with AI and machine learning. As part of our contribution, we fully
open-source the code for our UI10.
Accessibility As users worldwide use different devices and operating systems, we decided to
support both mobile and desktop interfaces [Muhammad et al., 2023]. Approximately 54% of users
accessed Aya UI via desktop browsers while 46% utilized mobile browsers. We attribute the high
fraction of mobile users to the skew towards mobile users in the Global South [Avle et al., 2018].
We supported Single Sign-On (SSO) capabilities to enable seamless tracking of user profiles and
reward users with points for contributing data across multiple sessions. We initially only supported
Discord sign-on but discovered that Discord is inaccessible or not widely used in certain countries.
Also, the necessity of a platform-specific account created an obstacle to user engagement with Aya.
This prompted us to add Google sign-on as an alternative option.
Languages Supported Aya project contributors could select the languages they are proficient
in when signing up using the Aya UI. They could then make annotations in the language(s) they
selected. Giventhesheernumberoflanguageswecouldcollectannotationsfor,wechosetoprioritize
annotation support for the 101 languages available in the mT5 model [Xue et al., 2021]. We note
that ultimately, some of these languages didn‚Äôt receive enough contributions to include them in the
final dataset. Conversely, we received substantial contributions from languages not initially part of
the original list, like Wolof, leading to their inclusion; the final Aya Dataset covers 65 languages.
Table 5 provides details of these languages.
Contributors We aimed to include individuals from diverse backgrounds‚Äînot limited to AI
experts‚Äîenablinganyoneproficientinalanguagetocontribute. Ourpoolofcontributorsultimately
reflects this inclusive approach. During the registration process, we request specific demographic
details from each Aya UI user such as country of residence, languages of fluent communication,
9https://aya.for.ai/
10https://github.com/for-ai/aya-annotations-ui
6gender, age range, and familiar dialects. We display the onboarding form in Figure 17 in the
Appendix. TheAyacommunityofcontributorsincludes2,997registeredusersacross134languages.
Registered Users by Age Registered Users by Gender
50 100
40.7%
40 37.8% 80
68.1%
30 60
20 40
14.1% 28.4%
10 20
4.5%
1.1% 1.8% 0.0% 0.1% 2.4% 0.7% 0.3%
0 0
0-18 18-25 25-35 35-45 45-55 55-65 65-75 75-121 Male Female
Prefer
Not To
Say Non-Binary Other
Figure3: Left: DistributionofregisteredusersontheAyaUIbyageusingspecifiedvalues. Right:
Distribution of registered users on the Aya UI by gender using specified values
DemographicsFigure3illustratesthedemographicsofregisteredAyaUIusersbyageandgender.
Regarding the age profiles of users, more than two-thirds were aged between 18 and 35. Approx-
imately 68.1% of users identified themselves as male and 28.5% as female. Overall, 6.6% of users
self-reported dialects. Within this group, 75% specified one dialect, 20% specific two dialects, and
the remaining 5% specified three or more dialects, with a maximum of six.
During the development of Aya, registered users
were geographically distributed across 119 coun-
tries based on their residence. Certain countries
like Afghanistan, Bulgaria, Kuwait, and Tajikistan
had just one registered user. Figure 2 displays this
global distribution, highlighting India with the high-
est number of registered users (346 out of 2,997).
Geographic-Based Contribution Assessment
We grouped the languages by the regions in which
they either originate or are widely spoken. The lan-
guage statistics by region for the original 101 lan-
guages we wanted to cover are as follows: 14 lan-
guages in Africa, 41 languages in Asia, 42 languages Figure 4: Distribution of total contributions
in Europe, and 4 languages in Latin America (See across different regions.
Appendix C.1 for more details and some exceptions
of the distribution). As seen in Figure 4, more than
half of all contributions for the Aya project came from Asia with 58.8%, followed by the African
region with 27.4%. Europe, Latin America, and other regions account for the remaining 13.8% of
the contributions.
We observe a large skew in terms of regional contributions, which deserves further research to
understand why certain networks of contributors remained motivated for the entire project. These
7
egatnecrePdisparities in participation may be due to opportunity cost in time [Gerosa et al., 2021; Wu et al.,
2007], cultural beliefs around sharing data [Huang et al., 2023], or the belief that the language in
question is not well served by the current technology [Nicholas & Bhatia, 2023].
Acknowledgement of contributions Recognitionandtransparencyweremaintainedthroughout
the project through the use of a leaderboard11 to acknowledge contributions. We implemented a
scoring system where contributors earned a maximum of three points for each re-annotation, with
one point awarded for rating the prompt and completion, one point for editing the prompt, and
one point for editing the completion. Each original annotation was awarded with two points. We
describe the different annotation tasks in the Aya UI in detail in Section 2.2.
The Aya Leaderboard is organized to display daily, weekly, and cumulative scores, providing a
comprehensive overview of user contributions. The users have the flexibility to filter scores based
on specific languages, allowing for a sense of community amongst contributors of a particular lan-
guage. This design aimed to boost contributors‚Äô motivation to provide high-quality inputs for their
chosen languages. Figure 19 shows an example of the leaderboard. We discuss further details on
collaborating with the community in Section 7.
2.2 Annotation tasks
On the Aya Annotation Platform, contributors were able to contribute to three different tasks,
following the find-fix-verify paradigm [Bernstein et al., 2015]: Writing new examples from scratch
(original annotations), editing existing examples to improve the quality and comprehensiveness
(re-annotations), and giving feedback on the quality of existing contributions (annotation feed-
back). We describe each briefly below:
2.2.1 Original Annotations
This task facilitates the inclusion of human-generated organic content by allowing annotators to
submit original prompt-completion pairs in their language. Existing multilingual models have been
shown to produce generations influenced by Western culture [Yuan et al., 2021; Naous et al., 2023;
Lee et al., 2023] reflecting the underlying representation bias [Mehrabi et al., 2021] of their training
datasets. This task aims to encourage annotators to submit fresh samples that are representative of
their language, culture, literature, history, and region. The guidelines for contributors is available
in Appendix B.3.
2.2.2 Re-Annotations
The purpose of this task is to facilitate the re-annotation or editing of prompt and completion
pairs. The decision to add a re-annotation task partly stems from the need to help annotators
understand the expected format of instruction-style datasets and to convey the variety of tasks
in existing datasets, including question answering [Saad-Falcon et al., 2023; Arefeen et al., 2023],
summarization [Stiennon et al., 2020; Wu et al., 2021], paraphrasing [Witteveen & Andrews, 2019;
Reimers&Gurevych,2019],andtranslation[NLLB-Teametal.,2022;Barraultetal.,2023]. Editing
examples from existing datasets not only helped familiarize annotators with the expected format
11The Aya Leaderboard is accessible at: https://aya.for.ai/leaderboard/
8Leaderboard
Leaderboard
Contribute Your Language Rate Model Performance
Help us add more examples by writing your own prompt and their Help improve the model performance by rating the prompt-completion pairs below
completion in your language.
Edit Mode English
English
Prompt
Look out for: Correct Grammar Reasonable Length Clear Instructions
Prompt
What does it mean in English "to crave" something?
what does "to crave" mean?
Edit Distance[Prompt]: 35
Completion
Completion Look out for: Clear Answer Full Sentences with Correct Answer Reasonable Length
to crave is to really really want something, or to have a deep To crave is to have a strong and intense desire for something. It implies a deep need
or longing for the object of the craving. It can involve emotional and physical feelings
desire.
of addiction and can sometimes lead to actions against one's best interests. It is
important to note that there is a difference between wanting or liking something and
craving it, as craving can be destructive and lead to unhealthy behaviors.
Edit Distance[Completion]: 321
Submit Entry Skip Submit Entry
(a) Example of an original annotation contribution. (b) Example of a re-annotation contribution.
Made by the C4AI Open Science Community. The Aya Project
Figure5: Demonstrationofasampleoriginalannotationandre-annotationcontribution,inEnglish.
(a) exemplifies an original contribution input by an annotator from scratch. (b) shows a sample of
re-annotation. Here, the annotator may have improved upon either a prompt and completion pair
pulled from the database or a prompt and completion originally created by another contributor.
but also allowed for human evaluation and rating of existing widely used instruction-style datasets.
In total, we collected datasets from 19 public data sources and translated them into 114 available
languages, including dialects using the NLLB 3.3B parameter machine translation model [NLLB-
Team et al., 2022]. From each collection, we randomly chose 100 examples (per dataset and per
language),creatingourdatasetforannotation,afterwhichwehad1Mtranslatedprompt-completion
pairs initially populated in the Aya UI as re-annotation tasks. These translated pairs served as
a starting point for prompts and completions which annotators could improve. We release the
raw translations as part of the Aya Collection, provide more details about the provenance of the
translated datasets, and how they were selected in Section 4.2.
In addition to translated examples, there are other available data sources suitable for re-annotation:
original Aya pairs, pre-existing instruction-style datasets (e.g., xP3), and the transformation of
datasets into an instruction-style format, i.e., templated datasets. By re-annotating examples from
different sources, we simultaneously enhance the quality of individual examples while obtaining a
signalontheoverallqualityofthedatasetinaspecificlanguage. Ademonstrationofare-annotation,
where an annotator strengthens a given prompt/completion, is shown in Figure 5b.
92.2.3 Annotation Feedback
Data quality is critical to ensure that a model can represent a language well. Learning from noisy,
low-quality datasets harms the overall model performance and the relatively high cost of encoding
these noisy examples is a misuse of capacity [Hsueh et al., 2009; Dodge et al., 2021; Luccioni &
Viviano, 2021; Kreutzer et al., 2022]. Prior work has shown that improvements to quality through
data pruning or selection can have an significant impact on the downstream performance of a model
[Longpre et al., 2023c; Marion et al., 2023; Boubdir et al., 2023; Yang et al., 2023]. In particular,
for instruction-tuning datasets, a small subset of higher-quality instructions can greatly outperform
a larger volume of lower-quality instructions [AlShikh et al., 2023; Zhou et al., 2023; Chen et al.,
2023a]. Given these findings, ensuring high quality contributions is of paramount importance.
Ensuring consistent quality is particularly challenging in an open science initiative with a large
number of contributors. We face two key challenges:
Changes in the Annotator Pool. During the year-long project, annotators joined and left the
project at different points depending on their interests and availability. As a result, the window of
contribution for each annotator was different. Only a small fraction of annotators participated for
the entire duration of the year-long project. Annotators were active for an average of 1.3 sessions.
Figure 6 presents a histogram depicting the distribution of user engagement based on the number
of days they actively contributed. On average, Aya annotators spent five days contributing to the
project. Annotators tended to be highly active shortly after joining, but their activity declined
over time. There was a subgroup of annotators who maintained consistent activity over extended
periods.
Varying level of experience with AI.
An important goal of this project was to
have a diverse pool of annotators and we
thus did not limit the selection criteria to
working knowledge of language models or
AI in general. As a result, there were dif-
ferent levels of understanding amongst the
annotators what was meant by a prompt
and completion. For example, we found at
least one contributor with 3,684 contribu-
tions to three languages (English, Somali,
Standard Arabic) who failed to structure
their submissions as a prompt with a ques-
tion. Instead, the contributor used an ex-
tract of text as the prompt and its contin-
Figure 6: The distribution of annotators‚Äô engagement uation in the completion. Prefacing such
based on the number of days they actively contributed promptswithaninstructionsuchas‚ÄúCom-
in Aya UI plete the following partial extract of text:"
would have been a more suitable format.
While we routinely provided examples to contributors, there was a clear need for a systematic way
to review and measure the quality of submissions.
Validating the quality of contributionsWefollowapeer-reviewapproachwhereeachannotator
acts as a reviewer for the other annotators working on the same language. These reviews form the
10basis for a quality Aya score which is displayed on the leaderboard in the UI. The quality score for
an annotator is calculated by averaging the combined average ratings of their examples provided
by other annotators who serve as reviewers. We provide more details about how annotations are
reviewed in the Appendix Section B.1. All three tasks in the Aya UI are connected in a sequen-
tial pipeline where submissions from ‚ÄúOriginal Annotations‚Äù are reviewed in the ‚ÄúRe-Annotations‚Äù
task, and the re-annotations are further reviewed as part of the ‚ÄúAnnotation Feedback‚Äù task. This
systematic approach allows for a robust evaluation and enhancement of the collected data.
2.3 Criteria for Inclusion in Aya Dataset
TheAyaDatasetincludesalloriginalannotationsandasubsetofallre-annotations. Weonlyrelease
re-annotations if there is a difference between the original and the edited version. To determine this
subset, we compute the sum of edit distances d (Levenshtein distance [Levenshtein et al., 1966])
between the original and re-annotated prompts and completions on the character level and use an
acceptance threshold of (d ‚â• 5). This ensures that we do not release duplicates of existing data.
Only languages with at least 50 contributions were included in the final release of Aya Dataset.
This threshold was picked as it represents a balance between achieving a reasonable level of data
qualityandconsideringthepracticallimitationsofhumanresourcesforsomelanguages. Thegoalis
toincludeasmanylanguagesaspossiblewithoutloweringtheoverallqualityofthedataset. Table5
lists details of the languages included in the Aya Dataset.
Count
Original Annotations 138,844
xP3 datasets 2859
Re-Annotations Translated datasets 7757
Templated datasets 11013
Original Annotations 43641
Aya Dataset Total 204,114
Table 2: Aya Dataset Statistics (number of pairs of prompts and completions obtained through
various annotation tasks).
3 Analysis of Aya Dataset
3.1 Statistics
The Aya Dataset contains a total of 204,114 instances collected via the Aya Annotation Platform.
Table 2 provides the breakdown of original annotations and re-annotations in the final dataset. The
dataset covers 65 languages: 22 high-resource, 12 mid-resource, and 31 low-resource languages (See
Appendix E for more details on our language mappings).
3.2 Length of Aya Dataset
One objective of this project was to collect fluid original human prompts and completions. Table 3
provides examples of prompts and completions from the Aya Dataset. During the data collection
11Initial Length Edited Length
600
500
400
300
200
100
0
xP3* Translated* Templated* AYA original
annotations*
Figure 7: Average Completion Length before and after re-annotation. Here (*) indicates the subset
of all dataset categories (xP3, translated, templated, and Aya original annotations) that were
includedintheAyaDatasetafterre-annotation. Re-annotationimprovesaveragecompletionlength
across all datasets.
process, annotators were provided with examples and guidelines but were also trusted to explore
their own creativity and cultural background to come up with new examples. As a result, it is
meaningful to understand differences in aggregate statistics like length across datasets, language
type and relationship with perceived quality.
Impact of Re-Annotation When edit-
ing existing instances, we instructed the
HR MR LR
annotatorstoprioritizeenhancingboththe 600
quality and richness of the prompts and
completions. The average length of com- 500
pletions before and after edits are shown
in Figure 7. We observe that across all 400
data sources, the average length of com-
pletionincreasedafterediting. Onaverage, 300
thelengthofcompletionsaftereditsis25%
200
longer than before edits. We observed the
largest increase for Aya original annota-
100
tions surfaced in the UI ‚Äì which were 40%
longer on average than the original length.
0
Prompt Completion
Length difference across language
Figure 8: Average prompt and completion length of in-
groups The average prompt and com-
stances in the Aya Dataset across different language
pletion length (number of characters)
categories (high (HR), mid (MR) and low (LR) re-
observed across these different language
source languages, see Table 5).
groups is shown in Figure 8. A dis-
tinct contrast exists in completion lengths
between mid and low-resource languages
when compared to high-resource languages. Long completions and complete sentences are valuable
12
htgneL
noitelpmoC
egarevA
htgneL
egarevAFigure 9: Relationship between Average Prompt and Completion Length in characters and the
Average Approval Rate of the example.
in instruction-tuning datasets, particularly when training multilingual models to generate content
in those languages.
Length vs. Perceived Data Quality Although longer completions can be valuable for training
models to generate long and natural text, it does not necessarily imply higher quality. Using
annotators‚Äô feedback in the UI, we further investigate the impact of length on the perceived quality
ofthesamples. Figure9showcasesthisanalysis. Weobserveapositivecorrelationbetweenhowlong
the prompts and completions are and their resulting average approval ratio. Specifically, when we
plot combined prompt and completion length against quality, we observe a correlation coefficient
of 0.27. This finding emphasizes the importance of using longer prompts and completions and
incorporating complete sentences to ensure a positive human experience when engaging with such
a model.
Length difference by language Figure 25 in the Appendix illustrates the statistics per lan-
guage. We observe an array of patterns that differed across languages. For instance in Japanese,
completions are on average 31% shorter than prompts. On the other end, for Urdu and Yoruba,
completions are notably long relative to prompts. On average, completions are 1258% and 2516%
longer than the corresponding prompts for Urdu and Yoruba, respectively. The average completion
length in Yoruba is 1591% longer than the average prompt length in Japanese. Figure 26 provides
the average length of the combination of prompts and completions per language.
Comparison in Completion length Across DatasetsTheAyaDatasethasconsiderablylonger
completions on average when compared with other data collections as shown in Figure 12. This is
particularlynoteworthygiventhattheAyaDatasetishuman-curated. Giventhepresenceoflonger
completions in the training data for many low-resource languages, we expect that models trained
on the Aya Dataset will generate longer and more natural responses.
3.3 Annotator Skew
A feature of participatory research projects is the challenge of establishing and maintaining a bal-
anced number of annotations across groups of annotators. In the Aya project, the number of
annotators per language varied due to numerous factors. As a result, the distribution of annota-
13Lang Prompt Completion
ara
.(cid:1688)(cid:1645)(cid:1712)(cid:2629)(cid:2061)Ô∫ç(cid:1888)(cid:3548)(cid:3763)(cid:1862)(cid:1857)Ô∫°(cid:1678)(cid:1857)Ô∫ì(cid:1678)(cid:1645)(cid:1905)(cid:1698)Ô∫Ä(cid:1543)(cid:2800)(cid:2777)(cid:1542)(cid:4051)(cid:1854)(cid:1698) Ÿã(cid:3080)(cid:3075)(cid:1903)Ÿé(cid:1699)(cid:1722)(cid:1652)(cid:1711)(cid:1604)Ôªô(cid:2058)(cid:2042)Ÿè(cid:2510)(cid:2506)Ô∫çÔ∫°(cid:1678)Ÿé(cid:1857)Ôª•Ô∫á(cid:1443)
Ô∫©(cid:1543)(cid:3866)Ôª≠(cid:2521)(cid:5466)(cid:2513)Ô∫çŸéÔª≠Ôªâ(cid:1543)(cid:3871)(cid:3539)(cid:3522)Ô∫ç(cid:3843)(cid:3715)(cid:1678)Ÿé(cid:1857)(cid:1862)Ÿé(cid:1564)
(cid:1854)Ÿè(cid:4827)(cid:4810)Ÿê(cid:1857)(cid:1776)(cid:1699)(cid:3080)(cid:3075)Ÿê(cid:2629)(cid:2061)Ô∫ç(cid:2611)Ÿë (cid:1564)(cid:1543)(cid:1614)(cid:1677)Ÿé(cid:3872)Ô∫É(cid:5466) (cid:1960)Ÿé(cid:1843)
Ô∫Ä(cid:1543)(cid:2800)(cid:2777)(cid:2517)(cid:1443)(cid:2513)Ô∫ç(cid:4397)(cid:4383)(cid:2611)ŸéŸé(cid:2598)Ôª±Ô∫ØÔ∫ç(cid:1960)Ÿè(cid:1604)(cid:4693)Ÿé(cid:4648)
fra Qui a √©crit le livre La AntonineMailleta√©critLaSagouineen1971. Ellea√©critbeau-
Sagouine? coupd‚ÄôhistoiressurlesAcadiens(lesfrancophonesdelac√¥teEst
duCanada)etafaitconna√Ætrel‚ÄôAcadieaumonde.
ibo Kedu ka nd·ªã Igbo si eme Emume ji ·ªçh·ª•r·ª• n‚Äôomenala Igbo, b·ª• emume na-egosi njedebe
emumeji·ªçh·ª•r·ª•? oge·ªçr·ª•ugbo,na-amalitesiten‚Äôemumeekelematinyekwaoriri
naegwu. ·ªåb·ª•mmemme·ªçgbak·ªçebeana-eker·ªãtaji·ªçh·ª•r·ª•,na-
egosip·ª•taekelenammalitenkeoge·ªçh·ª•r·ª•,na-emekammek·ªçr·ªãta
mmad·ª•naibeyad·ªãkwuoelu.
por Qual√©acapitaldoestadoda A capital do estado da Bahia, no Brasil, √© Salvador. Fundada
Bahia? em 1549, foi a primeira capital do Brasil e √© conhecida por
seupatrim√¥nioculturalricoediversificado. Acidade√©famosa
porsuaarquiteturacolonial,particularmentenoPelourinho,um
centrohist√≥ricoquefoideclaradoPatrim√¥nioMundialpelaUN-
ESCO.
pes Ô∫ÆÔ∫óÔªÆÔ∫íÔÆêÔª™ÔªßÔªªÔ∫™Ôª®Ô≠ºÔ∫™Ô∫íÔª¥Ôª£Ôª™ÔªßÔ∫éÔ∫ßÔ∫ÆÔ∫óÔªÆÔ∫íÔÆêÔ∫ùÔ∫ÆÔ∫ëÔ∫≠Ô∫© Ô∫≠Ô∫çÔªÆÔªßÔª≠Ô∫©Ô∫≠Ô∫çÔ∫©Ô∫©ÔªÆÔ∫üÔª≠Ô∫ÆÔ∫óÔªÆÔ∫íÔÆêÔª™ÔªßÔªªÔ∫≠Ô∫çÔ∫∞Ôª´ Ô∫≠Ô∫éÔª¨Ô≠ºÔª•Ô∫ÅÔªûÔ∫ßÔ∫çÔ∫©Ôª™ÔÆêÔ∫ñÔ∫≥Ô∫çÔØºÔ∫ç Ôª™ÔªßÔ∫çÔªÆÔ∫òÔ∫≥Ô∫çÔØΩÔ∫üÔ∫ÆÔ∫ëÔ∫™Ô∫íÔª¥Ôª£Ôª™ÔªßÔ∫éÔ∫ß Ô∫ÆÔ∫óÔªÆÔ∫íÔÆê
ÿüÔ∫©Ô∫≠Ô∫çÔ∫©Ô∫©ÔªÆÔ∫üÔª≠ Ô∫ÆÔªÑÔ∫ßÔ∫ÆÔ∫ëÔ∫çÔ∫ÆÔ∫ëÔ∫≠Ô∫©Ô∫ùÔ∫ÆÔ∫ëÔª¶Ôª≥Ô∫ç .Ô∫ñÔ∫≥Ô∫çÔª©Ô∫™Ô∫∑Ôª©Ô∫™Ôª¥Ô∫∏ÔÆêÔ∫ùÔ∫ÆÔ∫ëÔ∫≠Ôª≠Ô∫©Ô∫éÔ∫óÔ∫≠Ôª≠Ô∫©Ôª•Ô∫çÔ∫ÆÔ∫óÔªÆÔ∫íÔÆêÔ∫èÔ∫¨Ô∫üÔØºÔ∫çÔ∫ÆÔ∫ëÔØΩÔÆïÔªßÔ∫≠Ô∫™Ôª¥ÔªîÔ∫≥
.Ô∫ñÔ∫≥Ô∫çÔª©Ô∫©ÔªÆÔ∫ëÔª¶Ôª§Ôª≥Ô∫çÔ∫≠Ô∫éÔª¥Ô∫¥Ô∫ëÔ∫éÔª´Ô∫ÆÔ∫óÔªÆÔ∫íÔÆêÔª™Ô∫ëÔ∫ïÔ∫éÔªßÔ∫çÔªÆÔª¥Ô∫£Ô∫ÆÔÆïÔª≥Ô∫©Ôª™Ôª†Ôª§Ô∫£
msa Apakahnasilemak? Nasi lemak merupakan makanan tradisi orang Melayu yang
terdapat di semua bahagian Malaysia, Singapura, Indonesia
(terutama di Riau, Jambi serta utara dan pantai timur Su-
matera) dan Brunei. Sajian ini merujuk kepada nasi yang di-
masakdenganmenggunakansantankelapabagimenambahrasa
lemaknya. Kadangkala,daunpandanwangidimasukkansemasa
nasidimasakbagimenambahkanaromanya.
tam ‡ØÜ‡Æö‡ÆØ‡Æ±‡Øç‡Øà‡Æï ‡Æ®‡ØÅ‡Æ£‡Øç‡Æ£‡Æ±(cid:167)‡Æµ‡ØÅ ‡ØÜ‡Æ™‡Ææ‡Æ§‡ØÅ‡Æµ‡Ææ‡Æï ‡ÆÆ‡Æ©‡Æø‡Æ§‡Æ∞‡Øç‡Æï‡Æ≥‡Ææ‡Æ≤‡Øç ‡ØÜ‡Æö‡ÆØ‡Øç‡ÆØ‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Æ£‡Æø‡Æï‡Øà‡Æ≥‡Æö‡Øç
‡Æé‡Æ©‡Øç‡Æ±‡Ææ‡Æ≤‡Øç‡Æé‡Æ©‡Øç‡Æ©? ‡ØÜ‡Æö‡ÆØ‡Øç‡ÆØ ‡Æí‡Æ∞‡ØÅ ‡Æï‡Æ£‡Æø‡Æ©‡Æø ‡ÆÖ‡Æ≤‡Øç‡Æ≤‡Æ§‡ØÅ ‡Æí‡Æ∞‡ØÅ ‡Æï‡Æ£‡Æø‡Æ©‡Æø‡ÆØ‡Ææ‡Æ≤‡Øç
‡Æï‡Æü‡Øç‡Æü‡ØÅ‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡ÆÆ‡Øç‡Æí‡Æ∞‡ØÅ‡Øá‡Æ∞‡Ææ‡Øá‡Æ™‡Ææ‡Æµ(cid:165)‡Æ©‡Øç‡Æ§(cid:166)‡Æ±‡Æ©‡Øç‡ØÜ‡Æö‡ÆØ‡Æ±‡Øç‡Øà‡Æï
‡Æ®‡ØÅ‡Æ£‡Øç‡Æ£‡Æ±(cid:167)‡Æµ‡ØÅ‡Æé‡Æ©‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡ÆÆ‡Øç.
Table 3: Examples of prompt and completions in the Aya Dataset.
tors is not uniform across languages. Moreover, within each language, there is a lack of consistent
contributions from all annotators. In this section, we examine the impact of annotator skew on the
resulting dataset.
Annotator Skew Across Languages. Annotatorswereencouragedtocontributetoanylanguage
in which they could comfortably read and write and were asked to focus most of their efforts on
languages other than English. Although a significant number of participants registered for many
languages, the engagement level of annotators was not equal, which resulted in considerable differ-
ences in the number of contributions across languages. Figure 10 (top) provides an overview of the
percentage of each language present in the final compilation. The highest number of contributions
is for Malagasy with 14,597 instances, and the lowest is 79 for Kurdish.
Annotator Skew Within a Language. The final contributions for each language in the Aya
Dataset are not evenly distributed among annotators. The median number of annotators per lan-
guage is 15 (mean is 24.75) with one language having only a single active annotator (Sindhi) and
146
4
2
0
1.00
0.75
Top 1
Top 2
Top 3 0.50
Top 4
Top 5
0.25
High number of active annotators Low number of active annotators
Figure 10: Top: Ratio of all annotations per language with respect to the whole dataset. Bottom:
Ratio of annotations done by the top-k most active contributors (k = 1,...,5). Languages annota-
tions follow their respective ISO codes from Table 5.
some having over 80 annotators (English and Portuguese). Note that annotators made contri-
butions at varying rates, and there is no direct correlation between the number of annotators and
the ultimate count of language contributions. A limited pool of annotators for some languages im-
plies that most instances in that language originate from a smaller group of individuals. Figure 10
(bottom) illustrates the proportion of instances in a language originating from the most active
annotators. We observe a skewed pattern where for 12 languages, the 5 most active annotators
contributed all examples. There is an uneven distribution of contributions for many languages be-
cause those languages had a smaller number of voluntary annotators throughout the entire project
despiterigorousoutreach. Additionally, wedidnotestablishaspecificquotaforannotatorstomeet;
everyone contributed as they desired, resulting in varying levels of activity among annotators.
ThemostextremecasesareZuluandSindhi, whereoneannotatorineachlanguagevolunteeredfor
all contributions in Annotation and Re-annotation tasks. Thus, in Figure 10 their top-1 contributor
ratio is 1.0 and does not change when moving to top-2 or further. The languages with the least
skewed distributions are Malagasy, Tamil, Nepali, Hindi, English and Portuguese. The lan-
guage English also had the highest number of unique annotators with 130 individuals out of which
95 annotators contributed to English as their second language for annotation purposes. Given
the uneven distribution of annotators per language, it is important to acknowledge that individual
annotator quality has a disproportionate influence on some languages.
3.4 The impact of introducing the Aya Score
As part of our collaborative annotation effort in Aya, we emphasized the importance of quality as
well as long completions that contain clear responses to the instructions specified in the prompt
during the project. To encourage high-quality examples from the annotators, we introduced the
Aya Score (Section B.2) halfway through the project to focus on the quality, in addition to the
quantity, of contributions.
15
)%(
egatnecrep
noitatonnA
glm mat pen nih gne rop aws aps mos jug aym rik sur obi ati uah dni til arf nis nak ara low asm sep ohz ued aht nuh prs sup dru nad rut ans tah rok ohx lif rku neb ram eiv hma lle lop nap osn bec let lam dln roy elg vaj sue nif iqs ews ayn nus npj ruk luz dnsThe Aya Score encouraged participants to incorporate more edits during annotation, with one
specific guideline urging them to transform short answers into full sentences or paragraphs. Fig-
ure 11(right) shows the change in the completion lengths over time. We observe that after in-
troduction of the Aya score, there is a marked uptick in the completion length of all submitted
annotations.
Original Annotations and Re-annotations Original Annotations Re-annotations
800
40000
Aya Score introduced
600
30000
Aya Score introduced
400
20000
10000 200
0
May
2023
Jun
2023
Jul
2023
Aug
2023
Sep
2023
Oct
2023
Nov
2023
Dec
2023
May
2023
Jun
2023
Jul
2023
Aug
2023
Sep
2023
Oct
2023
Nov
2023
Dec
2023
(a) Volume of submissions over time (b) Average completion length over time
Figure11: Thevolumeoforiginalannotationsandre-annotationsincreasesaftertheintroductionof
Aya Score. We also observe a marked uptick in the completion length of all submitted annotations
with the introduction of the Aya Score.
4 Aya Collection
We introduce the Aya Collection, a comprehensive, large corpus of datasets that can be used by
researchers around the world to train multilingual models. Our goal is only to include datasets with
permissive licensing for manipulation and redistribution.12 Where possible, we report the license
associated with each dataset within the Aya Collection.
The Aya Collection consists of three different sources of data:
1. Templated data: We collaborated with fluent speakers to create templates that allowed for
the automatic expansion of existing datasets into various languages.
2. Translated data: We translated a hand-selected subset of 19 datasets into 101 languages
(114 dialects) using the NLLB 3.3B parameter machine translation model [NLLB-Team et al.,
2022]. The full list of datasets translated is listed in Appendix Table 9.
3. Aya Dataset: We release the Aya Dataset described in Section 3 as a subset of the overall
collection. This is the only dataset in the collection that is human-annotated in its entirety.
Dataset Selection Criteria The templated and translated datasets in the Aya Collection were
selectivelyhandpickedtoachieveamixofdifferenttasktypes. Ourcriteriaprioritizeddatasetswith
high-qualitynaturalandcompletesentences, suitableforcreatingpairsofpromptsandcompletions.
Datasets that could potentially yield single-word answers were deliberately excluded. Finally, to
12https://en.wikipedia.org/wiki/Permissive_software_license
16
snoissimbuS
fo
emuloV
htgneL
noitelpmoC
egarevA500
400
300
200
100
0
Aya Dataset xp3 Aya Collection Aya Collection
(Templates) (Translations)
Figure 12: Comparison of completion lengths between Aya Dataset, Aya Collection, and xP3
(excluding the "code" split).
create a high-quality collection, we examined all datasets and excluded those identified as unclean
or noisy, primarily attributable to their automatic creation processes.
4.1 Templating Existing Datasets
We explored the automatic expansion of existing datasets in various languages with human-written
prompt templates, following previous works [Mishra et al., 2022; Bach et al., 2022; Wei et al., 2022a;
Wang et al., 2022e]. Unlike prior works that still either use English prompts in a multilingual
dataset or rely on automatic translation to generate multilingual prompts, to our knowledge, Aya
Collection is the first broad effort to involve fluent speakers in creating prompts unique to their
language to expand existing datasets for instruction tuning.
We used the PromptSource framework [Bach et al., 2022] to template these datasets. We asked
Aya community members to submit instructions and create templates for datasets in the languages
they were proficient in. Our process includes: 1) Templating datasets with instructions in the same
language as the original dataset; 2) If the dataset is not in English, annotating instructions in
English. Our input prompts can be monolingual or code-mixed, depending on whether we apply
templates in the same language or in English to the dataset of a particular language. Note that
code-mixedinputpromptshererefertoastructured mixingofEnglishinstructionswithnon-English
monolingual data [Lin et al., 2022], which is different from the typical sociolinguistic definition of
code-mixing (or code-switching) of languages in natural conversational utterances [Winata et al.,
2023a; Yong et al., 2023c; Doƒüru√∂z et al., 2023; Srivastava & Singh, 2021].
We examined the suggested templates and subsequently converted each dataset into an instruction-
style format. We release these datasets under the Aya Collection. We list the details of all datasets
we apply templates to in Appendix Table 8.
17
htgneL
noitelpmoC
egarevA4.2 Automatic Translation
Research has demonstrated that training models with translated data can yield significant benefits
[Aharoni et al., 2019; Zhang et al., 2018b; Tang et al., 2021]. We experiment with improving
coverage of low-resource languages by selectively translating high-quality datasets from various
existing collections.
Setup We selectively pick 19 high-quality IFT datasets from xP3 [Muennighoff et al., 2023c], the
Flan Collection [Longpre et al., 2023a], Dolly [Conover et al., 2023], along with additional sources
such as SODA [Kim et al., 2022] and Mintaka [Sen et al., 2022]. Datasets were prioritized for
translation based on the richness of task diversity and length of completions. The complete list
of these datasets is given in Appendix 9. These translations are available and open-source as part
of the Aya Collection. We process datasets for translation using the No Language Left Behind
(NLLB) [NLLB-Team et al., 2022] machine translation model, which is capable of single-sentence
translations between 200 different languages and dialects in various scripts. For best performance,
we use the largest NLLB model with 3.3B parameters.
Translation Quality Appendix Section G.1 lists NLLB
translation quality for each of the languages of interest, as
70
reported in [NLLB-Team et al., 2022]. Figure 13 shows the
60
translation quality across languages grouped by their resource-
fulness. The mean ChrF++ score on FLORES is 48.17 (min: 50
10.9,max: 69.6)fortranslationsoutofEnglish,withafewout-
40
liers for HR and LR. We interpret this optimistically as strong
30
enough to sufficiently serve our translation needs. However,
upon inspection of translation outputs for fine-tuning data, we 20
encounter significant translation errors with Standard Arabic 10
in Latin script and Minangkabau in Arabic script, so we ex- HR MR LR
clude them from our translated dataset. In total, 19 public
Figure 13: ChrF++ scores for the
datasets were translated into 101 languages (114 dialects). De-
NLLB translation model, averaged
tails of these datasets can be found in Appendix Table 9.
across resourcefulness buckets.
In addition to releasing the translated datasets used as a ba-
sis for re-annotation, we also translated Dolly [Conover et al.,
2023]. Dolly is a 15k instruction dataset Databricks collected by relying on its employees as anno-
tators [Conover et al., 2023]. Annotators were instructed to curate prompt and completion pairs
in each of eight different instruction categories. In contrast to the mentioned NLP datasets, Dolly
was purposefully designed to align language models with human expectations. It stands out as a
high-quality, manually curated dataset covering a range of topics including brainstorming, classifi-
cation, closedquestionanswering, generation, informationextraction, openquestionanswering, and
summarization. The addition of the translated Dolly datasets is a valuable resource for languages
that experience a scarcity of conversational instruction fine-tuning datasets.
The list of datasets, along with the number of languages, templates, and other statistics, can be
found in Appendix Table 9.
18
++FrhCMain Task Type Fine-grained Task Type
Question Answering ‚Äî
Natural Language Generation Summarization
Translation
Paraphrasing
Dialogue
Text Simplification
Text Classification Sentiment Analysis
Information Extraction
Named Entity Recognition
Event Linking
Natural Language Inference
Document Representation
Table 4: Task Taxonomy of NLP tasks in the Aya Collection.
5 Analysis of Aya Collection
5.1 Statistics
Overview The Aya Collection consists of existing NLP datasets that are templated to include
instructions as well as datasets already in instruction format submitted by the Aya community.
Table 8 shows the detailed list of datasets. The full list of templates is available in Section K.
The final Aya Collection consists of 44 multilingual and non-English templated datasets and 19
translated datasets, with 513M individual instances. Overall, the collection covers 114 languages13.
Tasks Covered Across Templated and Translated Datasets We aim to include datasets
from various tasks in the collection while ensuring that they follow our selection criteria. Table 4
illustrates our task coverage in the Aya Collection, drawing inspiration from xP3 and the Flan
Collection. We have a total of three main task types: Question Answering (QA), Natural Language
Generation (NLG), and Text Classification (TC). Within these larger umbrella tasks, we define
several finer-grained task types based on the datasets, resulting in a total of 11 finer-grained task
types. These finer-grained task types are determined by the frequency of datasets in the Aya
Collection encapsulating that task.
ForQA,wedecidedtokeeponlythemaintasktype,astheintendedgoalofquestion-answeringtasks
is clear: Answer a proposed question. The type of the question can be different: open-ended, close-
ended, multiple-choice, single response. For NLG, finer-grained task types include Summarization,
Translation, Paraphrasing, Dialogue (Generation), and Text Simplification. For TC, we include
the following finer-grained task types: Sentiment Analysis, Information Extraction, Named Entity
Recognition, Event Linking, Natural Language Inference, and Scientific Document Representation.
Finally, we label the task categories of each dataset in the Aya Collection in Table 10 and Table 11.
If we are not able to find a fine-grained task type for the dataset, we keep the main task type.
13WereleasetheAyaDatasetaspartoftheAyaCollection,bringingthetotalnumberoflanguagesinthecollection
to 115. However, for the sake of clarity, when referencing the Aya Collection statistics in this paper, we exclude the
Aya Dataset.
19Number of Wikipedia Articles
Median
Number of instances in Aya Collection
106
106
105
105
104
104
103 103
102
102
Figure14: Numberofprompt/completionpairsineachlanguageintheAyaCollection(templated).
Many languages with limited digital presence, as indicated by a low number of Wikipedia pages,
are well-represented in the templated portion of the Aya Collection. Note that absolute Both axes
are in log-scale.
Language Balance One of the objectives of templating (and translating) existing datasets is
to broaden the available resources for languages that have limited digital data. To examine if our
final collection adheres to a similar distribution pattern, we use the number of Wikipedia pages in
each language as a proxy for the online presence of its fluent speakers. Figure 14 showcases that
although the number of instances for languages varies in the Aya Collection (templated subset),
it does not disadvantage languages with fewer Wikipedia pages. The distribution still ensures a
reasonable coverage across all languages. It is imperative to emphasize that our analysis does not
involve a direct comparison of absolute values, given the disparate units of measurement involved.
Instead, we examine the patterns of data scarcity for various languages in our collection versus
Wikipedia. Including the translated datasets in the Aya Collection further reduces disparities
between languages and contributes to creating a more balanced collection.
Prompt and Completion Lengths Figure 15 shows the distribution of length across languages.
No discernible pattern is observed when examining lengths for high-resource languages compared to
low-resource languages. Low-resource languages appear at both ends of the distribution, occupying
both the head and tail. In the Aya Collection some low-resource languages (e.g., Somali and
Amharic)havelongeraveragecompletionslengththanmediumorevenhigh-resourcelanguages. The
dedication of individual participants in identifying datasets in their own language and templating
them has made a significant difference for many languages.
20
noitcelloC
ayA
ni
secnatsni
fo
rebmuN
gne ued arf lop npj ati dln aps sur ews ron nif tac rku rut nor sec nuh kls nad dni beh bra rok prs vls lub eiv vrh sep let aht lle nih ram neb mat vaj nus leb rfa dru lam hws nak eyh hma jil jug nis low obi mos luz nik iwt uah
Number
of
Wikipedia
Articles1000
Language Category
HR
MR
LR
800
600
400
200
0
Figure 15: The average length of prompts and completions for high (HR), medium (MR) and low-
resource (LR) languages in Aya Collection.
5.2 Quality Assessment of All Different Data Sources
Aspreviouslystated,binaryfeedbackonthequalityoftheprompt-completionpairingswascollected
from the annotators. We define the average approval ratio per dataset which serves as a valuable
metric for assessing the quality of datasets across various languages and diverse data sources. We
compute the average approval ratio as T +/T, where T + represents the total number of thumbs up,
and T represents the total number of votes per dataset. An average approval ratio of 1.0 would
indicate that every annotation was perceived to be of good quality and all prompts and completions
had received a thumbs up. An average approval ratio of 0.0 would indicate that every annotation
was perceived to be of poor quality, and all prompts and completions had received a thumbs down.
We constrained our quality analysis to the 40 datasets in our pool for which we had at least 20
instances of feedback.
Overall, we observe that the majority of datasets were of above average (0.5) quality based on
their approval ratio, with all translated data as well as Original Annotations being above average.
However, across all the datasets within each group ‚ÄîxP3, Templated, Translated, and Aya original
annotations‚Äî Aya original annotations were perceived to be of the highest quality, with an average
approval ratio of approximately 0.81, compared to the lowest quality dataset, xP3, which had an
average approval ratio of approximately 0.50. This aligns with our intuition that carefully curated
datasets lead to high-quality annotations as perceived by human annotators. Figure 16 provides
a summary of the results for each group. Figure 23 in the Appendix provides approval ratios per
datasets in each group.
21
)noitelpmoc
+
tpmorp(
htgnel
egarevA
vrh ued lif arf gne nih glm bec oms dru diy mos let ztl irm mat sec lle ohx iqs dln aps ati elg dni tac luz tlm nak ans uah lam bzu aws nus uak nor sep roy rop rfa vaj glg myc sur aym eyh mhk kgt eiv lop dkm neb ope obi ruk lub nom sak jil nad nuh rku leb jug ram rut tak zak ews ron til prs vls sue val nis kls lsi pen oal nif tse dns ara aht beh hma nik rok npj iwt ohz low1.0
0.81%
0.8
0.70%
0.66%
0.6
0.50%
0.4
0.2
0.0
xP3 Aya Collection Aya Collection Aya Original
(Templates) (Translations) Annotations
Figure 16: Average approval ratio per dataset group, constrained to datasets receiving at least 20
votes.
6 Aya Evaluation Suite
Lastly, as part of the Aya project we curate and release an evaluation suite tailored for multilingual
models. This set is a valuable contribution in tackling the scarcity of multilingual data, a challenge
that becomes even more apparent when considering evaluation sets. While there are several test
sets available for evaluating multilingual models [Conneau et al., 2018; Ponti et al., 2020; Lin et al.,
2022], they focus primarily on discriminative tasks. To evaluate multilingual models‚Äô generations,
theliteratureincludestask-specificevaluationsetssuchasTranslation[Goyaletal.,2021b],Summa-
rization [Hasan et al., 2021] and Question Answering [Clark et al., 2020]. However there is currently
a gap in evaluating open-ended generation capabilities of LLMs within a multilingual context. We
aim to address this gap by curating a multilingual evaluation set tailored for assessing the open-
ended generation capabilities of LLMs, such as brainstorming, planning, and other unstructured,
long-form responses.
Tostrikeabalancebetweenlanguagecoverageandthequalitythatcomeswithhumanattention, we
create an evaluation suite that includes (1) human-curated examples in a limited set of languages,
(2) automatically translations of handpicked examples into a more extensive number of languages,
and(3)human-post-editedtranslationsintoasmallnumberoflanguages. Weconsidertwoprimary
sourcesofdata: originalannotationsfromAyadataset(comprisingnewexamplesculturallycurated
fordifferentlanguages)andDollyprompts(high-quality, human-writtenexamplescarefullyselected
to have a universal reach). The subsets comprising the Aya evaluation suite are:
aya-human-annotated
test set For ease of future adoption, we have partitioned the Aya
dataset into training and testing splits. The test set of the Aya Dataset contains 1,750 of the
total instances (250 instances from 7 languages), selected at random from original annotations. Our
goal is to achieve a balanced representation of languages in the test set and ensure a sufficient
number of examples per language. To guarantee enough data remains for training, we focused
on languages with at least 2000 original annotations. In order to ensure linguistic diversity, we
includedlanguagesthatwerevariedintermsofhigh,mid,orlow-resourcedness,aswellasscriptand
language families. For those reasons, the test set consists of English (high-resource, Latin script,
Indo-European), Portuguese (mid-resource, Latin script, Indo-European), Simplified Chinese
22
oitaR
lavorppA
egarevA(high-resource, Han, Sino-Tibetan), Standard Arabic (high-resource, Arabic script, Afro-Asiatic),
Telugu (low-resource, Telugu script, Dravidian), Turkish (mid-resource, Latin script, Turkic), and
Yoruba (low-resource, Latin script, Atlantic-Congo). See Table 5 for more details.
dolly-machine-translated
testset Weseparateacuratedsubsetof200Dollyprompts[Conover
et al., 2023] to serve as an additional translated evaluation set. Our aim with this selection was to
exclude any culturally or geographically specific prompts and completions. Hence, two reviewers
inspectedasetofinitially500Englishpromptsthatwereuniformlysampledbasedonthetaskcate-
goriesinDolly. Thereviewersexcludedpromptsthatrelyongeographicknowledgesuchas‚ÄúLooking
at cities in Australia that are on the east coast and the west coast of the country, which coast are
the cities of Fremantle, Sydney, Brisbane, Perth, Cairns, Townsville, Newcastle located on?‚Äù, or
prompts such as ‚ÄúWhy is NFL football called football when players use their hands mainly?‚Äù that
relyon overly specific cultural references. When two reviewersdisagreed, athird reviewerwasasked
to break the tie. We kept prompts such as ‚ÄúIs art useless?‚Äù or ‚ÄúWrite a short paragraph about why
you should not have both a pet cat and a pet bird.‚Äù and questions that refer to geographic specific
knowledge where the supporting evidence was provided in the prompt itself e.g., ‚ÄúGiven a reference
text about Minister for Food, Agriculture and Fisheries of Denmark, when was the position created
and was was it named?‚Äù. Although not perfect, the intention behind this selection was to gather a
test set that allows us to evaluate the fluency and quality of responses in various languages while
avoiding model assessment on prompts tied to specific cultural or geographic references that might
have language-dependent validity. We automatically translate the prompts with NLLB into 101
languages and their dialects that are captured by NLLB. Including the original English prompts
this dataset covers 115 dialects.
dolly-human-edited
test set The automatic translation process may introduce errors in the
prompts that render them nonsensical. For example, the prompt ‚ÄúWhich is a species of fish? Bleak
or Weary‚Äù requires domain expertise to choose the right translation of the fish names rather than
literal translations of the adjectives (as e.g. in the NLLB Translation into Spanish: ‚ÄúDesanimado
o cansado.‚Äù (=‚Äúdiscouraged or tired‚Äù)). If the prompt does not make any sense, there is no clear
expectationandmeasurementofwhatagoodandcorrectcompletionshouldlooklike. Toconfidently
interpret evaluation results, it is imperative to establish a reliable set of prompts for evaluation. To
enhancethereliabilityoftestingontheseprompts,wethereforeenlistprofessionalhumanannotators
to post-edit the examples (e.g. for the example above ‚ÄúAlburno o Cansado‚Äù (=‚Äú[Fish name] or
Tired‚Äù). We post-edit the prompts for a subset of six languages: Arabic, Hindi, Spanish, French,
SerbianandRussian. AppendixFdescribesthepost-editingprocessandeffortinmoredetail. The
exampleaboveillustratesthatsomeprompts,evenwhentranslatedcorrectly,mightstillnottransfer
well into other languages‚Äîwhich is the main difference between a translated English-centric set like
aya-human-annotated
this and an evaluation set originally written in each target language like .
dolly-machine-translated
We open-source the test set to be an additional resource for
researchers, although warn that the expressiveness of a translated evaluation set is limited by the
quality of the translation model (and human post-edit) and may adversely impact an estimate of
ability in languages where translations are not adequate [Nogara et al., 2023]. Ultimately, this
is a compromise between having evaluation coverage in a more complete set of languages (101
languages and 114 dialects in total) versus having human-annotated evaluation sets. If using the
automatically translated test set, we recommend it be paired and reported with the
dolly-human-edited aya-human-
professionally post-edited for 6 languages, or the
annotated
set which also only covers 7 languages but is entirely created by proficient
23target language speakers.
7 A Participatory Approach to Research
Recent breakthroughs in NLP have predominantly come from narrow collaborations that involve
researchers from a handful of institutions and regions of the world [Nakamura et al., 2023]. This
reliance on small, specialized collaboration networks has been shown to hinder innovation [Park
et al., 2023]. Dataset creation as a process has often been undervalued, with minimization of the
value of creators‚Äô contributions [Andress et al., 2020; Peng et al., 2021; Hanley et al., 2020]. Under
such conditions, the richness and diversity of the data are often compromised, as it reflects a limited
perspective that aligns with the interests of those who wield greater power in these transactions.
Data is not, as metaphors such as ‚Äòdata mining‚Äô [Puschmann & Burgess, 2014], or ‚Äòdata is the new
oil‚Äô [Stark & Hoffmann, 2019; Awati & Shum, 2015], might suggest, a natural resource waiting to
be exploited. Whenever we engage with data, we are also engaging with the connections that data
has to the people who produce, prepare, and distribute it [Seaver, 2021; Pinel C, 2020; Crawford,
2021]. Participatory approaches in AI design and research are one way to address gaps in access to
resources needed for research: through collaborative partnerships with language speakers and local
communities.
Aya is an example of a participatory research project [Birhane et al., 2022; Corbett et al., 2023;
Delgado et al., 2023]. Here, the research is the result of a broad cross-institutional, global col-
laboration. This type of cross-sectional work facilitates the collection of vital linguistic data and
community engagement, which is crucial for developing effective language technologies [Joshi et al.,
2019; ‚àÄ et al., 2020]. We describe below some of the guiding principles we followed throughout the
year-long Aya project.
Fluid Ownership and Growth Ouropenscienceframeworkallowedustochallengethenormsof
how computer science usually proceeds [Wittenburg, 2021; Sabou et al., 2012]. Traditional research
approaches often involve rigid hierarchies; typically, research is conducted within academic insti-
tutions or corporate labs where roles are clearly defined, and collaboration is mostly synchronous,
relying on in-person meetings or real-time communication. In contrast, Aya took a decentralized
and democratic approach to collaboration, supporting fluid leadership and flexible role adoption.
This empowered members to take initiative and lead in areas where they had passion or expertise,
regardless of their position in academia, or when they became involved in the project. For example,
membersbecameLanguage Ambassadorsat many differentpoints during theyear-longproject, and
mentorship roles evolved naturally with more experienced researchers providing guidance to those
more junior (see Appendix C for more details of different roles in the project).
Organizational Structure The communication channels and organizational structure of Aya
were designed to facilitate rich collaboration that could evolve with the interests of participating
researchers over the year-long project. For example, most communication between independent re-
searchersinvolvedwithinAyawasasynchronousoverDiscord,whichallowedresearchersindifferent
timezonestoparticipateindiscussions. Monthlymeetingswereopenforanyonetoattendandwere
recorded for asynchronous viewing. We describe the structure of meetings and communication more
thoroughly in Appendix D.1 and D.2.
Inclusion and Access The open nature of the Aya UI allowed us to bypass the gate-keeping
24mechanisms of academic science that often marginalize non-English speakers and people without
formal academic credentials [West et al., 2020]. Expertise in the command of a spoken or written
languageisclearlydistinctfromexpertiseinmachinelearning. Theinclusionofsuchawiderangeof
volunteers gave us more representative data in a wide variety of languages and also gave volunteers
a glimpse into the often obscure world of machine learning.
Who Participated in Aya The motivations of contributors were not based on financial remu-
neration but on ideals of community, identity, and social justice. Participants saw their roles as
Language Ambassadors and contributors as crucial to ensuring the inclusion of their languages in
the ongoing transition to a digital, information-driven economy. The Language Ambassador for
Malagasy, a language-driven to the risk of extinction by colonial French rule in Madagascar [Spol-
sky, 2018], is planning hackathons in 2024 to use the Aya Dataset to create voice-to-text apps that
will help non-literate speakers of Malagasy participate in the modern economy. In Telugu, a tradi-
tional genre of poetry known as Sathakam is an integral part of the educational system. However,
chatbots that can translate text into Telugu have little to no understanding of the Sathakam form.
The Telugu Language Ambassador told a newspaper in Toronto that ‚Äúin Aya, we made sure to
include as many Sathakams as we could find‚Äù [Castaldo, 2023].
These motivations are not peripheral to the strength of the final Aya Dataset but are key factors in
the data‚Äôs provenance [Loukissas, 2019]. These qualitative dimensions remind us that language is,
forthepeoplewhouseiteveryday,anintimatelysocialphenomenon. Beyondthesymbolicnotation
that connects tokens to referents in the real world, we find a robust network of social relations that
are necessary for languages to flourish [Sidnell & Enfield, 2012; Goodwin, 2017; Agha, 2006]. The
social interactions between contributors, ML researchers, and social scientists in the Aya project
were crucial to its success. Contributors shared playlists of their favorite songs from their home
country, recipes from their childhood, and snapshots of the views from their home offices. They
debated subtle nuances of how they wanted their language represented in the dataset and pushed
back on some of the assumptions made by project coordinators on what constituted a distinct
language as opposed to a regional dialect (see Section 9). More than one contributor sat down with
their grandparents to contribute to a language that spanned three generations of use.
The realities of the conditions under which many people work and live were present every day.
For example, Zoom meetings were cut short for some volunteers due to power outages in their
countries or lack of access to a stable internet connection. Burmese, a language spoken in Myanmar,
started out strong in the project with a group of 35 motivated volunteers but saw a sudden pause
in contributions as civil war broke out in the country resulting in the withdrawal of the volunteers
from the project [Petty, 2023]. The Language Ambassador for Armenian also had to drop out of
the project because of a conflict in that country [Reuters, 2023]. In some countries, postal services
only functioned a few days per month because of ongoing warfare, creating challenges for organizers
when mailing out Aya gifts to thank committed volunteers. Ultimately, organizers were not able to
send gifts to thank volunteers who participated from Somalia, Yemen and Palestine. For Somalia
andYemen,bothCanadaPost,DHLandFedexwherenotabletosupportshipments. ForPalestine,
the cost of shipment proved to be prohibitively expensive ‚Äì with an estimated shipping cost of 294
US dollars per t-shirt. These geo-political realities shaped both our contributors‚Äô experience as well
as the progress of the project.
Including these factors in our post-mortem analysis of the project is crucial to understanding both
the motivation of people willing to volunteer for open-science projects, and also to understanding
25the data itself: its breadth, its provenance, its shortcomings, and its living history.
ISOCode Language Script Family Subgrouping Resources Included
ace Achinese Arabic/Latin Austronesian Malayo-Polynesian Low ‚ô§‚ô†
afr Afrikaans Latin Indo-European Germanic Mid ‚ô§‚ô†
amh Amharic Ge‚Äôez Afro-Asiatic Semitic Low ‚ô¶‚ô¢‚ô§‚ô†
ara Arabic Arabic Afro-Asiatic Semitic High ‚ô¶‚ô¢‚ô§‚ô†
aze Azerbaijani Arabic/Latin Turkic CommonTurkic Low ‚ô§‚ô†
ban Balinese Latin Austronesian Malayo-Polynesian Low ‚ô§‚ô†
bbc TobaBatak Latin Austronesian Malayo-Polynesian Low ‚ô§‚ô†
bel Belarusian Cyrillic Indo-European Balto-Slavic Mid ‚ô§‚ô†
bem Bemba Latin Niger-Congo Atlantic-Congo Low ‚ô§‚ô†
ben Bengali Bengali Indo-European Indo-Aryan Mid ‚ô¶‚ô¢‚ô§‚ô†
bjn Banjar Arabic/Latin Austronesian Malayo-Polynesian Low ‚ô§‚ô†
bul Bulgarian Cyrillic Indo-European Balto-Slavic Mid ‚ô§‚ô†
cat Catalan Latin Indo-European Italic High ‚ô§‚ô†
ceb Cebuano Latin Austronesian Malayo-Polynesian Mid ‚ô¶‚ô¢‚ô§‚ô†
ces Czech Latin Indo-European Balto-Slavic High ‚ô§‚ô†
cym Welsh Latin Indo-European Celtic Low ‚ô§‚ô†
dan Danish Latin Indo-European Germanic Mid ‚ô¶‚ô¢‚ô§‚ô†
deu German Latin Indo-European Germanic High ‚ô¶‚ô¢‚ô§‚ô†
ell Greek Greek Indo-European Graeco-Phrygian Mid ‚ô¶‚ô¢‚ô§‚ô†
eng English Latin Indo-European Germanic High ‚ô¶‚ô¢‚ô§‚ô†
epo Esperanto Latin Constructed Esperantic Low ‚ô§‚ô†
est Estonian Latin Uralic Finnic Med ‚ô§‚ô†
eus Basque Latin Basque - High ‚ô¶‚ô¢‚ô§‚ô†
fil Filipino Latin Austronesian Malayo-Polynesian Mid ‚ô¶‚ô¢‚ô§‚ô†
fin Finnish Latin Uralic Finnic Mid ‚ô¶‚ô¢‚ô§‚ô†
fon Fon Latin Niger-Congo Atlantic-Congo Low ‚ô§‚ô†
fra French Latin Indo-European Italic High ‚ô¶‚ô¢‚ô§‚ô†
gla ScottishGaelic Latin Indo-European Celtic Low ‚ô§‚ô†
gle Irish Latin Indo-European Celtic Low ‚ô¶‚ô¢‚ô§‚ô†
glg Galician Latin Indo-European Italic Med ‚ô§‚ô†
guj Gujarati Gujarati Indo-European Indo-Aryan Low ‚ô¶‚ô¢‚ô§‚ô†
hat HaitianCreole Latin Indo-European Italic Low ‚ô¶‚ô¢‚ô§‚ô†
hau Hausa Latin Afro-Asiatic Chadic Low ‚ô¶‚ô¢‚ô§‚ô†
heb Hebrew Hebrew Afro-Asiatic Semitic Mid ‚ô§‚ô†
hin Hindi Devanagari Indo-European Indo-Aryan High ‚ô¶‚ô¢‚ô§‚ô†
hrv Croatian Latin Indo-European Balto-Slavic. High ‚ô§‚ô†
hun Hungarian Latin Uralic - High ‚ô¶‚ô¢‚ô§‚ô†
hye Armenian Armenian Indo-European Armenic Low ‚ô§‚ô†
ibo Igbo Latin Atlantic-Congo Benue-Congo Low ‚ô¶‚ô¢‚ô§‚ô†
ind Indonesian Latin Austronesian Malayo-Polynesian Mid ‚ô¶‚ô¢‚ô§‚ô†
isl Icelandic Latin Indo-European Germanic Low ‚ô§‚ô†
ita Italian Latin Indo-European Italic High ‚ô¶‚ô¢‚ô§‚ô†
jav Javanese Latin Austronesian Malayo-Polynesian Low ‚ô¶‚ô¢‚ô§‚ô†
jpn Japanese Japanese Japonic Japanesic High ‚ô¶‚ô¢‚ô§‚ô†
kan Kannada Kannada Dravidian SouthDravidian Low ‚ô¶‚ô¢‚ô§‚ô†
kas Kashmiri Arabic Indo-European Indo-Aryan Low ‚ô§‚ô†
kat Georgian Georgian Kartvelian Georgian-Zan Mid ‚ô§‚ô†
kau Kanuri Arabic/Latin Saharan WesternSaharan Low ‚ô§‚ô†
kaz Kazakh Cyrillic Turkic CommonTurkic Mid ‚ô§‚ô†
khm Khmer Khmer Austroasiatic Khmeric Low ‚ô§‚ô†
kin Kinyarwanda Latin Niger-Congo Atlantic-Congo Low ‚ô§‚ô†
kir Kyrgyz Cyrillic Turkic CommonTurkic Low ‚ô¶‚ô¢‚ô§‚ô†
kor Korean Hangul Koreanic Korean Mid ‚ô¶‚ô¢‚ô§‚ô†
kur Kurdish Latin Indo-European Iranian Low ‚ô¶‚ô¢‚ô§‚ô†
lao Lao Lao Tai-Kadai Kam-Tai Low ‚ô§‚ô†
lav Latvian Latin Indo-European Balto-Slavic Mid ‚ô§‚ô†
lij Ligurian Latin Indo-European Italic Low ‚ô§‚ô†
lit Lithuanian Latin Indo-European Balto-Slavic Mid ‚ô¶‚ô¢‚ô§‚ô†
ltz Luxembourgish Latin Indo-European Germanic Low ‚ô§‚ô†
mad Madurese Latin Austronesian Malayo-Polynesian Low ‚ô§‚ô†
mal Malayalam Malayalam Dravidian SouthDravidian Low ‚ô¶‚ô¢‚ô§‚ô†
man Manipuri Bengali Sino-Tibetan Kuki-Chin-Naga Low ‚ô§‚ô†
26mar Marathi Devanagari Indo-European Indo-Aryan Low ‚ô¶‚ô¢‚ô§‚ô†
min Minangkabau Latin Austronesian Malayo-Polynesian Low ‚ô§‚ô†
mkd Macedonian Cyrillic Indo-European Balto-Slavic Low ‚ô§‚ô†
mlg Malagasy Latin Austronesian Malayo-Polynesian Low ‚ô¶‚ô¢‚ô§‚ô†
mlt Maltese Latin Afro-Asiatic Semitic Low ‚ô§‚ô†
mon Mongolian Cyrillic Mongolic-Khitan Mongolic Low ‚ô§‚ô†
mri Maori Latin Austronesian Malayo-Polynesian Low ‚ô§‚ô†
msa Malay Latin Austronesian Malayo-Polynesian Mid ‚ô¶‚ô¢‚ô§‚ô†
mya Burmese Myanmar Sino-Tibetan Burmo-Qiangic Low ‚ô¶‚ô¢‚ô§‚ô†
nep Nepali Devanagari Indo-European Indo-Aryan Low ‚ô¶‚ô¢‚ô§‚ô†
nij Ngaju Latin Austronesian Malayo-Polynesian Low ‚ô§‚ô†
nld Dutch Latin Indo-European Germanic High ‚ô¶‚ô¢‚ô§‚ô†
nor Norwegian Latin Indo-European Germanic Low ‚ô§‚ô†
nso NorthernSotho Latin Atlantic-Congo Benue-Congo Low ‚ô¶‚ô¢‚ô§‚ô†
nya Chichewa Latin Atlantic-Congo Benue-Congo Low ‚ô¶‚ô¢
pan Punjabi Gurmukhi Indo-European Indo-Aryan Low ‚ô¶‚ô¢‚ô§‚ô†
pes Persian Arabic Indo-European Iranian High ‚ô¶‚ô¢‚ô§‚ô†
pol Polish Latin Indo-European Balto-Slavic High ‚ô¶‚ô¢‚ô§‚ô†
por Portuguese Latin Indo-European Italic High ‚ô¶‚ô¢‚ô§‚ô†
pus Pashto Arabic Indo-European Iranian Low ‚ô¶‚ô¢‚ô§‚ô†
ron Romanian Latin Indo-European Italic Mid ‚ô§‚ô†
rus Russian Cyrillic Indo-European Balto-Slavic High ‚ô¶‚ô¢‚ô§‚ô†
sin Sinhala Sinhala Indo-European Indo-Aryan Low ‚ô¶‚ô¢‚ô§‚ô†
slk Slovak Latin Indo-European Balto-Slavic Mid ‚ô§‚ô†
slv Slovenian Latin Indo-European Balto-Slavic Mid ‚ô§‚ô†
smo Samoan Latin Austronesian Malayo-Polynesian Low ‚ô§‚ô†
sna Shona Latin Indo-European Indo-Aryan Low ‚ô¶‚ô¢‚ô§‚ô†
snd Sindhi Arabic Indo-European Indo-Aryan Low ‚ô¶‚ô¢‚ô§‚ô†
som Somali Latin Afro-Asiatic Cushitic Low ‚ô¶‚ô¢‚ô§‚ô†
sot SouthernSotho Latin Atlantic-Congo Benue-Congo Low ‚ô§‚ô†
spa Spanish Latin Indo-European Italic High ‚ô¶‚ô¢‚ô§‚ô†
sqi Albanian Latin Indo-European Albanian Low ‚ô¶‚ô¢‚ô§‚ô†
srp Serbian Cyrillic Indo-European Balto-Slavic High ‚ô¶‚ô¢‚ô§‚ô†
sun Sundanese Latin Austronesian Malayo-Polynesian Low ‚ô¶‚ô¢‚ô§‚ô†
swa Swahili Latin Atlantic-Congo Benue-Congo Low ‚ô¶‚ô¢‚ô§‚ô†
swe Swedish Latin Indo-European Germanic High ‚ô¶‚ô¢‚ô§‚ô†
tam Tamil Tamil Dravidian SouthDravidian Mid ‚ô¶‚ô¢‚ô§‚ô†
taq Tamasheq Latin/Tifinagh Afro-Asiatic Berber Low ‚ô§‚ô†
tel Telugu Telugu Dravidian SouthDravidian Low ‚ô¶‚ô¢‚ô§‚ô†
tgk Tajik Cyrillic Indo-European Iranian Low ‚ô§‚ô†
tha Thai Thai Tai-Kadai Kam-Tai Mid ‚ô¶‚ô¢‚ô§‚ô†
tur Turkish Latin Turkic CommonTurkic High ‚ô¶‚ô¢‚ô§‚ô†
twi Twi Latin Niger-Congo Atlantic-Congo Low ‚ô§‚ô†
ukr Ukrainian Cyrillic Indo-European Balto-Slavic Mid ‚ô¶‚ô¢‚ô§‚ô†
urd Urdu Arabic Indo-European Indo-Aryan Mid ‚ô¶‚ô¢‚ô§‚ô†
uzb Uzbek Latin Turkic CommonTurkic Med ‚ô§‚ô†
vie Vietnamese Latin Austroasiatic Vietic High ‚ô¶‚ô¢‚ô§‚ô†
wol Wolof Latin Atlantic-Congo North-CentralAtlantic Low ‚ô¶‚ô¢‚ô§‚ô†
xho Xhosa Latin Atlantic-Congo Benue-Congo Low ‚ô¶‚ô¢‚ô§‚ô†
yid Yiddish Hebrew Indo-European Germanic Low ‚ô§‚ô†
yor Yor√πb√° Latin Atlantic-Congo Benue-Congo Low ‚ô¶‚ô¢‚ô§‚ô†
zho Chinese Han Sino-Tibetan Sinitic High ‚ô¶‚ô¢‚ô§‚ô†
zul Zulu Latin Atlantic-Congo Benue-Congo Low ‚ô¶‚ô¢‚ô§‚ô†
Table 5: 65 languages in the Aya Dataset and 114 languages in the Aya Collection, each language‚Äôs
corresponding script, family, subgrouping, and if it is classified as ‚Äúlower-‚Äù, ‚Äúmid-‚Äù or ‚Äúhigher‚Äù-
resourced according to the taxonomy classes by [Joshi et al., 2020] (low: [0, 1, 2], mid: [3], high: [4,
5]). The language is either included in the Aya Dataset
(‚ô¶‚ô¢
), Aya Collection
(‚ô§‚ô†),
or both. Note
that Ngaju (nij) and Toba Batak (bbc) are not listed in [Joshi et al., 2020].
278 Related Work
8.1 Multilingual datasets
Low-resource languages have long been a challenge in NLP, with limited data impacting task per-
formance [Kunchukuttan et al., 2021]. To address this, researchers have explored techniques like
data augmentation [Sennrich et al., 2016; Dhole et al., 2021], transfer learning [Zoph et al., 2016],
repeating[Luukkonenetal.,2023;Muennighoffetal.,2023b], andmultilingualmodels[Dabreetal.,
2020;Muennighoffetal.,2023c;Yongetal.,2023b],achievingpromisingresultsinareaslikemachine
translation. Here, we focus on efforts that are centered on multilingual dataset creation.
Several works have created large-scale multilingual corpora. These are often unstructured texts,
ideal for large-scale unsupervised pre-training [Abadji et al., 2021; Ortiz Su‚Äôarez et al., 2019; Scao
et al., 2022a;b; Lauren√ßon et al., 2022; Kudugunta et al., 2023; Whitehouse et al., 2023]. Another
group of multilingual datasets is focused on machine translation [Lucia Specia et al., 2010; Fan
et al., 2021]. They consist of parallel texts in two or more languages, enabling models to learn
the mappings between them. Ideally, machine translation datasets encompass diverse domains and
language pairs, from commonly spoken languages to resource-scarce ones, promoting inclusivity
and linguistic diversity. One of the most extensive collections of parallel corpora is available at
the OPUS project website14 [Tiedemann, 2012]. Large capacity models for language understanding
may obtain strong performance on high-resource languages while greatly improving low-resource
languages [Goyal et al., 2021a]. In Whitehouse et al. [2023], the effectiveness of LLM-powered data
augmentationincross-lingualcommonsensereasoningwasdemonstrated. Animprovedperformance
was shown when smaller cross-lingual models were finetuned with data generated by LLMs. Some
recently released datasets focus on specialized language domains such as law [Niklaus et al., 2023],
education [Zhang et al., 2023c], or healthcare [Wang et al., 2023].
These corpora often suffer from inadequate data quality and require extensive cleaning [Abadji
et al., 2022; Kreutzer et al., 2022]. Task-specific datasets, such as XCOPA [Ponti et al., 2020] or
XNLI [Conneau et al., 2018], are smaller in scale but offer higher quality data targeted at a specific
model capability such as cross-lingual understanding and transfer learning. This type of data is
crucial for evaluating and enhancing the performance of models in diverse linguistic contexts.
No Language Left Behind [NLLB-Team et al., 2022] open-sourced bitext, mined bitext, and data
generated using back-translation in 200+ languages specifically for text-to-text translation. While
Seamless4MT [Barrault et al., 2023] released the metadata of SeamlessAlign, an open multimodal
translation dataset, there are relatively fewer works for data creation/curation in low-resource lan-
guages. Cahyawijaya et al. [2023] introduced NusaCrowd, a standardized collection of 137 datasets
covering 19 Indonesian local languages in text, speech, and image modalities. Our work differs
from previous datasets as we create a large-scale instruction-tuning dataset spanning hundreds of
different tasks, yet retain high-quality by involving human annotation and rigorous quality control
across the entire data creation process.
14https://opus.nlpl.eu
288.2 Instruction-tuning datasets
Instruction-tuning datasets are collections of human-curated instructions and response pairs, tem-
platized NLP tasks, or synthetic instructions generated by a language model. There are a growing
number of NLP meta-datasets such as Natural instructions [Mishra et al., 2022], SuperNatural In-
structions[Wang et al., 2022d], Flan 2021 [Wei et al., 2022a], Flan 2022 [Longpre et al., 2023a],
Public Pool of Prompts (P3) [Sanh et al., 2022], Unnatural Instructions [Honovich et al., 2023],
OPT-IML [Iyer et al., 2022], inter alia [Khashabi et al., 2020; Ye et al., 2021; Min et al., 2021]
that collate numerous instruction finetuned datasets together. Some work focuses on specific ap-
plications such as dialogue [K√∂pf et al., 2023], structured knowledge grounding [Xie et al., 2022],
or chain-of-thought reasoning [Wei et al., 2022b; Kim et al., 2023]. Manual efforts include Open
Assistant [K√∂pf et al., 2023] crowd-sourcing volunteers who wrote both instructions and responses,
Databricks employees creating 15k examples in Dolly [Conover et al., 2023], and LIMA [Zhou et al.,
2023] which is a collection of 1,000 author-curated IFT examples.
Syntheticinstruction-tuningdatasetscompriseinstructionssampledfromalanguagemodel, suchas
the Self-Instruct dataset [Wang et al., 2022b] generated by GPT-3 [Brown et al., 2020], the Alpaca
dataset [Taori et al., 2023] generated by GPT-3.5, and the Guanaco dataset [Joseph Cheung, 2023].
Increasingly, the synthetic generation of instruction-finetuned datasets is more sophisticated. [Xu
et al., 2023a] propose a novel Evol-Instruct framework to obtain complex and difficult instructions
gradually. [Luo et al., 2023] and [Gunasekar et al., 2023] further expand this idea to promote
reasoning,codegeneration,andalgorithmicskills. InstructionWild[Nietal.,2023]andShareGPT15
are collections of user-shared conversations with ChatGPT.
8.3 Multilingual Instruction-Tuning Datasets
Despite ever-larger collections of IFT datasets, prior work has been largely English-centric. Most
approaches to extend instruction finetuned datasets outside of English have relied on 1) translating
English datasets into other languages [Holmstr√∂m & Doostmohammadi, 2023; Li et al., 2023a;
Winata et al., 2023b], 2) template based dataset creation [Yu et al., 2023; Gupta et al., 2023] or 3)
human curating instruction datasets in languages outside of English [Muennighoff et al., 2023c; Li
etal.,2023c;Wangetal.,2022c]. Therehavebeensomenotableexceptionswithlargeproportionsof
non-English data [Joseph Cheung, 2023; K√∂pf et al., 2023; Lai et al., 2023; Li et al., 2023a; Longpre
et al., 2023a; Muennighoff et al., 2023a;c; Zhuo et al., 2024; Nguyen et al., 2023].
Template-Based Datasets. Themostrelevanteffortisrecentworkby[Muennighoffetal.,2023c]
releasing Crosslingual Public Pool of Prompts (xP3). xP3 expands the P3 taxonomy and adds
28 new multilingual datasets. However, their datasets usually use the same template in different
languages, thuslimitingtaskdiversity. Forexample, arandombatchfromtheirdatasetmayinclude
the same sample in different languages multiple times. Their xP3 corpus has task instructions
exclusively in English. In [Muennighoff et al., 2023c], the experiments with matching the task
instructiontotherespectivelanguageofthesampleviamachinetranslation(xP3mt)showedslightly
improvedperformancefornon-Englishtaskinstructionsatinference. Ourworkisdistinctinthatour
human-curated constructed dataset is unique for each of the 65 languages. Such diversity has been
emphasized as a key ingredient for instruction tuning [Longpre et al., 2023a]. Further, we create
non-English task instructions via human annotators, ensuring these are of high-quality, which is
15https://sharegpt.com/
29another pillar of a good performance [Zhou et al., 2023].
Machine Translated Datasets. Machine-translated prompts often lack variability and the cul-
tural nuance inherent in natively written text. However, they are still useful for expanding the
language coverage of the training data and can help bridge the resource gap for languages with
limited training data [Urbizu et al., 2023; Lin et al., 2022]. They can also adapt already-trained
instruction-tuned language models to follow instructions in new languages [Yong et al., 2023b].
Furthermore, LLMs trained on designed prompts have also been shown to be successful at tasks
like EAE (Event Argument Extraction) from multilingual data in a zero-shot setup [Huang et al.,
2022]. [Zhang et al., 2023a] constructed high-quality Chinese instructions from existing English
instruction datasets. They first translated the English instructions into Chinese and then used a
human verification process to determine whether these translations were usable; the verified dataset
set consists of around 200k Chinese instruction-tuning samples. [Li et al., 2023a] constructed in-
struction data for 52 popular languages using Google Translate to translate English prompts and
completions from Alpaca [Taori et al., 2023] (52K) and Dolly [Conover et al., 2023] (15K) dataset,
then used this data to finetune LLaMA [Touvron et al., 2023] using the LoRA [Hu et al., 2021]
technology. [Zhang et al., 2023b] prompted LLMs to translate a task request, which was overlaid
with the more granular user-based corrects. This process naturally connects different languages as
well as human preferences with LLMs, leveraging LLaMA [Touvron et al., 2023] for foundational
support and employing automatic construction of interactive translation instructions for instruc-
tional tuning, thereby enhancing the model‚Äôs multilingual capability and alignment with diverse
linguistic needs.
Human-Curated Multilingual Examples. Most relevant to our work on the Aya dataset are
other datasets that have been curated by humans, often in English. Databricks collected a 15k
instruction dataset databricks-dolly-15k by relying on its employees as annotators [Conover
et al., 2023]. Annotators were instructed to curate prompt / response pairs in each of eight different
instruction categories. [K√∂pf et al., 2023] released the OpenAssistant corpus with over 10,000
dialogues from more than 13,500 international annotators. While this dataset contains multilingual
annotations, this was not an explicit goal of the initiative. In contrast to our corpus which only has
2.05% contributions in English, 42.8% of the OpenAssistant project remains in English [K√∂pf et al.,
2023].
8.4 Participatory Research in Machine Learning
If you want to go fast go alone; if you want to go far, go together. ‚Äî African Proverb
Priorparticipatoryresearchinitiativeshavecenteredaroundregionsorspecifictasksliketranslation
or character recognition. For example, [Clanuwat et al., 2018] tackles the problem of reading and
understanding Kuzushiji, a cursive style of Japanese writing no longer in common use. Another
example of culturally diverse data collection is [Liu et al., 2021], which recruited native speakers
from five languages (Indonesian, Swahili, Tamil, Turkish, and Mandarin Chinese) that are
typologically, genealogically, and geographically diverse, to provide images of concepts that are
representative of their cultures. Then, they recruited native-speaking professional linguists to write
captions for these images. However, this dataset is small (less than 8,000 data points) and thus
limited to evaluation only. It is worth noting that these works are solely focused on the image
domain, unlike our work, which concentrates on text.
30More relevant to our work are participatory data creation initiatives focused on NLP. [Guevara-
Rukoz et al., 2020] presents a study focusing on the creation of a crowd-sourced corpus for Latin
American Spanish dialects to address the scarcity of resources for these languages. [‚àÄ et al., 2020]
focuses on the task of Machine Translation (MT), and curates a dataset in 30 under-represented
African languages according to a participatory research framework. Our work is very much in
the spirit of these prior efforts, with differences in terms of global rather than regional focus. In
contrast to these works, which have a specific regional focus, Aya collaborators came from multiple
continents covering a diverse range of languages.
Several works have explored the organizational structures required to facilitate the development
of research communities around under-represented languages. [Siminyu et al., 2021] details work
on the AI4D - African Language Program, which aimed to enhance language resources for African
languages. The outcome included creating over nine open-source African language datasets and
establishing baseline models, demonstrating the program‚Äôs significant impact on language tech-
nology for African languages. [Azunre et al., 2021] describes the establishment of NLP Ghana,
with its collaborative open-source community. [Strassel & Tracey, 2016] discusses the challenges
of developing resources for low-resource languages under the LORELEI (Low Resource Languages
for Emergent Incidents) program. They focus on the pressing need for digital resources in these
languages, particularly in critical situations such as mitigating the effects of natural disasters.
Open science community initiatives like Aya yield significant advancements in language modeling.
Related efforts (in terms of compute and resources required) can be found in the BigScience Work-
shop [Akiki et al., 2022], which began in 2021. The BigScience project was initiated to address the
limitations in LLM development, emphasizing open science and inclusive collaboration. Leveraging
open science principles, it united a global network of researchers working to collaboratively and
ethically enhance machine learning. Their work culminated in key developments like the BLOOM
model [Scao et al., 2022a] and ROOTS corpus [Lauren√ßon et al., 2022]. These achievements under-
score the value of community-driven, ethical, and diverse research programs for large-scale language
technologies. FollowingBigScience, therehavebeenotherrecenteffortsonopenscienceinlanguage
modeling [Groeneveld et al., 2024; Soldaini et al., 2024].
9 Limitations of our work
1. Language and dialect coverage: The Aya Dataset and Aya Collection cover 65 and 114
languages respectively‚Äîsignificantly more than existing multilingual datasets. However, this
is still only a tiny fraction of the world‚Äôs linguistic diversity. Of the world‚Äôs approximately
7,000 languages, only half of them are captured in any sort of written form [Adda et al., 2016].
Of this half, only a few hundred are included on the internet in machine readable corpora
[Adda et al., 2016]. This means that 93% of the world‚Äôs languages are still not being used
to train LLMs. It is also notoriously difficult to determine the dividing line between different
languages and different dialects of the same language [Rooy, 2021]. Geo-cultural variation
within a language often gives rise to new dialects or creoles over time [Zampieri et al., 2020;
Wolfram,1997;Brownetal.,2020;Lentetal.,2022;Blaschkeetal.,2023]and,assuch,dialects
can serve an important function in establishing and maintaining cultural identity [Falck et al.,
2012]. Many different dialects that are generally recognized as belonging to a single parent
language are not represented in the dataset. For example, in the case of Malay, one of
the largest Southeast Asian languages in the dataset, there are no contributions for regional
31dialects that are widely spoken in certain states of Malaysia. Contributions by volunteers who
wishedtoself-identifyasspeakingaparticulardialectweretaggedassuchinthedatatoallow
for limited analysis of the use of regional dialects in annotations. Lastly, socio-linguistic data
show that multilingual speakers often ‚Äòcode-switch‚Äô between languages or dialects depending
on context [Myers-Scotton, 2017], but in this project, we kept the languages isolated to make
them easier to classify and to be used downstream for language-specific applications. Aya
also does not cover programming languages. There has been prior work on covering diverse
programming languages [Li et al., 2023d; Allal et al., 2023] and we leave further explorations
in this direction to future work.
2. Uneven distribution of contributions: As explored in Section 3.3, despite the large num-
ber of participants, the activity of annotators was skewed, with a ‚Äòlong tail‚Äô of annotators
only contributing one or two annotations. Relatively few contributors accounted for the most
annotations (see Figure 10 - bottom). Similarly, there is a huge gap between languages with
thehighestnumberofcontributionsandoneswiththelowestnumberofcontributions. Conse-
quently, this suggests potential unevenness in dataset distributions across different languages
and a lack of annotator diversity within some languages dominated by one or two frequent
contributors.
3. Cultural or personal bias: Anotherlimitationisthepresenceofannotationswithparticular
cultural biases. Some languages in our dataset have limited representation, with only a few
annotators responsible for annotating the bulk of their dataset. This might mean that data
for a particular language is dominated by annotations that represent the opinions or priorities
of a particular contributor or could represent a narrow selection of cultural viewpoints. For
example, annotations in French might contain many examples about the history of France, its
food, songs, andotherculturalpractices, butnotcontainmuchinformationaboutthecultural
heritage of French-speaking communities in Qu√©bec, Togo, or Senegal [Vigouroux, 2013]. This
bias is particularly problematic given the skewed distribution of the most active annotators.
There is also a potential bias in the availability of particular kinds of content. For example, it
is easier to find online text from news sites for many African languages than it is to find text
from other domains. Accordingly, these datasets will be skewed towards the grammar and
lexicon used in news reports instead of the kind of natural language people use in everyday
life [Hovy & Prabhumoye, 2021].
4. Gendered pronouns: Many of the languages in the Aya Dataset only contain pronouns
that are explicitly gendered (e.g., Arabic) or that lack gender-neutral third-person pronouns
for gender-neutral reference (e.g. Estonian). This means that in responding to prompts that
might not specify a gender, care needs to be taken to ensure that responses remain neutral
as to the gender of any assumed participants [Ghosh & Caliskan, 2023]. For example, if a
response requires reference to ‚Äúa teacher‚Äù in French, the annotator would need to include
references to both ‚Äúun/e enseignant/e‚Äù. While care was taken to ensure neutral responses for
new annotations, gendered annotations in existing datasets might not have been flagged, as
they are not, strictly speaking, incorrect. Instead, they merely presuppose a gendered reading
where one might not be implied [Hardmeier & Guillou, 2018].
5. Formality distinctions: Many of the languages in the Aya Dataset also require the speaker
or annotator to make situational choices as to the formality of the pronoun used in response
to a particular prompt. Languages such as Japanese, Persian, Indonesian, Javanese,
Yoruba, French, Spanish, and German include different levels of honorifics that are used
32in formal or informal settings, or used between community members who differ in status
(determined by a variety of factors such as age, profession, seniority, or ethnicity) [Brown &
Gilman, 1968]. In Yoruba, for example, the pronoun that roughly translates as "they" can
either be used as a singular honorific or as a third-person plural pronoun [Yusuf, 2022]. We
deferred to the individual annotators in crafting their responses, allowing them to rely on
the norms of their particular speech community to determine how to respond. Often, these
decisions hinged on the content being discussed, or on how formally the prompt was crafted in
the original data set. When in doubt, annotators were asked to imagine what kind of ‚Äòvoice‚Äô
they would expect an LLM to have when answering a given prompt [Wilson, 2023].
This means our released dataset contains many languages that have varying levels of stan-
dardization and differing style guidelines. Standardization is often deeply intertwined with
power and identity, and the manner of speech may be connected to aspects of identity like
age, education level, tribal affiliation, and religion. The lack of standardization is also largely
due to regional and cultural differences across the same language, exemplified by Portuguese
in the dataset: European Portuguese diverges from Brazilian Portuguese not only in formality
but also in grammar, spelling, and vocabulary. Often, standards are projected by others to
ensure adherence to cultural values [Bourdieu, 1987; De Mauro et al., 2015; Haugen, 1959;
Rickford et al., 2012].
6. Toxic or offensive speech: The Aya Annotation Platform did not contain specific flags
for toxic, harmful, or offensive speech, so it is possible that malicious users could submit
unsafe data. We believe this is of relatively low risk because of the high rate of human-verified
annotations and peer-review, making it unlikely that toxic prompts or completions made it
intothefinaldataset. However,thereisnoguaranteethateveryentrywasaudited. Whiledata
poisoning has rarely been observed as a viable threat in practice, it has been demonstrated
to be of concern for instruction-tuning with very few examples [Xu et al., 2023b; Wan et al.,
2023] and for pre-training under realistic conditions [Carlini et al., 2023]. During the eight
months of crowd-sourced annotating, there were no reported cases of hateful or toxic speech
in the existing datasets nor were there any instances of offensive speech reported in the peer-
reviewing phase of new annotations.
We also note that data that might be offensive to one annotator might not be offensive to
another, for instance, the completion of a prompt that asks for a definition of the word ‚Äúwoke‚Äù
[Castaldo, September 16, 2023]. Prompts written on partisan political topics, or the inclusion
ofpoliticaladvertisementsorcampaignmessagescouldcauseoffensedependingonthepolitical
proclivities of the annotator. In short, we tried to mitigate offensive speech by relying heavily
on human annotation and peer review, but there is no guarantee that all such data points
were removed from the corpus.
7. Accounting for mislabeled data: The Aya Annotation Platform did not contain any
components that enabled re-labeling the assigned language of annotations. This may result
in prompts and completions that appear under a particular language, but were submitted
incorrectly and would need to be re-categorized into a different language. Additionally, while
we trusted annotators were able to follow directions and had a high rate of manual auditing,
some examples likely made it into the Aya Dataset that were not in instruction-style format
or were free-form texts.
3310 Conclusion
Open participatory research continues to be under-resourced and undervalued, particularly when
that work focuses on data creation [Sambasivan et al., 2021]. Aya involved participants from many
differentcountries, differentages, anddifferentlevelsoffamiliaritywiththefieldofnaturallanguage
processing. We see continued opportunity for computational linguists and machine-learning engi-
neers to collaborate with social scientists such as sociolinguists, anthropologists, sociologists, and
media studies scholars. As new norms in open science emerge [Krishna, 2020; Bowser et al., 2020],
collaborations like these can help ensure that projects in NLP are motivated by an understanding
of what language means to the people who use it every day.
With Aya, we hope to change the way data is created for multilingual NLP research. In line with
this view, we release the Aya Dataset which is the first human-curated open-source, multilingual
instruction-style dataset consisting of 204,114 prompt-completion pairs covering 65 languages. This
dataset was built with the help of our open-science community of 2,997 collaborators from 119
countries over a period of eight months.
We also release the Aya Collection, which consists of 44 instruction-style datasets. These were
preparedbytransformingexistingNLPdatasetsintoprompt-completionpairsthatcanbeleveraged
for instruction tuning. Furthermore, we translate several high-quality datasets into 101 languages,
thereby expanding coverage, particularly for many low-resource languages. This collection consists
of 513M prompt and completion pairs covering 114 languages in total and is the largest multilingual
instruction-finetuning collection today. Additionally, we release Aya Evaluation Suite, consisting
of human-curated examples in 13 languages and translation of carefully selected prompts in 101
languages. Finally, we are also open-sourcing the Aya Annotation Platform so that communities
can continue to use the platform to support the process of multilingual data collection. We hope
these communities continue to grow and develop, and to connect speakers of low-resource languages
around the world.
References
Julien Abadji, Pedro Javier Ortiz Su√°rez, Laurent Romary, and Beno√Æt Sagot. Ungoliant: An
optimized pipeline for the generation of a very large-scale multilingual web corpus. In Harald
L√ºngen,MarcKupietz,PiotrBa≈Ñski,AdrienBarbaresi,SimonClematide,andInesPisetta(eds.),
CMLC 2021-9th Workshop on Challenges in the Management of Large Corpora, Proceedings of
the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12
July 2021 (Online-Event), pp. 1 ‚Äì 9, Mannheim, 2021. Leibniz-Institut f√ºr Deutsche Sprache. doi:
10.14618/ids-pub-10468. URL https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688.
JulienAbadji,PedroOrtizSuarez,LaurentRomary,andBeno√ÆtSagot. Towardsacleanerdocument-
oriented multilingual crawled corpus. In Proceedings of the Thirteenth Language Resources and
Evaluation Conference, pp. 4344‚Äì4355, Marseille, France, June 2022. European Language Re-
sources Association. URL https://aclanthology.org/2022.lrec-1.463.
Tilahun Abedissa, Ricardo Usbeck, and Yaregal Assabie. AmQA: Amharic Question Answering
Dataset. arXiv preprint arXiv:2303.03290, 2023.
Gilles Adda, Sebastian St√ºker, Martine Adda-Decker, Odette Ambouroue, Laurent Besacier, David
Blachon, H√©l√®ne Bonneau-Maynard, Pierre Godard, Fatima Hamlaoui, Dmitry Idiatov, Guy-No√´l
34Kouarata,LoriLamel,Emmanuel-MosellyMakasso,AnnieRialland,MarkVandeVelde,Fran√ßois
Yvon, and Sabine Zerbian. Breaking the unwritten language barrier: The bulb project. Procedia
Computer Science, 81:8‚Äì14, 2016. ISSN 1877-0509. doi: https://doi.org/10.1016/j.procs.2016.0
4.023. URL https://www.sciencedirect.com/science/article/pii/S1877050916300370.
SLTU-20165thWorkshoponSpokenLanguageTechnologiesforUnder-resourcedlanguages09-12
May 2016 Yogyakarta, Indonesia.
David Ifeoluwa Adelani, Marek Masiak, Israel Abebe Azime, Jesujoba Alabi, Atnafu Lambebo
Tonja, Christine Mwase, Odunayo Ogundepo, Bonaventure F. P. Dossou, Akintunde Oladipo,
DoreenNixdorf,ChrisChinenyeEmezue,sanaalazzawi,BlessingSibanda,DavisDavid,Lolwethu
Ndolela, Jonathan Mukiibi, Tunde Ajayi, Tatiana Moteu, Brian Odhiambo, Abraham Owodunni,
Nnaemeka Obiefuna, Muhidin Mohamed, Shamsuddeen Hassan Muhammad, Teshome Mulugeta
Ababu, Saheed Abdullahi Salahudeen, Mesay Gemeda Yigezu, Tajuddeen Gwadabe, Idris Ab-
dulmumin, Mahlet Taye, Oluwabusayo Awoyomi, Iyanuoluwa Shode, Tolulope Adelani, Habiba
Abdulganiyu, Abdul-Hakeem Omotayo, Adetola Adeeko, Abeeb Afolabi, Anuoluwapo Aremu,
Olanrewaju Samuel, Clemencia Siro, Wangari Kimotho, Onyekachi Ogbu, Chinedu Mbonu, Chia-
maka Chukwuneke, Samuel Fanijo, Jessica Ojo, Oyinkansola Awosan, Tadesse Kebede, Toad-
oum Sari Sakayo, Pamela Nyatsine, Freedmore Sidume, Oreen Yousuf, Mardiyyah Oduwole,
Tshinu Tshinu, Ussen Kimanuka, Thina Diko, Siyanda Nxakama, Sinodos Nigusse, Abdulme-
jid Johar, Shafie Mohamed, Fuad Mire Hassan, Moges Ahmed Mehamed, Evrard Ngabire, Jules
Jules, Ivan Ssenkungu, and Pontus Stenetorp. MasakhaNEWS: News Topic Classification for
African Languages, 2023.
Asif Agha. Language and Social Relations. Studies in the Social and Cultural Foundations of
Language. Cambridge University Press, 2006.
RoeeAharoni,MelvinJohnson,andOrhanFirat. Massivelymultilingualneuralmachinetranslation,
2019.
Orevaoghene Ahia, Julia Kreutzer, and Sara Hooker. The low-resource double bind: An empirical
study of pruning for low-resource machine translation. In Findings of the Association for Compu-
tational Linguistics: EMNLP 2021, pp. 3316‚Äì3333, Punta Cana, Dominican Republic, November
2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.findings-emnlp.282.
URL https://aclanthology.org/2021.findings-emnlp.282.
AhmadMustafa. Urdu-Instruct-News-Article-Generation. https://huggingface.co/datasets/Ah
madMustafa/Urdu-Instruct-News-Article-Generation, 2023a. Accessed: 2023-11-28.
AhmadMustafa. Urdu-Instruct-News-Category-Classification. https://huggingface.co/datas
ets/AhmadMustafa/Urdu-Instruct-News-Category-Classification, 2023b. Accessed:
2023-11-28.
AhmadMustafa. Urdu-Instruct-News-Headline-Generation. https://huggingface.co/datasets/
AhmadMustafa/Urdu-Instruct-News-Headline-Generation, 2023c. Accessed: 2023-11-28.
AITamilNadu. Tamilstories. https://huggingface.co/datasets/aitamilnadu/tamil_stories,
2023a. Accessed: 2023-12-15.
AI Tamil Nadu. Thirukkural Instruct. https://huggingface.co/datasets/aitamilnadu/thiruk
kural_instruct, 2023b. Accessed: 2023-11-30.
35Christopher Akiki, Giada Pistilli, Margot Mieskes, Matthias Gall√©, Thomas Wolf, Suzana Iliƒá, and
YacineJernite. Bigscience: Acasestudyinthesocialconstructionofamultilinguallargelanguage
model, 2022.
Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz
Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, et al. Santacoder: don‚Äôt
reach for the stars! arXiv preprint arXiv:2301.03988, 2023.
Waseem AlShikh, Manhal Daaboul, Kirk Goddard, Brock Imel, Kiran Kamble, Parikshith Kulka-
rni, and Melisa Russak. Becoming self-instruct: introducing early stopping criteria for minimal
instruct tuning. arXiv preprint arXiv:2307.03692, 2023.
Hossein Amirkhani, Mohammad AzariJafari, Soroush Faridan-Jahromi, Zeinab Kouhkan, Zohreh
Pourjafari, and Azadeh Amirak. Farstail: A Persian natural language inference dataset. Soft
Computing, 2023. doi: 10.1007/s00500-023-08959-3.
Lauri Andress, Tristen Hall, Sheila Davis, Judith Levine, Kimberly Cripps, and Dominique Guinn.
Addressing power dynamics in community-engaged research partnerships. Journal of Patient-
Reported Outcomes 4: 24, 2020.
Md Adnan Arefeen, Biplob Debnath, and Srimat Chakradhar. Leancontext: Cost-efficient domain-
specific question answering using llms. arXiv preprint arXiv:2309.00841, 2023.
Mikel Artetxe, Sebastian Ruder, and Dani Yogatama. On the cross-lingual transferability of mono-
lingual representations. CoRR, abs/1910.11856, 2019.
SeyramAvle, EmmanuelQuartey, andDavidHutchful. Researchonmobilephonedataintheglobal
south. The Oxford Handbook of Networked Communication, 2018. URL https://api.semantic
scholar.org/CorpusID:168167342.
KailashAwatiandSimonBuckinghamShum. Bigdatametaphorsweliveby. Towards Data Science,
2015. URL https://towardsdatascience.com/big-data-metaphors-we-live-by-98d3fa44e
bf8.
Paul Azunre, Salomey Osei, Salomey Afua Addo, Lawrence Asamoah Adu-Gyamfi, Stephen Moore,
Bernard Adabankah, Bernard Opoku, Clara Asare-Nyarko, Samuel Nyarko, Cynthia Amoaba,
Esther Dansoa Appiah, Felix Akwerh, Richard Nii Lante Lawson, Joel Budu, Emmanuel Debrah,
Nana Adowaa Boateng, Wisdom Ofori, Edwin Buabeng-Munkoh, Franklin Adjei, Isaac. K. E.
Ampomah, Joseph Otoo., Reindorf Nartey Borkor, Standylove Birago Mensah, Lucien Mensah,
Mark Amoako Marcel, Anokye Acheampong Amponsah, and James Ben Hayfron-Acquah. Nlp
for ghanaian languages. ArXiv, abs/2103.15475, 2021. URL https://api.semanticscholar.or
g/CorpusID:232404908.
Stephen H Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin Raffel, Nihal V Nayak,
Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry, et al. Promptsource: An
integrateddevelopmentenvironmentandrepositoryfornaturallanguageprompts. arXiv preprint
arXiv:2202.01279, 2022.
Lo√Øc Barrault, Yu-An Chung, Mariano Cora Meglioli, David Dale, Ning Dong, Paul-Ambroise
Duquenne, Hady Elsahar, Hongyu Gong, Kevin Heffernan, John Hoffman, et al. Seamlessm4t-
massivelymultilingual&multimodalmachinetranslation. arXivpreprintarXiv:2308.11596,2023.
36Max Bartolo, Alastair Roberts, Johannes Welbl, Sebastian Riedel, and Pontus Stenetorp. Beat the
ai: Investigating adversarial human annotation for reading comprehension. Transactions of the
Association for Computational Linguistics, 8:662‚Äì678, 2020. doi: 10.1162/tacl\_a\_00338. URL
https://doi.org/10.1162/tacl_a_00338.
Azam Bastanfard, Mohammad Shahabipour, and Dariush Amirkhani. Crowdsourcing of labeling
image objects: an online gamification application for data collection. Multimedia Tools and
Applications, Aug 2023. ISSN 1573-7721. doi: 10.1007/s11042-023-16325-6. URL https:
//doi.org/10.1007/s11042-023-16325-6.
SusanneBeck,CarstenBergenholtz,MarcelBogers,Tiare-MariaBrasseur,MarieLouiseConradsen,
Diletta Di Marco, Andreas P. Distel, Leonhard Dobusch, Daniel D√∂rler, Agnes Effert, Benedikt
Fecher, DespoinaFiliou, LarsFrederiksen, ThomasGillier, ChristophGrimpe, MarcGruber, Car-
olin Haeussler, Florian Heigl, Karin Hoisl, Katie Hyslop, Olga Kokshagina, Marcel LaFlamme,
Cornelia Lawson, Hila Lifshitz-Assaf, Wolfgang Lukas, Markus Nordberg, Maria Theresa Norn,
Marion Poetz, Marisa Ponti, Gernot Pruschak, Laia Pujol Priego, Agnieszka Radziwon, Janet
Rafner, Gergana Romanova, Alexander Ruser, Henry Sauermann, Sonali K. Shah, Jacob F. Sher-
son, Julia Suess-Reyes, Christopher L. Tucci, Philipp Tuertscher, Jane Bj√∏rn Vedel, Theresa
Velden, Roberto Verganti, Jonathan Wareham, Andrea Wiggins, and Sunny Mosangzi Xu.
The open innovation in science research field: a collaborative conceptualisation approach. In-
dustry and Innovation, 29(2):136‚Äì185, 2022. doi: 10.1080/13662716.2020.1792274. URL
https://doi.org/10.1080/13662716.2020.1792274.
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic parsing on Freebase from
question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural
Language Processing, pp. 1533‚Äì1544, Seattle, Washington, USA, October 2013. Association for
Computational Linguistics. URL https://aclanthology.org/D13-1160.
Michael S. Bernstein, Greg Little, Robert C. Miller, Bj√∂rn Hartmann, Mark S. Ackerman, David R.
Karger, David Crowell, and Katrina Panovich. Soylent: a word processor with a crowd inside.
Commun. ACM, 58(8):85‚Äì94, 2015. doi: 10.1145/2791285. URL https://doi.org/10.1145/27
91285.
Steven Bird. Local languages, third spaces, and other high-resource scenarios. In Proceedings
of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
Papers), pp. 7817‚Äì7829, Dublin, Ireland, May 2022. Association for Computational Linguistics.
doi: 10.18653/v1/2022.acl-long.539. URL https://aclanthology.org/2022.acl-long.539.
Abeba Birhane, William Isaac, Vinodkumar Prabhakaran, Mark Diaz, Madeleine Clare Elish, Iason
Gabriel, and Shakir Mohamed. Power to the people? opportunities and challenges for participa-
tory ai. In Equity and Access in Algorithms, Mechanisms, and Optimization, EAAMO ‚Äô22. ACM,
October 2022. doi: 10.1145/3551624.3555290. URL http://dx.doi.org/10.1145/3551624.355
5290.
Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, and Yejin Choi. Piqa: Reasoning
aboutphysicalcommonsenseinnaturallanguage. InThirty-FourthAAAIConferenceonArtificial
Intelligence, 2020.
Verena Blaschke, Hinrich Schuetze, and Barbara Plank. A survey of corpora for Germanic low-
resource languages and dialects. In Proceedings of the 24th Nordic Conference on Computational
37Linguistics (NoDaLiDa), pp. 392‚Äì414, T√≥rshavn, Faroe Islands, May 2023. University of Tartu
Library. URL https://aclanthology.org/2023.nodalida-1.41.
Su Lin Blodgett, Lisa Green, and Brendan O‚ÄôConnor. Demographic dialectal variation in social
media: A case study of African-American English. In Proceedings of the 2016 Conference on
Empirical Methods in Natural Language Processing, pp. 1119‚Äì1130, Austin, Texas, November
2016. Association for Computational Linguistics. doi: 10.18653/v1/D16-1120. URL https:
//aclanthology.org/D16-1120.
Jan A. Botha, Manaal Faruqui, John Alex, Jason Baldridge, and Dipanjan Das. Learning to split
and rephrase from Wikipedia edit history. In Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing, pp. 732‚Äì737, Brussels, Belgium, October-November
2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1080. URL https:
//aclanthology.org/D18-1080.
Meriem Boubdir, Edward Kim, Beyza Ermis, Marzieh Fadaee, and Sara Hooker. Which prompts
make the difference? data prioritization for efficient human llm evaluation, 2023.
Pierre Bourdieu. What makes a social class? on the theoretical and practical existence of groups.
Berkeley journal of sociology, 32:1‚Äì17, 1987.
Anne Bowser, Caren Cooper, Alex De Sherbinin, Andrea Wiggins, Peter Brenton, Tyng-Ruey
Chuang, Elaine Faustman, Mordechai Haklay, and Metis Meloche. Still in need of norms: the
state of the data in citizen science. Citizen Science: Theory and Practice, 5(1), 2020.
Roger Brown and Albert Gilman. THE PRONOUNS OF POWER AND SOLIDARITY, pp. 252‚Äì
275. De Gruyter Mouton, Berlin, Boston, 1968. ISBN 9783110805376. doi: doi:10.1515/978311
0805376.252. URL https://doi.org/10.1515/9783110805376.252.
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-
wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,
Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M.
Ziegler,JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,
Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,
Ilya Sutskever, and Dario Amodei. Language models are few-shot learners, 2020.
Samuel Cahyawijaya, Holy Lovenia, Alham Fikri Aji, Genta Winata, Bryan Wilie, Fajri Koto, Rah-
madMahendra,ChristianWibisono,AdeRomadhony,KarissaVincentio,etal. Nusacrowd: Open
source initiative for indonesian nlp resources. In Findings of the Association for Computational
Linguistics: ACL 2023, pp. 13745‚Äì13818, 2023.
Nicholas Carlini, Matthew Jagielski, Christopher A. Choquette-Choo, Daniel Paleka, Will Pearce,
Hyrum Anderson, Andreas Terzis, Kurt Thomas, and Florian Tram√®r. Poisoning web-scale train-
ing datasets is practical, 2023.
Joe Castaldo. ‚ÄúAI chatbots fall short in dozens of languages. A non-profit project aims to fix that".
Globe & Mail, 2023.
Joe Castaldo. Meet the gig workers making ai machines more accurate, capable and powerful. The
Globe and Mail, September 16, 2023.
38Isaac Caswell, Theresa Breiner, Daan van Esch, and Ankur Bapna. Language ID in the wild:
Unexpected challenges on the path to a thousand-language web text corpus. In Proceedings
of the 28th International Conference on Computational Linguistics, pp. 6588‚Äì6608, Barcelona,
Spain (Online), December 2020. International Committee on Computational Linguistics. doi:
10.18653/v1/2020.coling-main.579. URL https://aclanthology.org/2020.coling-main.579.
Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay
Srinivasan, TianyiZhou, HengHuang, etal. Alpagasus: Trainingabetteralpacawithfewerdata.
arXiv preprint arXiv:2307.08701, 2023a.
Pinzhen Chen, Shaoxiong Ji, Nikolay Bogoychev, Barry Haddow, and Kenneth Heafield. Monolin-
gual or multilingual instruction tuning: Which makes a better alpaca, 2023b.
Sanxing Chen, Yongqiang Chen, and B√∂rje F. Karlsson. Dataset and baseline system for multi-
lingual extraction and normalization of temporal and numerical expressions. arXiv preprint
arXiv:2303.18103, 2023c.
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan
Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned
language models. arXiv preprint arXiv:2210.11416, 2022.
John Chung, Ece Kamar, and Saleema Amershi. Increasing diversity while maintaining accuracy:
Text data generation with large language models and human interventions. In Proceedings of the
61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers).
Association for Computational Linguistics, 2023. doi: 10.18653/v1/2023.acl-long.34. URL
http://dx.doi.org/10.18653/v1/2023.acl-long.34.
Tarin Clanuwat, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb, Kazuaki Yamamoto, and
David Ha. Deep learning for classical japanese literature. ArXiv, abs/1812.01718, 2018. URL
https://api.semanticscholar.org/CorpusID:54458639.
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina
Toutanova. Boolq: Exploring the surprising difficulty of natural yes/no questions. In NAACL,
2019.
JonathanH.Clark,EunsolChoi,MichaelCollins,DanGarrette,TomKwiatkowski,VitalyNikolaev,
and Jennimaria Palomaki. Tydi qa: A benchmark for information-seeking question answering in
typologically diverse languages. Transactions of the Association for Computational Linguistics,
2020.
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and
Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge.
arXiv:1803.05457v1, 2018.
Alexis Conneau, Guillaume Lample, Ruty Rinott, Adina Williams, Samuel R Bowman, Holger
Schwenk, and Veselin Stoyanov. Xnli: Evaluating cross-lingual sentence representations. arXiv
preprint arXiv:1809.05053, 2018.
Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick
Wendell, Matei Zaharia, and Reynold Xin. Free Dolly: Introducing the World‚Äôs First Truly Open
Instruction-Tuned LLM, 2023. URL https://www.databricks.com/blog/2023/04/12/dolly-f
irst-open-commercially-viable-instruction-tuned-llm.
39ConseggioLigure. Lij news instruct ita-lij. https://huggingface.co/datasets/ConseggioLigur
e/lijnews-instruct-ita-lij, 2023a. Accessed: 2023-11-28.
ConseggioLigure. Lij news instruct lij-ita. https://huggingface.co/datasets/ConseggioLigur
e/lijnews-instruct-lij-ita, 2023b. Accessed: 2023-11-28.
ConseggioLigure. Seed instruct eng-lij. https://huggingface.co/datasets/ConseggioLigure/
seed-instruct-eng-lij, 2023c. Accessed: 2023-11-28.
ConseggioLigure. Seed instruct lij-eng. https://huggingface.co/datasets/ConseggioLigure/
seed-instruct-lij-eng, 2023d. Accessed: 2023-11-28.
Eric Corbett, Emily Denton, and Sheena Erete. Power and public participation in ai. In Proceed-
ings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Opti-
mization, EAAMO ‚Äô23, New York, NY, USA, 2023. Association for Computing Machinery. ISBN
9798400703812. doi: 10.1145/3617694.3623228. URL https://doi.org/10.1145/3617694.3623
228.
Kate Crawford. Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence. Yale
University Press, New Haven, Connecticut, 2021.
Yiming Cui, Ting Liu, Wanxiang Che, Li Xiao, Zhipeng Chen, Wentao Ma, Shijin Wang, and
Guoping Hu. A span-extraction dataset for Chinese machine reading comprehension. In Pro-
ceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and
the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp.
5883‚Äì5889, Hong Kong, China, November 2019. Association for Computational Linguistics. doi:
10.18653/v1/D19-1600. URL https://aclanthology.org/D19-1600.
Yiming Cui, Ziqing Yang, and Xin Yao. Efficient and effective text encoding for chinese llama and
alpaca, 2023.
Raj Dabre, Chenhui Chu, and Anoop Kunchukuttan. A survey of multilingual neural machine
translation. ACM Comput. Surv., 53(5), sep 2020. ISSN 0360-0300. doi: 10.1145/3406095. URL
https://doi.org/10.1145/3406095.
Viet Dac Lai, Chien Van Nguyen, Nghia Trung Ngo, Thuat Nguyen, Franck Dernoncourt, Ryan A
Rossi, and Thien Huu Nguyen. Okapi: Instruction-tuned large language models in multiple
languages with reinforcement learning from human feedback. arXiv e-prints, pp. arXiv‚Äì2307,
2023.
PradeepDasigi, NelsonF.Liu, AnaMarasovic, NoahA.Smith, andMattGardner. Quoref: Aread-
ing comprehension dataset with questions requiring coreferential reasoning. arXiv:1908.05803v2,
2019.
Flavio A. de Franga, Adriana S. Vivacqua, and Maria Luiza M. Campos. Designing a gamification
mechanism to encourage contributions in a crowdsourcing system. In 2015 IEEE 19th Interna-
tional Conference on Computer Supported Cooperative Work in Design (CSCWD), pp. 462‚Äì466,
2015. doi: 10.1109/CSCWD.2015.7231003.
Andrea De Mauro, Marco Greco, and Michele Grimaldi. What is big data? a consensual definition
and a review of key research topics. In AIP conference proceedings, volume 1644, pp. 97‚Äì104.
American Institute of Physics, 2015.
40Fernando Delgado, Stephen Yang, Michael Madaio, and Qian Yang. The participatory turn in ai
design: Theoretical foundations and the current state of practice. Proceedings of the 3rd ACM
Conference on Equity and Access in Algorithms, Mechanisms, and Optimization, 2023. URL
https://api.semanticscholar.org/CorpusID:263605822.
Yue Deng, Wenxuan Zhang, Sinno Jialin Pan, and Lidong Bing. Multilingual jailbreak challenges
in large language models. ArXiv, abs/2310.06474, 2023. URL https://api.semanticscholar.
org/CorpusID:263831094.
desik98. Telugu Riddles. https://huggingface.co/datasets/desik98/TeluguRiddles, 2023.
Accessed: 2023-11-30.
Kaustubh D Dhole, Varun Gangal, Sebastian Gehrmann, Aadesh Gupta, Zhenhao Li, Saad Ma-
hamood, Abinaya Mahendiran, Simon Mille, Ashish Shrivastava, Samson Tan, et al. Nl-
augmenter: A framework for task-sensitive natural language augmentation. arXiv preprint
arXiv:2112.02721, 2021.
Sumanth Doddapaneni, Rahul Aralikatte, Gowtham Ramesh, Shreya Goyal, Mitesh M. Khapra,
AnoopKunchukuttan,andPratyushKumar. TowardsleavingnoIndiclanguagebehind: Building
monolingual corpora, benchmark and models for Indic languages. In Proceedings of the 61st
Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp.
12402‚Äì12426, Toronto, Canada, July 2023. Association for Computational Linguistics. URL
https://aclanthology.org/2023.acl-long.693.
Jesse Dodge, Maarten Sap, Ana Marasovic, William Agnew, Gabriel Ilharco, Dirk Groeneveld, and
Matt Gardner. Documenting the english colossal clean crawled corpus. CoRR, abs/2104.08758,
2021. URL https://arxiv.org/abs/2104.08758.
A Seza Doƒüru√∂z, Sunayana Sitaram, and Zheng-Xin Yong. Representativeness as a forgot-
ten lesson for multilingual and code-switched data collection and preparation. arXiv preprint
arXiv:2310.20470, 2023.
Bill Dolan and Chris Brockett. Automatically constructing a corpus of sentential paraphrases. In
Third International Workshop on Paraphrasing (IWP2005). Asia Federation of Natural Language
Processing, January 2005. URL https://www.microsoft.com/en-us/research/publication
/automatically-constructing-a-corpus-of-sentential-paraphrases/.
Esin Durmus, Karina Nyugen, Thomas I Liao, Nicholas Schiefer, Amanda Askell, Anton Bakhtin,
Carol Chen, Zac Hatfield-Dodds, Danny Hernandez, Nicholas Joseph, et al. Towards mea-
suring the representation of subjective global opinions in language models. arXiv preprint
arXiv:2306.16388, 2023.
el2e10. Aya Indic Sentiment. https://huggingface.co/datasets/el2e10/aya-indicsentiment,
2023a. Accessed: 2023-11-28.
el2e10. Aya Paraphrase. https://huggingface.co/datasets/el2e10/aya-paraphrase, 2023b.
Accessed: 2023-11-28.
Alexander R. Fabbri, Irene Li, Tianwei She, Suyi Li, and Dragomir R. Radev. Multi-news: a
large-scale multi-document summarization dataset and abstractive hierarchical model, 2019.
Oliver Falck, Stephan Heblich, Alfred Lameli, and Jens S√ºdekum. Dialects, cultural identity, and
economic exchange. Journal of urban economics, 72(2-3):225‚Äì239, 2012.
41Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Man-
deep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, et al. Beyond english-centric
multilingual machine translation. Journal of Machine Learning Research, 22(107):1‚Äì48, 2021.
Mehrdad Farahani, Mohammad Gharachorloo, and Mohammad Manthouri. Leveraging parsbert
and pretrained mt5 for persian abstractive text summarization. In 2021 26th International Com-
puter Conference, Computer Society of Iran (CSICC), pp. 1‚Äì6. IEEE, 2021.
Emilio Ferrara. Should chatgpt be biased? challenges and risks of bias in large language models.
arXiv preprint arXiv:2304.03738, 2023.
‚àÄ, Wilhelmina Nekoto, Vukosi Marivate, Tshinondiwa Matsila, Timi Fasubaa, Taiwo Fagbo-
hungbe, Solomon Oluwole Akinola, Shamsuddeen Muhammad, Salomon Kabongo Kabenamualu,
Salomey Osei, Freshia Sackey, Rubungo Andre Niyongabo, Ricky Macharm, Perez Ogayo, Ore-
vaogheneAhia,MusieMeressaBerhe,MofetoluwaAdeyemi,MasabataMokgesi-Selinga,Lawrence
Okegbemi, LauraMartinus, KolawoleTajudeen, KevinDegila, KelechiOgueji, KathleenSiminyu,
Julia Kreutzer, Jason Webster, Jamiil Toure Ali, Jade Abbott, Iroro Orife, Ignatius Ezeani,
Idris Abdulkadir Dangana, Herman Kamper, Hady Elsahar, Goodness Duru, Ghollah Kioko,
Murhabazi Espoir, Elan van Biljon, Daniel Whitenack, Christopher Onyefuluchi, Chris Chinenye
Emezue, Bonaventure F. P. Dossou, Blessing Sibanda, Blessing Bassey, Ayodele Olabiyi, Arshath
Ramkilowan, Alp √ñktem, Adewale Akinfaderin, and Abdallah Bashir. Participatory research for
low-resourcedmachinetranslation: AcasestudyinAfricanlanguages. InTrevorCohn, YulanHe,
and Yang Liu (eds.), Findings of the Association for Computational Linguistics: EMNLP 2020,
Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findi
ngs-emnlp.195. URL https://aclanthology.org/2020.findings-emnlp.195.
Chiara Franzoni and Henry Sauermann. Crowd science: The organization of scientific research in
open collaborative projects. Research Policy, 43(1):1‚Äì20, 2014. ISSN 0048-7333. doi: https:
//doi.org/10.1016/j.respol.2013.07.005. URL https://www.sciencedirect.com/science/arti
cle/pii/S0048733313001212.
ganeshjcs. Hindi Article Summarization. https://huggingface.co/datasets/ganeshjcs/hind
i-article-summarization, 2023a. Accessed: 2023-11-28.
ganeshjcs. Hindi Headline Article Generation. https://huggingface.co/datasets/ganeshjcs/
hindi-headline-article-generation, 2023b. Accessed: 2023-11-28.
Ya Gao and WenQi Liu. Measures to sustain endangered languages: A bilingual competition model
with sliding mode control. PLOS ONE, 18(6):1‚Äì16, 06 2023. doi: 10.1371/journal.pone.0287850.
URL https://doi.org/10.1371/journal.pone.0287850.
Dan Garrette, Jason Mielens, and Jason Baldridge. Real-world semi-supervised learning of pos-
taggers for low-resource languages. In Proceedings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers), pp. 583‚Äì592, 2013.
Marco Gerosa, Igor Wiese, Bianca Trinkenreich, Georg Link, Gregorio Robles, Christoph Treude,
Igor Steinmacher, and Anita Sarma. The shifting sands of motivation: Revisiting what drives
contributors in open source. In 2021 IEEE/ACM 43rd International Conference on Software
Engineering (ICSE), pp. 1046‚Äì1058. IEEE, 2021.
42Sourojit Ghosh and Aylin Caliskan. Chatgpt perpetuates gender bias in machine translation and
ignores non-gendered pronouns: Findings across bengali and five other low-resource languages,
2023.
Bogdan Gliwa, Iwona Mochol, Maciej Biesek, and Aleksander Wawer. SAMSum corpus: A human-
annotated dialogue dataset for abstractive summarization. In Proceedings of the 2nd Workshop
on New Frontiers in Summarization, pp. 70‚Äì79, Hong Kong, China, November 2019. Association
for Computational Linguistics. doi: 10.18653/v1/D19-5409. URL https://aclanthology.org
/D19-5409.
Charles Goodwin. Co-Operative Action. Learning in Doing: Social, Cognitive and Computational
Perspectives. Cambridge University Press, 2017.
Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, and Alexis Conneau. Larger-Scale Trans-
formers for Multilingual Masked Language Modeling. In Proceedings of the 6th Workshop on
Representation Learning for NLP (RepL4NLP-2021). Association for Computational Linguistics,
2021a.
Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen, Guillaume Wenzek, Da Ju, San-
jana Krishnan, Marc‚ÄôAurelio Ranzato, Francisco Guzman, and Angela Fan. The flores-101 eval-
uation benchmark for low-resource and multilingual machine translation, 2021b.
David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. English gigaword. Linguistic Data
Consortium, Philadelphia, 4(1):34, 2003.
Giovanni Grano, Andrea Di Sorbo, Francesco Mercaldo, Corrado A Visaggio, Gerardo Canfora, and
Sebastiano Panichella. Android apps and user feedback: a dataset for software evolution and
quality improvement. In Proceedings of the 2nd ACM SIGSOFT international workshop on app
market analytics, pp. 8‚Äì11, 2017.
Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord,
AnanyaHarshJha,HamishIvison,IanMagnusson,YizhongWang,ShaneArora,DavidAtkinson,
Russell Authur, Khyathi Chandu, Arman Cohan, Jennifer Dumas, Yanai Elazar, Yuling Gu, Jack
Hessel, Tushar Khot, William Merrill, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik,
Crystal Nam, Matthew E. Peters, Valentina Pyatkin, Abhilasha Ravichander, Dustin Schwenk,
Saurabh Shah, Will Smith, Nishant Subramani, Mitchell Wortsman, Pradeep Dasigi, Nathan
Lambert, Kyle Richardson, Jesse Dodge, Kyle Lo, Luca Soldaini, Noah A. Smith, and Hannaneh
Hajishirzi. OLMo: Accelerating the Science of Language Models. arXiv preprint, 2024.
Yuling Gu, Bhavana Dalvi, and Peter Clark. DREAM: Improving situational QA by first elab-
orating the situation. In Proceedings of the 2022 Conference of the North American Chapter
of the Association for Computational Linguistics: Human Language Technologies, pp. 1115‚Äì
1127, Seattle, United States, July 2022. Association for Computational Linguistics. doi:
10.18653/v1/2022.naacl-main.82. URL https://aclanthology.org/2022.naacl-main.82.
Adriana Guevara-Rukoz, Isin Demirsahin, Fei He, Shan-Hui Cathy Chu, Supheakmungkol Sarin,
Knot Pipatsrisawat, Alexander Gutkin, Alena Butryna, and Oddur Kjartansson. Crowdsourcing
Latin American Spanish for low-resource text-to-speech. In Proceedings of the Twelfth Language
Resources and Evaluation Conference, pp. 6504‚Äì6513, Marseille, France, May 2020. European
Language Resources Association. ISBN 979-10-95546-34-4. URL https://aclanthology.org/2
020.lrec-1.801.
43Antonio Gulli. AG‚Äôs Corpus of News Articles. Dipartimento di Informatica, University of Pisa,
Nov, 2005. URL http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html.
Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio C√©sar Teodoro Mendes, Allie Del Giorno, Sivakanth
Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital
Shah, Harkirat Singh Behl, Xin Wang, S√©bastien Bubeck, Ronen Eldan, Adam Tauman Kalai,
Yin Tat Lee, and Yuanzhi Li. Textbooks are all you need, 2023.
Himanshu Gupta, Kevin Scaria, Ujjwala Anantheswaran, Shreyas Verma, Mihir Parmar,
Saurabh Arjun Sawant, Chitta Baral, and Swaroop Mishra. Targen: Targeted data generation
with large language models, 2023.
Margot Hanley, Apoorv Khandelwal, Hadar Averbuch-Elor, Noah Snavely, and Helen Nissenbaum.
An ethical highlighter for people-centric dataset creation. arXiv preprint arXiv:2011.13583, 2020.
Christian Hardmeier and Liane Guillou. Pronoun translation in english-french machine translation:
An analysis of error types, 2018.
Kai Hartung, Aaricia Herygers, Shubham Kurlekar, Khabbab Zakaria, Taylan Volkan, S√∂ren Gr√∂t-
trup, and Munir Georges. Measuring sentiment bias in machine translation, 2023.
Tahmid Hasan, Abhik Bhattacharjee, Md. Saiful Islam, Kazi Mubasshir, Yuan-Fang Li, Yong-Bin
Kang, M. Sohel Rahman, and Rifat Shahriyar. XL-sum: Large-scale multilingual abstractive
summarization for 44 languages. In Findings of the Association for Computational Linguistics:
ACL-IJCNLP 2021, pp. 4693‚Äì4703, Online, August 2021. Association for Computational Lin-
guistics. doi: 10.18653/v1/2021.findings-acl.413. URL https://aclanthology.org/2021.find
ings-acl.413.
Einar Haugen. Planning for a standard language in modern norway. Anthropological linguistics, pp.
8‚Äì21, 1959.
William Held, Camille Harris, Michael Best, and Diyi Yang. A material lens on coloniality in nlp,
2023.
Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa
Suleyman, and Phil Blunsom. Teaching machines to read and comprehend. In Advances in neural
information processing systems, pp. 1693‚Äì1701, 2015.
hghader1. FarsTail-Instruct-LLM. https://huggingface.co/datasets/hghader1/FarsTail-Ins
truct-LLM, 2023. Accessed: 2023-11-28.
Oskar Holmstr√∂m and Ehsan Doostmohammadi. Making instruction finetuning accessible to non-
Englishlanguages: AcasestudyonSwedishmodels. InProceedings of the 24th Nordic Conference
on Computational Linguistics (NoDaLiDa), pp. 634‚Äì642, T√≥rshavn, Faroe Islands, May 2023.
University of Tartu Library. URL https://aclanthology.org/2023.nodalida-1.62.
Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning
language models with (almost) no human labor. In Proceedings of the 61st Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers), pp. 14409‚Äì14428, Toronto,
Canada, July 2023. Association for Computational Linguistics. URL https://aclanthology.o
rg/2023.acl-long.806.
44Dirk Hovy and Shrimai Prabhumoye. Five sources of bias in natural language processing. Language
and Linguistics Compass, 15(8):e12432, 2021.
Eduard Hovy, Laurie Gerber, Ulf Hermjakob, Chin-Yew Lin, and Deepak Ravichandran. Toward
semantics-based answer pinpointing. In Proceedings of the First International Conference on
Human Language Technology Research, 2001. URL https://aclanthology.org/H01-1069.
Pei-Yun Hsueh, Prem Melville, and Vikas Sindhwani. Data quality from crowdsourcing: a study of
annotationselectioncriteria. InProceedings of the NAACL HLT 2009 workshop on active learning
for natural language processing, pp. 27‚Äì35, 2009.
Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,
and Weizhu Chen. Lora: Low-rank adaptation of large language models, 2021.
Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Dingjie Song, Zhihong Chen,
Abdulmohsen Alharthi, Bang An, Ziche Liu, et al. Acegpt, localizing large language models in
arabic. arXiv preprint arXiv:2309.12053, 2023.
Kuan-Hao Huang, I-Hung Hsu, Premkumar Natarajan, Kai-Wei Chang, and Nanyun Peng. Multi-
lingual generative language models for zero-shot cross-lingual event argument extraction, 2022.
Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Cosmos QA: Machine reading
comprehensionwithcontextualcommonsensereasoning. InProceedings of the 2019 Conference on
Empirical Methods in Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP), pp. 2391‚Äì2401, Hong Kong, China, November
2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1243. URL https:
//aclanthology.org/D19-1243.
Khalid Hussain, Nimra Mughal, Irfan Ali, Saif Hassan, and Sher Muhammad Daudpota. Urdu
News Dataset 1M. Technical report, Mendeley Data, V3, 2021.
Mika H√§m√§l√§inen. Endangered Languages are not Low-Resourced!, pp. 1‚Äì11. University of Helsinki,
March 2021. doi: 10.31885/9789515150257.1. URL http://dx.doi.org/10.31885/9789515150
257.1.
Iftitahu. Indonesian Instruct Stories. https://huggingface.co/datasets/Iftitahu/indonesia
n_instruct_stories, 2023a. Accessed: 2023-11-28.
Iftitahu. Javanese Instruct Stories. https://huggingface.co/datasets/Iftitahu/javanese_in
struct_stories, 2023b. Accessed: 2023-11-28.
Iftitahu. Sudanese Instruct Stories. https://huggingface.co/datasets/Iftitahu/sundanese_i
nstruct_stories, 2023c. Accessed: 2023-11-28.
Amirova Gulruh Ilhomovna and S Yuldasheva. You have got to know your language to understand
your culture. In Interdiscipline Innovation and Scientific Research Conference, volume 1, pp.
103‚Äì106, 2023.
Shankar Iyer, Nikhil Dandekar, and Korn√§l Csernai. Quora question pairs, 2012.
Srinivasan Iyer, Xi Victoria Lin, Ramakanth Pasunuru, Todor Mihaylov, Daniel Simig, Ping Yu,
KurtShuster,TianluWang,QingLiu,PunitSinghKoura,etal. Opt-iml: Scalinglanguagemodel
instruction meta learning through the lens of generalization. arXiv preprint arXiv:2212.12017,
2022.
45Meng Ji, Meng Ji, Pierrette Bouillon, and Mark Seligman. Cultural and Linguistic Bias of Neural
Machine Translation Technology, pp. 100‚Äì128. Studies in Natural Language Processing. Cam-
bridge University Press, 2023a. doi: 10.1017/9781108938976.005.
YunjieJi,YanGong,YongDeng,YipingPeng,QiangNiu,BaochangMa,andXiangangLi. Towards
betterinstructionfollowinglanguagemodelsforchinese: Investigatingtheimpactoftrainingdata
and evaluation, 2023b.
jjzha. IMDB Dutch Instruct. https://huggingface.co/datasets/jjzha/imdb-dutch-instruct,
2023. Accessed: 2023-11-28.
Anna J√∏rgensen, Dirk Hovy, and Anders S√∏gaard. Challenges of studying and processing dialects
in social media. In Proceedings of the Workshop on Noisy User-generated Text, pp. 9‚Äì18, Beijing,
China, July 2015. Association for Computational Linguistics. doi: 10.18653/v1/W15-4302. URL
https://aclanthology.org/W15-4302.
Joseph Cheung. GuanacoDataset (Revision 8cf0d29) , 2023. URL https://huggingface.co/dat
asets/JosephusCheung/GuanacoDataset.
Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. triviaqa: A Large Scale Distantly
SupervisedChallengeDatasetforReadingComprehension. arXiv e-prints, art.arXiv:1705.03551,
2017.
Pratik Joshi, Christain Barnes, Sebastin Santy, Simran Khanuja, Sanket Shah, Anirudh Srinivasan,
Satwik Bhattamishra, Sunayana Sitaram, Monojit Choudhury, and Kalika Bali. Unsung chal-
lenges of building and deploying language technologies for low resource language communities.
In Proceedings of the 16th International Conference on Natural Language Processing, pp. 211‚Äì
219, International Institute of Information Technology, Hyderabad, India, December 2019. NLP
Association of India. URL https://aclanthology.org/2019.icon-1.25.
Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. The state and
fate of linguistic diversity and inclusion in the NLP world. In Proceedings of the 58th Annual
Meeting of the Association for Computational Linguistics, pp. 6282‚Äì6293, Online, July 2020.
Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.560. URL https:
//aclanthology.org/2020.acl-main.560.
jxmorris12, thomwolf, lhoestq, and lewtun. ag_news. https://huggingface.co/datasets/ag_n
ews, 2023. Accessed: 2023-11-28.
Jenna Kanerva, Filip Ginter, Li-Hsin Chang, Iiro Rastas, Valtteri Skantsi, Jemina Kilpel√§inen,
Hanna-Mari Kupari, Jenna Saarni, Maija Sev√≥n, and Otto Tarkka. Finnish paraphrase corpus.
InProceedingsofthe23rdNordicConferenceonComputationalLinguistics(NoDaLiDa),pp.288‚Äì
298, Reykjavik, Iceland (Online), May 31‚Äì2 June 2021. Link√∂ping University Electronic Press,
Sweden. URL https://aclanthology.org/2021.nodalida-main.29.
Khyati Khandelwal, Manuel Tonneau, Andrew M. Bean, Hannah Rose Kirk, and Scott A. Hale.
Casteist but not racist? quantifying disparities in large language model bias between india and
the west. ArXiv, abs/2309.08573, 2023. URL https://api.semanticscholar.org/CorpusID:
262013517.
46Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, and Dan Roth. Looking
beyond the surface:a challenge set for reading comprehension over multiple sentences. In Pro-
ceedings of North American Chapter of the Association for Computational Linguistics (NAACL),
2018.
Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, and
Hannaneh Hajishirzi. Unifiedqa: Crossing format boundaries with a single qa system. arXiv
preprint arXiv:2005.00700, 2020.
Md Tawkat Islam Khondaker, Abdul Waheed, El Moatez Billah Nagoudi, and Muhammad Abdul-
Mageed. Gptaraeval: A comprehensive evaluation of chatgpt on arabic nlp, 2023.
Tushar Khot, Peter Clark, Michal Guerquin, Peter Jansen, and Ashish Sabharwal. Qasc: A dataset
for question answering via sentence composition. arXiv:1910.11473v2, 2020.
Hyunwoo Kim, Jack Hessel, Liwei Jiang, Peter West, Ximing Lu, Youngjae Yu, Pei Zhou, Ronan Le
Bras, Malihe Alikhani, Gunhee Kim, Maarten Sap, and Yejin Choi. Soda: Million-scale dialogue
distillation with social commonsense contextualization. ArXiv, abs/2212.10465, 2022.
Joongwon Kim, Mounica Maddela, Reno Kriz, Wei Xu, and Chris Callison-Burch. BiSECT:
Learning to split and rephrase sentences with bitexts. In Proceedings of the 2021 Confer-
ence on Empirical Methods in Natural Language Processing, pp. 6193‚Äì6209, Online and Punta
Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi:
10.18653/v1/2021.emnlp-main.500. URL https://aclanthology.org/2021.emnlp-main.500.
Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye, Jamin Shin, and Minjoon
Seo. The cot collection: Improving zero-shot and few-shot learning of language models via chain-
of-thought fine-tuning. arXiv preprint arXiv:2305.14045, 2023.
AndreasK√∂pf,YannicKilcher,DimitrivonR√ºtte,SotirisAnagnostidis,Zhi-RuiTam,KeithStevens,
Abdullah Barhoum, Nguyen Minh Duc, Oliver Stanley, Rich√°rd Nagyfi, et al. Openassistant
conversations‚Äìdemocratizing large language model alignment. arXiv preprint arXiv:2304.07327,
2023.
Hadas Kotek, Rikker Dockum, and David Q. Sun. Gender bias and stereotypes in large language
models. Proceedings of The ACM Collective Intelligence Conference, 2023. URL https://api.
semanticscholar.org/CorpusID:261276445.
JuliaKreutzer,IsaacCaswell,LisaWang,AhsanWahab,DaanvanEsch,NasanbayarUlzii-Orshikh,
Allahsera Tapo, Nishant Subramani, Artem Sokolov, Claytone Sikasote, Monang Setyawan,
Supheakmungkol Sarin, Sokhar Samb, Beno√Æt Sagot, Clara Rivera, Annette Rios, Isabel Pa-
padimitriou, Salomey Osei, Pedro Ortiz Suarez, Iroro Orife, Kelechi Ogueji, Andre Niyongabo
Rubungo, Toan Q. Nguyen, Mathias M√ºller, Andr√© M√ºller, Shamsuddeen Hassan Muhammad,
Nanda Muhammad, Ayanda Mnyakeni, Jamshidbek Mirzakhalov, Tapiwanashe Matangira, Colin
Leong, NzeLawson, SnehaKudugunta, YacineJernite, MathiasJenny, OrhanFirat, Bonaventure
F. P. Dossou, Sakhile Dlamini, Nisansa de Silva, Sakine √áabuk Ballƒ±, Stella Biderman, Alessia
Battisti, Ahmed Baruwa, Ankur Bapna, Pallavi Baljekar, Israel Abebe Azime, Ayodele Awokoya,
Duygu Ataman, Orevaoghene Ahia, Oghenefego Ahia, Sweta Agrawal, and Mofetoluwa Adeyemi.
Quality at a glance: An audit of web-crawled multilingual datasets. Transactions of the As-
sociation for Computational Linguistics, 10:50‚Äì72, 2022. doi: 10.1162/tacl_a_00447. URL
https://aclanthology.org/2022.tacl-1.4.
47Venni V. Krishna. Open science and its enemies: Challenges for a sustainable science‚Äìsociety social
contract. Journal of Open Innovation: Technology, Market, and Complexity, 6(3):61, 2020. ISSN
2199-8531. doi: https://doi.org/10.3390/joitmc6030061.
Sneha Kudugunta, Isaac Caswell, Biao Zhang, Xavier Garcia, Christopher A Choquette-Choo,
Katherine Lee, Derrick Xin, Aditya Kusupati, Romi Stella, Ankur Bapna, et al. Madlad-400: A
multilingual and document-level large audited dataset. arXiv preprint arXiv:2309.04662, 2023.
Anoop Kunchukuttan, Siddharth Jain, and Rahul Kejriwal. A large-scale evaluation of neural
machinetransliterationforIndiclanguages. InProceedings of the 16th Conference of the European
Chapter of the Association for Computational Linguistics: Main Volume, pp. 3469‚Äì3475, Online,
April 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.eacl-main.303.
URL https://aclanthology.org/2021.eacl-main.303.
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris
Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion
Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav
Petrov. Natural questions: A benchmark for question answering research. Transactions of the
Association for Computational Linguistics, 7:452‚Äì466, 2019. doi: 10.1162/tacl_a_00276. URL
https://aclanthology.org/Q19-1026.
AndreasK√∂pf,YannicKilcher,DimitrivonR√ºtte,SotirisAnagnostidis,Zhi-RuiTam,KeithStevens,
Abdullah Barhoum, Nguyen Minh Duc, Oliver Stanley, Rich√°rd Nagyfi, Shahul ES, Sameer Suri,
David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and
AlexanderMattick. Openassistantconversations‚Äìdemocratizinglargelanguagemodelalignment,
2023.
Faisal Ladhak, Esin Durmus, Claire Cardie, and Kathleen McKeown. WikiLingua: A new bench-
mark dataset for cross-lingual abstractive summarization. In Findings of the Association for
Computational Linguistics: EMNLP 2020, pp. 4034‚Äì4048, Online, November 2020. Associa-
tion for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.360. URL
https://aclanthology.org/2020.findings-emnlp.360.
Preethi Lahoti, Nicholas Blumm, Xiao Ma, Raghavendra Kotikalapudi, Sahitya Potluri, Qijun Tan,
Hansa Srinivasan, Ben Packer, Ahmad Beirami, Alex Beutel, and Jilin Chen. Improving diversity
of demographic representation in large language models via collective-critiques and self-voting,
2023.
GuokunLai, QizheXie, HanxiaoLiu, YimingYang, andEduardHovy. RACE:Large-scaleReAding
comprehension dataset from examinations. In Proceedings of the 2017 Conference on Empirical
Methods in Natural Language Processing, pp. 785‚Äì794, Copenhagen, Denmark, September 2017.
Association for Computational Linguistics. doi: 10.18653/v1/D17-1082. URL https://aclant
hology.org/D17-1082.
Viet Dac Lai, Chien Van Nguyen, Nghia Trung Ngo, Thuat Nguyen, Franck Dernoncourt, Ryan A
Rossi, and Thien Huu Nguyen. Okapi: Instruction-tuned large language models in multiple
languages with reinforcement learning from human feedback. arXiv preprint arXiv:2307.16039,
2023.
Guillaume Lample and Alexis Conneau. Cross-lingual language model pretraining. arXiv preprint
arXiv:1901.07291, 2019.
48Hugo Lauren√ßon, Lucile Saulnier, Thomas Wang, Christopher Akiki, Albert Villanova del Moral,
TevenLeScao, LeandroVonWerra,ChenghaoMou,EduardoGonz√°lezPonferrada,HuuNguyen,
et al. The bigscience roots corpus: A 1.6 tb composite multilingual dataset. Advances in Neural
Information Processing Systems, 35:31809‚Äì31826, 2022.
R√©mi Lebret, David Grangier, and Michael Auli. Generating text from structured data with appli-
cation to the biography domain. CoRR, abs/1603.07771, 2016. URL http://arxiv.org/abs/16
03.07771.
Nayeon Lee, Chani Jung, and Alice Oh. Hate speech classifiers are culturally insensitive. In
Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP), pp. 35‚Äì
46, Dubrovnik, Croatia, May 2023. Association for Computational Linguistics. URL https:
//aclanthology.org/2023.c3nlp-1.5.
Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo Mendes,
Sebastian Hellmann, Mohamed Morsey, Patrick Van Kleef, S√∂ren Auer, and Christian Bizer.
Dbpedia - a large-scale, multilingual knowledge base extracted from wikipedia. Semantic Web
Journal, 6, 01 2014. doi: 10.3233/SW-140134.
Regina Lenart-Gansiniec, Wojciech Czakon, ≈Åukasz Su≈Çkowski, and Jasna Pocek. Understanding
crowdsourcing in science. Review of Managerial Science, 17(8):2797‚Äì2830, Nov 2023. ISSN 1863-
6691. doi: 10.1007/s11846-022-00602-z. URLhttps://doi.org/10.1007/s11846-022-00602-z.
HeatherLent,KelechiOgueji,MiryamdeLhoneux,OrevaogheneAhia,andAndersS√∏gaard. Whata
creole wants, what a creole needs. In Proceedings of the Thirteenth Language Resources and Eval-
uation Conference, pp. 6439‚Äì6449, Marseille, France, June 2022. European Language Resources
Association. URL https://aclanthology.org/2022.lrec-1.691.
Vladimir I Levenshtein et al. Binary codes capable of correcting deletions, insertions, and reversals.
In Soviet physics doklady, volume 10, pp. 707‚Äì710. Soviet Union, 1966.
Patrick Lewis, Barlas Oƒüuz, Ruty Rinott, Sebastian Riedel, and Holger Schwenk. Mlqa: Evaluating
cross-lingual extractive question answering, 2020.
Haonan Li, Fajri Koto, Minghao Wu, Alham Fikri Aji, and Timothy Baldwin. Bactrian-x: A
multilingual replicable instruction-following model with low-rank adaptation. arXiv preprint
arXiv:2305.15011, 2023a.
Haoran Li, Yulin Chen, Jinglong Luo, Yan Kang, Xiaojin Zhang, Qi Hu, Chunkit Chan, and
Yangqiu Song. Privacy in large language models: Attacks, defenses and future directions. ArXiv,
abs/2310.10383, 2023b. URL https://api.semanticscholar.org/CorpusID:264145758.
Lei Li, Yuwei Yin, Shicheng Li, Liang Chen, Peiyi Wang, Shuhuai Ren, Mukai Li, Yazheng Yang,
Jingjing Xu, Xu Sun, Lingpeng Kong, and Qi Liu. M3it: A large-scale dataset towards multi-
modal multilingual instruction tuning, 2023c.
Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou,
Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et al. Starcoder: may the source be with
you! arXiv preprint arXiv:2305.06161, 2023d.
Xin Li and Dan Roth. Learning question classifiers. In COLING 2002: The 19th International
Conference on Computational Linguistics, 2002. URL https://aclanthology.org/C02-1150.
49YifeiLi, ZeqiLin, ShizhuoZhang, QiangFu, BeiChen, Jian-GuangLou, andWeizhuChen. Making
large language models better reasoners with step-aware verifier, 2023e.
Yudong Li, Yuqing Zhang, Zhe Zhao, Linlin Shen, Weijie Liu, Weiquan Mao, and Hui Zhang. Csl:
A large-scale chinese scientific literature dataset, 2022.
Constantine Lignos, Nolan Holley, Chester Palen-Michel, and Jonne S√§lev√§. Toward more mean-
ingful resources for lower-resourced languages. In Findings of the Association for Computational
Linguistics: ACL 2022, pp. 523‚Äì532, Dublin, Ireland, May 2022. Association for Computational
Linguistics. doi: 10.18653/v1/2022.findings-acl.44. URL https://aclanthology.org/2022.fi
ndings-acl.44.
Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra Bhagavatula, Yejin Choi, and
Xiang Ren. CommonGen: A constrained text generation challenge for generative commonsense
reasoning. InFindings of the Association for Computational Linguistics: EMNLP 2020,pp.1823‚Äì
1840, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/20
20.findings-emnlp.165. URL https://aclanthology.org/2020.findings-emnlp.165.
Bill Yuchen Lin, Seyeon Lee, Xiaoyang Qiao, and Xiang Ren. Common sense beyond English:
Evaluating and improving multilingual language models for commonsense reasoning. In Pro-
ceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the
11th International Joint Conference on Natural Language Processing (Volume 1: Long Pa-
pers), pp. 1274‚Äì1287, Online, August 2021. Association for Computational Linguistics. doi:
10.18653/v1/2021.acl-long.102. URL https://aclanthology.org/2021.acl-long.102.
Kevin Lin, Oyvind Tafjord, Peter Clark, and Matt Gardner. Reasoning over paragraph effects in
situations. In EMNLP 2019 MRQA Workshop, pp. 58, 2019.
Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle
Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh
Koura, Vishrav Chaudhary, Brian O‚ÄôHoro, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva,
Mona Diab, Veselin Stoyanov, and Xian Li. Few-shot learning with multilingual generative lan-
guage models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language
Processing, pp. 9019‚Äì9052, Abu Dhabi, United Arab Emirates, December 2022. Association for
Computational Linguistics. URL https://aclanthology.org/2022.emnlp-main.616.
Fangyu Liu, Emanuele Bugliarello, Edoardo Maria Ponti, Siva Reddy, Nigel Collier, and Desmond
Elliott. Visually grounded reasoning across languages and cultures. In Proceedings of the 2021
Conference on Empirical Methods in Natural Language Processing, pp. 10467‚Äì10485, Online and
Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics.
doi: 10.18653/v1/2021.emnlp-main.818. URL https://aclanthology.org/2021.emnlp-main.
818.
ShayneLongpre, LeHou, TuVu, AlbertWebson, HyungWonChung, YiTay, DennyZhou, QuocV.
Le,BarretZoph,JasonWei,andAdamRoberts. Theflancollection: Designingdataandmethods
for effective instruction tuning. In Proceedings of the 40th International Conference on Machine
Learning, ICML‚Äô23. JMLR.org, 2023a.
Shayne Longpre, Robert Mahari, Anthony Chen, Naana Obeng-Marnu, Damien Sileo, William
Brannon, NiklasMuennighoff, NathanKhazam, JadKabbara, KartikPerisetla, XinyiWu, Enrico
Shippole, Kurt Bollacker, Tongshuang Wu, Luis Villa, Sandy Pentland, and Sara Hooker. The
data provenance initiative: A large scale audit of dataset licensing & attribution in ai, 2023b.
50Shayne Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny
Zhou, Jason Wei, Kevin Robinson, David Mimno, et al. A pretrainer‚Äôs guide to training
data: Measuring the effects of data age, domain coverage, quality, & toxicity. arXiv preprint
arXiv:2305.13169, 2023c.
Yanni Alexander Loukissas. All Data Are Local: Thinking Critically in a Data-Driven Society. MIT
Press, Cambridge, Massachusetts, 2019.
Lalita Lowphansirikul, Charin Polpanumas, Attapol T Rutherford, and Sarana Nutanong. A large
English‚ÄìThai parallel corpus from the web and machine-generated text. Language Resources and
Evaluation, 56(2):477‚Äì499, 2022.
Alexandra Luccioni and Joseph Viviano. What‚Äôs in the box? an analysis of undesirable con-
tent in the Common Crawl corpus. In Proceedings of the 59th Annual Meeting of the Asso-
ciation for Computational Linguistics and the 11th International Joint Conference on Natu-
ral Language Processing (Volume 2: Short Papers), pp. 182‚Äì189, Online, August 2021. Asso-
ciation for Computational Linguistics. doi: 10.18653/v1/2021.acl-short.24. URL https:
//aclanthology.org/2021.acl-short.24.
LuciaSpecia, NicolaCancedda, andMarcDymetman. ADatasetforAssessingMachineTranslation
Evaluation Metrics. International Conference on Language Resources and Evaluation, 2010.
Li Lucy, Suchin Gururangan, Luca Soldaini, Emma Strubell, David Bamman, Lauren Klein, and
Jesse Dodge. Aboutme: Using self-descriptions in webpages to document the effects of english
pretraining data filters, 2024.
Nils Lukas, A. Salem, Robert Sim, Shruti Tople, Lukas Wutschitz, and Santiago Zanella-B‚Äôeguelin.
Analyzing leakage of personally identifiable information in language models. 2023 IEEE Sympo-
sium on Security and Privacy (SP), pp. 346‚Äì363, 2023. URL https://api.semanticscholar.
org/CorpusID:256459554.
Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing
Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with
evol-instruct, 2023.
Risto Luukkonen, Ville Komulainen, Jouni Luoma, Anni Eskelinen, Jenna Kanerva, Hanna-Mari
Kupari, Filip Ginter, Veronika Laippala, Niklas Muennighoff, Aleksandra Piktus, et al. Fingpt:
Large generative models for a small language. arXiv preprint arXiv:2311.05640, 2023.
Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher
Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics: Human Language Technologies, pp. 142‚Äì150,
Portland, Oregon, USA, June 2011. Association for Computational Linguistics. URL http:
//www.aclweb.org/anthology/P11-1015.
Jean Maillard, Cynthia Gao, Elahe Kalbassi, Kaushik Ram Sadagopan, Vedanuj Goswami, Philipp
Koehn, Angela Fan, and Francisco Guzm√°n. Small data, big impact: Leveraging minimal data
for effective machine translation. In Proceedings of the 61st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers), pp. 2740‚Äì2756, Toronto, Canada, 2023.
Association for Computational Linguistics. URL https://aclanthology.org/2023.acl-long.
154.
51Max Marion, Ahmet √úst√ºn, Luiza Pozzobon, Alex Wang, Marzieh Fadaee, and Sara Hooker. When
less is more: Investigating data pruning for pretraining llms at scale, 2023.
Vukosi Marivate, Tshephisho Sefara, Vongani Chabalala, Keamogetswe Makhaya, Tumisho Mok-
gonyane, Rethabile Mokoena, and Abiodun Modupe. Investigating an approach for low resource
language dataset creation, curation and classification: Setswana and sepedi. In Proceedings of
the first workshop on Resources for African Indigenous Languages, pp. 15‚Äì20, Marseille, France,
May 2020. European Language Resources Association (ELRA). ISBN 979-10-95546-60-3. URL
https://aclanthology.org/2020.rail-1.3.
maxbartolo. AdversarialQA D(BERT). https://huggingface.co/datasets/adversarial_qa/v
iewer/dbert, 2023a. Accessed: 2023-11-28.
maxbartolo. AdversarialQA D(BiDAF). https://huggingface.co/datasets/adversarial_qa/v
iewer/dbidaf, 2023b. Accessed: 2023-11-28.
maxbartolo. AdversarialQA D(RoBERTa). https://huggingface.co/datasets/adversarial_qa
/viewer/droberta, 2023c. Accessed: 2023-11-28.
Mike Maxwell and Baden Hughes. Frontiers in linguistic annotation for lower-density languages.
In Proceedings of the workshop on frontiers in linguistically annotated corpora 2006, pp. 29‚Äì37,
2006.
Stephen Mayhew, Terra Blevins, Shuheng Liu, Marek ≈†uppa, Hila Gonen, Joseph Marvin Imperial,
B√∂rjeF.Karlsson,PeiqinLin,NikolaLjube≈°iƒá,LJMiranda,BarbaraPlank,ArijRiabi,andYuval
Pinter. Universal NER: A Gold-Standard Multilingual Named Entity Recognition Benchmark.
arXiv preprint arXiv:2311.09122, 2023.
Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. The natural language
decathlon: Multitask learning as question answering. arXiv preprint arXiv:1806.08730, 2018.
Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. A
survey on bias and fairness in machine learning. ACM computing surveys (CSUR), 54(6):1‚Äì35,
2021.
Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. Can a suit of armor conduct
electricity? a new dataset for open book question answering. In EMNLP, 2018.
Sewon Min, Mike Lewis, Luke Zettlemoyer, and Hannaneh Hajishirzi. Metaicl: Learning to learn
in context. arXiv preprint arXiv:2110.15943, 2021.
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Cross-task generaliza-
tion via natural language crowdsourcing instructions. In ACL, 2022.
Steven Moran and Christian Chiarcos. 4 linguistic linked open data and under-resourced languages:
From collection to application. Development of Linguistic Linked Open Data Resources for Col-
laborative Data-Intensive Research in the Language Sciences, pp. 39, 2020.
Benedikt Morschheuser, Juho Hamari, Jonna Koivisto, and Alexander Maedche. Gamified crowd-
sourcing: Conceptualization, literature review, and future agenda. International Journal of
Human-Computer Studies, 106:26‚Äì43, 2017. ISSN 1071-5819. doi: https://doi.org/10.1016/
j.ijhcs.2017.04.005. URL https://www.sciencedirect.com/science/article/pii/S1071581
917300642.
52NiklasMuennighoff,QianLiu,ArmelZebaze,QinkaiZheng,BinyuanHui,TerryYueZhuo,Swayam
Singh, Xiangru Tang, Leandro von Werra, and Shayne Longpre. Octopack: Instruction tuning
code large language models. arXiv preprint arXiv:2308.07124, 2023a.
NiklasMuennighoff,AlexanderMRush,BoazBarak,TevenLeScao,AleksandraPiktus,Nouamane
Tazi, Sampo Pyysalo, Thomas Wolf, and Colin Raffel. Scaling data-constrained language models.
arXiv preprint arXiv:2305.16264, 2023b.
Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven
LeScao,MSaifulBari,ShengShen,ZhengXinYong,HaileySchoelkopf,XiangruTang,Dragomir
Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson,
Edward Raff, and Colin Raffel. Crosslingual generalization through multitask finetuning. In
Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers), pp. 15991‚Äì16111, Toronto, Canada, July 2023c. Association for Computational
Linguistics. URL https://aclanthology.org/2023.acl-long.891.
Shamsuddeen Muhammad, Idris Abdulmumin, Abinew Ayele, Nedjma Ousidhoum, David Adelani,
Seid Yimam, Ibrahim Ahmad, Meriem Beloucif, Saif Mohammad, Sebastian Ruder, Oumaima
Hourrane, Alipio Jorge, Pavel Brazdil, Felermino Ali, Davis David, Salomey Osei, Bello Shehu-
Bello, Falalu Lawan, Tajuddeen Gwadabe, Samuel Rutunda, Tadesse Belay, Wendimu Messelle,
Hailu Balcha, Sisay Chala, Hagos Gebremichael, Bernard Opoku, and Stephen Arthur. AfriSenti:
A Twitter sentiment analysis benchmark for African languages. In Houda Bouamor, Juan Pino,
and Kalika Bali (eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural
LanguageProcessing,pp.13968‚Äì13981,Singapore,December2023.AssociationforComputational
Linguistics. doi: 10.18653/v1/2023.emnlp-main.862. URL https://aclanthology.org/2023.
emnlp-main.862.
Carol Myers-Scotton. Code-switching. The handbook of sociolinguistics, pp. 217‚Äì237, 2017.
Ranjita Naik, Varun Chandrasekaran, Mert Yuksekgonul, Hamid Palangi, and Besmira Nushi. Di-
versity of thought improves reasoning abilities of large language models, 2023.
Gabriel Nakamura, Bruno Soares, Val√©rio Pillar, Jos√© Diniz-Filho, and Leandro Duarte. Three
pathways to better recognize the expertise of global south researchers. npj Biodiversity, 08 2023.
doi: 10.1038/s44185-023-00021-7.
Ramesh Nallapati, Bowen Zhou, Cicero Nogueira dos santos, Caglar Gulcehre, and Bing Xiang.
Abstractive text summarization using sequence-to-sequence rnns and beyond, 2016.
Tarek Naous, Michael Joseph Ryan, and Wei Xu. Having beer after prayer? measuring cultural
bias in large language models. ArXiv, abs/2305.14456, 2023. URL https://api.semanticscho
lar.org/CorpusID:258865272.
Shashi Narayan, Shay B. Cohen, and Mirella Lapata. Don‚Äôt give me the details, just the summary!
topic-aware convolutional neural networks for extreme summarization. ArXiv, abs/1808.08745,
2018.
Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. Feder Cooper, Daphne Ip-
polito, Christopher A. Choquette-Choo, Eric Wallace, Florian Tram√®r, and Katherine Lee. Scal-
able extraction of training data from (production) language models, 2023.
53Huu Nguyen, Sameer Suri, Ken Tsui, and Christoph Schuhmann. The open instruction generalist
(oig) dataset. https://laion.ai/blog/oig-dataset/, 2023.
JinjieNi,FuzhaoXue,KabirJain,MahirHiteshShah,ZangweiZheng,andYangYou. Instructionin
the wild: A user-based instruction dataset. https://github.com/XueFuzhao/InstructionWild,
2023.
Gabriel Nicholas and Aliya Bhatia. Lost in translation: Large language models in non-english
content analysis, 2023.
Joel Niklaus, Veton Matoshi, Matthias St√ºrmer, Ilias Chalkidis, and Daniel E Ho. Multilegalpile:
A 689gb multilingual legal corpus. arXiv preprint arXiv:2306.02069, 2023.
NLLB-Team, Marta R. Costa-juss√†, James Cross, Onur √áelebi, Maha Elbayad, Kenneth Heafield,
Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler
Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez,
Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe,
Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov,
Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzm√°n, Philipp Koehn, Alexandre
Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang. No language
left behind: Scaling human-centered machine translation, 2022.
Gianluca Nogara, Francesco Pierri, Stefano Cresci, Luca Luceri, Petter T√∂rnberg, and Silvia Gior-
dano. Toxic bias: Perspective api misreads german as more toxic, 2023.
Odunayo Ogundepo, Tajuddeen Gwadabe, Clara Rivera, Jonathan Clark, Sebastian Ruder, David
Adelani, Bonaventure Dossou, Abdou Diop, Claytone Sikasote, Gilles Hacheme, Happy Buzaaba,
IgnatiusEzeani, RooweitherMabuya, SalomeyOsei, ChrisEmezue, AlbertKahira, Shamsuddeen
Muhammad, Akintunde Oladipo, Abraham Owodunni, Atnafu Tonja, Iyanuoluwa Shode, Akari
Asai, Anuoluwapo Aremu, Ayodele Awokoya, Bernard Opoku, Chiamaka Chukwuneke, Chris-
tine Mwase, Clemencia Siro, Stephen Arthur, Tunde Ajayi, Verrah Otiende, Andre Rubungo,
Boyd Sinkala, Daniel Ajisafe, Emeka Onwuegbuzia, Falalu Lawan, Ibrahim Ahmad, Jesujoba
Alabi, Chinedu Mbonu, Mofetoluwa Adeyemi, Mofya Phiri, Orevaoghene Ahia, Ruqayya Iro,
and Sonia Adhiambo. Afriqa: Cross-lingual open-retrieval question answering for african lan-
guages. In Houda Bouamor, Juan Pino, and Kalika Bali (eds.), Findings of the Association
for Computational Linguistics: EMNLP 2023, pp. 14957‚Äì14972, Singapore, December 2023. As-
sociation for Computational Linguistics. doi: 10.18653/v1/2023.findings-emnlp.997. URL
https://aclanthology.org/2023.findings-emnlp.997.
Jessica Ojo, Kelechi Ogueji, Pontus Stenetorp, and David I. Adelani. How good are large language
models on african languages?, 2023.
PedroJavierOrtizSu‚Äôarez, BenoitSagot, andLaurentRomary. Asynchronouspipelinesforprocess-
ing huge corpora on medium to low resource infrastructures. In Piotr Ba≈Ñski, Adrien Barbaresi,
Hanno Biber, Evelyn Breiteneder, Simon Clematide, Marc Kupietz, Harald L"ungen, and Caro-
lineIliadi(eds.),7thWorkshopontheChallengesintheManagementofLargeCorpora(CMLC-7),
ProceedingsoftheWorkshoponChallengesintheManagementofLargeCorpora(CMLC-7)2019.
Cardiff, 22nd July 2019, pp. 9 ‚Äì 16, Mannheim, 2019. Leibniz-Institut f"ur Deutsche Sprache.
doi: 10.14618/ids-pub-9021. URL http://nbn-resolving.de/urn:nbn:de:bsz:mh39-90215.
osyvokon. UA-GEC instruction tuning . https://huggingface.co/datasets/osyvokon/ua_gec_
instruction_tuning, 2023. Accessed: 2023-11-28.
54Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong
Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kel-
ton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike,
and Ryan Lowe. Training language models to follow instructions with human feedback, 2022.
Bo Pang and Lillian Lee. Seeing stars: Exploiting class relationships for sentiment categorization
with respect to rating scales. In Proceedings of the ACL, 2005.
Denis Paperno, Germ√°n Kruszewski, Angeliki Lazaridou, Quan Ngoc Pham, Raffaella Bernardi,
Sandro Pezzelle, Marco Baroni, Gemma Boleda, and Raquel Fern√°ndez. The lambada dataset:
Word prediction requiring a broad discourse context, 2016.
Michael Park, Erin Leahey, and Russell J. Funk. Papers and patents are becoming less disruptive
over time. Nature, 613:138‚Äì144, 2023. URL https://api.semanticscholar.org/CorpusID:
255466666.
Kenny Peng, Arunesh Mathur, and Arvind Narayanan. Mitigating dataset harms requires steward-
ship: Lessons from 1000 papers. arXiv preprint arXiv:2108.02922, 2021.
Laura Perez-Beltrachini and Mirella Lapata. Models and datasets for cross-lingual summarisation.
In Proceedings of The 2021 Conference on Empirical Methods in Natural Language Processing,
Punta Cana, Dominican Republic, 2021.
Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick S. H. Lewis, Majid Yazdani, Nicola De
Cao,JamesThorne,YacineJernite,VladimirKarpukhin,JeanMaillard,VassilisPlachouras,Tim
Rockt√§schel,andSebastianRiedel. KILT:abenchmarkforknowledgeintensivelanguagetasks. In
Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-T√ºr, Iz Beltagy, Steven
Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou (eds.), Proceedings of the 2021
Conference of the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021, pp. 2523‚Äì2544.
Association for Computational Linguistics, 2021. URL https://www.aclweb.org/anthology/2
021.naacl-main.200/.
Martin Petty. Explainer: Why is Myanmar‚Äôs military holding an election?, 2023. URL https:
//www.reuters.com/world/asia-pacific/why-is-myanmars-military-holding-an-electio
n-2023-03-29/. Accessed on Jan. 17, 2024.
Mohammad Taher Pilehvar and Jose Camacho-Collados. Wic: the word-in-context dataset for
evaluating context-sensitive meaning representations, 2019.
McKevitt C Pinel C, Prainsack B. Caring for data: Value creation in a data-intensive research
laboratory. Social Studies of Science, 50(2):175‚Äì197, April 2020.
Edoardo Maria Ponti, Goran Glava≈°, Olga Majewska, Qianchu Liu, Ivan Vuliƒá, and Anna Ko-
rhonen. Xcopa: A multilingual dataset for causal commonsense reasoning. arXiv preprint
arXiv:2005.00333, 2020.
Maja Popoviƒá. chrF: character n-gram F-score for automatic MT evaluation. In Proceedings of the
Tenth Workshop on Statistical Machine Translation, pp. 392‚Äì395, Lisbon, Portugal, September
2015. Association for Computational Linguistics. doi: 10.18653/v1/W15-3049. URL https:
//aclanthology.org/W15-3049.
55Matt Post. A call for clarity in reporting BLEU scores. In Proceedings of the Third Con-
ference on Machine Translation: Research Papers, pp. 186‚Äì191, Brussels, Belgium, Octo-
ber 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-6319. URL
https://aclanthology.org/W18-6319.
Adithya Pratapa, Rishubh Gupta, and Teruko Mitamura. Multilingual event linking to Wikidata.
In Proceedings of the Workshop on Multilingual Information Access (MIA), pp. 37‚Äì58, Seattle,
USA, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.mia-1.5.
URL https://aclanthology.org/2022.mia-1.5.
Danti Pudjiati, Ninuk Lustyantie, Ifan Iskandar, and Tira Nur Fitria. Post-editing of machine
translation: Creating a better translation of cultural specific terms. Language Circle: Journal of
Language and Literature, 17(1):61‚Äì73, 2022.
Cornelius Puschmann and Jean Burgess. Big data, big questions| metaphors of big data. Interna-
tional Journal of Communication, 8(0), 2014.
Mahima Pushkarna, Andrew Zaldivar, and Oddur Kjartansson. Data cards: Purposeful and trans-
parent dataset documentation for responsible ai. In Proceedings of the 2022 ACM Conference
on Fairness, Accountability, and Transparency, FAccT ‚Äô22, pp. 1776‚Äì1826, New York, NY, USA,
2022. Association for Computing Machinery. ISBN 9781450393522. doi: 10.1145/3531146.3533
231. URL https://doi.org/10.1145/3531146.3533231.
PyThaiNLP. scb_mt_2020_en2th_prompt. https://huggingface.co/datasets/pythainlp/sc
b_mt_2020_en2th_prompt, 2023a. Accessed: 2023-11-29.
PyThaiNLP. scb_mt_2020_th2en_prompt. https://huggingface.co/datasets/pythainlp/sc
b_mt_2020_th2en_prompt, 2023b. Accessed: 2023-11-29.
PyThaiNLP. Thai-Pos-prompt. https://huggingface.co/datasets/pythainlp/Thai-Pos-pro
mpt, 2023c. Accessed: 2023-11-29.
PyThaiNLP. thai_usembassy_en2th_prompt. https://huggingface.co/datasets/pythainlp/
thai_usembassy_en2th_prompt, 2023d. Accessed: 2023-11-29.
PyThaiNLP. thai_usembassy_th2en_prompt. https://huggingface.co/datasets/pythainlp/
thai_usembassy_th2en_prompt, 2023e. Accessed: 2023-11-29.
PyThaiNLP. thai-wiktionary-prompt. https://huggingface.co/datasets/pythainlp/thai-wik
tionary-prompt, 2023f. Accessed: 2023-11-29.
Alessandro Raganato, Tommaso Pasini, Jose Camacho-Collados, and Mohammad Taher Pilehvar.
XL-WiC: A multilingual benchmark for evaluating semantic contextualization. In Proceedings
of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp.
7193‚Äì7206, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v
1/2020.emnlp-main.584. URL https://aclanthology.org/2020.emnlp-main.584.
Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. Explain yourself!
leveraging language models for commonsense reasoning. In Proceedings of the 2019 Conference
of the Association for Computational Linguistics (ACL2019), 2019. URL https://arxiv.org/
abs/1906.02361.
56PranavRajpurkar,JianZhang,KonstantinLopyrev,andPercyLiang. SQuAD:100,000+Questions
for Machine Comprehension of Text. arXiv e-prints, art. arXiv:1606.05250, 2016.
SivaReddy, DanqiChen, andChristopherD.Manning. CoQA:Aconversationalquestionanswering
challenge. Transactions of the Association for Computational Linguistics, 7:249‚Äì266, 2019. doi:
10.1162/tacl_a_00266. URL https://aclanthology.org/Q19-1016.
NilsReimersandIrynaGurevych.Sentence-bert: Sentenceembeddingsusingsiamesebert-networks.
arXiv preprint arXiv:1908.10084, 2019.
Reuters. Explainer: WhatishappeningbetweenArmeniaandAzerbaijanoverNagorno-Karabakh?,
2023. URL https://www.reuters.com/world/what-is-happening-between-armenia-azerb
aijan-over-nagorno-karabakh-2023-09-19/. Accessed on Jan. 17, 2024.
John R Rickford, Julie Sweetland, Angela E Rickford, and Thomas Grano. African American,
Creole, and other vernacular Englishes in education: A bibliographic resource. Routledge, 2012.
Nathaniel R. Robinson, Perez Ogayo, David R. Mortensen, and Graham Neubig. Chatgpt mt:
Competitive for high- (but not low-) resource languages. ArXiv, abs/2309.07423, 2023. URL
https://api.semanticscholar.org/CorpusID:261824661.
AnnaRogers,OlgaKovaleva,MatthewDowney,andAnnaRumshisky.GettingclosertoAIcomplete
question answering: A set of prerequisite real tasks. In The Thirty-Fourth AAAI Conference
on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial
Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in
Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pp. 8722‚Äì8731.
AAAI Press, 2020. URL https://aaai.org/ojs/index.php/AAAI/article/view/6398.
Raf Van Rooy. Language or Dialect? The History of a Conceptual Pair. Oxford University Press,
2021.
Alexander M. Rush, Sumit Chopra, and Jason Weston. A neural attention model for abstractive
sentence summarization. Proceedings of the 2015 Conference on Empirical Methods in Natural
Language Processing, 2015. doi: 10.18653/v1/d15-1044. URL http://dx.doi.org/10.18653/v1
/D15-1044.
Jon Saad-Falcon, Joe Barrow, Alexa Siu, Ani Nenkova, Ryan A Rossi, and Franck Dernoncourt.
Pdftriage: Questionansweringoverlong,structureddocuments. arXivpreprintarXiv:2309.08872,
2023.
Marta Sabou, Kalina Bontcheva, and Arno Scharl. Crowdsourcing research opportunities: Lessons
from natural language processing. In Proceedings of the 12th International Conference on Knowl-
edge Management and Knowledge Technologies, i-KNOW ‚Äô12, New York, NY, USA, 2012. Asso-
ciation for Computing Machinery. ISBN 9781450312424. doi: 10.1145/2362456.2362479. URL
https://doi.org/10.1145/2362456.2362479.
Amrita Saha, Rahul Aralikatte, Mitesh M. Khapra, and Karthik Sankaranarayanan. DuoRC: To-
wards Complex Language Understanding with Paraphrased Reading Comprehension. In Meeting
of the Association for Computational Linguistics (ACL), 2018.
57Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and
Lora M Aroyo. ‚Äúeveryone wants to do the model work, not the data work‚Äù: Data cascades in high-
stakes ai. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems,
CHI‚Äô21,NewYork,NY,USA,2021.AssociationforComputingMachinery. ISBN9781450380966.
doi: 10.1145/3411764.3445518. URL https://doi.org/10.1145/3411764.3445518.
Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine
Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker,
Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, De-
bajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen,
Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen,
Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Teven Le
Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M Rush. Multitask prompted
training enables zero-shot task generalization. In International Conference on Learning Repre-
sentations, 2022. URL https://openreview.net/forum?id=9Vrb9D0WI4.
Maarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. Socialiqa: Common-
sense reasoning about social interactions, 2019.
Beatrice Savoldi, Marco Gaido, Luisa Bentivogli, Matteo Negri, and Marco Turchi. Gender bias in
machine translation, 2021.
Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Iliƒá, Daniel Hesslow, Roman
Castagn√©, Alexandra Sasha Luccioni, Fran√ßois Yvon, Matthias Gall√©, et al. Bloom: A 176b-
parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100, 2022a.
Teven Le Scao, Thomas Wang, Daniel Hesslow, Lucile Saulnier, Stas Bekman, M Saiful Bari, Stella
Bideman, Hady Elsahar, Niklas Muennighoff, Jason Phang, et al. What language model to train
if you have one million gpu hours? arXiv preprint arXiv:2210.15424, 2022b.
Reva Schwartz, Apostol Vassilev, Kristen Greene, Lori Perine, Andrew Burt, Patrick Hall, et al.
Towards a standard for identifying and managing bias in artificial intelligence. NIST special
publication, 1270(10.6028), 2022.
Nick Seaver. Care and scale: Decorrelative ethics in algorithmic recommendation. Cultural Anthro-
pology, 36(3):509‚Äì537, 2021.
UN Secretariat. International decade of indigenous languages, 2022‚Äì2032: Global action plan:
note/by the secretariat, 2022.
Abigail See, Peter J. Liu, and Christopher D. Manning. Get to the point: Summarization with
pointer-generator networks. CoRR, abs/1704.04368, 2017. URL http://arxiv.org/abs/1704.0
4368.
Priyanka Sen, Alham Fikri Aji, and Amir Saffari. Mintaka: A complex, natural, and multilingual
dataset for end-to-end question answering. In Proceedings of the 29th International Conference
on Computational Linguistics, pp. 1604‚Äì1619, Gyeongju, Republic of Korea, October 2022. Inter-
national Committee on Computational Linguistics. URL https://aclanthology.org/2022.co
ling-1.138.
Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with
subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational
58Linguistics (Volume 1: Long Papers), pp. 1715‚Äì1725, Berlin, Germany, August 2016. Association
for Computational Linguistics. doi: 10.18653/v1/P16-1162. URL https://aclanthology.org
/P16-1162.
Shafagh. Aya Persian Instruction pn Summary. https://huggingface.co/datasets/Shafagh/ay
a_persian_instruction_pn-summary, 2023a. Accessed: 2023-11-28.
Shafagh. Aya Persian Instruction pn Summary Title. https://huggingface.co/datasets/Shaf
agh/aya_persian_instruction_pn-summary-title, 2023b. Accessed: 2023-11-28.
Chih Chieh Shao, Trois Liu, Yuting Lai, Yiying Tseng, and Sam Tsai. Drcd: a chinese machine
reading comprehension dataset, 2019.
Jack Sidnell and N. J. Enfield. Language diversity and social action: A third locus of linguistic
relativity. Current Anthropology, 53(3):302‚Äì333, 2012.
Kathleen Siminyu, Godson Kalipe, Davor Orlic, Jade Z. Abbott, Vukosi Marivate, Sackey Freshia,
PrateekSibal,BhanuNeupane,DavidIfeoluwaAdelani,AmeliaV.Taylor,JamiilToureAli,Kevin
Degila, Momboladji Balogoun, Thierno Ibrahima Diop, Davis David, Chayma Fourati, Hatem
Haddad,andMalekNaski.AI4D-africanlanguageprogram.InKathleenSiminyu,JuliaKreutzer,
Hady Elsahar, Vukosi Marivate, Nishant Subramani, Jade Z. Abbott, and Bernardt Duvenhage
(eds.), 2nd AfricaNLP Workshop Proceedings, AfricaNLP@EACL 2021, Virtual Event, April 19,
2021, 2021. URL https://arxiv.org/abs/2104.02516.
Gary F. Simons. Two centuries of spreading language loss. Proceedings of the Linguistic Society of
America, 4(1):27:1‚Äì12, Mar. 2019. doi: 10.3765/plsa.v4i1.4532. URL https://journals.lingu
isticsociety.org/proceedings/index.php/PLSA/article/view/4532.
Amanpreet Singh, Mike D‚ÄôArcy, Arman Cohan, Doug Downey, and Sergey Feldman. SciRepEval:
A Multi-Format Benchmark for Scientific Document Representations. ArXiv, abs/2211.13308,
2022.
Luca Soldaini, Rodney Kinney, Akshita Bhagia, Dustin Schwenk, David Atkinson, Russell Authur,
Ben Bogin, Khyathi Chandu, Jennifer Dumas, Yanai Elazar, Valentin Hofmann, Ananya Harsh
Jha, Sachin Kumar, Li Lucy, Xinxi Lyu, Ian Magnusson, Jacob Morrison, Niklas Muennighoff,
Aakanksha Naik, Crystal Nam, Matthew E. Peters, Abhilasha Ravichander, Kyle Richardson,
Zejiang Shen, Emma Strubell, Nishant Subramani, Oyvind Tafjord, Evan Pete Walsh, Hannaneh
Hajishirzi,NoahA.Smith,LukeZettlemoyer,IzBeltagy,DirkGroeneveld,JesseDodge,andKyle
Lo. Dolma: An Open Corpus of Three Trillion Tokens for Language Model Pretraining Research.
arXiv preprint, 2024.
Lucia Specia and Atefeh Farzindar. Estimating machine translation post-editing effort with HTER.
In Proceedings of the Second Joint EM+/CNGL Workshop: Bringing MT to the User: Research
on Integrating MT in the Translation Industry, pp. 33‚Äì43, Denver, Colorado, USA, November 4
2010. Association for Machine Translation in the Americas. URL https://aclanthology.org/2
010.jec-1.5.
Bernard Spolsky. Language policy in french colonies and after independence. Current Issues in
Language Planning, 19(3):231‚Äì315, 2018. doi: 10.1080/14664208.2018.1444948.
Vivek Srivastava and Mayank Singh. Challenges and considerations with code-mixed nlp for mul-
tilingual societies, 2021.
59Luke Stark and Anna Lauren Hoffmann. Data is the new what? popular metaphors & professional
ethics in emerging data culture. Journal of Cultural Analytics, 4(1), 2019.
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford,
Dario Amodei, and Paul F Christiano. Learning to summarize with human feedback. Advances
in Neural Information Processing Systems, 33:3008‚Äì3021, 2020.
Stephanie Strassel and Jennifer Tracey. LORELEI language packs: Data, tools, and resources
for technology development in low resource languages. In Proceedings of the Tenth International
ConferenceonLanguageResourcesandEvaluation(LREC‚Äô16),pp.3273‚Äì3280,Portoro≈æ,Slovenia,
May 2016. European Language Resources Association (ELRA). URL https://aclanthology.o
rg/L16-1521.
JiaoSun,ThibaultSellam,ElizabethClark,TuVu,TimothyDozat,DanGarrette,AdityaSiddhant,
Jacob Eisenstein, and Sebastian Gehrmann. Dialect-robust evaluation of generated text. In
Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers), pp. 6010‚Äì6028, Toronto, Canada, July 2023. Association for Computational
Linguistics. URL https://aclanthology.org/2023.acl-long.331.
SuryaKrishna02. Aya Telugu Food Recipes. https://huggingface.co/datasets/SuryaKrishna
02/aya-telugu-food-recipes, 2023a. Accessed: 2023-11-28.
SuryaKrishna02. Aya Telugu Jokes. https://huggingface.co/datasets/SuryaKrishna02/aya-t
elugu-jokes, 2023b. Accessed: 2023-11-28.
SuryaKrishna02. Aya Telugu News Articles. https://huggingface.co/datasets/SuryaKrishna
02/aya-telugu-news-articles, 2023c. Accessed: 2023-11-28.
SuryaKrishna02. Aya Telugu Paraphrase. https://huggingface.co/datasets/SuryaKrishna02
/aya-telugu-paraphrase, 2023d. Accessed: 2023-11-28.
SuryaKrishna02. Aya Telugu Poems. https://huggingface.co/datasets/SuryaKrishna02/aya
-telugu-poems, 2023e. Accessed: 2023-11-28.
Masahiro Suzuki, Masanori Hirano, and Hiroki Sakaji. From base to conversational: Japanese
instruction dataset and tuning large language models. arXiv preprint arXiv:2309.03412, 2023.
syntaxshill. Arpa aya. https://huggingface.co/datasets/syntaxshill/arpa-aya, 2023.
Accessed: 2023-11-28.
OleksiySyvokon, OlenaNahorna, PavloKuchmiichuk, andNastasiiaOsidach. UA-GEC:Grammat-
ical error correction and fluency corpus for the Ukrainian language. In Proceedings of the Second
Ukrainian Natural Language Processing Workshop (UNLP),pp.96‚Äì102, Dubrovnik, Croatia, May
2023. Association for Computational Linguistics. URL https://aclanthology.org/2023.unlp
-1.12.
Oyvind Tafjord, Peter Clark, Matt Gardner, Wen-tau Yih, and Ashish Sabharwal. Quarel: A
dataset and models for answering questions about qualitative relationships. In Proceedings of the
AAAI Conference on Artificial Intelligence, volume 33, pp. 7063‚Äì7071, 2019a.
Oyvind Tafjord, Matt Gardner, Kevin Lin, and Peter Clark. Quartz: An open-domain dataset of
qualitative relationship questions. arXiv preprint arXiv:1909.03553, 2019b.
60TahmidH. Annotated News Summary. https://huggingface.co/datasets/TahmidH/annotate
d_news_summary, 2023. Accessed: 2023-11-28.
NiketTandon,BhavanaDalviMishra,KeisukeSakaguchi,AntoineBosselut,andPeterClark. Wiqa:
A dataset for "what if..." reasoning over procedural text. arXiv:1909.04739v1, 2019.
Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu,
andAngelaFan. Multilingualtranslationfromdenoisingpre-training. Findings of the Association
for Computational Linguistics: ACL-IJCNLP, 2021. doi: 10.18653/v1/2021.findings-acl.304.
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy
Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.
https://github.com/tatsu-lab/stanford_alpaca, 2023.
Tellarin.ai. LLM Japanese Dataset Vanilla Aya Format. https://huggingface.co/datasets/te
llarin-ai/llm-japanese-dataset-vanilla-aya-format, 2023a. Accessed: 2023-11-28.
Tellarin.ai. NTX LLM Instructions. https://huggingface.co/datasets/tellarin-ai/ntx_llm_
instructions, 2023b. Accessed: 2023-11-28.
theblackcat102. Joke explaination. https://huggingface.co/datasets/theblackcat102/joke_
explaination, 2023. Accessed: 2023-11-29.
J√∂rg Tiedemann. Parallel data, tools and interfaces in opus. In Nicoletta Calzolari (Conference
Chair), Khalid Choukri, Thierry Declerck, Mehmet Ugur Dogan, Bente Maegaard, Joseph Mari-
ani, Jan Odijk, and Stelios Piperidis (eds.), Proceedings of the Eight International Conference on
Language Resources and Evaluation (LREC‚Äô12), Istanbul, Turkey, may2012.EuropeanLanguage
Resources Association (ELRA). ISBN 978-2-9517408-7-7.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-
lay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher,
Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy
Fu,WenyinFu,BrianFuller,CynthiaGao,VedanujGoswami,NamanGoyal,AnthonyHartshorn,
Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel
Kloumann,ArtemKorenev,PunitSinghKoura,Marie-AnneLachaux,ThibautLavril,JenyaLee,
Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,
Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi,
Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh
Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov,
Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert
Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat
models, 2023.
Ming Tu, Guangtao Wang, Jing Huang, Yun Tang, Xiaodong He, and Bowen Zhou. Multi-hop
reading comprehension across multiple documents by reasoning over heterogeneous graphs, 2019.
TurkuNLP. Turku Paraphrase Corpus. https://huggingface.co/datasets/TurkuNLP/turku_p
araphrase_corpus, 2023. Accessed: 2023-11-28.
Universal NER. UNER LLM Instructions. https://huggingface.co/datasets/universalner/u
ner_llm_instructions, 2023. Accessed: 2023-11-28.
61Gorka Urbizu, I√±aki San Vicente, Xabier Saralegi, and Ander Corral. Not enough data to pre-train
your language model? MT to the rescue! In Findings of the Association for Computational Lin-
guistics: ACL 2023, pp. 3826‚Äì3836, Toronto, Canada, July 2023. Association for Computational
Linguistics. URL https://aclanthology.org/2023.findings-acl.235.
Eva Vanmassenhove, Dimitar Shterionov, and Matthew Gwilliam. Machine translationese: Effects
of algorithmic bias on linguistic complexity in machine translation. In Proceedings of the 16th
Conference of the European Chapter of the Association for Computational Linguistics: Main
Volume, pp. 2203‚Äì2213, Online, April 2021. Association for Computational Linguistics. doi:
10.18653/v1/2021.eacl-main.188. URL https://aclanthology.org/2021.eacl-main.188.
Aniket Vashishtha, Kabir Ahuja, and Sunayana Sitaram. On evaluating and mitigating gender
biases in multilingual settings, 2023.
C√©cile B. Vigouroux. Francophonie. Annual Review of Anthropology, 42(1):379‚Äì397, 2013. doi:
10.1146/annurev-anthro-092611-145804. URL https://doi.org/10.1146/annurev-anthro-0
92611-145804.
Alexander Wan, Eric Wallace, Sheng Shen, and Dan Klein. Poisoning language models during
instruction tuning, 2023.
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman.
Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv
preprint arXiv:1804.07461, 2018.
AlexWang,YadaPruksachatkun,NikitaNangia,AmanpreetSingh,JulianMichael,FelixHill,Omer
Levy, and Samuel R Bowman. Superglue: A stickier benchmark for general-purpose language
understanding systems. arXiv preprint arXiv:1905.00537, 2019.
Guangyu Wang, Guoxing Yang, Zongxin Du, Longjun Fan, and Xiaohu Li. Clinicalgpt: Large
language models finetuned with diverse medical data and comprehensive evaluation, 2023.
Jun Wang, Benjamin Rubinstein, and Trevor Cohn. Measuring and mitigating name biases in
neural machine translation. In Proceedings of the 60th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), pp. 2576‚Äì2590, Dublin, Ireland, May 2022a.
Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-long.184. URL https:
//aclanthology.org/2022.acl-long.184.
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and
Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions.
ArXiv preprint, abs/2212.10560, 2022b. URL https://arxiv.org/abs/2212.10560.
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, An-
jana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, Eshaan
Pathak, Giannis Karamanolakis, Haizhi Gary Lai, Ishan Purohit, Ishani Mondal, Jacob Ander-
son, Kirby Kuznia, Krima Doshi, Maitreya Patel, Kuntal Kumar Pal, Mehrad Moradshahi, Mihir
Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravsehaj Singh
Puri, Rushang Karia, Shailaja Keyur Sampat, Savan Doshi, Siddhartha Mishra, Sujan Reddy,
Sumanta Patro, Tanay Dixit, Xudong Shen, Chitta Baral, Yejin Choi, Noah A. Smith, Hannaneh
Hajishirzi, and Daniel Khashabi. Super-naturalinstructions: Generalization via declarative in-
structions on 1600+ nlp tasks, 2022c.
62Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, An-
jana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al.
Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks. arXiv
preprint arXiv:2204.07705, 2022d.
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei,
Atharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, Es-
haan Pathak, Giannis Karamanolakis, Haizhi Lai, Ishan Purohit, Ishani Mondal, Jacob An-
derson, Kirby Kuznia, Krima Doshi, Kuntal Kumar Pal, Maitreya Patel, Mehrad Moradshahi,
Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravse-
haj Singh Puri, Rushang Karia, Savan Doshi, Shailaja Keyur Sampat, Siddhartha Mishra,
Sujan Reddy A, Sumanta Patro, Tanay Dixit, and Xudong Shen. Super-NaturalInstructions:
Generalization via declarative instructions on 1600+ NLP tasks. In Proceedings of the 2022
Conference on Empirical Methods in Natural Language Processing, pp. 5085‚Äì5109, Abu Dhabi,
United Arab Emirates, December 2022e. Association for Computational Linguistics. URL
https://aclanthology.org/2022.emnlp-main.340.
AlexWarstadt,AmanpreetSingh,andSamuelRBowman. Neuralnetworkacceptabilityjudgments.
arXiv preprint arXiv:1805.12471, 2018.
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,
Andrew M. Dai, and Quoc V Le. Finetuned language models are zero-shot learners. In Interna-
tional Conference on Learning Representations, 2022a. URL https://openreview.net/forum?i
d=gEZrGCozdqR.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny
Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in
Neural Information Processing Systems, 35:24824‚Äì24837, 2022b.
Xiangpeng Wei, Haoran Wei, Huan Lin, Tianhao Li, Pei Zhang, Xingzhang Ren, Mei Li, Yu Wan,
Zhiwei Cao, Binbin Xie, et al. Polylm: An open source polyglot large language model. arXiv
preprint arXiv:2307.06018, 2023.
JohannesWelbl, NelsonFLiu, andMattGardner. Crowdsourcingmultiplechoicesciencequestions.
arXiv preprint arXiv:1707.06209, 2017.
Richard E West, Timothy Newby, Zui Cheng, Alyssa Erickson, and Kyle Clements. Acknowledging
all learning: Alternative, micro, and open credentials. Handbook of Research in Educational
Communications and Technology: Learning Design, pp. 593‚Äì613, 2020.
Chenxi Whitehouse, Monojit Choudhury, and Alham Fikri Aji. Llm-powered data augmentation
for enhanced crosslingual performance. arXiv preprint arXiv:2305.14288, 2023.
W Bruce Willis. The Adinkra dictionary: A visual primer on the language of Adinkra. Pyramid
Complex, 1998.
Joseph Wilson. Voicing an algorithm: trials of strength in artificial intelligence research. Anthro-
pology News, 2023. URL https://www.anthropology-news.org/articles/combat-by-algor
ithm-trials-of-strength-in-artificial-intelligence-research/.
Genta Winata, Alham Fikri Aji, Zheng Xin Yong, and Thamar Solorio. The decades progress on
code-switching research in NLP: A systematic survey on trends and challenges. In Findings of
63the Association for Computational Linguistics: ACL 2023, pp. 2936‚Äì2978, Toronto, Canada, July
2023a. Association for Computational Linguistics. URL https://aclanthology.org/2023.fi
ndings-acl.185.
Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Rahmad Mahendra, Fajri Koto, Ade
Romadhony, Kemal Kurniawan, David Moeljadi, Radityo Eko Prasojo, Pascale Fung, Timo-
thy Baldwin, Jey Han Lau, Rico Sennrich, and Sebastian Ruder. NusaX: Multilingual par-
allel sentiment dataset for 10 Indonesian local languages. In Proceedings of the 17th Confer-
ence of the European Chapter of the Association for Computational Linguistics, pp. 815‚Äì834,
Dubrovnik, Croatia, May 2023b. Association for Computational Linguistics. URL https:
//aclanthology.org/2023.eacl-main.57.
Peter Wittenburg. Open Science and Data Science. Data Intelligence, 3(1):95‚Äì105, 02 2021.
Sam Witteveen and Martin Andrews. Paraphrasing with large language models. arXiv preprint
arXiv:1911.09661, 2019.
Walt Wolfram. Issues in dialect obsolescence: An introduction. American speech, 72(1):3‚Äì11, 1997.
Chorng-Guang Wu, James H Gerlach, and Clifford E Young. An empirical analysis of open source
software developers‚Äô motivations and continuance intentions. Information & Management, 44(3):
253‚Äì262, 2007.
Jeff Wu, Long Ouyang, Daniel M Ziegler, Nisan Stiennon, Ryan Lowe, Jan Leike, and Paul Chris-
tiano. Recursively summarizing books with human feedback. arXiv preprint arXiv:2109.10862,
2021.
Tianbao Xie, Chen Henry Wu, Peng Shi, Ruiqi Zhong, Torsten Scholak, Michihiro Yasunaga,
Chien-Sheng Wu, Ming Zhong, Pengcheng Yin, Sida I Wang, et al. Unifiedskg: Unifying and
multi-tasking structured knowledge grounding with text-to-text language models. arXiv preprint
arXiv:2201.05966, 2022.
CanXu,QingfengSun,KaiZheng,XiuboGeng,PuZhao,JiazhanFeng,ChongyangTao,andDaxin
Jiang. Wizardlm: Empowering large language models to follow complex instructions, 2023a.
Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, and Muhao Chen. Instructions as back-
doors: Backdoor vulnerabilities of instruction tuning for large language models, 2023b.
Liang Xu, Hai Hu, Xuanwei Zhang, Lu Li, Chenjie Cao, Yudong Li, Yechen Xu, Kai Sun,
Dian Yu, Cong Yu, Yin Tian, Qianqian Dong, Weitang Liu, Bo Shi, Yiming Cui, Junyi
Li, Jun Zeng, Rongzhao Wang, Weijian Xie, Yanting Li, Yina Patterson, Zuoyu Tian, Yi-
wen Zhang, He Zhou, Shaoweihua Liu, Zhe Zhao, Qipeng Zhao, Cong Yue, Xinrui Zhang,
Zhengliang Yang, Kyle Richardson, and Zhenzhong Lan. CLUE: A Chinese language under-
standing evaluation benchmark. In Proceedings of the 28th International Conference on Com-
putational Linguistics, pp. 4762‚Äì4772, Barcelona, Spain (Online), December 2020. International
Committee on Computational Linguistics. doi: 10.18653/v1/2020.coling-main.419. URL
https://aclanthology.org/2020.coling-main.419.
Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya
Barua, and Colin Raffel. mT5: A massively multilingual pre-trained text-to-text transformer. In
Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur, Iz Beltagy, Steven
Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou (eds.), Proceedings of the 2021
64Conference of the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, pp. 483‚Äì498, Online, June 2021. Association for Computational
Linguistics. doi: 10.18653/v1/2021.naacl-main.41. URL https://aclanthology.org/2021.na
acl-main.41.
ShuoYang,ZekeXie,HanyuPeng,MinXu,MingmingSun,andPingLi. Datasetpruning: Reducing
training data by examining generalization influence, 2023.
Yi Yang, Wen-tau Yih, and Christopher Meek. WikiQA: A challenge dataset for open-domain
question answering. In Proceedings of the 2015 Conference on Empirical Methods in Natural
Language Processing, pp. 2013‚Äì2018, Lisbon, Portugal, September 2015. Association for Compu-
tational Linguistics. doi: 10.18653/v1/D15-1237. URL https://aclanthology.org/D15-1237.
Yinfei Yang, Yuan Zhang, Chris Tar, and Jason Baldridge. PAWS-X: A Cross-lingual Adversarial
Dataset for Paraphrase Identification. In Proc. of EMNLP, 2019.
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan Salakhutdinov,
and Christopher D. Manning. HotpotQA: A dataset for diverse, explainable multi-hop question
answering. InConference on Empirical Methods in Natural Language Processing (EMNLP),2018.
Qinyuan Ye, Bill Yuchen Lin, and Xiang Ren. CrossFit: A few-shot learning challenge for cross-
task generalization in NLP. In Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing, pp.7163‚Äì7189, OnlineandPuntaCana, DominicanRepublic, 2021.
Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.572. URL
https://aclanthology.org/2021.emnlp-main.572.
Zheng Xin Yong, Cristina Menghini, and Stephen Bach. Low-resource languages jailbreak GPT-4.
In Socially Responsible Language Modelling Research, 2023a. URL https://openreview.net/f
orum?id=pn83r8V2sv.
Zheng Xin Yong, Hailey Schoelkopf, Niklas Muennighoff, Alham Fikri Aji, David Ifeoluwa Ade-
lani, Khalid Almubarak, M Saiful Bari, Lintang Sutawika, Jungo Kasai, Ahmed Baruwa, Genta
Winata, Stella Biderman, Edward Raff, Dragomir Radev, and Vassilina Nikoulina. BLOOM+1:
Adding language support to BLOOM for zero-shot prompting. In Proceedings of the 61st An-
nual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp.
11682‚Äì11703, Toronto, Canada, July 2023b. Association for Computational Linguistics. URL
https://aclanthology.org/2023.acl-long.653.
Zheng Xin Yong, Ruochen Zhang, Jessica Zosa Forde, Skyler Wang, Arjun Subramonian, Holy
Lovenia,SamuelCahyawijaya,GentaIndraWinata,LintangSutawika,JanChristianBlaiseCruz,
et al. Prompting multilingual large language models to generate code-mixed texts: The case of
south east asian languages. In Sixth Workshop on Computational Approaches to Linguistic Code-
Switching, 2023c.
YueYu, YuchenZhuang, JieyuZhang, YuMeng, AlexanderRatner, RanjayKrishna, JiamingShen,
and Chao Zhang. Large language model as attributed training data generator: A tale of diversity
and bias, 2023.
Ann Yuan, Daphne Ippolito, Vitaly Nikolaev, Chris Callison-Burch, Andy Coenen, and Sebastian
Gehrmann. Synthbio: A case study in human-ai collaborative curation of text datasets. CoRR,
abs/2111.06467, 2021. URL https://arxiv.org/abs/2111.06467.
65Tajudeen Yusuf. Politeness in arabic and yoruba: Personal pronouns as a case study. Asian Journal
of Language, Literature and Culture Studies, 5(2):82‚Äì88, 2022.
Marcos Zampieri, Shervin Malmasi, Nikola Ljube≈°iƒá, Preslav Nakov, Ahmed Ali, J√∂rg Tiedemann,
YvesScherrer,andNo√´miAepli.FindingsoftheVarDialevaluationcampaign2017.InProceedings
of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial), pp. 1‚Äì
15, Valencia, Spain, April 2017. Association for Computational Linguistics. doi: 10.18653/v1/
W17-1201. URL https://aclanthology.org/W17-1201.
Marcos Zampieri, Preslav Nakov, and Yves Scherrer. Natural language processing for similar lan-
guages, varieties, and dialects: A survey. Natural Language Engineering, 26(6):595‚Äì612, 2020.
Daniel Zhang, Nestor Maslej, Erik Brynjolfsson, John Etchemendy, Terah Lyons, James Manyika,
Helen Ngo, Juan Carlos Niebles, Michael Sellitto, Ellie Sakhaee, Yoav Shoham, Jack Clark, and
Raymond Perrault. The ai index 2022 annual report, 2022.
Ge Zhang, Yemin Shi, Ruibo Liu, Ruibin Yuan, Yizhi Li, Siwei Dong, Yu Shu, Zhaoqun Li, Zekun
Wang, Chenghua Lin, Wenhao Huang, and Jie Fu. Chinese open instruction generalist: A pre-
liminary release, 2023a.
Shaolei Zhang, Qingkai Fang, Zhuocheng Zhang, Zhengrui Ma, Yan Zhou, Langlin Huang, Mengyu
Bu, Shangtong Gui, Yunji Chen, Xilin Chen, and Yang Feng. Bayling: Bridging cross-lingual
alignment and instruction following through interactive translation for large language models,
2023b.
Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, and Benjamin Van Durme.
Record: Bridging the gap between human and machine commonsense reading comprehension,
2018a.
WenxuanZhang,SharifahMahaniAljunied,ChangGao,YewKenChia,andLidongBing. M3exam:
A multilingual, multimodal, multilevel benchmark for examining large language models, 2023c.
Xiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text classi-
fication. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett (eds.), Advances
in Neural Information Processing Systems, volume 28. Curran Associates, Inc., 2015. URL
https://proceedings.neurips.cc/paper_files/paper/2015/file/250cf8b51c773f3f8
dc8b4be867a9a02-Paper.pdf.
YuanZhang,JasonBaldridge,andLuhengHe. Paws: Paraphraseadversariesfromwordscrambling,
2019.
Zhirui Zhang, Shujie Liu, Mu Li, Ming Zhou, and Enhong Chen. Joint training for neural machine
translation models with monolingual data. CoRR, abs/1803.00353, 2018b. URL http://arxiv.
org/abs/1803.00353.
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat,
Ping Yu, Lili Yu, et al. Lima: Less is more for alignment. arXiv preprint arXiv:2305.11206, 2023.
Terry Yue Zhuo, Armel Zebaze, Nitchakarn Suppattarachai, Leandro von Werra, Harm de Vries,
Qian Liu, and Niklas Muennighoff. Astraios: Parameter-efficient instruction tuning code large
language models. arXiv preprint arXiv:2401.00788, 2024.
66Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul
Christiano, and Geoffrey Irving. Fine-tuning language models from human preferences, 2020.
Barret Zoph, Deniz Yuret, Jonathan May, and Kevin Knight. Transfer learning for low-resource
neural machine translation. In Proceedings of the 2016 Conference on Empirical Methods in
Natural Language Processing, pp. 1568‚Äì1575, Austin, Texas, November 2016. Association for
Computational Linguistics. doi: 10.18653/v1/D16-1163. URL https://aclanthology.org/D16
-1163.
67A Aya Annotation Platform
In this section, we discuss the detailed design and development of the Aya Annotation Platform
and the gamification strategy employed. Together, these attempts aimed to ensure high-quality
curation of the Aya Dataset.
Figure 17: The onboarding page for a new user. We collect some demographic information and
ask them to specify the languages they are comfortable annotating data in. These are the language
options they are presented with later on in the UI.
A.1 Engagement Strategies
We decided to employ gamification methods to enhance annotator engagement [de Franga et al.,
2015;Bastanfardetal.,2023;Morschheuseretal.,2017]. Ourstrategyinvolvedusingapoints-based
rewards system, motivating contributors through social media recognition, and fostering friendly
competition with leaderboards. Regular mini-challenges and sprints helped to create collective
achievement goals and fostered a sense of community [Bastanfard et al., 2023]. Real-time feedback
reinforced positive behavior and customization options, such as avatars, provided a personalized
experience. Overall, these gamification strategies aimed to boost engagement, improve data quality,
and created a more enjoyable experience for the crowd-sourcing participants. [Morschheuser et al.,
2017].
To recognize and incentivize the efforts of our contributors, we established a tiered reward system
based on contribution milestones: 500, 1,000, and 5,000 contributions. Contributors who achieved
these goals on the project leaderboard were rewarded with certificates and specially designed Aya
project apparel. The attire varied according to the contribution level, with different packages for
each milestone. Additionally, the most active contributors were prominently acknowledged in the
project‚Äôsdatasetdocumentation,highlightingtheirsignificantroleaskeycontributorstotheproject.
This system not only motivated contributors but also served as a token of appreciation for their
dedication and hard work.
In addition to the leaderboard, the Aya Discord Bot was developed to recognize contributors with
a high number of points. This bot recognized the daily top 10 contributors by tagging them in a
message that was posted on the Aya Discord server. It also aggregated daily total contributions
per region and specified how many days were left until the data collection phase ended. As shown
68Figure 18: Aya Discord Bot message aggregating daily statistics and top 10 annotators
in Figure 18, these messages provided a regular snapshot of progression that allowed annotators to
see the dataset grow across all languages.
Figure 19: Aya Leaderboard. Daily and weekly leaderboards are shown on the top left and right
respectively. At the bottom are language-specific and overall leader boards, where annotators are
ranked based on their Aya score.
69A.2 Accessibility of Registration Tools
The accessibility and popularity of registration tools differed from country to country and this had
an impact on where the Aya UI users joined from. Figure 20 compares the percentage of registered
users using Discord and Gmail to sign up in the top 10 countries. After introducing Google SSO, we
observedasignificantjumpinthenumberofregisteredusersfromseveralnewcountries(Figure21).
Figure 20: Percentage of Aya UI users that registered via Left: Discord and Right: Gmail.
Figure 21: Percentage of the Aya UI users that registered after the introduction of Google SSO in
the platform.
B UI Tasks
B.1 Reviewing Annotators
In the Aya UI, we display the original and re-annotated versions of both prompt and completion
along with the name of the annotator who did the re-annotation. Reviewers are tasked with rating
the re-annotated prompt and completion on a scale from 1 to 5. The ratings are defined as follows:
(1) Much worse than the original annotation;
(2) Worse than the original annotation;
(3) No noticeable difference compared to the original annotation;
(4) Better than the original annotation;
(5) Much better than the original annotation.
If any of the prompt/completion pairs receive a rating below 5 (i.e., anything lower than ‚ÄúMuch
70betterthantheoriginalannotation‚Äù),thereviewerisprovidedwithanoptiontomodifytheprovided
prompt and completion pair to improve its quality. An ‚ÄúAdditional Feedback‚Äù text box is also
available for reviewers to explain the reasoning behind their chosen rating.
B.2 Aya Score
To encourage annotators to make high-quality submissions, we designed a ranking score favoring
contributions that received high peer ratings. The Aya Score for an individual annotator is:
ScoreAya = w 1√ó(E)+w 2√óC, (1)
with weights w 1, w 2 defined as:
(cid:18) (cid:19)
(cid:16) (cid:17) T
w 1 = max 0,(QÀÜ ‚àí3) ,w 2 = + (2)
T
where:
‚Ä¢ E represents the total number of re-annotations in which the annotator edited prompts and
completions
‚Ä¢ C represents the total number of original annotations submitted by an annotator
‚Ä¢
QÀÜ
represents the average quality rating derived for an annotator through peer review via
Annotation Feedback task
‚Ä¢ T + represents the total number of original annotations made by an annotator that received
positive feedback in Re-annotations task
‚Ä¢ T represents the total number original annotations made by an annotator that feedback
received in Re-annotations task.
The rationale behind introducing the ScoreAya was to boost a competitive environment among
annotators and encourage them to focus on submitting high-quality data, consequently improving
the overall quality of the Aya Dataset.
B.3 Annotation Guidelines
The annotators were provided with the following evaluation criteria for what a good prompt and
completion pair must look like. Re-Annotations were then performed if they determined that the
prompts or completions needed editing.
1. No grammatical or spelling mistakes in both the prompt and completion text.
2. The prompt provides clear instruction on what the task is.
713. The completion answers the prompt correctly. Both the prompts and completions should be
in full sentences and coherent, with reasonable length.
4. For original annotations, the prompts and completions should not be generated from other
language models.
Re-Annotations Before editing, annotators rated the quality of existing prompt and comple-
tion pairs by choosing either the thumbs-up or thumbs-down option. If the provided prompt and
completion pair were already of good quality according to the criteria above, then annotators rated
them with thumbs up and moved ahead without editing. Overall, annotators were encouraged to
re-annotate the completions, in particular by adding more details and context to them since many
of them were often short one-word answers.
C Language Representation via Community
C.1 Division by Regions
We chose to divide languages into four primary regions: Africa, Asia, Europe, and Latin America.
Thesefourregionswereestablishedinordertofacilitatetheadministrationofusercontributionsand
were not intended to prescribe boundaries within which certain languages are exclusively spoken.
The language statistics by region are as follows: Africa (14 languages), Asia (41 languages), Europe
(42languages),andLatin America (4languages). Almostallthelanguageswereassignedtoaregion
but there are some exceptions, Maori and Samoan were unassigned to any specific region as they
didn‚Äôtalignwiththepredefinedregions. Englishwasleftunassigned,servingasacommonlanguage
acrossallregions. Additionally, contributionsinSpanishandPortuguesewere distributed between
Europe and Latin America based on contributors‚Äô countries. Similarly, Arabic contributions were
shared between Africa and Asia depending on the contributors‚Äô country of origin. Additional
dialects of Arabic were included in regions separate from that of their parent language because
we had a significant number of speakers from these regions eager to contribute to their respective
dialects. Each region had at least one ‚ÄúRegional Lead‚Äù responsible for coordinating ‚ÄúLanguage
Ambassadors,‚Äù and for recruiting fluent speakers for the languages within their area.
C.2 Language Ambassadors
The Language Ambassador‚Äôs role was pivotal in bridging the gap between the data collected in a
language and its speakers. An essential criterion for selection was native fluency in the specific
language. The Language Ambassador‚Äôs expertise in specific languages and familiarity with the
cultures of the language speakers was invaluable. They assisted not only in spreading awareness
among participants but also in identifying and addressing potential data issues specific to each
language,suchaslanguagesincorrectlyassignedtotheirregion. Theirculturalandlinguisticinsights
enabled them to make informed decisions, like choosing suitable data sources for collection in their
respective languages. Not every language had a designated Language Ambassador, and some had
more than one. In total, we had 84 Language Ambassadors over the course of the initiative. Their
combined efforts played a vital role in broadening the contributor base for each language. Support
fortheLanguageAmbassadors‚Äôprogressandtrouble-shootingchallengestheyfacedwascoordinated
asynchronously and through weekly online meetups, discussed in Sec. D.1 and Sec. D.2.
72C.3 Regional Leads
There were a total of six Regional Leads: two for Latin America, one for Africa, one for Asia, and
two for Europe. The selection for Regional Lead roles was on a voluntary basis, with the only
requirement being that they must originate from the regions they intended to lead. The invitation
for this role was specifically extended to individuals who were already actively participating in
Cohere For AI projects or engaged in other open science projects. Regional Leads had several key
roles throughout the project, such as selecting Language Ambassadors and aiding their efforts in
attracting more annotators and maintaining their engagement.
D Communication
D.1 Platforms
We established a Discord server for coordination between Regional Leads, Language Ambassadors
and annotators. The server provided basic channels for internal communications: introductions,
inquiries, and announcements, as well as specific channels for Language Ambassadors, for each
region, and for each language, along with any other channels that proved useful for the particular
region. Forexternalcommunications,weusedsocialmediaplatforms(e.g.,X,LinkedIn,WhatsApp,
Facebook), recognizing that the choice of communication platform varied based on cultural and
regional preferences. Using multiple platforms not only facilitated internal organization but also
broadened our project‚Äôs outreach by providing flexible and inclusive means of outreach to diverse
communities and audiences.
D.2 Meetings
In addition to asynchronous communication through Discord, we conducted meetings to maintain
team collaboration and cohesion:
1. Regional Leads and Language Ambassadors Meeting: A weekly meeting in which
Regional Leads and Language Ambassadors shared project updates, exchanged ideas, and ad-
dressed questions from Language Ambassadors. It served as an excellent platform for gather-
ing ideas from Language Ambassadors and brainstorming new strategies to engage annotators
effectively.
2. New Contributor Introduction Meeting: Held weekly, this meeting aimed to introduce
new contributors to the project‚Äôs specifics. It included explanations about the motivations
behind the project, a walk-through of the Aya UI, and a sharing of regional statistics. Addi-
tionally, this meeting provided examples of both good and bad annotations and edits to guide
new annotators in their work. It concluded with a synchronous challenge for the annotators
to submit a few initial annotations in real time to familiarize them with the process and allow
them to ask questions if they got stuck.
3. Regional Leads Meeting: Held bi-weekly, this meeting brought together Regional Leads
to assess progress, discuss upcoming steps, and provide advice on how to engage and sustain
contributions for their respective regions. Furthermore, this meeting facilitated collaborative
troubleshooting efforts and helped make important decisions for the following week.
734. Technical Update: This meeting was dedicated to sharing technical updates, with a focus
on recent UI progress, data, and benchmarking. The purpose of this monthly update was to
ensureallteammembersandannotatorswerewell-informedabouttheproject‚Äôscurrentstatus
and upcoming priorities. It was a place for open discussion to hear feedback from everyone
interested in the project.
5. Language Specific Meeting: Held weekly or biweekly, these meetings were co-working
sessions or datathons led by the language ambassadors with their respective annotators to
submit annotations synchronously. It also acted as an onboarding session to welcome new
contributors from regions that could not join the New Contributor Introduction Meeting due
to conflicting time zones. Demonstrations on using the UI, as well as brainstorming sessions,
were conducted to improve the representation of specific languages in the project.
E Language Groupings
Inthisworkwewillrefertogroupsoflanguagestobe‚Äúlower-‚Äù,‚Äúmid-‚Äù or‚Äúhigher‚Äù-resourcedaccording
to their recorded, written, and catalogued NLP resources [Joshi et al., 2020]. Joshi et al. [2020]
grouplanguagesinto5distinctclustersbasedontheamountofdatafromacombinedrangeofsource
(LDCcatalog16, ELRAMap17, Wikipedia18), whichweinterpretasaproxyfordataavailabilityfor
pretraining and IFT training of LLMs. We group these 5 distinct clusters into a rough taxonomy
of lower-resourced (LR), mid-resourced (MR) and higher-resourced (HR) (See Table 6).
See Table 5 for full mapping of languages to categories. We note that this grouping is inevitably
imperfect; languages and their varieties cannot absolutely nor universally be classified based on this
single dimension [H√§m√§l√§inen, 2021; Lignos et al., 2022; Bird, 2022]. The categorization in our case
serves the purpose of aggregation in our analysis of the data distribution.
Group Category Languages Examples
5 7 Arabic, Chinese, English, French, Spanish
Higher-Resourced
4 18 Hindi, Italian, Portuguese, Russian, Turkish
Mid-Resourced 3 25 Afrikaans, Indonesian, Kazakh, Malay, Latvian
2 13 Hausa, Icelandic, Irish, Lao, Maltese
Lower-Resourced 1 39 Albanian, Gujarati, Igbo, Luxembourgish
0 12‚àó Kurdish, Kyrgyz, Sinhala, Yiddish
Table 6: Language grouping for the Aya Collection. We assign categories to languages based
on [Joshi et al., 2020]. (*) We assign label 0 to two languages not found in Joshi et al. [2020]‚Äôs
taxonomy (manipuri and ngaju).
16https://catalog.ldc.upenn.edu/
17https://catalog.elra.info/en-us/
18https://wikipedia.org/
74F Post-Editing the dolly-machine-translated Test Set
F.1 Annotators
Annotator Selection The primary demographic make-up of the participants in the evaluations
was recruited based on their proficiency in the language groups. The proficiency was self-reported,
and our requirements were natively proficient or professionally proficient in the specific languages
needed for the project. Outside of this, the participants come from diverse social backgrounds
comprised of students and individuals with full-time or part-time jobs that do annotation as a ‚Äúside
gig‚Äù.
Socio-Demographics The annotator pool is comprised of people from diverse backgrounds, and
this spans across socioeconomic backgrounds, careers, levels of education, and self-reported gender
and sexual identities. We do not ask any annotators to share or report any of these statistical
pieces of information in a formal way; any insights into this are gathered organically and through
self-reporting by the annotators.
Quality Considerations We do not believe that any socio-demographic characteristics have led
to any impact on the data that has been annotated. Through every part of the project we have
reiterated the importance of this work and the fact that this is helping to support a global-scale
research project. We are confident in the trust we have built with the annotators in this project,
and they care greatly about the overall outcome and therefore have been diligent in completing the
task with a high degree of accuracy. Where possible, we have done our best to have annotators
work on this project and be representatives of the communities that the project aims to support.
Compensation The annotators were paid 30 CAD per hour. No special consideration was made
to the hourly rate as that is the standard rate offered to Cohere‚Äôs annotators who work on highly
complex tasks.
F.2 Annotation Process
Communication Annotators were briefed by one of the authors in a virtual introduction session,
and were able to ask questions and raise issues throughout the annotation task in a Slack channel.
They were also encouraged to share frequent error patterns, artifacts, or hard decisions that they
encountered throughout the task with the authors and other annotators.
Schedule There was no fixed time schedule for the annotations and annotators contributed a
varying amount of hours and ratings, depending on their availabilities and speed. Each translation
was post-edited by one annotator, and there were 3‚Äì4 annotators involved in each task. After post-
edits were completed, a second annotator (not the original post-editor) assessed the post-edit for
quality and proposed new final edits if necessary.
Interface Post-edits were collected on Google Sheets with an interface built in Google Apps Script.
75F.3 Instructions
dolly-machine-translated
The instructions given to professional annotators for the test set
post-edits were the following: ‚ÄúAs an annotator, you have the task to improve the quality of the
prompts for our multilingual model! The prompts are originally machine-translated from English,
and sometimes the translation introduces errors in the prompts that make them hard to follow.
We need your help to identify these cases, and to edit these translations so that they...
1. Convey the same instruction/task/request as the English original ‚Äî not more and not less.
2. Are grammatically correct.
3. Are free from phrases too literally translated from English (we call this ‚ÄúTranslationese‚Äù).
This is how:
For each pair of English prompt and translated prompt shown, decide whether the prompt is okay
as it is (according to the above criteria), or needs an edit.
‚Ä¢ If it needs an edit, edit the prompt until the quality is satisfactory (in the field ‚ÄúEdited
Prompt‚Äù). Try to keep your edits minimal. Then confirm that the edited prompt fulfills the
above three criteria.
‚Ä¢ If it‚Äôs okay as is, just proceed (without editing the ‚ÄúEdited Prompt‚Äù field) to confirm that it
fulfills the above three criteria.‚Äù
Annotations were done through an interface built on top of Google Sheets. One annotator edited
each prompt, and another verified the edit, if necessary had a discussion and edited the original
edit. Three to four editors collaborated on each language.
F.4 Post-Editing Effort
For each prompt, we measure the post-editing effort with Human-targeted Translation Error Rate
(HTER) [Specia & Farzindar, 2010], an edit-distance metric that compares the original machine
translationwiththepost-editedversionintermsofeditoperationsonunitsofwords. Thisalsogives
us an estimate of how severe the errors in the original translations were, and how critically the post-
editors assessed the original translations. Analogously, we estimate with a Human-targeted Char-
acter F-Score (HChrF) score how much the original translation overlaps with the final post-edited
translation. This metric is based on the ChrF score [Popoviƒá, 2015] and operates on character-level
matches. Computations of HTER and HChrF are based on the sacrebleu implementation [Post,
2018].
dolly-machine-translated
Table 7 reports these statistics for the six languages of the test set.
Wefindthateditorseditedatleast41%ofpromptsinalllanguages,asurprisinglyhighnumber. This
dolly-machine-translated
indicates that translation errors in the test set are quite common.
76Language % of Prompts Edited HTER HChrF
Arabic 41.0% 10.78 92.74
French 84.5% 5.56 96.81
Hindi 60.0% 6.16 95.00
Russian 86.5% 37.43 75.92
Serbian 72.5% 9.06 92.79
Spanish 75.5% 9.13 93.25
Table 7: Post-editing effort measured by the overall percentage of edited dolly test prompts,
HTER (Human-targeted Translation Error Rate: the higher, the more effort), and HChrF (Human-
Targeted Character F-Score: the lower, the more effort).
For Russian, the post-editing effort was overall largest, with an average of 37.43 HTER, which
means that 37.43% of words in the final post-edit had to be edited from the original. This stands in
contrast with the post-edits for French, where a similar ratio of original prompts was edited (84.5%
compared to 86.5% for Russian), but to a much lesser extent (5.56 HTER).
G Translation using NLLB
Additional Generation details One caveat with using NLLB is that since the model was trained
onsinglesentencepairs,thetranslationstendtocutoffabruptlywhenfullparagraphsaretranslated.
To get around this, we sentence-tokenize the paragraphs using the sentence-splitter Python package
(similar to [NLLB-Team et al., 2022]) and concatenate them post-translation. To avoid known
translation introduced artefacts, We also filter any samples which have <unk> tokens introduced by
the NLLB tokenizer or model.
G.1 Translation Quality of NLLB
Figure22illustratesNLLBtranslationqualityasmeasuredbyChrF++ontheFLORESbenchmark
for the languages of interest for Aya, grouped by their resourcefulness according to [Joshi et al.,
2020]. The scores were extracted from https://github.com/facebookresearch/fairseq/blob/n
llb/README.md for the dense 3.3B model.
7760
40
20
0
(a) Low-resource Languages: [Joshi et al., 2020] classes 0, 1, 2
60
40
20
0
(b) Mid-resource Languages: [Joshi et al., 2020] class 3
60
40
20
0
(c) High-resource Languages: [Joshi et al., 2020] classes 4, 5
Figure 22: NLLB Translation Quality: ChrF++ scores on FLORES for translations from English
intotheAyatargetlanguagesthatarecoveredbyNLLB,groupedbytheirresourcefulnessaccording
to [Joshi et al., 2020].
78
++FrhC
++FrhC
++FrhC
barA_cnk
gneB_inm
tnaH_ohz
barA_eca barA_njb
tnaH_euy
ntaL_qat
iahT_aht
barA_bza
snaH_ohz
ntaL_cnk
lryC_leb
napJ_npj
ntaL_roy rmyM_aym
roeG_tak
gnaH_rok
barA_sak rmhK_mhk
barA_dru
barA_bea
rbeH_ddy ntaL_eca
barA_yra
gneB_neb
ihtE_hma
barA_mca
ntaL_rmk barA_tbp
mylM_lam
barA_zra
ntaL_obi lryC_khk
lryC_zak
barA_qca
ntaL_ans ntaL_mos
kerG_lle
barA_cpa
ntaL_jza
ntaL_lop
hniS_nis
ntaL_svl
lryC_rik
ntaL_sue
ooaL_oal ntaL_irm
ntaL_nzu
barA_sep
barA_bkc ntaL_nus
lmaT_mat
barA_pja
aveD_ipn
barA_sra
ntaL_tos
ntaL_til
aveD_ram
ntaL_nif
ntaL_njb
ntaL_tse
ntaL_alg
ntaL_aps
ntaL_ohx
ntaL_vls
ntaL_dln
barA_dns ntaL_lsi
lryC_rku
barA_bra
lryC_kgt ntaL_tlp
ntaL_nuh
ntaL_osn
rbeH_beh
ntaL_oms
lryC_sur
ntaL_nim
ntaL_bec
ntaL_sec
ntaL_tah nmrA_eyh
ntaL_kls
aveD_nih
rjuG_jug ntaL_uah
ntaL_glg
ntaL_ati
adnK_nak
ntaL_rut
ntaL_onn
ntaL_nor
ntaL_luz
lryC_prs
ntaL_vaj uleT_let
lryC_lub
ntaL_eiv
ntaL_elg ntaL_ztl
ntaL_rfa
ntaL_ued
ntaL_sla
ntaL_tac
ntaL_bon
ntaL_msz
lryC_dkm
ntaL_ews
ntaL_hws
ntaL_nad
ntaL_ope
ntaL_rop
ntaL_tlm ntaL_myc
ntaL_dni
ntaL_arfH Additional Figures
1.0
0.8
Translated
XP3
Templated
0.6 Aya Dataset
0.4
0.2
0.0
X- NC uS sQ aA xX-i - psn 3s e _t n Gti E-i TMn u_s rt B ki x uS -pE p3C _ aT rp aa pw hs r- ax s xe Mi- pi n 3n t _s at xk qa- ui an ds _t Ax fq riu Sa ed nt Xi l- Fi leln a_s nt - Jw l od a- ki Wm ein -bs ki et a - xsd plpa l i a( it-T ni) an ts it o ( Xn l-T i) eln _st w ( d-T i P) n Ast W ( S-T) Wiki W I( MK iIT ) n Ft lQ a aA k n( -a-T ui) nn i As fit d e v( d eT - r) sQ aA r i( aT l
F
) lWiQ akA ni --( s CT p o) li MT-t a- si sun abs kt hmi ax N( ET) W N FS l- Qi a-n nO -st p Ge En S M( -OT w) iD kA i- -i lin nst gu Da xol( plT y 3) - _v G2 E( MT) _ Hxl ots pu otm QA A f( riT) Q CMA- Li Nn Q N x-s oAt
r
p- D ie 3a gi _in l kn( py- haT 3l a) __M
li
kaai d hl n a al( n lt iT o _) t dta ay lti tdi _o tq Tn y eas l- di ug q gol a u- -d p np Tri e elwm usa g-r uay -r fti oc ol de -s r e Tc ei l Ip u ne g T ds u ie- lj cuo Xgk Pue a- rs p ao pe hrm a Ts s ele- ui gn ust Riddles
x
Figure 23: Average Approval Ratio per dataset, constrained to datasets receiving at least 20 votes.
Initial Length Edited Length Initial Length Edited Length
500 500
400 400
300 300
200 200
100 100
0 0
HR MR LR HR MR LR
(a) Average prompt length (b) Average completion length
Figure 24: Average prompt and completion length of instances in the Aya Dataset before and after
re-annotation across different language categories.
79
oitaR
lavorppA
.gvA
htgneL
tpmorP
egarevA
htgneL
noitelpmoC
egarevA2000
Language Category
HR
1750 MR
LR
1500
1250
1000
750
500
250
0
(a) Average completion length for every language in the Aya Dataset.
Language Category
1200
HR
MR
LR
1000
800
600
400
200
0
(b) Average prompt length for every language in the Aya Dataset
Figure 25: Average prompt and completion length for every language in the Aya Dataset
80
htgneL
noitelpmoC
egarevA
htgneL
tpmorP
egarevA
dru
luz
roy
dns
mos
eiv
tah
mos
nap
nap
eiv
tah
mat
dni
aym
lle
prs
nad
jug
osn
ayn
vaj
nif
neb
let
lam
neb
let
elg
ohx
gne
dln
arf
til
sup
rku
asm
aps
nih
ans
dns
lop
dni
ews
rku
aht
nis
ati
dln
sep
sur
nak
ued
sur
nuh
prs
sep
nus
rut
nuh
aws
uah
til
ued
ans
dru
pen
obi
rik
nih
lam
sup
lif
aym
aps
glm
ram
ara
ohx
sue
nak
arf
nad
npj
ati
gne
luz
rop
rok
mat
lle
jug
obi
asm
ews
lif
uah
pen
vaj
rok
sue
rut
lop
hma
rop
iqs
osn
aws
ara
nif
glm
ram
aht
rik
low
nis
bec
roy
nus
low
npj
bec
ohz
elg
iqs
ruk
hma
ayn
ruk
ohzLanguage Category
2000 HR
MR
1750 LR
1500
1250
1000
750
500
250
0
Figure 26: Average prompt and completion length across different languages in Aya Dataset.
I Additional Tables
Dataset #Langs Templatelang Datasetlang L¬Ø prompt L¬Ø compl. License Task
bem, fon, hau,
AfriQA-inst
ibo, kin, swh, Question
[Ogundepoetal., 12 46 15 CCBY4.0
twi, wol, yor, Answering
2023]
zul,eng,fra
AfriSenti-inst amh, arq, hau,
Sentiment
[Muhammadetal., 9 ibo, kin, ary, 168 44 CCBY4.0
Analysis
2023] por,swh,twi
AmharicQA MIT Question
1 amh amh 1114 33
[Abedissaetal.,2023] license Answering
News-summary-
instruct[TahmidH, 1 ben ben 174 67 CC01.0 Summarization
2023]
Arpa-instruct
1 hye hye 165 118 Artistic-2.0 Paraphrasing
[syntaxshill,2023]
Telugu-food-recipes
[SuryaKrishna02, 1 tel tel 70 870 Apache2.0 Generation
2023a]
Telugu-jokes
[SuryaKrishna02, 1 tel tel 80 276 Apache2.0 Generation
2023b]
Telugu-news-articles
[SuryaKrishna02, 1 tel tel 448 426 Apache2.0 Generation
2023c]
Telugu-poems
[SuryaKrishna02, 1 tel tel 357 198 Apache2.0 Generation
2023e]
FarsTail-Instruct Natural
[Amirkhanietal., 1 pes pes 224 112 Apache2.0 Language
2023;hghader1,2023] Inference
Hindi-article-
CCBY-SA
summarization 1 hin hin 3813 175 Summarization
4.0
[ganeshjcs,2023a]
81
)noitelpmoC
+
tpmorP(
htgneL
egarevA
dru roy mos eiv luz nap tah dns mat aym prs neb dni jug let nif ayn gne rku arf dln elg nad lle sup nih sur lam asm vaj ued til osn sep ans nuh ohx aps nis ati ews nak lop uah rut pen aws lif obi rik ram rok sue aht rop nus glm ara low npj bec iqs hma ohz rukHindi-article-
CCBY-SA
generation[ganeshjcs, 1 hin hin 102 3683 Generation
4.0
2023b]
IMDB-Dutch-instruct
Sentiment
[Maasetal.,2011; 1 nld nld 1470 31 Apache2.0
Analysis
jjzha,2023]
ben, guj, hni,
IndicSentiment-inst
kan, mal, mar,
[Doddapanenietal., 11 eng 174 141 MIT Translation
pan, tam, tel,
2023;el2e10,2023a]
urd,eng
IndicXParaphrase-inst
[Doddapanenietal., ben, guj, hin, ben, guj, hin,
Paraphrase
2023;el2e10,2023b; 7 mar, pan, mal, mar, pan, mal, 132 93 MIT
Identification
SuryaKrishna02, tel tel
2023d]
Indo-stories-instruct
3 ind,sun,jav ind,sun,jav 345 322 CCBY4.0 Translation
[Iftitahu,2023a;b;c]
Joke-explaination-inst
1 eng 118 548 MIT Generation
[theblackcat102,2023]
Lijnews-instruct
[ConseggioLigure, 2 ita,lij it,lij 893 898 CCBY4.0 Translation
2023a;b]
LLM-Japanese-
Vanilla-inst[Suzuki CCBY-SA Question
1 jpn jpn 60 97
etal.,2023; 4.0 Answering
Tellarin.ai,2023a]
amh, eng, fra,
hau, ibo, lin,
MasakhaNEWS-inst cgg, orm, pcm, Text
16 1483 1459 AFL-3.0
[Adelanietal.,2023] run, sna, som, Classification
swh, tir, xho,
yor
arb, deu, spa,
Mintaka-inst[Sen Question
9 eng fra, jpn, por, 102 49 CCBY4.0
etal.,2022] Answering
hin,ita,eng
arb, zho, nld, arb, zho, nld,
NTX-LLM-inst[Chen eng, fra, deu, eng, fra, deu,
CCBY-SA Information
etal.,2023c; 13 hin, ita, jpn, hin, ita, jpn, 917 493
4.0 Extraction
Tellarin.ai,2023b], kor, por, spa, kor, por, spa,
tur tur
ace, ban, bjn,
NusaX-senti-inst bug, eng, ind, Sentiment
12 219 22 Apache2.0
[Winataetal.,2023b] jav, mad, min, Analysis
nij,sun,bbc
Persian-instruct-pn
[Farahanietal.,2021; 1 pes pes 1713 128 MIT Summarization
Shafagh,2023a;b]
SCB-MT-2020-prompt
[Lowphansirikuletal., CCBY-SA
2 tha,eng tha,eng 181 127 Translation
2022;PyThaiNLP, 4.0
2023a;b]
Scientific
Scirepeval-biomimicry-
1 eng 996 523 ODC-BY Document
inst[Singhetal.,2022]
Representation
Seed-instruct-lij
[Maillardetal.,2023; CCBY-SA
2 lij,eng lij,eng 184 186 Translation
ConseggioLigure, 4.0
2023c;d]
SODA-inst[Kimetal.,
1 eng 412 328 CCBY4.0 Dialogue
2022]
TamilStories[AITamil
1 tam tam 2266 2172 Apache2.0 Generation
Nadu,2023a]
TeluguRiddles Question
1 tel tel 74 44 Apache2.0
[desik98,2023] Answering
Thai-USEmbassy-
prompt[PyThaiNLP, 2 tha,eng tha,eng 2131 2077 CC01.0 Translation
2023d;e]
Thai-POS-inst CCBY-SA
1 tha tha 72 36 Generation
[PyThaiNLP,2023c] 3.0
82Thai-Wiktionary-inst CCBY-SA
1 tha tha 35 147 Generation
[PyThaiNLP,2023f] 3.0
Thirukkural-instruct
[AITamilNadu, 1 tam tam 133 542 Apache2.0 Generation
2023b]
Turku-paraphrase-inst
CCBY-SA Paraphrase
[Kanervaetal.,2021; 1 fin fin 108 59
4.0 Identification
TurkuNLP,2023]
UA-Gec-inst[Syvokon
etal.,2023;osyvokon, 1 ukr ukr 192 148 CCBY4.0 Generation
2023]
zho, hrv, dan, zho, hrv, dan,
UNER-LLM-inst
eng, deu, por, eng, deu, por, CCBY-SA NamedEntity
[Mayhewetal.,2023; 11 768 109
rus, srp, slk, rus, srp, slk, 4.0 Recognition
UniversalNER,2023]
swe,tgl swe,tgl
Urdu-News-Gen-
Article[Hussainetal.,
1 urd urd 109 1313 CCBY4.0 Generation
2021;AhmadMustafa,
2023a]
Urdu-News-Category-
Class[Hussainetal., Text
1 urd urd 1407 43 CCBY4.0
2021;AhmadMustafa, Classification
2023b]
Urdu-News-Gen-
Headline[Hussain
etal.,2021; 1 urd urd 1314 94 CCBY4.0 Generation
AhmadMustafa,
2023c]
Wiki-split-inst[Botha Text
1 eng 200 166 CCBY4.0
etal.,2018] Simplification
eng, zho, deu,
spa, fra, ita,
X-CSQA-inst[Lin jpn, nld, pol, Question
16 197 21 MIT
etal.,2021] por, rus, arb, Answering
vie, hin, swa,
urd
Xlel_wd-inst[Pratapa
44 379 190 CCBY4.0 EventLinking
etal.,2022]
XWikis-inst
ces, fra, eng,
[Perez-Beltrachini& 4 5662 346 MIT Summarization
deu
Lapata,2021]
Table 8: List of datasets in Aya Collection (templated datasets).
Dataset #Langs L¬Ø prompt L¬Ø compl. License Task
Question
AdversarialQA(T)[Bartoloetal.,2020] 101 159 721 CCBY-SA3.0
Answering
CNN-Daily-Mail(T)[Seeetal.,2017]
101 1980 305 Apache2.0 Summarization
[Hermannetal.,2015]
Flan-Coqa(T)[Weietal.,2022a;Reddy Question
101 2143 364 Multiple*
etal.,2019] Answering
Flan-CoT-submix(T)[Weietal.,2022a] 101 239 160 Unknown Generation
Flan-GEM-wiki-lingua(T)[Weietal.,2022a; CCBY-NC-SA
101 1732 572 Summarization
Ladhaketal.,2020] 3.0
Flan-lambada(T)[Weietal.,2022a;Paperno
101 232 7 CCBY4.0 Generation
etal.,2016]
Flan-unified-QA(T)[Weietal.,2022a; Question
101 281 13 Apache2.0
Khashabietal.,2020] Answering
Question
HotpotQA(T)[Yangetal.,2018] 101 129 15 CCBY-SA4.0
Answering
83Joke-explaination-inst(T)[theblackcat102,
101 111 545 MIT Generation
2023]
Question
Mintaka-inst(T)[Senetal.,2022] 101 54 67 CCBY4.0
Answering
Question
MLQA-en(T)[Lewisetal.,2020] 101 819 20 CCBY-SA3.0
Answering
Question
NQ-Open(T)[Kwiatkowskietal.,2019] 101 68 14 CCBY-SA3.0
Answering
Custom
Paraphrase
PAWS-Wiki(T)[Zhangetal.,2019] 101 308 6 license,
Identification
attribution
Question
PIQA(T)[Bisketal.,2020] 101 304 100 Unknown
Answering
SODA-inst(T) [Kimetal.,2022] 101 86 208 CCBY4.0 Dialogue
Question
WIKIQA(T)[Yangetal.,2015] 101 205 36 MSRDLA*
Answering
Text
Wiki-split-inst(T)[Bothaetal.,2018] 101 126 220 CCBY-SA4.0
Simplification
Xlel_wd-inst(T)[Pratapaetal.,2022] 101 300 274 CCBY4.0 EventLinking
Dolly-v2(T) [Conoveretal.,2023] 101 427 357 CCBY-SA3.0 Generation
Table 9: List of datasets in Aya Collection (translated datasets).
MainTaskType Fine-grainedTaskType Dataset
QuestionAnswering AfriQA-inst[Ogundepoetal.,2023]
AmharicQA[Abedissaetal.,2023]
LLM-Japanese-Vanilla-inst[Tellarin.ai,2023a]
Mintaka-inst[Senetal.,2022]
X-CSQA-inst[Linetal.,2021]
TeluguRiddles[desik98,2023]
NaturalLanguage Summarization News-summary-instruct[TahmidH,2023]
Generation Persian-instruct-pn[Shafagh,2023a]
Hindi-article-summarization[ganeshjcs,2023a]
XWikis-inst[Perez-Beltrachini&Lapata,2021]
Translation IndicSentiment-inst[el2e10,2023a]
Indo-stories-instruct[Iftitahu,2023a;b;c]
Lijnews-instruct[ConseggioLigure,2023a;b]
SCB-MT-2020-prompt[PyThaiNLP,2023a;b]
Thai-USEmbassy-prompt[PyThaiNLP,2023d;e]
SEED-instruct-lij[ConseggioLigure,2023c;d]
Paraphrasing Arpa-instruct[syntaxshill,2023]
IndicXParaphrase-inst[el2e10,2023b;SuryaKrishna02,2023d]
Turku-paraphrase-inst[TurkuNLP,2023]
TextSimplification Wiki-split-inst[Bothaetal.,2018]
Dialogue SODA-inst[Kimetal.,2022]
NLGeneration Telugu-food-recipes[SuryaKrishna02,2023a]
Telugu-jokes[SuryaKrishna02,2023b]
Telugu-news-articles[SuryaKrishna02,2023c]
Telugu-poems[SuryaKrishna02,2023e]
TamilStories[AITamilNadu,2023a]
Joke-explaination-inst[theblackcat102,2023]
Thirukkural-instruct[AITamilNadu,2023b]
Hindi-article-generation[ganeshjcs,2023b]
Thai-Wiktionary-inst[PyThaiNLP,2023f]
UA-Gec-inst[osyvokon,2023]
Urdu-News-Gen-Article[AhmadMustafa,2023a]
Urdu-News-Gen-Headline[AhmadMustafa,2023c]
Thai-POS-inst[PyThaiNLP,2023c]
84TextClassification SentimentAnalysis AfriSenti-inst[Muhammadetal.,2023]
IMDB-Dutch-instruct[jjzha,2023]
NusaX-senti-inst[Winataetal.,2023b]
InformationExtraction NTX-LLM-inst[Tellarin.ai,2023b]
NamedEntityRecognition UNER-LLM-inst[UniversalNER,2023]
NaturalLanguageInference FarsTail-Instruct[hghader1,2023]
EventLinking Xlel_wd-inst[Pratapaetal.,2022]
Sci.Doc.Representation Scirepeval-biomimicry-inst[Singhetal.,2022]
TextClassification Urdu-News-Category-Class[AhmadMustafa,2023b]
MasakhaNEWS-inst[Adelanietal.,2023]
Table 10: Task Taxonomy of Templated Datasets (Aya Collection). We classify the templated
datasetswithastandardtasktaxonomyofthreemaintasks: QuestionAnswering,NaturalLanguage
Generation, and Text Classification (Table 4). We then have a fine-grained task taxonomy within
each task, such as Summarization, Translation, Paraphrasing, Sentiment Analysis, Information
Extraction, and Named Entity Recognition. If there is not a recognized fine-grained task taxonomy
for a specific dataset, we put it in the main task type category.
MainTaskType Fine-grainedTaskType Dataset
QuestionAnswering AdversarialQA(T)[Bartoloetal.,2020]
Flan-Coqa(T)[Weietal.,2022a;Reddyetal.,2019]
Flan-unified-QA(T)[Weietal.,2022a;Khashabi
etal.,2020]
HotpotQA(T)[Yangetal.,2018]
Mintaka-inst(T)[Senetal.,2022]
MLQA-en(T)[Lewisetal.,2020]
NQ-Open(T)[Kwiatkowskietal.,2019]
PIQA(T)[Bisketal.,2020]
WIKIQA(T)[Yangetal.,2015]
CNN-Daily-Mail(T)[Seeetal.,2017][Hermann
NaturalLanguage Summarization
etal.,2015]
Flan-GEM-wiki-lingua(T)[Weietal.,2022a;Ladhak
Generation
etal.,2020]
TextSimplification Wiki-split-inst(T)[Bothaetal.,2018]
Dialogue SODA-inst(T)[Kimetal.,2022]
NLGeneration Joke-explaination-inst(T)[theblackcat102,2023]
Flan-CoT-submix(T)[Weietal.,2022a]
Flan-lambada(T)[Weietal.,2022a;Papernoetal.,
2016]
Dolly-v2(T)[Conoveretal.,2023]
TextClassification EventLinking Xlel_wd-inst(T)[Pratapaetal.,2022]
ParaphraseIdentification PAWS-Wiki(T)[Zhangetal.,2019]
Table 11: Task Taxonomy of Translated Datasets (Aya Collection). We classify the translated
datasets similar to templated datasets (Table 10). If there is not a recognized fine-grained task
taxonomy for a specific dataset, we put it in the main task type category.
85Dataset #Langs D Laa nta gs ue at ge L¬Ø prompt L¬Ø compl. License Task
adversarial_qadbert[Bartoloetal., CCBY-SA Question
1 eng 655 263
2020;maxbartolo,2023a] 3.0 Answering
adversarial_qadbidaf[Bartoloetal., CCBY-SA Question
1 eng 669 256
2020;maxbartolo,2023b] 4.0 Answering
adversarial_qadroberta[Bartolo CCBY-SA Question
1 eng 742 243
etal.,2020;maxbartolo,2023c] 4.0 Answering
ag_news[Gulli,2005;jxmorris12 BSD-3- Text
1 eng 292 40
etal.,2023] Clause Classification
ai2_arcARC-Challenge[Clarketal., Question
1 eng 351 33 GPL-3
2018] Answering
Question
ai2_arcARC-Easy[Clarketal.,2018] 1 eng 307 26 GPL-3
Answering
BSD-3- Sentiment
amazon_polarity[Zhangetal.,2015] 1 eng 454 83
Clause Analysis
Sentiment
app_reviews[Granoetal.,2017] 1 eng 159 28 Unknown
Analysis
Question
cluec3[Xuetal.,2020] 1 zho 338 7 Apache2.0
Answering
CCBY-SA Question
cluecmrc2018[Cuietal.,2019] 1 zho 426 178
4.0 Answering
Question
cluecsl[Lietal.,2022] 1 zho 315 64 Apache2.0
Answering
CCBY-SA Question
cluedrcd[Shaoetal.,2019] 1 zho 436 128
3.0 Answering
Question
cluetnews[Xuetal.,2020] 1 zho 235 7 Apache2.0
Answering
cnn_dailymail_3.0.0[Nallapatietal.,
1 eng 1699 646 Unknown Summarization
2016]
common_gen[Linetal.,2020] 1 eng 96 49 MIT Generation
BSD-3-
cos_e_v1.11[Rajanietal.,2019] 1 eng 208 19 Generation
Clause
Question
cosmos_qa[Huangetal.,2019] 1 eng 547 51 Unknown
Answering
Topic
dbpedia_14[Lehmannetal.,2014] 1 eng 378 64 Apache2.0
Classification
Question
dream[Guetal.,2022] 1 eng 511 152 Apache2.0
Answering
duorcParaphraseRC[Sahaetal., Question
1 eng 1438 663 MIT
2018] Answering
Question
duorcSelfRC[Sahaetal.,2018] 1 eng 1411 645 MIT
Answering
Text
GEM/BiSECT[Kimetal.,2021] 3 eng,spa,fra 346 251 Unknown
Simplification
CC
GEM/xlsum[Hasanetal.,2021] 2 eng,ben 1156 636 BY-NC-SA Summarization
4.0
gigaword[Rushetal.,2015;Graff
1 eng 181 80 Unknown Summarization
etal.,2003]
gluemrpc[Warstadtetal.,2018;
Text
Wangetal.,2018;Dolan&Brockett, 1 eng 270 38 MIT
Classification
2005]
glueqqp[Warstadtetal.,2018;Wang Text
1 eng 199 4 Unknown
etal.,2018;Iyeretal.,2012] Classification
Sentiment
imdb[Maasetal.,2011] 1 eng 1089 106 Unknown
Analysis
arb, ben, eng, Question
tydiqa-goldp[Clarketal.,2020] 6 526 115 Apache2.0
ind,swh,tel Answering
arb, ben, eng, Question
tydiqa-primary[Clarketal.,2020] 6 1110 332 Apache2.0
ind,swa,tel Answering
kilt_taskshotpotqa[Petronietal., Question
1 eng 137 15 MIT
2021] Answering
Custom
multi_news[Fabbrietal.,2019] 1 eng 3466 1442 Summarization
license
86openbookqamain[Mihaylovetal., Question
1 eng 163 16 Apache2.0
2018] Answering
CCBY-NC Text
xlwicxlwic[Raganatoetal.,2020] 1 eng 225 3
4.0 Classification
pawslabeled_final[Zhangetal., Custom Paraphrase
1 eng 285 12
2019] license Identification
eng, spa, fra, Custom Paraphrase
paws-x[Yangetal.,2019] 4 255 11
zho license Identification
Question
piqa[Bisketal.,2020] 1 eng 256 72 AFL3.0
Answering
Question
qasc[Khotetal.,2020] 1 eng 314 38 Apache2.0
Answering
CC
Question
quail[Rogersetal.,2020] 1 eng 1752 18 BY-NC-SA
Answering
4.0
Question
quarel[Tafjordetal.,2019a] 1 eng 289 10 CCBY4.0
Answering
Question
quartz[Tafjordetal.,2019b] 1 eng 307 9 CCBY4.0
Answering
Question
quoref[Dasigietal.,2019] 1 eng 1556 388 CCBY4.0
Answering
Custom Question
racehigh[Laietal.,2017] 1 eng 1723 229
license Answering
Custom Question
racemiddle[Laietal.,2017] 1 eng 1141 144
license Answering
Question
ropes[Linetal.,2019] 1 eng 886 97 CCBY4.0
Answering
Sentiment
rotten_tomatoes[Pang&Lee,2005] 1 eng 152 18 Unknown
Analysis
CCBY-
samsum[Gliwaetal.,2019] 1 eng 473 170 Summarization
NC-ND4.0
CCBY-NC Question
sciq[Welbletal.,2017] 1 eng 346 139
3.0 Answering
Question
social_i_qa[Sapetal.,2019] 1 eng 182 15 CCBY4.0
Answering
CCBY-SA Question
squad_v2[Rajpurkaretal.,2016] 1 eng 689 82
4.0 Answering
super_glueboolq[Clarketal.,2019; CCBY-SA Question
1 eng 653 76
Wangetal.,2019] 3.0 Answering
super_gluemultirc[Khashabietal., Custom Question
1 eng 1509 120
2018] license Answering
super_gluerecord[Zhangetal., Question
1 eng 1175 70 Apache2.0
2018a] Answering
super_gluewic[Pilehvar& CCBY-NC Text
1 eng 170 3
Camacho-Collados,2019] 4.0 Classification
trec[Li&Roth,2002;Hovyetal., Text
1 eng 144 9 Unknown
2001] Classification
trivia_qaunfiltered[Joshietal., Question
1 eng 148 92 Unknown
2017] Answering
Question
web_questions[Berantetal.,2013] 1 eng 70 17 Unknown
Answering
CCBY-SA
wiki_bio[Lebretetal.,2016] 1 eng 586 328 Generation
3.0
CCBY-SA Question
wiki_hoporiginal[Tuetal.,2019] 1 eng 6363 748
3.0 Answering
Custom Question
wiki_qa[Yangetal.,2015] 1 eng 224 26
license Answering
Question
wiqa[Tandonetal.,2019] 1 eng 408 44 Apache-2.0
Answering
CCBY-SA Question
xquad[Artetxeetal.,2019] 2 zho,vie 652 173
4.0 Answering
xsum[Narayanetal.,2018] 1 eng 1412 250 MIT Summarization
Custom Sentiment
yelp_review_full[Zhangetal.,2015] 1 eng 620 91
license Analysis
Table 12: List of xP3 datasets [Muennighoff et al., 2023c].
87J Data Cards
Following Pushkarna et al. [2022] and the HuggingFace data card template19, we present the data
card for the Aya Dataset.
Data Card for the Aya Dataset
The Aya Dataset is a multilingual instruction fine-tuning dataset curated by an open-science
community. The dataset contains a total of 204,114 annotated prompt-completion pairs.
‚Ä¢ Curated by: 2,007 contributors from 110 countries
‚Ä¢ Language(s): 65 languages
‚Ä¢ License: Apache 2.0
‚Ä¢ Repository: https://huggingface.co/datasets/CohereForAI/aya_dataset
Authorship
Publishing Organization: Industry Type: Contact Details:
Cohere For AI Not-for-profit - Tech https://aya.for.ai/
Example of Data Points
The dataset contains multilingual prompts and completions in the following format: {prompt:
"What day is followed by Saturday?", completion : "Saturday is followed by
Sunday.", language: "English" }
Motivations & Intentions
Curation Rationale: The curation effort employed an open-science approach to create a diverse
instruction-style dataset through annotators across the globe that ensures comprehensive repre-
sentation across all languages. The success of the curation effort, led by volunteers across diverse
backgrounds, was significantly influenced by their hope to meaningfully bring NLP advancements
to their languages.
Provenance
Methods Used Methodology Details
crowd-sourced through volunteer annotations, Source: Originalannotationsandeditsofopen-
followedbyaqualityassessmentphaseinwhich source NLP datasets
samples from the dataset were checked. Platform: Aya Annotation Platform
Dates of Collection: Jun 2023 - Dec 2023
Dataset Version and Maintenance
Maintenance Status Version Details Maintenance Plan
Actively Maintained Current version: 1.0 Updates will be periodically
Last Update: 12/2023 made available based on vol-
First Release: 02/2024 unteer contributions
19https://huggingface.co/docs/datasets/v2.15.0/en/dataset_card
88Data Card for the Aya Collection
TheAyaCollectionincorporatesinstruction-styletemplatesfromfluentspeakersandappliesthem
to a curated list of 44 datasets. It also includes translations of 19 instruction-style datasets into
101languages. Thiscollectionprovides513,579,625instancesofpromptsandcompletionscovering
a wide range of tasks..
‚Ä¢ Curated by: 2007 contributors from 110 countries
‚Ä¢ Language(s): 114 languages
‚Ä¢ License: Apache 2.0
‚Ä¢ Repository: https://huggingface.co/datasets/CohereForAI/aya_collection
Authorship
Publishing Organization: Industry Type: Contact Details:
Cohere For AI Not-for-profit - Tech https://aya.for.ai
Example of Data Points
The dataset contains multilingual prompts and completions in the following format: {‚Äòprompt‚Äô:
"Generate an article for the given headline: {{headline}}", ‚Äòcompletion‚Äô:
"{{news_article}}", ‚Äòlang‚Äô: "English" }
Motivations & Intentions
Curation Rationale: Automaticaugmentationofexistingdatasetsservestoenhancetheavailable
linguistic resources for multiple languages. List of languages were established from mT5 and
alignedwithannotators‚ÄôlanguagelistandNLLBtranslationmodel. Thedatasetsweretranslated
directly from English for all languages.
Provenance
Methods Used Methodology Details
combination of crowd-sourced templating and Source: Existing NLP datasets
automatic translation. Platform: Aya Annotation Platform
Dates of Collection: Jun 2023 - Dec 2023
Dataset Version and Maintenance
Maintenance Status Version Details Maintenance Plan
Actively Maintained Current version: 1.0 No updates planned.
Last updated: 12/2023
Release date: 02/2024
89Data Card for the Aya Evaluation Suite
The Aya Evaluation Suite contains a total of 25,750 open-ended conversation-style prompts cov-
ering 101 languages of three subsets:
aya-human-annotated: 250 original human-written prompts in 7 languages each.
dolly-machine-translated: 200 human-selected prompts from Conover et al. [2023], au-
tomatically translated with the NLLB model [NLLB-Team et al., 2022] from English into 101
languages.
dolly-human-edited: 200 dolly-machine-translated prompts post-edited by fluent speakers
for 6 languages.
‚Ä¢ Curated by: contributors, professional annotators, and synthetic generation
‚Ä¢ Language(s): 101 languages
‚Ä¢ License: Apache 2.0
‚Ä¢ Repository: https://huggingface.co/datasets/CohereForAI/aya_evaluation_suite
Authorship
Publishing Organization: Industry Type: Contact Details:
Cohere For AI Not-for-profit - Tech https://aya.for.ai
Example of Data Points
The dataset contains multilingual prompts in the following format: {‚Äòprompt‚Äô: "Which is a
species of fish? Bleak or Weary", ‚Äòlang‚Äô: "English" }
Motivations & Intentions
Curation Rationale: This evaluation suite is tailored for testing the generation quality of multi-
lingual models, with the aim to balance language coverage and human-sourced quality. It covers
prompts originally written in each language, as well as English-centric translated and manually
curatedoreditedpromptsforalinguisticallybroadbutrichtestbed. Thelistoflanguageswases-
tablishedfrommT5andalignedwithannotators‚ÄôlanguagelistandtheNLLBtranslationmodel.
Provenance
Methods Used Methodology Details
combination of original annotations by volun- Source: Original annotations and translations
teers, automatic translation, and post-editing and post-edits of Dolly
of translations by professional annotators. Platform: Aya Annotation Platform
Dates of Collection: Jun 2023 - Dec 2023
Dataset Version and Maintenance
Maintenance Status Version Details Maintenance Plan
Actively Maintained Current version: 1.0 No updates planned.
Last updated: 02/2024
Release date: 02/2024
90K Aya Collection Templates
Dataset #Id PromptTemplate CompletionTemplate
Answerthegivenquestioninoneofthe
followinglanguages,[bem,fon,hau,ibo,kin,
swh,twi,wol,yor,zul,eng,fra].
1 {{answer_in_target_language}}
AfriQA-inst
[Ogundepoetal., {{question_in_target_language}}
2023]
Giventhetweet,providethesentiment
associatedwithit.
Amongwhichofthesentimentcategories Iwouldclassifythegiventweetas:
1
AfriSenti-inst wouldyouclassifythefollowingtweet? {{sentiment}}
[Muhammadetal., positive,negative,orneutral
2023] {{tweet}}
Isthetweetbelowexpressingapositive,
Thetweetisexpressing{{sentiment}}
2 negative,orneutralsentiment? {{tweet}}
sentiment.
Giventhecontext,providetheanswertothe
askedquestion.
·ä®·å•·ã´·âÑ·ãç·åã·à≠·ã®·àö·àµ·àõ·àõ·ãç·àù·àã·àΩ{{answer_text}}
1
AmharicQA ·ä®·ãö·àÖ·â†·â≥·âΩ·â†·â∞·åà·àà·å∏·ãç·ä†·ãç·ãµ·â∞·ä®·â≥·ã©·äï·å•·ã´·âÑ·ã≠·àò·àç·à±·ç° ·äê·ãç·ç¢
[Abedissaetal.,2023] {{context}}{{question}}
·ä®·ãö·àÖ·â†·â≥·âΩ·ã´·àà·ãç·äï·ãù·à≠·ãù·à≠·àò·à®·åÉ·â†·àò·å†·âÄ·àù
·àà·àö·ä®·â∞·àà·ãç·å•·ã´·âÑ·àò·àç·àµ·ã≠·àµ·å°·ç°{{context}} ·ä®·å•·ã´·âÑ·ãç·ä†·äï·åª·à≠·âµ·ä≠·ä≠·àà·äõ·ãç·àò·àç·àµ{{answer_text}}
2
{{question}} ·äê·ãç·ç¢
·ä®·ãö·àÖ·â†·â≥·âΩ·ã´·àà·ãç·äï·åΩ·àë·çç·â†·àõ·å£·âÄ·àµ·ä•·â£·ä≠·ãé·äï
3
·àà·àö·ä®·â∞·àà·ãç·àò·àç·àµ·ã≠·àµ·å°{{context}}
·àà·å•·ã´·âÑ·ãç·àò·àç·àµ{{answer_text}}·äê·ãç·ç¢
{{question}}
·ã®·â∞·à∞·å†·ãç·äï·å•·ã´·âÑ·àà·àò·àò·àà·àµ·ä®·ãö·àÖ·â†·â≥·âΩ·ã®·âÄ·à®·â†·ãç·äï·àò·à®·åÉ
·àà·â∞·å†·âÄ·à∞·ãç·å•·ã´·âÑ·âµ·ä≠·ä≠·àà·äõ·ãç·àù·àã·àΩ
4 ·ã≠·àò·àç·ä®·â±·ç°{{context}}{{question}} {{answer_text}}·äê·ãç·ç¢
·àà·àö·ä®·â∞·àà·ãç·å•·ã´·âÑ·àù·àã·àΩ·àà·àò·àµ·å†·âµ·ä®·ãö·àÖ·â†·â≥·âΩ
5
·ã®·âÄ·à®·â†·ãç·äï·ä†·ãç·ãµ·â∞·å†·âÄ·àù·ç°{{context}}
·àà·å•·ã´·âÑ·ãç·àò·àç·à± {{answer_text}}·äê·ãç·ç¢
{{question}}
·ã®·â∞·à∞·å†·ãç·äï·å•·ã´·âÑ·ä®·ãö·àÖ·â†·â≥·âΩ·â†·â∞·à∞·å†·ãç·ä†·ãç·ãµ·àò·à∞·à®·âµ
6 ·àò·àç·à±·ç°{{context}}{{question}} ·àà·å•·ã´·âÑ·ãç·âµ·ä≠·ä≠·àà·äõ·ãç·àù·àã·àΩ{{answer_text}}·äê·ãç·ç¢
Generatethesummary/headlineofthegiven
newsarticle.
1 ‡¶è‡¶á‡¶∏‡¶Ç‡¶¨‡¶æ‡ßá‡¶¶‡¶∞‡¶ú‡¶®‡ßç‡¶Ø‡¶è‡¶ï‡¶ø‡¶ü‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡¶ø‡¶∂‡ßá‡¶∞‡¶æ‡¶®‡¶æ‡¶Æ‡ßá‡¶≤‡¶ñ: ‡¶™‡ßç‡¶∞‡¶¶‡ßé‡¶§‡¶∏‡¶Ç‡¶¨‡¶æ‡ßá‡¶¶‡¶∞‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡¶ø‡¶∂‡ßá‡¶∞‡¶æ‡¶®‡¶æ‡¶Æ‡¶π‡ßá‡¶≤‡¶æ, {{headline}}
News-summary-
instruct[TahmidH,
{{article}}
2023]
2
‡¶è‡¶ï‡¶ø‡¶ü‡¶¨‡¶æ‡ßá‡¶ï‡ßç‡¶Ø‡ßá‡¶≤‡¶ñ‡¶æ‡¶ø‡¶ü‡¶∞‡¶Æ‡¶≤‡ßÇ ‡¶¨(cid:8970)‡¶¨‡ßç‡¶Ø‡¶§‡ßá‡ßÅ‡¶≤‡¶ß‡¶∞:{{article}}
‡¶™‡ßç‡¶∞‡¶¶‡ßé‡¶§‡¶Ö‡¶®‡ßá‡ßÅ(cid:9003)‡ßá‡¶¶‡¶∞‡¶∏‡¶Ç‡¶ø‡¶ï‡ßç‡¶∑(cid:9074)‡¶Æ‡¶≤‡ßÇ ‡¶≠‡¶æ‡¶¨‡¶π‡ßá‡¶≤‡¶æ, {{summary}}
‡¶ø‡¶®‡ßá‡¶ö‡¶∞‡¶Ö‡¶®‡ßá‡ßÅ(cid:9003)‡ßá‡¶¶‡¶ï‡ßÄ‡¶¨‡¶≤‡¶æ‡¶π‡ßá‡ßü‡ßá‡¶õ‡¶§‡¶æ‡¶∏‡¶Ç‡ßá‡¶ï‡ßç‡¶∑‡ßá‡¶™‡¶¨‡¶£‡¶∞‡ßç‡¶®‡¶æ‡¶ï‡¶∞‡•§
3 ‡¶™‡ßç‡¶∞‡¶¶‡ßé‡¶§‡¶Ö‡¶®‡ßá‡ßÅ(cid:9003)‡ßá‡¶¶‡¶∞‡¶∏‡¶Ç‡¶ø‡¶ï‡ßç‡¶∑(cid:9074)‡¶Æ‡¶≤‡ßÇ ‡¶≠‡¶æ‡¶¨‡¶π‡ßá‡¶≤‡¶æ, {{summary}}
{{article}}
‡¶ø‡¶®‡ßá‡¶ö‡¶∞‡¶Ö‡¶®‡ßá‡ßÅ(cid:9003)‡ßá‡¶¶‡¶ï‡ßÄ‡¶¨‡¶≤‡¶æ‡¶π‡ßá‡ßü‡ßá‡¶õ‡¶§‡¶æ‡¶∏‡¶Ç‡ßá‡¶ï‡ßç‡¶∑‡ßá‡¶™‡¶¨‡¶£‡¶∞‡ßç‡¶®‡¶æ‡¶ï‡¶∞‡•§
4 {{summary}}
{{article}}
‡¶è‡¶ï‡¶¨‡¶æ‡ßá‡¶ï‡ßç‡¶Ø‡¶ø‡¶®‡ßá‡¶ö‡¶∞‡¶Ö‡¶®‡ßá‡ßÅ(cid:9003)‡ßá‡¶¶‡¶∞‡¶∏‡¶æ‡¶∞‡¶æ‡¶Ç‡¶∂‡ßá‡¶≤‡¶ñ‡•§
5 ‡¶™‡ßç‡¶∞‡¶¶‡ßé‡¶§‡¶Ö‡¶®‡ßá‡ßÅ(cid:9003)‡ßá‡¶¶‡¶∞‡¶∏‡¶Ç‡¶ø‡¶ï‡ßç‡¶∑(cid:9074)‡¶Æ‡¶≤‡ßÇ ‡¶≠‡¶æ‡¶¨‡¶π‡ßá‡¶≤‡¶æ, {{summary}}
{{article}}
91‡¶∏‡¶Ç‡ßá‡¶ï‡ßç‡¶∑‡ßá‡¶™‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶ø‡¶ü‡¶∞‡¶Æ‡¶≤‡ßÇ ‡¶≠‡¶æ‡¶¨‡¶§‡ßá‡ßÅ‡¶≤‡¶ß‡ßá‡¶∞‡¶æ: {{article}}
6 {{summary}}
‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡¶ø‡¶∂‡ßá‡¶∞‡¶æ‡¶®‡¶æ‡¶Æ‡¶ø‡¶≤‡¶ñ‡¶®‡ßÅ : {{article}}
7 ‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡¶ø‡¶ü‡¶∞‡¶ø‡¶∂‡ßá‡¶∞‡¶æ‡¶®‡¶æ‡¶Æ‡¶π‡ßá‡¶≤‡¶æ, {{headline}}
‡¶∏‡¶Ç‡ßá‡¶ï‡ßç‡¶∑‡ßá‡¶™‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶ø‡¶ü‡¶∞‡¶Æ‡¶≤‡ßÇ ‡¶≠‡¶æ‡¶¨‡¶§‡ßá‡ßÅ‡¶≤‡¶ß‡ßá‡¶∞‡¶æ: {{article}}
8 ‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶ø‡¶ü‡¶∞‡¶∏‡¶Ç‡¶ø‡¶ï‡ßç‡¶∑(cid:9074)‡¶Æ‡¶≤‡ßÇ ‡¶≠‡¶æ‡¶¨‡¶π‡ßá‡¶≤‡¶æ, {{summary}}
‡¶ø‡¶®(cid:9071)‡¶ø‡¶≤‡¶ø‡¶ñ‡¶§‡¶∏‡¶Ç‡¶¨‡¶æ‡ßá‡¶¶‡¶∞‡¶ø‡¶∂‡ßá‡¶∞‡¶æ‡¶®‡¶æ‡¶Æ‡¶ï‡ßÄ‡¶π‡ßá‡¶§‡¶™‡¶æ‡ßá‡¶∞?
9 ‡¶™‡ßç‡¶∞‡¶¶‡ßé‡¶§‡¶∏‡¶Ç‡¶¨‡¶æ‡ßá‡¶¶‡¶∞‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡¶ø‡¶∂‡ßá‡¶∞‡¶æ‡¶®‡¶æ‡¶Æ‡¶π‡ßá‡¶≤‡¶æ, {{headline}}
{{article}}
‡¶è‡¶ï‡¶¨‡¶æ‡ßá‡¶ï‡ßç‡¶Ø‡¶ø‡¶®‡ßá‡¶ö‡¶∞‡¶Ö‡¶®‡ßá‡ßÅ(cid:9003)‡ßá‡¶¶‡¶∞‡¶∏‡¶æ‡¶∞‡¶æ‡¶Ç‡¶∂‡ßá‡¶≤‡¶ñ‡•§
10 {{summary}}
{{article}}
‡¶Ü‡ßá‡¶∞‡¶æ‡¶ï‡¶Æ‡¶∂‡ßá‡¶¨‡ßç‡¶¶‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶ø‡¶ü‡¶∞‡¶Æ‡¶≤‡ßÇ ‡¶≠‡¶æ‡¶¨‡¶¨‡¶£‡¶∞‡ßç‡¶®‡¶æ‡¶ï‡¶∞: {{article}}
11 {{summary}}
‡¶™‡ßç‡¶∞‡¶¶‡ßé‡¶§‡¶§‡¶•‡ßç‡¶Ø‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ï‡ßá‡¶∞‡¶è‡¶ï‡¶ø‡¶ü‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡¶ø‡¶∂‡ßá‡¶∞‡¶æ‡¶®‡¶æ‡¶Æ‡¶ø‡¶≤‡¶ñ‡¶®‡ßÅ :
12 {{article}} ‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡¶ø‡¶ü‡¶∞‡¶ø‡¶∂‡ßá‡¶∞‡¶æ‡¶®‡¶æ‡¶Æ‡¶π‡ßá‡¶≤‡¶æ, {{headline}}
13 ‡¶Ü‡ßá‡¶∞‡¶æ‡¶ï‡¶Æ‡¶∂‡ßá‡¶¨‡ßç‡¶¶‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶ø‡¶ü‡¶∞‡¶Æ‡¶≤‡ßÇ ‡¶≠‡¶æ‡¶¨‡¶¨‡¶£‡¶∞‡ßç‡¶®‡¶æ‡¶ï‡¶∞: {{article}} ‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶ø‡¶ü‡¶∞‡¶∏‡¶Ç‡¶ø‡¶ï‡ßç‡¶∑(cid:9074)‡¶Æ‡¶≤‡ßÇ ‡¶≠‡¶æ‡¶¨‡¶π‡ßá‡¶≤‡¶æ, {{summary}}
‡¶è‡¶ï‡¶ø‡¶ü‡¶¨‡¶æ‡ßá‡¶ï‡ßç‡¶Ø‡ßá‡¶≤‡¶ñ‡¶æ‡¶ø‡¶ü‡¶∞‡¶Æ‡¶≤‡ßÇ ‡¶¨(cid:8970)‡¶¨‡ßç‡¶Ø‡¶§‡ßá‡ßÅ‡¶≤‡¶ß‡¶∞: {{article}}
14 {{summary}}
‡¶ø‡¶®(cid:9093)‡¶ø‡¶≤‡¶ø‡¶ñ‡¶§‡¶∏‡¶Ç‡¶¨‡¶æ‡ßá‡¶¶‡¶∞‡¶ø‡¶≠‡¶ø‡ßé‡¶§‡ßá‡¶§‡¶è‡¶ï‡¶ø‡¶ü‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡¶ø‡¶∂‡ßá‡¶∞‡¶æ‡¶®‡¶æ‡¶Æ‡¶ø‡¶≤‡¶ñ‡¶®‡ßÅ
15 ‡¶™‡ßç‡¶∞‡¶¶‡ßé‡¶§‡¶∏‡¶Ç‡¶¨‡¶æ‡ßá‡¶¶‡¶∞‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡¶ø‡¶∂‡ßá‡¶∞‡¶æ‡¶®‡¶æ‡¶Æ‡¶π‡ßá‡¶≤‡¶æ, {{headline}}
{{article}}
Paraphrasethefollowingsentence.
’é’•÷Ä’°’∫’°’ø’¥’•÷Ñ’∞’°’ª’∏÷Ä’§
1 {{sentence2}}
Arpa-instruct ’∂’°’≠’°’§’°’Ω’∏÷Ç’©’µ’∏÷Ç’∂’®:
[syntaxshill,2023] {{sentence1}}
‘≥÷Ä’•÷Ñ’∞’°’ª’∏÷Ä’§’∂’°’≠’°’§’°’Ω’∏÷Ç’©’µ’°’∂
’æ’•÷Ä’°’∫’°’ø’¥’∏÷Ç’¥’®:
2 {{sentence2}}
{{sentence1}
‘≥÷Ä’•÷Ñ’∂’°’≠’°’§’°’Ω’∏÷Ç’©’µ’∏÷Ç’∂’æ’•÷Ä’°’∫’°’ø’¥’•’¨’∏÷Ç
’∞’°’¥’°÷Ä’∞’°’ª’∏÷Ä’§’®:
3 {{sentence2}}
{{sentence1}
FoodItem‡∞ï‡∞ø‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞ß‡±ç‡∞≤‡±Å‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á
Giventhenameofthefooditem,generates
‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç‡∞á‡∞ï‡∞ï‡±ç‡∞°‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø.‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞•‡±ç‡∞≤‡±Å:
thedetailedrecipealongwiththeingredients.
{{Ingredients}}
1
Telugu-food-recipes
[SuryaKrishna02,
{{FoodItem}}‡∞é‡∞≤‡∞æ‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡∞æ‡∞§‡±ç‡∞∞‡±ã‡∞ï‡±Å‡∞≤‡±ç‡∞™‡∞§‡±ç‡∞Ç‡∞ó‡∞æ‡∞á‡∞µ‡∞µ‡±ç‡∞Ç‡∞°‡∞ø.
‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç:
2023a] {{CookingInstructions}}
FoodItem‡∞ï‡∞ø‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞ß‡±ç‡∞≤‡±Å‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á
‡∞Æ‡±Ä‡∞∞‡±Å{{FoodItem}}‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±Ü‡∞Ø‡∞Ø‡±ç‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø‡∞é‡∞ü‡±Å‡∞µ‡∞Ç‡∞ü‡∞ø ‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç‡∞á‡∞ï‡∞ï‡±ç‡∞°‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø.‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞•‡±ç‡∞≤‡±Å:
2 ‡∞§‡∞ø‡∞Ç‡∞°‡∞ø‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞ß‡±ç‡∞≤‡±Å‡∞µ‡∞æ‡∞°‡±Å‡∞§‡±Å‡∞∞‡±Å‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞è‡∞µ‡∞ø‡∞ß‡∞Æ‡±Å‡∞ó‡∞æ‡∞ö‡±á‡∞∏‡∞æ‡∞§‡±ç‡∞∞‡±ã {{Ingredients}}
‡∞µ‡∞ø‡∞µ‡∞∞‡∞£‡∞á‡∞µ‡∞µ‡±ç‡∞Ç‡∞°‡∞ø.
‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç:
{{CookingInstructions}}
FoodItem‡∞ï‡∞ø‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞ß‡±ç‡∞≤‡±Å‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á
‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç‡∞á‡∞ï‡∞ï‡±ç‡∞°‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø.‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞•‡±ç‡∞≤‡±Å:
‡∞®‡±á‡∞®‡±Å{{FoodItem}}‡∞ö‡∞æ‡∞≤‡∞æ‡∞∞‡±Å‡∞ö‡∞ø‡∞ï‡∞∞‡∞Ç‡∞ó‡∞æ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡∞ø‡∞Ö‡∞®‡∞ø
{{Ingredients}}
3 ‡∞µ‡∞ø‡∞®‡∞æ‡∞®‡±ç‡∞®‡±Å. ‡∞®‡∞æ‡∞ï‡±Å‡∞á‡∞¶‡∞ø‡∞é‡∞≤‡∞æ‡∞ö‡±Ü‡∞Ø‡∞æ‡∞Ø‡±ç‡∞≤‡±ã‡∞∏‡∞Ç‡∞ï‡∞ø‡∞™‡∞≤‡±ç ‡∞§‡±ç‡∞Ç‡∞ó‡∞æ‡∞ö‡±Ü‡∞™‡±Å‡∞™‡±ç.
‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç:
{{CookingInstructions}}
92FoodItem‡∞ï‡∞ø‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞ß‡±ç‡∞≤‡±Å‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á
‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç‡∞á‡∞ï‡∞ï‡±ç‡∞°‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø.‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞•‡±ç‡∞≤‡±Å:
‡∞Æ‡±ä‡∞¶‡∞ü‡∞ø‡∞∏‡∞æ‡∞∞‡∞ø‡∞µ‡∞Ç‡∞ü‡∞ö‡±á‡∞∏‡±á‡∞µ‡∞æ‡∞∞‡∞ø‡∞ï‡∞ø‡∞ö‡±Ü‡∞™‡∞ø‡∞™‡±ç‡∞®‡∞ü‡∞ü‡±ç‡±Å‡∞®‡∞æ‡∞ï‡±ÅFoodItem
{{Ingredients}}
4 ‡∞é‡∞≤‡∞æ‡∞ö‡±Ü‡∞Ø‡∞æ‡∞Ø‡±ç‡∞≤‡±ä‡∞ö‡±Ü‡∞™‡±Å‡∞™‡±ç
‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç:
{{CookingInstructions}}
FoodItem‡∞ï‡∞ø‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞ß‡±ç‡∞≤‡±Å‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á
{{FoodItem}}‡∞é‡∞≤‡∞æ‡∞ö‡±á‡∞Ø‡∞æ‡∞≤‡∞ø? ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç‡∞≤‡±ã ‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç‡∞á‡∞ï‡∞ï‡±ç‡∞°‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø.‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞•‡±ç‡∞≤‡±Å:
5 ‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞ß‡±ç‡∞≤‡±Å‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç {{Ingredients}}
‡∞â‡∞Ç‡∞°‡∞æ‡∞≤‡∞ø.
‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç:
{{CookingInstructions}}
FoodItem‡∞ï‡∞ø‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞ß‡±ç‡∞≤‡±Å‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á
‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç‡∞á‡∞ï‡∞ï‡±ç‡∞°‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø.‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞•‡±ç‡∞≤‡±Å:
6
{{FoodItem}}‡∞é‡∞≤‡∞æ‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡∞æ‡∞§‡±ç‡∞Ç? {{Ingredients}}
‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç:
{{CookingInstructions}}
FoodItem‡∞ï‡∞ø‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞ß‡±ç‡∞≤‡±Å‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á
‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç‡∞á‡∞ï‡∞ï‡±ç‡∞°‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø.‡∞ï‡∞æ‡∞µ‡∞≤‡∞∏‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞∞‡∞æ‡∞•‡±ç‡∞≤‡±Å:
7
{{FoodItem}}‡∞∞‡±Ü‡∞∏‡∞ø‡∞™‡±Ä‡∞è‡∞Ç‡∞ü‡∞ø? {{Ingredients}}
‡∞§‡∞Ø‡∞æ‡∞∞‡±Å‡∞ö‡±á‡∞∏‡±á‡∞µ‡∞ø‡∞ß‡∞æ‡∞®‡∞Ç:
{{CookingInstructions}}
Giventhetitleofafunnyconversation,
generateafunnyconversationbasedonthe
‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
title.
1
Telugu-jokes
{{FunnyConversation}}
[SuryaKrishna02, {{Title}}‡∞Ö‡∞®‡±á‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞§‡±ã‡∞ú‡±ã‡∞ï‡±ç‚Äç‡∞á‡∞µ‡±Å‡∞µ‡±ç
2023b]
‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
2
{{Title}}‡∞Ö‡∞®‡±á(cid:337)‡∞ü‡∞ø‡∞≤‡±ç‚Äç‡∞§‡±ã‡∞ú‡±ã‡∞ï‡±ç‚Äç‡∞á‡∞µ‡±Å‡∞µ‡±ç
{{FunnyConversation}}
‡∞í‡∞ï‡∞π‡∞æ‡∞∏‡∞Ø‡±ç‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø‡∞Ø‡±ä‡∞ï‡∞ï‡±ç‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
3 {{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
‡∞í‡∞ï‡∞ö‡∞ø‡∞®‡∞®‡±ç‡∞π‡∞æ‡∞∏‡∞Ø‡±ç‡∞∏‡∞®‡∞ø‡∞®‡±ç‡∞µ‡±á‡∞∂‡∞Ç‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø‡∞Ø‡±ä‡∞ï‡∞ï‡±ç‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
4 {{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
‡∞í‡∞ï‡∞ö‡∞Æ‡∞§‡∞æ‡∞ï‡±ç‡∞∞‡∞Æ‡∞Ø‡∞ø‡∞®‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
5 ‡∞Ø‡±ä‡∞ï‡∞ï‡±ç‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï{{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
‡∞í‡∞ï‡∞ö‡∞ø‡∞®‡∞®‡±ç‡∞ö‡∞Æ‡∞§‡∞æ‡∞ï‡±ç‡∞∞‡∞Æ‡∞Ø‡∞ø‡∞®‡∞∏‡∞®‡∞ø‡∞®‡±ç‡∞µ‡±á‡∞∂‡∞Ç‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
6 ‡∞Ø‡±ä‡∞ï‡∞ï‡±ç‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï{{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
‡∞í‡∞ï‡∞§‡∞Æ‡∞æ‡∞∑‡∞æ‡∞Ö‡∞Ø‡∞ø‡∞®‡∞æ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
7 ‡∞Ø‡±ä‡∞ï‡∞ï‡±ç‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï{{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
‡∞í‡∞ï‡∞ö‡∞ø‡∞®‡∞®‡±ç‡∞§‡∞Æ‡∞æ‡∞∑‡∞æ‡∞Ö‡∞Ø‡∞ø‡∞®‡∞æ‡∞∏‡∞®‡∞ø‡∞®‡±ç‡∞µ‡±á‡∞∂‡∞Ç‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
8 ‡∞Ø‡±ä‡∞ï‡∞ï‡±ç‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï{{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
‡∞í‡∞ï‡∞π‡∞æ‡∞∏‡∞Ø‡±ç‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø‡∞Ø‡±ä‡∞ï‡∞ï‡±ç(cid:337)‡∞ü‡∞ø‡∞≤‡±ç‚Äç ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
9 {{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
‡∞í‡∞ï‡∞ö‡∞ø‡∞®‡∞®‡±ç‡∞π‡∞æ‡∞∏‡∞Ø‡±ç‡∞∏‡∞®‡∞ø‡∞®‡±ç‡∞µ‡±á‡∞∂‡∞Ç‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø‡∞Ø‡±ä‡∞ï‡∞ï‡±ç(cid:337)‡∞ü‡∞ø‡∞≤‡±ç‚Äç ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
10 {{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
‡∞í‡∞ï‡∞ö‡∞Æ‡∞§‡∞æ‡∞ï‡±ç‡∞∞‡∞Æ‡∞Ø‡∞ø‡∞®‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
11 ‡∞Ø‡±ä‡∞ï‡∞ï‡±ç(cid:337)‡∞ü‡∞ø‡∞≤‡±ç‚Äç{{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
93‡∞í‡∞ï‡∞ö‡∞ø‡∞®‡∞®‡±ç‡∞ö‡∞Æ‡∞§‡∞æ‡∞ï‡±ç‡∞∞‡∞Æ‡∞Ø‡∞ø‡∞®‡∞∏‡∞®‡∞ø‡∞®‡±ç‡∞µ‡±á‡∞∂‡∞Ç‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
12 ‡∞Ø‡±ä‡∞ï‡∞ï‡±ç(cid:337)‡∞ü‡∞ø‡∞≤‡±ç‚Äç{{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
‡∞í‡∞ï‡∞§‡∞Æ‡∞æ‡∞∑‡∞æ‡∞Ö‡∞Ø‡∞ø‡∞®‡∞æ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
13 ‡∞Ø‡±ä‡∞ï‡∞ï‡±ç(cid:337)‡∞ü‡∞ø‡∞≤‡±ç‚Äç{{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
‡∞í‡∞ï‡∞ö‡∞ø‡∞®‡∞®‡±ç‡∞§‡∞Æ‡∞æ‡∞∑‡∞æ‡∞Ö‡∞Ø‡∞ø‡∞®‡∞æ‡∞∏‡∞®‡∞ø‡∞®‡±ç‡∞µ‡±á‡∞∂‡∞Ç‡∞á‡∞µ‡±Å‡∞µ‡±ç‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å‡∞¶‡∞æ‡∞®‡∞ø ‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï: {{Title}}
14 ‡∞Ø‡±ä‡∞ï‡∞ï‡±ç(cid:337)‡∞ü‡∞ø‡∞≤‡±ç‚Äç{{Title}}‡∞â‡∞Ç‡∞°‡±á‡∞≤‡∞æ‡∞ó‡∞æ‡∞á‡∞µ‡±Å‡∞µ‡±ç.
{{FunnyConversation}}
GivenTitle/Headlineofthearticle,generate
thearticlewiththatTitle/Headline.
Onewordfromtheset(enclosedwithin
squarebrackets)ischosenatrandomanda
prompttemplateiscreated.
1 {{Article}}
Telugu-news-articles
[SuryaKrishna02, [‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞ø|‡∞ï‡∞ø‡∞Ç‡∞¶‡∞ø|‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞®|‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®][‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞§‡±ã|(cid:337)‡∞ü‡∞ø‡∞≤‡±ç‚Äç‡∞§‡±ã
2023c] |‡∞π‡±Ü‡∞°‡±Ü(cid:604)‡∞®‡±ç‚Äç‡∞§‡±ã][‡∞µ‡∞æ‡∞∞‡∞æ(cid:588) ‡∞ï‡∞•‡∞®‡∞æ‡∞®‡∞ø‡∞®‡±ç|‡∞®‡±Ç‡∞Ø‡±ç‡∞∏‡±ç‚Äç‡∞Ü‡∞∞‡∞ø‡∞ü‡±ç‡∞ï‡∞≤‡±ç‚Äç‡∞®‡∞ø|‡∞®‡±Ç‡∞Ø‡±ç‡∞∏‡±ç‚Äç
‡∞ï‡∞•‡∞®‡∞æ‡∞®‡∞ø‡∞®‡±ç][‡∞µ‡∞æ(cid:582)‡∞Ø‡∞Ç‡∞°‡∞ø|‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø]:
{{Title}}
Giventhearticle,generatetheTitle/Headline
forthearticle.
Onewordfromtheset(enclosedwithin
Onewordfromtheset(enclosedwithin
squarebrackets)ischosenatrandomanda
squarebrackets)ischosenatrandomanda
completiontemplateiscreated.
prompttemplateiscreated.
2
[‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®|‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞®][‡∞µ‡∞æ‡∞∞‡∞æ(cid:588) ‡∞ï‡∞•‡∞®‡∞æ‡∞®‡∞ø‡∞ï‡∞ø|‡∞®‡±Ç‡∞Ø‡±ç‡∞∏‡±ç‚Äç‡∞Ü‡∞∞‡∞ø‡∞ü‡±ç‡∞ï‡∞≤‡±ç‚Äç‡∞ï‡∞ø
[‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞ø|‡∞ï‡∞ø‡∞Ç‡∞¶‡∞ø|‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞®|‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®][‡∞µ‡∞æ‡∞∞‡∞æ(cid:588) ‡∞ï‡∞•‡∞®‡∞æ‡∞®‡∞ø‡∞ï‡∞ø|
|‡∞®‡±Ç‡∞Ø‡±ç‡∞∏‡±ç‚Äç‡∞ï‡∞•‡∞®‡∞æ‡∞®‡∞ø‡∞ï‡∞ø][‡∞∏‡∞∞‡∞ø‡∞™‡±ã‡∞Ø‡±á|‡∞§‡∞ó‡∞ø‡∞®|‡∞Ö‡∞®‡±Å(cid:357)‡∞®][‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï
‡∞®‡±Ç‡∞Ø‡±ç‡∞∏‡±ç‚Äç‡∞Ü‡∞∞‡∞ø‡∞ü‡±ç‡∞ï‡∞≤‡±ç‚Äç‡∞ï‡∞ø|‡∞®‡±Ç‡∞Ø‡±ç‡∞∏‡±ç‚Äç‡∞ï‡∞•‡∞®‡∞æ‡∞®‡∞ø‡∞ï‡∞ø][‡∞∂‡±Ä‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞®‡±Å|(cid:337)‡∞ü‡∞ø‡∞≤‡±ç‚Äç‡∞®‡±Å
|(cid:337)‡∞ü‡∞ø‡∞≤‡±ç‚Äç|‡∞π‡±Ü‡∞°‡±Ü(cid:604)‡∞®‡±ç‚Äç]‚Äô{{Title}}‚Äô.
|‡∞π‡±Ü‡∞°‡±Ü(cid:604)‡∞®‡±ç‚Äç‡∞®‡±Å][‡∞µ‡∞æ(cid:582)‡∞Ø‡∞Ç‡∞°‡∞ø|‡∞á‡∞µ‡∞µ‡±ç‡∞Ç‡∞°‡∞ø|‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø]:
{{Article}}
Giventhepoemandtypeofpoetry,explain
themeaningofthepoem.
‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Ç:
Telugu-poems
1 ‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø
{{Meaning}}
[SuryaKrishna02, ‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Ç‡∞á‡∞µ‡∞µ‡±ç‡∞Ç‡∞°‡∞ø:
{{Poem}}
2023e]
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø‡∞≠‡∞æ‡∞µ‡∞Ç
2 ‡∞á‡∞µ‡∞µ‡±ç‡∞Ç‡∞°‡∞ø: ‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø‡∞≠‡∞æ‡∞µ‡∞Ç:
{{Poem}} {{Meaning}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø
3 ‡∞≠‡∞æ‡∞µ‡∞Æ‡±Å‡∞á‡∞µ‡∞µ‡±ç‡∞Ç‡∞°‡∞ø: ‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø‡∞≠‡∞æ‡∞µ‡∞Æ‡±Å:
{{Poem}} {{Meaning}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø
4 ‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Æ‡±Å‡∞á‡∞µ‡∞µ‡±ç‡∞Ç‡∞°‡∞ø: ‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Æ‡±Å:
{{Poem}} {{Meaning}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø‡∞Ö‡∞∞‡∞ß‡±ç‡∞Ç
5 ‡∞á‡∞µ‡∞µ‡±ç‡∞Ç‡∞°‡∞ø:
‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø‡∞Ö‡∞∞‡∞ß‡±ç‡∞Ç:
{{Poem}} {{Meaning}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø‡∞Ö‡∞∞‡∞ß‡±ç‡∞Æ‡±Å
6 ‡∞á‡∞µ‡∞µ‡±ç‡∞Ç‡∞°‡∞ø:
‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®{{Poetry_Type}}‡∞≤‡±ã‡∞®‡∞ø‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞ï‡∞ø‡∞Ö‡∞∞‡∞ß‡±ç‡∞Æ‡±Å:
{{Poem}} {{Meaning}}
94Giventhemeaningandthetypeofpoetry,
generatethecorrespondingpoem.
‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Ç‡∞µ‡∞ö‡±á‡∞ö‡±ç{{Poetry_Type}}(cid:358)‡∞≤‡∞ø‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
7 ‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Ç‡∞µ‡∞ö‡±á‡∞ö‡±ç‡∞≤‡∞æ‡∞ó‡∞æ{{Poetry_Type}}
{{Poem}}
(cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø:
{{Meaning}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞≠‡∞æ‡∞µ‡∞Ç‡∞µ‡∞ö‡±á‡∞ö‡±ç‡∞≤‡∞æ‡∞ó‡∞æ{{Poetry_Type}}
8 (cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø: ‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞≠‡∞æ‡∞µ‡∞Ç‡∞µ‡∞ö‡±á‡∞ö‡±ç{{Poetry_Type}}(cid:358)‡∞≤‡∞ø‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{Meaning}} {{Poem}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞≠‡∞æ‡∞µ‡∞Æ‡±Å‡∞µ‡∞ö‡±á‡∞ö‡±ç‡∞≤‡∞æ‡∞ó‡∞æ{{Poetry_Type}}
9 (cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø: ‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞≠‡∞æ‡∞µ‡∞Æ‡±Å‡∞µ‡∞ö‡±á‡∞ö‡±ç{{Poetry_Type}}(cid:358)‡∞≤‡∞ø‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{Meaning}} {{Poem}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Æ‡±Å‡∞µ‡∞ö‡±á‡∞ö‡±ç‡∞≤‡∞æ‡∞ó‡∞æ ‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Æ‡±Å‡∞µ‡∞ö‡±á‡∞ö‡±ç{{Poetry_Type}}(cid:358)‡∞≤‡∞ø
10
{{Poetry_Type}}(cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø:
‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{Meaning}}
{{Poem}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞Ö‡∞∞‡∞ß‡±ç‡∞Ç‡∞µ‡∞ö‡±á‡∞ö‡±ç‡∞≤‡∞æ‡∞ó‡∞æ{{Poetry_Type}}
11 (cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø:
‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞Ö‡∞∞‡∞ß‡±ç‡∞Ç‡∞µ‡∞ö‡±á‡∞ö‡±ç{{Poetry_Type}}‡∞≤‡∞ø‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{Meaning}} {{Poem}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞Ö‡∞∞‡∞ß‡±ç‡∞Æ‡±Å‡∞µ‡∞ö‡±á‡∞ö‡±ç‡∞≤‡∞æ‡∞ó‡∞æ{{Poetry_Type}}
12 (cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø:
‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞Ö‡∞∞‡∞ß‡±ç‡∞Æ‡±Å‡∞µ‡∞ö‡±á‡∞ö‡±ç{{Poetry_Type}}(cid:358)‡∞≤‡∞ø‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{Meaning}} {{Poem}}
Giventhepartialpoemandtypeofpoetry,
generatetherestofthepoem.
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Ç‡∞Ö‡∞®‡±Å‡∞∏‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®
‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞®‡±ç{{Poetry_Type}}(cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞∏‡∞ø‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø: ‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞°‡±ç‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø:
13 ‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Ç: ‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{Meaning}} {{Poem}}
‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{PartialPoem}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞≠‡∞æ‡∞µ‡∞Ç‡∞Ö‡∞®‡±Å‡∞∏‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞®‡±ç
{{Poetry_Type}}(cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞∏‡∞ø‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø:
‡∞≠‡∞æ‡∞µ‡∞Ç:
‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞°‡±ç‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø:
{{Meaning}}
14 ‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{Poem}}
‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{PartialPoem}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞≠‡∞æ‡∞µ‡∞Æ‡±Å‡∞Ö‡∞®‡±Å‡∞∏‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®
‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞®‡±ç{{Poetry_Type}}(cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞∏‡∞ø‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø:
‡∞≠‡∞æ‡∞µ‡∞Æ‡±Å:
‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞°‡±ç‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø:
{{Meaning}}
15 ‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{Poem}}
‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{PartialPoem}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Æ‡±Å‡∞Ö‡∞®‡±Å‡∞∏‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®
‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞®‡±ç{{Poetry_Type}}(cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞∏‡∞ø‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø:
‡∞§‡∞æ‡∞§‡∞™‡±ç‡∞∞‡∞Ø‡±ç‡∞Æ‡±Å:
‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞°‡±ç‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø:
{{Meaning}}
16 ‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{Poem}}
‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{PartialPoem}}
95‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞Ö‡∞∞‡∞ß‡±ç‡∞Ç‡∞Ö‡∞®‡±Å‡∞∏‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞®‡±ç
{{Poetry_Type}}(cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞∏‡∞ø‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø:
‡∞Ö‡∞∞‡∞ß‡±ç‡∞Ç:
‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞°‡±ç‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø:
17 {{Meaning}} ‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{Poem}}
‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{PartialPoem}}
‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞ö‡∞ø‡∞ö‡±ç‡∞®‡∞Ö‡∞∞‡∞ß‡±ç‡∞Æ‡±Å‡∞Ö‡∞®‡±Å‡∞∏‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®
‡∞™‡∞¶‡∞æ‡∞Ø‡±ç‡∞®‡∞ø‡∞®‡±ç{{Poetry_Type}}(cid:358)‡∞≤‡∞ø‡∞≤‡±ã‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞∏‡∞ø‡∞∞‡∞æ‡∞Ø‡∞Ç‡∞°‡∞ø:
‡∞Ö‡∞∞‡∞ß‡±ç‡∞Æ‡±Å:
‡∞™‡±Ç‡∞∞‡∞ø(cid:588)‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞°‡±ç‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞á‡∞µ‡∞µ‡±ç‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø:
18 {{Meaning}} ‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{Poem}}
‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞(cid:351)‡∞£‡±ç ‡∞Ø‡∞ø‡∞®‡∞™‡∞¶‡∞Ø‡±ç‡∞Ç:
{{PartialPoem}}
Givenapremise,providethehypothesis
basedonthelabelvalue. Thelabelcanbe
eitherentailmentorcontradiction.
FarsTail-Instruct EntailmentPromptsandTargets:
1 :(cid:1576)(cid:1699)(cid:3006)(cid:2987)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)Ôª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫ç
[hghader1,2023] {{hypothesis}}
:(cid:1576)(cid:1699)(cid:3006)(cid:2987)Ôª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)ÔØºÔ∫ç (cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)(cid:1772)(cid:3888)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫ç
{{premise}}
2 :(cid:1576)(cid:1699)(cid:3006)(cid:2987)Ôª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)ÔØºÔ∫ç (cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)(cid:1772)(cid:3888)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫ç :(cid:1576)(cid:1699)(cid:3006)(cid:2987)(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫çÔª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø (cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}} {{hypothesis}}
3 :(cid:1576)(cid:1699)(cid:3006)(cid:2987)Ôª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)ÔØºÔ∫ç (cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)(cid:1772)(cid:3888)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫ç :(cid:1576)(cid:1699)(cid:3006)(cid:2987)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)Ôª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:1772)(cid:1611)(cid:1772)(cid:3877)(cid:1960)(cid:1617)(cid:1543)(cid:1611)
{{premise}} {{hypothesis}}
4 :(cid:1678)(cid:1922)(cid:1543)(cid:1611)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857) (cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)(cid:2262)(cid:2238)Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :(cid:1576)(cid:1699)(cid:3006)(cid:2987)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)Ôª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫ç
{{premise}} {{hypothesis}}
5 :(cid:1678)(cid:1922)(cid:1543)(cid:1611)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857) (cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)(cid:2262)(cid:2238)Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :(cid:1576)(cid:1699)(cid:3006)(cid:2987)(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫çÔª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø (cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}} {{hypothesis}}
6 :(cid:1678)(cid:1922)(cid:1543)(cid:1611)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857) (cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)(cid:2262)(cid:2238)Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :(cid:1576)(cid:1699)(cid:3006)(cid:2987)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)Ôª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:1772)(cid:1611)(cid:1772)(cid:3877)(cid:1960)(cid:1617)(cid:1543)(cid:1611)
{{premise}} {{hypothesis}}
7 :(cid:1576)(cid:1699)(cid:3006)(cid:2987)(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫çÔª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :(cid:1576)(cid:1699)(cid:3006)(cid:2987)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)Ôª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫ç
{{premise}} {{hypothesis}}
8 :(cid:1576)(cid:1699)(cid:3006)(cid:2987)(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫çÔª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :(cid:1576)(cid:1699)(cid:3006)(cid:2987)(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫çÔª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø (cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}} {{hypothesis}}
9 :(cid:1576)(cid:1699)(cid:3006)(cid:2987)(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)Ô∫ØÔ∫çÔª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :(cid:1576)(cid:1699)(cid:3006)(cid:2987)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø(cid:1772)(cid:3894)(cid:1670)(cid:4005)(cid:3961)Ôª•Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:1772)(cid:1611)(cid:1772)(cid:3877)(cid:1960)(cid:1617)(cid:1543)(cid:1611)
{{premise}} {{hypothesis}}
ContradictionPromptsandTargets:
10 :(cid:1678)(cid:1655)(cid:1812) (cid:4623)(cid:4583)(cid:1893)(cid:1711)(cid:1614)Ô∫çÔ∫≠Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:2037)(cid:2022)Ô∫Ø(cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{hypothesis}}
:(cid:1678)(cid:1922)(cid:1543)(cid:1611)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)(cid:1893)(cid:1698)(cid:1543)(cid:1614)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}}
11 :(cid:1678)(cid:1922)(cid:1543)(cid:1611)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)(cid:1893)(cid:1698)(cid:1543)(cid:1614)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :Ô∫©Ô∫≠Ô∫çÔ∫©(cid:1893)(cid:1698)(cid:1543)(cid:2573)(cid:3262)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:1543)(cid:1611)(cid:2037)(cid:2022)Ô∫Ø(cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}} {{hypothesis}}
12 :(cid:1678)(cid:1922)(cid:1543)(cid:1611)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)(cid:1893)(cid:1698)(cid:1543)(cid:1614)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :(cid:1576)(cid:1919)Ô∫çÔª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:1893)(cid:1698)(cid:1543)(cid:1614)(cid:2037)(cid:2022)Ô∫Ø(cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}} {{hypothesis}}
13 :(cid:1678)(cid:1655)(cid:1812)(cid:1893)(cid:1711)(cid:1614)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :(cid:1678)(cid:1655)(cid:1812) (cid:4623)(cid:4583)(cid:1893)(cid:1711)(cid:1614)Ô∫çÔ∫≠Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:2037)(cid:2022)Ô∫Ø(cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}} {{hypothesis}}
14 :(cid:1678)(cid:1655)(cid:1812)(cid:1893)(cid:1711)(cid:1614)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :Ô∫©Ô∫≠Ô∫çÔ∫©(cid:1893)(cid:1698)(cid:1543)(cid:2573)(cid:3262)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:1543)(cid:1611)(cid:2037)(cid:2022)Ô∫Ø(cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}} {{hypothesis}}
15 :(cid:1678)(cid:1655)(cid:1812)(cid:1893)(cid:1711)(cid:1614)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)(cid:4362)(cid:4339)(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :(cid:1576)(cid:1919)Ô∫çÔª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:1893)(cid:1698)(cid:1543)(cid:1614)(cid:2037)(cid:2022)Ô∫Ø(cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}} {{hypothesis}}
9616 :(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)(cid:1543)(cid:1611)(cid:1893)(cid:1698)(cid:1543)(cid:1655)(cid:1658)(cid:1857)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :(cid:1678)(cid:1655)(cid:1812) (cid:4623)(cid:4583)(cid:1893)(cid:1711)(cid:1614)Ô∫çÔ∫≠Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:2037)(cid:2022)Ô∫Ø(cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}} {{hypothesis}}
17 :(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)(cid:1543)(cid:1611)(cid:1893)(cid:1698)(cid:1543)(cid:1655)(cid:1658)(cid:1857)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :Ô∫©Ô∫≠Ô∫çÔ∫©(cid:1893)(cid:1698)(cid:1543)(cid:2573)(cid:3262)Ôª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:1543)(cid:1611)(cid:2037)(cid:2022)Ô∫Ø(cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}} {{hypothesis}}
18 :(cid:4021)(cid:3658)(cid:1960)(cid:2573)(cid:3256)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)(cid:1543)(cid:1611)(cid:1893)(cid:1698)(cid:1543)(cid:1655)(cid:1658)(cid:1857)ÔØºÔ∫ç (cid:4393)(cid:4389)(cid:4487)(cid:4473) :(cid:1576)(cid:1919)Ô∫çÔª©(cid:1678)(cid:1922)Ôª©Ô∫©Ô∫çÔ∫©(cid:3476)(cid:3462)(cid:1857)(cid:1893)(cid:1698)(cid:1543)(cid:1614)(cid:2037)(cid:2022)Ô∫Ø(cid:4393)(cid:4389)(cid:4487)(cid:4473)
{{premise}} {{hypothesis}}
Givenanarticle,generatethesummaryof
thearticle.
‡§Ø‡§π‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§π‡•à:
1
Hindi-article- ‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç {{Summary}}
summarization {{Article}}
[ganeshjcs,2023a]
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§∏‡§Ç(cid:610)‡§ï‡•ç‡§∑‡§™‡•ç‡§§‡§™‡§æ‡§†:
2 {{Article}}
{{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
3 {{Article}} {{Summary}}
‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
4 {{Article}} {{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:
5 {{Article}}
{{Summary}}
‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
‡§Ø‡§π‡§æ‡§Å‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§π‡•à:
6 {{Article}}
{{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
‡§∏‡§Ç(cid:610)‡§ï‡•ç‡§∑‡§™‡•ç‡§§‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:
7 {{Article}}
{{Summary}}
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§Ø‡§π‡§π‡•ã‡§∏‡§ï‡§§‡§æ‡§π‡•à:
8 {{Article}}
{{Summary}}
‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:
9 {{Article}}
{{Summary}}
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§∏‡§Ç(cid:610)‡§ï‡•ç‡§∑‡§™‡•ç‡§§‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:
10 {{Article}}
{{Summary}}
‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§Ø‡§π‡§æ‡§Å‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§π‡•à:
11 {{Article}}
{{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:
12 {{Article}}
{{Summary}}
‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
‡§Ø‡§π‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§π‡•à:
13 {{Article}}
{{Summary}}
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§∏‡§Ç(cid:610)‡§ï‡•ç‡§∑‡§™‡•ç‡§§‡§™‡§æ‡§†:
14 {{Article}}
{{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
‡§Ø‡§π‡§æ‡§Å‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§π‡•à:
15 {{Article}}
{{Summary}}
‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:
16 {{Article}}
{{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
‡§∏‡§Ç(cid:610)‡§ï‡•ç‡§∑‡§™‡•ç‡§§‡§™‡§æ‡§†:
17 {{Article}}
{{Summary}}
97‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
‡§∏‡§Ç(cid:610)‡§ï‡•ç‡§∑‡§™‡•ç‡§§‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:
18 {{Article}}
{{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§Ø‡§π‡§π‡•ã‡§∏‡§ï‡§§‡§æ‡§π‡•à:
19 {{Article}}
{{Summary}}
‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
20 {{Article}} {{Summary}}
‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§∏‡§Ç(cid:610)‡§ï‡•ç‡§∑‡§™‡•ç‡§§‡§™‡§æ‡§†:
21 {{Article}}
{{Summary}}
‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§Ø‡§π‡§π‡•ã‡§∏‡§ï‡§§‡§æ‡§π‡•à:
22 {{Article}}
{{Summary}}
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§Ø‡§π‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§π‡•à:
23 {{Article}}
{{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
24 {{Article}} {{Summary}}
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
25 {{Article}} {{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
‡§Ø‡§π‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§π‡•à:
26 {{Article}}
{{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§Ø‡§π‡§π‡•ã‡§∏‡§ï‡§§‡§æ‡§π‡•à:
27 {{Article}}
{{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§Ø‡§π‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§π‡•à:
28 {{Article}}
{{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§∏‡§Ç(cid:610)‡§ï‡•ç‡§∑‡§™‡•ç‡§§‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:
29 {{Article}}
{{Summary}}
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:
30 {{Article}}
{{Summary}}
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§Ø‡§π‡§æ‡§Å‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§π‡•à:
31 {{Article}}
{{Summary}}
‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡§æ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§Ø‡§π‡§π‡•ã‡§∏‡§ï‡§§‡§æ‡§π‡•à:
32 {{Article}}
{{Summary}}
‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§ì:
‡§∏‡§Ç(cid:610)‡§ï‡•ç‡§∑‡§™‡•ç‡§§‡§™‡§æ‡§†
33 {{Article}}
{{Summary}}
(cid:606)‡§¶‡§è‡§ó‡§è‡§™‡§æ‡§†‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§Ø‡§π‡§æ‡§Å‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§π‡•à:
34 {{Article}}
{{Summary}}
‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡§¨‡§®‡§æ‡§è:‡§Ç
‡§∏‡§Ç(cid:610)‡§ï‡•ç‡§∑‡§™‡•ç‡§§‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:
35 {{Article}}
{{Summary}}
Giventhetitleofanarticle,generatethe
article.
‡§≤‡•á‡§ñ:
1
Hindi-article- ‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç(cid:611)‡§ú‡§∏‡§ï‡§æ‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§á‡§∏‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡§π‡•à: {{Article}}
generation[ganeshjcs, {{Title}}
2023b]
‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç(cid:611)‡§ú‡§∏‡§ï‡§æ‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§á‡§∏‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡§π‡•à:
2 {{Title}} {{Article}}
98‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç(cid:611)‡§ú‡§∏‡§ï‡§æ‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§á‡§∏‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡§π‡•à:
(cid:606)‡§¶‡§è‡§ó‡§è‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§ï‡•á ‡§Ö‡§®‡•Å‡§∞‡•Ç‡§™‡§è‡§ï‡§™‡§æ‡§†‡§Ø‡§π‡§π‡•ã‡§∏‡§ï‡§§‡§æ‡§π‡•à:
3 {{Title}}
{{Article}}
‡§Ø‡§π‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§π‡•à,‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
4 {{Title}} {{Article}}
‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
‡§≤‡•á‡§ñ:
5 {{Title}}
{{Article}}
‡§á‡§∏‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§ï‡•á ‡§∏‡§æ‡§•‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
‡§Ø‡§π‡§è‡§ï‡§≤‡•á‡§ñ‡§π‡•à:
6 {{Title}}
{{Article}}
‡§á‡§∏‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§ï‡•á ‡§∏‡§æ‡§•‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
(cid:606)‡§¶‡§è‡§ó‡§è‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§ï‡•á ‡§Ö‡§®‡•Å‡§∞‡•Ç‡§™‡§è‡§ï‡§™‡§æ‡§†‡§Ø‡§π‡§π‡•ã‡§∏‡§ï‡§§‡§æ‡§π‡•à:
7 {{Title}}
{{Article}}
‡§Ø‡§π‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§π‡•à,‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
‡§≤‡•á‡§ñ:
8 {{Title}}
{{Article}}
‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
9 {{Title}} {{Article}}
‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
‡§Ø‡§π‡§è‡§ï‡§≤‡•á‡§ñ‡§π‡•à:
10 {{Title}}
{{Article}}
‡§á‡§∏‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§ï‡•á ‡§∏‡§æ‡§•‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
‡§≤‡•á‡§ñ:
11 {{Title}}
{{Article}}
‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
(cid:606)‡§¶‡§è‡§ó‡§è‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§ï‡•á ‡§Ö‡§®‡•Å‡§∞‡•Ç‡§™‡§è‡§ï‡§™‡§æ‡§†‡§Ø‡§π‡§π‡•ã‡§∏‡§ï‡§§‡§æ‡§π‡•à:
12 {{Title}}
{{Article}}
‡§Ø‡§π‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§π‡•à,‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
(cid:606)‡§¶‡§è‡§ó‡§è‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§ï‡•á ‡§Ö‡§®‡•Å‡§∞‡•Ç‡§™‡§è‡§ï‡§™‡§æ‡§†‡§Ø‡§π‡§π‡•ã‡§∏‡§ï‡§§‡§æ‡§π‡•à:
13 {{Title}}
{{Article}}
‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç(cid:611)‡§ú‡§∏‡§ï‡§æ‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§á‡§∏‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡§π‡•à:
‡§Ø‡§π‡§è‡§ï‡§≤‡•á‡§ñ‡§π‡•à:
14 {{Title}}
{{Article}}
‡§á‡§∏‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§ï‡•á ‡§∏‡§æ‡§•‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
15 {{Title}} {{Article}}
‡§Ø‡§π‡§∂‡•Ä‡§∑‡§∞‡•ç‡§ï‡§π‡•à,‡§á‡§∏‡§ï‡•á (cid:609)‡§≤‡§è‡§è‡§ï‡§≤‡•á‡§ñ(cid:609)‡§≤‡§ñ‡•á‡§Ç:
‡§Ø‡§π‡§è‡§ï‡§≤‡•á‡§ñ‡§π‡•à:
16 {{Title}}
{{Article}}
Giventhemoviereview,identifythe
sentiment.
Gegevenderecensie,mijnantwoordis
1
IMDB-Dutch-instruct {{Sentiment}}
Isdezerecensiepositiefofnegatief?
[jjzha,2023]
Isdezerecensiepositiefofnegatief?
2 Dezerecensieis{{Sentiment}}
Isdezerecensiepositiefofnegatief?
3 Debeoordelinghieris{{Sentiment}}
Isdezerecensiepositiefofnegatief?
4 Hetantwoordis{{Sentiment}}
Watishetsentimentvanderecensie?
5 Derecensieis{{Sentiment}}
Watishetsentimentvanderecensie? Gegevenderecensie,mijnantwoordis
6
{{Sentiment}}
Watishetsentimentvanderecensie?
7 Dezerecensieis{{Sentiment}}
Watishetsentimentvanderecensie?
8 Debeoordelinghieris{{Sentiment}}
99Watishetsentimentvanderecensie?
9 Hetantwoordis{{Sentiment}}
Watvoortoonheeftdevolgenderecensie?
10 Derecensieis{{Sentiment}}
Watvoortoonheeftdevolgenderecensie? Gegevenderecensie,mijnantwoordis
11
{{Sentiment}}
Watvoortoonheeftdevolgenderecensie?
12 Dezerecensieis{{Sentiment}}
Watvoortoonheeftdevolgenderecensie?
13 Debeoordelinghieris{{Sentiment}}
Watvoortoonheeftdevolgenderecensie?
14 Hetantwoordis{{Sentiment}}
Metwatvoorsentimentzoujedezerecensie
15 beoordelen? Derecensieis{{Sentiment}}
Metwatvoorsentimentzoujedezerecensie
Gegevenderecensie,mijnantwoordis
16 beoordelen?
{{Sentiment}}
Metwatvoorsentimentzoujedezerecensie
17 beoordelen? Dezerecensieis{{Sentiment}}
Metwatvoorsentimentzoujedezerecensie
18 beoordelen? Debeoordelinghieris{{Sentiment}}
Metwatvoorsentimentzoujedezerecensie
19 beoordelen? Hetantwoordis{{Sentiment}}
Isdezerecensiepositiefofnegatief?
20 Derecensieis{{Sentiment}}
GeneratethetranslationforthegivenEnglish
reviewtooneofthetargetIndiclanguages
[ben,guj,hin,kan,mal,mar,pan,tam,tel
andurd].
1 {{Indic_Review}}
IndicSentiment-inst
TranslatefromEnglishto
[el2e10,2023a]
{{target_language}}:
{{English_Review}}
Translatethissentenceto
{{target_language}}:
2 {{Indic_Review}}
{{English_Review}}
What‚Äôsthe{{target_language}}translation
ofthissentence:
3 {{Indic_Review}}
{{English_Review}}
Canyoutranslatethistextto
{{target_language}}:
4 {{Indic_Review}}
{{English_Review}}
Generatetheparaphraseofthegiven
sentenceinoneoftheIndiclanguages[ben,
IndicXParaphrase-
guj,hin,mar,pan,mal,tel]
inst [el2e10, 2023b;
1 {{paraphrased_sentence}}
SuryaKrishna02,
‡¶ø‡¶≠(cid:9070)‡¶∂‡¶¨‡ßç‡¶¶‡¶ó‡ßÅ(cid:9003)‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ï‡ßá‡¶∞‡¶ø‡¶®‡ßá‡¶ö‡¶∞‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶ø‡¶ü‡ßá‡¶≤‡¶ñ:
2023d]
"{{original_sentence}}".
‡¶ø‡¶®‡ßá‡¶ö‡¶∞‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶ø‡¶ü‡¶ø‡¶≠(cid:9070)‡¶≠‡¶æ‡ßá‡¶¨‡ßá‡¶≤‡¶ñ:
2 "{{original_sentence}}" {{paraphrased_sentence}}
‡¶Ö‡ßá‡¶•‡¶∞‡ßç‡¶∞‡¶™‡¶ø‡¶∞‡¶¨‡¶§‡¶∞‡ßç‡¶®‡¶®‡¶æ‡¶ï‡ßá‡¶∞‡¶ø‡¶®‡ßá‡¶ö‡¶∞‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶ø‡¶ü‡¶®‡¶§‡¶®‡ßÅ ‡¶≠‡¶æ‡ßá‡¶¨‡ßá‡¶≤‡¶ñ:
3 "{{original_sentence}}" {{paraphrased_sentence}}
100‡™®‡´Ä‡™ö‡´á‡™®‡™æ‡™µ‡™æ(cid:242)‡™®‡´á ‡™Ö‡™≤‡™ó‡™∂‡™¨‡´ç‡™¶‡´ã‡™®‡´ã‡™â‡™™‡™Ø‡´ã‡™ó‡™ï‡™∞‡´Ä‡™®‡´á ‡™≤‡™ñ‡´ã:
4 ‚Äù{{original_sentence}}‚Äù. {{paraphrased_sentence}}
‡™®‡´Ä‡™ö‡´á‡™®‡™æ‡™µ‡™æ(cid:242)‡™®‡´á ‡™Ö‡™≤‡™ó‡™∞‡´Ä‡™§‡´á ‡™´‡™∞‡´Ä‡™•‡´Ä‡™≤‡™ñ‡´ã:
5 ‚Äù{{original_sentence}}‚Äù {{paraphrased_sentence}}
‡™®‡´Ä‡™ö‡´á‡™®‡™æ‡™µ‡™æ(cid:242)‡™®‡´á ‡™¨‡´Ä‡™ú‡™æ‡™∏‡´ç‡™µ‡™∞‡´Ç‡™™‡™Æ‡™æ‡™Ç ‡™´‡™∞‡´Ä‡™•‡´Ä‡™≤‡™ñ‡´ã:
6 ‚Äù{{original_sentence}}‚Äù {{paraphrased_sentence}}
‡§¶‡•Å‡§∏‡§∞‡•á‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç‡§ï‡§æ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§ï‡§∞‡§ï‡•á ‡§á‡§∏‡§µ‡§æ‡§ï‡•ç‡§Ø‡§ï‡•ã(cid:609)‡§≤(cid:612)‡§ñ‡§è:
7 ‚Äù{{original_sentence}}‚Äù. {{paraphrased_sentence}}
‡§á‡§∏‡§µ‡§æ‡§ï‡•ç‡§Ø‡§ï‡•ã‡§Ö‡§®‡•ç‡§Ø‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á(cid:607)‡§´‡§∞‡§∏‡•á(cid:609)‡§≤(cid:612)‡§ñ‡§è:
8 ‚Äù{{original_sentence}}‚Äù {{paraphrased_sentence}}
(cid:607)‡§®‡§Æ‡•ç‡§®(cid:609)‡§≤(cid:612)‡§ñ‡§§‡§µ‡§æ‡§ï‡•ç‡§Ø‡§ï‡§æ‡§Ö‡§•‡§∞‡•ç‡§¨‡§¶‡§≤‡•á(cid:607)‡§¨‡§®‡§æ‡§â‡§∏‡•á‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ(cid:609)‡§≤(cid:612)‡§ñ‡§è:
9 ‚Äù{{original_sentence}}‚Äù {{paraphrased_sentence}}
‡§ñ‡§æ‡§≤‡•Ä‡§≤‡§µ‡§æ‡§ï‡•ç‡§Ø‡§¶‡•Å‡§∏‡§∞‡•á-(cid:610)‡§≠(cid:545)‡§∂‡§¨‡•ç‡§¶‡§µ‡§æ‡§™‡§∞‡•Ç‡§®(cid:609)‡§≤‡§π‡§æ:
10 ‚Äù{{original_sentence}}‚Äù. {{paraphrased_sentence}}
‡§ñ‡§æ‡§≤‡•Ä‡§≤‡§µ‡§æ‡§ï‡•ç‡§Ø‡§µ‡•á‡§ó‡§≥‡•ç‡§Ø‡§æ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡•á‡§™‡•Å‡§®‡•ç‡§π‡§æ(cid:609)‡§≤‡§π‡§æ:
11 ‚Äù{{original_sentence}}‚Äù {{paraphrased_sentence}}
‡§ñ‡§æ‡§≤‡•Ä‡§≤‡§µ‡§æ‡§ï‡•ç‡§Ø‡§¶‡•Å‡§∏‡§∞‡•á‡§∂‡§¨‡•ç‡§¶‡§µ‡§æ‡§™‡§∞‡•Ç‡§®‡§∞‡•Ç‡§™‡§æ‡§Ç‡§§(cid:605)‡§∞‡§§-‡§Ö‡§®‡•Å‡§µ‡§æ(cid:606)‡§¶‡§§‡§ï‡§∞‡§æ:
12 ‚Äù{{original_sentence}}‚Äù {{paraphrased_sentence}}
‡®µ‡©±‡®ñ-‡®µ‡©±‡®ñ‡®∏‡®º‡®¨‡®¶‡®æ‡®Ç‡®¶‡©Ä‡®µ‡®∞‡®§‡©ã‡®Ç‡®ï‡®∞‡®ï‡©á‡®π‡©á‡®†‡®æ‡®Ç‡®ø‡®¶‡©±‡®§‡©á‡®µ‡®æ‡®ï‡®®‡©Ç‡©∞‡®ø‡®≤‡®ñ‡©ã:
13 ‚Äù{{original_sentence}}‚Äù. {{paraphrased_sentence}}
‡®ø‡®®‡®Æ‡®®‡®ø‡®≤‡®ñ‡®§‡®µ‡®æ‡®ï‡®®‡©Ç‡©∞‡®µ‡©±‡®ñ‡®∞‡©á‡®§‡®∞‡©Ä‡®ï‡©á‡®®‡®æ‡®≤‡®¶‡©Å‡®¨‡®æ‡®∞‡®æ‡®ø‡®≤‡®ñ‡©ã:
14 ‚Äù{{original_sentence}}‚Äù {{paraphrased_sentence}}
‡®π‡©á‡®†‡®æ‡®Ç‡®ø‡®¶‡©±‡®§‡©á‡®µ‡®æ‡®ï‡®®‡©Ç‡©∞‡®∏‡®Æ‡®ù‡®æ‡®ì:
15 ‚Äù{{original_sentence}}‚Äù {{paraphrased_sentence}
‡¥á‡¥®‡¥ø‡¥™‡µç‡¥™‡¥±‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥µ‡¥æ‡¥ö‡¥ï‡¥Ç‡¥µ‡µç‡¥Ø‡¥§‡µç‡¥Ø‡¥∏‡µç‡¥§
16 ‡¥µ‡¥æ‡¥ï‡µç‡¥ï‡µÅ‡¥ï‡¥≥‡¥ø‡µΩ‡¥é‡¥¥‡µÅ‡¥§‡µÅ‡¥ï: {{paraphrased_sentence}}
‚Äù{{original_sentence}}‚Äù.
‡¥á‡¥®‡¥ø‡¥™‡µç‡¥™‡¥±‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥µ‡¥æ‡¥ö‡¥ï‡¥Ç‡¥Æ‡µÜ‡¥±‡µç‡¥±‡¥æ‡¥∞‡µÅ‡¥∞‡µÄ‡¥§‡¥ø‡¥Ø‡¥ø‡µΩ
17 ‡¥é‡¥¥‡µÅ‡¥§‡µÅ‡¥ï: {{paraphrased_sentence}}
‚Äù{{original_sentence}}‚Äù
‡¥§‡¥æ‡µÜ‡¥¥‡¥™‡µç‡¥™‡¥±‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥µ‡¥æ‡¥ö‡¥ï‡¥Ç‡¥™‡¥∞‡¥æ‡¥µ‡µº‡¥§‡µç‡¥§‡¥®‡¥Ç
18 ‡µÜ‡¥ö‡¥Ø‡µç‡¥Ø(cid:242)‡¥ï: {{paraphrased_sentence}}
‚Äù{{original_sentence}}‚Äù
Givenasentence,generateasentencewith
similarmeaning.
19 {{ParaphrasedSentence}}
‡∞à‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞ø‡∞µ‡∞æ‡∞ï‡∞Ø‡±ç‡∞Ç‡∞Æ‡∞∞‡±ã‡∞∞‡±Ä‡∞§‡∞ø‡∞≤‡±ã‡∞∞‡∞æ‡∞Ø‡∞ø:
{{OriginalSentence}}
20 ‡∞à‡∞µ‡∞æ‡∞ï‡∞Ø‡±ç‡∞Ç‡∞Æ‡∞∞‡±ã‡∞∞‡±Ä‡∞§‡∞ø‡∞≤‡±ã‡∞∞‡∞æ‡∞Ø‡∞ø: {{OriginalSentence}} {{ParaphrasedSentence}}
‡∞à‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞ø‡∞µ‡∞æ‡∞ï‡∞Ø‡±ç‡∞Ç‡∞á‡∞Ç‡∞ï‡±ä‡∞≤‡∞æ‡∞ó‡∞æ‡∞∞‡∞æ‡∞Ø‡∞ø:
21 {{OriginalSentence}} {{ParaphrasedSentence}}
22 ‡∞à‡∞µ‡∞æ‡∞ï‡∞Ø‡±ç‡∞Ç‡∞á‡∞Ç‡∞ï‡±ä‡∞≤‡∞æ‡∞ó‡∞æ‡∞∞‡∞æ‡∞Ø‡∞ø: {{OriginalSentence}} {{ParaphrasedSentence}}
‡∞à‡∞ï‡∞ø(cid:552)‡∞Ç‡∞¶‡∞ø‡∞µ‡∞æ‡∞ï‡∞Ø‡±ç‡∞Ç‡∞Æ‡∞∞‡±ã‡∞∞‡∞ï‡∞Ç‡∞ó‡∞æ‡∞∞‡∞æ‡∞Ø‡∞ø:
23 {{OriginalSentence}} {{ParaphrasedSentence}}
10124 ‡∞à‡∞µ‡∞æ‡∞ï‡∞Ø‡±ç‡∞Ç‡∞Æ‡∞∞‡±ã‡∞∞‡∞ï‡∞Ç‡∞ó‡∞æ‡∞∞‡∞æ‡∞Ø‡∞ø: {{OriginalSentence}} {{ParaphrasedSentence}}
GiventheinstructioninIndonesian,translate
thegiveninputtooneofthethreelanguages
[ind,sun,jav].
TranslatefromEnglishtoIndonesian. Terjemahanataupadanantekstersebut
dalamBahasaIndonesiaadalah:
1
Indo-stories-instruct Terjemahkanlahpenggalanteksceritaanak
[Iftitahu,2023a;b;c] berikutdariteksberbahasaInggrisketeks {{ind_output}}
dalamBahasaIndonesia:
{{eng_input}}
TranslatefromJavanesetoIndonesian.
Terjemahkanlahpenggalanteksceritaanak Terjemahanataupadanantekstersebut
berikutdariteksberbahasaJawaketeks dalamBahasaIndonesiaadalah:
2
dalamBahasaIndonesia:
{{ind_output}}
{{jav_input}}
TranslatefromSudanesetoIndonesian.
Terjemahkanlahpenggalanteksceritaanak Terjemahanataupadanantekstersebut
berikutdariteksberbahasaSundaketeks dalamBahasaIndonesiaadalah:
3
dalamBahasaIndonesia:
{{ind_output}}
{{sun_input}}
GiventheinstructioninJavanese,translate
thegiveninputtooneofthethreelanguages
[ind,sun,jav]
TranslatefromEnglishtoJavanese. Terjemahaneutawapadanantekscrito
kasebutingBasaJawayaiku:
4
Terjemahnopenggalantekscritoingngisor
ikisakaBahasaInggrisdaditekscritoing {{jav_output}}
BasaJawa:
{{eng_input}}
TranslatefromIndonesiantoJavanese.
Terjemahnopenggalantekscritoingngisor Terjemahaneutawapadanantekscrito
ikisakaBahasaIndonesiadaditekscritoing kasebutingBasaJawayaiku:
5
BasaJawa:
{{jav_output}}
{{ind_input}}
TranslatefromEnglishtoSudanese.
Terjemahnopenggalantekscritoingngisor Terjemahaneutawapadanantekscrito
ikisakaBahasaSundadaditekscritoing kasebutingBasaJawayaiku:
6
BasaJawa:
{{jav_output}}
{{sun_input}}
102GiventheinstructioninSudanese,translate
thegiveninputtooneofthethreelanguages
[ind,sun,jav]
TranslatefromEnglishtoSudanese. Tarjamahanatawasasaruaannaskahdina
basaSunda:
7
Tarjamahkeunteksdongengbarudakdi
handaptinateksbasaInggriskanateksbasa {{sun_output}}
Sunda:
{{eng_input}}
TranslatefromIndonesiantoSudanese.
Tarjamahkeunteksdongengbarudakdi Tarjamahanatawasasaruaannaskahdina
handaptinateksbasaIndonesiakanateks basaSunda:
8
basaSunda:
{{sun_output}}
{{ind_input}}
TranslatefromJavanesetoSudanese.
Tarjamahkeunteksdongengbarudakdi Tarjamahanatawasasaruaannaskahdina
handaptinateksbasaJawakanateksbasa basaSunda:
9
Sunda:
{{sun_output}}
{{jav_input}}
Identifythejoke‚Äôspunchlineorexplainit.
{{joke}}
1 {{explanation}}
Joke-explaination-inst Whatdoyouthinkisthepunchlineofthe
[theblackcat102,2023] abovejoke?
Explainthefollowingjoke?
2 {{joke}} {{explanation}}
TranslatethegivensentencefromLigurianto
Italian.
Atradu√ßioninitaliandotestoal√©:
1 ‚Äô
Lijnews-instruct Traduxiinitalian: {{sentence}}
[ConseggioLigure, {{sentence}}
2023a;b]
Traduxida-ozeneise√†litalian:
2 {{sentence}} ‚Äô Atradu√ßioninitaliandotestoal ‚Äô√©:
{{sentence}}
Traduxida-oligure√†litalian:
3 {{sentence}} ‚Äô Atradu√ßioninitaliandotestoal ‚Äô√©:
{{sentence}}
Traduxistotestoinitalian:
Atradu√ßioninitaliandotestoal√©:
4 {{sentence}} ‚Äô
{{sentence}}
Traduxiinlenguaitalia√±a:
Atradu√ßioninitaliandotestoal√©:
5 {{sentence}} ‚Äô
{{sentence}}
Traduxistotestoda-ozeneise√†litalian:
6 {{sentence}} ‚Äô Atradu√ßioninitaliandotestoal ‚Äô√©:
{{sentence}}
Traduxistotestoda-oligure√†litalian:
7 {{sentence}} ‚Äô Atradu√ßioninitaliandotestoal ‚Äô√©:
{{sentence}}
Comm√†l√©atradu√ßionitalia√±adestotesto?
8 ‚Äô ‚Äô {{sentence}} Atradu√ßioninitaliandotestoal ‚Äô√©:
{{sentence}}
Qu√¶al√©atradu√ßionitalia√±adestotesto?
9 ‚Äô {{sentence}} Atradu√ßioninitaliandotestoal ‚Äô√©:
{{sentence}}
103Tipeutraduestotestoinitalian?
Atradu√ßioninitaliandotestoal√©:
10 {{sentence}} ‚Äô
{{sentence}}
TranslatethegivensentencefromItalianto
Ligurian.
Latraduzioneingenovesedeltesto√®:
11
Traduciingenovese: {{sentence}}
{{sentence}}
Traduciinligure:
Latraduzioneingenovesedeltesto√®:
12 {{sentence}}
{{sentence}}
Traducidallitalianoalgenovese:
13 {{sent‚Äô ence}} Latraduzioneingenovesedeltesto√®:
{{sentence}}
Traducidallitalianoalligure:
‚Äô Latraduzioneingenovesedeltesto√®:
14 {{sentence}}
{{sentence}}
Traducidallitalianoalligure(genovese):
15 {{s‚Äô entence}} Latraduzioneingenovesedeltesto√®:
{{sentence}}
Traduciquestotestoingenovese:
Latraduzioneingenovesedeltesto√®:
16 {{sentence}}
{{sentence}}
Traduciinlinguagenovese:
Latraduzioneingenovesedeltesto√®:
17 {{sentence}}
{{sentence}}
Qual√®latraduzionegenovesediquestotesto?
Latraduzioneingenovesedeltesto√®:
18 {{sentence}}
{{sentence}}
Puoitradurrequestotestoingenovese?
Latraduzioneingenovesedeltesto√®:
19 {{sentence}}
{{sentence}}
Followingtheinstruction,pleaseanswer.
1 {{translated_sentence}}
LLM-Japanese- {{answer}}
Vanilla-inst
[Tellarin.ai,2023a] Pleaseanswerthefollowingquestion.
2 {{answer}}
{{question}} „Åì„ÅÆË≥™Âïè„ÅÆÁ≠î„Åà„ÅØ
‰ª•‰∏ã„ÅÆË≥™Âïè„Å´Á≠î„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÅ
Answerthefollowingquestion.
3 {{answer}}
{{question}}
‰ª•‰∏ã„ÅÆË≥™Âïè„Å´Á≠î„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÅ
Giventhetext,generatetheheadlineforthe
textandviceversa.
Sure,here‚Äôsaheadlineforthegiventext-
1
MasakhaNEWS-inst Generateaheadlineforthefollowingtext: {{headline}}
[Adelanietal.,2023] {{text}}
Generateanarticleforthefollowingheadline:
2 {{headline}} {{article}}.
Giveanexampleofthetriviaintheprovided
category.
1 {{question}}{{answer}}
Mintaka-inst[Sen
etal.,2022] :(cid:1776)(cid:1642)(cid:1712)(cid:1843)Ô∫çÔª©(cid:1677)(cid:1777)(cid:4626)(cid:4589)(cid:1776)(cid:1857)(cid:1543)(cid:1571)(cid:1843)Ô∫çÔ∫ï(cid:1543)(cid:1857)(cid:2058)(cid:2042)(cid:1571)(cid:2510)(cid:2506)Ô∫ç(cid:2438)(cid:2427)(cid:3871)Ÿã(cid:2518)(cid:2513)(cid:1543)(cid:1660)(cid:1857)(cid:3617)(cid:3587)(cid:1946)(cid:1564)Ô∫É
{{category}}
104Giveanexampleofthetriviaintheprovided
category.
2 {{question}}{{answer}}
Givemeanexampleoftriviainthiscategory:
{{category}}
Answerthequestionfromthegivencategory.
Thefollowingqueryin{{lang}}istakenfrom
3 {{answer}}
the{{category}}category. Whatcouldbe
theanswertothequestion? {{question}}
Findthecategoryofthegivenquestion.
Thecategoryfromwhichthequestioncomes
4 Whatcategoryisthisquestionfrom:
is{{category}}
{{question}}.
Answerthegivenquestion.
Thecorrectanswertothequestionis
5 Whatisthecorrectanswertothisquestion:
{{answer}}
{{question}}
Identifythecategoryofthequestion.
6 cualeseltemaprincipaldeestapregunta: {{category}}
{{question}}
Givemeatriviabasedonthewords.
7 Writemeatriviaquestionthatcontainsthe Sure,apossiblequestionis‚Äù{{question}}‚Äù
words: {{comma_separated_words}}
Identifythedateortimementionsandtheir
typesinthegivensentencebasedonthe
exampleprovided.
(cid:4626)(cid:4589)Ô∫ìÔ∫≠(cid:1960)(cid:1803)(cid:1677)(cid:2510)(cid:2506)Ô∫ç(cid:1854)(cid:1779)(cid:1564)Ô∫ç(cid:1960)(cid:1614)Ô∫ÉÔª≠Ô∫ï(cid:1543)(cid:1698)Ôª≠(cid:2521)(cid:2513)Ô∫çÔª≠(cid:3842)(cid:3715)Ô∫≠Ô∫ç(cid:1960)(cid:1658)(cid:1843)Ô∫ç(cid:1557)(cid:1645)(cid:4487)(cid:4473)(cid:2262)(cid:2228)(cid:1678)(cid:3179)(cid:3164)(cid:3117)(cid:1854)(cid:1698)(cid:4901)(cid:4881)(cid:1903)(cid:1699)(cid:1862)(cid:1857)
:(cid:2444)(cid:2427)(cid:1604)(cid:1543)(cid:1860)(cid:1645)(cid:1699)(cid:4397)(cid:4389)(cid:3872)(cid:1678)(cid:2510)(cid:2506)Ô∫ç(cid:4397)(cid:4389)(cid:2549)(cid:2537)(cid:2528)Ô∫ç
"Results": [{
"Text": "{{text}}",
.(cid:4397)(cid:4389)(cid:1900)Ô∫çÔ∫´(cid:1543)(cid:1614)(cid:4260)(cid:4173)Ô∫çÔ∫´Ô∫á(cid:3047)(cid:2596)(cid:1743)(cid:1888)(cid:2510)(cid:2506)Ô∫ç(cid:1576)(cid:1698)(cid:1960)(cid:1843)Ô∫çÔª≠(cid:3842)(cid:3715)Ô∫≠(cid:1543)(cid:1658)(cid:1843)Ô∫çÔ∫≠(cid:1543)(cid:1652)(cid:1658)(cid:1564)(cid:2518)(cid:2513)Ô∫ç(cid:3476)(cid:3449)(cid:3871)(cid:4626)(cid:4589)(cid:1677)(cid:3872)
"Start": {{index_1}},
JSONÿå(cid:1873)(cid:1645)(cid:1930)(cid:4002)(cid:3964)(cid:3847)(cid:3712)(cid:1543)(cid:1658)(cid:1655)(cid:1843)Ô∫çÔ∫ùÔ∫ç(cid:3515)(cid:3485)Ô∫á(cid:1785)(cid:1645)(cid:1849)(cid:3871)(cid:1589)(cid:3552)(cid:3756) .Ôª°(cid:1678)(cid:1711)(cid:2510)(cid:2506)Ô∫çÔªù(cid:1543)(cid:1660)(cid:2510)(cid:2506)Ô∫ç(cid:4620)(cid:4607)Ô∫á(cid:1772)(cid:1652)(cid:4005)(cid:3961)Ô∫ç "End": {{index_2}},
.Ôª©(cid:1543)(cid:1614)Ô∫©Ô∫ÉÔ∫≠(cid:1960)(cid:1803)(cid:1677)(cid:2510)(cid:2506)Ô∫çÔªù(cid:1543)(cid:1660)(cid:3095)(cid:4923)(cid:4839)(cid:1776)(cid:4827)(cid:4766)(cid:1543)(cid:1933)(cid:1857)(cid:1776)(cid:1645)(cid:4207)(cid:4221)(cid:1645)(cid:1777)Ôªâ(cid:1543)(cid:2570)(cid:3262)Ô∫çÔª≠ "TypeName": "{{type_name}}",
"Resolution": {
:(cid:3847)(cid:3712)(cid:1543)(cid:1658)(cid:1655)(cid:1843)Ô∫çÔª≠(cid:3047)(cid:2596)(cid:1743)(cid:2613)(cid:2598)(cid:1576)(cid:1698)Ôª≠Ôª≠(cid:3842)(cid:3715)Ô∫≠(cid:1543)(cid:1617)Ôª≠(cid:4397)(cid:4389)(cid:4487)(cid:4473)(cid:2438)(cid:2427)(cid:3871)Ôªù(cid:1543)(cid:1660)(cid:1857)
"values": [{
1
NTX-LLM-inst
"timex": "{{time}}",
[Tellarin.ai,2023b] {{example_sentence}}
"type": "{{type}}",
"value": "{{value}}"
}]
:(cid:3047)(cid:2596)(cid:1743)(cid:1888)(cid:2510)(cid:2506)Ô∫ç(cid:1576)(cid:1698)(cid:1960)(cid:1843)Ô∫çÔª≠(cid:3842)(cid:3715)Ô∫≠(cid:1543)(cid:1658)(cid:1843)Ô∫ç
{{reference_date}} }
}]
{{reference_time}}
ÿü(cid:1776)(cid:3894)(cid:1645)(cid:4005)(cid:1655)(cid:1843)Ô∫ç(cid:4626)(cid:4611)(cid:1543)(cid:1857)ÿåÔª©(cid:1543)(cid:1614)Ô∫©Ô∫É(cid:4397)(cid:4389)(cid:3872)(cid:1678)(cid:2510)(cid:2506)Ô∫ç(cid:4397)(cid:4389)(cid:2549)(cid:2537)(cid:2528)Ô∫ç(cid:4620)(cid:4607)Ô∫á(cid:1888)(cid:1945)(cid:1655)(cid:1843)(cid:1543)(cid:1611)
{{input_sentence}}
105ËØ∑Âú®‰∏ãÈù¢Êèê‰æõÁöÑËæìÂÖ•Âè•Â≠ê‰∏≠ËØÜÂà´ÊâÄÊúâÊó•ÊúüÊàñÊó∂Èó¥
ÊèêÂèäÂèäÂÖ∂Á±ªÂûã„ÄÇ "Results": [{
"Text": "{{text}}",
Â¶ÇÊûúÁõ∏ÂÖ≥ÔºåËØ∑ËÄÉËôëÊèê‰æõÁöÑÂèÇËÄÉÊó•ÊúüÊó∂Èó¥„ÄÇ
"Start": {{index_1}},
JSON
ËØ∑Ê≥®ÊÑèÊèê‰æõÁöÑÁ§∫‰æã„ÄÇÊÇ®Â∫îËØ•‰ª• Ê†ºÂºèËæìÂá∫Áªì "End": {{index_2}},
ÊûúÔºåÈÅµÂæ™‰∏éÊâÄÊèê‰æõÁöÑÁ§∫‰æãÁªìÊûúÁ±ª‰ººÁöÑÁªìÊûÑ„ÄÇ
"TypeName": "{{type_name}}",
"Resolution": {
‰æãÂè•„ÄÅÂèÇËÄÉÊó•ÊúüÂíåÁªìÊûúÔºö
2 "values": [{
{{example_sentence}}
"timex": "{{time}}",
: {{reference_date}} "type": "{{type}}",
ÂèÇËÄÉÊó•Êúü
"value": "{{value}}"
{{reference_time}}
}]
}
ËÄÉËôëÂà∞‰∏ãÈù¢ÁöÑËæìÂÖ•Âè•Â≠êÔºåËæìÂá∫ÁªìÊûúÊòØ‰ªÄ‰πàÔºü
}]
{{input_sentence}}
Identificeeralledataentijdvermeldingenin
dezinhieronder.
Houdrekeningmet,indienrelevant,de
opgegevenreferentiedatum/tijd.
"Results": [{
Letgoedophetgegevenvoorbeeld. De "Text": "{{text}}",
resultatenmoeteninJSONformaatzijn, "Start": {{index_1}},
hetzelfdealsdestructuurvanhetgegeven "End": {{index_2}},
voorbeeld.
"TypeName": "{{type_name}}",
Voorbeeldzin,referentiedatum/tijd,en "Resolution": {
3 resultaten: "values": [{
"timex": "{{time}}",
{{example_sentence}}
"type": "{{type}}",
Referentie: {{reference_date}} "value": "{{value}}"
}]
{{reference_time}}
}
}]
Gegevendezinhieronder,watishet
resultaat?
{{input_sentence}}
Pleaseidentifyalldateortimementionsand
theirtypesintheinputsentenceprovided
below.
Takeintoconsiderationtheprovided "Results": [{
referencedatetime,ifrelevant. "Text": "{{text}}",
"Start": {{index_1}},
Payattentiontotheprovidedexample. You
shouldoutputtheresultsinJSONformat, "End": {{index_2}},
followingasimilarstructuretotheexample "TypeName": "{{type_name}}",
resultprovided. "Resolution": {
4 "values": [{
Examplesentence,referencedatetime,and
results: {{example_sentence}} "timex": "{{time}}",
"type": "{{type}}",
Referencedatetime: {{reference_date}}
"value": "{{value}}"
}]
{{reference_time}}
}
Consideringtheinputsentencebelow,whatis}]
theoutputresult?
{{input_sentence}}
106Identifiertouteslesr√©f√©rencesdedateou
d‚Äôheureetleurstypesdanslaphrasefournie
ci-dessous.
Tenezcomptedeladate/heureder√©f√©rence
fournie,lecas√©ch√©ant. "Results": [{
"Text": "{{text}}",
Faitesattention√†l‚Äôexemplefourni. Vous
"Start": {{index_1}},
devezaÔ¨Äicherlesr√©sultatsauformatJSON,
ensuivantunestructuresimilaire√†cellede "End": {{index_2}},
l‚Äôexempleder√©sultatfourni. "TypeName": "{{type_name}}",
"Resolution": {
Exempledephrase,date/heureder√©f√©rence
5 "values": [{
etr√©sultats:
"timex": "{{time}}",
{{example_sentence}} "type": "{{type}}",
"value": "{{value}}"
Date/heureder√©f√©rence: {{reference_date}}
}]
{{reference_time}} }
}]
Comptetenudelaphrasedentr√©eci-dessous,
‚Äô
quelestler√©sultatdesortie?
{{input_sentence}}
BitteidentifizierealleVorkommenvon
DatumoderUhrzeiten,mitihremjeweiligen
Typ,imInputsatzunten.
Beachte,wennn√∂tig,dieangegebene
Referenz-Datetime. "Results": [{
"Text": "{{text}}",
AchteaufdasvorgegebeneBeispiel. Gibdie
"Start": {{index_1}},
ErgebnisseimJSON-Formatausundfolge
einer√§hnlichenStrukturwiedas "End": {{index_2}},
Beispielergebnis. "TypeName": "{{type_name}}",
"Resolution": {
Beispielsatz,Referenz-Datetime,und
6 "values": [{
Ergebnisse:
"timex": "{{time}}",
{{example_sentence}} "type": "{{type}}",
"value": "{{value}}"
Referenz-Datetime: {{reference_date}}
}]
{{reference_time}} }
}]
BezogenaufdenInputsatzunten,wasistdas
richtigeErgebnis?
{{input_sentence}}
107‡§ï‡•É‡§™‡§Ø‡§æ(cid:607)‡§®‡§Æ‡•ç‡§®(cid:609)‡§≤(cid:612)‡§ñ‡§§‡§µ‡§æ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§Æ‡•á‡§Ç‡§∏‡§≠‡•Ä(cid:606)‡§¶‡§®‡§æ‡§Ç‡§ï‡§Ø‡§æ‡§∏‡§Æ‡§Ø‡§â‡§≤‡•ç‡§≤‡•á‡§ñ‡•ã‡§Ç
‡§î‡§∞‡§â‡§®‡§ï‡•á ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞‡•ã‡§Ç‡§ï(cid:655)‡§™‡§π‡§ö‡§æ‡§®‡§ï‡§∞‡•á‡§Ç‡•§
‡§Ø‡§¶(cid:653)‡§â(cid:609)‡§ö‡§§‡§π‡•ã,‡§§‡•ã(cid:606)‡§¶‡§Ø‡•á‡§ó‡§è‡§∏‡§Ç‡§¶(cid:634)‡§≠(cid:652)‡§ï(cid:606)‡§¶‡§®‡§æ‡§Ç‡§ï-‡§∏‡§Æ‡§Ø‡§ï‡•ã‡§ß‡•ç‡§Ø‡§æ‡§®‡§Æ‡•á‡§Ç
‡§∞‡§ñ‡•á‡§Ç‡•§
"Results": [{
"Text": "{{text}}",
(cid:606)‡§¶‡§Ø‡•á‡§ó‡§è‡§â‡§¶‡§æ‡§π‡§∞‡§£‡§™‡§∞‡§ß‡•ç‡§Ø‡§æ‡§®‡§¶‡•á‡§Ç‡•§‡§Ü‡§™‡§ï‡•ã(cid:606)‡§¶‡§Ø‡•á‡§ó‡§è‡§â‡§¶‡§æ‡§∞‡§π‡§£
‡§™(cid:605)‡§∞‡§£‡§æ‡§Æ‡§ï‡•á ‡§∏‡§Æ‡§æ‡§®‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ‡§ï‡§æ‡§™‡§æ‡§≤‡§®‡§ï‡§∞‡§§‡•á‡§π‡•Å‡§è,JSON "Start": {{index_1}},
‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™‡§Æ‡•á‡§Ç‡§™(cid:605)‡§∞‡§£‡§æ‡§Æ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü‡§ï‡§∞‡§®‡§æ‡§ö‡§æ(cid:607)‡§π‡§è‡•§ "End": {{index_2}},
"TypeName": "{{type_name}}",
‡§µ‡§æ‡§ï‡•ç‡§Ø,‡§∏‡§Ç‡§¶(cid:634)‡§≠(cid:652)‡§ï(cid:606)‡§¶‡§®‡§æ‡§Ç‡§ï-‡§∏‡§Æ‡§Ø‡§è‡§µ‡§Ç‡§™(cid:605)‡§∞‡§£‡§æ‡§Æ‡§ï‡§æ‡§â‡§¶‡§æ‡§∞‡§π‡§£:
"Resolution": {
7 {{example_sentence}} "values": [{
"timex": "{{time}}",
‡§∏‡§Ç‡§¶(cid:634)‡§≠(cid:652)‡§ï(cid:606)‡§¶‡§®‡§æ‡§Ç‡§ï-‡§∏‡§Æ‡§Ø:
"type": "{{type}}",
{{reference_date}} "value": "{{value}}"
}]
{{reference_time}} }
}]
(cid:607)‡§®‡§Æ‡•ç‡§®(cid:609)‡§≤(cid:612)‡§ñ‡§§‡§á‡§®‡§™‡•Å‡§ü‡§µ‡§æ‡§ï‡•ç‡§Ø‡§ï‡•ã‡§ß‡•ç‡§Ø‡§æ‡§®‡§Æ‡•á‡§Ç‡§∞‡§ñ‡§§‡•á‡§π‡•Å‡§è,‡§â‡§∏‡§ï‡•á
‡§Ü‡§â‡§ü‡§™‡•Å‡§ü‡§™(cid:605)‡§∞‡§£‡§æ‡§Æ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á‡§Æ‡•á‡§Ç(cid:609)‡§≤‡§ñ‡•á‡§Ç‡•§
{{input_sentence}}
Sipregadiidentificaretuttelemenzionidi
dataooraeirelativitipinellafrasediinput
fornitadiseguito.
Prendereinconsiderazioneladata/oradi
riferimentofornita,sepertinente. "Results": [{
"Text": "{{text}}",
Prestareattenzioneall‚Äôesempiofornito.
"Start": {{index_1}},
Dovrestirestituireirisultatiinformato
JSON,seguendounastrutturasimileal "End": {{index_2}},
risultatodiesempiofornito. "TypeName": "{{type_name}}",
"Resolution": {
Frasediesempio,data/oradiriferimentoe
8 "values": [{
risultati:
"timex": "{{time}}",
{{example_sentence}} "type": "{{type}}",
"value": "{{value}}"
Dataeoradiriferimento: {{reference_date}}
}]
{{reference_time}} }
}]
Considerandolafrasediinputseguente,qual
√®ilrisultatodioutput?
{{input_sentence}}
108‰ª•‰∏ã„Å´Á§∫„ÅôÂÖ•ÂäõÊñá„Åß„ÄÅ„Åô„Åπ„Å¶„ÅÆÊó•‰ªò„Åæ„Åü„ÅØÊôÇÂàª
„ÅÆË®ÄÂèä„Å®„Åù„ÅÆÁ®ÆÈ°û„ÇíË≠òÂà•„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
"Results": [{
Èñ¢ÈÄ£„Åô„ÇãÂ†¥Âêà„ÅØ„ÄÅÊèê‰æõ„Åï„Çå„ÇãÂèÇÁÖßÊó•ÊôÇ„ÇíËÄÉÊÖÆ„Åó
"Text": "{{text}}",
„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
"Start": {{index_1}},
Êèê‰æõ„Åï„Çå„Åü‰æã„Å´Ê≥®ÊÑè„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÊèê J‰æõ S„Åï ON„Çå„Åü "End": {{index_2}},
„Çµ„É≥„Éó„É´ÁµêÊûú„Å®ÂêåÊßò„ÅÆÊßãÈÄ†„Å´Âæì„Å£„Å¶„ÄÅ ÂΩ¢
"TypeName": "{{type_name}}",
Âºè„ÅßÁµêÊûú„ÇíÂá∫Âäõ„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ
"Resolution": {
9 Êñá„ÄÅÂèÇÁÖßÊó•ÊôÇ„ÄÅÁµêÊûú„ÅÆ‰æãÔºö "values": [{
{{example_sentence}} "timex": "{{time}}",
"type": "{{type}}",
{{reference_date}} "value": "{{value}}"
ÂèÇÁÖßÊó•ÊôÇÔºö
}]
{{reference_time}}
}
}]
Ê¨°„ÅÆÂÖ•ÂäõÊñá„ÇíËÄÉÊÖÆ„Åó„Å¶„ÄÅÂá∫ÂäõÁµêÊûú„ÅØ‰Ωï„Åß„Åô„Åã„ÄÇ
{{input_sentence}}
ÏïÑÎûòÏóêÏ†úÍ≥µÎêúÏûÖÎ†•Î¨∏Ïû•ÏóêÏÑúÎÇ†ÏßúÎÇòÏãúÍ∞ÑÏóêÍ¥ÄÌïúÏñ∏Í∏âÎ∞è
.
Í∑∏Îì§ÏùòÏú†ÌòïÏùÑÎ™®ÎëêÏãùÎ≥ÑÌïòÏã≠ÏãúÏò§
"Results": [{
/ .
Ìï¥ÎãπÎêòÎäîÍ≤ΩÏö∞Ï†úÍ≥µÎêúÏ∞∏Ï°∞ÎÇ†Ïßú ÏãúÍ∞ÑÏùÑÍ≥†Î†§ÌïòÏã≠ÏãúÏò§ "Text": "{{text}}",
. JSON "Start": {{index_1}},
Ï†úÍ≥µÎêúÏòàÏãúÏóêÏ£ºÎ™©Ìï¥Ï£ºÏã≠ÏãúÏò§ Í≤∞Í≥ºÎ•º ÌòïÏãù
, "End": {{index_2}},
ÏúºÎ°úÏ∂úÎ†•ÌïòÏó¨ ÏòàÏãúÍ≤∞Í≥ºÏôÄÏú†ÏÇ¨ÌïúÍµ¨Ï°∞Î•ºÍ∞ñÎèÑÎ°ùÌï¥Ïïº
.
Ìï©ÎãàÎã§ "TypeName": "{{type_name}}",
, : "Resolution": {
10 ÏòàÏãúÎ¨∏Ïû• Ï∞∏Ï°∞ÎÇ†ÏßúÎ∞èÍ≤∞Í≥º "values": [{
{{example_sentence}} "timex": "{{time}}",
"type": "{{type}}",
: {{reference_date}}
Ï∞∏Ï°∞ÎÇ†Ïßú "value": "{{value}}"
{{reference_time}} }]
}
?
ÏïÑÎûòÏùòÏûÖÎ†•Î¨∏Ïû•ÏùÑÍ≥†Î†§ÌïòÎ©¥Í≤∞Í≥ºÎäîÎ¨¥ÏóáÏûÖÎãàÍπå }]
{{input_sentence}}
109Porfavoridentifiquetodasasmen√ß√µesde
datasoutempoeseustiposnafrase
fornecidaabaixo.
Leveemconsidera√ß√£oadataehorade
refer√™nciafornecida,serelevante.
"Results": [{
Presteaten√ß√£oaoexemplofornecido. Voc√™ "Text": "{{text}}",
devegerarresultadosnoformatoJSON, "Start": {{index_1}},
seguindoumaestruturasemelhanteao "End": {{index_2}},
resultadodoexemplofornecido.
"TypeName": "{{type_name}}",
Frasedeexemplo,dataehoraderefer√™nciae "Resolution": {
11 resultados: "values": [{
"timex": "{{time}}",
{{example_sentence}}
"type": "{{type}}",
Dataehoraderefer√™ncia: "value": "{{value}}"
{{reference_date}} }]
}
{{reference_time}}
}]
Considerandoafraseabaixo,qual√©o
resultadoproduzido?
{{input_sentence}}
Porfavoridentificatodaslasmencionesde
fechasuhorasysuscategor√≠aseneltextode
entradaqueseencuentradebajo.
Tenencuentalafechayhoradereferencia
proporcionadas,encasodequesearelevante.
"Results": [{
Prestaatenci√≥nalejemplodado. Debes "Text": "{{text}}",
devolverlosresultadosenformatoJSON, "Start": {{index_1}},
siguiendounaestructurasimilaraladel "End": {{index_2}},
ejemploderesultado.
"TypeName": "{{type_name}}",
Textodeejemplo,fechayhora,ylos "Resolution": {
12 resultadoscorrespondientes: "values": [{
"timex": "{{time}}",
{{example_sentence}}
"type": "{{type}}",
Fechayhoradereferencia: "value": "{{value}}"
{{reference_date}} }]
}
{{reference_time}}
}]
Ahoraconsideraeltextodeentradaqueest√°
debajo,¬øcu√°lser√≠aelresultado?
{{input_sentence}}
110L√ºtfena≈üaƒüƒ±daverilenc√ºmledekit√ºmtarih
veyasaatifadelerinivebunlarƒ±nt√ºrlerini
belirtin.
Egerdatetimeobjesivarise,onunreferans
gosterdigitarihvesaatialin. saƒülanan
"Results": [{
referanstarihsaatinidikkatealƒ±n.
"Text": "{{text}}",
Saƒülanan√∂rneksonucabenzerbiryapƒ±yƒ± "Start": {{index_1}},
takipedereksonu√ßlarƒ±JSONformatƒ±nda "End": {{index_2}},
√ßƒ±karmalƒ±sƒ±nƒ±z.
"TypeName": "{{type_name}}",
√ñrnekc√ºmle,referansdatetimeobjesive "Resolution": {
13 sonu√ßlar: "values": [{
"timex": "{{time}}",
{{example_sentence}}
"type": "{{type}}",
Referansdatetimeobjesi: {{reference_date}} "value": "{{value}}"
}]
{{reference_time}}
}
}]
Yukarƒ±dakikurallarg√∂z√∂n√ºnde
bulundurulduƒüunda,a≈üaƒüƒ±dakigirdi
c√ºmlesinin√ßƒ±ktƒ±sonucunedir?
{{input_sentence}}
Shareyouropinionaboutaperson‚Äôsfeeling.
1 theyfeel{{label}}.
NusaX-senti-inst ifsomeonesays‚Äùtext‚Äù,howaretheyfeeling?
[Winataetal.,2023]
Givenatext,findthesentiment.
Hereisasentencein{{lang}}language.
2 {{label}}.
Identifythesentenceaspositive,negativeor
neutral. {{text}}
Givenatext,generateasummaryforit.
Persian-instruct-pn 1 :(cid:1678)(cid:1670)(cid:1655)(cid:1812)(cid:1772)(cid:1900)(cid:3080)(cid:3075)(cid:3872)Ô∫çÔ∫≠(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857) {{OriginalSummary}}
[Shafagh,2023a;b]
{{OriginalText}}
:(cid:1678)(cid:1670)(cid:2797)(cid:2793)(cid:1960)(cid:2573)(cid:3256)(cid:1772)(cid:1900)(cid:3080)(cid:3075)(cid:3872)(cid:1794)(cid:1630)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)ÔØºÔ∫ç(cid:2037)(cid:2003)
2 {{OriginalSummary}}
{{OriginalText}}
:(cid:1678)(cid:1670)(cid:2797)(cid:2793)(cid:1960)(cid:2573)(cid:3256)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)(cid:1772)(cid:1900)(cid:3080)(cid:3075)(cid:3872)Ôª•Ô∫ç(cid:1960)(cid:1655)(cid:1564)(cid:1772)(cid:1611)(cid:4393)(cid:4389)(cid:4487)(cid:4473)(cid:1678)(cid:1655)(cid:1754)(cid:1543)(cid:1630)(cid:1794)(cid:1630)
3 {{OriginalSummary}}
{{OriginalText}}
Givenatext,generateasummaryforit.
:(cid:1678)(cid:1922)(cid:1543)(cid:1611)(cid:1589)(cid:1919)(cid:1543)(cid:1655)(cid:1857)(cid:1888)(cid:1945)(cid:1614)Ô∫©Ô∫≠(cid:1960)(cid:1857)(cid:3476)(cid:3462)(cid:1857)ÔØºÔ∫ç(cid:2037)(cid:2003)(cid:2262)(cid:2238)Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)Ôª•Ô∫ç(cid:1960)(cid:1655)(cid:1564)(cid:2726)(cid:2724)Ô∫ç
4 :(cid:1678)(cid:1670)(cid:1777)Ô∫©Ô∫©(cid:1543)(cid:4827)(cid:4810)(cid:1933)(cid:4017)(cid:3956)(cid:1589)(cid:1919)(cid:1543)(cid:1655)(cid:1857)Ôª•Ô∫ç(cid:1960)(cid:1655)(cid:1564)(cid:1794)(cid:1630)(cid:2037)(cid:2022)Ô∫Ø(cid:3476)(cid:3462)(cid:1857)ÔØºÔ∫ç(cid:2037)(cid:2003)
{{OriginalTitle}}
{{OriginalText}}
:ÿü(cid:1678)(cid:1922)(cid:1543)(cid:1611)(cid:2262)(cid:2238)Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)(cid:1772)(cid:3888)(cid:2037)(cid:2022)Ô∫Ø(cid:4393)(cid:4383)(cid:1543)(cid:1711)(cid:1857)ÔØºÔ∫ç(cid:2037)(cid:2003)(cid:1589)(cid:1919)(cid:1543)(cid:1655)(cid:1857)(cid:2859)(cid:2832)(cid:2588)(cid:3262)(cid:1794)(cid:1630)(cid:1543)(cid:4505)(cid:4493)(cid:1888)(cid:1945)(cid:1614)Ô∫ØÔ∫ç
5 :(cid:1678)(cid:1922)(cid:1543)(cid:1611)(cid:1589)(cid:1919)(cid:1543)(cid:1655)(cid:1857)(cid:1888)(cid:1945)(cid:1614)Ô∫©Ô∫≠(cid:1960)(cid:1857)(cid:3476)(cid:3462)(cid:1857)ÔØºÔ∫ç(cid:2037)(cid:2003)(cid:2262)(cid:2238)Ô∫ç(cid:1960)(cid:1617) (cid:4623)(cid:4583)Ôª•Ô∫ç(cid:1960)(cid:1655)(cid:1564)(cid:2726)(cid:2724)Ô∫ç
{{OriginalText}} {{OriginalTitle}}
111GivenasentenceinThai,generatethe
Englishtranslation.
1 {{English_sentence}}.
SCB-MT-2020-prompt ‡πÅ‡∏õ‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏£‡∏≠‡∏∑ ‡∏¢‡∏≠‡πà ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏á‡∏± ‡∏Å‡∏§‡∏©:
[PyThaiNLP,2023a;b] {{Thai_sentence}}
GivenasentenceinEnglish,generatethe
Thaitranslation.
2 {{Thai_sentence}}.
‡πÅ‡∏õ‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏£‡∏≠‡∏∑ ‡∏¢‡∏≠‡πà ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏á‡∏± ‡∏Å‡∏§‡∏©‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢:
{{English_sentence}}
Givenanabstract,generatethetitle.
Iwanttosubmitanarticleto{{venue}}.
Theabstractisasfollows: Surething,oneofthepossibletitlechoicesis
1
Scirepeval-biomimicry- ‚Äù{{title}}‚Äù.
inst[Singhetal.,2022] {{abstract}}
Pleasegivemeagoodtitlesuggestion.
Givenanabstract,generatethetitle.
2 Pleasehelpmeinwritingatitleforthe {{title}}
followingabstract:
{{abstract}}
Givenatitle,generateanabstract.
3 {{abstract}}
Pleasewriteanabstractforthefollowing
title: {{title}}
GivenasentenceinEnglish,generatethe
Liguriantranslation.
TheLigurian(Genoese)translationis:
1
Seed-instruct- TranslatetoLigurian: {{sentence}}
lij {{sentence}}
[ConseggioLig-
ure,2023c;d] TranslatetoGenoese:
TheLigurian(Genoese)translationis:
2 {{sentence}}
{{sentence}}
TranslatetoLigurian(Genoese):
TheLigurian(Genoese)translationis:
3 {{sentence}}
{{sentence}}
TranslatefromEnglishtoLigurian:
TheLigurian(Genoese)translationis:
4 {{sentence}}
{{sentence}}
TranslatefromEnglishtoGenoese:
TheLigurian(Genoese)translationis:
5 {{sentence}}
{{sentence}}
TranslatefromEnglishtoLigurian(Genoese
dialect): TheLigurian(Genoese)translationis:
6
{{sentence}} {{sentence}}
TranslatethissentencetoLigurian:
TheLigurian(Genoese)translationis:
7 {{sentence}}
{{sentence}}
TranslatethissentencetoGenoese:
TheLigurian(Genoese)translationis:
8 {{sentence}}
{{sentence}}
WhatstheLiguriantranslationofthis
‚Äô sentence? TheLigurian(Genoese)translationis:
9
{{sentence}} {{sentence}}
WhatstheGenoesetranslationofthis
‚Äô sentence? TheLigurian(Genoese)translationis:
10
{{sentence}} {{sentence}}
112CanyoutranslatethistexttoLigurian?
TheLigurian(Genoese)translationis:
11 {{sentence}}
{{sentence}}
GivenasentenceinLigurian,generatethe
Englishtranslation.
Atradu√ßioniningleisedotestoal√©:
12 ‚Äô
Traduxiiningleise: {{sentence}}
{{sentence}}
Traduxida-ozeneise√†lingleise:
13 {{sentence}} ‚Äô Atradu√ßioniningleisedotestoal ‚Äô√©:
{{sentence}}
Traduxida-oligure√†lingleise:
‚Äô Atradu√ßioniningleisedotestoal√©:
14 {{sentence}} ‚Äô
{{sentence}}
Traduxistotestoiningleise:
Atradu√ßioniningleisedotestoal√©:
15 {{sentence}} ‚Äô
{{sentence}}
Traduxiinlenguaingleise:
Atradu√ßioniningleisedotestoal√©:
16 {{sentence}} ‚Äô
{{sentence}}
Traduxistotestoda-ozeneise√†lingleise:
17 {{sentence}} ‚Äô Atradu√ßioniningleisedotestoal ‚Äô√©:
{{sentence}}
Traduxistotestoda-oligure√†lingleise:
18 {{sentence}} ‚Äô Atradu√ßioniningleisedotestoal ‚Äô√©:
{{sentence}}
Comm√†l√©atradu√ßioningleisedestotesto?
19 ‚Äô ‚Äô {{sentence}} Atradu√ßioniningleisedotestoal ‚Äô√©:
{{sentence}}
Qu√¶al√©atradu√ßioningleisedestotesto?
20 ‚Äô {{sentence}} Atradu√ßioniningleisedotestoal ‚Äô√©:
{{sentence}}
Tipeutraduestotestoiningleise?
Atradu√ßioniningleisedotestoal√©:
21 {{sentence}} ‚Äô
{{sentence}}
Generateanarrativeforthegiven
conversation.
{{speakers}}: {{dialogue}}
1 {{narrative}}
SODA-inst[Kimetal.,
2022] Whatdoyouthinkthenarrativeofthe
conversationaboveis?
Givenanarrative,extenditintoadialogue
script.
Ihavethefollowingshortstorypremise:
Sure,hereisonepossibledialogue:
2 {{narrative}}
{{speakers}}: {{dialogue}}
Now,canyouextendthatintoashort
dialoguescript?
Generatethegistofthegivendialogue.
3 What‚Äôsthegistofthisdialogue? Thisisthegistofthedialogue-{{narrative}}
{{dialogue}}
Givenatopic,generateashortparagraphof
narrative.
Sure,hereisashortparagraph:
4 Writeashortparagraphofnarrativegiven
{{narrative}}
thefollowingtopic:
{{head}}
113Givenastory,generatetheappropriatetitle
forthestory.
‡ØÜ‡Æï‡Ææ‡Æü‡ØÅ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡ØÅ‡Æ≥‡Øç‡Æ≥‡Æï‡Øà‡Æ§‡Æï‡Øç‡Æï‡ØÅ‡Æ™‡Øç
‡Æï‡ØÄ‡Øá‡Æ¥‡ØÜ‡Æï‡Ææ‡Æü‡ØÅ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡ØÅ‡Æ≥‡Øç‡Æ≥‡Æï‡Øà‡Æ§‡Æï‡Øç‡Æï‡ØÅ‡Æ™‡Øç
1 ‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Æ§‡Øç‡Æ§‡ÆÆ‡Ææ‡Æ©‡Æ§‡Øà‡Æ≤‡Æ™‡Øç‡Æ™‡ØÅ‚Äô{{Title}}‚Äô
TamilStories[AITamil ‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Æ§‡Øç‡Æ§‡ÆÆ‡Ææ‡Æ©‡Æ§‡Øà‡Æ≤‡Æ™‡Øç‡Øà‡Æ™‡Æï‡Øç‡ØÜ‡Æï‡Ææ‡Æü‡ØÅ.
‡Æé‡Æ©‡Øç‡Æ™‡Æ§‡Ææ‡Æï‡ØÅ‡ÆÆ‡Øç.
Nadu,2023a] ‡Æï‡Øà‡Æ§:
{{Story}}
Givensomeprominentcharacters/wordsfrom
astoryalongwithatitle,generatethe
completestory.
‡Æï‡ØÄ‡Øá‡Æ¥‡ØÜ‡Æï‡Ææ‡Æü‡ØÅ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡ØÅ‡Æ≥‡Øç‡Æ≥
2 ‡Æµ‡Ææ‡Æ∞‡Øç‡Æ§‡Øç‡Øà‡Æ§‡Æï‡Øà‡Æ≥‡ÆØ‡ØÅ‡ÆÆ‡Øç‡Æ§‡Øà‡Æ≤‡Æ™‡Øç‡Øà‡Æ™‡ÆØ‡ØÅ‡ÆÆ‡Øç {{Story}}
‡Æ™‡ÆØ‡Æ©‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§(cid:166)‡Æö(cid:167)‡Æ±‡ØÅ‡Æï‡Øà‡Æ§‡Æé‡Æ¥‡ØÅ‡Æ§‡ØÅ‡Æï.
‡Æµ‡Ææ‡Æ∞‡Øç‡Æ§‡Øç‡Øà‡Æ§‡Æï‡Æ≥‡Øç:
{{Comma_Separated_Words}}
‡Æ§‡Øà‡Æ≤‡Æ™‡Øç‡Æ™‡ØÅ:{{Title}}
Giventheriddle,generatetheanswerforthat
riddle.
TeluguRiddles 1 ‡∞Æ‡±Ä‡∞∞‡±Å‡∞Ö‡∞°‡∞ø‡∞ó‡∞ø‡∞®‡∞∞‡∞ø‡∞°‡∞ø‡∞≤‡±ç‚Äç‡∞ï‡∞ø‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç: {{Answer}}
[desik98,2023] ‡∞à‡∞∞‡∞ø‡∞°‡∞ø‡∞≤‡±ç‚Äç‡∞ï‡∞ø‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç‡∞á‡∞µ‡±Å‡∞µ‡±ç: {{Riddle}}
2
‡∞à‡∞™‡±ä‡∞°‡±Å‡∞™‡±Å‡∞ï‡∞•‡∞ï‡∞ø‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç‡∞á‡∞µ‡±Å‡∞µ‡±ç{{Riddle}}
‡∞Æ‡±Ä‡∞∞‡±Å‡∞Ö‡∞°‡∞ø‡∞ó‡∞ø‡∞®‡∞™‡±ä‡∞°‡±Å‡∞™‡±Å‡∞ï‡∞•‡∞ï‡∞ø‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç: {{Answer}}
GivenanEnglishsentence,translateitto
Thai.
1 {{Thai_Sentence}}
Thai-USEmbassy- ‡πÅ‡∏õ‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏£‡∏≠‡∏∑ ‡∏¢‡∏≠‡πà ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏á‡∏± ‡∏Å‡∏§‡∏©‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢:
prompt[PyThaiNLP, {{English_Sentence}}
2023d;e]
GivenaThaisentence,translateittoEnglish.
2 ‡πÅ‡∏õ‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏´‡∏£‡∏≠‡∏∑ ‡∏¢‡∏≠‡πà ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏á‡∏± ‡∏Å‡∏§‡∏©: {{English_Sentence}}
{{Thai_Sentence}}
GiventhePOStags,generateasentence
basedonthestructure.
1 {{Thai_sentence}}
Thai-POS-inst
[PyThaiNLP,2023c] ‡∏à‡∏á‡∏™‡∏£‡∏≤‡πâ ‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡∏≤‡πâ ‡∏á{{POS}}
Givenaword,provideitsmeaningbasedon
thedifferentPOS. ‡∏Ñ‡πç‡∏≤‡∏ß‡∏≤‡πà {{word}}
1 ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ï‡∏≤‡∏°‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡πç‡∏≤‡πÑ‡∏î‡πâ‡∏î‡∏±‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ -POS
Thai-Wiktionary-inst ‡∏à‡∏á‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡πç‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ: ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ß‡∏≤‡πà themeaningofword(split
[PyThaiNLP,2023f] {{word}} with‚Äù/‚Äù)
114‡ØÜ‡Æï‡Ææ‡Æü‡ØÅ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡ØÅ‡Æ≥‡Øç‡Æ≥‡Æï‡ØÅ‡Æ±‡Æ≥‡Æø‡Æ©‡Øç‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Æ≥‡Øç:
{{Kural_Meaning}}‡Æé‡Æ©‡Øç‡Æ™‡Æ§‡Ææ‡Æï‡ØÅ‡ÆÆ‡Øç.‡Æá‡Æ®‡Øç‡Æ§
‡Æï‡ØÅ‡Æ±‡Æ≥‡Øç{{Adigaram_Name}}‡Æé‡Æ©‡Øç‡Æ©‡ØÅ‡ÆÆ‡Øç
‡ÆÖ‡Æ§(cid:166)‡Æï‡Ææ‡Æ∞‡Æ§‡Øç‡Æ§(cid:166)‡Æ≤‡Øç‡Æµ‡Æ∞‡ØÅ‡ÆÆ‡Øç
{{Kural_Number}}‡ÆÜ‡ÆÆ‡Øç‡Æï‡ØÅ‡Æ∞‡Æ≥‡Øç‡ÆÜ‡Æï‡ØÅ‡ÆÆ‡Øç.
‡Æ§(cid:166)‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡Æ±‡Æ≥‡Øç‡Æâ‡Æ≤‡Æï‡Æ™‡ØÅ‡Æï‡Æ¥‡Øç‡ØÜ‡Æ™‡Æ±‡Øç‡Æ±‡ØÜ‡Æ™‡Ææ‡Æ§‡ØÅ
‡ÆÆ‡Øà‡Æ±‡Æ®‡ØÇ‡Æ≤‡Øç.‡Æá‡Æ®‡Øç‡Æ®‡ØÇ‡Øà‡Æ≤‡Æá‡ÆØ‡Æ±‡Øç‡Æ±(cid:167)‡ÆØ‡Æµ‡Æ∞‡Øç
‡Æ§(cid:166)‡Æ∞‡ØÅ‡Æµ‡Æ≥‡Øç‡Æ≥‡ØÅ‡Æµ‡Æ∞‡Øç.‡Æ§(cid:166)‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡Æ±‡Æ≥‡Æø‡Æ≤‡Øç133
‡ÆÖ‡Æ§(cid:166)‡Æï‡Ææ‡Æ∞‡ÆÆ‡ØÅ‡ÆÆ‡Øç,‡ÆÖ‡Æ§(cid:166)‡Æï‡Ææ‡Æ∞‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Øç‡Æï‡ØÅ10‡Æï‡ØÅ‡Æ±‡Æ≥‡ØÅ‡ÆÆ‡Øç
‡ØÜ‡ÆÆ‡Ææ‡Æ§‡Øç‡Æ§‡ÆÆ‡Øç1330‡Æï‡ØÅ‡Æ±‡Æ≥‡ØÅ‡ÆÆ‡Øç
‡ÆÖ‡Æü‡Æô‡Øç‡Æï(cid:166)‡ÆØ‡ØÅ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ.‡Æí‡Æµ‡Øç‡ØÜ‡Æµ‡Ææ‡Æ∞‡ØÅ‡Æï‡ØÅ‡Æ±‡Æ≥‡ØÅ‡ÆÆ‡Øç
‡Æá‡Æ∞‡Æ£‡Øç‡Æü‡ØÅ‡ÆÖ‡Æü‡Æø‡Æï‡Øà‡Æ≥‡ÆØ‡ØÅ‡ÆÆ‡Øç‡Æè‡Æ¥‡ØÅ‡Æö‡ØÄ‡Æ∞‡ØÅ‡ÆÆ‡Øç
‡ØÜ‡Æï‡Ææ‡Æ£‡Øç‡Æü‡ØÜ‡Æµ‡Æ£‡Øç‡Æ™‡Ææ‡Æµ‡Ææ‡Æï‡ØÅ‡ÆÆ‡Øç.‡Æá‡Æ®‡Øç‡Æ®‡ØÇ‡Æ≤‡Æø‡Æ≤‡Øç
Giventhekuralandaskforitsmeaning, ‡ØÜ‡Æ™‡Æ∞‡ØÅ‡ÆÆ‡Øç‡Æ™(cid:165)‡Æ∞‡Æø‡Æµ‡ØÅ‡Æ™‡Ææ‡Æ≤‡Øç‡Æé‡Æ©‡Æµ‡ØÅ‡ÆÆ‡Øç,‡Æö(cid:167)‡Æ±‡ØÅ‡Æ™(cid:165)‡Æ∞‡Æø‡Æµ‡ØÅ
generatesthemeaningofthekural. ‡Æá‡ÆØ‡Æ≤‡Øç‡Æé‡Æ©‡Æµ‡ØÅ‡ÆÆ‡Øç,‡ÆÖ‡Æ§‡Æ©‡Æø‡Æ©‡ØÅ‡ÆÆ‡Øç‡Æö(cid:167)‡Æ±(cid:167)‡ÆØ‡Æ§‡ØÅ
‡ÆÖ‡Æ§(cid:166)‡Æï‡Ææ‡Æ∞‡ÆÆ‡Øç‡Æé‡Æ©‡Øç‡Æ±‡ØÅ‡Æµ‡Æï‡ØÅ‡Æï‡Øç‡Æï‡ØÜ‡Æ™‡Æ±‡Øç‡Æ±‡ØÅ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ.
1 {{Adigaram_Name}}‡Æé‡Æ©‡Øç‡Æ©‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æ±‡Æ§‡Øç‡Æ§‡ØÅ‡Æ™‡Øç‡Æ™‡Ææ‡Æ≤‡Æø‡Æ≤‡Øç38‡ÆÖ‡Æ§(cid:166)‡Æï‡Ææ‡Æ∞‡Æô‡Øç‡Æï‡Øà‡Æ≥‡ÆØ‡ØÅ‡ÆÆ‡Øç,
Thirukkural-instruct
‡ÆÖ‡Æ§(cid:166)‡Æï‡Ææ‡Æ∞‡Æ§‡Øç‡Æ§(cid:166)‡Æ≤‡Øç‡Æµ‡Æ∞‡ØÅ‡ÆÆ‡Øç,{{Complete_Kural}} ‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Æü‡Øç‡Æ™‡Ææ‡Æ≤‡Æø‡Æ≤‡Øç70‡ÆÖ‡Æ§(cid:166)‡Æï‡Ææ‡Æ∞‡Æô‡Øç‡Æï‡Øà‡Æ≥‡ÆØ‡ØÅ‡ÆÆ‡Øç
[AITamilNadu,
‡Æé‡Æ©‡Øç‡Æ±‡Æï‡ØÅ‡Æ±‡Æ≥‡Æø‡Æ©‡Øç‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Øà‡Æ≥‡Æµ(cid:165)‡Æ≥‡Æï‡Øç‡Æï‡ØÅ‡Æï. ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç‡Æï‡Ææ‡ÆÆ‡Æ§‡Øç‡Æ§‡ØÅ‡Æ™‡Øç‡Æ™‡Ææ‡Æ≤‡Æø‡Æ≤‡Øç25
2023b]
‡ÆÖ‡Æ§(cid:166)‡Æï‡Ææ‡Æ∞‡Æô‡Øç‡Æï‡Øà‡Æ≥‡ÆØ‡ØÅ‡ÆÆ‡Øç‡ØÜ‡Æï‡Ææ‡Æ£‡Øç‡Æü‡ØÅ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ.
‡Æá‡Æ®‡Øç‡Æ®‡ØÇ‡Æ≤‡Øç‡ÆÖ‡Æ±‡ÆÆ‡Øç,‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Æ≥‡Øç,‡Æá‡Æ©‡Øç‡Æ™‡ÆÆ‡Øç(‡Æï‡Ææ‡ÆÆ‡ÆÆ‡Øç)
‡Æé‡Æ©‡Øç‡Æ©‡ØÅ‡ÆÆ‡Øç‡ÆÆ‡ØÅ‡Æ™‡Øç‡Æ™‡Ææ‡Øà‡Æ≤‡ÆØ‡ØÅ‡ÆÆ‡Øç‡ÆÖ‡Æ¥‡Æï‡Ææ‡Æï
‡Æé‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Øà‡Æ∞‡Æï‡Øç‡Æï(cid:166)‡Æ±‡Æ§‡ØÅ.‡Æµ‡Ææ‡Æ¥‡Øç‡Øà‡Æï‡ÆØ(cid:165)‡Æ©‡Øç
‡ÆÖ‡Øà‡Æ©‡Æ§‡Øç‡Æ§‡ØÅ‡Æ™‡Æï‡ØÅ‡Æ§(cid:166)‡Æï‡Øà‡Æ≥‡ÆØ‡ØÅ‡ÆÆ‡Øç
‡Æé‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Øà‡Æ∞‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç‡Æí‡Æ∞‡ØÅ‡Æö(cid:167)‡Æ±‡Æ®‡Øç‡Æ§‡Æµ‡Ææ‡Æ¥‡Øç‡Æµ(cid:165)‡ÆØ‡Æ≤‡Øç
‡Æ®‡ØÇ‡Æ≤‡Ææ‡Æï‡ØÅ‡ÆÆ‡Øç.‡Æö‡Ææ‡Æ§(cid:166),‡ÆÆ‡Æ§‡ÆÆ‡Øç,‡ØÜ‡ÆÆ‡Ææ‡Æ¥‡Æø,‡Æ®‡Ææ‡Æü‡ØÅ‡Æé‡Æ©‡Øç‡Æ±‡ØÅ
‡Øá‡Æµ‡Æ±‡ØÅ‡Æ™‡Ææ‡Æü‡ØÅ‡Æá‡Æ≤‡Øç‡Æ≤‡Ææ‡ÆÆ‡Æ≤‡Øç‡ÆÆ‡Æï‡Øç‡Æï‡Æ≥‡Øç
‡ÆÖ‡Øà‡Æ©‡Æµ‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡ØÅ‡Æµ‡Æ§‡Ææ‡Æï
‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡Ææ‡Æ≤‡Øç‡Æâ‡Æ≤‡Æï‡ØÜ‡Æ™‡Ææ‡Æ§‡ØÅ‡ÆÆ‡Øà‡Æ±‡Æé‡Æ©‡Øç‡Æ±‡ØÅ
‡ÆÖ‡Øà‡Æ¥‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æï(cid:166)‡Æ±‡Æ§‡ØÅ.‡ØÜ‡Æ§‡ÆØ‡Øç‡Æµ‡Æ®‡ØÇ‡Æ≤‡Øç,
‡ØÜ‡Æ™‡Ææ‡ÆØ‡Øç‡ÆØ‡Ææ‡ØÜ‡ÆÆ‡Ææ‡Æ¥‡Æø,‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç‡ÆÆ‡Øà‡Æ±,‡ÆÆ‡ØÅ‡Æ™‡Øç‡Æ™‡Ææ‡Æ≤‡Øç
‡Æé‡Æ©‡Øç‡Æ±‡ØÅ‡Øá‡Æµ‡Æ±‡ØÅ‡ØÜ‡Æ™‡ÆØ‡Æ∞‡Øç‡Æï‡Æ≥‡ØÅ‡ÆÆ‡Øç
‡Æ§(cid:166)‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡Æ±‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡Æâ‡Æ£‡Øç‡Æü‡ØÅ.
Giventhemeaningofthekural,generatesthe ‚Äù{{Complete_Kural}}‚Äù‡Æé‡Æ©‡Øç‡Æ©‡ØÅ‡ÆÆ‡Øç‡Æï‡ØÅ‡Æ±‡Øá‡Æ≥
originalkural. ‡ØÜ‡Æï‡Ææ‡Æü‡ØÅ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡ØÅ‡Æ≥‡Øç‡Æ≥‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡Æ™‡Øç
‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Æ§‡Øç‡Æ§‡ÆÆ‡Ææ‡Æ©‡Æï‡ØÅ‡Æ±‡Æ≥‡Ææ‡Æï‡ØÅ‡ÆÆ‡Øç.
{{Kural_Meaning}}‡Æé‡Æ©‡Øç‡Æ©‡ØÅ‡ÆÆ‡Øç‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡ØÜ‡Æï‡Ææ‡Æü‡ØÅ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡ØÅ‡Æ≥‡Øç‡Æ≥‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Æ≥‡Øç‡ÆÆ‡ØÅ.
2
‡Æè‡Æ±‡Øç‡Æ±{{Adigram_Name}}‡Æé‡Æ©‡Øç‡Æ©‡ØÅ‡ÆÆ‡Øç ‡Æµ‡Æ∞‡Æ§‡Æ∞‡Ææ‡Æö‡Æ©‡Ææ‡Æ∞‡Øç‡ÆÖ‡Æµ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç‡Æé‡Æ¥‡ØÅ‡Æ§(cid:166)‡ÆØ
‡ÆÖ‡Æ§(cid:166)‡Æï‡Ææ‡Æ∞‡Æ§‡Øç‡Æ§(cid:166)‡Æ≤‡Øç‡Æµ‡Æ∞‡ØÅ‡ÆÆ‡Øç ‡Æâ‡Øà‡Æ∞‡ÆØ(cid:165)‡Æ≤‡Æø‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡ØÅ‡Æé‡Æü‡ØÅ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡Æ§‡ØÅ.
{{Kural_Number}}‡ÆÜ‡ÆÆ‡Øç‡Æï‡ØÅ‡Æ±‡Øà‡Æ≥‡Æ§‡Øç‡Æ§‡Æ∞‡ØÅ‡Æï. ‡Æ§(cid:166)‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡Æ±‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡Øá‡Æµ‡Æ±‡ØÅ‡Æö(cid:167)‡Æ≤‡ÆÖ‡Æ±(cid:167)‡Æû‡Æ∞‡Øç‡Æï‡Æ≥‡ØÅ‡ÆÆ‡Øç
‡Æâ‡Øà‡Æ∞‡Æé‡Æ¥‡ØÅ‡Æ§(cid:166)‡ÆØ‡ØÅ‡Æ≥‡Øç‡Æ≥‡Æ©‡Æ∞‡Øç.
Giventhebeginningofakuralandaskforits
meaning,generatestheoriginalkuralalong ‚Äù{{Complete_Kural}}‚Äù‡Æé‡Æ©‡Øç‡Æ©‡ØÅ‡ÆÆ‡Øç‡Æï‡ØÅ‡Æ±‡Øá‡Æ≥
withitsmeaning. ‡ØÜ‡Æï‡Ææ‡Æü‡ØÅ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡ØÅ‡Æ≥‡Øç‡Æ≥
3 ‡Æµ‡Ææ‡Æ∞‡Øç‡Æ§‡Øç‡Øà‡Æ§‡Æï‡Æ≥‡Æø‡Æ≤‡Æø‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡ØÅ‡ØÜ‡Æ§‡Ææ‡Æü‡Æô‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç
‚Äù{{Kural_Starting}}‚Äù‡Æé‡Æ©‡Æ§‡Øç‡ØÜ‡Æ§‡Ææ‡Æü‡Æô‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç ‡Æï‡ØÅ‡Æ±‡Æ≥‡Ææ‡Æï‡ØÅ‡ÆÆ‡Øç.‡Æá‡Æ§‡Æ©‡Øç‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Æ≥‡Øç:
‡Æï‡ØÅ‡Æ±‡Øà‡Æ≥‡ÆØ‡ØÅ‡ÆÆ‡Øç‡ÆÖ‡Æ§‡Æ©‡Øç‡ØÜ‡Æ™‡Ææ‡Æ∞‡ØÅ‡Øà‡Æ≥‡ÆØ‡ØÅ‡ÆÆ‡Øç‡Æ§‡Æ∞‡ØÅ‡Æï. {{Kural_Meaning}}
Paraphrasethegiventext.
1 Canyouparaphrasethefollowingtextforme: {{paraphrased_text}}
Turku-paraphrase-inst
{{text}}
[TurkuNLP,2023]
Rewritethegiventext(sentence/long
documents)withoutgrammaticalerrors.
–ü–µ—Ä–µ–ø–∏—à–∏–Ω–∞—Å—Ç—É–ø–Ω–∏–π—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫: target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
1
UA-Gec-inst target_pos: {{corrected_text}}
[osyvokon,2023] #–¢–µ–∫—Å—Ç
{{text}}
–ü–µ—Ä–µ–ø–∏—à–∏—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
2
{{text}} target_pos: {{corrected_text}}
115target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
–í–∏–ø—Ä–∞–≤–ø–æ–º–∏–ª–∫–∏—É—Ç–µ–∫—Å—Ç—ñ.
target_pos: –ó–≤–∏—á–∞–π–Ω–æ.–û—Å—å—Ç–µ–∫—Å—Ç–∑
3
{{text}} –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–∏–º–∏–ø–æ–º–∏–ª–∫–∞–º–∏:
{{corrected_text}}
–ü–µ—Ä–µ–≤—ñ—Ä,–±—É–¥—å–ª–∞—Å–∫–∞,–ø—Ä–∞–≤–∏–ª—å–Ω—ñ—Å—Ç—å–≥—Ä–∞–º–∞—Ç–∏–∫–∏—É
–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É—Ç–µ–∫—Å—Ç—ñ.
target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
4
target_pos: {{corrected_text}}
{{text}}
–í–∏–ø—Ä–∞–≤–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–ø–æ–º–∏–ª–∫–∏–≤–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É—Ç–µ–∫—Å—Ç—ñ:
target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
5 {{text}}
target_pos: {{corrected_text}}
target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
–í–∏–ø—Ä–∞–≤–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–ø–æ–º–∏–ª–∫–∏–≤–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É—Ç–µ–∫—Å—Ç—ñ:
target_pos: –ó–≤–∏—á–∞–π–Ω–æ.–û—Å—å—Ç–µ–∫—Å—Ç–∑
6 {{text}}
–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–∏–º–∏–ø–æ–º–∏–ª–∫–∞–º–∏:
{{corrected_text}}
target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
–ü–µ—Ä–µ–ø–∏—à–∏—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
target_pos: –ó–≤–∏—á–∞–π–Ω–æ.–û—Å—å—Ç–µ–∫—Å—Ç–∑
7
{{text}} –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–∏–º–∏–ø–æ–º–∏–ª–∫–∞–º–∏:
{{corrected_text}}
target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
–ü–µ—Ä–µ–≥–ª—è–Ω—å,–±—É–¥—å–ª–∞—Å–∫–∞,–Ω–∞—Å—Ç—É–ø–Ω–∏–π—Ç–µ–∫—Å—Ç.–í–∏–ø—Ä–∞–≤–∏
—É—Å—ñ–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–Ω–µ—Ç–æ—á–Ω–æ—Å—Ç—ñ.
target_pos: –ó–≤–∏—á–∞–π–Ω–æ.–û—Å—å—Ç–µ–∫—Å—Ç–∑
8
–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–∏–º–∏–ø–æ–º–∏–ª–∫–∞–º–∏:
{{text}}
{{corrected_text}}
–í–∏–ø—Ä–∞–≤–ø–æ–º–∏–ª–∫–∏—É—Ç–µ–∫—Å—Ç—ñ. target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
#–¢–µ–∫—Å—Ç target_pos: –ó–≤–∏—á–∞–π–Ω–æ.–û—Å—å—Ç–µ–∫—Å—Ç–∑
9
–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–∏–º–∏–ø–æ–º–∏–ª–∫–∞–º–∏:
{{text}}
{{corrected_text}}
–ü–µ—Ä–µ–≤—ñ—Ä,–±—É–¥—å–ª–∞—Å–∫–∞,–ø—Ä–∞–≤–∏–ª—å–Ω—ñ—Å—Ç—å–≥—Ä–∞–º–∞—Ç–∏–∫–∏—É
–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É—Ç–µ–∫—Å—Ç—ñ.
target_neg: {{text}}
10
target_pos: {{corrected_text}}
{{text}}
–ü–µ—Ä–µ–ø–∏—à–∏—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
target_neg: {{text}}
11
{{text}} target_pos: {{corrected_text}}
–ü–µ—Ä–µ–ø–∏—à–∏–Ω–∞—Å—Ç—É–ø–Ω–∏–π—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫:
target_neg: {{text}}
12 #–¢–µ–∫—Å—Ç
target_pos: {{corrected_text}}
{{text}}
–í–∏–ø—Ä–∞–≤–ø–æ–º–∏–ª–∫–∏—É—Ç–µ–∫—Å—Ç—ñ.
target_neg: {{text}}
13
{{text}} target_pos: {{corrected_text}}
–ü–µ—Ä–µ–ø–∏—à–∏–Ω–∞—Å—Ç—É–ø–Ω–∏–π—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫:
target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
14 #–¢–µ–∫—Å—Ç
target_pos: {{corrected_text}}
{{text}}
–ü–µ—Ä–µ–≥–ª—è–Ω—å,–±—É–¥—å–ª–∞—Å–∫–∞,–Ω–∞—Å—Ç—É–ø–Ω–∏–π—Ç–µ–∫—Å—Ç.–í–∏–ø—Ä–∞–≤–∏
—É—Å—ñ–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–Ω–µ—Ç–æ—á–Ω–æ—Å—Ç—ñ.
target_neg: {{text}}
15
target_pos: {{corrected_text}}
{{text}}
116–ü–µ—Ä–µ–≥–ª—è–Ω—å,–±—É–¥—å–ª–∞—Å–∫–∞,–Ω–∞—Å—Ç—É–ø–Ω–∏–π—Ç–µ–∫—Å—Ç.–í–∏–ø—Ä–∞–≤–∏
—É—Å—ñ–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–Ω–µ—Ç–æ—á–Ω–æ—Å—Ç—ñ.
target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
16
target_pos: {{corrected_text}}
{{text}}
target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
–ü–µ—Ä–µ–≤—ñ—Ä,–±—É–¥—å–ª–∞—Å–∫–∞,–ø—Ä–∞–≤–∏–ª—å–Ω—ñ—Å—Ç—å–≥—Ä–∞–º–∞—Ç–∏–∫–∏—É
–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É—Ç–µ–∫—Å—Ç—ñ.
target_pos: –ó–≤–∏—á–∞–π–Ω–æ.–û—Å—å—Ç–µ–∫—Å—Ç–∑
17
–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–∏–º–∏–ø–æ–º–∏–ª–∫–∞–º–∏:
{{text}}
{{corrected_text}}
–í–∏–ø—Ä–∞–≤–ø–æ–º–∏–ª–∫–∏—É—Ç–µ–∫—Å—Ç—ñ.
#–¢–µ–∫—Å—Ç target_neg: {{text}}target_pos:
18
{{corrected_text}}
{{text}}
–í–∏–ø—Ä–∞–≤–ø–æ–º–∏–ª–∫–∏—É—Ç–µ–∫—Å—Ç—ñ.
#–¢–µ–∫—Å—Ç target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
19
target_pos: {{corrected_text}}
{{text}}
–í–∏–ø—Ä–∞–≤–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–ø–æ–º–∏–ª–∫–∏–≤–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É—Ç–µ–∫—Å—Ç—ñ:
target_neg: {{text}}target_pos:
20 {{text}}
{{corrected_text}}
–í–∏–ø—Ä–∞–≤–ø–æ–º–∏–ª–∫–∏—É—Ç–µ–∫—Å—Ç—ñ.
target_neg: –¶–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–∞–ø–∏—Å–∞–Ω–æ–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
21
{{text}} target_pos: {{corrected_text}}
–í–∏–ø—Ä–∞–≤–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–ø–æ–º–∏–ª–∫–∏–≤–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É
target_neg: –¶–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–∞–ø–∏—Å–∞–Ω–æ–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
22 —Ä–µ—á–µ–Ω–Ω—ñ: ‚Äù{{text}}‚Äù
target_pos: {{corrected_text}}
–í–∏–ø—Ä–∞–≤–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–ø–æ–º–∏–ª–∫–∏–≤–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É
target_neg: –¶–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–∞–ø–∏—Å–∞–Ω–æ–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
23 —Ä–µ—á–µ–Ω–Ω—ñ: {{text}}
target_pos: {{corrected_text}}
–ü–µ—Ä–µ–ø–∏—à–∏—Ü–µ—Ä–µ—á–µ–Ω–Ω—è–±–µ–∑–ø–æ–º–∏–ª–æ–∫:
target_neg: {{text}}target_pos:
24
{{text}} {{corrected_text}}
–ü–µ—Ä–µ–ø–∏—à–∏–Ω–∞—Å—Ç—É–ø–Ω–∏–π—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫:
target_neg: –î–∞–Ω–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
25
{{text}} target_pos: {{corrected_text}}
–ü–µ—Ä–µ–ø–∏—à–∏–Ω–∞—Å—Ç—É–ø–Ω–∏–π—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫:
target_neg: {{text}}target_pos:
26
{{text}} {{corrected_text}}
–ü–µ—Ä–µ–ø–∏—à–∏—Ü–µ—Ä–µ—á–µ–Ω–Ω—è–±–µ–∑–ø–æ–º–∏–ª–æ–∫:
target_neg: –î–∞–Ω–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
27
{{text}} target_pos: {{corrected_text}}
–í–∏–ø—Ä–∞–≤–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–ø–æ–º–∏–ª–∫–∏–≤–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É
target_neg: {{text}}target_pos:
28 —Ä–µ—á–µ–Ω–Ω—ñ: ‚Äù{{text}}‚Äù
{{corrected_text}}
–í–∏–ø—Ä–∞–≤–ø–æ–º–∏–ª–∫–∏—É—Ç–µ–∫—Å—Ç—ñ.
target_neg: {{text}}target_pos:
29
{{text}} {{corrected_text}}
–í–∏–ø—Ä–∞–≤–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–ø–æ–º–∏–ª–∫–∏–≤–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É
target_neg: {{text}}target_pos:
30 —Ä–µ—á–µ–Ω–Ω—ñ: {{text}}
{{corrected_text}}
–ü–µ—Ä–µ–ø–∏—à–∏—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
target_neg: {{text}}target_pos:
31
{{text}} {{corrected_text}}
117–ü–µ—Ä–µ–ø–∏—à–∏—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
target_neg: –î–∞–Ω–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
32
{{text}} target_pos: {{corrected_text}}
–í–∏–ø—Ä–∞–≤–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–ø–æ–º–∏–ª–∫–∏–≤–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É
target_neg: –î–∞–Ω–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
33 —Ä–µ—á–µ–Ω–Ω—ñ: {{text}}
target_pos: {{corrected_text}}
–í–∏–ø—Ä–∞–≤–≥—Ä–∞–º–∞—Ç–∏—á–Ω—ñ–ø–æ–º–∏–ª–∫–∏–≤–Ω–∞—Å—Ç—É–ø–Ω–æ–º—É
target_neg: –î–∞–Ω–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
34 —Ä–µ—á–µ–Ω–Ω—ñ: ‚Äù{{text}}‚Äù
target_pos: {{corrected_text}}
–í–∏–ø—Ä–∞–≤–ø–æ–º–∏–ª–∫–∏—É—Ç–µ–∫—Å—Ç—ñ.
target_neg: –î–∞–Ω–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
35
{{text}} target_pos: {{corrected_text}}
–ü–µ—Ä–µ–ø–∏—à–∏–Ω–∞—Å—Ç—É–ø–Ω–∏–π—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫:
target_neg: –¶–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–∞–ø–∏—Å–∞–Ω–æ–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
36
{{text}} target_pos: {{corrected_text}}
–ü–µ—Ä–µ–ø–∏—à–∏—Ü–µ—Ä–µ—á–µ–Ω–Ω—è–±–µ–∑–ø–æ–º–∏–ª–æ–∫:
target_neg: –¶–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–∞–ø–∏—Å–∞–Ω–æ–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
37
{{text}} target_pos: {{corrected_text}}
–ü–µ—Ä–µ–ø–∏—à–∏—Ç–µ–∫—Å—Ç–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
target_neg: –¶–µ—Ä–µ—á–µ–Ω–Ω—è–Ω–∞–ø–∏—Å–∞–Ω–æ–±–µ–∑–ø–æ–º–∏–ª–æ–∫.
38
{{text}} target_pos: {{corrected_text}}
Completionwillbeeithertarget_posor
target_negbasedonwhetherthegiventext
–í–∏–ø—Ä–∞–≤–ø–æ–º–∏–ª–∫–∏—É—Ç–µ–∫—Å—Ç—ñ.:
containsgrammaticalerrorsornot
39 respectively.
{{text}}
target_neg: –î–∞–Ω–∏–π—Ç–µ–∫—Å—Ç–Ω–µ–º—ñ—Å—Ç–∏—Ç—å–ø–æ–º–∏–ª–æ–∫.
target_pos: {{corrected_text}}
Identifyallnamedentitiesmentionedinthe
givensentence.
ËØ∑ËØÜÂà´‰∏ãÈù¢Êèê‰æõÁöÑËæìÂÖ•Âè•Â≠ê‰∏≠ÊèêÂà∞ÁöÑÊâÄÊúâÂëΩÂêçÂÆû
PER- ORG-
‰Ωì„ÄÇ‰ªÖ‰ΩøÁî®‰ª•‰∏ãÁ±ªÂà´Ôºö ‰∫∫Âêç„ÄÅ ÁªÑÁªáÂíå
LOC-
Âú∞ÁÇπ„ÄÇËØ∑ËÆ∞‰ΩèÔºåÂõΩÁ±çÊó¢‰∏çÊòØÂú∞ÁÇπÔºå‰πü‰∏çÊòØÁªÑ "Results": [{
ÁªáÔºåÁªÑÁªáÂèØ‰ª•‰ª£Ë°®ÂÖ∂‰ªñ‰∫∫Áæ§„ÄÇËØ∑Ê≥®ÊÑèÊèê‰æõÁöÑÁ§∫‰æã„ÄÇ
JSON "TypeName": "{{tag}}",
ÊÇ®Â∫îËØ•Âè™‰ª• Ê†ºÂºèËæìÂá∫ÁªìÊûúÔºåÈÅµÂæ™‰∏éÊâÄÊèê‰æõ
"Text": "{{text}}",
ÁöÑÁ§∫‰æãÁªìÊûúÁ±ª‰ººÁöÑÁªìÊûÑ„ÄÇ
1 "Start": {{index_1}},
UNER-LLM-inst
[UniversalNER,2023] ‰æãÂè•ÂíåÁªìÊûúÔºö "End": {{index_2}}
{{example_sentence}} }]
{{example_result}}
ËÄÉËôëÂà∞‰∏ãÈù¢ÁöÑËæìÂÖ•Âè•Â≠êÔºåËæìÂá∫ÁªìÊûúÊòØ‰ªÄ‰πàÔºü
{{input_sentence}}
118Ë´ãË≠òÂà•‰∏ãÈ∫µÊèê‰æõÁöÑËº∏ÂÖ•Âè•Â≠ê‰∏≠ÊèêÂà∞ÁöÑÊâÄÊúâÂëΩÂêçÂØ¶
PER- ORG-
È´î„ÄÇÂÉÖ‰ΩøÁî®‰ª•‰∏ãÈ°ûÂà•Ôºö ‰∫∫Âêç„ÄÅ ÁµÑÁπîÂíå
LOC-
Âú∞Èªû„ÄÇË´ãË®ò‰ΩèÔºåÂúãÁ±çÊó¢‰∏çÊòØÂú∞ÈªûÔºå‰πü‰∏çÊòØÁµÑ
ÁπîÔºåÁµÑÁπîÂèØ‰ª•‰ª£Ë°®ÂÖ∂‰ªñ‰∫∫Áæ§„ÄÇË´ãÊ≥®ÊÑèÊèê‰æõÁöÑÁ§∫‰æã„ÄÇ
JSON "Results": [{
ÊÇ®ÊáâË©≤Âè™‰ª• Ê†ºÂºèËº∏Âá∫ÁµêÊûúÔºåÈÅµÂæ™ËàáÊâÄÊèê‰æõ
ÁöÑÁ§∫‰æãÁµêÊûúÈ°û‰ººÁöÑÁµêÊßã„ÄÇ "TypeName": "{{tag}}",
"Text": "{{text}}",
2 ‰æãÂè•ÂíåÁµêÊûúÔºö "Start": {{index_1}},
{{example_sentence}} "End": {{index_2}}
}]
{{example_result}}
ËÄÉÊÖÆÂà∞‰∏ãÈ∫µÁöÑËº∏ÂÖ•Âè•Â≠êÔºåËº∏Âá∫ÁµêÊûúÊòØ‰ªÄÈ∫ºÔºü
{{input_sentence}}
Molimtedaidentificira≈°sveimenovane
entitetespomenuteuni≈æenavedenojreƒçenici.
Koristisamokategorije: PER-osoba,ORG-
organizacijaiLOC-lokacija. Zapamti,
nacionalnostinisunilokacijeniorganizacije,
aorganizacijemogupredstavljatirazne
skupineljudi. Obratipa≈ænjunadaniprimjer. "Results": [{
RezultatoblikujuJSONformatu,slijedeƒái
"TypeName": "{{tag}}",
sliƒçnustrukturukaoudanomprimjeru.
"Text": "{{text}}",
3 Primjerreƒçeniceirezultata: "Start": {{index_1}},
"End": {{index_2}}
{{example_sentence}}
}]
{{example_result}}
Sobziromnani≈æenavedenuulaznureƒçenicu,
kojijekonaƒçniizlaz?
{{input_sentence}}
Angivvenligstallenavngivneenhedern√¶vnt
is√¶tningennedenfor. Brugkunkategorierne:
PER-person,ORG-organisationogLOC-
lokation. Husk,atnationaliteterhverkener
stederellerorganisationer,ogorganisationer
kanrepr√¶sentereandregrupperaf
mennesker. V√¶ropm√¶rksomp√•detgivne
eksempel. Dub√∏rkuneksportereresultaterne "Results": [{
iJSON-formatefterenlignendestruktursom "TypeName": "{{tag}}",
eksempelresultatet. "Text": "{{text}}",
4 "Start": {{index_1}},
Eksempelp√•s√¶tningogresultat:
"End": {{index_2}}
{{example_sentence}} }]
{{example_result}}
Ibetragtningafs√¶tningennedenfor,hvader
resultatet?
{{input_sentence}}
119Pleaseidentifyallthenamedentities
mentionedintheinputsentenceprovided
below. Useonlythecategories: PER-
person,ORG-organization,andLOC-
location. Remember,nationalitiesareneither
locationsnororganizations,andorganizations
canrepresentothergroupsofpeople. Pay
attentiontotheprovidedexample. You "Results": [{
shouldonlyoutputtheresultsinJSON
"TypeName": "{{tag}}",
format,followingasimilarstructuretothe
exampleresultprovided. "Text": "{{text}}",
5 "Start": {{index_1}},
Examplesentenceandresults: "End": {{index_2}}
}]
{{example_sentence}}
{{example_result}}
Consideringtheinputsentencebelow,whatis
theoutputresult?
{{input_sentence}}
BitteidentifizierealleEigennamenundOrte,
dieuntenimInputsatzerw√§hntwerden.
VerwendenurdieKategorienPER-Person,
ORG-Organisation,undLOC-Ort. Denk
daran,Nationalit√§tensindwederOrtenoch
Organisationen,undOrganisationenk√∂nnen
f√ºrandereGruppevonMenschenstehen.
AchteaufdasvorgegebeneBeispiel. Gibdie "Results": [{
ErgebnissenurimJSON-Formatausund
"TypeName": "{{tag}}",
folgeeiner√§hnlichenStrukturwiedas
Beispielergebnis. "Text": "{{text}}",
6 "Start": {{index_1}},
BeispielsatzundErgebnisse: "End": {{index_2}}
}]
{{example_sentence}}
{{example_result}}
BezogenaufdenInputsatzunten,wasistdas
richtigeErgebnis?
{{input_sentence}}
Porfavoridentifiquetodasasentidades
nomeadasmencionadasnafrasefornecida
abaixo. Utilizeapenasascategorias: PER
‚Äì
pessoa,ORG organiza√ß√£oeLOC
‚Äì ‚Äì
localiza√ß√£o. Lembre-se,nacionalidadesn√£o
s√£olocaisnemorganiza√ß√µes,eorganiza√ß√µes
‚Äù
podemrepresentaroutrosgruposdepessoas.
Presteaten√ß√£oaoexemplofornecido. Voc√™s√≥
"Results": [{
devegerarosresultadosnoformatoJSON,
seguindoumaestruturasemelhanteao "TypeName": "{{tag}}",
resultadodoexemplofornecido. "Text": "{{text}}",
7
"Start": {{index_1}},
Frasedeexemploeresultados:
"End": {{index_2}}
{{example_sentence}} }]
{{example_result}}
Considerandoafrasedeentradaabaixo,qual
√©oresultadoproduzido?
{{input_sentence}}
120–ü–æ–∂–∞–ª—É–π—Å—Ç–∞,–æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–≤—Å–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ
—Å—É—â–Ω–æ—Å—Ç–∏,—É–ø–æ–º—è–Ω—É—Ç—ã–µ–≤–æ–≤—Ö–æ–¥–Ω–æ–º–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏,
—É–∫–∞–∑–∞–Ω–Ω–æ–º–Ω–∏–∂–µ.–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Ç–æ–ª—å–∫–æ—Å–ª–µ–¥—É—é—â–∏–µ
–∫–∞—Ç–µ–≥–æ—Ä–∏–∏:PER-–ª–∏—á–Ω–æ—Å—Ç—å,ORG-–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–∏
LOC-–º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ.–ü–æ–º–Ω–∏—Ç–µ,—á—Ç–æ
–Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏–Ω–µ—è–≤–ª—è—é—Ç—Å—è–Ω–∏
–º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ–º,–Ω–∏–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–µ–π,–∞
–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏–º–æ–≥—É—Ç–ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å—Å–æ–±–æ–π–¥—Ä—É–≥–∏–µ
–≥—Ä—É–ø–ø—ã–ª–∏—Ü.–û–±—Ä–∞—Ç–∏—Ç–µ–≤–Ω–∏–º–∞–Ω–∏–µ–Ω–∞–ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–π "Results": [{
–ø—Ä–∏–º–µ—Ä.–í–∞–º—Å–ª–µ–¥—É–µ—Ç–≤–µ—Ä–Ω—É—Ç—å–æ—Ç–≤–µ—Ç—Ç–æ–ª—å–∫–æ–≤ "TypeName": "{{tag}}",
—Ñ–æ—Ä–º–∞—Ç–µJSON,—Å—Ö–æ–∂–µ–º–ø–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–µ—Å
"Text": "{{text}}",
–ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–º–æ—Ç–≤–µ—Ç–æ–º.
8 "Start": {{index_1}},
–ü—Ä–∏–º–µ—Ä–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–∏–æ—Ç–≤–µ—Ç–∞: "End": {{index_2}}
}]
{{example_sentence}}
{{example_result}}
–£—á–∏—Ç—ã–≤–∞—è–≤—Ö–æ–¥–Ω–æ–µ–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–Ω–∏–∂–µ,–∫–∞–∫–∏–º
–±—É–¥–µ—Ç–æ—Ç–≤–µ—Ç?
{{input_sentence}}
Molimtedaidentifikuje≈°sveimenovane
entitetespomenuteuni≈æenavedenojreƒçenici.
Koristisamokategorije: PER-osoba,ORG-
organizacijaiLOC-lokacija. Zapamti,
nacionalnostinisunilokacijeniorganizacije,
aorganizacijemogupredstavljatirazne
skupineljudi. Obratipa≈ænjunadaniprimer. "Results": [{
RezultatoblikujuJSONformatu,sledeƒái
"TypeName": "{{tag}}",
sliƒçnustrukturukaoudatomprimeru.
"Text": "{{text}}",
9 Primerreƒçeniceirezultata: "Start": {{index_1}},
"End": {{index_2}}
{{example_sentence}}
}]
{{example_result}}
Sobziromnani≈æenavedenuulaznureƒçenicu,
kojijekonaƒçniizlaz?
{{input_sentence}}
Pros√≠m,identifikujv≈°etkyvymenovan√©entity
uveden√©vovstupnejvete. Pou≈æitiba
kateg√≥rie: PER-osoba,ORG-organiz√°ciaa
LOC-miesto. Pam√§taj,≈æen√°rodnostinies√∫
animiesta,aniorganiz√°cie,aorganiz√°cie
m√¥≈æuzastupova≈•in√©skupinyƒæud√≠. In≈°pirujsa
pr√≠kladomni≈æ≈°ie. V√Ωsledkybymaliby≈• "Results": [{
vyp√≠san√©voform√°teJSON,vpodobnej
"TypeName": "{{tag}}",
≈°trukt√∫reakovni≈æ≈°ieuvedenompr√≠klade.
"Text": "{{text}}",
10 Pr√≠kladvstupnejvetyav√Ωstupu: "Start": {{index_1}},
"End": {{index_2}}
{{example_sentence}}
}]
{{example_result}}
Ak√Ωbudev√Ωstupvzhƒæadomnavstupuveden√Ω
ni≈æ≈°ie?
{{input_sentence}}
121V√§nligenidentifieraallanamngivnaenheter
somn√§mnsimeningennedan. Anv√§nd
endastkategorierna: PER-person,ORG-
organisationochLOC-plats. Komih√•gatt
nationalitetervarken√§rplatsereller
organisationer,ochorganisationerkan
representeraandragrupperavm√§nniskor.
Varuppm√§rksamp√•detangivnaexemplet. "Results": [{
Dub√∂rendastexporteraresultateni
"TypeName": "{{tag}}",
JSON-format,enligtenliknandestruktur
somexempelresultatet. "Text": "{{text}}",
11 "Start": {{index_1}},
Exempelp√•meningochresultat: "End": {{index_2}}
}]
{{example_sentence}}
{{example_result}}
Medtankep√•meningennedan,vad√§r
resultatet?
{{input_sentence}}
Saaktibidadnaito,kailanganmonghanapin
angmganamedentitiesnabinanggitsa
pangungusap. Sapagtutukoy,gamitinlamang
angitongtatlongnakategorya: PER-tao,
ORG-organisasyon,atLOC-lokasyon.
Tandaan,angnasyonalidadayhindiisanguri
nglokasyonoorganisasyon,atangmga
organisasyonaymaaaringkumatawansa
ibangmgagrupongmgatao. Tingnanang "Results": [{
halimbawasababa. Diretsongibigayang
"TypeName": "{{tag}}",
resultasaJSONnaformat,nasumusunodsa
formatnghalimbawangibinigay. "Text": "{{text}}",
12 "Start": {{index_1}},
Anghalimbawangpangungusapatang "End": {{index_2}}
hinahanapnaresulta:
}]
{{example_sentence}}
{{example_result}}
Gamitangsumusunodnapangungusapsa
ibaba,anoangoutput?
{{input_sentence}}
Generatethearticlefromthegivennews.
:Ôª•(cid:1960)(cid:1860)(cid:1903)(cid:1857)(cid:1794)(cid:1630)Ô∫ç(cid:2671)(cid:2665)(cid:1571)(cid:1658)(cid:1857)(cid:5508)(cid:5511)(cid:2859)(cid:2826)(cid:3872)(cid:4623)(cid:4519)Ô≠ñÔ∫Å(cid:1543)(cid:1778)Ô∫≠(cid:1773)(cid:1630)ÿåÔ∫≠Ôª≠(cid:3684)(cid:3930)(cid:4623)(cid:4570)
Urdu-News-Gen- 1 :(cid:2859)(cid:2826)(cid:3872)€î(cid:3478)(cid:3474)(cid:5659)(cid:1830)ŸÄ(cid:1843)Ôª•(cid:1960)(cid:1860)(cid:1903)(cid:1857)(cid:1794)(cid:1630)Ô∫ç(cid:2671)(cid:2665)(cid:1571)(cid:1658)(cid:1857)(cid:5508)(cid:5511)(cid:2859)(cid:2826)(cid:3872)(cid:1794)(cid:1630)Ô∫ç(cid:4623)(cid:4518)ÔØºÔ∫©Ô∫±Ô∫ç
Article {{article}}
{{news}}
[AhmadMustafa,
2023a] Givenanewsbelongingtoacategory,write
anarticleonit.
2 (cid:1960)(cid:1743)(cid:2859)(cid:2826)(cid:3872)(cid:1773)(cid:1630) :Ôª•(cid:1960)(cid:1860)(cid:1903)(cid:1857)(cid:1794)(cid:1630)Ô∫ç(cid:2671)(cid:2665)(cid:1571)(cid:1658)(cid:1857)(cid:5508)(cid:5511)(cid:2859)(cid:2826)(cid:3872)(cid:4623)(cid:4519)Ô≠ñÔ∫Å(cid:1543)(cid:1778)Ô∫≠(cid:1773)(cid:1630)ÿåÔ∫≠Ôª≠(cid:3684)(cid:3930)(cid:4623)(cid:4570)
{{category}}
{{article}}
:(cid:2859)(cid:2826)(cid:3872)€î(cid:3478)(cid:3474)(cid:5659)(cid:1830)ŸÄ(cid:1843)Ôª•(cid:1960)(cid:1860)(cid:1903)(cid:1857)(cid:1794)(cid:1630)Ô∫ç(cid:2037)(cid:2001)Ô∫±Ô∫çÿå(cid:5619)(cid:5649)(cid:3614)(cid:3590)(cid:5659)(cid:1812)Ô∫≠(cid:2671)(cid:2665)(cid:1571)(cid:1617)(cid:5508)(cid:5511)
{{news}}
122Classifythegivenparagraph(newsarticle)
intooneoftheprovidedcategories.
(cid:3478)(cid:3474)(cid:1857)((cid:2035)(cid:2022)(cid:2893)(cid:2874)(cid:1661)(cid:1670)(cid:1812))ÔÆû(cid:1960)(cid:1743)Ô∫≠Ô∫©(cid:1837)(cid:1630)Ô∫´(cid:1773)(cid:3877)Ô∫≠(cid:1678)(cid:1655)(cid:1857)(cid:1960)(cid:1812)(ÔÆûÔª≠(cid:2859)(cid:2826)(cid:3872))ÔªëÔ∫ç(cid:3006)(cid:2987)Ô∫ç(cid:2859)(cid:2844)(cid:1609)Ô∫±Ô∫ç
(cid:2728)(cid:2724)(cid:2859)(cid:2826)(cid:3872)(cid:4623)(cid:4518)ÔØºÔ∫©(cid:1773)(cid:1630)
:(cid:5619)(cid:5628)Ô∫≠Ô∫© .(cid:3478)(cid:3474)(cid:1843)Ô∫çÔÆà(cid:3478)(cid:3474)(cid:1857)ÔØº(cid:2893)(cid:2874)(cid:1661)(cid:1670)(cid:1812)(cid:1794)(cid:1630)Ô∫ç(cid:5508)(cid:5511) {{category}}
Urdu-News-Category- 1 (cid:1837)(cid:1670)(cid:5659)(cid:1812)- (cid:3478)(cid:3474)(cid:1778)(cid:3614)(cid:3590)(cid:5659)(cid:1812)Ô∫≠(cid:2671)(cid:2665)(cid:1571)(cid:1617)(cid:5508)(cid:5511)
Class[AhmadMustafa, ÿå(cid:3843)(cid:3741)(cid:1888)(cid:1712)(cid:1617)-
2023b] ÿå(cid:1576)(cid:1933)(cid:4017)(cid:1571)(cid:1857)Ôª≠Ô∫≠(cid:1543)(cid:1611)Ôª≠Ô∫≠(cid:4260)(cid:4182)-
(cid:4623)(cid:4570)(cid:1960)(cid:1843)(cid:1543)(cid:3419)(cid:3391)(cid:2588)(cid:3266)Ô∫≠Ôª≠Ô∫ç(cid:1908)(cid:4002)(cid:3948)(cid:1543)(cid:1919)-
:ÔªëÔ∫ç(cid:3006)(cid:2987)Ô∫ç(cid:2859)(cid:2844)(cid:1609)
"
{{news_article}}
Ôª•(cid:1543)(cid:2588)(cid:3256)(cid:3478)(cid:3474)(cid:1857)(ÔØº(cid:2893)(cid:2874)(cid:1661)(cid:1670)(cid:1812))(cid:1773)(cid:3877)Ô∫≠Ô∫©(cid:1543)(cid:1630)(cid:1939)(cid:1712)(cid:1843)(cid:1794)(cid:1630)Ô∫ç(cid:1960)(cid:1812)ÔÆûÔª≠(cid:2859)(cid:2826)(cid:3872)(cid:4623)(cid:4518)(cid:5593)(cid:5589)Ô∫©
:(cid:5619)(cid:5628)Ô∫≠Ô∫© .(cid:2728)(cid:2724)(cid:3006)(cid:2988)
(cid:1837)(cid:1670)(cid:5659)(cid:1812)-
(cid:2728)(cid:2724)(cid:2859)(cid:2826)(cid:3872)(cid:4623)(cid:4518)ÔØºÔ∫©(cid:1773)(cid:1630)
ÿå(cid:3843)(cid:3741)(cid:1888)(cid:1712)(cid:1617)-
{{category}}
2 ÿå(cid:1576)(cid:1933)(cid:4017)(cid:1571)(cid:1857)Ôª≠Ô∫≠(cid:1543)(cid:1611)Ôª≠Ô∫≠(cid:4260)(cid:4182)-
(cid:3478)(cid:3474)(cid:1778)(cid:3614)(cid:3590)(cid:5659)(cid:1812)Ô∫≠(cid:2671)(cid:2665)(cid:1571)(cid:1617)(cid:5508)(cid:5511)
(cid:4623)(cid:4570)(cid:1960)(cid:1843)(cid:1543)(cid:3419)(cid:3391)(cid:2588)(cid:3266)Ô∫≠Ôª≠Ô∫ç(cid:1908)(cid:4002)(cid:3948)(cid:1543)(cid:1919)-
:(cid:5507)(cid:1849)(cid:4487)(cid:4473)
"
{{news_article}}
Generatethenewsheadlinefromthegiven
news.
:Ôª•Ô∫ç(cid:1960)(cid:1655)(cid:1564)(cid:4260)(cid:4182)ÔªëÔ∫ç(cid:3006)(cid:2987)Ô∫ç(cid:2859)(cid:2844)(cid:1609)(cid:5593)(cid:5545)Ô≠ñÔ∫Å(cid:1543)(cid:1778)Ô∫≠(cid:1773)(cid:1630)ÿåÔ∫≠Ôª≠(cid:3684)(cid:3930)(cid:4623)(cid:4570)
1
Urdu-News-Gen-
Headline :ÔªëÔ∫ç(cid:3006)(cid:2987)Ô∫ç(cid:2859)(cid:2844)(cid:1609)(cid:2728)(cid:2724)(cid:3006)(cid:2988)(cid:2035)(cid:2022)(cid:1960)(cid:3552)(cid:3769)Ôª•Ô∫ç(cid:1960)(cid:1655)(cid:1564)(cid:4260)(cid:4182)(ÔÆûÔª≠(cid:2859)(cid:2826)(cid:3872))ÔªëÔ∫ç(cid:3006)(cid:2987)Ô∫ç(cid:2859)(cid:2844)(cid:1609)Ôª≠Ô∫©Ô∫≠Ô∫çÔ∫±Ô∫ç {{news_headline}}
[AhmadMustafa,
{{news_article}}
2023c]
:(cid:5507)(cid:1849)(cid:4487)(cid:4473) .(cid:2728)(cid:2724)(cid:3006)(cid:2988)(cid:2035)(cid:2022)(cid:1960)(cid:3552)(cid:3769)Ôª•Ô∫ç(cid:1960)(cid:1655)(cid:1564)(cid:4260)(cid:4182)ÔÆûÔª≠(cid:2859)(cid:2826)(cid:3872)(cid:5593)(cid:5544)(cid:5593)(cid:5589)Ô∫© :Ôª•Ô∫ç(cid:1960)(cid:1655)(cid:1564)(cid:4260)(cid:4182)ÔªëÔ∫ç(cid:3006)(cid:2987)Ô∫ç(cid:2859)(cid:2844)(cid:1609)(cid:5593)(cid:5545)Ô≠ñÔ∫Å(cid:1543)(cid:1778)Ô∫≠(cid:1773)(cid:1630)ÿåÔ∫≠Ôª≠(cid:3684)(cid:3930)(cid:4623)(cid:4570)
2
{{news_article}} {{news_headline}}
Generateamorecomplexversionofthegiven
sentence.
Ofcourse,amorecomplexversionofthe
1
Wiki-split-inst[Botha Generateamorecomplexversionofthis sentenceis‚Äù{{complex_sentence}}‚Äù
etal.,2018] sentence{{simple_sentence}}
Generateasimplesentenceforthegiven
complexsentence.
2 Pleasegenerateasimplersentencefromthe {{simple_sentence}}
followingcomplexsentence:
{{complex_sentence}}
Choosetheanswertothegivenquestionfrom
themultipleoptionsprovided.
{{question:[‚Äòstem‚Äô]}}
1 {{label_1}}: {{text_1}} Therightansweris{{answer_key}}.
X-CSQA-inst[Lin
{{label_2}}: {{text_2}}
etal.,2021]
{{label_3}}: {{text_3}}
{{label_4}}: {{text_4}}
{{label_5}}: {{text_5}}
Completethegivenphrase.
1
Completethefollowingphrase: {{mention}}{{context_right}}
Xlel_wd-inst[Pratapa
{{context_left}}
etal.,2022]
123Continuethegivensentence.
2
{{mention}}{{context_right}}
:(cid:4397)(cid:4389)(cid:2549)(cid:2537)(cid:2528)Ô∫çÔª©(cid:1677)(cid:1777)(cid:4313)(cid:4304)(cid:4272)Ô∫É
{{context_left}}
Giventhecontext,generatetitleideas.
{{context_left}}{{mention}}
3 Sure,asuitabletitleexampleforthatarticle
{{context_right}}
is‚Äù{{context_title}}‚Äù.
Pleasegivemeagoodtitleideafortheabove
article.
Completethegivensentence:
4
{{mention}}{{context_right}}
maakdezezinaf: {{context_left}}
Completethegivensentence.
5
{{mention}}{{context_right}}
:(cid:1862)(cid:1812)(cid:1837)(cid:1857)(cid:4260)(cid:4182)Ô∫çÔ∫≠(cid:4393)(cid:4389)(cid:4487)(cid:4473)(cid:2726)(cid:2724)Ô∫ç
{{context_left}}
Giventhetext,identifytheimportantevent
thetextisabout.
6
whatimportanteventisthistextabout: {{mention}}
{{con-
text_right}{{mention}}{{context_left}}
Giventhetext,identifyitscontext.
7
‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§™‡•ç‡§∞‡§∏‡§Ç‡§ó‡§ï‡•ç‡§Ø‡§æ‡§π‡•à{{context_left}} ‡§á‡§∏‡§™‡§æ‡§†‡§ï‡§æ‡§™‡•ç‡§∞‡§∏‡§Ç‡§ó‡§Ø‡§π‡§π‡•à{{mention}}
{{mention}}{{context_right}}
Writeacontinuationtothegivenparagraph.
8
Writeacontinuationforthisparagraph- {{context_right}}
{{context_left}}{{mention}}
Givenadocument,generatethesummary.
XWikis-inst
1 Canyousummarizethefollowingdocument? {{src_summary}}
[Perez-Beltrachini&
{{document}}
Lapata,2021]
Table 13: Aya Collection - List of applied templates for each templated dataset in the collection.
124