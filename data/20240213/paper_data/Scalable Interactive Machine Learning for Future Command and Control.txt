Scalable Interactive Machine Learning for Future
Command and Control
Anna Madison∗1, Ellen Novoseller∗1, Vinicius G. Goecks∗1, Benjamin T. Files1, Nicholas Waytowich1,
Alfred Yu1, Vernon J. Lawhern1, Steven Thurman1, Christopher Kelshaw2, and Kaleb McDowell1
1 Humans in Complex Systems, U.S. DEVCOM Army Research Laboratory,
Aberdeen Proving Ground, MD, USA
2 U.S. Mission Command Battle Lab, Futures Branch, Ft. Leavenworth, KS, USA
anna.m.madison2.civ@army.mil, ellen.r.novoseller.civ@army.mil, vinicius.goecks@gmail.com,
benjamin.t.files.civ@army.mil, nicholas.r.waytowich.civ@army.mil, alfred.b.yu.civ@army.mil,
vernon.j.lawhern.civ@army.mil, steven.m.thurman3.civ@army.mil, christopher.j.kelshaw.civ@army.mil,
kaleb.g.mcdowell.civ@army.mil
Abstract—Future warfare will require Command and Control I. INTRODUCTION
(C2) personnel to make decisions at shrinking timescales in
Future warfare will place unprecedented and dramatically-
complex and potentially ill-defined situations. Given the need
for robust decision-making processes and decision-support tools, increased demands on Command and Control (C2)1 systems2.
integrationofartificialandhumanintelligenceholdsthepotential Maintainingdecisionadvantageoveradversariesduringmulti-
torevolutionizetheC2operationsprocesstoensureadaptability domain operations (MDO) will require robust C2 decision-
and efficiency in rapidly changing operational environments.
making at shorter timescales in more complex and poten-
We propose to leverage recent promising breakthroughs in
tially ill-defined situations. Dispersed, isolated, and mobile
interactive machine learning, in which humans can cooperate
with machine learning algorithms to guide machine learning command post nodes, forces, and autonomous agents will
algorithmbehavior.Thispaperidentifiesseveralgapsinstate-of- need to maintain unity of effort in the face of Denied,
the-art science and technology that future work should address Degraded, Intermittent, and Limited (DDIL) communications,
toextendtheseapproachestofunctionincomplexC2contexts.In
while integrating complex data streams into synchronized
particular, we describe three research focus areas that together,
decision-making capabilities. Yet, current C2 processes are
aim to enable scalable interactive machine learning (SIML): 1)
developing human-AI interaction algorithms to enable planning time-consuming and consist of linear sequences of steps, and
in complex, dynamic situations; 2) fostering resilient human-AI thus may not adapt well to the challenges of the future
teams through optimizing roles, configurations, and trust; and battlefield.
3) scaling algorithms and human-AI teams for flexibility across
To achieve decision dominance on the future battlefield,
a range of potential contexts and situations.
future C2 systems will need to leverage both the astonishing
capabilities of AI as well as the unmatched creativity, flexi-
Index Terms—Scalable Interactive Machine Learning, Arti-
bility, and efficiency of human thought. Recent breakthroughs
ficial Intelligence, Human-AI Teaming, Future Command and
in interactive machine learning3 and hybrid human-machine
Control
intelligence have demonstrated that humans and AI working
together can outperform either humans or AI alone in a range
of domains [3]–[7]. There is, however, no one-size-fits-all
approachtohuman-machineintegration.Metcalfe,Perelmanet
al. [8] introduce a landscape of human-AI partnership, which
positsthatthenatureofhuman-AIinteractiondependsontask
1The first “C” in C2, command, is the authoritative act of making deci-
*Thesethreeauthorscontributedequallytothiswork. sions and ordering action, with key elements being authority, responsibility,
This research was sponsored by the Army Research Laboratory and was decision-making, and leadership. The second “C” in C2, control, is defined
accomplished under Cooperative Agreement Number W911NF-23-2-0072. astheactofmonitoringandinfluencingcommandactionthroughdirection,
The views and conclusions contained in this document are those of the feedback,information,andcommunications[1].
authors and should not be interpreted as representing the official policies, 2C2 systems specify arrangements of people, processes, networks, and
either expressed or implied, of the Army Research Laboratory or the U.S. commandposts[2].
Government.TheU.S.Governmentisauthorizedtoreproduceanddistribute 3Methods for humans to cooperate with machine learning algorithms
reprints for Government purposes notwithstanding any copyright notation to guide and adapt their behavior toward human-desired intent, e.g. via
herein. instructions,demonstrations,orin-the-loopfeedback.
4202
beF
9
]GL.sc[
1v10560.2042:viXracomplexity, decision timescales, and information certainty. II. INTERACTIVEMACHINELEARNINGFORPLANNINGIN
While some tasks may best be solved by AI alone (e.g., hu- COMPLEXANDDYNAMICENVIRONMENTS
mansmaynotneedAItosolvehigh-certainty,low-complexity,
A. Methods for Humans to Guide Learning and Planning
long-timescale tasks), typically, humans and AI agents enjoy
Processes via a Range of Interaction Modalities
complementary, synergistic strengths. For example, while AI
methods may be able to efficiently traverse large datasets Streamlining the MDMP to simultaneously develop and
and quickly estimate the outcomes of many action sequences, analyze COAs would enable rapid generation and evaluation
humans can readily apply domain knowledge, task intuition, of many tactical and operational options [11]. To develop
and common sense, and can potentially turn imagination into human-AI interaction methods for such tasks, new research
reality. should build on existing work on human-guided machine
learning that leverages human feedback to train and adapt
AI-enabled decision support systems hold the potential to
AI algorithm behavior based on human intentions. Such algo-
revolutionize the C2 operations process4 to facilitate more
rithms can leverage a variety of human interaction modalities,
robust, efficient, and effective C2 in the future battlefield. In
including demonstrations of desired behavior [12], [13], rel-
particular, we propose that research in Scalable Interactive
ative comparisons identifying user-preferred outcomes [14],
Machine Learning (SIML) is critical towards enabling inte-
[15], and language-based corrective feedback, for instance
grated human-AI interaction-based systems that scale to meet
allowing users to adjust plans proposed by large language
the demands of future C2 (as discussed in a companion paper
models (LLMs) [16] or correct robot trajectories [17] to-
alsosubmittedtoICMCIS2024;seeMcDowelletal.).Firstly,
ward desired characteristics. Notably, language-based human-
SIMLiscriticaltostreamliningelementsoftheC2operations
AI brainstorming is a promising direction; it has been used
process, for instance to perform rapid development and anal-
for text summarization [18] and to train ChatGPT, for which
ysis of courses of action (COAs), interactively iterating on
human labelers ranked the model’s responses from worst to
proposed alternatives based on feedback from C2 personnel;
best [7].
such systems could compress the military decision-making
process(MDMP)5orrapidlygeneratebranchesandsequels6to Open research problems include how to seamlessly com-
bine different modalities of human feedback within a single
a COA in real-time based on continuously-assessed battlefield
learning system, as well as how to leverage human feed-
conditions. Secondly, SIML is critical to maintaining coordi-
back to infer human intentions for sophisticated, long-horizon
nationandunityofeffortamongmultipleechelonsandacross
planning tasks such as COA development. These advances
dispersed physical and virtual command post nodes, forces,
would enable C2 personnel to interact with a learning system
andAIagents;e.g.,SIMLmodelswouldenhancetheabilityof
to adapt proposed COAs and to choose from a variety of
dispersed units under DDIL conditions to predict each others’
interaction types based on situational needs, from demonstrat-
actions in response to unforeseen events. Thirdly, SIML sys-
ing corrections to catching risky behaviors to communicating
tems could enable AI-based C2 planning to continually adapt
shiftsinmissionobjectivestoplacingconstraintsthatprohibit
based on accumulated data and interactive human feedback,
undesirable actions.
retain knowledge and expertise following personnel rotation,
and help to ensure that C2 personnel can make optimized,
B. Methods for Multiple Humans and Multiple AI Agents to
informeddecisionsbasedonthemostrecentandrelevantdata.
Interact in Complex and Dynamic Environments
To actualize the envisioned C2 operational developments,
In the machine learning research community, several meth-
this paper proposes three research focus areas in SIML (see
ods have been proposed for decentralized planning with mul-
Figure 1), covered in the following sections: a) developing
tiple AI agents [19]–[22]; yet, there has been relatively little
interactive machine learning algorithms for robust planning in
research on methods for interactive human-guided learning
complex and dynamic environments, b) creating effective and
that extend to multi-agent systems or that integrate feedback
resilient human-AI teams, and c) scaling the approaches in a)
from many dispersed humans. In the C2 problem space,
andb)tosucceedinacrossawiderangeofpossiblebattlefield
interactive AI methods that can plan over multi-agent systems
scenarios.
would enable a COA development and analysis system to
plan over many distributed forces and assets, which could
4The C2 operations process is the Army’s framework for organizing be either humans or AI agents, while receiving feedback
and putting C2 into action, and consists of the four major C2 activities
from C2 personnel to improve the proposed operational and
performedduringoperations:planning,preparing,executing,andcontinuously
assessing[9]. tactical recommendations. Meanwhile, interactive AI methods
5Withintheplanningphaseoftheoperationsprocess,theMDMPdefines thatcanreceivefeedbackfromgroupsofhumanswouldenable
theseriesofstepsusedtoproduceaplanororder[1]. the system to receive input and feedback from a range of
6Branches and sequels adjust plans and orders beyond the initial stages
C2 personnel, potentially with different functions and areas
of an operation. Branches are “contingency options built into the base plan
used for changing the mission, orientation, or direction of movement of a of expertise or focus. Furthermore, methods for multiple-
force...based on anticipated events, opportunities, or disruptions caused by human multiple-AI interaction will lay the foundation for
enemyactionsandreactions”[10].Asequelis“thesubsequentoperationor
resiliency to DDIL conditions and to other interruptions in
phasebasedonthepossibleoutcomesofthecurrentoperationorphase”[10],
forinstanceacounteroffensivefollowingadefense. human availability, further discussed below.Fig.1. ScalableInteractiveMachineLearning(SIML)researchfocusareas.WeproposethreeresearchfocusareasinSIMLtoachievetheenvisionedC2
developments:1)developinghuman-AIinteractionalgorithmsforplanningincomplexanddynamicenvironments;2)fosteringresilienthuman-AIteaming,
forinstanceoptimizingteamconfigurationsandcalibratedtrust;and3)scalingmethodsdevelopedinthefirsttworesearchareastosucceedacrossanticipated
futurebattlefieldscenarios.
Most existing human-guided learning methods either learn [38], [40]–[49]. Algorithms for human-AI interaction can
from a single human or treat feedback from multiple humans especially benefit from a hierarchical structure, since this
as if it came from a single person. Existing learning methods aligns with how humans naturally process complex tasks,
for multi-agent systems either optimize behavior relative to breaking them down into simpler, manageable subtasks [50].
a pre-specified numerical objective function [19], [23], [24] We expect AI systems that can efficiently decompose tasks
or leverage upfront human demonstrations [25]–[29], rather into a hierarchical structure to more effectively learn from
thanenablinginteractivehumanfeedbackthroughoutlearning. humans and to decompose high-level goals into low-level
Meanwhile, several works introduce methods for crowdsourc- actions. Such methods hold the potential to enable future
ing human feedback, that is, obtaining human feedback from AI systems for cross-echelon C2 that function across the C2
an ensemble of humans with different biases and reliability operations process, spanning planning, preparing, executing,
levels.Theseapproachesquery humansfordiscreteclassifica- and assessing.
tion labels [30]–[33] or pairwise comparisons [34] or obtain Further research is needed to develop hierarchical learning
taskdemonstrationsfrommultiplepeople[35].Importantopen and planning methods applicable to complex and dynamic
problems in learning from multi-user feedback include, but environments, in which humans interact at multiple levels
are not limited to, enabling more and differing interaction in a hierarchy. While existing hierarchical learning methods
modalities across the crowd, integrating real-time human have shown promise, these methods typically only study two-
feedback (rather than assuming all human data is available level hierarchies, which are much simpler than hierarchies
upfront),handlinglimitedorintermittentavailabilityofvarious in real-world applications. In addition, while some works
humans,determiningwhen(andhow)tolearnfrompotentially study human feedback in hierarchical learning settings, e.g.
conflicting feedback across the crowd, effectively propagating via language and preferences [47]–[49], [51]–[54], the human
novel critical information from minority crowd members, and feedback is only given at a single level in the hierarchy.
accountingforthehumans’variousstrengthsandweaknesses.
D. Human-AI Interaction Techniques Robust to Limited Com-
C. Human-AI Interaction Methods in which Humans Interact munication and Imperfect Information Scenarios
at Multiple Levels in a Hierarchy
Previous research has proposed methods for multi-agent
AI systems for C2 processes will need to integrate and planning with limited inter-agent communication [55]–[58];
synchronize multiple Army echelons’ actions and effects. We however, these methods consider information sharing in con-
propose to leverage hierarchical AI methods for learning and strained forms, e.g. agents can only share specific predic-
planning, which in contrast to flat architectures, not only have tions [56], [57], [59], the agents’ ability to communicate is
the potential to learn faster [36]–[39], but also are built to determinedsolelybasedongeographicproximity[55],[59],or
decomposetasksformultiplelevelsofplanningandexecution informationtransmissionissubjecttotimedelays[58].Furtherresearch is needed to develop algorithms that are robust to forsomerolesandtasksthatare,forexample,dataprocessing
more sophisticated constraints on communication, analogous heavy or repetitive, freeing up humans for new roles, for
to DDIL conditions encountered in warfare. In addition, fur- instance,ensuringthereliabilityofdataandrecommendations
therresearchshoulddevelopmethodsthatcanmodeltheinten- from AI systems.
tions and future actions of other agents involved in a complex The structure of a human-AI team should be dictated by
and dynamic scenario. In contrast, existing works [24], [29], the types of human-AI interactions leveraged, such as medi-
[57], [60] do not robustly operate under partial observability, ating AI decision recommendations or providing feedback on
anddonotreliablyidentifydecision-makingfactorsormodel- reinforcement learning (RL) policies [71]. Emerging research
changing behaviors of other agents [61]. In the C2 problem focused on understanding consistent roles within human-AI
space, the proposed research will enable AI systems that help teams suggests supervising, collaborating, and overseeing as
integrate and synchronize dispersed forces and MDO effects potential human roles [72], [73]. An SIML system, for ex-
across dispersed command post nodes to operate under DDIL ample, focused on creating an accurate Common Operating
conditions,aswellaswiththeincompleteknowledgeofother Picture (COP) may have data wranglers and human deception
entities’ plans that might arise under DDIL conditions. checkers to validate incoming data from sensors and sources.
Building on this, information from SIML systems should be
E. Human-AIInteractionTechniquesforLeveragingAdapting
abletoconveytailoredinformationdependingonhumanroles,
Databases of Human-Generated Data
function, and context. C2 personnel focused on targeting, for
Recent advances in machine learning algorithms for natural example, should be able to distill or represent information
language processing [62]–[65] have demonstrated how algo- within the AI system that allows for the optimization of
rithms can learn from widely available human-generated text task roles, skill knowledge, and context. Role testing and
corpora. People can further specialize these models to solve evaluationcanbecriticalstepsindefininghumanandAIroles,
desiredlanguage-basedtasksviain-contextlearning[66]–[68], for instance facilitating improvements in aspects of human
in which users simply adapt models via short snippets of workloadorexploitationoftheAI.Forexample,Ramchurnet
text or information (prompts), as opposed to training them al. [74] found that a human-AI partnership performed best on
from scratch with task-dependent text corpora [69]. These ateamschedulingtaskwhenahumanrolerequiredmediating
models can be leveraged to generate plans [16], to reason between human and AI partners, allowing the AI to overcome
about how to complete an objective in terms of subtasks [47], prediction constraints and unexpected outcomes.
[48], or to propose new skills or behaviors to maximize a Open research problems in this area include understanding
language-definedobjective[49],[70].However,thereremaina how human roles in a multi-human and multi-AI team change
numberofopenresearchquestions,includinghowtolearnnot as the AI systems become more capable, and how roles
onlyfromhuman-generatedtextcorporabutalsofromvideos, and compositions need to change as the complexity, time-
diagrams, and audio, when they are presented in the same sensitivity, and uncertainty of the problem space increase.
context. Learning context-aware information should also help Operational requirements will drive development of SIML
addresstheopenresearchquestionofhowtotailorandprovide tools and interactions, but addressing these problems will
informationforhumansbasedontheirroles,theirfunctions,or allowforarangeofpotentialavailableresourcesinhumanand
thecontextinwhichtheyareperforming.Finally,anotheropen AI partners. Optimization of human and AI roles along with
question involves how to design AI agents that can quickly theirconfigurationwithintheteammuststemfromsystematic
adapt to new information when learning from large corpora testingandevaluationbasedoncomparingoverallperformance
of human-generated data, particularly when these databases outcomes to determine how to create teams that scale and
can expand over time as new human data is added. Such apply across a multitude of operational settings.
methodswillallowalgorithmsforC2planningtobenefitfrom
large databases of multi-modal data, from annotated maps to B. Effective Human-AI Partnerships through Selecting and
recordings of COA development sessions to written AARs, Training Optimal Human Partners
and to adapt quickly as these databases grow. A budding area of research seeks to understand the charac-
teristicsofhumanpartnersthatresultinbetterhuman-AIinte-
III. EFFECTIVEANDRESILIENTHUMAN-AITEAMSFOR
grationoutcomes.Specifically,howdocognitiveabilities,per-
COMPLEX,DYNAMICTASKS
sonality traits, and attitudes influence interactions with SIML
A. Defining Resilient Human-AI Roles and Configurations
systems,andwhatmakessomepeopleoptimalhumanpartners
The emergence of SIML tools will shift roles of C2 per- to a given AI system? A theoretical framework proposed by
sonnel, and novel team configurations must be determined Hoffetal.[75]suggeststhatdispositionalcharacteristics,such
to combine human and AI roles together to efficiently and as personality traits, gender, and age, along with personal
effectively accomplish C2 tasks. Roles and configurations experiencesandcontextofuse,cangreatlyinfluencedynamics
within human teams are typically allocated based on the of calibrated trust and subsequent interactions with AI or
knowledge, skills, and abilities of each team member, but autonomoussystems.Akeyaspectofhuman-AIinteractionsis
SIML tools enable non-traditional, flexible team roles and the formation of a shared mental model, suggesting that traits
configurations [71]. Machine intelligence will be better suited such as empathy, theory of mind, or emotional intelligencemightallowahumantobeflexibleinhisorhermentalmodel Robust planning in complex and dynamic environments
of the AI agent. Selection and understanding of these traits requiresmodelingandaccountingforuncertainty,whichalong
inhumanpartnerscouldthenadvantageouslyremedyinherent with confidence ratings by which AI systems convey their de-
AI bias, provide over-correction in training data, or result in gree of certainty, are shown to increase trust between humans
moreflexiblementalmodelsthataremoreresilienttochanges and AI [91]. Existing machine learning techniques that track
in AI systems. Emerging work with human-AI teams in code andpropagateuncertaintyestimatesareeithercomputationally
translation tasks suggests human teammates can overcome intractable for complex problems [92] or account only for
limitations in AI capabilities by successfully performing tasks model uncertainty [93].
withimperfectAI[76].Similarly,understandingandreasoning Open problems in this area include developing SIML that
over quantified uncertainty is a human skill that can be accounts for uncertainty in current and future states without
improved,insomecontexts,withdeliberatepractice[77],[78]. becoming computationally intractable under high complexity
SIML systems will differ in their sophistication and abil- and conveying complex, probabilistic forecasts to humans in
ity to be used effectively amongst the general population. a way that supports calibrated trust. Recent progress has been
Research is needed to identify characteristics of optimal made in conveying such uncertainty to people [94], [95] in
human partners and compatibility with AI; such work will relatively simple contexts, but new approaches will be needed
aid in alignment of roles and configurations to result in the for complex, high-dimensional, and long-horizon planning
best performance outcomes to develop robust, ethical human- tasks accounting for environmental variables and potential
AI partnerships [79]. While work is ongoing to define and risks and points of failure. Research in these areas will help
modelAItechnologicalfluency[80],theremightbeadditional to create AI tools for C2 systems that effectively quantify and
predictors of successful human-AI partnering that go beyond convey uncertainty information across the operational space.
more general use of AI. Compositionality is a concept related Just as a human teammate might be required to provide
to fluid intelligence that explains cognitive flexibility as the supporting reasoning and evidence for a recommendation,
ability to tackle complex tasks by combining simpler cogni- machineswillneedtoprovideexplanationstoensureashared
tive operations. Seeking this ability in both human and AI understanding of the costs and benefits of a particular rec-
teammates could serve as a foundation for successful human- ommendation. Explainable systems [96] may help humans
AI partnerships [81]. Given AI capabilities and vulnerabilities to build calibrated trust [91], [97] in the AI system, but
change rapidly, and these changes are likely to accelerate, explanations that are not well suited to the task or context
human ability to promptly identify and adapt to changing mightlead tomiscalibrated trust[98], [99].While muchwork
operational characteristics may be paramount [82]. on explainable AI focuses on supervised learning tasks, there
Open questions in this area include better understanding isalsoagrowingbodyofworkonexplainabilityinsequential
what human characteristics are relevant to successful interac- decision-making paradigms such as RL [100], for instance
tion with SIML systems; how best to develop a workforce that seeks explanations for individual action choices, learned
with those characteristics, be it through selection, education, reinforcement structures, or the learned policy. Miller [101]
training, or other approaches; and how to make sure humans argues that AI must leverage humans’ mental models of the
are able to keep up with the rapidly changing AI landscape. world to generate effective explanations.
Addressing these questions would potentially enable a greater While AI methods for decision-making, such as RL, can
population to effectively modify and guide AI systems, and quickly explore many decision sequences, the resulting poli-
ensure humans thrive as members of human-AI teams. cies—which convert observations to actions—can be difficult
to explain or justify to humans [100]. Yet, while RL methods
can train a policy—i.e., a function that maps observations to
C. Communication through Explainable AI and Shared Men-
recommended actions—RL policies are typically black-box
tal Models
functions that are unintuitive for humans to interpret [100].
Decades of human-automation research suggest that levels Algorithms for making policies more intuitive and self-
of autonomy [83]–[85], situational awareness [86], trans- explanatory would help humans to understand AI recommen-
parency [87], and/or explainability [88] can all greatly impact dations.However,thetaskofconvertinganoptimizedRLpol-
humanperformancewhenpartneringwithanAIorautomated icy to one or more human-understandable action trajectories
system. While we typically aim for human-AI partnerships remains an open problem.
to be more effective than humans or AI alone, communi- Further research should develop methods that leverage a
cation [79] and development of a shared mental model are policy to predict how current and future actions will unfold,
important for humans to accurately predict AI behavior [89] as has been demonstrated in simple domains with human
and behaviors of other humans; these enable humans to make feedback [102], [103]; such projections should be accompa-
decisions while maintaining calibrated trust to exert timely niedbyuncertaintyestimatesandsuccessprobabilities.Further
control over either good or poor AI performance. Calibrated research should not only extend such methods to function in
trust results in minimizing distrust that can lead to errors, complex and dynamic environments, but should also develop
disuse, and over-reliance [90], while reducing over-trust that methods that convert policies to explainable plans, e.g. via
can lead to miscalculations in risk. language,annotatedmaps,ortreesofpotentialoutcomes.SuchmethodscouldleveragegenerativeAItoolssuchasLLMsand speed and accuracy) [112], these methods apply to limited
image generation models [7], [63], [104], [105] and combine settings that are significantly simpler than C2 scenarios. Fur-
machine learning methods for sequential planning (e.g., RL) thermore,theyoftenutilizenohumaninteraction[107],[109],
withgenerativeAI[29]toconveyinformationtohumanusers. [110], [112], or at most a single human interaction modal-
In the Army, such research would enable an AI-based COA ity [108], [111], and often only employ the budget constraint
tool to communicate recommendations such as AI-generated to determine when to halt algorithm execution [107]–[109].
COAs to personnel in intuitive formats such as language and Further research should develop human-AI interaction meth-
annotated maps [101], [106] and support the maintenance of ods that can flexibly scale to a range of temporal constraints,
a COP to improve decision quality. for instance determining the best allocation of human and
computational resources and the optimal human interaction
IV. INTERACTIVEMACHINELEARNINGFORFLEXIBLE
approach under the available time.
ANDSCALABLEDECISION-MAKING
B. Scalability across the Numbers of Human and AI Agents
To deploy human-AI interaction systems not only in sim-
ulations and simplified exercises, but also in real-world C2, Human-AI integration techniques must also scale to chang-
AI algorithms will need to scale flexibly and robustly in ing numbers of human and AI agents in the system. They
responsetoa varietyofdynamicfactors. Thissectionoutlines should be capable of integrating feedback from many people,
four problem domains in which flexible scalability will be while remaining effective when only a few people—or even
critical and discusses open research opportunities in each. just a single person—are available to interact or provide
Addressingthesegapswillbekeytoenablingscalablehuman- feedback. Existing AI approaches for integrating feedback
AI partnerships that can learn and plan in complex and across multiple people typically assume that all human data
dynamic environments, as are prevalent in C2. is provided upfront (rather than given interactively) [30]–
[33], [35] and do not consider sequential decision-making
A. Temporal Scalability tasks [30]–[33]. In contrast, future work should develop
Algorithms for human-AI interaction must function decision-making methods that are flexible given shifts in the
smoothly across both longer and shorter decision-making numbers and expertise of accessible humans, including in
timescales. This is important for C2 applications, since de- dynamicscenarios,tomaximizehumanresourceswhilefilling
pending on circumstances, the available decision-making time in when people become unavailable. In C2 scenarios, such
could vary from minutes or hours to days, while possi- approaches would integrate feedback from many battlefield
bly respecting further constraints such as the 1/3-2/3 rule7. assets and C2 personnel, while remaining robust when only
Algorithms should adapt their behavior given the amount few C2 personnel are present, seamlessly adapting based on
of available time, e.g. by intelligently trading off between the specific roles and functions of available staff.
factors such as solution optimality, the number of explored In addition, decision-making algorithms must scale to ro-
decision alternatives, and a temporal budget. Furthermore, bustly direct either many or few AI agents. Existing algo-
temporal budgets could in turn constrain resources such as rithms for multi-agent learning and planning often become
computationaltimeandhumantimespentinteractingwiththe computationally intractable as the number of AI agents in-
AI.Suchtrade-offscouldaffectAIbehaviorinmanyways,for creases [113]–[116], or cannot adapt if AI agents are dynam-
instancebyinformingthenumberofAI-generatedalternatives ically added to or removed from the system. We envision
(e.g.COAs)showntoC2personnel,thenumberofsimulations improved algorithms for human-AI integration that scale to
or wargames in which these alternatives are evaluated (e.g. plan over many (hundreds or more) forces and assets on
COA analysis), the choice of which alternatives to present the battlefield, while also reliably generating plans when
to personnel (e.g. COAs with more predictable outcomes vs. comparativelyfewassetsarepresent,orwhenassetavailability
high-risk,high-rewardalternatives),andthechosenmodalities shifts in real-time.
of human-AI interaction (e.g. querying personnel for detailed
C. Scalability across Hierarchical Structures
feedback vs. a simple COA selection among presented alter-
natives). To tackle sophisticated problem scenarios such as arise in
While some existing AI decision-making methods consider C2,weforeseehuman-AIpartnershipsthatareorganizedhier-
a query budget that limits algorithm exploration [107]–[109], archically, with structured human-AI interactions occurring at
consider the time required to process input features [110], multiplehierarchicallevels.AsdiscussedinSectionII-C,such
trade off between speed and accuracy in streaming classifica- hierarchicalorganizationcanfacilitatetaskdecompositionand
tiontasks[111],oruseatemporalbudgettoinformthefidelity AI agent specialization to optimally leverage both human
atwhichtorunsimulations(i.e.,balancingbetweensimulation and AI capabilities and promote efficient solutions. While
SectionII-CoverviewssomepriorworkonAIalgorithmsthat
7From U.S. Army Doctrine Publication 5.0, “The Operations Process”: operateontwo-levelhierarchies,tothebestofourknowledge,
“Commanders follow the ‘one-third, two-thirds rule’ as a guide to allocate therearefewapproachesthatconsiderhierarchiesofmorethan
timeavailable.Theyuseone-thirdofthetimeavailablebeforeexecutionfor
two levels [36] and none that consider human-AI interaction
theirownplanningandallocatetheremainingtwo-thirdsofthetimeavailable
beforeexecutiontotheirsubordinatesforplanningandpreparation”[9]. atmultiplehierarchicallevels(evenforatwo-levelhierarchy).Further research should develop hierarchical algorithms for difficult to execute, this research focus area is critical to the
human-AI interaction that can flexibly scale across different transition of such SIML-enabled systems to real-world C2
hierarchicalorganizations,e.g.withvaryingnumbersofhierar- contexts.
chical levels and extending to tree-like hierarchical structures.
In the C2 space, such algorithms will promote robust human- ACKNOWLEDGEMENTS
AIinteractionacrossthedifferentmulti-echelonorganizational
The authors would like to acknowledge Lee Venison from
structuresthatalreadyexistintheArmy,assistingeachechelon
the Apex Analytics Group and the Mission Command Battle
and unit individually while maintaining unity of effort.
LabatFortLeavenworth,Kansas,fortheirinsightfulfeedback
and discussion when refining the concepts proposed in this
D. Scalability across Problem Spheres
report.
In complex domains such as C2, learning and planning
algorithmsshouldidentifythesphere(orscope)oftheproblem REFERENCES
that is most crucial for effective decision-making, and then
autonomouslyadaptdecision-makingtothekeyfactorswithin [1] Headquarters, Department of the Army, Army Field Manual 6-0:
CommanderandStaffOrganizationandOperations,2022.
thissphere.Forinstance,suchacapabilitycouldhelptofocus
[2] Headquarters, Department of the Army, Army Doctrine Publication
algorithmic planning for C2 on the most relevant geographic 6-0,MissionCommand:CommandandControlofArmyForces,2019.
regions; perhaps, for the current operation, activity in the [3] C. Thompson, “Clive Thompson on the cyborg advantage.” Wired.
https://www.wired.com/2010/03/st-thompson-cyborgs/, 2010. Ac-
east must be estimated more accurately than activity in the
cessed:2023-08-28.
west,whileforadifferentoperation,activitymustbeprecisely [4] N. Csomay-Shanklin, M. Tucker, M. Dai, J. Reher, and A. D. Ames,
estimatedoveralargerregionofthebattlefield.Meanwhile,AI “Learning controller gains on bipedal walking robots via user prefer-
ences,”in2022InternationalConferenceonRoboticsandAutomation
planningshouldalsoscaleitsfocustoconcentrateonthemost
(ICRA),pp.10405–10411,IEEE,2022.
relevant warfighting functions; for example, perhaps for the [5] M. Tucker, N. Csomay-Shanklin, W.-L. Ma, and A. D. Ames,
current mission, fires must be estimated more accurately than “Preference-based learning for user-guided HZD gait generation on
bipedal walking robots,” in 2021 IEEE International Conference on
sustainment.Algorithmsthatcanleveragepreviousexperience
RoboticsandAutomation(ICRA),pp.2804–2810,IEEE,2021.
and human interaction to scale their attention to a problem’s [6] D. Wang, A. Khosla, R. Gargeya, H. Irshad, and A. H. Beck,
most critical aspects would facilitate improved utilization “Deeplearningforidentifyingmetastaticbreastcancer,”arXivpreprint
arXiv:1606.05718,2016.
of temporal and computational resources under constrained
[7] O. Blog, “Introducing ChatGPT,” Internet:
conditions. Currently, we are not aware of any existing work https://openai.com/blog/chatgpt,2022.
in either human-AI integration or AI for sequential decision- [8] J.S.Metcalfe,B.S.Perelman,D.L.Boothe,andK.Mcdowell,“Sys-
temicoversimplificationlimitsthepotentialforhuman-AIpartnership,”
makingthatfacilitatessuchscalabilityacrossproblemspheres,
IEEEAccess,vol.9,pp.70242–70260,2021.
and more work is needed to develop the envisioned capabili- [9] Headquarters, Department of the Army, Army Doctrine Publication
ties. 5-0:TheOperationsProcess,2019.
[10] Headquarters, Department of the Army, Army Field Manual 5-0:
V. DISCUSSION PlanningandOrdersProduction,2022.
[11] M. Farmer, “Four-dimensional planning at the speed of relevance:
An SIML-enabled C2 system has the potential to revolu- Artificial-intelligence-enabledmilitarydecision-makingprocess,”Mil-
itaryReview,pp.64–73,Nov-Dec2022.
tionize C2 personnel effectiveness and efficiency to achieve
[12] B.D.Argall,S.Chernova,M.Veloso,andB.Browning,“Asurveyof
decision advantage over peer and near-peer adversaries. Yet, robotlearningfromdemonstration,”Roboticsandautonomoussystems,
additional research is needed to develop the SIML science vol.57,no.5,pp.469–483,2009.
and technology capabilities necessary for interactive machine [13] V. G. Goecks, G. M. Gremillion, V. J. Lawhern, J. Valasek, and
N. R. Waytowich, “Efficiently combining human demonstrations and
learning approaches to be practical and robust in the C2
interventionsforsafetrainingofautonomoussystemsinreal-time,”in
domain. Here, we proposed and described three critical re- ProceedingsoftheAAAIconferenceonartificialintelligence,vol.33,
search focus areas for enabling SIML systems for C2. Firstly, pp.2462–2470,2019.
[14] P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and
successful SIML relies on leveraging human-AI interactions
D. Amodei, “Deep reinforcement learning from human preferences,”
within decision-support tools for planning to achieve effective Advancesinneuralinformationprocessingsystems,vol.30,2017.
decision-making. Research in this area is needed to address [15] K.Lee,L.M.Smith,andP.Abbeel,“PEBBLE:Feedback-efficientin-
teractivereinforcementlearningviarelabelingexperienceandunsuper-
how multiple humans and multiple agents can collaborate
visedpre-training,”inInternationalConferenceonMachineLearning,
together via a variety of interaction modalities and across pp.6152–6163,PMLR,2021.
hierarchical levels. Secondly, while the current MDMP is [16] V. G. Goecks and N. R. Waytowich, “DisasterResponseGPT: Large
languagemodelsforacceleratedplanofactiondevelopmentindisaster
a fundamentally human endeavor, an SIML-enabled MDMP
response scenarios,” in Workshop on Challenges in Deployable Gen-
must consider human roles in addition to AI roles and overall erativeAIatInternationalConferenceonMachineLearning(ICML),
team configurations. Future research should aim to better un- 2023.
[17] P. Sharma, B. Sundaralingam, V. Blukis, C. Paxton, T. Hermans,
derstandhowtooptimizeteamperformancethroughselection,
A. Torralba, J. Andreas, and D. Fox, “Correcting robot plans with
training, and role assignment. Thirdly, advances in human- naturallanguagefeedback,”arXivpreprintarXiv:2204.05186,2022.
AI integration and resilient teaming will only be meaningful [18] N. Stiennon, L. Ouyang, J. Wu, D. Ziegler, R. Lowe, C. Voss,
A.Radford,D.Amodei,andP.F.Christiano,“Learningtosummarize
for C2 situations if they are flexible and scalable to a broad
with human feedback,” Advances in Neural Information Processing
rangeofpotentialoperationalcontexts.Whileperhapsthemost Systems,vol.33,pp.3008–3021,2020.[19] M. Matta, G. C. Cardarilli, L. Di Nunzio, R. Fazzolari, D. Giardino, [41] A. S. Vezhnevets, S. Osindero, T. Schaul, N. Heess, M. Jaderberg,
M. Re, F. Silvestri, and S. Spano`, “Q-RTS: a real-time swarm intel- D.Silver,andK.Kavukcuoglu,“Feudalnetworksforhierarchicalrein-
ligencebasedonmulti-agentq-learning,”ElectronicsLetters,vol.55, forcementlearning,”inInternationalConferenceonMachineLearning,
no.10,pp.589–591,2019. pp.3540–3549,PMLR,2017.
[20] W. Zhang, X. Wang, J. Shen, and M. Zhou, “Model-based multi- [42] S. Sukhbaatar, E. Denton, A. Szlam, and R. Fergus, “Learning goal
agent policy optimization with adaptive opponent-wise rollouts,” in embeddings via self-play for hierarchical reinforcement learning,”
InternationalJointConferenceonArtificialIntelligence,2021. arXivpreprintarXiv:1811.09083,2018.
[21] R. Wang, J. C. Kew, D. Lee, T.-W. Lee, T. Zhang, B. Ichter, J. Tan, [43] K.Frans,J.Ho,X.Chen,P.Abbeel,andJ.Schulman,“Metalearning
and A. Faust, “Model-based reinforcement learning for decentralized sharedhierarchies,”arXivpreprintarXiv:1710.09767,2017.
multiagent rendezvous,” in Conference on Robot Learning, pp. 711– [44] P.-L.Bacon,J.Harb,andD.Precup,“Theoption-criticarchitecture,”in
725,PMLR,2021. ProceedingsoftheAAAIconferenceonartificialintelligence,vol.31,
[22] I.Elleuch,A.Pourranjbar,andG.Kaddoum,“Anoveldistributedmulti- 2017.
agentreinforcementlearningalgorithmagainstjammingattacks,”IEEE [45] C. Tessler, S. Givony, T. Zahavy, D. Mankowitz, and S. Mannor,
CommunicationsLetters,vol.25,no.10,pp.3204–3208,2021. “A deep hierarchical approach to lifelong learning in Minecraft,” in
[23] O.Vinyals,I.Babuschkin,W.M.Czarnecki,M.Mathieu,A.Dudzik, ProceedingsoftheAAAIconferenceonartificialintelligence,vol.31,
J. Chung, D. H. Choi, R. Powell, T. Ewalds, P. Georgiev, et al., 2017.
“Grandmaster level in StarCraft II using multi-agent reinforcement [46] O.Nachum,S.S.Gu,H.Lee,andS.Levine,“Data-efficienthierarchi-
learning,”Nature,vol.575,no.7782,pp.350–354,2019. calreinforcementlearning,”Advancesinneuralinformationprocessing
[24] S. A. Wu, R. E. Wang, J. A. Evans, J. B. Tenenbaum, D. C. Parkes, systems,vol.31,2018.
and M. Kleiman-Weiner, “Too many cooks: Bayesian inference for [47] A. Brohan, Y. Chebotar, C. Finn, K. Hausman, A. Herzog, D. Ho,
coordinating multi-agent collaboration,” Topics in Cognitive Science, J.Ibarz,A.Irpan,E.Jang,R.Julian,etal.,“DoasIcan,notasIsay:
vol.13,no.2,pp.414–432,2021. Grounding language in robotic affordances,” in Conference on Robot
[25] J.Fu,A.Tacchetti,J.Perolat,andY.Bachrach,“Evaluatingstrategic Learning,pp.287–318,PMLR,2023.
structures in multi-agent inverse reinforcement learning,” Journal of [48] D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter,
ArtificialIntelligenceResearch,vol.71,pp.925–951,2021. A.Wahid,J.Tompson,Q.Vuong,T.Yu,etal.,“PaLM-E:Anembodied
[26] H. M. Le, Y. Yue, P. Carr, and P. Lucey, “Coordinated multi-agent multimodallanguagemodel,”inInternationalConferenceonMachine
imitationlearning,”inInternationalConferenceonMachineLearning, Learning(ICML),2023.
pp.1995–2003,PMLR,2017. [49] G. Wang, Y. Xie, Y. Jiang, A. Mandlekar, C. Xiao, Y. Zhu, L. Fan,
[27] J. Song, H. Ren, D. Sadigh, and S. Ermon, “Multi-agent generative and A. Anandkumar, “Voyager: An open-ended embodied agent with
adversarial imitation learning,” Advances in neural information pro- largelanguagemodels,”arXivpreprintarXiv:2305.16291,2023.
cessingsystems,vol.31,2018. [50] C. Gebhardt, A. Oulasvirta, and O. Hilliges, “Hierarchical reinforce-
[28] L. Yu, J. Song, and S. Ermon, “Multi-agent adversarial inverse rein- mentlearningasamodelofhumantaskinterleaving,”Computational
forcementlearning,”inInternationalConferenceonMachineLearning, BrainandBehavior,2021.
pp.7194–7201,PMLR,2019. [51] R. Pinsler, R. Akrour, T. Osa, J. Peters, and G. Neumann, “Sample
[29] A. Bakhtin, N. Brown, E. Dinan, G. Farina, C. Flaherty, D. Fried, andfeedbackefficienthierarchicalreinforcementlearningfromhuman
A. Goff, J. Gray, H. Hu, et al., “Human-level play in the game of preferences,”in2018IEEEInternationalConferenceonRoboticsand
diplomacy by combining language models with strategic reasoning,” Automation(ICRA),pp.596–601,2018.
Science,vol.378,no.6624,pp.1067–1074,2022. [52] N. Bougie and R. Ichise, “Hierarchical learning from human prefer-
[30] F.Parisi,F.Strino,B.Nadler,andY.Kluger,“Rankingandcombining encesandcuriosity,”AppliedIntelligence,pp.1–21,2022.
multiplepredictorswithoutlabeleddata,”ProceedingsoftheNational [53] J. Gehring, G. Synnaeve, A. Krause, and N. Usunier, “Hierarchical
AcademyofSciences,vol.111,no.4,pp.1253–1258,2014. skills for efficient exploration,” Advances in Neural Information Pro-
[31] Y. Sakata, Y. Baba, and H. Kashima, “Crownn: Human-in-the-loop cessingSystems,vol.34,pp.11553–11564,2021.
network with crowd-generated inputs,” in ICASSP 2019-2019 IEEE [54] X.Wang,K.Lee,K.Hakhamaneshi,P.Abbeel,andM.Laskin,“Skill
InternationalConferenceonAcoustics,SpeechandSignalProcessing preferences:Learningtoextractandexecuteroboticskillsfromhuman
(ICASSP),pp.7555–7559,IEEE,2019. feedback,”inConferenceonRobotLearning,pp.1259–1268,PMLR,
[32] Y.Zhang,X.Chen,D.Zhou,andM.I.Jordan,“Spectralmethodsmeet 2022.
EM: A provably optimal algorithm for crowdsourcing,” Advances in [55] P. C. Heredia and S. Mou, “Distributed multi-agent reinforcement
neuralinformationprocessingsystems,vol.27,2014. learningbyactor-criticmethod,”InternationalFederationofAutomatic
[33] N. B. Shah, S. Balakrishnan, and M. J. Wainwright, “A permutation- Control,vol.52,no.20,pp.363–368,2019.
based model for crowd labeling: Optimal estimation and robustness,” [56] K. Zhang, Z. Yang, and T. Bas¸ar, “Decentralized multi-agent rein-
IEEE Transactions on Information Theory, vol. 67, no. 6, pp. 4162– forcementlearningwithnetworkedagents:Recentadvances,”Frontiers
4184,2020. of Information Technology & Electronic Engineering, vol. 22, no. 6,
[34] G. Zhang and H. Kashima, “Batch reinforcement learning from pp.802–814,2021.
crowds,” in Joint European Conference on Machine Learning and [57] W. Kim, J. Park, and Y. Sung, “Communication in multi-agent rein-
KnowledgeDiscoveryinDatabases,pp.38–51,Springer,2022. forcementlearning:Intentionsharing,”inInternationalConferenceon
[35] M.Beliaev,A.Shih,S.Ermon,D.Sadigh,andR.Pedarsani,“Imitation LearningRepresentations,2020.
learning by estimating expertise of demonstrators,” in International [58] K.Kondo,J.Tordesillas,R.Figueroa,J.Rached,J.Merkel,P.C.Lusk,
ConferenceonMachineLearning,pp.1732–1748,PMLR,2022. and J. P. How, “Robust MADER: Decentralized and asynchronous
[36] P.DayanandG.E.Hinton,“Feudalreinforcementlearning,”Advances multiagenttrajectoryplannerrobusttocommunicationdelay,”in2023
inneuralinformationprocessingsystems,vol.5,1992. IEEE International Conference on Robotics and Automation (ICRA),
[37] R. Parr and S. Russell, “Reinforcement learning with hierarchies of pp.1687–1693,IEEE,2023.
machines,”Advancesinneuralinformationprocessingsystems,vol.10, [59] H.-T.Wai,Z.Yang,Z.Wang,andM.Hong,“Multi-agentreinforcement
1997. learningviadoubleaveragingprimal-dualoptimization,”Advancesin
[38] A.Pashevich,D.Hafner,J.Davidson,R.R.Sukthankar,andC.Schmid, NeuralInformationProcessingSystems,vol.31,2018.
“Modulatedpolicyhierarchies,”inDeepReinforcementLearningWork- [60] R. Raileanu, E. Denton, A. Szlam, and R. Fergus, “Modeling others
shopatNeurIPS2018,2018. using oneself in multi-agent reinforcement learning,” in International
[39] T.G.Dietterich,“HierarchicalreinforcementlearningwiththeMAXQ conferenceonmachinelearning,pp.4257–4266,PMLR,2018.
value function decomposition,” Journal of artificial intelligence re- [61] S. V. Albrecht and P. Stone, “Autonomous agents modelling other
search,vol.13,pp.227–303,2000. agents: A comprehensive survey and open problems,” Artificial Intel-
[40] T.D.Kulkarni,K.Narasimhan,A.Saeedi,andJ.Tenenbaum,“Hier- ligence,vol.258,pp.66–95,2018.
archicaldeepreinforcementlearning:Integratingtemporalabstraction [62] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
and intrinsic motivation,” Advances in neural information processing Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,”
systems,vol.29,2016. Advancesinneuralinformationprocessingsystems,vol.30,2017.[63] J.D.Kenton,M.-W.Chang,andL.K.Toutanova,“BERT:Pre-training rep., Technical Report ARL-TR-9432. US Combat Capabilities De-
of deep bidirectional transformers for language understanding,” in velopment Command, Army Research Laboratory, Aberdeen Proving
Proceedings of the 2019 Conference of the North American Chapter GroundUnitedStates,2022.
of the Association for Computational Linguistics: Human Language [83] M. R. Endsley and D. B. Kaber, “Level of automation effects on
Technologies,vol.1,p.2,2019. performance, situation awareness and workload in a dynamic control
[64] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, task,”Ergonomics,vol.42,no.3,pp.462–492,1999.
Y.Zhou,W.Li,andP.J.Liu,“Exploringthelimitsoftransferlearn- [84] R.Parasuraman,T.B.Sheridan,andC.D.Wickens,“Amodelfortypes
ing with a unified text-to-text transformer,” The Journal of Machine andlevelsofhumaninteractionwithautomation,”IEEETransactions
LearningResearch,vol.21,no.1,pp.5485–5551,2020. onsystems,man,andcybernetics-PartA:SystemsandHumans,vol.30,
[65] T.Brown,B.Mann,N.Ryder,M.Subbiah,J.D.Kaplan,P.Dhariwal, no.3,pp.286–297,2000.
A.Neelakantan,P.Shyam,G.Sastry,A.Askell,etal.,“Languagemod- [85] N. L. Tenhundfeld, E. J. De Visser, K. S. Haring, A. J. Ries, V. S.
elsarefew-shotlearners,”Advancesinneuralinformationprocessing Finomore,andC.C.Tossell,“Calibratingtrustinautomationthrough
systems,vol.33,pp.1877–1901,2020. familiaritywiththeautoparkingfeatureofaTeslaModelX,”Journal
[66] T. Le Scao and A. M. Rush, “How many data points is a prompt ofcognitiveengineeringanddecisionmaking,vol.13,no.4,pp.279–
worth?,”inProceedingsofthe2021ConferenceoftheNorthAmerican 294,2019.
Chapter of the Association for Computational Linguistics: Human [86] C.D.Wickens,“Situationawareness:Impactofautomationanddisplay
LanguageTechnologies,pp.2627–2636,2021. technology,”Situationawareness:Limitationsandenhancementinthe
[67] S.Min,X.Lyu,A.Holtzman,M.Artetxe,M.Lewis,H.Hajishirzi,and aviationenvironment,p.k2,1996.
L. Zettlemoyer, “Rethinking the role of demonstrations: What makes [87] J. Y. Chen and M. J. Barnes, “Agent transparency for human-agent
in-contextlearningwork?,”arXivpreprintarXiv:2202.12837,2022. teaming effectiveness,” in 2015 IEEE International Conference on
[68] S. M. Xie, A. Raghunathan, P. Liang, and T. Ma, “An explanation Systems,Man,andCybernetics,pp.1381–1385,2015.
ofin-contextlearningasimplicitBayesianinference,”inInternational [88] A. B. Arrieta, N. D´ıaz-Rodr´ıguez, J. Del Ser, A. Bennetot, S. Tabik,
ConferenceonLearningRepresentations,2021. A.Barbado,S.Garc´ıa,S.Gil-Lo´pez,D.Molina,R.Benjamins,etal.,
[69] J.Luketina,N.Nardelli,G.Farquhar,J.Foerster,J.Andreas,E.Grefen- “Explainable artificial intelligence (XAI): Concepts, taxonomies, op-
stette, S. Whiteson, and T. Rockta¨schel, “A survey of reinforcement portunitiesandchallengestowardresponsibleAI,”Informationfusion,
learninginformedbynaturallanguage,”inProceedingsoftheTwenty- vol.58,pp.82–115,2020.
EighthInternationalJointConferenceonArtificialIntelligence,IJCAI [89] R.W.Andrews,J.M.Lilly,D.Srivastava,andK.M.Feigh,“Therole
2019, August 10-16 2019, Macao, China., vol. 57, pp. 6309–6317, of shared mental models in human-AI teams: a theoretical review,”
AAAI Press (Association for the Advancement of Artificial Intelli- TheoreticalIssuesinErgonomicsScience,vol.24,no.2,pp.129–175,
gence),2019. 2023.
[70] Y.Du,O.Watkins,Z.Wang,C.Colas,T.Darrell,P.Abbeel,A.Gupta, [90] C.D.Wickens,B.A.Clegg,A.Z.Vieane,andA.L.Sebok,“Compla-
and J. Andreas, “Guiding pretraining in reinforcement learning with cencyandautomationbiasintheuseofimperfectautomation,”Human
large language models,” in International Conference on Machine factors,vol.57,no.5,pp.728–739,2015.
Learning(ICML),2023. [91] Y. Zhang, Q. V. Liao, and R. K. Bellamy, “Effect of confidence and
[71] S.D.Ramchurn,S.Stein,andN.R.Jennings,“Trustworthyhuman-AI explanation on accuracy and trust calibration in AI-assisted decision
partnerships,”Iscience,vol.24,no.8,2021. making,”inProceedingsofthe2020conferenceonfairness,account-
[72] L. Onnasch and E. Roesler, “A taxonomy to structure and analyze ability,andtransparency,pp.295–305,2020.
human–robot interaction,” International Journal of Social Robotics, [92] Z. Ghahramani, “Probabilistic machine learning and artificial intelli-
vol.13,no.4,pp.833–849,2021. gence,”Nature,vol.521,no.7553,pp.452–459,2015.
[73] D. Siemon, “Elaborating team roles for artificial intelligence-based [93] Y. Gal and Z. Ghahramani, “Dropout as a Bayesian approximation:
teammates in human-AI collaboration,” Group Decision and Negoti- Representing model uncertainty in deep learning,” in International
ation,vol.31,no.5,pp.871–912,2022. ConferenceonMachineLearning,pp.1050–1059,PMLR,2016.
[74] S.D.Ramchurn,T.D.Huynh,F.Wu,Y.Ikuno,J.Flann,L.Moreau, [94] L.Padilla,S.C.Castro,andH.Hosseinpour,“Areviewofuncertainty
J.E.Fischer,W.Jiang,T.Rodden,E.Simpson,etal.,“Adisasterre- visualizationerrors:Workingmemoryasanexplanatorytheory,”Psy-
sponsesystembasedonhuman-agentcollectives,”JournalofArtificial chologyofLearningandMotivation,vol.74,pp.275–315,2021.
IntelligenceResearch,vol.57,pp.661–708,2016. [95] A.Kale,F.Nguyen,M.Kay,andJ.Hullman,“Hypotheticaloutcome
[75] K.A.HoffandM.Bashir,“Trustinautomation:Integratingempirical plotshelpuntrainedobserversjudgetrendsinambiguousdata,”IEEE
evidenceonfactorsthatinfluencetrust,”Humanfactors,vol.57,no.3, transactions on visualization and computer graphics, vol. 25, no. 1,
pp.407–434,2015. pp.892–902,2018.
[76] J.D.Weisz,M.Muller,S.Houde,J.Richards,S.I.Ross,F.Martinez, [96] R.Confalonieri,L.Coba,B.Wagner,andT.R.Besold,“Ahistorical
M.Agarwal,andK.Talamadupula,“Perfectionnotrequired?Human- perspective of explainable artificial intelligence,” Wiley Interdisci-
AIpartnershipsincodetranslation,”in26thInternationalConference plinaryReviews:DataMiningandKnowledgeDiscovery,vol.11,no.1,
onIntelligentUserInterfaces,pp.402–412,2021. p.e1391,2021.
[77] S. A. Kusumastuti, K. A. Pollard, A. H. Oiknine, B. Dalangin, T. R. [97] J. Cha, M. Barnes, and J. Y. Chen, “Visualization techniques for
Raber, and B. T. Files, “Practice improves performance of a 2D transparent human-agent interface designs,” tech. rep., Technical Re-
uncertainty integration task within and across visualizations,” IEEE portARL-TR-8674).USCombatCapabilitiesDevelopmentCommand
TransactionsonVisualizationandComputerGraphics,2022. Army Research Laboratory Aberdeen Proving Ground United States,
[78] M.Kay,T.Kola,J.R.Hullman,andS.A.Munson,“When(ish)ismy 2019.
bus? User-centered visualizations of uncertainty in everyday, mobile [98] G.Bansal,T.Wu,J.Zhou,R.Fok,B.Nushi,E.Kamar,M.T.Ribeiro,
predictive systems,” in Proceedings of the 2016 CHI conference on and D. Weld, “Does the whole exceed its parts? the effect of AI
humanfactorsincomputingsystems,pp.5092–5103,2016. explanationsoncomplementaryteamperformance,”inProceedingsof
[79] N. J. McNeese, B. G. Schelble, L. B. Canonico, and M. Demir, the 2021 CHI Conference on Human Factors in Computing Systems,
“Who/what is my teammate? Team composition considerations in pp.1–16,2021.
human-AIteaming,”IEEETransactionson Human-MachineSystems, [99] H. Vasconcelos, M. Jo¨rke, M. Grunde-McLaughlin, T. Gerstenberg,
vol.51,no.4,pp.288–299,2021. M.S.Bernstein,andR.Krishna,“Explanationscanreduceoverreliance
[80] S.Campbell,R.Nguyen,E.Bonsignore,B.Carter,andC.Neubauer, on AI systems during decision-making,” Proceedings of the ACM on
“DefiningandmodelingAItechnicalfluencyforeffectivehumanma- Human-ComputerInteraction,vol.7,no.CSCW1,pp.1–38,2023.
chineinteraction,”inHumanFactorsinRobots,DronesandUnmanned [100] S.Milani,N.Topin,M.Veloso,andF.Fang,“Asurveyofexplainable
Systems,AHFEInternational,2023. reinforcementlearning,”arXivpreprintarXiv:2202.08434,2022.
[81] J.Duncan,D.Chylinski,D.J.Mitchell,andA.Bhandari,“Complexity [101] T.Miller,“Explanationinartificialintelligence:Insightsfromthesocial
andcompositionalityinfluidintelligence,”ProceedingsoftheNational sciences,”Artificialintelligence,vol.267,pp.1–38,2019.
AcademyofScience,vol.114,no.20,pp.5295–5299,2017. [102] S. Reddy, A. Dragan, S. Levine, S. Legg, and J. Leike, “Learning
[82] K.A. Pollard,B. T.Files,A. H.Oiknine,and B.Dalangin, “Howto humanobjectivesbyevaluatinghypotheticalbehavior,”inInternational
prepareforrapidlyevolvingtechnology:Focusonadaptability,”tech. ConferenceonMachineLearning,pp.8020–8029,PMLR,2020.[103] Y.Liu,G.Datta,E.Novoseller,andD.S.Brown,“Efficientpreference-
basedreinforcementlearningusinglearneddynamicsmodels,”in2023
InternationalConferenceonRoboticsandAutomation(ICRA),2023.
[104] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz,
E. Kamar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg, et al., “Sparks of
artificial general intelligence: Early experiments with GPT-4,” arXiv
preprintarXiv:2303.12712,2023.
[105] G. Marcus, E. Davis, and S. Aaronson, “A very preliminary analysis
ofDALL-E2,”arXivpreprintarXiv:2204.13807,2022.
[106] D.Gunning,E.Vorm,J.Y.Wang,andM.Turek,“DARPA’sexplainable
AI(XAI)program:Aretrospective,”2021.
[107] M.E.Taylor,N.Carboni,A.Fachantidis,I.Vlahavas,andL.Torrey,
“Reinforcement learning agents providing advice in complex video
games,”ConnectionScience,vol.26,no.1,pp.45–63,2014.
[108] M. Samadi, P. Talukdar, M. Veloso, and T. Mitchell, “AskWorld:
Budget-sensitive query evaluation for knowledge-on-demand,” in
Twenty-FourthInternationalJointConferenceonArtificialIntelligence,
2015.
[109] E. Ilhan, J. Gow, and D. Perez-Liebana, “Teaching on a budget in
multi-agent deep reinforcement learning,” in 2019 IEEE Conference
onGames(CoG),pp.1–8,IEEE,2019.
[110] Z.Xu,K.Q.Weinberger,andO.Chapelle,“Thegreedymiser:Learning
undertest-timebudgets,”inProceedingsofthe29thInternationalCon-
ferenceonInternationalConferenceonMachineLearning,pp.1299–
1306,2012.
[111] S. Basu, S. Gutstein, B. Lance, and S. Shakkottai, “Pareto optimal
streamingunsupervisedclassification,”inInternationalConferenceon
MachineLearning,pp.505–514,PMLR,2019.
[112] J.Song,Y.Chen,andY.Yue,“Ageneralframeworkformulti-fidelity
BayesianoptimizationwithGaussianprocesses,”inThe22ndInterna-
tional Conference on Artificial Intelligence and Statistics, pp. 3158–
3167,PMLR,2019.
[113] D. Reifsteck, T. Engesser, R. Mattmu¨ller, and B. Nebel, “Epistemic
multi-agent planning using Monte-Carlo tree search,” in KI 2019:
Advances in Artificial Intelligence: 42nd German Conference on AI,
Kassel, Germany, September 23–26, 2019, Proceedings 42, pp. 277–
289,Springer,2019.
[114] O.Kaduri,E.Boyarski,andR.Stern,“Algorithmselectionforoptimal
multi-agent pathfinding,” in Proceedings of the International Confer-
ence on Automated Planning and Scheduling, vol. 30, pp. 161–165,
2020.
[115] K.Kasaura,M.Nishimura,andR.Yonetani,“Prioritizedsafeinterval
path planning for multi-agent pathfinding with continuous time on
2D roadmaps,” IEEE Robotics and Automation Letters, vol. 7, no. 4,
pp.10494–10501,2022.
[116] A.Wong,T.Ba¨ck,A.V.Kononova,andA.Plaat,“Deepmultiagentre-
inforcementlearning:Challengesanddirections,”ArtificialIntelligence
Review,vol.56,no.6,pp.5023–5056,2023.