[
    {
        "title": "Feedback Loops With Language Models Drive In-Context Reward Hacking",
        "authors": "Alexander PanErik JonesMeena JagadeesanJacob Steinhardt",
        "links": "http://arxiv.org/abs/2402.06627v1",
        "entry_id": "http://arxiv.org/abs/2402.06627v1",
        "pdf_url": "http://arxiv.org/pdf/2402.06627v1",
        "summary": "Language models influence the external world: they query APIs that read and\nwrite to web pages, generate content that shapes human behavior, and run system\ncommands as autonomous agents. These interactions form feedback loops: LLM\noutputs affect the world, which in turn affect subsequent LLM outputs. In this\nwork, we show that feedback loops can cause in-context reward hacking (ICRH),\nwhere the LLM at test-time optimizes a (potentially implicit) objective but\ncreates negative side effects in the process. For example, consider an LLM\nagent deployed to increase Twitter engagement; the LLM may retrieve its\nprevious tweets into the context window and make them more controversial,\nincreasing engagement but also toxicity. We identify and study two processes\nthat lead to ICRH: output-refinement and policy-refinement. For these\nprocesses, evaluations on static datasets are insufficient -- they miss the\nfeedback effects and thus cannot capture the most harmful behavior. In\nresponse, we provide three recommendations for evaluation to capture more\ninstances of ICRH. As AI development accelerates, the effects of feedback loops\nwill proliferate, increasing the need to understand their role in shaping LLM\nbehavior.",
        "updated": "2024-02-09 18:59:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.06627v1"
    },
    {
        "title": "Understanding the Effects of Iterative Prompting on Truthfulness",
        "authors": "Satyapriya KrishnaChirag AgarwalHimabindu Lakkaraju",
        "links": "http://arxiv.org/abs/2402.06625v1",
        "entry_id": "http://arxiv.org/abs/2402.06625v1",
        "pdf_url": "http://arxiv.org/pdf/2402.06625v1",
        "summary": "The development of Large Language Models (LLMs) has notably transformed\nnumerous sectors, offering impressive text generation capabilities. Yet, the\nreliability and truthfulness of these models remain pressing concerns. To this\nend, we investigate iterative prompting, a strategy hypothesized to refine LLM\nresponses, assessing its impact on LLM truthfulness, an area which has not been\nthoroughly explored. Our extensive experiments delve into the intricacies of\niterative prompting variants, examining their influence on the accuracy and\ncalibration of model responses. Our findings reveal that naive prompting\nmethods significantly undermine truthfulness, leading to exacerbated\ncalibration errors. In response to these challenges, we introduce several\nprompting variants designed to address the identified issues. These variants\ndemonstrate marked improvements over existing baselines, signaling a promising\ndirection for future research. Our work provides a nuanced understanding of\niterative prompting and introduces novel approaches to enhance the truthfulness\nof LLMs, thereby contributing to the development of more accurate and\ntrustworthy AI systems.",
        "updated": "2024-02-09 18:57:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.06625v1"
    },
    {
        "title": "Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning",
        "authors": "Shivalika SinghFreddie VargusDaniel DsouzaBörje F. KarlssonAbinaya MahendiranWei-Yin KoHerumb ShandilyaJay PatelDeividas MataciunasLaura OMahonyMike ZhangRamith HettiarachchiJoseph WilsonMarina MachadoLuisa Souza MouraDominik KrzemińskiHakimeh FadaeiIrem ErgünIfeoma OkohAisha AlaagibOshan MudannayakeZaid AlyafeaiVu Minh ChienSebastian RuderSurya GuthikondaEmad A. AlghamdiSebastian GehrmannNiklas MuennighoffMax BartoloJulia KreutzerAhmet ÜstünMarzieh FadaeeSara Hooker",
        "links": "http://arxiv.org/abs/2402.06619v1",
        "entry_id": "http://arxiv.org/abs/2402.06619v1",
        "pdf_url": "http://arxiv.org/pdf/2402.06619v1",
        "summary": "Datasets are foundational to many breakthroughs in modern artificial\nintelligence. Many recent achievements in the space of natural language\nprocessing (NLP) can be attributed to the finetuning of pre-trained models on a\ndiverse set of tasks that enables a large language model (LLM) to respond to\ninstructions. Instruction fine-tuning (IFT) requires specifically constructed\nand annotated datasets. However, existing datasets are almost all in the\nEnglish language. In this work, our primary goal is to bridge the language gap\nby building a human-curated instruction-following dataset spanning 65\nlanguages. We worked with fluent speakers of languages from around the world to\ncollect natural instances of instructions and completions. Furthermore, we\ncreate the most extensive multilingual collection to date, comprising 513\nmillion instances through templating and translating existing datasets across\n114 languages. In total, we contribute four key resources: we develop and\nopen-source the Aya Annotation Platform, the Aya Dataset, the Aya Collection,\nand the Aya Evaluation Suite. The Aya initiative also serves as a valuable case\nstudy in participatory research, involving collaborators from 119 countries. We\nsee this as a valuable framework for future research collaborations that aim to\nbridge gaps in resources.",
        "updated": "2024-02-09 18:51:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.06619v1"
    },
    {
        "title": "FaBERT: Pre-training BERT on Persian Blogs",
        "authors": "Mostafa MasumiSeyed Soroush MajdMehrnoush ShamsfardHamid Beigy",
        "links": "http://arxiv.org/abs/2402.06617v1",
        "entry_id": "http://arxiv.org/abs/2402.06617v1",
        "pdf_url": "http://arxiv.org/pdf/2402.06617v1",
        "summary": "We introduce FaBERT, a Persian BERT-base model pre-trained on the HmBlogs\ncorpus, encompassing both informal and formal Persian texts. FaBERT is designed\nto excel in traditional Natural Language Understanding (NLU) tasks, addressing\nthe intricacies of diverse sentence structures and linguistic styles prevalent\nin the Persian language. In our comprehensive evaluation of FaBERT on 12\ndatasets in various downstream tasks, encompassing Sentiment Analysis (SA),\nNamed Entity Recognition (NER), Natural Language Inference (NLI), Question\nAnswering (QA), and Question Paraphrasing (QP), it consistently demonstrated\nimproved performance, all achieved within a compact model size. The findings\nhighlight the importance of utilizing diverse and cleaned corpora, such as\nHmBlogs, to enhance the performance of language models like BERT in Persian\nNatural Language Processing (NLP) applications. FaBERT is openly accessible at\nhttps://huggingface.co/sbunlp/fabert",
        "updated": "2024-02-09 18:50:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.06617v1"
    },
    {
        "title": "TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations",
        "authors": "Sudhir AgarwalAnu Sreepathy",
        "links": "http://arxiv.org/abs/2402.06608v1",
        "entry_id": "http://arxiv.org/abs/2402.06608v1",
        "pdf_url": "http://arxiv.org/pdf/2402.06608v1",
        "summary": "We study the problem of generating plans for given natural language planning\ntask requests. On one hand, LLMs excel at natural language processing but do\nnot perform well on planning. On the other hand, classical planning tools excel\nat planning tasks but require input in a structured language such as the\nPlanning Domain Definition Language (PDDL). We leverage the strengths of both\nthe techniques by using an LLM for generating the PDDL representation (task\nPDDL) of planning task requests followed by using a classical planner for\ncomputing a plan. Unlike previous approaches that use LLMs for generating task\nPDDLs directly, our approach comprises of (a) translate: using an LLM only for\ngenerating a logically interpretable intermediate representation of natural\nlanguage task descriptions, (b) infer: deriving additional logically dependent\ninformation from the intermediate representation using a logic reasoner\n(currently, Answer Set Programming solver), and (c) compile: generating the\ntarget task PDDL from the base and inferred information. We observe that using\nan LLM to only output the intermediate representation significantly reduces LLM\nerrors. Consequently, TIC approach achieves, for at least one LLM, high\naccuracy on task PDDL generation for all seven domains of our evaluation\ndataset.",
        "updated": "2024-02-09 18:39:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.06608v1"
    }
]