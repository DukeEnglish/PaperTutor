[
    {
        "title": "SAMF: Small-Area-Aware Multi-focus Image Fusion for Object Detection",
        "authors": "Xilai LiXiaosong LiHaishu TanJinyang Li",
        "links": "http://arxiv.org/abs/2401.08357v1",
        "entry_id": "http://arxiv.org/abs/2401.08357v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08357v1",
        "summary": "Existing multi-focus image fusion (MFIF) methods often fail to preserve the\nuncertain transition region and detect small focus areas within large defocused\nregions accurately. To address this issue, this study proposes a new\nsmall-area-aware MFIF algorithm for enhancing object detection capability.\nFirst, we enhance the pixel attributes within the small focus and boundary\nregions, which are subsequently combined with visual saliency detection to\nobtain the pre-fusion results used to discriminate the distribution of focused\npixels. To accurately ensure pixel focus, we consider the source image as a\ncombination of focused, defocused, and uncertain regions and propose a\nthree-region segmentation strategy. Finally, we design an effective pixel\nselection rule to generate segmentation decision maps and obtain the final\nfusion results. Experiments demonstrated that the proposed method can\naccurately detect small and smooth focus areas while improving object detection\nperformance, outperforming existing methods in both subjective and objective\nevaluations. The source code is available at https://github.com/ixilai/SAMF.",
        "updated": "2024-01-16 13:35:28 UTC",
        "id": 1
    },
    {
        "title": "Multi-view Distillation based on Multi-modal Fusion for Few-shot Action Recognition(CLIP-$\\mathrm{M^2}$DF)",
        "authors": "Fei GuoYiKang WangHan QiWenPing JinLi Zhu",
        "links": "http://arxiv.org/abs/2401.08345v1",
        "entry_id": "http://arxiv.org/abs/2401.08345v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08345v1",
        "summary": "In recent years, few-shot action recognition has attracted increasing\nattention. It generally adopts the paradigm of meta-learning. In this field,\novercoming the overlapping distribution of classes and outliers is still a\nchallenging problem based on limited samples. We believe the combination of\nMulti-modal and Multi-view can improve this issue depending on information\ncomplementarity. Therefore, we propose a method of Multi-view Distillation\nbased on Multi-modal Fusion. Firstly, a Probability Prompt Selector for the\nquery is constructed to generate probability prompt embedding based on the\ncomparison score between the prompt embeddings of the support and the visual\nembedding of the query. Secondly, we establish a Multi-view. In each view, we\nfuse the prompt embedding as consistent information with visual and the global\nor local temporal context to overcome the overlapping distribution of classes\nand outliers. Thirdly, we perform the distance fusion for the Multi-view and\nthe mutual distillation of matching ability from one to another, enabling the\nmodel to be more robust to the distribution bias. Our code is available at the\nURL: \\url{https://github.com/cofly2014/MDMF}.",
        "updated": "2024-01-16 13:23:51 UTC",
        "id": 2
    },
    {
        "title": "Generative Denoise Distillation: Simple Stochastic Noises Induce Efficient Knowledge Transfer for Dense Prediction",
        "authors": "Zhaoge LiuXiaohao XuYunkang CaoWeiming Shen",
        "links": "http://arxiv.org/abs/2401.08332v2",
        "entry_id": "http://arxiv.org/abs/2401.08332v2",
        "pdf_url": "http://arxiv.org/pdf/2401.08332v2",
        "summary": "Knowledge distillation is the process of transferring knowledge from a more\npowerful large model (teacher) to a simpler counterpart (student). Numerous\ncurrent approaches involve the student imitating the knowledge of the teacher\ndirectly. However, redundancy still exists in the learned representations\nthrough these prevalent methods, which tend to learn each spatial location's\nfeatures indiscriminately. To derive a more compact representation (concept\nfeature) from the teacher, inspired by human cognition, we suggest an\ninnovative method, termed Generative Denoise Distillation (GDD), where\nstochastic noises are added to the concept feature of the student to embed them\ninto the generated instance feature from a shallow network. Then, the generated\ninstance feature is aligned with the knowledge of the instance from the\nteacher. We extensively experiment with object detection, instance\nsegmentation, and semantic segmentation to demonstrate the versatility and\neffectiveness of our method. Notably, GDD achieves new state-of-the-art\nperformance in the tasks mentioned above. We have achieved substantial\nimprovements in semantic segmentation by enhancing PspNet and DeepLabV3, both\nof which are based on ResNet-18, resulting in mIoU scores of 74.67 and 77.69,\nrespectively, surpassing their previous scores of 69.85 and 73.20 on the\nCityscapes dataset of 20 categories. The source code is available at\nhttps://github.com/ZhgLiu/GDD.",
        "updated": "2024-01-17 07:18:11 UTC",
        "id": 3
    },
    {
        "title": "Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation",
        "authors": "Devavrat TomarGuillaume VrayJean-Philippe ThiranBehzad Bozorgtabar",
        "links": "http://arxiv.org/abs/2401.08328v1",
        "entry_id": "http://arxiv.org/abs/2401.08328v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08328v1",
        "summary": "In an era where test-time adaptation methods increasingly rely on the nuanced\nmanipulation of batch normalization (BN) parameters, one critical assumption\noften goes overlooked: that of independently and identically distributed\n(i.i.d.) test batches with respect to unknown labels. This assumption\nculminates in biased estimates of BN statistics and jeopardizes system\nstability under non-i.i.d. conditions. This paper pioneers a departure from the\ni.i.d. paradigm by introducing a groundbreaking strategy termed \"Un-Mixing\nTest-Time Normalization Statistics\" (UnMix-TNS). UnMix-TNS re-calibrates the\ninstance-wise statistics used to normalize each instance in a batch by mixing\nit with multiple unmixed statistics components, thus inherently simulating the\ni.i.d. environment. The key lies in our innovative online unmixing procedure,\nwhich persistently refines these statistics components by drawing upon the\nclosest instances from an incoming test batch. Remarkably generic in its\ndesign, UnMix-TNS seamlessly integrates with an array of state-of-the-art\ntest-time adaptation methods and pre-trained architectures equipped with BN\nlayers. Empirical evaluations corroborate the robustness of UnMix-TNS under\nvaried scenarios ranging from single to continual and mixed domain shifts.\nUnMix-TNS stands out when handling test data streams with temporal correlation,\nincluding those with corrupted real-world non-i.i.d. streams, sustaining its\nefficacy even with minimal batch sizes and individual samples. Our results set\na new standard for test-time adaptation, demonstrating significant improvements\nin both stability and performance across multiple benchmarks.",
        "updated": "2024-01-16 12:48:52 UTC",
        "id": 4
    },
    {
        "title": "The Faiss library",
        "authors": "Matthijs DouzeAlexandr GuzhvaChengqi DengJeff JohnsonGergely SzilvasyPierre-Emmanuel MazaréMaria LomeliLucas HosseiniHervé Jégou",
        "links": "http://arxiv.org/abs/2401.08281v1",
        "entry_id": "http://arxiv.org/abs/2401.08281v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08281v1",
        "summary": "Vector databases manage large collections of embedding vectors. As AI\napplications are growing rapidly, so are the number of embeddings that need to\nbe stored and indexed. The Faiss library is dedicated to vector similarity\nsearch, a core functionality of vector databases. Faiss is a toolkit of\nindexing methods and related primitives used to search, cluster, compress and\ntransform vectors. This paper first describes the tradeoff space of vector\nsearch, then the design principles of Faiss in terms of structure, approach to\noptimization and interfacing. We benchmark key features of the library and\ndiscuss a few selected applications to highlight its broad applicability.",
        "updated": "2024-01-16 11:12:36 UTC",
        "id": 5
    }
]