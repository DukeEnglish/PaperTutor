[
    {
        "title": "Sparse PCA with False Discovery Rate Controlled Variable Selection",
        "authors": "Jasin MachkourArnaud BreloyMichael MumaDaniel P. PalomarFrédéric Pascal",
        "links": "http://arxiv.org/abs/2401.08375v1",
        "entry_id": "http://arxiv.org/abs/2401.08375v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08375v1",
        "summary": "Sparse principal component analysis (PCA) aims at mapping large dimensional\ndata to a linear subspace of lower dimension. By imposing loading vectors to be\nsparse, it performs the double duty of dimension reduction and variable\nselection. Sparse PCA algorithms are usually expressed as a trade-off between\nexplained variance and sparsity of the loading vectors (i.e., number of\nselected variables). As a high explained variance is not necessarily synonymous\nwith relevant information, these methods are prone to select irrelevant\nvariables. To overcome this issue, we propose an alternative formulation of\nsparse PCA driven by the false discovery rate (FDR). We then leverage the\nTerminating-Random Experiments (T-Rex) selector to automatically determine an\nFDR-controlled support of the loading vectors. A major advantage of the\nresulting T-Rex PCA is that no sparsity parameter tuning is required. Numerical\nexperiments and a stock market data example demonstrate a significant\nperformance improvement.",
        "updated": "2024-01-16 14:07:36 UTC",
        "id": 1
    },
    {
        "title": "Causal Machine Learning for Moderation Effects",
        "authors": "Nora BearthMichael Lechner",
        "links": "http://arxiv.org/abs/2401.08290v1",
        "entry_id": "http://arxiv.org/abs/2401.08290v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08290v1",
        "summary": "It is valuable for any decision maker to know the impact of decisions\n(treatments) on average and for subgroups. The causal machine learning\nliterature has recently provided tools for estimating group average treatment\neffects (GATE) to understand treatment heterogeneity better. This paper\naddresses the challenge of interpreting such differences in treatment effects\nbetween groups while accounting for variations in other covariates. We propose\na new parameter, the balanced group average treatment effect (BGATE), which\nmeasures a GATE with a specific distribution of a priori-determined covariates.\nBy taking the difference of two BGATEs, we can analyse heterogeneity more\nmeaningfully than by comparing two GATEs. The estimation strategy for this\nparameter is based on double/debiased machine learning for discrete treatments\nin an unconfoundedness setting, and the estimator is shown to be\n$\\sqrt{N}$-consistent and asymptotically normal under standard conditions.\nAdding additional identifying assumptions allows specific balanced differences\nin treatment effects between groups to be interpreted causally, leading to the\ncausal balanced group average treatment effect. We explore the finite sample\nproperties in a small-scale simulation study and demonstrate the usefulness of\nthese parameters in an empirical example.",
        "updated": "2024-01-16 11:34:59 UTC",
        "id": 2
    },
    {
        "title": "Statistical Test for Attention Map in Vision Transformer",
        "authors": "Tomohiro ShiraishiDaiki MiwaTeruyuki KatsuokaVo Nguyen Le DuyKoichi TajiIchiro Takeuchi",
        "links": "http://arxiv.org/abs/2401.08169v1",
        "entry_id": "http://arxiv.org/abs/2401.08169v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08169v1",
        "summary": "The Vision Transformer (ViT) demonstrates exceptional performance in various\ncomputer vision tasks. Attention is crucial for ViT to capture complex\nwide-ranging relationships among image patches, allowing the model to weigh the\nimportance of image patches and aiding our understanding of the decision-making\nprocess. However, when utilizing the attention of ViT as evidence in\nhigh-stakes decision-making tasks such as medical diagnostics, a challenge\narises due to the potential of attention mechanisms erroneously focusing on\nirrelevant regions. In this study, we propose a statistical test for ViT's\nattentions, enabling us to use the attentions as reliable quantitative evidence\nindicators for ViT's decision-making with a rigorously controlled error rate.\nUsing the framework called selective inference, we quantify the statistical\nsignificance of attentions in the form of p-values, which enables the\ntheoretically grounded quantification of the false positive detection\nprobability of attentions. We demonstrate the validity and the effectiveness of\nthe proposed method through numerical experiments and applications to brain\nimage diagnoses.",
        "updated": "2024-01-16 07:18:47 UTC",
        "id": 3
    },
    {
        "title": "Fundamental limits of community detection from multi-view data: multi-layer, dynamic and partially labeled block models",
        "authors": "Xiaodong YangBuyu LinSubhabrata Sen",
        "links": "http://arxiv.org/abs/2401.08167v1",
        "entry_id": "http://arxiv.org/abs/2401.08167v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08167v1",
        "summary": "Multi-view data arises frequently in modern network analysis e.g. relations\nof multiple types among individuals in social network analysis, longitudinal\nmeasurements of interactions among observational units, annotated networks with\nnoisy partial labeling of vertices etc. We study community detection in these\ndisparate settings via a unified theoretical framework, and investigate the\nfundamental thresholds for community recovery. We characterize the mutual\ninformation between the data and the latent parameters, provided the degrees\nare sufficiently large. Based on this general result, (i) we derive a sharp\nthreshold for community detection in an inhomogeneous multilayer block model\n\\citep{chen2022global}, (ii) characterize a sharp threshold for weak recovery\nin a dynamic stochastic block model \\citep{matias2017statistical}, and (iii)\nidentify the limiting mutual information in an unbalanced partially labeled\nblock model. Our first two results are derived modulo coordinate-wise convexity\nassumptions on specific functions -- we provide extensive numerical evidence\nfor their correctness. Finally, we introduce iterative algorithms based on\nApproximate Message Passing for community detection in these problems.",
        "updated": "2024-01-16 07:13:32 UTC",
        "id": 4
    },
    {
        "title": "Differentially Private Sliced Inverse Regression: Minimax Optimality and Algorithm",
        "authors": "Xintao XiaLinjun ZhangZhanrui Cai",
        "links": "http://arxiv.org/abs/2401.08150v1",
        "entry_id": "http://arxiv.org/abs/2401.08150v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08150v1",
        "summary": "Privacy preservation has become a critical concern in high-dimensional data\nanalysis due to the growing prevalence of data-driven applications. Proposed by\nLi (1991), sliced inverse regression has emerged as a widely utilized\nstatistical technique for reducing covariate dimensionality while maintaining\nsufficient statistical information. In this paper, we propose optimally\ndifferentially private algorithms specifically designed to address privacy\nconcerns in the context of sufficient dimension reduction. We proceed to\nestablish lower bounds for differentially private sliced inverse regression in\nboth the low and high-dimensional settings. Moreover, we develop differentially\nprivate algorithms that achieve the minimax lower bounds up to logarithmic\nfactors. Through a combination of simulations and real data analysis, we\nillustrate the efficacy of these differentially private algorithms in\nsafeguarding privacy while preserving vital information within the reduced\ndimension space. As a natural extension, we can readily offer analogous lower\nand upper bounds for differentially private sparse principal component\nanalysis, a topic that may also be of potential interest to the statistical and\nmachine learning community.",
        "updated": "2024-01-16 06:47:43 UTC",
        "id": 5
    }
]