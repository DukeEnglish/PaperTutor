[
    {
        "title": "Cross-lingual neural fuzzy matching for exploiting target-language monolingual corpora in computer-aided translation",
        "authors": "Miquel Esplà-GomisVíctor M. Sánchez-CartagenaJuan Antonio Pérez-OrtizFelipe Sánchez-Martínez",
        "links": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.511",
        "entry_id": "http://arxiv.org/abs/2401.08374v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08374v1",
        "summary": "Computer-aided translation (CAT) tools based on translation memories (MT)\nplay a prominent role in the translation workflow of professional translators.\nHowever, the reduced availability of in-domain TMs, as compared to in-domain\nmonolingual corpora, limits its adoption for a number of translation tasks. In\nthis paper, we introduce a novel neural approach aimed at overcoming this\nlimitation by exploiting not only TMs, but also in-domain target-language (TL)\nmonolingual corpora, and still enabling a similar functionality to that offered\nby conventional TM-based CAT tools. Our approach relies on cross-lingual\nsentence embeddings to retrieve translation proposals from TL monolingual\ncorpora, and on a neural model to estimate their post-editing effort. The paper\npresents an automatic evaluation of these techniques on four language pairs\nthat shows that our approach can successfully exploit monolingual texts in a\nTM-based CAT environment, increasing the amount of useful translation\nproposals, and that our neural model for estimating the post-editing effort\nenables the combination of translation proposals obtained from monolingual\ncorpora and from TMs in the usual way. A human evaluation performed on a single\nlanguage pair confirms the results of the automatic evaluation and seems to\nindicate that the translation proposals retrieved with our approach are more\nuseful than what the automatic evaluation shows.",
        "updated": "2024-01-16 14:00:28 UTC",
        "id": 1
    },
    {
        "title": "Morphology and Syntax of the Tamil Language",
        "authors": "Kengatharaiyer Sarveswaran",
        "links": "http://arxiv.org/abs/2401.08367v1",
        "entry_id": "http://arxiv.org/abs/2401.08367v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08367v1",
        "summary": "This paper provides an overview of the morphology and syntax of the Tamil\nlanguage, focusing on its contemporary usage. The paper also highlights the\ncomplexity and richness of Tamil in terms of its morphological and syntactic\nfeatures, which will be useful for linguists analysing the language and\nconducting comparative studies. In addition, the paper will be useful for those\ndeveloping computational resources for the Tamil language. It is proven as a\nrule-based morphological analyser cum generator and a computational grammar for\nTamil have already been developed based on this paper. To enhance accessibility\nfor a broader audience, the analysis is conducted without relying on any\nspecific grammatical formalism.",
        "updated": "2024-01-16 13:52:25 UTC",
        "id": 2
    },
    {
        "title": "Hallucination Detection and Hallucination Mitigation: An Investigation",
        "authors": "Junliang LuoTianyu LiDi WuMichael JenkinSteve LiuGregory Dudek",
        "links": "http://arxiv.org/abs/2401.08358v1",
        "entry_id": "http://arxiv.org/abs/2401.08358v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08358v1",
        "summary": "Large language models (LLMs), including ChatGPT, Bard, and Llama, have\nachieved remarkable successes over the last two years in a range of different\napplications. In spite of these successes, there exist concerns that limit the\nwide application of LLMs. A key problem is the problem of hallucination.\nHallucination refers to the fact that in addition to correct responses, LLMs\ncan also generate seemingly correct but factually incorrect responses. This\nreport aims to present a comprehensive review of the current literature on both\nhallucination detection and hallucination mitigation. We hope that this report\ncan serve as a good reference for both engineers and researchers who are\ninterested in LLMs and applying them to real world tasks.",
        "updated": "2024-01-16 13:36:07 UTC",
        "id": 3
    },
    {
        "title": "Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models",
        "authors": "Jianhui PangFanghua YeLongyue WangDian YuDerek F. WongShuming ShiZhaopeng Tu",
        "links": "http://arxiv.org/abs/2401.08350v2",
        "entry_id": "http://arxiv.org/abs/2401.08350v2",
        "pdf_url": "http://arxiv.org/pdf/2401.08350v2",
        "summary": "The evolution of Neural Machine Translation (NMT) has been significantly\ninfluenced by six core challenges (Koehn and Knowles, 2017), which have acted\nas benchmarks for progress in this field. This study revisits these challenges,\noffering insights into their ongoing relevance in the context of advanced Large\nLanguage Models (LLMs): domain mismatch, amount of parallel data, rare word\nprediction, translation of long sentences, attention model as word alignment,\nand sub-optimal beam search. Our empirical findings indicate that LLMs\neffectively lessen the reliance on parallel data for major languages in the\npretraining phase. Additionally, the LLM-based translation system significantly\nenhances the translation of long sentences that contain approximately 80 words\nand shows the capability to translate documents of up to 512 words. However,\ndespite these significant improvements, the challenges of domain mismatch and\nprediction of rare words persist. While the challenges of word alignment and\nbeam search, specifically associated with NMT, may not apply to LLMs, we\nidentify three new challenges for LLMs in translation tasks: inference\nefficiency, translation of low-resource languages in the pretraining phase, and\nhuman-aligned evaluation. The datasets and models are released at\nhttps://github.com/pangjh3/LLM4MT.",
        "updated": "2024-01-17 06:47:29 UTC",
        "id": 4
    },
    {
        "title": "RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning",
        "authors": "Junjie YeYilong WuSongyang GaoSixian LiGuanyu LiXiaoran FanQi ZhangTao GuiXuanjing Huang",
        "links": "http://arxiv.org/abs/2401.08326v1",
        "entry_id": "http://arxiv.org/abs/2401.08326v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08326v1",
        "summary": "Tool learning has generated widespread interest as a vital means of\ninteraction between Large Language Models (LLMs) and the physical world.\nCurrent research predominantly emphasizes LLMs' capacity to utilize tools in\nwell-structured environments while overlooking their stability when confronted\nwith the inevitable noise of the real world. To bridge this gap, we introduce\nRoTBench, a multi-level benchmark for evaluating the robustness of LLMs in tool\nlearning. Specifically, we establish five external environments, each featuring\nvarying levels of noise (i.e., Clean, Slight, Medium, Heavy, and Union),\nproviding an in-depth analysis of the model's resilience across three critical\nphases: tool selection, parameter identification, and content filling.\nExperiments involving six widely-used models underscore the urgent necessity\nfor enhancing the robustness of LLMs in tool learning. For instance, the\nperformance of GPT-4 even drops significantly from 80.00 to 58.10 when there is\nno substantial change in manual accuracy. More surprisingly, the noise\ncorrection capability inherent in the GPT family paradoxically impedes its\nadaptability in the face of mild noise. In light of these findings, we propose\nRoTTuning, a strategy that enriches the diversity of training environments to\nbolster the robustness of LLMs in tool learning. The code and data are\navailable at https://github.com/Junjie-Ye/RoTBench.",
        "updated": "2024-01-16 12:45:15 UTC",
        "id": 5
    }
]