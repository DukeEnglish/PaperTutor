[
    {
        "title": "Interrogating AI: Characterizing Emergent Playful Interactions with ChatGPT",
        "authors": "Mohammad Ronagh NikghalbJinghui Cheng",
        "links": "http://arxiv.org/abs/2401.08405v1",
        "entry_id": "http://arxiv.org/abs/2401.08405v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08405v1",
        "summary": "In an era of AI's growing capabilities and influences, recent advancements\nare reshaping HCI and CSCW's view of AI as mere tools. Playful interactions\nwith AI systems naturally emerged as a way for users to make sense of the\never-changing technology. However, these emergent and playful interactions are\nunderexamined. We target this gap by investigating playful interactions\nexhibited by users of a recently trending powerful AI technology, ChatGPT.\nThrough a thematic analysis of 372 user-generated posts on the ChatGPT\nsubreddit, we found that a substantial portion of user discourse revolves\naround playful interactions. The analysis further allowed us to construct a\npreliminary taxonomy to describe these interactions, categorizing them into six\ntypes: reflecting, jesting, imitating, challenging, tricking, and contriving;\neach included sub-categories. Overall, this study contributes to the field of\nHCI and CSCW by illuminating the multifaceted nature of playful interactions\nwith AI, underlining their significance in shaping the human-AI relationship.",
        "updated": "2024-01-16 14:44:13 UTC",
        "id": 1
    },
    {
        "title": "Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine",
        "authors": "Qiao JinFangyuan ChenYiliang ZhouZiyang XuJustin M. CheungRobert ChenRonald M. SummersJustin F. RousseauPeiyun NiMarc J LandsmanSally L. BaxterSubhi J. Al'ArefYijia LiMichael F. ChiangYifan PengZhiyong Lu",
        "links": "http://arxiv.org/abs/2401.08396v1",
        "entry_id": "http://arxiv.org/abs/2401.08396v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08396v1",
        "summary": "Recent studies indicate that Generative Pre-trained Transformer 4 with Vision\n(GPT-4V) outperforms human physicians in medical challenge tasks. However,\nthese evaluations primarily focused on the accuracy of multi-choice questions\nalone. Our study extends the current scope by conducting a comprehensive\nanalysis of GPT-4V's rationales of image comprehension, recall of medical\nknowledge, and step-by-step multimodal reasoning when solving New England\nJournal of Medicine (NEJM) Image Challenges - an imaging quiz designed to test\nthe knowledge and diagnostic capabilities of medical professionals. Evaluation\nresults confirmed that GPT-4V outperforms human physicians regarding\nmulti-choice accuracy (88.0% vs. 77.0%, p=0.034). GPT-4V also performs well in\ncases where physicians incorrectly answer, with over 80% accuracy. However, we\ndiscovered that GPT-4V frequently presents flawed rationales in cases where it\nmakes the correct final choices (27.3%), most prominent in image comprehension\n(21.6%). Regardless of GPT-4V's high accuracy in multi-choice questions, our\nfindings emphasize the necessity for further in-depth evaluations of its\nrationales before integrating such models into clinical workflows.",
        "updated": "2024-01-16 14:41:20 UTC",
        "id": 2
    },
    {
        "title": "A Micro Architectural Events Aware Real-Time Embedded System Fault Injector",
        "authors": "Enrico MaglianoAlessio CarpegnaAlessadro SavinoStefano Di Carlo",
        "links": "http://arxiv.org/abs/2401.08397v1",
        "entry_id": "http://arxiv.org/abs/2401.08397v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08397v1",
        "summary": "In contemporary times, the increasing complexity of the system poses\nsignificant challenges to the reliability, trustworthiness, and security of the\nSACRES. Key issues include the susceptibility to phenomena such as\ninstantaneous voltage spikes, electromagnetic interference, neutron strikes,\nand out-of-range temperatures. These factors can induce switch state changes in\ntransistors, resulting in bit-flipping, soft errors, and transient corruption\nof stored data in memory. The occurrence of soft errors, in turn, may lead to\nsystem faults that can propel the system into a hazardous state. Particularly\nin critical sectors like automotive, avionics, or aerospace, such malfunctions\ncan have real-world implications, potentially causing harm to individuals.\n  This paper introduces a novel fault injector designed to facilitate the\nmonitoring, aggregation, and examination of micro-architectural events. This is\nachieved by harnessing the microprocessor's PMU and the debugging interface,\nspecifically focusing on ensuring the repeatability of fault injections. The\nfault injection methodology targets bit-flipping within the memory system,\naffecting CPU registers and RAM. The outcomes of these fault injections enable\na thorough analysis of the impact of soft errors and establish a robust\ncorrelation between the identified faults and the essential timing\npredictability demanded by SACRES.",
        "updated": "2024-01-16 14:41:20 UTC",
        "id": 3
    },
    {
        "title": "Deep Learning-based Group Causal Inference in Multivariate Time-series",
        "authors": "Wasim AhmadMaha ShadaydehJoachim Denzler",
        "links": "http://arxiv.org/abs/2401.08386v1",
        "entry_id": "http://arxiv.org/abs/2401.08386v1",
        "pdf_url": "http://arxiv.org/pdf/2401.08386v1",
        "summary": "Causal inference in a nonlinear system of multivariate timeseries is\ninstrumental in disentangling the intricate web of relationships among\nvariables, enabling us to make more accurate predictions and gain deeper\ninsights into real-world complex systems. Causality methods typically identify\nthe causal structure of a multivariate system by considering the cause-effect\nrelationship of each pair of variables while ignoring the collective effect of\na group of variables or interactions involving more than two-time series\nvariables. In this work, we test model invariance by group-level interventions\non the trained deep networks to infer causal direction in groups of variables,\nsuch as climate and ecosystem, brain networks, etc. Extensive testing with\nsynthetic and real-world time series data shows a significant improvement of\nour method over other applied group causality methods and provides us insights\ninto real-world time series. The code for our method can be found\nat:https://github.com/wasimahmadpk/gCause.",
        "updated": "2024-01-16 14:19:28 UTC",
        "id": 4
    },
    {
        "title": "Exploiting Inter-Layer Expert Affinity for Accelerating Mixture-of-Experts Model Inference",
        "authors": "Jinghan YaoQuentin AnthonyAamir ShafiHari SubramoniDhabaleswar K.Panda",
        "links": "http://arxiv.org/abs/2401.08383v2",
        "entry_id": "http://arxiv.org/abs/2401.08383v2",
        "pdf_url": "http://arxiv.org/pdf/2401.08383v2",
        "summary": "In large language models like the Generative Pre-trained Transformer, the\nMixture of Experts paradigm has emerged as a powerful technique for enhancing\nmodel expressiveness and accuracy. However, deploying GPT MoE models for\nparallel inference on distributed systems presents significant challenges,\nprimarily due to the extensive Alltoall communication required for expert\nrouting and aggregation. This communication bottleneck exacerbates the already\ncomplex computational landscape, hindering the efficient utilization of\nhigh-performance computing resources. In this paper, we propose a lightweight\noptimization technique called ExFlow, to largely accelerate the inference of\nthese MoE models. We take a new perspective on alleviating the communication\noverhead by exploiting the inter-layer expert affinity. Unlike previous\nmethods, our solution can be directly applied to pre-trained MoE models without\nany fine-tuning or accuracy degradation. By proposing a context-coherent expert\nparallelism on distributed systems, our design only uses one Alltoall\ncommunication to deliver the same functionality while previous methods all\nrequire two Alltoalls. By carefully examining the conditional probability in\ntokens' routing across multiple layers, we proved that pre-trained GPT MoE\nmodels implicitly exhibit a strong inter-layer expert affinity. We then design\nan efficient integer programming model to capture such features and show that\nby properly placing the experts on corresponding GPUs, we can reduce up to 67%\ncross-GPU routing latency. Our solution beats the cutting-edge MoE\nimplementations with experts from 8 to 64, with up to 2.2x improvement in\ninference throughput. We further provide a detailed study of how the model\nimplicitly acquires this expert affinity at the very early training stage and\nhow this affinity evolves and stabilizes during training.",
        "updated": "2024-01-17 03:37:00 UTC",
        "id": 5
    }
]