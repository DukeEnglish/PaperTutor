Preprint. Underreview.
ON THE EFFECTIVENESS OF DATASET ALIGNMENT
FOR FAKE IMAGE DETECTION
AnirudhSundaraRajan* UtkarshOjha* JedidiahSchloesser YongJaeLee
UniversityofWisconsin-Madison
ABSTRACT
As latent diffusion models (LDMs) democratize image generation capabilities,
there is a growing need to detect fake images. A good detector should focus on
the generative model’s fingerprints while ignoring image properties such as se-
manticcontent,resolution,fileformat,etc. Fakeimagedetectorsareusuallybuilt
in a data-driven way, where a model is trained to separate real from fake im-
ages. Existingworksprimarilyinvestigatenetworkarchitecturechoicesandtrain-
ingrecipes. Inthiswork, wearguethatinadditiontothesealgorithmicchoices,
we also require a well-aligned dataset of real/fake images to train a robust de-
tector. For the family of LDMs, we propose a very simple way to achieve this:
wereconstructalltherealimagesusingtheLDM’sautoencoder,withoutanyde-
noisingoperation. Wethentrainamodeltoseparatetheserealimagesfromtheir
reconstructions. Thefakescreatedthiswayareextremelysimilartotherealones
in almost every aspect (e.g., size, aspect ratio, semantic content), which forces
themodeltolookfortheLDMdecoder’sartifacts. Weempiricallyshowthatthis
wayofcreatingalignedreal/fakedatasets,whichalsosidestepsthecomputation-
ally expensive denoising process, helps in building a detector that focuses less
on spurious correlations, something that a very popular existing method is sus-
ceptible to. Finally, to demonstrate just how effective the alignment in a dataset
canbe,webuildadetectorusingimagesthatarenotnaturalobjects,andpresent
promisingresults.Overall,ourworkidentifiesthesubtlebutsignificantissuesthat
arisewhentrainingafakeimagedetectorandproposesasimpleandinexpensive
solutiontoaddresstheseproblems.
1 INTRODUCTION
Therehasbeenatransformationinthevisualworldoftheinternetwiththeriseofmoderngenerative
models. Hyper-realisticAIimagesareallaroundus. Diffusionmodels(Sohl-Dicksteinetal.,2015;
Song&Ermon,2020;Hoetal.,2020;Dhariwal&Nichol,2021)haveplayedakeyroleinheralding
this shift. With the aid of internet-scale vision-language datasets like LAION (Schuhmann et al.,
2022), the models have enabled users to create images using textual descriptions (Ramesh et al.,
2022;Rombachetal.,2022;Sahariaetal.,2022). Someareexcitedandoptimisticforthedifferent
waysinwhichpeoplewillusethesetoolstoincreasetheircreativityandproductivity. Others,less
so. Not long ago, people on Twitter got falsely convinced that Donald Trump had been arrested
by the FBI1 because of some AI generated images. In general, because of how powerful these
algorithmshavebecome,thereisagrowinguneaseabouthowrealanyarbitraryimageontheinternet
is. Consequently,thefieldoffakeimagedetectionhasgrowntotrytoaddresstheseissues.
Standardclass-conditionalpixel-spacediffusionmodels (Sahariaetal.,2022;Rameshetal.,2022)
are hard to train and customize due to their high computation and memory requirements. Latent
Diffusionmodels(Vahdatetal.,2021;Rombachetal.,2022)reducethiscomputationalburden,and
have greatly increased accessibility of diffusion models. For instance, recent open-source text-to-
imagediffusionmodels(Chenetal.,2023;Lietal.,2024;Podelletal.,2023)operateinthelatent
space. However, thissameaffordabilityalsoraisesconcernsaboutmisuse. Inthiswork, westudy
fakeimagedetectionforlatentdiffusionmodels.
*Equalcontribution
1https://x.com/EliotHiggins/status/1637927681734987777?s=20
1
4202
tcO
51
]VC.sc[
1v53811.0142:viXraPreprint. Underreview.
Figure1: Differentwaysofgeneratingimageswiththeaidoflatentdiffusionmodels(LDMs). The
mostpopularway(left)istostartfromnoiseandatextpromptandgothroughthedenoisingprocess
overmanystepsusingaparticularconfiguration(e.g.,guidancescale,resolution,aspectratio). Our
proposedapproachistotakeasetofrealimages(middle)intheiroriginalform(e.g.,aspectratio)
andreconstructthemusingonlytheLDM’sautoencoder(right)withoutthedenoisingprocess.
Themostpopularandeffectivewaytodetectwhetheranimageisrealorfakeinvolvestwomajor
steps. First, one collects an appropriate set of real images and synthesizes fake images using a
generativemodelofinterest.Onethentrainsaclassificationnetworktodistinguishthesetwoclasses
ofimages.Therehasbeenadecentamountofworkinstudyingthelatterstep-somesuggesttraining
the whole network using certain augmentations (Wang et al., 2020), while others propose ways to
keepthenumberoftrainableparameterstobeminimalorevenhavenotrainingatall(Ojhaetal.,
2024;Rickeretal.,2024). However,acriticalingredientintheeffectivenessofanysuchclassifier
willbethereal/fakedatasetthatisusedtotrainit. Ideally,theonlydifferencebetweentherealand
fakeimagesshouldbetheartifactsintroducedduetothegenerativemodel. Webelievethatthereis
roomforimprovementinthisarea.
For training a fake image detector, dataset design is of critical importance. During training, the
detectorcouldlatchontosubtledifferencesbetweentherealandfakeimagesinthedataset. Ifthese
differencesarenotcontrolled,thedetectorcouldlearntofocusonspuriouspatterns. Wehighlight
some of these errors, and propose a principled way to mitigate these issues. Our key contribution
for better real/fake alignment is very simple - we take a set of real images (Fig. 1 middle) and
reconstructthemusingthegenerativemodel(Fig.1right). Thesereconstructionsarenear-identical
to their real counterparts visually- e.g., in resolution, semantic content and color tone, except that
theyhaveartifactsintroducedthroughthegenerativemodel. Hence,theyserveasourfakeimages.
Withthisimprovedalignment,weobservethatthedetectorfocuseslessonthefalsepatterns. With
latentdiffusionmodels,wecanusetheirVAE(Kingma&Welling,2022;vandenOordetal.,2018)
toreconstructtherealimages. Bydoingso,weforcethefakedetectortofocusonthefingerprints
oftheVAEdecoder. Sincethegeneratedimagesalwayspassthroughthedecoder,theymustshare
thesamefingerprints.
Ifwecompareourmethodtothemorecommonparadigminwhichfakeimagesaregeneratedusing
the full denoising process (Ojha et al., 2024; Corvi et al., 2022; Cozzolino et al., 2024), there are
many advantages. First, our way of getting the fake images for training is not as expensive. The
standardwayofgeneratingimagesusingdiffusionmodelsisaniterative,timeconsumingprocess.
Inourcase, thereisjustoneforwardpassthroughtheautoencoder. Second,inthestandardsetup,
therealandfakeimagescouldhavedifferentpropertiesbeyondjustthegenerativemodel’sartifacts.
For example, their resolutions could be different; and if they have to be resized to a fixed size,
realandfakeimagescouldhavedifferentamountofresizingartifacts,somethingthattheclassifier
can latch on to during training. We show that one of the most effective detectors (Corvi et al.,
2022)indeedsuffersfromthisproblem,andhowourbetteralignedtrainingdataresultsinamuch
more robust detector. Third, since generating fake images aligned to a set of real images is so
simpleusingourmethod(wedon’thavetoworryaboutsettingtheidealguidancescaleorprompt
2Preprint. Underreview.
engineering), we can use any set of real images to train the detector. To demonstrate this point,
wecollectalgorithmicallygeneratedimagesusingOpenGL,whichlooknothinglikenaturalimages
(Baradadetal.,2023). Treatingthoseasourrealimages,weobtaintheirreconstructionsandtraina
detectortodistinguishthetwo. Thedetectorworkswellnotjustindetectingotheralgorithmically
generatedreal/fakeimages,butalsoindetectingnaturallookingreal/fakeimages.Thisunreasonable
effectiveness points to a principle about building robust detectors: it may be more important how
realandfakeimagesdifferfromeachother,andlessimportanthowrealimagesinthemselvesare.
Weconductextensiveexperimentstoassessourmethod. Wetrainonimagesgeneratedbytheorig-
inal LDM model (Rombach et al., 2022), and test on images generated by later versions of Stable
DiffusionaswellasnewerlatentmodelssuchasPlayground(Lietal.,2024),Kandinsky(Razzhi-
gaevetal.,2023),PixelArt-α(Chenetal.,2023)andLatentConsistencymodels(Luoetal.,2023).
WealsotestitonimagesgeneratedbyMidjourney(mid),aclosed-sourcecommercialmodel. Our
methodisabletomatch,andoftenoutperform,thebestexistingdetectorsindetectingfakeimages.
Usingourapproach,onecantrainadetectorthatisless-likelytofocusonspuriouspatterns. Finally,
sincewegeneratefaketrainingimagesusingtheLDM’sautoencoder,withoutanydenoisingoper-
ation, ourapproachis10xless-expensivethanstate-of-the-artmethods. Wealsoreportlimitations
that even our method cannot circumvent. Overall, we hope that our work highlights the subtle er-
rorsthatcanoccurwhentrainingfakeimagedetectorsandencouragesfurtherresearchontraining
detectorswithouttheseerrors.
2 RELATED WORK
Several algorithms to identify fake images have been proposed. Wang et al. (2020) fine-tunes a
ResNet-50(Heetal.,2015)modeltoclassifyimagesaseitherrealorfake. Ittrainsonfakeimages
generatedbyProGAN(Karrasetal.,2018). Trainingwithaggressivedataaugmentationenablesthe
detectortosuccessfullyidentifyimagesgeneratedbyvariousCNN-basedmodels.Tobetterpreserve
low-level details of the image, Gragnaniello et al. (2021) removes the downsampling operations
presentintheinitiallayersoftheneuralnetwork.Furthermore,Chaietal.(2020)trainsadetectoron
imagepatchestoforcethemodeltolearnlocalfingerprints. Combiningtheabovepractices,Corvi
et al. (2022) trains a fake image detector for LDM generated images. Unlike previous methods
that fine-tune the entire neural network, Ojha et al. (2024) demonstrate that linear probing of a
pre-trained, frozen CLIP image encoder (Radford et al., 2021) can effectively detect fake images
generated by a wide range of models. Work by Cozzolino et al. (2024) extends this approach to
detect images generated by additional models. Despite these algorithmic advances, the real and
fakeimagesusedfortrainingthesemodelsarenotwell-aligned. Ourworkdemonstratesthevarious
benefitsthatcomefromcreatingalignedfakeimagesthatarereconstructionsofrealimages.
The idea of leveraging reconstructions in fake image detection has been explored by some prior
works. Chai et al. (2020) create a fake image dataset for detecting GAN generated images by
reconstructingrealimages(Bauetal.,2019). However,theyobservethatadetectortrainedthisway
showsweakerresultsincomparisontoadetectortrainedusingrandomlygeneratedimages, likely
because the reconstructions obtained by Bau et al. (2019) are not faithful to the original image.
In contrast, the VAE reconstructions which we leverage are very faithful to the real images. As a
result, weshowthatafakedetectortrainedonlywithreconstructionsshowssuperiorperformance
comparedtoadetectortrainedonimagesgeneratedbyiterativedenoising. Anotherrelatedareais
that of reconstruction-based detection. Wang et al. (2023) observe that fake images are easier to
reconstructthanrealimages. Focusingondiffusionmodels,theyuseDDIMinversion(Songetal.,
2022)forreconstruction. Thedifferencebetweentheimageanditsreconstruction,calledDIRE,is
used to train a classifier. Ricker et al. (2024) extend this technique to LDMs by using the VAE to
obtain the reconstruction, and compute the reconstruction error using the LPIPS distance (Zhang
etal.,2018). Amajorlimitationofthesemethodsistheirneedtousethespecificgenerativemodel
duringinference. Moreover, theyfailwhencommonpost-processingoperationsareappliedtothe
images. In contrast, our approach only uses the reconstructed images during training, resulting in
fasterinferenceandwealsodemonstratebetterrobustnesstocorruptions.
3Preprint. Underreview.
3 PRELIMINARIES
Ourgoalistobuildafakeimagedetectortodetectwhetheranimageisrealorfake,i.e.,createdwith
theaidofagenerativemodel. Wefirstexplainourproblemstatementandthenprovideanoverview
oftheexistingparadigm.
3.1 PROBLEMSETUP
Recently, various image generation models have emerged. Among them, latent diffusion models
(LDMs)(Vahdatetal.,2021;Rombachetal.,2022)andthesubsequentstablediffusion(SD)series
have become noticeably ubiquitous. This is because they strike a good balance: users get control
(e.g.,throughtextprompts)togeneratequalitysyntheticimagesandtheoverallprocessiscomputa-
tionallymoreefficientthanothertext-to-imagediffusionmodels(Sahariaetal.,2022;Rameshetal.,
2022). Hence,ourspecificgoalinthisworkistodetectimagesgeneratedbyLDMs.
3.2 LATENTDIFFUSIONMODELS
A latent diffusion model first compresses images into a lower dimensional latent space using an
autoencoder. Thediffusionmodelthenoperatesinthislatentspace. Atext-conditionedlatentdiffu-
sionmodelconsistsofanencoder(ϕ ),decoder(ϕ )andaUNet(ϵ ). Givenahighdimensional
enc dec θ
imagespaceX andalower-dimensionallatentspaceZ, wetrainanencodernetworktocompress
animage(x ∈ X)intoalowerdimensionallatent(z ∈ Z). Thedecoderistrainedtoreconstruct
theimagefromthelatent.
In order to generate an image based on a conditioning signal c (prompt, bounding box, reference
image, etc.), we first sample z from a fixed prior (gaussian noise), where T corresponds to the
T
numberoftimesteps. WethendenoisetheimageforT stepsusingtheUNettogetalatentz . We
0
passz throughthedecoderϕ togeneratetheimage.
0 dec
3.3 EXISTINGFAKEDETECTIONPARADIGM
Sincewedon’tknowwhatpreciselymakesafakeimagefakeandarealimagereal,acommonand
effectiveapproachhasbeentolearnthatdifference(Wangetal.,2020;Corvietal.,2022;Cozzolino
et al., 2024). The first step is to create a dataset consisting of two categories (i) R consisting of
realimagesand(ii)F consistingoffakeimagessampledusingagenerativemodelG. Thenextstep
involves training a deep neural network ψ on the collected dataset D = {R∪F} for the task of
binaryclassification,sothat∀x∈R,ψ(x)≈0and∀x∈F,ψ(x)≈1. Thehopeisthatwhenψis
learningtoseparatethedistributionofF fromR,itdoessoonlybydiscoveringG’sartifactsinF
(somethingnotpresentinR),andnotbyusingsomeotherspuriousfeatures. Weexplainwhatthese
spuriousfeaturescanbewiththehelpofanexamplepriorwork.
Imperfect alignment between R and F: The work of Corvi et al. (2022) trains a detector in
the same way discussed above. For the real data R, it uses MS COCO (Lin et al., 2015) and
LSUN(Yuetal., 2016). Forfakeimages F, itusesthetextprompts fromMSCOCOtogenerate
imagesfromanLDMmodelatafixed256x256resolution. Therealimagestendtobeatahigher
resolution than fake images (see Appendix A.1.1 for details). Fig. 1 (left) shows the discrepancy
in the sizes of real and fake images. To make the detector robust to image resizing, the random
resized crop 2 data augmentation is used during training. By first cropping the image and then
resizing the cropped image to a fixed final resolution, the random resized crop introduces both
upsampling and downsampling artifacts to the training data. However, due to the discrepancy in
resolutionbetweenrealandfakeimages,therandomresizedcropintroducesdifferentsignalstoeach
distribution. Consequently,thereispotentialforψtousethissignalinsomecapacitytoseparateR
fromF. LateroninSec.5,weshowthattheresultingdetectorindeedlearnssuchspuriousfeatures
and changes its prediction if the same image is saved at a different resolutions. We want to avoid
suchsituationsandinsteadlookforaprincipledwaytolearnarobustfakeimagedetector.
2https://pytorch.org/vision/stable/generated/torchvision.transforms.
RandomResizedCrop.html
4Preprint. Underreview.
4 OUR APPROACH
Ifwedonotwantψtolearnanyspuriousfeatures,thenweneedtomakesuretheyarenotavailable
forψtolearnfromthetrainingdataitself. So,ourkeyideaistoalignRandF asmuchaspossible
sothattheironlydifferenceisduetoG’sartifacts. Notethatpriormethods(Ojhaetal.,2024;Corvi
etal.,2022;Cozzolinoetal.,2024)dotrytoalignRandF insomecapacity. Forexample,while
generatingF,insteadofusingarbitraryprompts,theyuseR’simagedescriptionstogenerateimages
using LDM. However, such images are only similar to the real images in terms of semantics. We
instead propose an approach that can bring the distribution of F to be much closer to that of R,
whichcanaidinsubduingmanyoftheotherdifferencesinimageproperties(e.g.,aspectratio).
Oursolutionissimple. TogenerateF,wereconstructimagesinRusingG’sparameters. Typically,
reconstructinganimagexinvolvesamulti-stepinversion(e.g.,DDIMinversion(Songetal.,2022))
from the image space to the noise space to compute latent z , such that G(z ) ≈ x. However,
x x
fortheparticularG thatisourtargetinthiswork, i.e., LDM/SD,thereisamuchsimplersolution.
Specifically, given a real image x, we pass it only through the pre-trained autoencoder, without
usingtheU-Nettodoanyforward/reverseprocess. UsingthenotationsdefinedinSec.3.2,wecan
mathematicallyformulatetheprocessinthefollowingway:
F ={ϕ (ϕ (x)) | ∀x∈R}
dec enc
The resulting reconstructed images can still be validly considered fake, at least for our task, since
theynecessarilycontainartifactsintroducedbyϕ .WecreatethisdistributionofF fromRbefore
dec
anytrainingbegins. Oncewehavethisdata,wethentrainadeepneuralnetworkψ usingthesame
trainingrecipeasproposedinCorvietal.(2022). Specifically,weuseResNet-50(Heetal.,2015)
pretrained on ImageNet and finetune the whole backbone for real-vs-fake image classification. In
each iteration, we sample a batch of real R and fake images F , and train ψ using binary cross
i i
entropyloss(real: 0andfake: 1).
Within this framework, we consider two variants depending on the composition of real and fake
imagesinabatch(i). Inonecase,thebatchcouldbearandomassortmentofrealandfakeimages
whereimagesinR andF donotneedtohaveanycorrespondencebetweenthem.Intheothercase,
i i
eachimageinF hasacorrespondingrealimageinR aspartofthesamebatch,withidenticaldata
i i
augmentations(e.g., crop). Withthislattervariant, thealignmentbetweenrealandfakeimagesis
ensured not just at the dataset level, but also at the batch level in each iteration, and we explore
if this further helps the model to focus on the desired features for fake detection. We call the two
variantsOursandOurs-Syncrespectively.Forboth,sincewetrainψtofocusontheartifactsofϕ ,
dec
thedetectorshoulddetecteventhoseimageswhichhavebeenproducedthroughthefulldenoising
processusingtheU-Netϵ . Thisisbecauseeventhoseimageswillhavetheirdenoisedlatentsgo
θ
throughthesamedecoderϕ ,andhenceshouldhavesimilarartifacts.
dec
5 EXPERIMENTS
Inthissection,wedemonstratethatusingreconstructionsprovidesaveryinexpensivewaytocreate
awell-alignedreal-vs-faketrainingdatasetwhichinturnreducesthelikelihoodofadetectorlearning
spuriouspatterns. Ourexperimentsshowthatadetectortrainedusingourapproachcaneffectively
detect fake images generated by various other text-to-image latent diffusion models. Finally, we
showthataslongasthereal-vs-fakedatasetiswell-aligned,thecontentoftheimagesisrelatively
lesssignificantfortrainingafakeimagedetector.
5.1 BASELINESANDTRAININGDETAILS
We consider the following baselines for detecting fake images: (i) Using the feature space of a
pre-trained CLIP model (Radford et al., 2021) to detect fake images (Ojha et al., 2024). The au-
thorscollectasetofreal/fakeimagesandperformlinearprobingontheCLIP’slastlayerwiththe
goalofbuildingauniversalfakedetector. Inthiswork, weconsidertwovariants: onewhichuses
GAN based training data (Ojha-ProGAN) and one which uses LDM based data (Ojha-LDM). (ii)
Cozzolino-LDM (Cozzolinoetal.,2024)whichpresentimprovementsover(Ojhaetal.,2024)by
improving dataset quality and using the CLIP-backbone trained on bigger datasets. (iii) AEROB-
LADE(Rickeretal.,2024)whichpresentsatrainingfreemethodbasedonhowcloseanimageis
to its LDM autoencoder’s reconstruction (fake images are closer). (iv) Training a ResNet-50 on a
5Preprint. Underreview.
datasetofreal(MSCOCO+LSUN)andLDMgeneratedimagesCorvietal.(2022). Thisbaseline,
which we call Corvi, combines the idea of augmentation driven training proposed in Wang et al.
(2020)andpatchbasedtrainingproposedinChaietal.(2020).
Wededicatethefirstpartofourexperimentstocomparingourmethodexclusivelyto(Corvietal.,
2022). Therearetworeasons. First, Corviisoneofthemosteffectivemethodsfordetectingfake
imagesfromvarioustext-to-imagelatentdiffusionmodels(wecompareallmethodslaterinTable1).
Yet,thetrainingpipelineusedbyCorvigivesrisetotheclassifierlearningsomespuriousfeatures,
and hence is a good test bed for our method, to see whether we can avoid making our detector
learnthosefeatures,whilestillpreservingorimprovingfakedetectioninageneralsense. Second,
since Corvi is representative of the existing paradigm of collecting fake images for training in a
computationally heavy way (iterative denoising process), we compare against it to see how much
moreefficientourmethodofcreatingthedatasetis.
Training details: Similar to Corvi et al. (2022), we use a combination of MS COCO (Lin et al.,
2015) and LSUN (Yu et al., 2016) as our real dataset, totaling 179257 images. We reconstruct
themusingtheautoencoderoftheLDMmodelproposedbyRombachetal.(2022)togetthesame
number of fake images. Starting from ImageNet pretrained ResNet-50 as ψ, we finetune it on the
real-vs-fakedataset. WeoptimizeusingAdam(Kingma&Ba,2015)withaninitiallearningrateset
to0.0001. TherestofthetrainingdetailscanbefoundinAppendixA.1.1.
5.2 SUBDUINGSPURIOUSFEATURES
A big emphasis throughout our work is that with a properly aligned real-vs-fake dataset, the fake
detector will be less susceptible to spurious features. In this section, we test that hypothesis. In
particular, we focus on the sensitivity of a detector when an image is resized to a higher or lower
resolutionthanitsoriginalresolution.
Issue caused by lack of well-aligned data: Corvi et al. (2022) use LDM generated images as
fake, and LSUN + MS COCO as real. All fake images are originally at 256 x 256 resolution.
Withintherealdistribution,theLSUNimagesareof256x256resolution. AlmostalloftheCOCO
images,however,areconsiderablylargerthan256x256. So,onaverage,realimagesareatahigher
resolutionthanfakeones.Akeycomponentinthedataaugmentationpipelineisthe‘randomresized
crop’ function, which works in the following way: a random crop is taken as a percentage of the
whole image. This percentage is chosen uniformly from the range [8,100]. The resulting crop is
thenresizedtoafixed256x256resolution.Hence,resizecroppedfakeimageshaveonlyup-scaling
artifacts. Ontheotherhand,manyrealimageswillhavebothup-scalinganddown-scalingartifacts.
Incontrast,forourmethod,therealimagesarethesameasCorvi’s(i.e.,COCO+LSUN)butour
faketrainingimagesareproducedbyreconstructingtherealimages,andhencehavethesameexact
resolutionastheirrealcounterpart. Inourwork,wefocusonfine-tuningthewholenetworksimilar
to Corvi, however, we show that these issues can manifest in other training based methods (like
Ojha-LDM).WereferthereadertoAppendixA.2.2foranin-depthanalysis.
Experiment details: We create a test set of real and fake images of increasing/decreasing resolu-
tions. Fortherealset,werandomlyselect500imagesfromtheRedcapsdataset(Desaietal.,2021).
Forfakeimages, wegenerate500imagesusingSD1.5(promptspertaintoobjectcategoriesfrom
CIFAR(Krizhevskyetal.,2010)). Theoriginalresolutionofbothrealandfakeimagesis512x512.
Weresizetheseimagestodifferentresolutionsintherangeof[128,1024]correspondingtoscaling
factorsof0.25and2.00respectively. Wethentestbothdetectors,Corviandours,toseehowthey
performonthisdataset. Bothmethodsproducetheprobabilityofaninputimagebeingfake.
Resultsandanalysis: InFig.2leftandright,weseethebehaviorofthetwodetectorsonfakeand
realimagesrespectively,wherex-axisdenotesthescalingfactoroftestimages,andy-axisrepresents
thefakenessscoreofthemodel. Wefirstfocusontheperformanceonfakeimages(left). Soonafter
we start downsizing from the base resolution (marked with the dotted line), the probability of the
imagebeingfakedropsdrastically. Thismakessensesinceduringtraining, theCorvidetectorhas
only seen downsizing artifacts on real images. The performance of our method falls at a much
slowerrate,strugglingonlywhenfacedwithextremedownsampling. Similarly, whenupsampling
real images (Fig. 2 right), the performance of the baseline detector worsens since during training,
up-samplingartifactsareseenmorewithfakeimages. Ourdetectorsremainmuchmoreconsistent
6Preprint. Underreview.
Figure2:Sensitivityoffakedetectorstoimageresizingforasetfakeimages(left)andasetofreal
images(right). Corviassociatesdownsamplingwithrealimagesandupsamplingwithfakeimages.
Ourdetectorsdonotlearnthatfalsepattern,showingbetterrobustness.
onrealimagesthroughouttheresizingrange.Overall,theseresultshighlighttheeffectivenessofthe
simplewayinwhichwecanmakethedetectormuchmorerobustthroughabetterdatasetalignment.
5.3 COMPUTATIONALEFFICIENCY
Training a fake image detector requires synthesizing a lot of images. This can become computa-
tionally heavy when using latent diffusion models, which utilize multiple rounds of forward pass
throughtheUNet(ϵ )andfinaldecodingthroughtheϕ . Additionally,atextencoderisalsoused
θ dec
toconditionthegenerationontextprompts. Sinceourapproachneitherutilizesthetextencodernor
theUNet,andonlygeneratesimageswithasingleforwardpassthroughϕ andϕ ,itismuch
enc dec
more efficient. We measure this difference in terms of the number of multiply-accumulate opera-
tions needed to generate the 179257 fake images. We ensure ours and the baseline are generating
imagesatthesameresolution.
Figure3:Computationalcostmea-
sured in the number of multiply-
accumulate operations. Ours is
more than 10x efficient than the
state-of-the-art method of (Corvi
et al., 2022). Note that text en-
coder cost is relatively negligi-
ble compared to the U-Net and
autoencoder.
Results and Discussion: Figure 3 shows the results, where our method of curating the dataset is
ten times more cost-effective than the existing state-of-the-art approach. Unsurprisingly, majority
of the cost comes from running the UNet. By skipping the UNet step, we are able to reduce the
computationalcost. Furthermore,ourapproachcanmaintainsimilareffectivenessevenwithlesser
data,comparedtothefulldataset,settingitapartfromCorvi. WediscussthisindetailinAppendix
A.2.1.
5.4 EVALUATIONONDIFFERENTTYPESOFREAL/FAKEIMAGES
Nowthatwehaveseenthebenefitsofourmethodinbeingabletoavoidcertainspuriouscorrelations
whilebeingcomputationallyveryefficient,wenowstudyhowitfaresinbeingabletodetectdifferent
typesoffakeimagesproducedbydifferenttypesoflatentdiffusionmodels.
Testdatasets: WecompareallthedetectorsintroducedinSec.5.1toourmethodonthefollowing
datasets. (i) The Real set contains real images from multiple sources; 1000 images from Red-
7Preprint. Underreview.
Real SD MJ Kandinsky Playground PixelArt-α LCM
AEROBLADE(Rickeretal.,2024) 96.58 74.50 99.50 99.26 14.87 75.93 99.96
Ojha-ProGAN(Ojhaetal.,2024) 95.13 17.84 12.96 23.56 21.03 19.73 23.93
Ojha-LDM(Ojhaetal.,2024) 54.16 69.56 69.40 90.70 92.16 90.73 73.66
Cozzolino-LDM(Cozzolinoetal.,2024) 85.36 47.36 50.93 51.06 59.73 59.52 34.70
Corvi(Corvietal.,2022) 99.96 99.73 96.90 99.92 82.13 100 99.60
Ours 99.93 99.31 98.50 99.92 94.85 100 100
Ours-Sync 99.76 99.57 99.37 99.57 99.48 100 100
Table1: Generalizationresults. Accuracyofdifferentmethodsfordetectingrealandfakeimages.
The finetuning based detectors (Corvi, Ours, and Ours-Sync) generally outperform the training-
free and linear probing based methods. Our approach is robust to drastic changes in the UNet
architecture(Playground)showingahugeimprovement(+12.72/+17.35forOurs/Ours-Sync)from
theCorvidetector.
Real SD MJ Kandinsky Playground PixelArt-α LCM
AEROBLADE(Rickeretal.,2024) 96.85 28.10 61.80 27.60 3.17 10.22 4.60
Ojha-ProGAN(Ojhaetal.,2024) 93.26 13.10 8.26 14.53 7.63 9.60 13.16
Ojha-LDM(Ojhaetal.,2024) 48.46 57.20 51.63 64.63 66.16 64.37 64.33
Cozzolino-LDM(Cozzolinoetal.,2024) 76.63 52.80 59.43 59.63 73.36 66.22 60.93
Corvi(Corvietal.,2022) 98.40 77.78 50.45 59.23 24.27 64.41 58.31
Ours 99.85 86.50 70.68 64.88 61.25 84.36 90.12
Ours-Sync 99.50 88.06 72.36 68.60 76.36 86.10 91.08
Table 2: Sensitivity to common post-processing operations. Analogous to Table 1, but the test
images have undergone random compression, resizing, blur and color jitter. Our detectors show
improvedrobustnessoverthebaselineswhendetectingfakeimagesfromdifferentlatentdiffusion
models. Ensuringbatch-levelalignment(Ours-Sync)offersincreasedrobustness.
Caps(Desaietal.,2021),800imagesfromLAION-Aesthetics(Schuhmannetal.,2022),1000im-
agesfromwhichfaceisreal(whi)and200imagesfromWikiArt(wik). Forfakeimages,wecollect
imagesfromthefollowingsources. (ii)DifferentvariantsofStableDiffusion(SD),whichincludes
1000fakeimagesfromInstructPix2Pix(Brooksetal.,2023), 1000imagesfromNights(Fuetal.,
2023) dataset and 1000 DDIM inversion of real face images; (iii) 3000 images from Midjourney
(MJ)(mid),whosemodelarchitectureisnotpublic;(iv)3000imagesfromKandinsky(Razzhigaev
etal.,2023)whichhasaVAEofadifferentarchitectureincomparisontotheLDMmodelwetrain
on;(v)3000imagesfromPlayground (Lietal.,2024)and(vi)3000fromPixelArt-α(Chenetal.,
2023), which have similar VAEs as ours, but their U-Net is different; and (vii) 3000 images from
Latentconsistencymodel(LCM)(Luoetal.,2023)whichwasdistilledfromafinetunedversionof
SD1.5usingtheobjectiveproposedbySongetal.(2023).
Wecreatethisoveralltestsettoensurethatthereisenoughdiversityofnaturalandartisticlooking
images. Theselectedmodelsofferawiderangeofarchitecturalchoicesutilizedbylatentdiffusion
models. Furthermore,forthesesamereal/fakeimages,weseparatelyconstructtheirpost-processed
versions where we randomly add JPEG compression, blurring, color jitter, and resize each image.
Thisenablesustotesttherobustnessofdetectorstocommonpost-processingoperations. Following
(Ojha et al., 2024), we use accuracy as the evaluation metric with 0.5 as the threshold (threshold
detailsforAEROBLADEcanbefoundatAppendixA.1.3).
Results and analysis: Tables 1 and 2 show the performances of various baselines on our test set,
before and after applying common post-processing operations, respectively. Overall, the methods
thatinvolvefine-tuning(CorviandOurs)outperformtheothermethodsthatareeitherlinearprobing
based(Ojha-ProGAN,Ojha-LDM,Cozzolino-LDM)orwithouttraining(AEROBLADE).Oursfur-
theroutperformsCorvi,especiallyonpost-processedimages(Table2). BothCorviandourmethod
use the common image corruptions as data augmentations during training, however our method
showshugeimprovements;e.g.,ourapproachobtainsa+36.98/+52.09improvementforOurs/Ours-
Sync over Corvi on Playground generated images. Playground is built from SDXL (Podell et al.,
2023),whichusesafine-tunedversionoftheLDMautoencoder,butusesaUNetwiththriceasmany
parameterscomparedtoLDM.WehypothesizethatsinceourmethodonlyfocusesontheVAE,itis
robusttodrasticchangesinUNetarchitectureasopposedtoCorviwhichusestheUNetfortraining.
8Preprint. Underreview.
Figure4: WeuseOpenGLshadergeneratedimages(Baradadetal.,2023),asourrealimagesand
reconstructthemtoobtainourfakeimages. Wethentrainadetectorusingthisdataset.
Original WithPost-Processing
Corvi Ours-Sync Ours Ours-Sync Corvi Ours-Sync Ours Ours-Sync
(shaders) (shaders) (shaders) (shaders)
Real 99.91 99.73 84.98 83.24 97.85 98.86 74.62 76.62
SD 99.68 99.80 99.75 99.44 78.05 84.73 77.82 72.30
MJ 97.71 99.30 98.56 95.79 51.03 72.38 53.45 46.43
Kandinsky 99.88 99.80 98.23 98.10 58.68 69.02 69.29 67.87
Playground 86.25 98.80 99.82 99.90 24.11 63.83 52.65 54.66
PixelArt-α 100 100 100 100 63.34 80.99 69.65 68.81
LCM 99.65 99.93 99.78 99.84 50.63 82.83 63.14 60.81
Table3: Generalizationresults. Comparingthemodeltrainedusingtheshadersdataset(Baradad
et al., 2023) to models trained on natural image datasets (Corvi, Ours-Sync). All models use a
threshold calibrated using a validation set. The detectors trained on shader images, show good
performanceonnaturalimages. Thisshowsthatawell-aligneddatasetismoreimportantthanthe
exactcontentoftheimagesthemselves.
LikeCorvi,theotherbaselinesalsostrugglewitharchitecturaldifferencesusedtoprocesstraining
datavs.testingdata. Forexample, AEROBLADEusestheVAEsofSD1.1, SD2andKandinsky
2.1andusesthesmallestreconstructionerrorofthethreetoperformreal/fakedetection. Itisunable
to detect images from SD, Playground, and PixelArt-α as they use a different VAE. Furthermore,
AEROBLADE struggles to detect images that have been through common post-processing opera-
tions. Interestingly, the Kandinsky VAE uses a different architecture from the LDM VAE that we
trained on, as it replaces the convolutional decoder of LDM with a MoVQ decoder (Zheng et al.,
2022)forimprovedgenerationquality. Weobservethatourdetectorislesssensitivetothischange
thanothermethods,likelybecausetheothermethodsadditionallyutilizetheUNetoraremoresus-
ceptibletospuriouscorrelationsduetonotenforcingaligneddataduringtraining,leadingtolarger
distributionaldifferencesinthegeneratedtrainingvs.testingimages.
Overall,theresultsconfirmouradvantageofhavingwell-alignedreal/faketrainingimagesgenerated
usingonlytheLDM’sVAE–ithelpsthefakedetectorfocusonthetruerealvs.fakesignalandless
onspuriouscorrelations,andmakesitrobusttoarchitecturalchangesintheUNet.
5.5 CANWETRAINONIMAGESTHATARENOTNATURAL?
Ourexperimentshaveshownthatusingaproperlyaligneddatasetcanmitigatethelearningofspu-
rious patterns. However, the training set for the detector and the test settings so far both contain
similarrealworldconcepts.Butifthegoalofalignmentistoforcethemodeltonotlookatanything
elsebuttheLDMdecoder’sartifacts,canthedetectorlearnthoseartifactswithoutbeingtrainedon
anynaturallyoccurringrealimagesatall? Tostudythis,wenexttrainourdetectorusingadataset
which does not capture the semantic concepts that we test the model on, and see if it succeeds in
detectingthesamereal/fakeimagesdescribedinTables1and2.
AsimilarmotivationwasdiscussedinBaradadetal.(2023),wheretheauthorswantedtolearnimage
representations without using real-world images. They proposed to generate images with 21,000
OpenGL fragment shaders, which are short programs that compute the color and transparency of
everypixelinanimage.SampleimagesareshowninFig.4(left).Althoughtheimagesaregenerated
algorithmically,theydonotinvolveaneuralnetwork. Forourusecase,weusetheseimagesasthe
“real” set. Specifically, our R consists of 100k such images of 384 x 384 resolution. We pass
9Preprint. Underreview.
theseimagesthroughtheSD1.5’sVAEinordertogetourreconstructionswhichserveasourfake
distribution F. We train the two versions of our detectors (normal and sync) in the same way as
describedinSec.4(e.g.,usingsameResNet-50asψ),andevaluatethemonthesametestsetfrom
section 5.4. We train detectors using 5 random seeds and report the average values. Different to
earlierexperiments,wecalibrateathreshold(insteadofusing0.5)onthevalidationset. Forfurther
details,wereferthereadertoAppendixA.1.2.
Results and Discussion: Similar to Tables 1 and 2, we report accuracy of our shaders-trained
detectors on original and post-processed images in Table 3. respectively. We also compare to
detectors trained on natural real/fake images (Corvi and our method). For uniformity, we train
themusing100kreal/fakeimages. First,wenoticethatOurs(shaders)/Ours-Sync(shaders)detect
84.98/83.24%ofrealimages,comparedtoCorvi/Ours-Syncwhichdetects99.91/99.73%ofrealim-
ages. However,whatissurprisingishoweffectiveourshaders-detectorsareatbeingabletodetect
all types of fake images without perturbation, having almost the same accuracy as our detectors
trainedwithnaturalimages. IfweespeciallycomparethemtoCorvionpost-processedfakeimages
(Table3)(right),weseethattheyhaveamuchbetteraccuracyinalmosteverycasebyadecentmar-
gin;e.g.,Ours(shaders)showsimprovementsof+10.61,+28.54,+6.31and+12.51onKandinsky,
Playground,PixelArtandLCMrespectively. However,whileOurs-shadersdetectorsdomatchthe
performance of our natural image trained detector (Ours-Sync) on clean fake images, they cannot
dosoonpost-processedfakeimages. Evenso,giventhatthedetectorsproposedinthissectionare
trainedwithoutevertrainingonnaturalrealimageoraproperlygenerated(iterativelydenoised)fake
image, being able to outperform the best existing detector (Corvi) which has both of those things
highlightsthecrucialrolethatdatasetalignmentcanplayindeployingrobustdetectors.
6 DISCUSSION AND LIMITATIONS
The principle of aligning data using the LDM’s autoencoder makes the assumption that most of
thepropertiesofrealimagescanbetransferredtothereconstructedimage(e.g.,semanticcontent).
However, there might be some low-level properties that do not get transferred as effectively. As
a specific example, if real images are originally saved in .webp format (a modern compression
technique),wefindthatthereconstructionsmightnotinheritthosecompressionartifacts,andhence
theresultingdetectorisnotcompletelyrobustto.webpcompression. Thisisdepictedinthefigure
below,whichplotstheeffectofdifferentlevelsof.webpcompression(x-axis)onthemodel’soutput
score, i.e., probability of the image being fake (y-axis). We start with a clean set of 500 images
generated by SD 1.5 (compression quality = 100). Both Ours-Sync as well as Corvi, which are
trainedonrealimagescontaining.webpartifacts,correctlyassignahighscoretotheimages. Aswe
increase the compression level, the models’ scores drop drastically. This implies that the detector
has learned to associate .webp artifacts to real images. This can become problematic since we do
not know what arbitrary properties, like .webp artifacts, might be present in commonly used real
images,whichcaninturn,makethedetectorsensitivetothosefeatures.
However, this is where the promise of algorithmi-
cally generated images come, like those discussed in
Sec.5.5. Sincewehavecompletecontroloverhowan
imageisgenerated, wecanmakesurethattheydonot
contain any unnecessary artifacts. In fact, the detector
trainedonshadersgeneratedimages,Ours(Shaders),is
muchmorerobustto.webpcompression.
Finally, while we have shown that our method can be
robusttosmallarchitecturalchangesintheU-Net(e.g.,
Playground) and VAE (Kandinsky), it struggles when there are major architectural differences in
theVAE.Asanexample,wetestedourdetectoron1950imagesgeneratedbyFLUX.1-dev(Labs),
whichutilizesalatentspaceof16channels(mostSDvariantshave4).TheaccuracyofCorvi,Ours,
Ours-Syncindetectingthemasfakeare3.18%,9.59%,25.87%. Perhapsunsurprisingly,thismeans
thatmodelswithvastlydifferentarchitecturestendtoproduceverydifferentkindsofartifacts.
7 CONCLUSION
In this work, we demonstrated the need to train fake image detectors using a completely aligned
dataset. We introduced a principled way to achieve this for Latent Diffusion Models. Through
10Preprint. Underreview.
carefulexperimentation,wesupportedourclaims.BytrainingafakeimagedetectorusingOpenGL-
generatedtextureimages,wedemonstratedtheimportanceoffocusingonthedifferencesbetween
therealandfakeimages,asopposedtotheimagesthemselves. Aninterestingfuturedirectioncould
betostudytheapplicationofthisideainthecontextofpixel-spacediffusionmodelswheretheVAE
is not available. We hope that our work highlights the importance of dataset alignment and paves
thewayforrobustfakeimagedetectorsthatcanhelpsocietycombatmisinformation.
8 REPRODUCIBILITY STATEMENT
Weprovideprecisedetailsonourexperimentalsetuptoensurereproducibility. Forourexperiments
ontrainingwithnatural-lookingrealimages,weprovidetrainingdetailsinSection5.1andAppendix
A.1.1. DetailsofourtestdatasetcanbefoundinSection5.4. Detailsregardingourexperimentson
shaderscanbefoundinSection5.5andAppendixA.1.2. Wealsointendtoreleaseourpre-trained
checkpoints,datasets,andcodetoensurereproducibility,withallresourcesmadepubliclyavailable
onGitHub.
9 ETHICS STATEMENT
Duringourstudy,wemadesuretoonlyusepubliclyavailabledata,respectingpeople’sprivacyon-
line.Wedidn’tcollectoranalyzeanypersonalorsensitiveinformation.Webelieveourresearchcan
helptacklethespreadofmisinformationontheinternet,contributingtoasaferandmoretrustworthy
digitalspace.
ACKNOWLEDGMENTS
This work was supported in part by NSF IIS2404180, Institute of Information & communica-
tionsTechnologyPlanning&Evaluation(IITP)grantsfundedbytheKoreagovernment(MSIT)(No.
2022-0-00871,DevelopmentofAIAutonomyandKnowledgeEnhancementforAIAgentCollab-
oration)and(No. RS2022-00187238,DevelopmentofLargeKoreanLanguageModelTechnology
forEfficientPre-training),andMicrosoftAccelerateFoundationModelsResearchProgram.
REFERENCES
Midjourney.https://www.midjourney.com/.
Whichfaceisreal? https://www.whichfaceisreal.com/.
Wikiart.https://www.wikiart.org/.
Manel Baradad, Chun-Fu Chen, Jonas Wulff, Tongzhou Wang, Rogerio Feris, Antonio Torralba,
andPhillipIsola. Proceduralimageprogramsforrepresentationlearning, 2023. URLhttps:
//arxiv.org/abs/2211.16412.
DavidBau,Jun-YanZhu,JonasWulff,WilliamPeebles,HendrikStrobelt,BoleiZhou,andAntonio
Torralba.Seeingwhatagancannotgenerate,2019.URLhttps://arxiv.org/abs/1910.
11626.
TimBrooks,AleksanderHolynski,andAlexeiA.Efros. Instructpix2pix: Learningtofollowimage
editinginstructions,2023. URLhttps://arxiv.org/abs/2211.09800.
Lucy Chai, David Bau, Ser-Nam Lim, and Phillip Isola. What makes fake images detectable?
understanding properties that generalize, 2020. URL https://arxiv.org/abs/2008.
10588.
JunsongChen,JinchengYu,ChongjianGe,LeweiYao,EnzeXie,YueWu,ZhongdaoWang,James
Kwok,PingLuo,HuchuanLu,andZhenguoLi. Pixart-α: Fasttrainingofdiffusiontransformer
for photorealistic text-to-image synthesis, 2023. URL https://arxiv.org/abs/2310.
00426.
11Preprint. Underreview.
Riccardo Corvi, Davide Cozzolino, Giada Zingarini, Giovanni Poggi, Koki Nagano, and Luisa
Verdoliva. On the detection of synthetic images generated by diffusion models, 2022. URL
https://arxiv.org/abs/2211.00680.
DavideCozzolino,GiovanniPoggi,RiccardoCorvi,MatthiasNießner,andLuisaVerdoliva.Raising
the bar of ai-generated image detection with clip, 2024. URL https://arxiv.org/abs/
2312.00195.
Karan Desai, Gaurav Kaul, Zubin Aysola, and Justin Johnson. Redcaps: web-curated image-text
data created by the people, for the people, 2021. URL https://arxiv.org/abs/2111.
11431.
Prafulla Dhariwal and Alex Nichol. Diffusion models beat gans on image synthesis, 2021. URL
https://arxiv.org/abs/2105.05233.
Stephanie Fu, Netanel Tamir, Shobhita Sundaram, Lucy Chai, Richard Zhang, Tali Dekel, and
Phillip Isola. Dreamsim: Learning new dimensions of human visual similarity using synthetic
data,2023. URLhttps://arxiv.org/abs/2306.09344.
Diego Gragnaniello, Davide Cozzolino, Francesco Marra, Giovanni Poggi, and Luisa Verdoliva.
Are gan generated images easy to detect? a critical analysis of the state-of-the-art, 2021. URL
https://arxiv.org/abs/2104.02617.
KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun. Deepresiduallearningforimagerecog-
nition,2015. URLhttps://arxiv.org/abs/1512.03385.
JonathanHo,AjayJain,andPieterAbbeel. Denoisingdiffusionprobabilisticmodels,2020. URL
https://arxiv.org/abs/2006.11239.
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for
improved quality, stability, and variation, 2018. URL https://arxiv.org/abs/1710.
10196.
DiederikP.KingmaandJimmyBa. Adam: Amethodforstochasticoptimization. 2015.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes, 2022. URL https:
//arxiv.org/abs/1312.6114.
Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 (canadian institute for advanced re-
search). URLhttp://www.cs.toronto.edu/kriz/cifar.html,5(4):1,2010.
BlackForestLabs. Flux1.https://blackforestlabs.ai/.
DaiqingLi, AleksKamko, EhsanAkhgari, AliSabet, LinmiaoXu, andSuhailDoshi. Playground
v2.5: Threeinsightstowardsenhancingaestheticqualityintext-to-imagegeneration,2024. URL
https://arxiv.org/abs/2402.17245.
Tsung-YiLin,MichaelMaire,SergeBelongie,LubomirBourdev,RossGirshick,JamesHays,Pietro
Perona,DevaRamanan,C.LawrenceZitnick,andPiotrDolla´r. Microsoftcoco:Commonobjects
incontext,2015. URLhttps://arxiv.org/abs/1405.0312.
SimianLuo,YiqinTan,LongboHuang,JianLi,andHangZhao. Latentconsistencymodels: Syn-
thesizinghigh-resolutionimageswithfew-stepinference,2023. URLhttps://arxiv.org/
abs/2310.04378.
UtkarshOjha,YuhengLi,andYongJaeLee. Towardsuniversalfakeimagedetectorsthatgeneralize
acrossgenerativemodels,2024. URLhttps://arxiv.org/abs/2302.10174.
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Mu¨ller, Joe
Penna,andRobinRombach. Sdxl: Improvinglatentdiffusionmodelsforhigh-resolutionimage
synthesis,2023. URLhttps://arxiv.org/abs/2307.01952.
12Preprint. Underreview.
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agar-
wal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya
Sutskever. Learning transferable visual models from natural language supervision, 2021. URL
https://arxiv.org/abs/2103.00020.
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-
conditional image generation with clip latents, 2022. URL https://arxiv.org/abs/
2204.06125.
AntonRazzhigaev,ArseniyShakhmatov,AnastasiaMaltseva,VladimirArkhipkin,IgorPavlov,Ilya
Ryabov,AngelinaKuts,AlexanderPanchenko,AndreyKuznetsov,andDenisDimitrov. Kandin-
sky: an improved text-to-image synthesis with image prior and latent diffusion, 2023. URL
https://arxiv.org/abs/2310.03502.
Jonas Ricker, Denis Lukovnikov, and Asja Fischer. Aeroblade: Training-free detection of latent
diffusionimagesusingautoencoderreconstructionerror,2024. URLhttps://arxiv.org/
abs/2401.17879.
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjo¨rn Ommer. High-
resolutionimagesynthesiswithlatentdiffusionmodels, 2022. URLhttps://arxiv.org/
abs/2112.10752.
ChitwanSaharia,WilliamChan,SaurabhSaxena,LalaLi,JayWhang,EmilyDenton,SeyedKam-
yarSeyedGhasemipour,BurcuKaragolAyan,S.SaraMahdavi,RaphaGontijoLopes,TimSal-
imans, Jonathan Ho, David J Fleet, and Mohammad Norouzi. Photorealistic text-to-image dif-
fusion models with deep language understanding, 2022. URL https://arxiv.org/abs/
2205.11487.
ChristophSchuhmann, RomainBeaumont, RichardVencu, CadeGordon, RossWightman, Mehdi
Cherti,TheoCoombes,AarushKatta,ClaytonMullis,MitchellWortsman,PatrickSchramowski,
SrivatsaKundurthy,KatherineCrowson,LudwigSchmidt,RobertKaczmarczyk,andJeniaJitsev.
Laion-5b:Anopenlarge-scaledatasetfortrainingnextgenerationimage-textmodels,2022.URL
https://arxiv.org/abs/2210.08402.
KarenSimonyanandAndrewZisserman. Verydeepconvolutionalnetworksforlarge-scaleimage
recognition,2015. URLhttps://arxiv.org/abs/1409.1556.
JaschaSohl-Dickstein, EricA.Weiss, NiruMaheswaranathan, andSuryaGanguli. Deepunsuper-
vised learning using nonequilibrium thermodynamics, 2015. URL https://arxiv.org/
abs/1503.03585.
JiamingSong,ChenlinMeng,andStefanoErmon. Denoisingdiffusionimplicitmodels,2022. URL
https://arxiv.org/abs/2010.02502.
YangSongandStefanoErmon.Generativemodelingbyestimatinggradientsofthedatadistribution,
2020. URLhttps://arxiv.org/abs/1907.05600.
Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever. Consistency models, 2023. URL
https://arxiv.org/abs/2303.01469.
ArashVahdat,KarstenKreis,andJanKautz.Score-basedgenerativemodelinginlatentspace,2021.
URLhttps://arxiv.org/abs/2106.05931.
AaronvandenOord,OriolVinyals,andKorayKavukcuoglu. Neuraldiscreterepresentationlearn-
ing,2018. URLhttps://arxiv.org/abs/1711.00937.
Sheng-YuWang,OliverWang,RichardZhang,AndrewOwens,andAlexeiA.Efros.Cnn-generated
images are surprisingly easy to spot... for now, 2020. URL https://arxiv.org/abs/
1912.11035.
Zhendong Wang, Jianmin Bao, Wengang Zhou, Weilun Wang, Hezhen Hu, Hong Chen, and
Houqiang Li. Dire for diffusion-generated image detection, 2023. URL https://arxiv.
org/abs/2303.09295.
13Preprint. Underreview.
Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xiao. Lsun:
Construction of a large-scale image dataset using deep learning with humans in the loop, 2016.
URLhttps://arxiv.org/abs/1506.03365.
RichardZhang,PhillipIsola,AlexeiA.Efros,EliShechtman,andOliverWang. Theunreasonable
effectivenessofdeepfeaturesasaperceptualmetric,2018.URLhttps://arxiv.org/abs/
1801.03924.
Chuanxia Zheng, Long Tung Vuong, Jianfei Cai, and Dinh Phung. Movq: Modulating quantized
vectors for high-fidelity image generation, 2022. URL https://arxiv.org/abs/2209.
09002.
A APPENDIX
A.1 IMPLEMENTATIONDETAILS
A.1.1 ADDITIONALTRAININGDETAILS
WefollowthetrainingrecipeusedbyCorvietal.(2022). Wetrainon96x96cropsofthewhole
imageusingabatchsizeof128. ThedataaugmentationsincluderandomJPGcompressionandblur
fromthepipelineproposedbyWangetal.(2020). FollowingGragnanielloetal.(2021),grayscale,
cutout and random noise are also used as augmentations. Finally, in order to make the network
invarianttowardsresizing,therandomresizedcropwasadded. ForourmethodaswellasCorvi,we
trainthemodelusingtwodifferentrandomseedsandreporttheaveragereading.
We use the validation set provided by Corvi et al. (2022) for our training. Just like our training
set,therealimagescomefromCOCO/LSUNandthefakeimagesaregeneratedat256x256using
LDM.Duringtraining,ifthevalidationaccuracydoesnotimproveby0.1%in10epochsthelearning
rateisdroppedby10x. Thetrainingisterminatedatlearningrate10−6.
Datasetdetails: WeusethedatasetprovidedbyCorvietal.(2022). Halfoftherealimagescome
fromLSUN(Yuetal.,2016),theremainingcomesfromCOCO(Linetal.,2015). Thereareatotal
of 90,000 images from COCO out of which most of them are high resolution images. The most
frequentlyoccurringresolutionsare640x480and640x427whichoccur19,581and11,292times
respectively. Forfurtherdetails,wereferthereadertothedownloadlink3 providedbyCorvietal.
(2022).
A.1.2 SHADERSEXPERIMENTDETAILS
Datasetdetails: Allourimagesareataresolutionof384x384. Byinspectingthecodeusedby
Baradadetal.(2023),wefigureouttheexactpost-processingdoneonourimages. Theyweresaved
intheJPGformat. Therefore,wealsosaveourfakeimagesintheJPGformat(quality ∼[70,100])
tomakesurethatthedetectordoesnotfocusoncompressionartifacts.
Training and Evaluation details: We train our detectors using the configurations from before
(refer Appendix A.1.1). In addition, we use the same validation set to compute the threshold for
classification. It is important to notice that our validation set consists of natural looking images.
We take 5000 real and fake images each from the validation set, and apply compression, resizing,
blurandcolorjitteroperationstotheseimages. WeevaluateallthemodelslistedinTable3onthe
validation set, selecting the threshold for each model that achieves the best accuracy. We use this
thresholdwhenevaluatingthemodelonthetestset.
A.1.3 EVALUATIONOFAEROBLADE
AEROBLADE (Ricker et al., 2024) is a training-free reconstruction based fake image detection
technique. The first requirement is to collect an ensemble of VAE’s of prominent latent diffusion
models. Given an image, it is first reconstructed using the VAE and then the reconstruction is
saved. TheoriginalimageaswellasthereconstructionarepassedthroughtheVGG16(Simonyan
3https://github.com/grip-unina/DMimageDetection/tree/main/training_code
14Preprint. Underreview.
&Zisserman,2015)andtheLPIPSdistanceiscomputed. Thekeyhypothesisisthat,afakeimage
canbereconstructedinaneasiermannerthanarealimage,thereforethedistancewillbelower. In
thepaper,theauthorsprovideaplotshowingthedistributionofrealandfakeimages. Basedonthis
plotandourtrialswiththemodel,wepickathresholdof0.018forclassification.
A.2 ABLATIONS
A.2.1 EFFECTOFDATASETSIZE
We study the effect of training dataset size on our methods and Corvi. Instead of training on all
179,257 images, we try training each method using smaller dataset sizes. We test by sampling of
1000, 10,000, 50,000 and 100,000 real and fake images each from our training distribution and
report the results here. We evaluate the detectors based on their performance on the whole test
datasetfromSection5.4. Ourrealdistributionhas6000images,consistingofboththeoriginaland
post-processed real images. We have 30,000 images in our fake distribution coming from the 6
modelsthatweteston. Furthermore, inordertodisentangletheeffectsofresizing, wedonotuse
resizingaspartofpost-processinghere. Duetotheimbalancednatureofthedataset,wereportthe
truepositiverate(TPR)atafixedfalsepostiverateof5%.
DatasetComposition Corvi Ours Ours-Sync
1k/1k 46.51 83.37 80.43
10k/10k 87.64 98.13 98.58
50k/50k 93.27 99.56 99.81
100k/100k 95.84 99.69 99.75
Table 4: Effects of varying the dataset size. We report the TPR@5FPR for detectors trained
on lesser data. Using an aligned dataset helps the model learn a good hypothesis with less data.
Ours/Ours-Sync shows improvements of +36.86/33.92, +10.49/10.94, +6.29/6.54 and +3.85/3.91
overCorviwhentrainedwith1k,10k,50kand100kimages(each)respectively.
WereportourresultsinTable4. Whentrainingonasmalldatasetsizeof1krealandfakeimages
each, the Corvi detector can detect only 46.51% of the fake images while allowing having a 5%
false positive rate. Ours and Ours-Sync on the other hand, can detect 83.37% and 80.43% of the
fakeimagesrespectivelyatthesamethreshold. Asimilarpatterncanbeseenwithdatasetsizesof
10k,50kand100kimageseach,thisshowsthatCorvineedsalargedatasetsizeinordertolearnthe
correcthypothesis. Asoppposedtoours,whichcanlearnitinadata-efficientmanner.
A.2.2 FALSEPATTERNLEARNINGINOJHA-LDM
Ojha et al. (2024) train a Universal Fake Image detector by linear probing a CLIP backbone on
ProGAN (Karras et al., 2018) generated images. However, they also train a version trained on
LAION (Schuhmann et al., 2022) and LDM (Rombach et al., 2022) images. This model (Ojha-
LDM) ends up associating downsampling with real images. We demonstrate this using a simple
experiment. First evaluate Ojha-LDM on our set of real images and SD generated images. Now
downsamplebothsetsofimagesto256x256andmeasuretheperformanceagain.
Real SD
Original 54.16 69.56
Downsampledto256x256 83.58 29.83
Table 5: Effects of resizing on Ojha-LDM. Real accuracy improves when the same real images
aredownsampled. ThefakeaccuracyonSDimagesalsodrops. Thisshowsthatimageswhichhave
downsamplingartifactsarelikelytobeidentifiedasrealimagesbyOjha-LDM.
Table5showstheresultsofourexperiment. Wecanseethatdownsamplingrealimagesincreases
thechanceofthedetectoridentifyingthem. Butatthesametime,thefakeaccuracydecreases.
15Preprint. Underreview.
Analysis: Such false patterns are also caused by lack of a well-aligned real-vs-fake dataset. We
lookintothedatasetthatOjha-LDMwastrainedon. TheirfakeimagescomefromLDM,andare
generated at a resolution of 256 x 256. However, their real images which come from LAION are
presentinavarietyofresolutions. However,theywereresizedto256x256duringtraining. During
training,themodelisabletousesomeoftheseartifactstofitthetrainingdistribution. Thisfurther
suggests that without proper dataset alignment, the detector can very easily pick up on spurious
featurespresentinthedata.
16