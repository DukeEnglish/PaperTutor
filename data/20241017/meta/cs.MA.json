[
    {
        "title": "G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks",
        "authors": "Guibin ZhangYanwei YueXiangguo SunGuancheng WanMiao YuJunfeng FangKun WangDawei Cheng",
        "links": "http://arxiv.org/abs/2410.11782v1",
        "entry_id": "http://arxiv.org/abs/2410.11782v1",
        "pdf_url": "http://arxiv.org/pdf/2410.11782v1",
        "summary": "Recent advancements in large language model (LLM)-based agents have\ndemonstrated that collective intelligence can significantly surpass the\ncapabilities of individual agents, primarily due to well-crafted inter-agent\ncommunication topologies. Despite the diverse and high-performing designs\navailable, practitioners often face confusion when selecting the most effective\npipeline for their specific task: \\textit{Which topology is the best choice for\nmy task, avoiding unnecessary communication token overhead while ensuring\nhigh-quality solution?} In response to this dilemma, we introduce G-Designer,\nan adaptive, efficient, and robust solution for multi-agent deployment, which\ndynamically designs task-aware, customized communication topologies.\nSpecifically, G-Designer models the multi-agent system as a multi-agent\nnetwork, leveraging a variational graph auto-encoder to encode both the nodes\n(agents) and a task-specific virtual node, and decodes a task-adaptive and\nhigh-performing communication topology. Extensive experiments on six benchmarks\nshowcase that G-Designer is: \\textbf{(1) high-performing}, achieving superior\nresults on MMLU with accuracy at $84.50\\%$ and on HumanEval with pass@1 at\n$89.90\\%$; \\textbf{(2) task-adaptive}, architecting communication protocols\ntailored to task difficulty, reducing token consumption by up to $95.33\\%$ on\nHumanEval; and \\textbf{(3) adversarially robust}, defending against agent\nadversarial attacks with merely $0.3\\%$ accuracy drop.",
        "updated": "2024-10-15 17:01:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.11782v1"
    },
    {
        "title": "Improve Value Estimation of Q Function and Reshape Reward with Monte Carlo Tree Search",
        "authors": "Jiamian Li",
        "links": "http://arxiv.org/abs/2410.11642v1",
        "entry_id": "http://arxiv.org/abs/2410.11642v1",
        "pdf_url": "http://arxiv.org/pdf/2410.11642v1",
        "summary": "Reinforcement learning has achieved remarkable success in perfect information\ngames such as Go and Atari, enabling agents to compete at the highest levels\nagainst human players. However, research in reinforcement learning for\nimperfect information games has been relatively limited due to the more complex\ngame structures and randomness. Traditional methods face challenges in training\nand improving performance in imperfect information games due to issues like\ninaccurate Q value estimation and reward sparsity. In this paper, we focus on\nUno, an imperfect information game, and aim to address these problems by\nreducing Q value overestimation and reshaping reward function. We propose a\nnovel algorithm that utilizes Monte Carlo Tree Search to improve the value\nestimation in Q function. Even though we choose Double Deep Q Learning as the\nfoundational framework in this paper, our method can be generalized and used in\nany algorithm which needs Q value estimation, such as the Actor-Critic.\nAdditionally, we employ Monte Carlo Tree Search to reshape the reward structure\nin the game environment. We compared our algorithm with several traditional\nmethods applied to games such as Double Deep Q Learning, Deep Monte Carlo and\nNeural Fictitious Self Play, and the experiments demonstrate that our algorithm\nconsistently outperforms these approaches, especially as the number of players\nin Uno increases, indicating a higher level of difficulty.",
        "updated": "2024-10-15 14:31:54 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.11642v1"
    },
    {
        "title": "Agent-Based Modelling of Older Adult Needs for Autonomous Mobility-on-Demand: A Case Study in Winnipeg, Canada",
        "authors": "Manon PrédhumeauEd Manley",
        "links": "http://arxiv.org/abs/2410.11416v1",
        "entry_id": "http://arxiv.org/abs/2410.11416v1",
        "pdf_url": "http://arxiv.org/pdf/2410.11416v1",
        "summary": "As the populations continue to age across many nations, ensuring accessible\nand efficient transportation options for older adults has become an\nincreasingly important concern. Autonomous Mobility-on-Demand (AMoD) systems\nhave emerged as a potential solution to address the needs faced by older adults\nin their daily mobility. However, estimation of older adult mobility needs, and\nhow they vary over space and time, is crucial for effective planning and\nimplementation of such service, and conventional four-step approaches lack the\ngranularity to fully account for these needs. To address this challenge, we\npropose an agent-based model of older adults mobility demand in Winnipeg,\nCanada. The model is built for 2022 using primarily open data, and is\nimplemented in the Multi-Agent Transport Simulation (MATSim) toolkit. After\ncalibration to accurately reproduce observed travel behaviors, a new AMoD\nservice is tested in simulation and its potential adoption among Winnipeg older\nadults is explored. The model can help policy makers to estimate the needs of\nthe elderly populations for door-to-door transportation and can guide the\ndesign of AMoD transport systems.",
        "updated": "2024-10-15 09:03:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.11416v1"
    },
    {
        "title": "STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack",
        "authors": "Naman GuptaShashank KirtaniaPriyanshu GuptaKrishna KariyaSumit GulwaniArun IyerSuresh ParthasarathyArjun RadhakrishnaSriram K. RajamaniGustavo Soares",
        "links": "http://arxiv.org/abs/2410.10584v1",
        "entry_id": "http://arxiv.org/abs/2410.10584v1",
        "pdf_url": "http://arxiv.org/pdf/2410.10584v1",
        "summary": "Large Language Models (LLMs) often generate incorrect or outdated\ninformation, especially in low-resource settings or when dealing with private\ndata. To address this, Retrieval-Augmented Generation (RAG) uses external\nknowledge bases (KBs), but these can also suffer from inaccuracies. We\nintroduce STACKFEED, a novel Structured Textual Actor-Critic Knowledge base\nediting with FEEDback approach that iteratively refines the KB based on expert\nfeedback using a multi-actor, centralized critic reinforcement learning\nframework. Each document is assigned to an actor, modeled as a ReACT agent,\nwhich performs structured edits based on document-specific targeted\ninstructions from a centralized critic. Experimental results show that\nSTACKFEED significantly improves KB quality and RAG system performance,\nenhancing accuracy by up to 8% over baselines.",
        "updated": "2024-10-14 14:56:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.10584v1"
    },
    {
        "title": "Content Caching-Assisted Vehicular Edge Computing Using Multi-Agent Graph Attention Reinforcement Learning",
        "authors": "Jinjin ShenYan LinYijin ZhangWeibin ZhangFeng ShuJun Li",
        "links": "http://arxiv.org/abs/2410.10071v1",
        "entry_id": "http://arxiv.org/abs/2410.10071v1",
        "pdf_url": "http://arxiv.org/pdf/2410.10071v1",
        "summary": "In order to avoid repeated task offloading and realize the reuse of popular\ntask computing results, we construct a novel content caching-assisted vehicular\nedge computing (VEC) framework. In the face of irregular network topology and\nunknown environmental dynamics, we further propose a multi-agent graph\nattention reinforcement learning (MGARL) based edge caching scheme, which\nutilizes the graph attention convolution kernel to integrate the neighboring\nnodes' features of each agent and further enhance the cooperation among agents.\nOur simulation results show that our proposed scheme is capable of improving\nthe utilization of caching resources while reducing the long-term task\ncomputing latency compared to the baselines.",
        "updated": "2024-10-14 01:25:56 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.10071v1"
    }
]