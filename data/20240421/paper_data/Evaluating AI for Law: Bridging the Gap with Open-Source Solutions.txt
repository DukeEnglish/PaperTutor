Evaluating AI for Law: Bridging the Gap with
Open-Source Solutions
Rohan Bhambhoria1,2[0000−0002−2597−670X],
Samuel Dahan1,2,3[0000−0002−1079−8998],
Jonathan Li2[0000−0002−7095−805X], and
Xiaodan Zhu1,2[0000−0003−3856−3696]
1 Queen’s University, Kingston ON K7L3N6, Canada
{r.bhambhoria, samuel.dahan, jxl, xiaodan.zhu}@queensu.ca
2 Ingenuity Labs
3 Cornell University
Abstract. Thisstudyevaluatestheperformanceofgeneral-purposeAI,
likeChatGPT,inlegalquestion-answeringtasks,highlightingsignificant
risks to legal professionals and clients. It suggests leveraging founda-
tionalmodelsenhancedbydomain-specificknowledgetoovercomethese
issues. The paper advocates for creating open-source legal AI systems
to improve accuracy, transparency, and narrative diversity, addressing
general AI’s shortcomings in legal contexts.
Keywords: Law · Open-Source · Large Language Models.
1 Introduction
In recent times, the rise of Large Language Models (LLMs) has become promi-
nent, especially with the unprecedented growth of ChatGPT, marking it as the
fastest-expanding consumer application to date. LLMs have shown extensive
utility in tasks related to productivity and in systems designed for low-stakes
decision-making, such as composing emails. However, its application in high-
stakesdecision-makingareas,includingcontractdraftingormedicaldiagnostics,
is met with cautious adaptation due to concerns about its large-scale deploy-
ment. AI models are notorious bullshitters [1].
We believe that Artificial Intelligence-powered legal advice, or ”legal AI,”
canimproveaccesstojusticeandcontributemorebroadlytothepracticeoflaw,
increasing the percentage of adequately-represented litigants and driving down
legal fees and the cost of legal research (Dahan and Liang 2020; Surden 2019).
ResearchhasshownthatlegalAIcansuccessfullyassistself-representedlitigants
with tasks such as determining the validity of a claim, online dispute resolution
and court filing (Dahan et al. 2020; 2023). However, AI remains plagued with
limitations, including the phenomenon of “hallucination” and the potential for
biasedadvice[10];andthereisgrowingevidenceofreliance–evenoverreliance–
ontheuseofgenerativeAItoolsforlegaladvice.Alarmingly,thisistrueamong
4202
rpA
81
]IA.sc[
1v94321.4042:viXra2 R. Bhambhoria et al.
both self-represented litigants and legal practitioners themselves [10] (Merken
2023, Little 2024).
The problem is further exacerbated by the proliferation of so-called AI ap-
plications specialised for law, many of which are actually general-purpose AIs
papered over with a legal interface. These applications, misleadingly presented
as specialized legal tools, mask the underlying limitations of the technology.
It should be noted that some large legal database providers have introduced
genuine generative AIs for law. However, these systems, which are closed, raise
transparency and accessibility concerns; conflict with the movement towards
openscience;andhinderunderstandingofAIknowledge[22].Furthermore,these
technologies are accessible primarily by large firms, thus offering limited benefit
to broader legal communities and doing nothing to improve access to justice.
Finally, current regulations, such as the EU AI Act and Canada’s AIDA
(Artificial Intelligence and Data Act ), do not yet provide solid benchmarks for
addressing these issues. Policymakers need to debate the accessibility, quality,
impact, and design of legal AI in order to produce industry standards for its
creation and use. Anything less not only hinders access to justice, but risks
hurting the very people who stand to gain the most from its development.
We propose two solutions to address the identified challenges: (i) revising
benchmarks and protocols to evaluating legal AI’s performance capabilities and
limitations in real-world settings, and (ii) based on performance findings, cre-
ating a domain-specific, open-source language model interface that allows for
diverse feedback collection.
Acknowledging the current AI regulations’ inadequacies in managing gener-
ative AI’s risks in legal contexts, we advocate for a sector-specific approach to
definereliablelegalAIsystems.Thisincludesdevelopingbenchmarksspecifically
tailored to legal challenges, focusing on legal misinformation, transparency, and
diversity in narrative representation. Utilizing computational benchmarking, we
aim to develop evaluation metrics centered on Bias Risk, Fact-Checking, Le-
gal Reasoning Ability, and Narrative Construction Diversity for application in
question-answering tasks.
Drawing from performance insights, we explore legal AI solutions that may
showsignificantimprovementovergeneral-purposeAI.Specifically,wehighlight
the potential of an open-source approach through www.OpenJustice.ai—a plat-
form that encourages collaborative and crowdsourced efforts to design and test
custom AI solutions for legal professionals and aid centers. This approach pro-
motes a transparent and inclusive method of AI development, allowing diverse
perspectives and expertise to contribute to more ethical and robust AI systems.
An essential aspect of this domain-specific solution is the emphasis on data
curation. The quality of data used to train these models is crucial for their
reliability and effectiveness [35]. Proper data curation entails not only gather-
ing extensive and diverse datasets but also ensuring the data is representative,
unbiased, and pertinent to the specific legal applications.A Call for an Open-source Legal Language Model 3
2 Background: AI Is Not Yet Ready for Law
Recent studies indicate a concerning trend in artificial intelligence: the as-yet-
unexplained ”drifting” phenomenon, characterized by significant fluctuations in
AI’s capabilities (Chen, Zaharia, and Zou 2023). For example, in one study, an
AI system’s accuracy rate in solving basic math problems dropped from 98% to
2% in the space of months. Certainly in the legal context, evidence has shown
that despite AI’s capacity to perform some legal tasks—even passing the bar
exam (Katz et al. 2023)—the technology has not yet fully matured. Generative
AI is prone to “hallucinating” inaccurate responses with confidence, offering
biased advice and erroneous citations (Chen et al. 2023). A further problem is
that Large Language Models (LLMs) tend to reflect a mainstream worldview.
When they are a primary source of AI training data, feedback loops are created
wherein AI-generated texts are reincorporated into the web, creating “AI echo
chambers” (Shur-Ofry 2023, 30).
1.Hallucinations,andconfidentregurgitation.Recentstudieshavedemon-
strated that generative AI is capable of executing a variety of legal tasks and
has even successfully passed the bar examination [5]. However, the technology
still has significant limitations. A well-documented issue with generative AI ar-
chitecturesistheirtendencytoproducehallucinated responses.Theseresponses
are characterized by high confidence levels in presenting incorrect information,
including the fabrication of facts, citations, and details. Generalized Large Lan-
guage Models (LLMs) such as ChatGPT operate by predicting a sequence of
wordsthatlogicallyfollowsaninitialuser-providedinput.Thisprocessincorpo-
rates an element of creativity, wherein the model randomly selects elements of
a sentence from a set of probable responses. This method, while innovative, also
contributestothechallengeofensuringaccuracyandreliabilityinthegenerated
content, particularly in contexts that demand high precision, like legal tasks.
In essence, AI systems primarily operate on statistical principles and thus
possess limited comprehension capabilities, particularly in specialized domains
such as law. The generative models currently in use demonstrate a notable de-
ficiency in capturing the semantic subtleties inherent in legal terminology. This
limitation is exemplified by the varying interpretations of the same legal term
across different jurisdictions. For instance, the term layoff is interpreted as sus-
pension inCanada,whereasitdenotestermination intheUnitedStates.Amore
pressing concern is the deceptive proficiency of generative AI systems in under-
standinglegalconcepts.Despiteappearances,thesesystemsoftenlackthecapa-
bility for counterfactual legal reasoning or the classification of different modes
of legal reasoning. This shortfall highlights the gap between the apparent and
actual capabilities of AI in complex, context-dependent fields such as law [6].
Thislimitationmaybeinconsequentialfortasksthatarestatisticalinnature,
suchastheretrievaloflegalprecedentsortheapplicationofstraightforwardrules
to facts. However, it presents a significant challenge for more complex legal rea-
soningtasks,whichrequireamultidimensionalapproachandanin-depthunder-
standing of legal issues. Beyond the problem of hallucinations or the generation
of inaccurate content, there are also concerns regarding biased analyses. This4 R. Bhambhoria et al.
is a well-documented issue in the application of predictive AI in legal contexts,
as referenced in [7] and [8]. For instance, ChatGPT, like many AI systems, has
been shown to exhibit biases that are commonly observed in human reasoning.
These include conjunction bias, probability weighting, overconfidence, framing
effects, anticipated regret, reference dependence, and confirmation bias, as de-
tailed in [9]. Such biases can significantly affect the objectivity and reliability of
AI-generated legal analyses, underscoring the need for cautious application and
rigorous evaluation of these technologies in legal settings.
2. Lack of diversity in generated responses. Theimplicationsofemploying
LargeLanguageModels(LLMs)intherealmofcomputationallinguisticsarenot
limited to issues of inaccuracies or the dissemination of misinformation in legal
contexts.AsignificantconcernarisesevenwhengenerativeAIsystemslikeLLMs
provide accurate information. These concerns stem from the inherent tendency
of general-purpose LLMs to replicate dominant worldviews. If LLMs become a
prevalent source of information, there is a potential for creating feedback loops.
In such scenarios, the text generated by LLMs could re-enter the digital ecosys-
tem,effectivelybecomingpartofthetrainingdatasetforsubsequentgenerations
oftext-generatingmodels.ThiscouldleadtothedevelopmentofAI echo cham-
bers, as articulated in [4]. Such chambers could substantially limit the diversity
of thought, posing a risk to the breadth of intellectual discourse and possibly
affecting the development of AI systems in ways that could hinder cultural di-
versity, narrative plurality, and the dynamism of democratic discourse.
3. Linear Reasoning. In the development and application of Large Language
Models (LLMs) for legal domains, several critical issues emerge. Unlike fields
with clear, mathematical solutions, law encompasses a spectrum of acceptable
answers and allows for considerable discretion. This characteristic renders the
useofLLMsinlegalcontextsnotmerelyastoolsforinformationretrieval,butas
systems that inherently shape the representation of legal information. The first
concern with such LLMs is the presumption that legal issues are algorithmic,
necessitating straightforward solutions. This assumption contradicts the reality
of legal practice, where different lawyers and judges often propose divergent
solutionstoidenticallegalscenarios,asevidencedinsources[23,7,24].Acommon
lawyer’s response, it depends, highlights this variability.
4. Lack of temporal dimension in legal applications. LLMs often operate
on the assumption that the facts and contexts of future legal cases will mirror
thoseofthepast,disregardingthedynamicnatureofsocialcontextsthatcontin-
uously introduce new facts and legal challenges. This approach risks stagnating
the legal field, potentially leading to the ossification and de-norming of law.
5. Static training databases. Afurthercomplicationarisesfromtheopaque-
ness of generative AI systems like LLMs, which often cannot cite their informa-
tion sources. This is particularly problematic in legal practice, where the sub-
stantiationofargumentswithappropriatelegalcitationsiscrucial.Theinability
of LLMs to reliably cite sources, and their tendency to generate fictitious case
law or legislation poses significant risks. While models like GPT-4 have shown
capabilities to reference relevant statutes and legal authorities, they continueA Call for an Open-source Legal Language Model 5
to exhibit limitations in generating accurate connections and in incorporating
new legal developments, given their training on a static dataset representing a
snapshot of the internet at a particular time.
Yet, despite these sizable concerns, there is little empirical data about AI
performance in legal context. Most knowledge stems from GPT-4’s varied per-
formance on legal exams [11,12,13] and discrete questions [14,15], alongside the-
oretical discussions on AI’s ethical use [16] and its impact on legal skills and
firm competitiveness [17]. Research reveals GPT-4’s inconsistent exam results
and its challenges in issue identification and rule application, noting its poten-
tial to assist lower-performing students without benefiting top achievers [18].
Limited evidence exists outside exams, with some studies highlighting AI’s po-
tential in legal reasoning and others cautioning against overreliance due to AI’s
hallucinations and misinterpretations.
In fact LegalBench [19] is a collaborative project designed to benchmark the
legal reasoning capabilities of Large Language Models (LLMs) using the IRAC
framework.ItsgoalistoassesshowwellcurrentAImodelscansupportandaug-
ment legal reasoning, particularly in administrative and transactional settings,
without aiming to replace legal professionals. In contrast, our project diverges
byfocusingonapplyingAItopractical,real-worldlegaltasksthroughadomain-
specific, open-source platform. We aim to directly evaluate AI’s effectiveness in
performing tasks that mirror the day-to-day work of legal professionals, moving
beyond theoretical benchmarks to assess practical utility and integration into
legal workflows.
Contrastingly, recent work investigates AI’s capabilities in contract review,
a narrowly defined task where AI has been shown to excel, even outperforming
lawyers in previous studies [20,21]. This focus contrasts with our project, which
extends beyond document analysis to cover a broader range of practical legal
tasks through a domain-specific, open-source platform, aiming to assess AI’s
utility in a wider legal context.
Finally, recent work by Choi et al, presents meaningful insights into how AI
mayaugmenttheperformanceofsomelawyers,particularlythelower-performing
ones. However, it also primarily focuses on tasks that are relatively easier for
LLMs, such as drafting legal documents and answering hypothetical questions
with provided materials. Our project aims to bridge these gaps by providing a
more detailed and nuanced examination of AI’s capabilities and deficiencies in
a broader range of legal tasks, moving beyond the realms explored by the afore-
mentioned studies. This endeavor not only highlights AI’s current limitations
in legal practice but also advocates for a targeted approach towards develop-
ing domain-specific, open-source legal AI solutions to address these challenges
effectively.
Our preliminary study aims to advance the literature on AI benchmarking
focusingonevaluatingGPT-4’sassistanceinpracticallawyering[18]tasks-espe-
ciallyQuestion-Answer,aimingtoadvancetheunderstandingofAI’squalitative
impacts in law.6 R. Bhambhoria et al.
(a) LegalQA: Distributions of Sequence Lengths
Question Token Length
600 Response Token Length
500
400
300
200
100
0
0 200 400 600 800 1000 1200 1400
Length (in Tokens)
(b) Law Stack Exchange: Distributions of Sequence Lengths
40 Question Token Length
Response Token Length
30
20
10
0
0 200 400 600 800 1000 1200 1400
Length (in Tokens)
Fig.1: Distribution of sequence lengths for LegalQA and Law Stack Exchange.
We measure the length in tokens (with byte-pair encoding) and combine the
train and test sets.
3 Datasets and Statistics
In this work, we curate a legal QA benchmark to reflect real-world scenarios.
Existing legal benchmarks, such as LegalBench [34], often lack real-world hy-
pothetical and document analysis aspects present in real-world legal challenges.
Specifically,mostLegalBenchtasksareclassificationproblems,whichfailtoeval-
uate various dimensions desirable for a language model in aiding laypeople with
legal tasks.
Tothisend,wecurateLegalQA,ahigh-qualitydatasetofover2000questions
asked by laypeople on real legal questions and answers vetted by legal experts.
Weasklawstudentstowriteexpertanswerstothesequestions(processdescribed
in more detail in Section 3.1). The questions are sourced from an online legal
community4.
Inconjunctionwithournewdataset,wealsosourceadditionallegalquestions
from Law Stack Exchange and collect the 200 most popular questions on the
4 https://reddit.com/r/legaladvice
selpmaS
fo
rebmuN
selpmaS
fo
rebmuNA Call for an Open-source Legal Language Model 7
site(toserveasaproxyforquestionsthatpeoplefindinteresting/challengingto
solve). Then, we use the top-voted answer for each question as the expert label.
These two datasets, from differing online platforms, address different do-
mains.Forexample,thelongersequencelengthsvisibleinFigure1reflectdiffer-
encesindatacollectionmethodologies;weencourageourlawstudentstoanswer
the question as concisely as possible (while addressing everything in the ques-
tion),whereastopstackexchangeanswersoftendirectlycopyalongblockquota-
tion to cite their sources clearly, increasing length. Together, these two datasets
provide an evaluation of a model’s capabilities of addressing a layperson’s legal
concerns across various settings.
3.1 Annotation Guidelines
Wedesignedadatalabellingproceduretobuildthemostrobustanswers.Follow-
ingprinciplesdescribedinSection6.2,weaskourhumanannotatorstohighlight
relevantfactsinthelegalquestion,writeaconciseanswer,andprovidealinkto
a reliable source of further reading.
Since our law students are trained under Canadian law, we ask law students
toconsiderquestionsonU.S.lawfromaCanadianperspective.Ifitisimpossible
tocontextualizewithinaCanadianlegalframework(e.g.,ifthequestionconcerns
specificgunlaws),thenweomitthisdata.Otherwise,ifthequestionasksabout
the law that is answerable with Canadian law, then our annotators will treat it
under a Canadian context. We consider these laws from a Canadian perspective
to maintain annotations that are verifiable by our Canadian legal experts.
Regarding the format of answers, we ask annotators to limit answers to 200-
300characters,andtostayasclosetotheevidenceaspossible—thisistomirrora
real-worldlegalenvironmentwheremakingconciseandevidence-drivenanswers
isimportant.Additionally,weaskannotatorstoavoidusinglegaleseandexplain
intermsunderstandablebyageneralaudience(thetargetaudience).Weinclude
an example annotation in Table 1.
4 Experimental Setup
To evaluate the landscape of current language models, we run experiments on
state-of-the-art closed and open-sourced models. Specifically, we evaluate Ope-
nAI’s most recent GPT-4 model, GPT-4-Turbo-1106 (hereinafter called “GPT-
4”) since it is the state-of-the-art general-purpose language model at the time
of writing. For the open-sourced model, we evaluated Mixtral-8x7B5, a state-of-
the-art mixture of experts chat-aligned language model with 46.7B parameters.
We evaluate the factuality (as opposed to style) of the resulting generations.
Since the real-world nature of this benchmark facilitates open-ended responses,
it is difficult to evaluate model responses without human feedback. As a proxy
for human evaluation, we evaluate the generated answers relative to the expert
5 https://mistral.ai/news/mixtral-of-experts/8 R. Bhambhoria et al.
Source ... my partner and I have been renting from a deadbeat property
management company for the last year. There was a maintenance
issue and a flooding issue 2 months after we moved in. We brought
totheirattention,theygaveitabandaidfixandhavebeenignoring
any contact since (I have records of all of the attempts to contact
them). We have called, texted, emailed, and my partner even went
to their office to try and speak to someone and basically got blown
off by the guy at the front desk who is one of the main agents for
thiscompany.Luckily,theissuehasn’tcauseddamagetoanyofour
personal property, but if it goes unfixed will inevitably damage the
houseitselfandbecomeamuchbiggerissue.Sufficetosay,we’renot
interested in continuing to rent from them. The issue I’m seeking
advice on is that we got an email asking if we’re interested in re-
newing (for $50 more a month for another 12 months) and they
are requesting we give notice by 3/1 if we intend to vacate. Our
leasewesignedsayswemustprovidenoticeby3/31,not3/1.It’sa
difficulttimeallaroundtofindanewplacetorentthatfitsintoour
timelineandbudgetandIwantasmuchtimeaswecansowedon’t
have to overlap leasing and also to guarantee we can actually find
somethingbeforeourleaseisupattheendofApril.Somyquestion
is: should/can I send an email saying the lease we signed says we
don’thavetogivenoticeuntil3/31whetherornotwe’llrenewand
thattheycanexpectouranswerthen?Althoughtheycanrequestwe
give them more advanced notice, contractually, I don’t think we’re
obligated to. Any advice would be greatly appreciated and thanks
for taking the time to read this.
Provided answer InOntario,inafixed-termtenancy,youmustgiveatleasta60-day
notice before the end of the lease. If not the tenancy continues. If
the tenancy agreement does not say what happens after the end
of the fixed-term, your lease will continue on a month-to-month
basis automatically. A landlord cannot force you to agree to end a
tenancy”.
Provided citationhttps://www.siskinds.com/pet-custody-laws-in-ontario
Table 1: Example question (“source”) and provided answers and citation. The
highlighted green portion denotes the relevant facts indicated by the annotator.
answerautomaticallywithalanguagemodel,basedontheopensourceautomatic
evaluationrepository,OpenAIEvals6.AsOpenAIEvalswerecreatedforgeneral-
purpose evaluations, we would like to highlight the need and requirement for
improvementsinthelegaldomain.WeuseGPT-4forthisautomaticevaluation,
asking it to compare the model-generated answer to the expert answer, and
indicatingiftheanswerisasubsetoftheexpertanswer,asupersetoftheexpert
answer,containsthesamedetailsastheexpertanswer,disagreeswiththeexpert
answer,oranswersthequestioninaincomparablewaytotheexpertanswer(see
6 https://github.com/openai/evalsA Call for an Open-source Legal Language Model 9
CategoryDescription
A (⊂) Thesubmittedanswerisasubsetoftheexpertanswerandisfullyconsistent
with it.
B (⊃) Thesubmittedanswerisasupersetoftheexpertanswerandisfullyconsis-
tent with it.
C (=) The submitted answer contains all the same details as the expert answer.
D (̸=) There is a disagreement between the submitted answer and the expert an-
swer.
?
E (≈) It is not possible to compare the answers directly for factuality because the
submittedansweraddressesthequestiondifferentlyfromtheexpertanswer.
Table 2: Classes used to automatically evaluate the factuality of model genera-
tions.
(a) LegalQA (b) Law Stack Exchange
1.0 1.0
Model Model
mixtral-8x7B mixtral-8x7B
0.8 gpt-3.5-turbo 0.8 gpt-3.5-turbo
gpt-4-turbo-1106 gpt-4-turbo-1106
0.6 0.6
0.4 0.4
0.2 0.2
0.0 0.0
A ( ) B ( ) C (=) D ( ) E ( ) A ( ) B ( ) C (=) D ( ) E ( )
Factuality Evaluation Factuality Evaluation
Fig.2: Automatic evaluation results for (a) LegalQA and (b) Law Stack Ex-
change. Experimental setting described in Section 3.1
Table 2). Then, we ask legal experts to review the model’s evaluations to assess
their reliability.
Our experiments reveal two insights. First, they evaluate various models in
legal question answering. Second, they shed light on the capabilities of language
models to be used for evaluation—something that is now done regularly in the
general domain but underexplored in the legal domain.
5 Results and Discussion
In this section we conduct experiments showcasing the ability of large language
models in a practical legal question-answering task. Different from benchmarks
cite legal bench, our task reflects real-world experimental settings.
tnuoC tnuoC10 R. Bhambhoria et al.
Apparent in Figure 2, the state-of-the-art language model GPT-4 seems to
perform relatively well on the LegalQA task, with under 5% of examples con-
taining factually incorrect responses. However, we observe that Mixtral 8x7B, a
state-of-the-art open language model, falls significantly behind.
Additionally, we hypothesize that a large language model does not evaluate
legal texts in the same way as a skilled human lawyer, so we ask law students
to evaluate some predictions. The comments as a result of these qualitative
observations are shown in Table 3. In general, we observe two phenomena that
suggest that, despite the seemingly strong performance of GPT-4, there is still
room for improvement:
– Lack of Citations. When building a language model; the lack of credible
citations given by models like GPT-4 stood out to our annotators—with an
openmodel,itiseasiertoaugmentthesemodelswithtools,facilitatingmore
trust in the form of citations.
– LongWindedAnswers.Ourannotatorsfoundanswerswrittenbyhumans
tobemore“tothepoint”and“direct”,whereasGPT-4oftenprovidesdetails
thatarenotrelatedtothelegalquestion.Fortheexamplesevaluated,GPT-4
fails to capture the concise answers that legal experts are trained to write.
Inthelegaldomain,theseconcerns—lackofcitationsandlackofconcision—
areespeciallyimportantduethethehigh-stakesnatureoflegaldecision-making.
Giventhatthetaskstested—LegalQAandLawStackExchange—wererelatively
simple benchmarks (but still ahead of existing benchmarks), GPT-4’s perfor-
mance raises flags, indicated by comments in Table 3 on using these models for
even more complex tasks, such as document analysis.
Our results challenge the conclusions of previous studies insofar as it shows
that when LLMs, like GPT-4, are subjected to more complex legal reasoning
tasks beyond document processing or answering questions with provided ma-
terial, their performance diminishes. Unlike these studies that highlighted AI’s
efficiency in relatively straightforward tasks, our experiments reveal limitations
in AI’s ability to match the nuanced understanding and precise reasoning of
human lawyers. Particularly, our findings underscore the issues of inadequate
citations and verbosity in AI-generated responses, highlighting the necessity for
domain-specific enhancements to meet the rigorous demands of legal practice.
6 A Framework for Legal AI
6.1 The State of Legal AI
Our results suggest that legal industry needs domain-specific solutions. Such
systems should be able to handle complex legal reasoning and nuance: after all,
in the legal sphere, questions often do not have a single “right answer”, but
rather a range of acceptable answers. However, the past few years have seen an
explosionofso-calledgenerativeAIsforlaw,manyofwhichareactuallygeneral-
purposeAIshiddenbeneathlegal-interfaceveneers.Thesesystemsobscuretheir
underlying limitations, despite being presented as specialized tools.A Call for an Open-source Legal Language Model 11
Comments
Ipreferthehumananswerinthisparticularcircumstance.Ithoughtthehumananswer
wasmoredirectanansweringthequestion.ItseemedasGPT-4wasprovidingplentyof
detailsthatwerenotnecessarilyrelevanttooverallanswertothequestion.Thehuman
answeralsohadatleastsomecitationsvsGPT-4.Neitheropinionreallyprovidesmuch
of an analysis of the circumstances.
Ipreferthehumanversion.IthinktheGPT-4answerisbetterwritten,butthehuman
responseprovidesanimportantcitationandanswersthequestionverydirectly.GPT-
4 does not provide the same important citation.
Inthiscase,thespecificexamplegivenbythehumanisperfect.Itanswersthequestion
directly and shows the principles in play by example. GPT-4, while referring more to
the example, is quite vague and long-winded in summarising that robbing a bank is
stealing.
Human response is far more to the point and interesting. The GPT-4 answer starts
by explaining the difference between crimes and civil wrongs without explaining why
that’s relevant from the start. It could have gone directly into addressing the em-
ployer/employertheftconcept,whileintegratingthoseideasin.Thatismoresowhat
the human response offered. The human also gave interesting context and history by
mentioninghowincertainjurisdictionsdebtmeritedimprisonment,orAustraliacon-
siders wage theft a crime. It gives far more food for thought and is more of what
the user was looking for. GPT-4 refers to labour law, but as it doesn’t dive in with
specifics, its quite vague and bland on the historical aspect.
BothspecifythereisnopolicytoprioritisethePresidentoftheUSinorgantransplan-
tation. The human answer provides links to pages informing on the frameworks and
mechanisms of organ transplantation. The GPT-4 answer considers the hypothetical
case a little but remains vague.
The human answer is superior as it directly references the relevant laws and rules,
providing a more precise and targeted response. In contrast, GPT’s answer appears
somewhat vague, lacking explicit mention of the applicable rules, which could com-
promise the clarity and specificity of the information provided.
Table 3: Feedback from law students on the automatic evaluations given by
GPT-4.
Unfortunately, consensus on the essential criteria for developing legal AI has
not yet been reached. There are three primary strategies being considered. One
possibility (Option 1) is to develop a purpose-built, law-specific generative AI
model from the ground up. To our knowledge, no such initiative has yet been
undertaken in law. It has been undertaken in finance with BloombergGPT (Wu
et al. 2023); but data on its short- and long-term performance is limited, and
recentevidenceshowsthatfinance-customizedBloombergGPTdoesnotoutper-
form generic GPT4 (Li et al. 2023). To our knowledge, no such initiative has
been undertaken in law, likely due to the cost. Furthermore, there is still lim-
ited data on short- and long-term performance, and recent evidence shows that12 R. Bhambhoria et al.
BloombergGPT does not perform better than GPT4, a generic model (Li et
al. 2023). A more economical choice (Option 2) involves fine-tuning an existing
LLM, such as GPT or LLAMA, for legal applications. Early findings indicate
that this could be an adequate short-term solution for some legal tasks (Guha
etal.2023).Finally,athirdoption(Option3)entailstrainingaSmallLanguage
Model(SLM)fromscratch.Researchshowsthatsmall-languagemodels,suchas
Orca 2, can exhibit strong reasoning abilities and outperform larger models by
learning from detailed explanation traces (Hughes 2023).
Irrespective of the selected approach, the essential requirement across all
solutions requires expertise in both law and computer science. In fact, compu-
tational law expertise is vital for constructing, evaluating, and refining legal AI
systems. Engaging with professionals possessing this dual expertise is crucial,
as they can provide nuanced and informed feedback essential for the continuous
improvement of these systems.
However, building an effective legal AI tool extends beyond just expert in-
volvement. Traditional approaches, such as creating closed-system AI platforms
accessibleonlytolawfirmsorthoseoperatingonrestricteddatabases,areinsuf-
ficient.Suchapproaches,exemplifiedbyplatformslikeHarvey7 andLexisNexis’s
Lexis Plus8, fall short in addressing the complexities highlighted in Section 2.
Thelimitationsoftheseclosedsystems,primarilytheirlackofbroaduserengage-
ment, can lead to stagnation, failing to adapt to the evolving legal landscape.
6.2 OpenJustice: A Recipe for Building a Crowdsourced Legal
Language Model
To overcome these limitations, we propose the development of an open-access
legal AI model. Launched in March 2023 by the Conflict Analytics Lab, Open-
JusticeentereddevelopmentinJanuary2021andoperatesasanatural-language
processing interface, including question-answering, document analysis, and cita-
tionretrieval.Thesystemhasthreelayersofdata.Thefirstisacoreopen-source
componenttrained oncuratedlegal data,encompassingthousands ofannotated
question-answer pairs and case law from the US, Canada, France, and the EU.
Thesecondlayerreliesoncrowdsourcedhumanfeedback,withOpenJusticehan-
dling approximately a few thousands requests per week. Finally, the third layer
uses proprietary data from partners to create custom models.
Note that we are experimenting with LLM-fine tuning (Option 2) and train-
ing Small Language Models (Option 3). These models are accessible to a wider
range of partners, such as law schools, aligning with goals like improving access
to justice and legal education. More importantly, this open-access approach can
significantlyenhancethequalityandeffectivenessoftheAIsystem.Itaddresses
keyissuessuchasthepreventionofAIhallucinations,ensuringfactualaccuracy,
promoting diversity of perspectives, and countering the static nature of tradi-
tional training databases. This open version, however, should be restricted to
7 https://www.harvey.ai/
8 https://go.lexisnexis.ca/lexis-plus-ppc-aiA Call for an Open-source Legal Language Model 13
Fig.3: Legal Community Feedback utilized for OpenJustice
sophisticated users—defined here as individuals with a legal background. This
restriction is proposed to maintain the quality of the feedback loop. Sophisti-
cated users, with their specialized knowledge and experience, are more likely
to provide constructive and relevant feedback, which is crucial for the iterative
improvement of the system. By incorporating inputs from a diverse yet expert
user base, the AI system can be continuously refined and updated, ensuring it
remains relevant and effective in a rapidly evolving legal environment.
Note that feedback dataprovided byprofessionals willtakemany forms—(i)
userbehaviour,(ii)handwrittenexpertfeedback,(iii)conversationsteering,(iv)
response ratings, (v) external feedback. All forms of data contribution by user-
contributors, depicted in Figure 3 through a platform called OpenJustice9, are
a valuable resource, which can be useful for supervision in our framework. Ad-
ditionally, databases in the unstructured format may potentially be valuable by
incorporatinginourframeworkthroughpretrainingordomain-adaptation.How-
ever, the value of the aforementioned remains unexplored in the legal domain,
and has been shown to not be useful in other domains such as finance[31].
In the rapidly evolving field of artificial intelligence, particularly in the con-
text of developing AI models for legal applications, a suite of advanced method-
ologies and research breakthroughs offer promising avenues. Direct Preference
Optimization(DPO)[32],isparticularlypertinentforlegalAIduetoitscapabil-
ity to align model outputs with complex, often subjective human preferences, a
commoncharacteristicinlegalreasoning.Thismethod’sabilitytorefineAIout-
puts based on nuanced user feedback makes it exceptionally suited for the legal
domain where interpretations and judgments are not always clear-cut. World
models, as outlined in [25], offer another compelling tool for legal AI. These
models enable the AI to create internal simulations of possible scenarios, an ap-
proach that mirrors the predictive and hypothetical reasoning often employed
in legal analysis. By simulating various legal outcomes and scenarios, a world
model-equipped legal AI can provide more comprehensive and informed sugges-
tions. Advances like Flash Attention 2 [33] contribute significantly by enabling
the processing of large volumes of legal texts efficiently. This efficiency is cru-
cial in legal contexts, where the ability to rapidly parse through extensive legal
9 https://openjustice.ai/14 R. Bhambhoria et al.
documents and case laws is a valuable asset. Furthermore, techniques like re-
jection sampling and reward modeling are instrumental in refining the quality
of AI-generated legal content. Rejection sampling can be used to filter out less
relevant or lower-quality content, ensuring that the AI’s outputs are pertinent
and of high quality. Reward modeling aligns the AI’s objectives with desired
outcomes, an essential feature when the AI is required to navigate the complex
landscapeoflegalethicsandstandards.Lastly,supervisedfine-tuningandalign-
ment research are integral to the development of a legal AI model. Supervised
fine-tuning allows the model to learn from specific, high-quality legal datasets,
ensuring that its outputs are relevant and accurate. Alignment research, which
focuses on ensuring that AI systems’ goals are aligned with human values and
intentions, is particularly critical in the legal domain, where the stakes of mis-
alignment can be particularly high.
The integration of the aforementioned methodologies and research develop-
ments presents a comprehensive approach for training legal AI models. This in-
tegrationnotonlyenhancesthecapabilityofAIinunderstandingandprocessing
legal information but also ensures that the AI’s functioning is aligned with the
nuanced,complex,andethicallyboundnatureoflegalreasoning.Also,thispro-
posed open-access, yet expert-restricted, legal AI model represents a paradigm
shift in the development of legal technology. It not only promises enhanced per-
formance in terms of accuracy and relevance but also embodies a progressive
approachtowardsdemocratizinglegalknowledgeandfosteringaninclusivelegal
tech ecosystem.
7 Conclusion
Artificialintelligencehasbeenbringingaprofoundimpactonlegalapplications.
Inthiswork,webringacallforopen-sourcelegallanguagemodels.Thisisdone
asameanstoaddresslimitationsofgeneral-purposelanguagemodelswhichmay
haveunderlyinglimitations,affectingtheirusageforhigh-stakesdecisionmaking.
Weprovidearecipeforcreatingalegallanguagemodel,calledOpenJustice.We
further introduce a real-world high-quality dataset manually annotated by legal
experts, called LegalQA, and run experiments outlining performance of current
state-of-the-artLLMs.Weplacefurtheremphasisonhighlightingthelimitations
in the automatic evaluation process when used on legal datasets.
8 Acknowledgements
We would like to thank students of the Conflict Analytics Lab at Queen’s Uni-
versity Faculty of Law for being a part of initial efforts put into this initiative,
and David Liang for coordinating efforts.A Call for an Open-source Legal Language Model 15
References
1. Huang, Lei et al., “A Survey on Hallucination in Large Language Models: Princi-
ples, Taxonomy, Challenges, and Open Questions”, Nov 2023. [Online]. Available:
abs/2311.05232
2. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timoth´ee Lacroix, Baptiste Rozi`ere, Naman Goyal, Eric Hambro, Faisal
Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample,
”LLaMA: Open and Efficient Foundation Language Models”, Feb 2023. [Online].
Available: https://arxiv.org/abs/2302.13971
3. Rohan Anil et al. ”Gemini: A Family of Highly Capable Multimodal Models”, Dec
2023. [Online]. Available: https://arxiv.org/abs/2312.11805
4. M. Shur-Ofry, “Multiplicity as an AI Governance Principle.” Rochester, NY, May
10, 2023. doi: 10.2139/ssrn.4444354.
5. D. M. Katz, M. J. Bommarito, S. Gao, and P. Arredondo, “GPT-4 Passes the Bar
Exam.” Rochester, NY, Mar. 15, 2023. doi: 10.2139/ssrn.4389233.
6. Jed Stiglitz, “Modeling Legal Reasoning: LM Annotation at the Edge of Human
Agreement,” Working Paper, 2023.
7. M.C.Cohen,S.Dahan,W.Khern-Am-Nuai,H.Shimao,andJ.Touboul,“Theuse
of AI in legal systems: determining independent contractor vs. employee status,”
Artificial intelligence and law, pp. 1–30, 2023.
8. J. Kleinberg, J. Ludwig, S. Mullainathan, and C. R. Sunstein, “Discrimination in
theAgeofAlgorithms,”JournalofLegalAnalysis,vol.10,pp.113–174,Dec.2018,
doi: 10.1093/jla/laz001.
9. Y. Chen, M. Andiappan, T. Jenkin, and A. Ovchinnikov, “A Manager and an AI
Walk into a Bar: Does ChatGPT Make Biased Decisions Like We Do?” Rochester,
NY, May 20, 2023. doi: 10.2139/ssrn.4380365.
10. SaraMerken,”NewYorklawyerssanctionedforusingfakeChatGPTcasesinlegal
brief”, Reuters, 2023.
11. Choi, Jonathan H. and Hickman, Kristin E. and Monahan, Amy and Schwarcz,
Daniel, ChatGPT Goes to Law School (January 23, 2023). 71 Journal of Legal
Education 387 (2022), Available at SSRN: https://ssrn.com/abstract=4335905 or
http://dx.doi.org/10.2139/ssrn.4335905
12. Blair-Stanek, Andrew and Carstens, Anne-Marie and Goldberg, Daniel S. and
Graber, Mark and Gray, David C. and Stearns, Maxwell L., GPT-4’s Law School
Grades: Con Law C, Crim C-, Law & Econ C, Partnership Tax B, Property B-,
Tax B (May 9, 2023). Available at SSRN: https://ssrn.com/abstract=4443471 or
http://dx.doi.org/10.2139/ssrn.4443471
13. Katz, Daniel Martin and Bommarito, Michael James and Gao,
Shang and Arredondo, Pablo, GPT-4 Passes the Bar Exam (March
15, 2023). Available at SSRN: https://ssrn.com/abstract=4389233 or
http://dx.doi.org/10.2139/ssrn.4389233
14. Nay, John J., et al. ”Large Language Models as Tax Attorneys: A Case Study in
Legal Capabilities Emergence.” arXiv preprint arXiv:2306.07075 (2023).
15. Blair-Stanek, Andrew, Nils Holzenberger, and Benjamin Van Durme. ”OpenAI
Cribbed Our Tax Example, But Can GPT-4 Really Do Tax?.” arXiv preprint
arXiv:2309.09992 (2023).
16. Medianik, Katherine. ”Artificially intelligent lawyers: updating the model rules of
professionalconductinaccordancewiththenewtechnologicalera.”CardozoL.Rev.
39 (2017): 1497.16 R. Bhambhoria et al.
17. Green, Bruce A., and Carole Silver. ”Technocapital@ Biglaw. com.” Nw. J. Tech.
& Intell. Prop. 18 (2020): 265.
18. Mart´ınez, Eric. ”Re-Evaluating GPT-4’s Bar Exam Performance.” Available at
SSRN 4441311 (2023).
19. Guha, Neel, et al. ”Legalbench: Prototyping a collaborative benchmark for legal
reasoning.” arXiv preprint arXiv:2209.06120 (2022).
20. Martin, Lauren et al. “Better Call GPT, Comparing Large Language Models
Against Lawyers.” ArXiv abs/2401.16212 (2024): n. pag.
21. Geex,Law.”Comparingtheperformanceofartificialintelligencetohumanlawyers
in the review of standard business contracts. Law Geex.” (2018).
22. Rudin, Cynthia. ”Stop explaining black box machine learning models for high
stakesdecisionsanduseinterpretablemodelsinstead.”Naturemachineintelligence
1.5 (2019): 206-215.
23. Samuel Dahan, Jonathan Touboul, Jason Lam, and Dan Sfedj, “Predicting Em-
ploymentNoticePeriodwithMachineLearning:PromisesandLimitations,”McGill
Law Journal, 2020.
24. C. Markou and S. Deakin, “Ex Machina Lex: Exploring the Limits of Legal Com-
putability.” Rochester, NY, Jun. 21, 2019. doi: 10.2139/ssrn.3407856.
25. D.HaandJ.Schmidhuber“WorldModels.”AdvancesinNeuralInformationPro-
cessing Systems 31 (NeurIPS 2018). https://arxiv.org/abs/1803.10122
26. R.Bhambhoria,S.Dahan,andX.Zhu,“InvestigatingtheState-of-the-ArtPerfor-
manceandExplainabilityofLegalJudgmentPrediction.,”inCanadianConference
on AI, 2021.
27. C. F. Luo, R. Bhambhoria, S. Dahan, and X. Zhu, “Evaluating Explanation Cor-
rectness in Legal Decision Making,” in Proceedings of the Canadian Conference
on Artificial Intelligence (5 2022). https://doi. org/10.21428/594757db. 8718dc8b,
2022.
28. C. F. Luo, R. Bhambhoria, S. Dahan, and X. Zhu, “Prototype-Based
Interpretability for Legal Citation Prediction.” arXiv, May 25, 2023. doi:
10.48550/arXiv.2305.16490.
29. J.Hilton,R.Nakano,S.Balaji,andJ.Schulman,“WebGPT:Improvingthefactual
accuracyoflanguagemodelsthroughwebbrowsing,”OpenAIBlog,December,vol.
16, 2021.
30. R.Nakanoetal.,“Webgpt:Browser-assistedquestion-answeringwithhumanfeed-
back,” arXiv preprint arXiv:2112.09332, 2021.
31. X.Lietal.“AreChatGPTandGPT-4General-PurposeSolversforFinancialText
Analytics? A Study on Several Typical Tasks ”, arXiv preprint arXiv:2305.05862,
2023.
32. R.Rafilovetal.“DirectPreferenceOptimization:YourLanguageModelisSecretly
a Reward Model”, arxiv preprint arXiv:2305.18290, 2023.
33. Tri Dao ”FlashAttention-2: Faster Attention with Better Parallelism and Work
Partitioning”, arxiv preprint arXiv:2307.08691, 2023.
34. Guha, Neel et al. “LegalBench: Prototyping a Collaborative Benchmark for Legal
Reasoning.”, arxiv preprint arXiv:2209.06120, 2022.
35. Nan Du et al. ”GLaM: Efficient Scaling of Language Models with Mixture-of-
Experts ”, Proceedings of the 39th International Conference on Machine Learning,
PMLR 162:5547-5569, 2022.