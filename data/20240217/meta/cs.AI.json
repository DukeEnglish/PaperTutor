[
    {
        "title": "Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation",
        "authors": "Huizhuo YuanZixiang ChenKaixuan JiQuanquan Gu",
        "links": "http://arxiv.org/abs/2402.10210v1",
        "entry_id": "http://arxiv.org/abs/2402.10210v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10210v1",
        "summary": "Fine-tuning Diffusion Models remains an underexplored frontier in generative\nartificial intelligence (GenAI), especially when compared with the remarkable\nprogress made in fine-tuning Large Language Models (LLMs). While cutting-edge\ndiffusion models such as Stable Diffusion (SD) and SDXL rely on supervised\nfine-tuning, their performance inevitably plateaus after seeing a certain\nvolume of data. Recently, reinforcement learning (RL) has been employed to\nfine-tune diffusion models with human preference data, but it requires at least\ntwo images (\"winner\" and \"loser\" images) for each text prompt. In this paper,\nwe introduce an innovative technique called self-play fine-tuning for diffusion\nmodels (SPIN-Diffusion), where the diffusion model engages in competition with\nits earlier versions, facilitating an iterative self-improvement process. Our\napproach offers an alternative to conventional supervised fine-tuning and RL\nstrategies, significantly improving both model performance and alignment. Our\nexperiments on the Pick-a-Pic dataset reveal that SPIN-Diffusion outperforms\nthe existing supervised fine-tuning method in aspects of human preference\nalignment and visual appeal right from its first iteration. By the second\niteration, it exceeds the performance of RLHF-based methods across all metrics,\nachieving these results with less data.",
        "updated": "2024-02-15 18:59:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10210v1"
    },
    {
        "title": "Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment",
        "authors": "Rui YangXiaoman PanFeng LuoShuang QiuHan ZhongDong YuJianshu Chen",
        "links": "http://arxiv.org/abs/2402.10207v1",
        "entry_id": "http://arxiv.org/abs/2402.10207v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10207v1",
        "summary": "We consider the problem of multi-objective alignment of foundation models\nwith human preferences, which is a critical step towards helpful and harmless\nAI systems. However, it is generally costly and unstable to fine-tune large\nfoundation models using reinforcement learning (RL), and the\nmulti-dimensionality, heterogeneity, and conflicting nature of human\npreferences further complicate the alignment process. In this paper, we\nintroduce Rewards-in-Context (RiC), which conditions the response of a\nfoundation model on multiple rewards in its prompt context and applies\nsupervised fine-tuning for alignment. The salient features of RiC are\nsimplicity and adaptivity, as it only requires supervised fine-tuning of a\nsingle foundation model and supports dynamic adjustment for user preferences\nduring inference time. Inspired by the analytical solution of an abstracted\nconvex optimization problem, our dynamic inference-time adjustment method\napproaches the Pareto-optimal solution for multiple objectives. Empirical\nevidence demonstrates the efficacy of our method in aligning both Large\nLanguage Models (LLMs) and diffusion models to accommodate diverse rewards with\nonly around $10\\%$ GPU hours compared with multi-objective RL baseline.",
        "updated": "2024-02-15 18:58:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10207v1"
    },
    {
        "title": "Ising on the Graph: Task-specific Graph Subsampling via the Ising Model",
        "authors": "Maria BånkestadJennifer AnderssonSebastian MairJens Sjölund",
        "links": "http://arxiv.org/abs/2402.10206v1",
        "entry_id": "http://arxiv.org/abs/2402.10206v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10206v1",
        "summary": "Reducing a graph while preserving its overall structure is an important\nproblem with many applications. Typically, the reduction approaches either\nremove edges (sparsification) or merge nodes (coarsening) in an unsupervised\nway with no specific downstream task in mind. In this paper, we present an\napproach for subsampling graph structures using an Ising model defined on\neither the nodes or edges and learning the external magnetic field of the Ising\nmodel using a graph neural network. Our approach is task-specific as it can\nlearn how to reduce a graph for a specific downstream task in an end-to-end\nfashion. The utilized loss function of the task does not even have to be\ndifferentiable. We showcase the versatility of our approach on three distinct\napplications: image segmentation, 3D shape sparsification, and sparse\napproximate matrix inverse determination.",
        "updated": "2024-02-15 18:58:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10206v1"
    },
    {
        "title": "Radio-astronomical Image Reconstruction with Conditional Denoising Diffusion Model",
        "authors": "Mariia DrozdovaVitaliy KinakhOmkar BaitOlga TaranErica LastufkaMiroslava Dessauges-ZavadskyTaras HolotyakDaniel SchaererSlava Voloshynovskiy",
        "links": "http://dx.doi.org/10.1051/0004-6361/202347948",
        "entry_id": "http://arxiv.org/abs/2402.10204v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10204v1",
        "summary": "Reconstructing sky models from dirty radio images for accurate source\nlocalization and flux estimation is crucial for studying galaxy evolution at\nhigh redshift, especially in deep fields using instruments like the Atacama\nLarge Millimetre Array (ALMA). With new projects like the Square Kilometre\nArray (SKA), there's a growing need for better source extraction methods.\nCurrent techniques, such as CLEAN and PyBDSF, often fail to detect faint\nsources, highlighting the need for more accurate methods. This study proposes\nusing stochastic neural networks to rebuild sky models directly from dirty\nimages. This method can pinpoint radio sources and measure their fluxes with\nrelated uncertainties, marking a potential improvement in radio source\ncharacterization. We tested this approach on 10164 images simulated with the\nCASA tool simalma, based on ALMA's Cycle 5.3 antenna setup. We applied\nconditional Denoising Diffusion Probabilistic Models (DDPMs) for sky models\nreconstruction, then used Photutils to determine source coordinates and fluxes,\nassessing the model's performance across different water vapor levels. Our\nmethod showed excellence in source localization, achieving more than 90%\ncompleteness at a signal-to-noise ratio (SNR) as low as 2. It also surpassed\nPyBDSF in flux estimation, accurately identifying fluxes for 96% of sources in\nthe test set, a significant improvement over CLEAN+ PyBDSF's 57%. Conditional\nDDPMs is a powerful tool for image-to-image translation, yielding accurate and\nrobust characterisation of radio sources, and outperforming existing\nmethodologies. While this study underscores its significant potential for\napplications in radio astronomy, we also acknowledge certain limitations that\naccompany its usage, suggesting directions for further refinement and research.",
        "updated": "2024-02-15 18:57:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10204v1"
    },
    {
        "title": "A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents",
        "authors": "Lingbo MoZeyi LiaoBoyuan ZhengYu SuChaowei XiaoHuan Sun",
        "links": "http://arxiv.org/abs/2402.10196v1",
        "entry_id": "http://arxiv.org/abs/2402.10196v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10196v1",
        "summary": "Language agents powered by large language models (LLMs) have seen exploding\ndevelopment. Their capability of using language as a vehicle for thought and\ncommunication lends an incredible level of flexibility and versatility. People\nhave quickly capitalized on this capability to connect LLMs to a wide range of\nexternal components and environments: databases, tools, the Internet, robotic\nembodiment, etc. Many believe an unprecedentedly powerful automation technology\nis emerging. However, new automation technologies come with new safety risks,\nespecially for intricate systems like language agents. There is a surprisingly\nlarge gap between the speed and scale of their development and deployment and\nour understanding of their safety risks. Are we building a house of cards? In\nthis position paper, we present the first systematic effort in mapping\nadversarial attacks against language agents. We first present a unified\nconceptual framework for agents with three major components: Perception, Brain,\nand Action. Under this framework, we present a comprehensive discussion and\npropose 12 potential attack scenarios against different components of an agent,\ncovering different attack strategies (e.g., input manipulation, adversarial\ndemonstrations, jailbreaking, backdoors). We also draw connections to\nsuccessful attack strategies previously applied to LLMs. We emphasize the\nurgency to gain a thorough understanding of language agent risks before their\nwidespread deployment.",
        "updated": "2024-02-15 18:51:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10196v1"
    }
]