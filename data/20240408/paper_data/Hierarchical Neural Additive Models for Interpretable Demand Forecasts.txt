Highlights
Hierarchical Neural Additive Models for Interpretable Demand
Forecasts
Leif Feddersen, Catherine Cleophas
• We introduce Hierarchical Neural Additive Models (HNAM) for time
series forecasting. These models provide interpretability by clearly at-
tributing how covariates affect forecasting outcomes while maintaining
competitive predictive accuracy compared to advanced black-box mod-
els like Temporal Fusion Transformers (TFT) and clearly outperform-
ing statistical methods.
• HNAM’s inherently explainable architecture, which composes forecasts
from individual covariate effects according to a user-specified interac-
tion hierarchy, has the potential to improve human-computer inter-
action in operational business planning by allowing practitioners to
integrate their expertise and trust into the forecasting process.
4202
rpA
5
]GL.sc[
1v07040.4042:viXraHierarchical Neural Additive Models for Interpretable
Demand Forecasts
Leif Feddersena,b, Catherine Cleophasa
aInstitute for Business, Christian-Albrechts-University Kiel, Germany
bCorresponding author
Abstract
Demand forecasts are the crucial basis for numerous business decisions, rang-
ingfrominventorymanagementtostrategicfacilityplanning. Whilemachine
learning (ML) approaches offer accuracy gains, their interpretability and ac-
ceptance are notoriously lacking. Addressing this dilemma, we introduce Hi-
erarchical Neural Additive Models for time series (HNAM). HNAM expands
upon Neural Additive Models (NAM) by introducing a time-series specific
additive model with a level and interacting covariate components.
Covariate interactions are only allowed according to a user-specified in-
teraction hierarchy. For example, weekday effects may be estimated inde-
pendently of other covariates, whereas a holiday effect may depend on the
weekday and an additional promotion may depend on both former covariates
that are lower in the interaction hierarchy.
Thereby, HNAM yields an intuitive forecasting interface in which ana-
lysts can observe the contribution for each known covariate. We evaluate
the proposed approach and benchmark its performance against other state-
of-the-art machine learning and statistical models extensively on real-world
retail data. The results reveal that HNAM offers competitive prediction
performance whilst providing plausible explanations.
Keywords: Interpretable Machine-Learning, Neural Networks,
Human-Computer-Interaction, Demand Prediction
Email addresses: feddersen@bwl.uni-kiel.de (Leif Feddersen),
cleophas@bwl.uni-kiel.de (Catherine Cleophas)
Preprint available on arXiv. April 8, 20241. Introduction
Demand forecasting as a problem of time series forecasting is at the heart
of business planning activities (Mentzer and Moon, 2004) and, therefore, fre-
quently subject to managerial oversight and intervention (Fildes et al., 2009).
Contributions on judgmental interventions show that their overall impact on
forecast accuracy is questionable while certainly costly (Fildes and Good-
win, 2021), biased and inefficient (Fildes et al., 2009), and highly dependent
on the adjuster’s expertise (Sanders and Ritzman, 1992; Edmundson et al.,
1988).
One motivation for adjustments can be misaligned incentives across the
organization(Mello,2009). However, ageneralaversiontoalgorithmicadvice
(Dietvorst et al., 2015) is further thought to contribute to counterproduc-
tive human-computer interactions in forecasting tasks (Prahl and Van Swol,
2017). One potential driver for algorithm aversion is that human decision-
makers perceive automated algorithms as incapable of capturing the true
demand dynamics (Lehmann et al., 2022), or conversely that opaque mod-
els prohibit model understanding, thus hindering trust (Adadi and Berrada,
2018).
Classical, less opaque time series models such as (Triple) Exponential
Smoothing, ARIMA, and Theta have long been viewed as superior to ma-
chine learning (ML) based forecasting approaches (Makridakis et al., 2018).
Yet, recent results from forecasting competitions point to the superiority of
ML methods for forecasting, particularly when time series are rich in covari-
ates (Makridakis et al., 2022). Hence, while the increasing availability of
high-dimensional data calls for complex ML models, their opaqueness could
ultimately prevent organizations from realizing their potential due to lack of
acceptance.
To address this dilemma for time series forecasting, we introduce a novel
approach we term Hierarchical Neural Additive Models (HNAM). HNAM
combines the quasi-unlimited expressivity of neural networks and the inter-
pretable form of additive models. Its forecasts are additively composed of
a level as well as covariate effects that account for interactions across vari-
ables over time. To that end, HNAM lets a neural network estimate the
coefficients of a linear model where the model’s available information set
expands for each covariate according to a to a user-specified interaction hi-
erarchy. For example, given the hierarchy Weekday, Promotion, Holiday,
the estimated coefficient for the weekday effect would only depend on past
2observations, product attributes, and the weekday itself. The estimated pro-
motion coefficient, one level up the hierarchy, would crucially account for a
weekday-dependent magnitude. Finally, the effect of a holiday depends on
its weekday as well as scheduled promotions at the same time. The obtained
coefficients are finally multiplied by the feature values. These feature values
are one-hot encodings for categorical values whereas real values are prefer-
ably expressed as relative changes to a baseline (e.g. price deviation from
the baseline) to foster sparsity and concise explanations.
Thereby, coefficients vary for each forecast and each horizon; HNAM
estimatesthemviaablack-boxneuralnetworkabletomodelinteractionsand
non-linearities. Yet, coefficients ultimately interact with the input features,
constrainingthemodel’sexpressivityandtherebyitspotentialforoverfitting.
Section 2 motivates the HNAM architecture by discussing related liter-
ature on judgemental forecasting, algorithm aversion, and the impact of a
decomposed transparent display of time series on acceptance and task out-
comes. This section also introduces the existing models that have inspired
our proposed architecture.
Section 3 details the technical aspects and implementation details of
HNAM. Section 4 introduces the three retail demand datasets and out-
lines the preprocessing used to benchmark HNAM against prevalent machine
learning and statistical models. Subsequently, Section 6 presents the results
ofthesebenchmarkingexperimentsandillustratesexemplaryinterpretability
outputs. We derive conclusions from these results in Section 7.
32. Motivation and Methodological Background
To motivate the proposed architecture, this section provides a brief
overview on algorithm aversion and links it to judgmental forecasting. This
motivation supports our argument that the interpretability output of HNAM
could improve managerial interaction with its forecasts. Additionally, this
section also provides a methodological background and outlines related ap-
proaches, namely Prophet, Neural Additive Models (NAMs) and Neural
Additive Time Series Models (NATMs).
2.1. Algorithm Aversion and Interpretability
Research on the efficacy of algorithmic decision-making and the reluc-
tance of human experts to accept algorithmic advice is extensive. It traces
back to work by Meehl (1954) on medical predictions and by Dawes (1979),
who showcase the superior performance of even basic linear models com-
pared to human predictions. Despite these findings, practitioners frequently
hesitate to rely on algorithmic advice. This reluctance is coined algorithm
aversion in Dietvorst et al. (2015). Burton et al. (2020) offer a comprehensive
literature review and identify five major factors for algorithm aversion. In
theremainderofthissection, wesummarizethesefactorsandarguehowthey
relate to our proposed architecture. We conclude that a lack of compatibility
in how managers and algorithms approach the forecasting task seems to be
at the core of algorithm aversion.
False Expectations. Decision-makers’ trust in algorithmic advice is shaped
by their own experiences and external reports, leading to different percep-
tions compared to human-generated advice. The desire for social interaction
with the advice source, particularly among confident experts, can make al-
gorithmic assistance seem unnecessary. People view human errors as random
and correctable, while algorithmic errors are seen as systematic. Even if ini-
tially trusting an algorithm, unavoidable errors may lead decision-makers to
preferentially rely on human decision-making, even despite recognizing the
algorithm’s superior performance. This aspect is largely independent of the
model, except for the obvious goal of avoiding erroneous algorithms.
Lack of Perceived Control. In high-stakes situations, decision-makers want
influence, independence, and the option to overrule or engage with algorith-
mic decisions. This necessitates the algorithm to be ”behaviorally packaged”
(Burtonetal.,2020, p.5)toimpartmeaningfulness. However, thealgorithm’s
4underlying architecture determines the degree to which it can be presented
meaningfully. In this contribution, we target this by designing HNAM to
create composed forecasts. Instead of adjusting outputs from an opaque ar-
chitecture, users can exert control on the level of individual covariate effects.
Cognitive Compatibility. While human decision-making processes tend to be
marked by instincts, heuristics, and biases, algorithms rely on deterministic,
data-driven logic. Integrating the two calls for bridging these very different
systems. Algorithmic interpretability could offer a solution, but at present, it
only applies to simpler approaches and not to cutting-edge machine learning
methods. The research presented here relies on the idea that managers tend
to think about forecasts by adding and subtracting the expected impact of
ex-ante known events to a baseline. Therefore, we design HNAM to feature
an additive output layer - thereby matching the world model of the decision-
maker. The preceding layers’ exact logic are still opaque and non-traceable.
However, we consider this aspect to mirror human experience insofar as hu-
mans come up with simple explanations of the world while the neurological
processes that underlie our conscious thinking are phenomenologically in the
dark (Nisbett and Wilson, 1977).
Lack of Incentives. Incorporating algorithmic advice in human decision-
making can require substantial work which requires appropriate incentives.
Economic rewards that encourage high-variance decision-making can deter
the application of supposedly lower-variance algorithmic advice (Dietvorst
and Bharti, 2020). Social and organizational incentives may not align with
the optimization function of the algorithm (Mello, 2009). This aspect is
largely model-independent and therefore not within the scope of this paper.
However, future research, particularly focusing on behavioural experiments,
could and should pick up on this aspect.
Divergent Rationalities. Humans and algorithms draw different subsets of
information from their surroundings, process them in unique ways, and may
have divergent objectives. In fact, ’broken-leg’ cues (i.e., highly pertinent
information that a human would know to incorporate into their judgment,
but which a statistical model based on historical data would miss) are a
common and sensible adjustment motive (Meehl, 1954). HNAM’s composed
forecasts enable a more precise injection of extra-model knowledge by clearly
differentiating considered covariates and their effect sizes.
52.2. Judgmental Forecasting and Adjustments
Unfortunately, behavioral research on improved acceptance and task out-
comes of additively composed forecasts is scarce. A related case study by
Vo¨ssing et al. (2022) finds that a more transparent forecasting interface,
which lists the considered covariates for a forecast, results in more favourable
adjustments. The authors conclude that their transparent user interface al-
lows managers to calibrate their interventions more precisely and produc-
tively. That is, they become more attuned to the circumstances under which
their extra-model information (or intuition) can, in fact, improve the forecast
whilst abstaining from adjustments otherwise.
Further relevant studies on judgmental forecasts suggest that a decom-
posedpresentationandprocessingoftimeseriesaidshumansincreatingtheir
own forecasts: Both Lawrence et al. (1985) and Carbone and Gorr (1985),
conduct a comparison of judgmental and statistical forecasts with M1 Com-
petition data (Makridakis et al., 1982). The former study finds that judg-
mental extrapolation matches the effectiveness of statistical extrapolation,
while the latter reveals a significantly inferior performance of human judg-
ment. The critical distinction in the experimental designs is that Lawrence
et al. (1985) let participants extrapolate the components of the time series,
including trend and seasonality, through a tabular or graphical presentation,
thus facilitating comparisons and the identification of seasonal patterns.
Noticing this discrepancy, Edmundson (1990) offers an application named
GRAFFECT to structure judgmental forecasting. The authors test this ap-
plication using a student sample and the 68 monthly time series from the
M1 Competition. GRAFFECT assists users in initially identifying a linear
trend with a potential of one change-point in history and an extrapolation
slope defined by the user. Following this, users discern the perceived seasonal
pattern from the de-trended data. This process can be repeated until users
are satisfied that the residual contains nothing beyond noise. The forecasts
produced through this approach significantly outperform unstructured judg-
mental forecasts. While they are also superior to any statistical method used
in the M1 competition, the difference is not statistically significant.
Similarly, Marmier and Cheikhrouhou (2010) develop a structured ap-
proach to guide forecasters in making adjustments to statistical forecasts
based on expert knowledge of event effects. They identify four types of
factors that can lead to significant and predictable changes in the forecast
but are not accounted for by purely statistical methods: transient factors,
transferred impact factors, quantum jump factors, and trend change factors.
6The authors test their approach in two case studies and find that the struc-
tured integration of managerial judgment leads to significant improvements
in forecast accuracy compared to unaided adjustments and purely statistical
forecasts.
Trapero et al. (2013) investigate the effectiveness of judgmental adjust-
ments to statistical forecasts in the presence of promotional events. The
studyfindsthatjudgmentaladjustmentscanimproveforecastaccuracywhen
dealing with promotions, particularly when the statistical model does not
explicitly account for promotional effects. The effectiveness of these adjust-
ments depends on various factors, such as the product type, promotional
characteristics, and the underlying statistical model. The authors suggest
that structured approaches to judgmental adjustments, which provide guid-
anceonwhenandhowtoadjustbasedonthecharacteristicsofthepromotion
and the statistical model, can lead to improved forecast accuracy.
The discussed research shows that judges perform considerably better
when they handle a time series component-wise and that adjustment quality
iscontingentontheproducttimeseriesandadjacentcovariates. Weconclude
that HNAM’s composed forecasts promise firstly a higher acceptance due to
a higher transparency and secondly more precise adjustments as they can
happen on the level of individual covariate effects.
2.3. Methodological Background
ThissectionintroducespriorworkthatmotivatedHNAM.Thatis,Meta’s
Prophet (Taylor and Letham, 2018) as a highly interpretable yet arguably
inflexible and narrowly applicable model as well as Neural Additive Models
(NAMs) Agarwal et al. (2021) for the idea of separately processing features
with small neural networks before adding them in a linear model. Finally,
Neural Additive Time Series Models (Jo and Kim, 2023) follow a similar ap-
proachasourswithsomeimportantdifferenceswithrespecttohowsequences
and feature interactions are handled.
Prophet. The Prophet algorithm, introduced by Taylor and Letham (2018)
relies on a seasonal decomposition with covariates to create interpretable
forecasts. Its accessible outputs and usability have generated considerable
academic and practical interest as evidenced by 2455 citations according to
Google Scholar and 17.7k stars on GitHub as per April 2024.
The Prophet forecast model is expressed as
y(t) = g(t)+s(t)+h(t)+e(t)
7Here, each function corresponds to a unique aspect of the time series data:
g(t) denotes the trend, encapsulating non-periodic changes in the time series.
This is typically modelled as a piece-wise linear or logistic function. s(t) sig-
nifies seasonality, capturing periodic changes. This can include daily, weekly,
or yearly cycles. h(t) accounts for the effects of holidays and additional co-
variates. e(t) represents the error term, capturing any idiosyncratic changes
not modelled by the trend, seasonality, or holiday effects.
Prophet’s ease of use and intuitive model structure makes it a popular
choice for applied forecasting. At the same time, the simple structure can
miss important non-linear effects and interactions. Further, Prophet has to
be individually fitted for each time series, foregoing the benefits of cross-
learning.
Neural Additive Models. NAMs, as introduced by Agarwal et al. (2021), rep-
resent a class of models that harness the structure of generalized additive
models with the ability to capture non-linear relationships characteristic of
neural networks.
The structure of the model can be denoted as:
d
(cid:88)
f(x) = f (x )
i i
i=1
In this formulation, each term f (x ) represents an individual shallow neural
i i
network that is associated with the ith feature or input, x , on the response,
i
f(x).
Accordingly, NAMs can capture non-linear effects. Additionally, their
modularity facilitates the independent examination of each feature’s effect
on the outcome. The additive structure inherent in NAMs provides a means
to infer the effect sizes of each feature on the response variable, akin to the
components g(t), s(t), and h(t) in the Prophet model.
Neural Additive Time Series Models. Jo and Kim (2023) propose Neural
Additive Time Series Models (NATMs). Similar to HNAM, NATMs adapt
the concept of NAMs for time series forecasting.
NATMs differ from our approach in that they use a small neural net
for every past timestep and for each feature. This makes NATMs poten-
tially computationally expensive - an aspect the authors address by sharing
weights across time or features. NATMs, in their original formulation, are
notmodelinginteractionsacrossfeaturesanddonothandlecovariatesknown
in the future.
8Ex-post interpretability. Research in interpretable and thereby more accept-
able ML produced numerous tools to create ex-post explanations, such as
LIME (Ribeiro et al., 2016) or SHAP (Lundberg and Lee, 2017). However,
their ex-post nature makes these methods computationally costly. At the
same time, they still generate over-simplified approximations of the actual
dynamics, leading scholars to call for inherently interpretable models (Rudin,
2019).
2.4. Research Gap
From the above, we conclude that present models are either interpretable
but oversimplifying or complex black-boxes that exacerbate algorithm aver-
sion. NAMs and NATMs provide promising steps towards interpretable yet
sufficiently complex models. Our proposed HNAM architecture builds on
these ideas to yield interpretable forecasts that account for complex tempo-
ral dependencies and feature interactions.
93. Proposed Architecture
In describing the proposed model architecture of HNAM, we first present
a conceptual overview and differentiate the roles of covariate types and the
functional components processing them. Afterwards, we describe our pro-
posed implementation of the functional components in detail.
3.1. Covariates and Components
Conceptual overview. Figure 1 gives a high-level view on the architecture of
HNAM. While all depicted concepts will be explained in later paragraphs,
the general setup is as follows: Covariates are differentiated with respect to
their temporal availability and whether they should have an individual effect
(i.e. be causal covariates). They are embedded or projected (i.e. translated
into a numerical representation of the model’s internal dimensionality). The
level network employs an Attention block (Vaswani et al., 2017) to project an
estimated demand level into the forecasting horizon, using only information
about the past. One Attention-based coefficient network per causal covariate
processesthepast, static, andnon-causalcovariatesinadditiontotherespec-
tive causal covariate and those lower in the interaction hierarchy to derive
one coefficient per timestep and causal covariate. These coefficients are mul-
tiplied with the respective transformed values of the otherwise unprocessed
covariates and all effects are added to the estimated level.
Causal covariates. HNAM is designed for demand forecasting situations,
where some covariates that affect demand are known in the past and in
advance. Examples of such covariates are the date (weekday, season, holi-
day) or planned promotional activities (price changes, advertisement). We
call these causal covariates. To address causal covariates, HNAM requires
them to be specified as a hierarchical list, so that each covariate’s estimated
causal effect can depend on the covariate itself and those lower in the hi-
erarchy. For the exemplary interaction hierarchy of Weekday, Promotion,
Holiday, the model estimates weekday effects independently of other causal
covariates, promotional effects are estimated contingent on the weekday, and
holiday effects are contingent on both weekday and promotional activity. Ac-
cordingly, HNAM considers a matrix C with one row per covariate, yielding
n rows ordered by the causal hierarchy, and T +T columns for the concate-
c h f
nation of historical and future timesteps, respectively. Note that our model
10Figure 1: Conceptual Overview of the HNAM architecture
does not prove or assume causality in the strict sense but differentiates co-
variates as to whether an analyst or manager deems that they should have
an individually estimated effect on demand.
Non-causal covariates. There are covariates that are known in the past and
future that do not require individually estimated effects. Typical examples
are the absolute and relative time indices and sinusoidal seasonal represen-
tations (Hyndman and Athanasopoulos, 2021, Chapter 12.1) that induce a
temporal understanding to each timestep. This is necessary in non-recurrent
neural networks (Vaswani et al., 2017). Thereby, non-causal covariates mod-
ulate the effects of causal covariates whilst not having an individually es-
timated effect. Matrix T stores these mostly time-related covariates across
T +T columns.
h f
Static covariates. Similarly, matrix S stores time-invariant covariates, typ-
ically product and store attributes that remain constant across T + T
h f
columns.
Past covariates. Finally, matrix P contains covariates that are only known
in the past across T columns. It typically contains the past demand obser-
f
11vations alongside other covariates that are not known in advance. Similar
to non-causal and static covariates, past covariates have no individually esti-
mated effects but also modulate causal covariate effects. For more convenient
indexing below, we let P also have T +T columns where values in the future
h f
are 0 and will not be used for forecasts.
Functional Components. Inordertoproduceaforecastvectory ofT forecast
f
steps, the introduced covariate matrices pass through a level neural network
g and coefficient neural networks f with one neural network for each of the
i
n causal covariates. Further, t is a transformation function that k-1 one-hot
c
encodes categorical causal covariates and standardizes continuous covariates.
In order for the estimated level and coefficients to be meaningful, we must
mask information accordingly. The level component only observes historical
information and projects a future level for each time step in the forecasting
horizon. In this way, it establishes the baseline demand level and captures
possible trends.
Each coefficient neural network f observes S, T, and P completely, in
i
addition to the ith causal covariate as well as causal covariates below it in the
interactionhierarchy. Forcontinuouscovariates,itoutputsonecoefficient; for
categorical covariates it outputs k−1 coefficients where k is their cardinality.
On a high-level, starting indexing at 0, HNAM can therefore be formu-
lated as:
n (cid:88)c−1
y = g(S,T,P)+ f (S,T,P,C[: (i+1)])·t(C[i,T :]) (1)
i h
i=0
3.2. Implementation
In the following, we detail how functional components are implemented.
These encompass how covariates are processed via embeddings and projec-
tions, how covariate interactions are enabled by additively assembling infor-
mation, and how temporal dependencies are modeled via Attention layers to
determine the forecast’s level and coefficients.
Embeddings and Projections. All covariates are projected into the model’s
embedding size, a hyperparameter that determines the model’s internal di-
mensionality and thereby expressiveness. To achieve this, an embedding
table handles categorical covariates. Embeddings are a sparser alternative to
one-hot encodings to translate categorical values into a numerical represen-
tation. Continuous covariates are projected into the model’s embedding size
through a linear-affine transformation.
12Assembling information tensors. The constant embedding size of embedded
covariates allows them to be summed in the feature dimension. When-
ever HNAM requires a certain information set, the respective covariates are
summed and then passed through a layer normalization.
MLP. At multiple points in our architecture, a multi-layer perceptron is re-
sponsiblefornon-linearprocessing. Theinputisprojectedintoanembedding
size that is larger by a user-parameterized factor and then passes through
a Gaussian Error Linear Unit (GELU) activation function for non-linearity.
Subsequently, the representation is projected back with dropout to the net-
work’s embedding size.
Temporal Convolution Layer. This layer expands its input using a 1-
dimensional convolution with a kernel size of 3, accounting for the last
two timesteps with zero padding for the two oldest observations. Post-
convolution, a GELU activation and dropout regularize the output before
it is projected back to the embedding size. This layer is used in Attention
blocks described below to extract local features across adjacent timesteps.
Attention Block. Bothlevel andcoefficient networks incorporateinformation
fromothertimestepsgloballyviamulti-headAttention(Vaswanietal.,2017)
with a temporal convolution to calculate queries, keys, and values. The
respective implementations are described below.
Level Network. The level component is implemented as an Attention block.
The query consists of of (S[:,T :] + T[:,T :]), i.e., static and temporal
h h
information for the forecast horizon. The keys and values both are (S+T +
P)[: T ], i.e., static, temporal, and past information in the past time steps.
h
• Query(Q),Key(K),andValue(V)projectionsareobtainedbypassing
the input sequence through temporal convolutional layers:
Q = TemporalConv((S +T)[:,T :]),
h
K = TemporalConv((S +T +P)[:,: T ]),
h
V = TemporalConv((S +T +P)[:,: T ])
h
• The sequence is split in the channel dimension into multiple heads and
13scaled dot-product Attention is computed for each head:
Y = Attention(Q,K,V)
(cid:18) QKT(cid:19)
= Softmax √ V
d
k
where d is the dimension of each head.
k
• The attention output is then combined with the output of an MLP
after layer normalization:
Y′ = Y +MLP(LayerNorm(Y))
• Finally, the Level vector and a Level Embedding in the embedding size
are projected from Y′:
Level = Linear(Y′)
Level Emb = Linear(Y′)
Coefficient Networks. For each causal covariate, we have one coefficient net-
work. A similar Attention block as described above is at the core of each
coefficient network. Queries, keys and values for the ith covariate and coef-
ficient network are obtained as:
Q = TemporalConv((S +T +C[: i+1])[T :]+Level Emb),
h
K = TemporalConv((S +T +P +C[: i+1])[: T ]),
h
V = TemporalConv((S +T +P +C[: i+1])[: T ]))
h
As described previously, for each causal covariate’s coefficient network, the
values of causal covariates higher in the interaction hierarchy are not avail-
able. We add the Level Embedding obtained earlier to the query to utilize
the extracted information on the level here.
Although each feature is processed in an individual network, we let At-
tention scores be computed in parallel by assembling tensors such that the
different causal covariates are stacked in a second batch dimension. The
results of the Attention block are projected back to obtain the coefficients.
144. Datasets and Preprocessing
For robust benchmarking, we generate and evaluate forecasts in three dif-
ferentretaildemanddatasets. Alldatasetshavemultiplecovariatesalongside
the recorded sales data. Two datasets are publicly available and one stems
from an industry partner.
In the following, we provide an overview of the preprocessing we apply in
this study, highlight how time series are filtered, what covariate features are
used, and how a rolling-forward evaluation is carried out.
4.1. Datasets
Walmart. This public dataset (University of Nicosia, 2020) consists of hier-
archical sales data provided by Walmart through the University of Nicosia
amid the M5 forecasting competition. It spans 1941 days from 2011 to 2016.
The dataset includes daily item-level sales data of 3049 products and 10 store
locations across three states.
Favorita. TheFavoritadataset(Favorita,2018)isapubliclyavailabledataset
provided by Corporaci´on Favorita, an Ecuadorian-based grocery retailer, for
a forecasting competition. It spans 1684 days from 2013 to 2017 across 4035
products and 54 stores.
Retail. We further evaluate models on a dataset provided by a medium-sized
retailer. Itspans2472daysfrom2015to2022observing2910productsacross
three stores.
4.2. Data Selection
The research documented in this paper focuses on the interpretability
aspect of forecasting to enhance human-computer interaction. To create a
fitting benchmarking environment for this purpose, we select for time series,
i.e. a unique product and store combination, that are likely to be adjusted
due to their economic relevance and for which we can assess the plausibility
of interpretability outputs.
Weexcludetimeserieswithapparentlylow, intermittent, orcyclicalsales.
All datasets lack pertinent information as to whether a product was out of
stock or not offered at all, making it challenging to create realistic bench-
marks for forecasting consumer demand. Since we can not differentiate these
scenarioswithoutmakingsubstantialassumptions,wefocusonproductswith
more stable sales, assuming they were less frequently out of stock.
15Further, we argue that daily forecasts of intermittently demanded prod-
ucts are generally less relevant than non-intermittent ones. For instance,
products with high daily demand and short shelf-lives, such as fruits, veg-
etables, and dairy products, typically do not exhibit intermittency. On the
other hand, products with slower turnover rates, often due to higher costs or
specificity, usuallyhavelongershelf-lives, likespices, beverages, andnon-food
items. For these products, aggregate forecasts are more relevant, making the
problem of intermittency conveniently disappear.
Based on these arguments, we select time series from the given data sets
according to the following criteria:
1. The time series must display non-zero sales for at least 100 days prior
to the first test period.
2. The time series must not exhibit more than 100 days of no sales after
the first recorded sale.
3. The time series’ median sales must be greater than five during the test
periods and 100 days before.
4. The time series must be in the top 500 in terms of sales during the test
periods and 100 days before.
5. The time series must be in the top 500 in terms of revenue during the
test periods and 100 days before (not applicable for Favorita since price
information is missing).
6. For Favorita, we instead select time series with less than 1% missing
observations.
This selection process yields 221 (Walmart), 287 (Favorita), and 193 (Re-
tail) time series.
4.3. Features
The multivariate models we benchmark utilize a number of covariates.
While most covariates are available in all datasets, some are dataset spe-
cific. Unless indicated otherwise, all covariates are available not only for
past observations but also in the prediction horizon. Table 1 lists the co-
variates, differentiates their type as categorical or continuous and indicates
their availability per dataset. In addition to the listed covariates, neural net-
works use an absolute and a relative time index as well as sine and cosine
embeddings of the day of the year to induce a temporal sense to the models.
16Table 1: Covariates entering multivariate models per dataset.
M5 Walmart Favorita Retail
Categorical
Product ✓ ✓ ✓
Store ✓ ✓ ✓
Promotion ✗ ✓ ✓
Weekday ✓ ✓ ✓
Holiday1 ✓ ✓ ✓
SNAP2 ✓ ✗ ✗
Continuous
Sales (only past) ✓ ✓ ✓
Relative Price 3 ✓ ✗ ✓
Oil Price (only past) ✗ ✓ ✗
1 For Favorita, we differentiate local, regional, and national
holidays as separate covariates; for Walmart we differentiate
sporting, cultural, and national events or holidays.
2 The Supplemental Nutrition Assistance Program (SNAP),
previously known as the Food Stamp Program, provides
funds specifically for purchasing food to low-income house-
holds. The feature marks a day at which funds are dis-
tributed.
3 The percentage deviation of the day’s price from the rolling
20-day mean.
4.4. Evaluation
Across all datasets, we use the last five fully available months as test
sets. For each test month, we train neural networks with observations up to
two weeks prior to the test month and use the remaining two weeks prior as
validation set for early stopping.
We generate forecasts with a maximum horizon of two weeks via a sliding
window in each test month without retraining. We fine tune with updated
data prior to each new test month. Similarly, we keep the hyperparameters
for the remaining benchmark models constant per test month but use all
data up to the respective forecast date for training.
We aim to forecast sales with daily granularity. While coarser temporal
aggregations can be sensible depending on the business case, we focus on
17our model’s interpretable forecasts based on covariates of daily frequency.
Further, we limit our exploration to forecasting expected sales, as opposed
toprovidingprobabilisticforecastsasrequiredfornewsvendormodels. While
HNAM supports quantile prediction, we opt for point forecasts for the sake
of clearer error metrics and interpretability outputs in this paper.
185. Models
The following provides an overview of the considered benchmarks and
implementation details. To that end, we first describe variants of HNAM
implemented for the various target sets, before, detailing our implementation
of Temporal Fusion Transformers, Prophet, ETS, and SARIMAX.
Hierarchical Neural Additive Models. HNAM’s architecture has been out-
lined in Section 3. There, we discriminated different types of covariates and
introduced the interaction hierarchy applied for the benchmark data sets.
We use the same hierarchy for all datasets, given that the respective
covariate is available: Weekday, Relative Price, Promotion, Holiday. We
select this hierarchy because it feels natural to estimate weekday effects in-
dependently of other modulating covariates and add more sparsely occurring
covariates on top. Generally speaking, we suggest to order covariates by de-
creasing frequency of their occurrence to limit the total amount of covariate
interactions.
The Walmart data set does not include information on scheduled pro-
motions. However, SNAP indicates days where eligible customers received
financial support for groceries. Holidays are differentiated into three separate
covariates in Walmart and Favorita, differentiating their type and regionality
respectively.
Temporal Fusion Transformers. Temporal Fusion Transformers (TFT) (Lim
et al., 2021) is a deep learning model that employs the transformer archi-
tecture for time series forecasting. Its introductory paper demonstrated
TFT outperforming other popular neural networks for forecasting, including
DeepAR (Salinas et al., 2020). Like HNAM, TFT handles and differenti-
ates covariates with respect to their availability during the forecast horizon.
Notably, its attention mechanism and variable selection networks offer some
interpretability that is, however, significantly less immediate than in our
proposed architecture (Feddersen and Cleophas, 2023).
Neural Network Implementations. The neural network-based methods above
are implemented in Pytorch Forecasting (Beitner, 2020). In pre-experiments,
we observed better validation scores with an embedding size of 32 rather
than 16 in both HNAM and TFT. Otherwise, we use the package’s default
implementations and parameters for TFT. We do not perform automatic hy-
perparameter tuning due to its exponential computational costs and because
19predictive accuracy is not the main proposition of our proposed architecture.
Rather, our aim is to validate whether constraints imposed on HNAM for
interpretability would reduce its predictive accuracy notably compared to
more opaque models like TFT.
Neural network models learn global models for all time series in a dataset
whereas the benchmark methods below fit local models per time series.
Global models can thereby offset their complexity (number of parameters)
with a relatively larger amount of training data (fitting only one model per
dataset instead of one model per time series). Accordingly, we fit the neural
network models with a learning rate of 0.001, weight decay of 0.01 and a
batch size of 256. For the first test month, we train up to 300 epochs with
early stopping on the loss in the validation set (i.e., the last two weeks of
each training set) with a patience of 30 epochs and select the best model
with respect to the validation loss. For the remaining test months, neural
networks are fine-tuned for up to 100 epochs, also employing early stopping.
The models are trained on a high-performance cluster node with an NVIDIA
V100 GPU.
Prophet. Prophet (Taylor and Letham, 2018) decomposes a time series into
trend, seasonality, and holiday components. The model conveniently handles
missing values and is intended to allow fast human-in-the-loop iterations.
We use Prophet’s Python implementation (Taylor and Letham, 2017) with
standard parameters. Per time series we validate an additive versus a multi-
plicative model in the training data and use the better performing model for
generating forecasts.
ETS. Seasonal exponential smoothing (also termed ETS for Error, Trend,
Seasonality) applies exponentially decaying weights to the error, trend, and
seasonal components of univariate time series. We use the statsforecast
(Garza et al., 2022) AutoETS implementation to automatically determine
the additive or multiplicative configuration of error, trend, and seasonality
via the Akaike Information Criterion.
SARIMAX. Seasonal Autoregressive Integrated Moving-Average with Ex-
ogenous Regressors (SARIMAX) models understand the detrended time se-
ries as a combination of autoregressive and moving average processes, along-
side a seasonal component and external regressors. The respective parame-
ters are found with the statsforecast AutoARIMA implementation.
206. Results
6.1. Computation Times
Table 2 depicts details on the training process of the neural network
models HNAM and TFT for the first test set of each data set. Although both
models run for similar numbers of epochs until early stopping triggers and
achieve comparable loss scores in the training and validation sets, HNAM
requires considerably less time per epoch. Accordingly, it needs markedly
shorter overall training times than TFT.
Astobeexpected, thelinearmodelstrainnotablyfaster, withETStaking
up to ten minutes, Prophet up to two hours, and SARIMAX up to four hours
on an M1 Macbook Pro to generate all forecasts. One should note, however,
that a pre-trained neural network requires less training time for ongoing fine-
tuning and that inference is possible in a few minutes.
Table 2: Training times and loss metrics for HNAM and TFT.
Walmart Favorita Retail
HNAM TFT HNAM TFT HNAM TFT
Time per epoch (m:s) 01:57 03:44 01:30 03:12 01:32 05:02
Epochs 258 253 220 261 211 217
Training time (h:m:s) 8:23:06 15:44:32 5:30:00 13:55:12 5:23:32 18:12:14
Training loss 0.650 0.636 0.537 0.517 0.572 0.569
Validation loss 0.601 0.669 0.518 0.500 0.543 0.550
6.2. Aggregate Error Metrics
This section presents aggregate error metrics of the considered models in
thethreedataset’stestsets. Negativepredictionsaretruncatedat0. Interms
of error metrics, we consider SMAPE, MAE and RMSE. We select SMAPE
for its intuitive interpretation noting its asymmetric weighing of over- and
underprediction. MAE as standardized with each time series’ standard devi-
ation provides a common linear and symmetric metric. We chose the equally
standardized RMSE as a loss metric in the training process. Finally, we also
consider the frequency of 1st and 2nd ranks achieved across time series when
ranking models by RMSE per time series.
Overall, we note that the neural network models HNAM and TFT clearly
outperform the linear benchmarks. Comparing the two, HNAM performs
21Table 3: Mean and median error metrics in Walmart
SMAPE Std. MAE Std. RMSE Rank Freq.
x¯ x˜ x¯ x˜ x¯ x˜ 1st 2nd
HNAM 0.297 0.211 0.571 0.451 4.000 1.387 76.5% 23.5%
TFT 0.310 0.222 0.601 0.485 4.304 1.611 23.5% 75.6%
PROPHET 0.412 0.307 0.838 0.653 9.590 2.897 0.0% 0.5%
SARIMAX 0.400 0.296 0.796 0.635 8.045 2.747 0.0% 0.5%
ETS 0.373 0.273 0.748 0.594 7.190 2.384 0.0% 0.0%
Table 4: Mean and median error metrics in Retail
SMAPE Std. MAE Std. RMSE Rank Freq.
x¯ x˜ x¯ x˜ x¯ x˜ 1st 2nd
HNAM 0.414 0.294 0.428 0.311 8.892 1.597 47.2% 50.3%
TFT 0.407 0.293 0.427 0.315 8.294 1.637 52.3% 46.6%
PROPHET 0.555 0.438 0.674 0.466 22.782 3.551 0.0% 0.5%
SARIMAX 0.587 0.465 0.715 0.493 25.649 3.983 0.0% 1.0%
ETS 0.541 0.416 0.647 0.434 23.738 3.060 0.5% 1.6%
better in the Walmart dataset (Table 3), whereas TFT dominates in the
Favorita dataset (Table 5), while Retail shows balanced outcomes slightly
favoring TFT (Table 4).
These results confirm that the considerably less flexible HNAM architec-
ture is competitive with a state-of-the-art model that employs more complex
components and takes considerably longer to train. As an additional in-
teresting finding, SARIMAX and Prophet, despite utilizing covariates, fare
worse than the univariate ETS, once again confirming ETS as a hard-to-beat
benchmark.
6.3. Interpretability
After confirming HNAM’s competitive accuracy on a macrolevel, this sec-
tion explores specific forecasting instances. This examination will highlight
HNAM’s ability to offer explanations for its forecasts, as well contrasting its
accuracy versus TFT in favorable and infavorable instances.
Figure 2a visualises a forecast instance from the Walmart dataset, where
HNAM fares considerably worse than TFT as measured by the largest gap
22Table 5: Mean and median error metrics in Favorita
SMAPE Std. MAE Std. RMSE Rank Freq.
x¯ x˜ x¯ x˜ x¯ x˜ 1st 2nd
HNAM 0.202 0.139 0.430 0.319 20.580 5.205 29.6% 68.6%
TFT 0.191 0.135 0.413 0.312 17.382 4.942 70.0% 30.0%
PROPHET 0.288 0.198 0.643 0.474 98.417 11.485 0.0% 0.0%
SARIMAX 0.282 0.204 0.637 0.471 49.997 11.361 0.0% 0.3%
ETS 0.261 0.185 0.591 0.434 45.212 9.617 0.3% 1.0%
between the two in SMAPE. Timestep 1802 on the the x-axis marks the
first date of the forecast horizon. The y-axis measures sales quantities. To
explain an HNAM forecast, one first considers the predicted Level (light-blue
line). Causal covariate effects are then added to that Level (colored stacked
bars)andamounttothemodel’sforecast(dashedblackline). Inthedepicted
instance, the first forecast at timestep 1802 is determined solely by the Level,
devoid of any causal covariate effects. This occurs due to the application of
k-1 dummy encoding for categorical variables, where the first category is
represented implicitly by the absence of other categories (all zeros in the
dummy-encoded vector). We state all potentially considered covariates in
the legend, even if they have no effect in the given forecast horizon. Such
a representation clarifies that the covariates would, in fact, be considered if
they had a non-zero effect. The TFT prediction is given as a dashed blue
line for comparison.
ComparativelybadperformancesofHNAMasobservedinFigure2aoften
occurafterrapidlevelchanges, however, wedonothaveaconciseexplanation
athandthatgoesbeyondsuspectingthatHNAMscomposedstructuremakes
it more inflexible for picking up such rapid shifts.
Figure 2b depicts an instance where HNAM markedly outperforms TFT.
Particularly, the initially demand-reducing effect of a substantial price in-
crease as well as a subsequent rebound following a slight price decrease is ac-
curatelycapturedbyHNAM.WeobservehowtheadditivenatureofHNAM’s
predictions arguably make it more prone for producing negative predictions
which would have to be truncated.
Figure 3 depicts an instance where HNAM performs relatively well and
apparently predicts the promotional effects quite well. This instance is an
example of its strength and weakness regarding the clear attribution to co-
23variates. Considering timestep 1494, the data does not indicate a planned
promotion for that day although it is surrounded by days with active pro-
motions. Yet, the actual sales remain relatively high which is accurately
predicted by TFT. Assuming this is a regular, learnable pattern, HNAM
would have no chance to do so since the estimated coefficient for promo-
tional activity for that day is multiplied with zero anyway.
(a)RelativelyinaccurateHNAMpredictionsforoneforecastinstanceinWalmart
(b)RelativelyaccurateHNAMpredictionsforoneforecastinstanceinWalmart
Figure 2: Composed HNAM predictions and TFT predictions versus actuals in Walmart.
24Figure 3: Composed HNAM predictions and TFT predictions versus actuals in Favorita.
257. Conclusions and Future Research
Accuracy results. This study introduces Hierarchical Neural Additive Mod-
els (HNAM) for time series forecasting emphasising the critical aspect of
interpretability. The accuracy results observed in the computational study
demonstrate that HNAM delivers competitive forecasting accuracy when
benchmarked against advanced models such as Temporal Fusion Trans-
formers (TFT) across multiple datasets. This is particularly noteworthy as
HNAM incorporates design elements aimed at enhancing interpretability,
which could potentially restrict the model’s expressive power. In addition,
HNAMS’s composed forecasts allow for precise attributions how different
covariates impact the forecast outcomes. This interpretability can be used
for designing user interfaces that foster trust and encourage the productive
injection of extra-model knowledge by managers.
Possible challenges in practice. Although HNAM marks a big step towards
inherently interpretable models for demand forecasting, we anticipate com-
mon problems upon its practical implementation for decision-support:
While HNAM’s architecture allows a clear mapping of which information
the model used to estimate a covariate effect, one must not confuse this
with proving causality. At least two examples come to mind: In the Retail
dataset, we have two covariates regarding promotional activity: promotion
and price change. Some products have promotions without price changes
and vice versa. Given a product that only has price changes concurrent with
promotions, the estimated price sensitivity might counterintuitively show a
negative effect of the price change if it is of a lesser extent than other price
changes during promotions. One solution would be to drop the promotion
covariate entirely or to use it only when there are no price changes. As a
similar example, it is conceivable that past price increases were a reaction
to anticipated increased demand. Then, the price sensitivity would again
imply higher demand for higher prices. Hence, the usual caveats of statistical
modeling apply to HNAM and estimated effects must be carefully evaluated
before concluding any causality to rest pricing decisions upon.
Behavioral validation. The present research rests upon the arguments laid
forth in Section 2 to motivate HNAM’s potential for improving human-
computer interaction in the retail demand prediction context. However, no
study to date has clearly examined the case where analysts work with a
26black-box versus a composed forecasting model. Therefore, we plan to con-
duct and encourage future behavioral research on analysts’ interactions with
explainable models like HNAM. These would optimally include discussions
and quantitative evaluations with domain-experts as well as larger-scale eval-
uations with business students.
Architecture. Our HNAM implementation uses several best practices (e.g.,
layer normalization, dropout, multi-head Attention), yet it is by no means
the result of an extensive architecture search. We emphasise that the general
idea of HNAM might be implemented in more efficient and more accurate
ways.
Delayed and anticipatory effects. As alluded to earlier when discussing Fig-
ure 3, HNAM in its current implementation does not natively model de-
layed or anticipatory effects. That is, for example, when a promotion affects
subsequent periods (Hewage et al., 2022), or when customers change their
shopping patterns in anticipation of an event or holiday. Such effects, if
suspected, could be captured by adding suitably engineered covariates with
positive and negative shifts. Future research, however, might further con-
sider neural architectural solutions that maintain the clear effect attribution
of HNAM while inherently modeling such time-shifted covariate effects.
Final Remarks. As organizations contend with data-rich environments and
challenges with algorithm aversion, our results demonstrate that HNAM
makes a significant step towards more effective decision-making through ac-
curate yet explainable models. We call for behavioral research that refines
the concept of algorithm aversion as to how it may be attenuated through
inherently interpretable models like the one presented here.
27References
Adadi, A. and Berrada, M. (2018). Peeking inside the black-box: a survey
on explainable artificial intelligence (xai). IEEE access, 6:52138–52160.
Agarwal, R., Melnick, L., Frosst, N., Zhang, X., Lengerich, B., Caruana,
R., and Hinton, G. E. (2021). Neural additive models: Interpretable ma-
chine learning with neural nets. Advances in neural information processing
systems, 34:4699–4711.
Beitner, J. (2020). GitHub - jdb78/pytorch-forecasting: Time series
forecasting with PyTorch — github.com. https://github.com/jdb78/
pytorch-forecasting. Accessed: 2024-04-03.
Burton, J. W., Stein, M.-K., and Jensen, T. B. (2020). A systematic review
ofalgorithmaversioninaugmenteddecisionmaking. Journal of Behavioral
Decision Making, 33(2):220–239.
Carbone, R. and Gorr, W. L. (1985). Accuracy of judgmental forecasting of
time series. Decision Sciences, 16(2):153–160.
Dawes,R.M.(1979). Therobustbeautyofimproperlinearmodelsindecision
making. American Psychologist, 34:571–582.
Dietvorst, B. J. and Bharti, S. (2020). People reject algorithms in uncertain
decision domains because they have diminishing sensitivity to forecasting
error. Psychological Science, 31(10):1302–1314.
Dietvorst, B. J., Simmons, J. P., and Massey, C. (2015). Algorithm aver-
sion: people erroneously avoid algorithms after seeing them err. Journal
of Experimental Psychology: General, 144(1):114.
Edmundson, B., Lawrence, M., and O’Connor, M. (1988). The use of non-
time series information in sales forecasting: A case study. Journal of
Forecasting, 7(3):201–211.
Edmundson, R. (1990). Decomposition; a strategy for judgemental forecast-
ing. Journal of Forecasting, 9(4):305–314.
Favorita, C. (2018). Corporacion favorita grocery sales
forecasting competition. https://www.kaggle.com/c/
favorita-grocery-sales-forecasting/. Accessed: 2024-04-03.
28Feddersen, L. and Cleophas, C. (2023). Solving the data-driven newsvendor
with attention to time. In ECIS 2023 Proceedings.
Fildes, R. and Goodwin, P. (2021). Stability in the inefficient use of fore-
casting systems: A case study in a supply chain company. International
Journal of Forecasting, 37(2):1031–1046.
Fildes, R., Goodwin, P., Lawrence, M., and Nikolopoulos, K. (2009). Ef-
fective forecasting and judgmental adjustments: an empirical evaluation
and strategies for improvement in supply-chain planning. International
Journal of Forecasting, 25(1):3–23.
Garza, F., Canseco, M.M., Challu´, C., andOlivares, K.G.(2022). StatsFore-
cast: Lightning fast forecasting with statistical and econometric models.
PyCon Salt Lake City, Utah, US 2022.
Hewage, H. C., Perera, H. N., and De Baets, S. (2022). Forecast adjust-
ments during post-promotional periods. European Journal of Operational
Research, 300(2):461–472.
Hyndman, R. J. and Athanasopoulos, G. (2021). Complex seasonality. In
Forecasting: Principles and Practice. OTexts, 3 edition. Online edition.
Jo, W. and Kim, D. (2023). Neural additive time-series models: Explainable
deep learning for multivariate time-series prediction. Expert Systems with
Applications, 228:120307.
Lawrence, M. J., Edmundson, R. H., and O’Connor, M. J. (1985). An ex-
amination of the accuracy of judgmental extrapolation of time series. In-
ternational Journal of Forecasting, 1(1):25–35.
Lehmann, C. A., Haubitz, C. B., Fu¨gener, A., and Thonemann, U. W.
(2022). The risk of algorithm transparency: How algorithm complexity
drives the effects on the use of advice. Production and Operations Man-
agement, 31(9):3419–3434.
¨
Lim, B., Arık, S. O., Loeff, N., and Pfister, T. (2021). Temporal fusion
transformers for interpretable multi-horizon time series forecasting. Inter-
national Journal of Forecasting, 37(4):1748–1764.
29Lundberg, S. M. and Lee, S.-I. (2017). A unified approach to interpreting
model predictions. Advances in neural information processing systems, 30.
Makridakis, S., Andersen, A., Carbone, R., Fildes, R., Hibon, M.,
Lewandowski, R., Newton, J., Parzen, E., and Winkler, R. (1982). The
accuracy of extrapolation (time series) methods: Results of a forecasting
competition. Journal of Forecasting, 1(2):111–153.
Makridakis, S., Spiliotis, E., and Assimakopoulos, V. (2018). Statistical and
machine learning forecasting methods: Concerns and ways forward. PLOS
ONE, 13(3):e0194889.
Makridakis, S., Spiliotis, E., and Assimakopoulos, V. (2022). M5 accuracy
competition: Results, findings, and conclusions. International Journal of
Forecasting, 38(4):1346–1364.
Marmier, F. and Cheikhrouhou, N. (2010). Structuring and integrating
human knowledge in demand forecasting: a judgemental adjustment ap-
proach. Production Planning and Control, 21(4):399–412.
Meehl, P. E. (1954). Clinical versus statistical prediction: A theoretical anal-
ysis and a review of the evidence. University of Minnesota Press, Min-
neapolis.
Mello, J. (2009). The impact of sales forecast game playing on supply chains.
Foresight: The International Journal of Applied Forecasting, 13:13–22.
Mentzer, J. T. and Moon, M. A. (2004). Sales forecasting management: a
demand management approach. Sage Publications.
Nisbett, R. E. and Wilson, T. D. (1977). Telling more than we can know:
Verbal reports on mental processes. Psychological Review, 84(3):231.
Prahl, A. and Van Swol, L. (2017). Understanding algorithm aversion: When
is advice from automation discounted? Journal of Forecasting, 36(6):691–
702.
Ribeiro, M. T., Singh, S., and Guestrin, C. (2016). ”why should i trust
you?” explaining the predictions of any classifier. In Proceedings of the
22nd ACM SIGKDD international conference on knowledge discovery and
data mining, pages 1135–1144.
30Rudin, C. (2019). Stop explaining black box machine learning models for
highstakesdecisionsanduseinterpretablemodelsinstead. Nature Machine
Intelligence, 1(5):206–215.
Salinas, D., Flunkert, V., Gasthaus, J., andJanuschowski, T.(2020). Deepar:
Probabilistic forecasting with autoregressive recurrent networks. Interna-
tional Journal of Forecasting, 36(3):1181–1191.
Sanders, N. R. and Ritzman, L. P. (1992). The need for contextual and tech-
nical knowledge in judgmental forecasting. Journal of Behavioral Decision
Making, 5(1):39–52.
Taylor, S. J. and Letham, B. (2017). GitHub - facebook/prophet: Prophet:
Automatic forecasting procedure — github.com. https://github.com/
facebook/prophet. Accessed: 2024-04-03.
Taylor, S. J. and Letham, B. (2018). Forecasting at scale. The American
Statistician, 72(1):37–45.
Trapero, J. R., Pedregal, D. J., Fildes, R., and Kourentzes, N. (2013). Analy-
sis of judgmental adjustments in the presence of promotions. International
Journal of Forecasting, 29(2):234–243.
University of Nicosia (2020). M5 forecasting - accuracy: Estimate
the unit sales of walmart retail goods. https://www.kaggle.com/c/
m5-forecasting-accuracy. Accessed: 2024-04-03.
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
Kaiser, L(cid:32) ., and Polosukhin, I. (2017). Attention is all you need. Advances
in neural information processing systems, 30.
Vo¨ssing, M., Ku¨hl, N., Lind, M., and Satzger, G. (2022). Designing trans-
parency for effective human-ai collaboration. Information Systems Fron-
tiers, 24(3):877–895.
31