Watermark-based Detection and Attribution of AI-Generated Content
ZhengyuanJiang,MoyangGuo,YuepengHu,NeilZhenqiangGong
DukeUniversity
{zhengyuan.jiang,moyang.guo,yuepeng.hu,neil.gong}@duke.edu
ABSTRACT
Severalcompanies‚ÄìsuchasGoogle,Microsoft,andOpenAI‚Äìhavedeployedtechniquestowatermark
AI-generatedcontenttoenableproactivedetection. However,existingliteraturemainlyfocuseson
user-agnosticdetection. Attributionaimstofurthertracebacktheuserofagenerative-AIservice
whogeneratedagivencontentdetectedasAI-generated. Despiteitsgrowingimportance,attribution
islargelyunexplored. Inthiswork,weaimtobridgethisgapbyprovidingthefirstsystematicstudy
on watermark-based, user-aware detection and attribution of AI-generated content. Specifically,
wetheoreticallystudythedetectionandattributionperformanceviarigorousprobabilisticanalysis.
Moreover,wedevelopanefficientalgorithmtoselectwatermarksfortheuserstoenhanceattribution
performance. Bothourtheoreticalandempiricalresultsshowthatwatermark-baseddetectionand
attributioninherittheaccuracyand(non-)robustnesspropertiesofthewatermarkingmethod.
1 Introduction
GenerativeAI(GenAI)‚ÄìsuchasDALL-E3,Midjourney,andChatGPT‚Äìcansynthesizeveryrealistic-lookingcontent
suchasimages,texts,andaudios. Beyonditssocietalbenefits,GenAIalsoraisesmanyethicalconcerns. Forinstance,
theycanbemisusedtogenerateharmfulcontent;theycanbeusedtoaiddisinformationandpropagandacampaigns
bygeneratingrealistic-lookingcontent[1];andpeoplecanfalselyclaimcopyrightownershipofcontentgeneratedby
them[2].
Watermark-baseddetectionandattributionofAI-generatedcontentisapromisingtechniquetomitigatetheseethical
concerns. For instance, several companies‚Äìsuch as Google, OpenAI, Stability AI, and Microsoft‚Äìhave deployed
suchtechniquestowatermarktheirAI-generatedimages. Specifically,OpenAIinsertsavisiblewatermarkintothe
imagesgeneratedbyitsDALL-E2[3];Google‚ÄôsSynthID[4]insertsaninvisiblewatermarkintoimagesgenerated
byitsImagen;StabilityAIdeploysawatermarkingmethodinitsStableDiffusion[5];andMicrosoftwatermarksall
AI-generatedimagesinBing[6].
However,existingliteraturemainlyfocusesonuser-agnosticdetectionofAI-generatedcontent. Inparticular,thesame
watermarkisinsertedintoallthecontentgeneratedbyaGenAIservice;andacontentisdetectedasgeneratedbythe
GenAIserviceifasimilarwatermarkcanbedecodedfromit. Attributionaimstofurthertracebacktheregistered
useroftheGenAIservicewhogeneratedagivencontent.1 SuchattributioncanaidtheGenAIserviceproviderorlaw
enforcementinforensicanalysisofcyber-crimes,suchasdisinformationandpropagandacampaigns,thatinvolvea
givenAI-generatedcontent. Despitethegrowingimportanceofattribution,itislargelyunexplored. Inthiswork,we
aimtobridgethisgapbyprovidingasystematicstudyonwatermark-baseddetectionandattributionofAI-generated
content.
Wenotethatarelevantbutorthogonalresearchdirectionistodevelopwatermarkingmethodsthatarerobustagainst
post-processingofAI-generatedcontent. Westressthatitisstillanongoingefforttodeveloprobustwatermarkingand
thecommunityhasalreadymadesignificantprogressinthepastseveralyears. Forinstance,non-learning-basedimage
watermarking[7‚Äì9],whichhasbeenstudiedfordecades,isnotrobustagainstcommonpost-processingsuchasJPEG
compression,Gaussianblur,andBrightness/Contrast. However,recentlearning-basedimagewatermarking[10‚Äì14]
is robust against such common post-processing [11] because it can leverage adversarial training [15]. Although
learning-basedimagewatermarkingisnotrobustyetagainstadversarialpost-processinginthewhite-boxsetting[16];
1AttributioncouldalsorefertotracingbacktheGenAIservicethatgeneratedagivencontent,whichwediscussinSection7.
4202
rpA
5
]RC.sc[
1v45240.4042:viXraWatermark Database Watermark Database
01001001
ùë§"
AI-gen &
ùëà!: ùë§!
Detection
generated by ùëà"
GenAI Encoder Decoder 01001001 &
Attribution
Watermark 01101001 ùëà" Non-AI-gen
Selection
ùëà!
ùë§!
Registration Generation Detection & Attribution
Figure1: Illustrationofregistration,generation,anddetection&attributionphasesofwatermark-baseddetectionand
attribution.
ithasgoodrobustnessagainstadversarialpost-processingwhenanattackercanonlyquerythedetectionAPIfora
smallnumberoftimesintheblack-boxsettingordoesnothaveaccesstothedetectionAPI[16]. Forinstance,Google
restrictsaccessofitsdetectionAPItoonlytrustedcustomers[17]. Sinceourdetectionandattributionmethodrelieson
watermarkingtechniques,itinheritstheir(non-)robustnessproperties.
Ourwork: Inthiswork,weconductthefirstsystematicstudyonthetheory,algorithm,andevaluationofwatermark-
baseddetectionandattributionofAI-generatedcontent. Figure1illustratesourmethod. Whenauserregistersin
aGenAIservice,theserviceproviderselectsawatermark(i.e.,abitstring)forhim/herandstoresitinawatermark
database. WhenausergeneratesacontentusingtheGenAIservice,theuser‚Äôswatermarkisinsertedintothecontent
usingthewatermarkencoder. AcontentisdetectedasgeneratedbytheGenAIserviceifthewatermarkdecodedfrom
thecontentissimilarenoughtoatleastoneuser‚Äôswatermarkinthewatermarkdatabase. Moreover,thecontentis
furtherattributedtotheuserwhosewatermarkisthemostsimilartothedecodedone.
Theory. Wetheoreticallyanalyzetheperformanceofwatermark-baseddetectionandattribution. Specifically,wedefine
threekeyevaluationmetrics: truedetectionrate(TDR),falsedetectionrate(FDR),andtrueattributionrate(TAR).
TDR(orTAR)istheprobabilitythatanAI-generatedcontentiscorrectlydetected(orattributed),whileFDRisthe
probabilitythatanon-AI-generatedcontentisfalselydetectedasAI-generated. Weshowthatotherrelevantevaluation
metricscanbederivedfromthesethree. Basedonaformalquantificationofawatermarkingmethod‚Äôsbehavior,we
derivelowerboundsofTDRandTAR,andanupperboundofFDRnomatterhowtheusers‚Äôwatermarksareselected.
Wealsodiscussmultipletheoreticalinsightsaboutthedetection/attributionperformancebasedonourderivedbounds.
Algorithm. Selecting watermarks for the users is a key component of watermark-based detection and attribution.
Intuitively, attribution is hard if the users‚Äô watermarks are similar to each other. In fact, our derived lower bound
ofTARalsoalignswithsuchintuition. Therefore,toenhanceattributionperformance,weaimtoselectdissimilar
watermarksfortheusers. Formally,weformulateawatermarkselectionproblem,whichaimstoselectawatermarkfor
anewregistereduserviaminimizingthemaximumsimilaritybetweentheselectedwatermarkandtheexistingusers‚Äô
watermarks. Wefindthatourwatermarkselectionproblemisequivalenttothewell-knownfartheststringproblem[18],
whichhasbeenstudiedextensivelyinthetheoreticalcomputersciencecommunity. Moreover,sincethefartheststring
problemisNP-hard,ourwatermarkselectionproblemisalsoNP-hard,whichimpliesthechallengesofdeveloping
efficient, exact solutions. Thus, we resort to efficient, approximate solutions. In particular, we adapt the bounded
searchtreealgorithm[19],astate-of-the-artinefficient,exactsolutiontothefartheststringproblem,asanefficient,
approximatealgorithmtoselectwatermarks.
Empiricalevaluation. WeempiricallyevaluateourmethodforAI-generatedimagesonthreeGenAImodels, i.e.,
StableDiffusion,Midjourney,andDALL-E2. WeuseHiDDeN[11],thestate-of-the-artlearning-basedwatermarking
method. Notethatourdetectionandattributioninheritthe(non-)robustnesspropertiesofHiDDeN.Inparticular,our
resultsshowthatdetectionandattributionareveryaccurate,i.e.,TDR/TARiscloseto1andFDRiscloseto0,when
AI-generatedimagesarenotpost-processed;detectionandattributionarestillaccuratewhencommonpost-processing,
suchasJPEGcompression,Gaussianblur,andBrightness/Contrast,isappliedtoAI-generatedimages;andadversarial
post-processing[16]withasmallnumberofqueriestothedetectionAPIdegradestheimagequalitysubstantiallyin
ordertoevadedetection/attribution. Moreover,weshowourwatermarkselectionalgorithmoutperformsbaselines,and
ourmethodisalsoapplicabletoAI-generatedtexts.
Tosummarize,ourcontributionsareasfollows:
‚Ä¢ Weprovidethefirstsystematicstudyonwatermark-based,user-awaredetectionandattributionofAI-generated
content.
‚Ä¢ Theory. Wetheoreticallyanalyzethedetectionandattributionperformanceforanywatermarkingmethodand
nomatterhowthewatermarksareselectedfortheusers.
2‚Ä¢ Algorithm. Weformulateawatermarkselectionproblem,whichisinspiredbyourtheoreticalresults;andwe
developanefficient,approximatesolutionforit.
‚Ä¢ Evaluation. Weconductextensiveevaluationofourmethodindifferentscenarios.
2 RelatedWork
2.1 WatermarkingMethods
A watermarking method typically consists of three components: watermark, encoder, and decoder. We consider
a watermark w to be a bitstring. An encoder E embeds a watermark into a content, while a decoder D decodes a
watermarkfroma(watermarkedorunwatermarked)content. Whenacontenthaswatermarkw,thedecodedwatermark
issimilartow. NotethattheencoderE andwatermarkwcanalsobeembeddedintotheparametersofaGenAImodel
suchthatitsgeneratedcontentisinherentlywatermarkedwithw[14].
Non-learning-basedvs. learning-based: Watermarkingmethodscanbecategorizedintotwogroupsbasedonthe
designoftheencoderanddecoder: non-learning-basedandlearning-based. Non-learning-basedmethods[7‚Äì9,20,
21]designtheencoderanddecoderbasedonsomehand-craftedheuristics,whilelearning-basedmethods[10‚Äì14,22]
useneuralnetworksastheencoder/decoderandautomaticallylearnthemusingacontentdataset. Forinstance,Tree-
Ring[20]andLM-watermarking[21]respectivelyarenon-learning-basedwatermarkingmethodsforimagesandtexts;
whileHiDDeN[11]andAWT[22]respectivelyarelearning-basedmethodsforimagesandtexts. Ourwatermark-based
detectionandattributionmethod,theory,andalgorithmareapplicabletobothcategoriesofwatermarkingmethods.
However,sincelearning-basedwatermarkingmethodsaremorerobustduetoadversarialtraining[11],weadopta
learning-basedwatermarkingmethodinourexperiments.
Standardtrainingvs. adversarialtraining: Inlearning-basedwatermarkingmethods,theencoderanddecoderare
automaticallylearntusingacontentdataset. Specifically,givenacontentC andarandomwatermarkw,thedecoded
watermarkD(E(C,w))forthewatermarkedcontentE(C,w)shouldbesimilartow,i.e.,D(E(C,w))‚âàw. Based
onthisintuition,standardtrainingaimstolearnanencoderE anddecoderDsuchthatD(E(C,w))issimilartow
foracontentdataset[10]. AwatermarkedcontentE(C,w)maybepost-processed,e.g.,awatermarkedimagemay
be post-processed by JPEG compression during transmission on the Internet. Zhu et al. [11] extended adversarial
training [15, 23], a standard technique to train robust classifiers, to train watermarking encoder and decoder that
aremorerobustagainstpost-processing. Specifically,adversarialtrainingaimstolearnanencoderE anddecoder
D suchthatD(P(E(C,w)))issimilartow, whereP standsforapost-processingoperationandP(E(C,w))isa
post-processedwatermarkedcontent. Ineachepochofadversarialtraining,aP israndomlysampledfromagivenset
ofthemforeachcontentinthecontentdataset.
Robustnessofwatermarking: Westressthatbuildingrobustwatermarkingmethodsisorthogonaltoourworkandis
stillanongoingeffort. Non-learning-basedwatermarkingmethods[7‚Äì9,20,21]areknowntobenon-robusttocommon
post-processingsuchasJPEGcompressionforimages[11,14]andparaphrasingfortexts[24],i.e.,suchcommon
post-processingcanremovethewatermarkfromawatermarkedcontent. Learning-basedwatermarkingmethods[10‚Äì14,
22]aremorerobusttosuchcommonpost-processingbecausetheycanleverageadversarialtraining. Forinstance,
common post-processing has to substantially decrease the quality of a watermarked image in order to remove the
watermark[12,13].
Jiangetal.[16]proposedadversarialpost-processingtoimagewatermarking,whichstrategicallyperturbsawater-
markedimagetoremovethewatermark. AccordingtoJiangetal.,learning-basedimagewatermarkingmethodsarenot
yetrobusttoadversarialpost-processinginthewhite-boxsettingwhereanattackerhasaccesstothedecoder. However,
they have good robustness to adversarial post-processing when an attacker can only query the detection API for a
smallnumberoftimesintheblack-boxsettingordoesnothaveaccesstothedetectionAPI.Inparticular,adversarial
post-processingsubstantiallydecreasesthequalityofawatermarkedimageinordertoremovethewatermarkinsuch
scenarios. Toenhancerobustness,aGenAIservicecankeepitswatermarkingencoder/decoderprivateandrestrictthe
accessofitsdetectionAPItoasmallnumberoftrustedcustomers. Forinstance,Google‚ÄôsSynthID[4]adoptssuch
strategy.
Weacknowledgethatourwatermark-baseddetectionandattributioninheritthewatermarkingmethod‚Äôs(non-)robustness
propertiesdiscussedabove.
32.2 Watermark-basedDetection
WatermarkhasbeenusedforproactivedetectionofAI-generatedcontent[21]. Inparticular,multiplecompanies‚Äìsuch
asStabilityAI,OpenAI,Google,andMicrosoft‚Äìhavedeployedwatermark-baseddetectionasdiscussedinIntroduction.
However,existingliteraturemainlyfocusesonuser-agnosticdetection. Specifically,aGenAIserviceproviderpicksa
watermark;wheneveracontentisgeneratedbytheGenAIservice,thewatermarkisembeddedintoitbeforereturningit
toauser;andacontentisdetectedasgeneratedbytheGenAIserviceifasimilarwatermarkcanbedecodedfromit. In
thiswork,westudywatermark-based,user-awaredetectionandattributionofAI-generatedcontent. Afterdetectinga
contentasgeneratedbytheGenAIservice,wefurthertracebacktheuseroftheGenAIservicewhogeneratedit.
3 ProblemFormulation
Problemsetup: SupposewearegivenagenerativeAImodel,whichisdeployedasaGenAIservice. Aregistereduser
sendsaprompt(i.e.,atext)totheGenAIservice,whichreturnsanAI-generatedcontenttotheuser. Thecontentcanbe
image,text,oraudio. Inthiswork,weconsiderdetectionandattributionofAI-generatedcontent. Detectionaimsto
decidewhetheragivencontentwasgeneratedbytheGenAIserviceornot;whileattributionfurthertracesbacktheuser
oftheGenAIservicewhogeneratedacontentdetectedasAI-generated. SuchattributioncanaidtheGenAIservice
providerorlawenforcementinforensicanalysisofcyber-crimes,e.g.,disinformationorpropagandacampaigns,that
involveagivenAI-generatedcontent. Weformallydefinethedetectionandattributionproblemsasfollows:
Definition1(DetectionofAI-generatedcontent). GivenacontentandaGenAIservice,detectionaimstoinferwhether
thecontentwasgeneratedbytheGenAIserviceornot.
Definition 2 (Attribution of AI-generated content). Given a content, a GenAI service, and s users U =
{U ,U ,¬∑¬∑¬∑ ,U }oftheGenAIservice,attributionaimstofurtherinferwhichuserusedtheGenAIservicetogenerate
1 2 s
thecontentafteritisdetectedasAI-generated.
WenotethatthesetofsusersU inattributioncouldincludeallregisteredusersoftheGenAIservice,inwhichsmaybe
verylarge. Alternatively,thissetmayconsistofasmallernumberofregisteredusersiftheGenAIserviceproviderhas
somepriorknowledgeonitsregisteredusers. Forinstance,theGenAIserviceprovidermayexcludetheregisteredusers,
whoareverifiedofflineastrusted,fromthesetU toreduceitssize. HowtoconstructthesetofusersU inattributionis
outofthescopeofthiswork. GivenanysetU,ourmethodaimstoinferwhichuserinU mayhavegeneratedagiven
content. WealsonotethatanotherrelevantattributionproblemistotracebacktheGenAIservicethatgeneratedagiven
content. OurmethodcanalsobeusedforsuchGenAI-serviceattribution,whichwediscussinSection7.
Threatmodel: AnAI-generated, watermarkedcontentmaybepost-processedbysomecommonpost-processing
techniquesinnon-adversarialsettings. Forinstance,animagemaybepost-processedbyJPEGcompressionduring
transmissionontheInternet,orausermayuseGaussianblurorBrightness/Contrasttoeditanimageinanimageeditor.
Inadversarialsettings,amalicioususermaypost-processanAI-generatedcontenttoevadedetectionand/orattribution.
Otherthanthecommonpost-processingtechniques,amalicioususermayalsouseadversarialpost-processing[16]
toremovethewatermarkinanAI-generatedcontent. Weassumethewatermarkencoder/decoderisprivateandthe
malicioususerhaslimitedaccesstothedetectionAPI,inwhichstate-of-the-artwatermarkingmethodshavegood
robustnesstopost-processing[16]. SuchthreatmodelariseswhenaGenAIserviceproviderrestrictstheaccessof
itsdetectionAPItoasmallsetoftrustedcustomers,e.g.,Google‚ÄôsSynthIDadoptsthisthreatmodel. Notethatour
theoreticalanalysisinSection5canexplicitlyquantifyandincorporatetheimpactofpost-processingonthedetection
andattributionperformance.
4 Watermark-basedDetectionandAttribution
4.1 Overview
Weproposeawatermark-baseddetectionandattributionmethod,whichisillustratedinFigure1. Whenauserregisters
intheGenAIservice,theserviceproviderselectsauniquewatermarkfortheuser. Wedenotebyw thewatermark
i
selectedforuserU ,whereiistheuserindex. Duringgeneration,whenauserU sendsaprompttotheGenAIservice
i i
togenerateacontent,theproviderusesthewatermarkencoderE toembedwatermarkw intothecontent. During
i
detectionandattribution,awatermarkisdecodedfromagivencontent;thegivencontentisdetectedasgeneratedby
theGenAIserviceifthedecodedwatermarkissimilarenoughtoatleastoneoftheusers‚Äôwatermarks;andthegiven
contentisfurtherattributedtotheuserwhosewatermarkisthemostsimilartothedecodedwatermarkafteritisdetected
asAI-generated.
4Next,wedescribethedetailsofdetectionandattribution. Moreover,wediscusshowtoselectwatermarksfortheusers
tomaximizetheattributionperformance.
4.2 Detection
Recall that we denote by U = {U ,U ,¬∑¬∑¬∑ ,U } the set of s users of the GenAI service for atribution. Each user
1 2 s
U hasawatermarkw ,wherei = 1,2,¬∑¬∑¬∑ ,s. Forconvenience,wedenotebyW = {w ,w ,¬∑¬∑¬∑ ,w }thesetofs
i i 1 2 s
watermarks. GivenacontentC,weusethedecoderDtodecodeawatermarkD(C)fromit. Ifthereexistsauser‚Äôs
watermarkthatissimilarenoughtoD(C),wedetectC asAI-generated. Weusebitwiseaccuracytomeasuresimilarity
betweentwowatermarks,whichweformallydefineasfollows:
BitwiseAccuracy(BA): Givenanytwowatermarkswandw‚Ä≤,theirbitwiseaccuracy(denotedasBA(w,w‚Ä≤))isthe
fractionofmatchedbitsinthem. Formally,wehavethefollowing:
n
1 ‚àëÔ∏Ç
BA(w,w‚Ä≤)= I(w[k]=w‚Ä≤[k]), (1)
n
k=1
wherenisthewatermarklength,w[k]isthekthbitofw,andIistheindicatorfunctionthathasavalue1ifw[k]=w‚Ä≤[k]
and0otherwise. AcontentC isdetectedasAI-generatedifandonlyifthefollowingsatisfies:
max BA(D(C),w )‚â•œÑ, (2)
i
i‚àà{1,2,¬∑¬∑¬∑,s}
whereœÑ >0.5isthedetectionthreshold.
4.3 Attribution
AttributionisappliedonlyafteracontentC isdetectedasAI-generated. Intuitively,weattributethecontenttotheuser
whosewatermarkisthemostsimilartothedecodedwatermarkD(C). Formally,weattributecontentC touserU ,
i‚àó
wherei‚àóisasfollows:
i‚àó = argmax BA(D(C),w ). (3)
i
i‚àà{1,2,¬∑¬∑¬∑,s}
4.4 WatermarkSelection
Akeycomponentofwatermark-baseddetectionandattributionishowtoselectwatermarksfortheusers. Next,wefirst
formulatewatermarkselectionasanoptimizationproblem,andthenproposeamethodtoapproximatelysolveit.
4.4.1 FormulatingaWatermarkSelectionProblem
Intuitively,iftwousershavesimilarwatermarks,thenitishardtodistinguishbetweenthemfortheattribution. An
extremeexampleisthattwousershavethesamewatermark,makingitimpossibletoattributeeitherofthem. Infact,our
theoreticalanalysisinSection5showsthatattributionperformanceisbetterifthemaximumpairwisebitwiseaccuracy
betweentheusers‚Äôwatermarksissmaller. Thus,toenhanceattribution,weaimtoselectwatermarksforthesusers
tominimizetheirmaximumpairwisebitwiseaccuracy. Formally,weformulatewatermarkselectionasthefollowing
optimizationproblem:
min max BA(w ,w ), (4)
i j
w1,w2,¬∑¬∑¬∑,wsi,j‚àà{1,2,¬∑¬∑¬∑,s},iÃ∏=j
whereBAstandsforbitwiseaccuracybetweentwowatermarks. Thisoptimizationproblemjointlyoptimizesthes
watermarkssimultaneously. Asaresult,itisverychallengingtosolvetheoptimizationproblembecausetheGenAI
serviceproviderdoesnotknowthenumberofregisteredusers(i.e.,s)inadvance. Inpractice,usersregisterinthe
GenAIserviceatverydifferenttimes. Toaddressthechallenge,weselectawatermarkforauseratthetimeofhis/her
registrationintheGenAIservice. ForthefirstuserU ,weselectawatermarkuniformlyatrandom. Supposewehave
1
selectedwatermarksfors‚àí1users. Then,thesthuserregistersandweaimtoselectawatermarkw whosemaximum
s
bitwiseaccuracywiththeexistings‚àí1watermarksisminimized. Formally, weformulateawatermarkselection
problemasfollows:
min max BA(w ,w ). (5)
i s
ws i‚àà{1,2,¬∑¬∑¬∑,s‚àí1}
54.4.2 SolvingtheWatermarkSelectionProblem
NP-hardness: WecanshowthatourwatermarkselectionprobleminEquation5isNP-hard. Inparticular,wecan
reducethewell-knownfartheststringproblem[18],whichisNP-hard,toourwatermarkselectionproblem. Inthe
fartheststringproblem,weaimtofindastringthatisthefarthestfromagivensetofstrings. Wecanviewastringasa
watermarkinourwatermarkselectionproblem,thegivensetofstringsasthewatermarksofthes‚àí1users,andthe
similaritymetricbetweentwostringsasourbitwiseaccuracy. Then,wecanreducethefartheststringproblemtoour
watermarkselectionproblem,whichmeansthatourwatermarkselectionproblemisalsoNP-hard. ThisNP-hardness
impliesthatitisverychallengingtodevelopanefficientexactsolutionforourwatermarkselectionproblem. Wenote
thatefficiencyisimportantforwatermarkselectionasweaimtoselectawatermarkforauseratthetimeofregistration.
Therefore,weaimtodevelopanefficientalgorithmthatapproximatelysolvesthewatermarkselectionproblem.
Random: ThemoststraightforwardmethodtoapproximatelysolvethewatermarkselectionprobleminEquation5is
togenerateawatermarkuniformlyatrandomasw . WedenotethismethodasRandom. Thelimitationofthismethod
s
isthattheselectedwatermarkw maybeverysimilartosomeexistingwatermarks,i.e.,max BA(w ,w )
s i‚àà{1,2,¬∑¬∑¬∑,s‚àí1} i s
islarge,makingattributionlessaccurate,asshowninourexperiments.
Decision problem: To develop an efficient algorithm to approximately solve our watermark selection problem,
wefirstdefineitsdecisionproblem. Specifically,giventhemaximumnumberofmatchedbitsbetweenw andthe
s
existings‚àí1watermarksasm,thedecisionproblemaimstofindsuchaw ifthereexistsoneandreturnNotExist
s
otherwise. Formally, thedecisionproblemistofindanywatermarkw inthefollowingsetifthesetisnonempty:
s
w ‚àà{w|max BA(w ,w)‚â§m/n},wherenisthewatermarklength. Next,wediscusshowtosolvethe
s i‚àà{1,2,¬∑¬∑¬∑,s‚àí1} i
decisionproblemandthenturnthealgorithmtosolveourwatermarkselectionproblem.
Boundedsearchtreealgorithm(BSTA)[19]: Recallthatourwatermarkselectionproblemisequivalenttothefarthest
stringproblem. Thus,ourdecisionproblemisequivalenttothatofthefartheststringproblem,whichhasbeenstudied
extensivelyinthetheoreticalcomputersciencecommunity. Inparticular,BSTAisthestate-of-the-artexactalgorithmto
solvethedecisionproblemversionofthefartheststringproblem. WeapplyBSTAtosolvethedecisionproblemversion
ofourwatermarkselectionproblemexactly,whichisshowninAlgorithm1inAppendix. ThekeyideaofBSTAisto
initializew as¬¨w (i.e.,eachbitofw flips),andthenreducethedecisionproblemtoasimplerproblemrecursively
s 1 1
untilitiseasilysolvableortheredoesnotexistasolutionw . Inparticular,givenaninitialw ,BSTAfirstfindsthe
s s
existingwatermarkw thathasthelargestbitwiseaccuracywithw . IfBA(w ,w ) ‚â§ m/n,thenw isalreadya
i‚àó s i‚àó s s
solutiontothedecisionproblemandthusBSTAreturnsw . Otherwise,BSTAchoosesanym+1bitsthatw andw
s s i‚àó
match. Foreachofthechosenm+1bits,BSTAflipsthecorrespondingbitinw andrecursivelysolvesthedecision
s
problemusingtheneww asaninitialization. Therecursionisappliedmtimesatmost,i.e.,therecursiondepthdisset
s
asmwhencallingAlgorithm1.
AkeylimitationofBSTAisthatithasanexponentialtimecomplexity[19]. Infact,sincethedecisionproblemis
NP-hard,allknownexactsolutionshaveexponentialtimecomplexity. Therefore,toenhancecomputationefficiency,
weresorttoapproximatesolutions. Next,wediscussthestate-of-the-artapproximatesolutionthatadaptsBSTAanda
newapproximatesolutionthatwepropose.
NonRedundantGuess(NRG)[25]: LikeBSTA,thisapproximatesolutionalsofirstinitializesw as¬¨w andfinds
s 1
theexistingwatermarkw thathasthelargestbitwiseaccuracywithw . IfBA(w ,w )‚â§m/n,thenNRGreturns
i‚àó s i‚àó s
w . Otherwise,NRGsamplesn¬∑BA(w ,w )‚àímbitsthatw andw matchuniformlyatrandom. Then,NRGflips
s i‚àó s s i‚àó
thesebitsinw andrecursivelysolvethedecisionproblemusingtheneww asaninitialization. NotethatNRGstops
s s
therecursionwhenmbitsoftheinitialw havebeenflipped. Algorithm2inAppendixshowsNRG.
s
Approximateboundedsearchtreealgorithm(A-BSTA): WeadaptBSTAasanefficientapproximatesolutionto
ourdecisionproblem. Specifically,A-BSTAmakestwoadaptionsofBSTA.First,weconstraintherecursiondepthd
tobeaconstant(e.g.,8inourexperiments)insteadofm,whichmakesthealgorithmapproximatebutimprovesthe
efficiencysubstantially. Second,insteadofinitializingw as¬¨w ,weinitializew asanuniformlyrandomwatermark.
s 1 s
AsourexperimentsinTable3inAppendixshow,ourinitializationfurtherimprovestheperformanceofA-BSTA.This
isbecausearandominitializationismorelikelytohavesmallbitwiseaccuracywithallexistingwatermarks. Notethat
BSTA,NRG,andA-BSTAallreturnNotExistiftheycannotfindasolutionw tothedecisionproblem.
s
Solvingourwatermarkselectionproblem: Givenanalgorithm(e.g.,BSTA,NRG,orA-BSTA)tosolvethedecision
problem,weturnitasasolutiontoourwatermarkselectionproblem. Specifically,ourideaistostartfromasmall
m, and then solve the decision problem. If we cannot find a watermark w for the given m, we increase it by 1
s
andsolvethedecisionproblemagain. Werepeatthisprocessuntilfindingawatermarkw . Notethatwestartfrom
s
m = max n¬∑BA(w ,w ),i.e.,themaximumnumberofmatchedbitsbetweenw andtheother
i‚àà{1,2,¬∑¬∑¬∑,s‚àí2} i s‚àí1 s‚àí1
6s‚àí2watermarks. Thisisbecauseanmsmallerthanthisvalueisunlikelytoproduceawatermarkw asitfailedtodo
s
sowhenselectingw . Algorithm3inAppendixshowsourmethod.
s‚àí1
Notethatbinarysearchisanotherwaytofindaproperm. Specifically,westartwithasmallm(denotedasm )that
l
doesnotproduceaw andalargem(denotedasm )thatdoesproduceaw . Ifm=(m +m )/2producesaw ,
s u s l u s
weupdatem =(m +m )/2;otherwiseweupdatem =(m +m )/2. Thesearchprocessstopswhenm ‚â•m .
u l u l l u l u
However,wefoundthatincreasingmby1asinourAlgorithm3ismoreefficientthanbinarysearch. Thisisbecause
increasingmby1expandsthesearchspaceofw substantially,whichoftenleadstoavalidw . Onthecontrary,binary
s s
searchwouldrequiresolvingthedecisionproblemmultipletimeswithdifferentmuntilfindingthatm+1isenough.
Timecomplexity: Weanalyzethetimecomplexityofthealgorithmstosolvethedecisionproblem. ForRandom,the
timecomplexityisO(n). ForBSTA,thetimecomplexitytosolvethedecisionproblemwithparametermisO(snmm)
‚àö
accordingto[19]. ForNRG,thetimecomplexityisO(sn+s m¬∑5m)accordingto[25]. ForA-BSTA,thetime
complexityisO(snmd),wheredisaconstant.
5 TheoreticalAnalysis
Wetheoreticallyanalyzethedetectionandattributionperformanceofourwatermark-basedmethod. Wefirstformally
defineseveralkeymetricstoevaluatetheperformanceofdetectionandattribution. Then,wetheoreticallyanalyzethe
evaluationmetrics. AllourproofsareshowninAppendix.
5.1 ContentDistributions
SupposewearegivensusersU ={U ,U ,¬∑¬∑¬∑ ,U },eachofwhichhasanuniquewatermarkw ,wherei=1,2,¬∑¬∑¬∑ ,s.
1 2 s i
WedenotetheswatermarksasasetW ={w ,w ,¬∑¬∑¬∑ ,w }. WhenauserU generatescontentviatheGenAIservice,
1 2 s i
theserviceproviderusestheencoderE toembedthewatermarkw intothecontent. WedenotebyP theprobability
i i
distributionofthewatermarkedcontentgeneratedbyU .NotethattwousersU andU mayhavedifferentAI-generated,
i i j
watermarkedcontentdistributionsP andP . Thisisbecausethetwousershavedifferentwatermarksandtheymay
i j
be interested in generating different types of content. Moreover, we denote by Q the probability distribution of
non-AI-generatedcontent.
5.2 EvaluationMetrics
(User-dependent) True Detection Rate (TDR): TDR is the probability that an AI-generated content is correctly
detected. NotethatdifferentusersmayhavedifferentAI-generatedcontentdistributions. Therefore,TDRdependson
users. WedenotebyTDR thetruedetectionrateforthewatermarkedcontentgeneratedbyuserU ,i.e.,TDR isthe
i i i
probabilitythatacontentC sampledfromtheprobabilitydistributionP uniformlyatrandomiscorrectlydetectedas
i
AI-generated. Formally,wehave:
TDR =Pr( max BA(D(C),w )‚â•œÑ), (6)
i j
j‚àà{1,2,¬∑¬∑¬∑,s}
whereBAisthebitwiseaccuracybetweentwowatermarks,Disthedecoder,C ‚àºP ,andœÑ isthedetectionthreshold.
i
Thenotation‚àºindicatesacontentissampledfromadistributionuniformlyatrandom.
FalseDetectionRate(FDR): FDRistheprobabilitythatacontentC sampledfromthenon-AI-generatedcontent
distributionQuniformlyatrandomisdetectedasAI-generated. NotethatFDRdoesnotdependonusers. Formally,we
have:
FDR=Pr( max BA(D(C),w )‚â•œÑ), (7)
j
j‚àà{1,2,¬∑¬∑¬∑,s}
whereC ‚àºQ.
(User-dependent)TrueAttributionRate(TAR): TARistheprobabilitythatanAI-generatedcontentiscorrectly
attributedtotheuserthatgeneratedthecontent. LikeTDR,TARalsodependsonusers. WedenotebyTAR thetrue
i
attributionrateforthewatermarkedcontentgeneratedbyuserU ,i.e.,TAR istheprobabilitythatacontentsampled
i i
fromP uniformlyatrandomiscorrectlyattributedtouserU . Formally,wehave:
i i
TAR =Pr( max BA(D(C),w )‚â•œÑ ‚àßBA(D(C),w )> max BA(D(C),w )), (8)
i j i j
j‚àà{1,2,¬∑¬∑¬∑,s} j‚àà{1,2,¬∑¬∑¬∑,s}/{i}
7Non-AI-gen AI-gen
Ground-truth label
Content Content
ùê∂ùê∂~ùí¨ùí¨ ùê∂ùê∂~ùí´ùí´ùëñùëñ
Detection Non-AI-gen AI-gen Non-AI-gen AI-gen
‚ë† ‚ë¢
Incorrect Correct Incorrect
Attribution
attribution attribution attribution
‚ë° ‚ë£ ‚ë§
Figure2: Taxonomyofdetectionandattributionresults. Nodeswithredcolorindicateincorrectdetection/attribution.
whereC ‚àºP ,thefirsttermmax BA(D(C),w )‚â•œÑ meansthatC isdetectedasAI-generated,andthe
i j‚àà{1,2,¬∑¬∑¬∑,s} j
secondtermBA(D(C),w )>max BA(D(C),w )meansthatC isattributedtouserU . Notethatwe
i j‚àà{1,2,¬∑¬∑¬∑,s}/{i} j i
havethefirsttermbecauseattributionisonlyappliedafterdetectingacontentasAI-generated.
OtherevaluationmetricscanbederivedfromTDR ,FDR,andTAR : Wenotethattherearealsootherrelevant
i i
detectionandattributionmetrics,e.g.,theprobabilitythatanAI-generatedcontentisincorrectlyattributedtoauser.
WeshowthatotherrelevantdetectionandattributionmetricscanbederivedfromTDR ,FDR,andTAR ,andthuswe
i i
focusonthesethreemetricsinourwork. Specifically,Figure2showsthetaxonomyofdetectionandattributionresults
fornon-AI-generatedcontentandAI-generatedcontentgeneratedbyuserU . Inthetaxonomytrees,thefirst-level
i
nodesrepresentground-truthlabelsofcontent;thesecond-levelnodesrepresentpossibledetectionresults;andthe
third-levelnodesrepresentpossibleattributionresults(notethatattributionisonlyperformedafteracontentisdetected
asAI-generated).
Inthetaxonomytrees,thereare5branchesintotal,whicharelabeledas‚ë†,‚ë°,‚ë¢,‚ë£,and‚ë§inthefigure. Eachbranch
startsfromarootnodeandendsataleafnode,andcorrespondstoametricthatmaybeofinterest. Forinstance,our
TDR istheprobabilitythatacontentC ‚àº P goesthroughbranches‚ë£or‚ë§;FDRistheprobabilitythatacontent
i i
C ‚àº Q goes through branch ‚ë°; and TAR is the probability that a content C ‚àº P goes through branch ‚ë£. The
i i
probabilitythatacontentgoesthroughotherbranchescanbecalculatedusingTDR ,FDR,and/orTAR . Forinstance,
i i
theprobabilitythatanon-AI-generatedcontentC ‚àºQiscorrectlydetectedasnon-AI-generatedistheprobabilitythat
Cgoesthroughthebranch‚ë†,whichcanbecalculatedas1‚àíFDR.TheprobabilitythatanAI-generatedcontentC ‚àºP
i
isincorrectlydetectedasnon-AI-generatedistheprobabilitythatC goesthroughthebranch‚ë¢,whichcanbecalculated
as1‚àíTDR . TheprobabilitythatauserU ‚ÄôsAI-generatedcontentC ‚àºP iscorrectlydetectedasAI-generatedbut
i i i
incorrectlyattributedtoadifferentuserU istheprobabilitythatC goesthroughthebranch‚ë§,whichcanbecalculated
j
asTDR ‚àíTAR .
i i
5.3 FormalQuantificationofWatermarking
Intuitively,totheoreticallyanalyzethedetectionandattributionperformance(i.e.,TDR ,FDR,andTAR ),weneed
i i
aformalquantificationofawatermarkingmethod‚ÄôsbehavioratdecodingwatermarksinAI-generatedcontentand
non-AI-generatedcontent. Towardsthisend,weformallydefineŒ≤-accurateandŒ≥-randomwatermarkingasfollows:
Definition 3 (Œ≤-accurate watermarking). For a randomly sampled AI-generated content C ‚àº P embedded with
watermark w, the bits of the decoded watermark D(C) are independent and each bit matches with that of w with
probabilityŒ≤,whereŒ≤ ‚àà[0,1]. Formally,wehavePr(D(C)[k]=w[k])=Œ≤,whereC ‚àºP,Disthedecoder,and[k]
representsthekthbitofawatermark. WesayawatermarkingmethodisŒ≤-accurateifitsatisfiestheabovecondition.
Definition 4 (Œ≥-random watermarking). For a randomly sampled non-AI-generated content C ‚àº Q without any
watermarkembedded,thebitsofthedecodedwatermarkD(C)areindependentandeachbitis1withprobabilityat
least0.5‚àíŒ≥andatmost0.5+Œ≥,whereŒ≥ ‚àà[0,0.5]. Formally,wehave|Pr(D(C)[k]=1)‚àí0.5|‚â§Œ≥,whereC ‚àºQ
and[k]representsthekthbitofawatermark. WesayawatermarkingmethodisŒ≥-randomifitsatisfiestheabove
condition.
8TheparameterŒ≤ isusedtocharacterizetheaccuracyofthewatermarkingmethodatencoding/decodingawatermark
in an AI-generated content. In particular, the watermarking method is more accurate when Œ≤ is closer to 1. For a
Œ≤-accuratewatermarkingmethod,thenumberofmatchedbitsbetweenthedecodedwatermarkD(C)forawatermarked
contentC andtheground-truthwatermarkfollowsabinomialdistributionwithparametersnandŒ≤,wherenisthe
watermark length. The parameter Œ≥ characterizes the behavior of the watermarking method for non-AI-generated
content. In particular, the decoded watermark for a non-AI-generated (i.e., unwatermarked) content is close to a
uniformlyrandomwatermark,whereŒ≥ quantifiesthedifferencebetweenthem. Thewatermarkingmethodismore
randomfornon-AI-generatedcontentifŒ≥ iscloserto0.
User-dependentŒ≤ : Sincetheusers‚ÄôAI-generatedcontentmayhavedifferentdistributionsP ,thesamewatermarking
i i
methodmayhavedifferentŒ≤ fordifferentusers. Tocapturethisphenomena,weconsiderthewatermarkingmethod
isŒ≤ -accurateforuserU ‚ÄôsAI-generatedcontentembeddedwithwatermarkw . NotethatthesameŒ≥ isusedacross
i i i
differentuserssinceitisusedtocharacterizethebehaviorofthewatermarkingmethodfornon-AI-generatedcontent,
whichisuser-independent. TheparametersŒ≤ andŒ≥canbeestimatedusingasetofAI-generatedandnon-AI-generated
i
content,asshowninourexperiments.
Incorporating post-processing: Our definition of Œ≤-accurate and Œ≥-random watermarking can also incorporate
post-processing(e.g.,JPEGcompression)thatanattacker/usermayapplytoAI-generatedornon-AI-generatedcontent.
In particular, we can replace D(C) as D(P(C)) in our definitions, where P stands for post-processing of content
C. WhenAI-generatedcontentispost-processed,thewatermarkingmethodmaybecomelessaccurate,i.e.,Œ≤ may
decrease.
5.4 DetectionPerformance
DerivingalowerboundofTDR : Intuitively,anuserU ‚ÄôsAI-generatedcontentC ‚àºP canbecorrectlydetectedas
i i i
AI-generatedintwocases:
‚Ä¢ CaseI.ThedecodedwatermarkD(C)issimilarenoughtotheuserU ‚Äôswatermarkw .
i i
‚Ä¢ CaseII.ThedecodedwatermarkD(C)isdissimilartow butsimilarenoughtosomeotheruser‚Äôswatermark.
i
Case II is more likely to happen when w is more dissimilar to some other user‚Äôs watermark, i.e., when Œ± =
i i
min BA(w ,w )issmaller. ThisisbecausethefactthatD(C)isdissimilartow andw isdissimilar
j‚àà{1,2,¬∑¬∑¬∑,s}/{i} i j i i
tosomeotheruser‚ÄôswatermarkimpliesthatD(C)issimilartosomeotheruser‚Äôswatermark. Formally,wecanderivea
lowerboundofTDR asfollows:
i
Theorem1(LowerboundofTDR ). SupposewearegivensuserswithanyswatermarksW ={w ,w ,¬∑¬∑¬∑ ,w }.
i 1 2 s
WhenthewatermarkingmethodisŒ≤ -accurateforuserU ‚ÄôsAI-generatedcontent,wehavealowerboundofTDR as
i i i
follows:
TDR ‚â•Pr(n ‚â•œÑn)+Pr(n ‚â§n‚àíœÑn‚àíŒ± n), (9)
i i i i
where n follows a binomial distribution with parameters n and Œ≤ , i.e., n ‚àº B(n,Œ≤ ), Œ± =
i i i i i
min BA(w ,w ),nisthewatermarklength,and0.5<œÑ <Œ≤ .
j‚àà{1,2,¬∑¬∑¬∑,s}/{i} i j i
ThetwotermsinthelowerboundrespectivelyboundtheprobabilitiesforCaseIandCaseIIofcorrectlydetectinguser
U ‚ÄôsAI-generatedcontent. BasedonTheorem1,wehavethefollowingcorollary.
i
Corollary1. Whenthewatermarkingmethodismoreaccurate,i.e.,Œ≤ iscloserto1,thelowerboundofTDR islarger.
i i
DerivinganupperboundofFDR: Intuitively,anon-AI-generatedcontentC ‚àº Qisalsoincorrectlydetectedas
AI-generatedintwocases: 1)thedecodedwatermarkD(C)issimilarenoughwithsomeuser‚Äôswatermark,e.g.,w ;
1
and2)thedecodedwatermarkD(C)isdissimilartow butsimilarenoughtosomeotheruser‚Äôswatermark. Basedon
1
thisintuition,wecanderiveanupperboundofFDRasfollows:
Theorem2(UpperboundofFDR). SupposewearegivensuserswithswatermarksW = {w ,w ,¬∑¬∑¬∑ ,w }and
1 2 s
watermarkw isselecteduniformlyatrandom. WehaveanupperboundofFDRasfollows:
1
FDR‚â§Pr(n ‚â•œÑn)+Pr(n ‚â§n‚àíœÑn+Œ± n), (10)
1 1 1
where n follows a binomial distribution with parameters n and 0.5, i.e., n ‚àº B(n,0.5), and Œ± =
1 1 1
max BA(w ,w ).
j‚àà{2,3,¬∑¬∑¬∑,s} 1 j
9NotethattheupperboundofFDRinTheorem2doesnotdependonŒ≥-randomwatermarkingsinceweconsiderw
1
ispickeduniformlyatrandom. However,wefoundsuchupperboundisloose. Thisisbecausethesecondtermof
the upper bound considers the worst-case scenario of the s watermarks. The next theorem shows that when the s
watermarksareconstrained,inparticularselectedindependently,wecanderiveatighterupperboundofFDR.
Theorem3(AlternativeupperboundofFDR). SupposewearegivensuserswithswatermarksW ={w ,w ,¬∑¬∑¬∑ ,w }
1 2 s
selectedindependently. WhenthewatermarkingmethodisŒ≥-randomfornon-AI-generatedcontent,wehaveanupper
boundofFDRasfollows:
FDR‚â§1‚àíPr(n‚Ä≤ <œÑn)s, (11)
wheren‚Ä≤ ‚àºB(n,0.5+Œ≥).
BasedonTheorem3,wehavethefollowingcorollary.
Corollary2. Whenthewatermarkingmethodismorerandomfornon-AI-generatedcontent,i.e.,Œ≥ iscloserto0,the
upperboundofFDRissmaller.
Impactofsonthebounds: Intuitively,whentherearemoreusers,i.e.,sislarger,itismorelikelytohaveatleastone
userwhosewatermarkhasabitwiseaccuracywiththedecodedwatermarkD(C)thatisnosmallerthanœÑ. Asaresult,
bothTDR andFDRmayincreaseassincreases,i.e.,scontrolsatrade-offbetweenTDR andFDR.Ourtheoretical
i i
resultsalignwiththisintuition. Ononehand,ourTheorem1showsthatthelowerboundofTDR islargerwhens
i
islarger. Inparticular,whensincreases,theparameterŒ± maybecomesmaller. Therefore,thesecondtermofthe
i
lowerboundincreases,leadingtoalargerlowerboundofTDR . Ontheotherhand,theupperboundofFDRinboth
i
Theorem2andTheorem3increasesassincreases. Inparticular,inTheorem2,theparameterŒ± becomeslargerwhen
1
sincreases,leadingtoalargersecondtermoftheupperbound.
User-agnostic vs. user-aware detection: Existing watermark-based detection is user-agnostic, i.e., it does not
distinguishbetweendifferentuserswhenembeddingawatermarkintoanAI-generatedcontent. Thefirsttermofthe
lowerboundinourTheorem1isalowerboundofTDRforuser-agnosticdetection;thefirsttermoftheupperboundin
ourTheorem2isanupperboundofFDRforuser-agnosticdetection;andtheupperboundwiths=1inourTheorem3
isanalternativeupperboundofFDRforuser-agnosticdetection. Therefore,comparedtouser-agnosticdetection,our
user-awaredetectionachieveslargerTDRbutalsolargerFDR.
5.5 AttributionPerformance
SupposewearegivenauserU ‚ÄôsAI-generatedcontentC ‚àºP . Intuitively,ifthewatermarkw isverydissimilarto
i i i
theothers‚àí1watermarks,i.e.,Œ± =max BA(w ,w )issmall,thenC canbecorrectlyattributedto
i j‚àà{1,2,¬∑¬∑¬∑,s}/{i} i j
U onceC isdetectedasAI-generated,i.e.,thedecodedwatermarkD(C)issimilarenoughtow . Ifthewatermarkw
i i i
issimilartosomeotherwatermark,i.e.,Œ± islarge,thenthedecodedwatermarkD(C)hastobeverysimilartow in
i i
ordertocorrectlyattributeC toU . Formally,wecanderivealowerboundofTAR inthefollowingtheorem.
i i
Theorem4(LowerboundofTAR ). SupposewearegivensuserswithanyswatermarksW ={w ,w ,¬∑¬∑¬∑ ,w }.
i 1 2 s
WhenthewatermarkingmethodisŒ≤ -accurateforuserU ‚ÄôsAI-generatedcontent,wehavealowerboundofTAR as
i i i
follows:
1+Œ±
TAR ‚â•Pr(n ‚â•max{‚åä in‚åã+1,œÑn}), (12)
i i 2
where n follows a binomial distribution with parameters n and Œ≤ , i.e., n ‚àº B(n,Œ≤ ), Œ± =
i i i i i
max BA(w ,w ),nisthewatermarklength,andœÑ isthedetectionthreshold.
j‚àà{1,2,¬∑¬∑¬∑,s}/{i} i j
OurTheorem4showsthatthelowerboundofTAR islargerwhenŒ≤ iscloserto1,i.e.,attributionperformanceis
i i
betterwhenthewatermarkingmethodismoreaccurate. Moreover,thelowerboundislargerwhenŒ± issmallerbecause
i
itiseasiertodistinguishbetweenusers. Thisisatheoreticalmotivationonwhyourwatermarkselectionproblemaims
toselectwatermarksfortheuserssuchthattheyhavesmallpairwisebitwiseaccuracy.
Detectionimpliesattribution: WhenœÑ > 1+ 2Œ±i,thelowerboundofTAR iinTheorem4becomesTAR
i
‚â•Pr(n
i
‚â•œÑn).
ThesecondtermofthelowerboundofTDR inTheorem1isusuallymuchsmallerthanthefirstterm. Inotherwords,
i
thelowerboundofTDR
i
isalsoroughlyPr(n
i
‚â•œÑn). Therefore,whenœÑ islargeenough(i.e.,> 1+ 2Œ±i),TDR
i
and
TAR areveryclose,whichisalsoconfirmedinourexperiments. ThisresultindicatesthatonceanAI-generatedcontent
i
iscorrectlydetected,itwouldalsobecorrectlyattributed.
101.000
0.975
0.950
StableDiffusion
0.925 Midjourney
DALL¬∑E2
0.900
0 1 2 3 4 5
RankIndex(Log10Scale)
Figure3: RankedTARsofthe100,000users.
6 Experiments
Inourmajorexperiments,wefocusondetectionandattributionofAI-generatedimages. InSection7,wealsoshow
resultsforAI-generatedtexts.
6.1 ExperimentalSetup
Datasets: WeconsiderbothAI-generatedandnon-AI-generatedimagesasfollows:
AI-generated. WeconsiderthreeGenAImodels,i.e.,StableDiffusion,Midjourney,andDALL-E2,whichcorrespond
tothreedatasetsofAI-generatedimages. ForStableDiffusion,weusepubliclyavailabledatasetDiffusionDB[26]. For
Midjourney,wecollectitsgeneratedimagesfromawebsite[27]. ForDALL-E2,wealsocollectitsgeneratedimages
from a website [28]. Following HiDDeN [11], for each dataset, we sample 10,000 images for training watermark
encodersanddecoders;andwesample1,000imagesfortestingtheperformanceofwatermark-baseddetectionand
attribution.
Non-AI-generated. To evaluate the likelihood that a non-AI-generated image is falsely detected as AI-generated,
weneednon-AI-generatedimages. Forthispurpose,wecombinetheimagesinthreebenchmarkdatasets,including
COCO[29],ImageNet[30],andConceptualCaption[31],andsample1,000imagesfromthecombinedsetuniformly
atrandomasournon-AI-generatedimagedataset.
Wescaletheimagesizeinalldatasetstobe128√ó128.
Watermarkingmethod: Weusethestate-of-the-artlearning-basedwatermarkingmethodHiDDeN[11]. Unless
otherwisementioned,weusestandardtrainingwiththedefaultparametersettingsinthepubliclyavailablecode,except
thatweuseResNet18asthedecodertoenlargethecapacitytoencode/decodelongerwatermarks. ForeachGenAI
model,wetrainawatermarkencoder/decoderusingthecorrespondingAI-generatedimagetrainingsetandevaluatethe
detectionandattributionperformanceonthetestingset.
Watermarkselectionmethods: WeevaluateRandom,NRG,andA-BSTAwatermarkselectionmethods. Unless
otherwisementioned,weuseA-BSTA.NotethatwedonotuseBSTAbecauseitisnotscalable. Forinstance,ittakes
BSTAmorethan8hourstogenerateeven16watermarks.
Evaluationmetrics: AsdiscussedinSection5.2,wemainlyusethreeevaluationmetrics,i.e.,TrueDetectionRate
(TDR),FalseDetectionRate(FDR),andTrueAttributionRate(TAR).FDRisthefractionofthe1,000non-AI-generated
imagesthatarefalselydetectedasAI-generated. FDRdoesnotdependonusers. Incontrast,TDRandTARdependon
usersbecausetheyusedifferentwatermarks,leadingtodifferentdistributionsofAI-generatedimages. Foreachofthes
users,weembeditswatermarkinto100imagesrandomlysampledfromatestingAI-generatedimagedataset;andthen
wecalculatetheTDRandTARfortheuser.
In most of our experiments, we report the average TDR and average TAR, which respectively are the TDR and
TARaveragedamongthesusers. However, averageTDRandaverageTARcannotreflectthedetection/attribution
performancefortheworst-caseusers,i.e.,someusersmayhavequitesmallTDR/TAR,buttheaverageTDR/TARmay
stillbeverylarge. Therefore,wefurtherconsiderthe1%users(atleast1user)withthesmallestTDR(orTAR)and
reporttheiraverageTDR(orTAR),whichwecallworst1%TDR(orworst1%TAR).
Parametersettings: Bydefault,wesetthenumberofuserss=100,000,watermarklengthn=64,anddetection
threshold œÑ = 0.9. To compute TAR of an user, we need to compute the bitwise accuracy between the decoded
watermarkandeachuser‚Äôswatermarkforeachwatermarkedimage,andthuswesets=100,000duetoourlimited
11Table1: TheaverageŒ≤ ofallusersandoftheworst1%ofusers,whereŒ≤ ofauserisestimatedusingthetesting
i i
images.
WatermarkLengthn 32 48 64 80
AverageŒ≤ 0.99 0.99 0.99 0.97
i
Worst1%Œ≤ 0.92 0.97 0.90 0.84
i
1.00 1.00 1.00
0.75 averageTDR 0.75 averageTDR 0.75 averageTDR
averageTAR averageTAR averageTAR
0.50 worst1%TDR 0.50 worst1%TDR 0.50 worst1%TDR
worst1%TAR worst1%TAR worst1%TAR
0.25 FDR 0.25 FDR 0.25 FDR
0.00 0.00 0.00
1 2 3 4 5 6 32 48 64 80 0.70 0.75 0.80 0.85 0.90 0.95
NumberofUserss(Log10Scale) WatermarkLengthn DetectionThresholdœÑ
(a) Impactofs (b) Impactofn (c) ImpactofœÑ
Figure4: Impactofnumberofuserss,watermarklengthn,anddetectionthresholdœÑ ondetectionandattribution
performance.
computationresources,butwewillalsoexplores=1,000,000inoneofourexperimentstoshowtheresultswhen
thenumberofusersinattributionisverylarge. Whenpost-processingmethodsareappliedtowatermarkedimages,
thewatermarkingmethodmaybecomelessaccurate(i.e.,Œ≤ maydecrease)andthuswereduceœÑ tobe0.85. Unless
otherwisementioned,weshowresultsfortheStableDiffusiondataset.
6.2 WithoutPost-processing
In this section, we show results when the AI-generated, watermarked images are not post-processed. Specifically,
weexploretheimpactofthethreeparameters,includingthenumberofuserss,watermarklengthn,anddetection
thresholdœÑ,onthedetectionandattributionperformance. Whenexploringtheimpactofoneparameter,wefixtheother
twoparametersastheirdefaultsettings.
Mainresults: ForeachGenAImodel,wecomputetheTDR/TARofeachuserandtheFDR.TheFDRsforthethree
GenAImodelsarenearly0. Then,weranktheusers‚ÄôTARs(orTDRs)inanon-descendingorder. Figure3showsthe
rankedTARsofthe100,000usersforthethreeGenAImodels. NotethatthecurveofTDRoverlapswiththatofTARfor
aGenAImodelandthusisomittedinthefigureforsimplicity. TDRandTARoverlapbecauseœÑ =0.9> 1+Œ±i (0.89in
2
ourexperiments),whichisconsistentwithourtheoreticalanalysisinSection5.5thatshowsdetectionimpliesattribution
insuchsettings. Ourresultsshowthatwatermark-baseddetectionandattributionareaccuratewhentheAI-generated,
watermarkedimagesarenotpost-processed. Specifically,theworstTARorTDRofauserislargerthan0.94;lessthan
0.1%ofusershaveTARs/TDRssmallerthan0.98;and85%ofusershaveTARs/TDRsof1forMidjourneyandDALL-E
2,and60%ofusershaveTARs/TDRsof1forStableDiffusion.
Impactofnumberofuserss: Figure4ashowstheaverageTDR,averageTAR,worst1%TDR,worst1%TAR,and
FDRwhensvariesfrom10to1,000,000. Wehavetwoobservations. First,bothaverageTDRandaverageTARare
consistentlycloseto1,andFDRisconsistentlycloseto0,whichmeansourdetectionandattributionareaccurate.
Second,worst1%TDRandworst1%TARdecreaseassincreases. Thisisbecausewhentherearemoreusers,the
worst1%ofthemhavesmallerTDRsandTARs. Moreover,theseworst1%ofusersalsomaketheaverageTDRand
averageTARdecreaseslightlywhensincreasesfrom100,000to1,000,000.
Impactofwatermarklengthn: Figure4bshowstheaverageTDR,averageTAR,worst1%TDR,worst1%TAR,
andFDRwhenthewatermarklengthnvariesfrom32to80. TheaverageTDRandaverageTARslightlydecrease
whennincreasesfrom64to80,whiletheworst1%TDR/TARslightlyincreasesasnincreasesfrom32to48andthen
decreasesasnfurtherincreases. Table1showstheestimatedaverageŒ≤ ofallusersandaverageŒ≤ oftheworst1%
i i
ofusersinŒ≤-accuratewatermarking. WeobservethatthepatternsofaverageTDR/TARandworst1%TDR/TARare
consistentwiththoseofaverageŒ≤ andworst1%Œ≤ ,respectively. Theseobservationsareconsistentwithourtheoretical
i i
analysiswhichshowsthatTDRorTARincreasesasŒ≤ increases. OurresultalsoimpliesthatHiDDeNwatermarking
i
maybeunabletoaccuratelyencode/decodeverylongwatermarks.
121.00 1.00 1.00 1.00
averageTDR averageTDR
0.75 0.75 averageTAR 0.75 0.75 averageTAR
averageTDR FDR averageTDR FDR
0.50 averageTAR 0.50 SSIM 0.50 averageTAR 0.50 SSIM
FDR FDR
SSIM SSIM
0.25 0.25 0.25 0.25
0.00 0.00 0.00 0.00
99 90 80 60 40 20 0.05 0.10 0.20 0.30 0.1 0.4 0.7 1.0 1.2 1.01.3 2.0 3.0 4.0
QualityFactorQ StandardDeviationœÉ StandardDeviationœÉ Parametera
(a)JPEG (b)Gaussiannoise (c)Gaussianblur (d)Brightness/Contrast
Figure 5: Detection and attribution results when AI-generated and non-AI-generated images are post-processed
bycommonpost-processingmethodswithdifferentparameters. SSIMmeasuresthequalityofanimageafterpost-
processing.
ImpactofdetectionthresholdœÑ: Figure4cshowstheaverageTDR,averageTAR,worst1%TDR,worst1%TAR,and
FDRwhenthedetectionthresholdœÑ variesfrom0.7to0.95. WhenœÑ increases,bothTDRandTARdecrease,while
FDRalsodecreases. Suchtrade-offofœÑ isconsistentwithTheorem1,3,and4.
6.3 CommonPost-processing
Commonpost-processingmethods: Commonpost-processingmethodsareoftenusedtoevaluatetherobustnessof
watermarkinginnon-adversarialsettings. Eachpost-processingmethodhasspecificparametersthatgoverntheextent
ofperturbationintroducedtoanimage. Inparticular,weconsidercommonpost-processingmethodsasfollows.
JPEG.JPEG[32]methodcompressesanimageviaadiscretecosinetransform. Theperturbationintroducedtoan
imageisdeterminedbythequalityfactorQ. AnimageisperturbedmorewhenQissmaller.
Gaussiannoise. ThismethodperturbsanimageviaaddingarandomGaussiannoisetoeachpixel. Inourexperiments,
themeanoftheGaussiandistributionis0. Theperturbationintroducedtoanimageisdeterminedbytheparameter
standarddeviationœÉ.
Gaussianblur. ThismethodblursanimageviaaGaussianfunction. Inourexperiments,wefixkernelsizes=5. The
perturbationintroducedtoanimageisdeterminedbytheparameterstandarddeviationœÉ.
Brightness/Contrast. Thismethodperturbsanimageviaadjustingthebrightnessandcontrast. Formally,themethod
hascontrastparameteraandbrightnessparameterb,whereeachpixelxisconvertedtoax+b. Inourexperiments,we
fixb=0.2andvaryatocontroltheperturbation.
Adversarialtraining[11]: WeuseadversarialtrainingtotrainHiDDeN.Specifically,duringtraining,werandomly
sampleapost-processingmethodfromnopost-processingandcommonpost-processingwitharandomparameterto
post-processeachwatermarkedimageinamini-batch. Followingpreviouswork[11],weconsiderthefollowingrange
ofparametersduringadversarialtraining: Q ‚àà[10,99]forJPEG,œÉ ‚àà[0,0.5]forGaussiannoise,œÉ ‚àà[0,1.5]for
Gaussianblur,anda‚àà[1,20]forBrightness/Contrast.
Results: Figure 5 shows the detection/attribution results when a common post-processing method with different
parametersisappliedtothe(AI-generatedandnon-AI-generated)images. SSIM[33]isapopularmetrictomeasure
visual similarity between two images. The SSIM in Figure 5 is the average between (AI-generated and non-AI-
generated)imagesandtheirpost-processedversions. WenotethatwhenHiDDeNistrainedusingstandardtraining,
detectionandattributionbecomeinaccurateafterAI-generatedimagesarepost-processed,asshowninFigure10in
Appendix. OurresultsshowthatdetectionandattributionusinganadversariallytrainedHiDDeNarerobusttocommon
post-processing. In particular, the average TDR and TAR are still high when a common post-processing does not
sacrificeimagequalitysubstantially. Forinstance,averageTDRandTARstarttodecreasewhenthequalityfactorQof
JPEGissmallerthan90. However,theaverageSSIMbetweenwatermarkedimagesandtheirpost-processedversions
alsodropsquickly. NotethatGaussianblurwithœÉ =1.2alreadyinfluencesvisualqualitysubstantiallyevenifSSIM
islargerthan0.75. Figure11inAppendixshowsawatermarkedimageandtheversionspost-processedbydifferent
methods.
6.4 AdversarialPost-processing
Inadversarialsettings, anattackermayapplyadversarialpost-processing[16]toperturbawatermarkedimageto
evadedetection/attribution. HiDDeNisnotrobusttoadversarialpost-processinginthewhite-boxsetting[16],i.e.,
130.4
0.2
0.0
100 5001k 2k 4k 10k 100k
QueryBudget
Figure6: AverageSSIMbetweenwatermarkedimagesandtheiradversariallypost-processedversionsasafunctionof
thequerybudgetintheblack-boxsetting.
1.00 1.0
0.9
0.75
0.8
0.50
0.7
0.25 Random 0.6 R Na Rn Gdom
NRG
0.00 A-BSTA 0.5 A-BSTA
0.75 0.80 0.85 0 1 2 3
Œ±i RankIndex(Log10Scale)
(a) CDFofŒ± (b) RankedTARs
i
Figure7: (a)Thecumulativedistributionfunction(CDF)ofŒ± and(b)rankedTARsoftheworst1,000usersforthe
i
threewatermarkselectionmethods.
Table2: Theaveragerunningtimefordifferentwatermarkselectionmethodstogenerateawatermark.
Random NRG A-BSTA
Time(ms) 0.01 2.11 24.00
adversarialpost-processingcanremovethewatermarkfromawatermarkedimagewithoutsacrificingitsvisualquality.
Thus,HiDDeN-baseddetection/attributionisalsonotrobusttoadversarialpost-processinginthewhite-boxsetting,i.e.,
TDR/TARcanbereducedto0whilemaintainingimagequality.
Figure6showstheaverageSSIMbetweenwatermarkedimagesandtheiradversariallypost-processedversionsas
afunctionofquerybudgetintheblack-boxsetting(i.e.,WEvade-B-Q[16]),wherethequerybudgetisthenumber
of queries to the detection API for each watermarked image. HiDDeN is trained via adversarial training in these
experiments. Both TDR and TAR are 0 in these experiments since WEvade-B-Q always guarantees evasion [16].
However,adversarialpost-processingsubstantiallysacrificesimagequalityintheblack-boxsetting(i.e.,SSIMissmall)
evenifanattackercanquerythedetectionAPIforalargenumberoftimes. Figure12inAppendixshowsseveral
examplesofadversariallypost-processedimageswithdegradedvisualquality. OurresultsshowthatHiDDeNandthus
ourHiDDeN-baseddetection/attributionhavegoodrobustnesstoadversarialpost-processingintheblack-boxsetting.
WenotethatJiangetal.[16]showedadversarialpost-processingdoesnotsacrificeimagevisualqualityintheblack-box
settingwhenevadingHiDDeN,whichwecanreproduceusingtheirpubliclyavailablecodeandthesameparameter
setting. However,theyusewatermarklength30,whileweuse64;andtheyuseasimpleneuralnetworkasthedecoder,
whileweuseResNet18asthedecoder. Moreover,weusestrongeradversarialtrainingwithalargerrangeofparameters
forthepost-processing. Ourresultsshowthatlongerwatermarks,moreexpressivedecoder,andstrongeradversarial
trainingcanfurtherenhancerobustnessofHiDDeN.
6.5 DifferentWatermarkSelectionMethods
Runningtime: Table2showstherunningtimetogenerateawatermarkaveragedamongthe100,000watermarks.
AlthoughA-BSTAisslowerthanRandomandNRG,therunningtimeisacceptable,i.e.,ittakesonly24mstogenerate
awatermarkonaverage.
DistributionofŒ± : RecallthatTAR ofauserdependsonthemaximumbitwiseaccuracybetweenthewatermarkw
i i i
andtheremainingwatermarks,i.e.,Œ± =max BA(w ,w ). Figure7ashowsthecumulativedistribution
i j‚àà{1,2,¬∑¬∑¬∑,s}/{i} i j
14
noitcnuFnoitubirtsiDevitalumuC1.0 Theoretical 1.0 Theoretical
Empirical Empirical
0.8 0.8
0.6 0.6
0.4 0.4
0.2 0.2
0.0 0.0
TDR TAR FDR TDR TAR FDR
(a)Nopost-processing (b)JPEG
Figure8: Theoreticalvs. empiricalresults.
1.00 1.00
0.75 0.75
averageTDR averageTDR
0.50 averageTAR 0.50 averageTAR
FDR FDR
0.25 0.25
0.00 0.00
1 2 3 4 5 1 2 3 4 5
NumberofUserss(Log10Scale) NumberofUserss(Log10Scale)
(a) Nopost-processing (b) Paraphrasing
Figure9: Resultsofwatermark-baseddetectionandattributionforAI-generatedtexts.
functionofŒ± amongtheswatermarksgeneratedbydifferentwatermarkselectionmethods. Ourresultsshowthatall
i
watermarksgeneratedbyA-BSTAhaveŒ± smallerthan0.74. However,RandomandNRGgeneratemanywatermarks
i
withlargerŒ± ,andRandomistheworstamongthethreemethods. ThisisbecauseRandomselectiondoesnotexplicitly
i
minimizeŒ± whengeneratingwatermarks.
i
TARs: Figure7bshowstherankedTARsoftheworst1,000users,wheretheAI-generatedimagesarepost-processed
by JPEG compression with quality factor Q = 90 and HiDDeN is adversarially trained. The results indicate that
A-BSTAoutperformsNRG,whichoutperformsRandom. ThisisbecauseA-BSTAselectswatermarkswithsmallerŒ± ,
i
whileRandomselectswatermarkswithlargerŒ± asshowninFigure7a.
i
6.6 Theoreticalvs. EmpiricalResults
ThetheoreticallowerboundsofTDRandTARofauserarerespectivelycalculatedusingTheorem1and4,whilethe
theoreticalupperboundofFDRiscalculatedusingTheorem3. WeestimateŒ≤ asthebitwiseaccuracybetweenthe
i
decodedwatermarkandw averagedamongthetestingAI-generatedimages,andestimateŒ≥ usingthefractionofbits
i
inthedecodedwatermarksthatare1amongthenon-AI-generatedimages. Figure8showstheaveragetheoreticalvs.
empiricalTDR/TAR,andtheoreticalvs. empiricalFDR,whennopost-processingorJPEGwithQ=90isapplied. The
resultsshowthatourtheoreticallowerboundsofTDRandTARmatchwithempiricalresultswell,whichindicatesthat
ourderivedlowerboundsaretight. ThetheoreticalupperboundofFDRisnotablyhigherthantheempiricalFDR.This
isbecausesomebitsmayhavelargerprobabilitiestobe1or0intheexperiments,butourtheoreticalanalysistreatsthe
bitsequally,leadingtoalooseupperboundofFDR.
7 DiscussionandLimitations
AI-generatedtexts: OurmethodcanalsobeusedforthedetectionandattributionofAI-generatedtexts. Fortext
watermarking,weusealearning-basedmethodcalledAdversarialWatermarkingTransformer(AWT)[22]. Givenatext,
AWTencoderembedsabitstringwatermarkintoit;andgivena(watermarkedorunwatermarked)text,AWTdecoder
decodesawatermarkfromit. Followingtheoriginalpaper[22],wetrainAWTontheword-levelWikiText-2dataset,
whichisderivedfromWikipediaarticles[34]. Weusemostofthehyperparametersettingsinthepubliclyavailablecode
ofAWTexcepttheweightofthewatermarkdecodingloss. Tooptimizewatermarkdecodingaccuracy,weincreasethis
weightduringtraining. ThedetailedhyperparametersettingsfortrainingcanbefoundinTable4inAppendix.
We use A-BSTA to select users‚Äô watermarks. For each user, we sample 10 text segments from the test corpus
uniformlyatrandom,andperformwatermark-baseddetectionandattribution. Moreover,weusetheunwatermarked
testcorpustocalculateFDR.Figure9showsthedetectionandattributionresultswhenthereisnopost-processingand
paraphrasing[35]isappliedtotexts,wheren=64,œÑ =0.85,andsrangesfrom10to100,000.Duetothefixed-length
15natureofAWT‚Äôsinput,weconstraintheoutputlengthoftheparaphrasertoacertainrange. Whenparaphrasingis
used,weextendadversarialtrainingtotrainAWT,andSectionGinAppendixshowsthedetails. Notethattheaverage
TDR/TARandFDRareallnearly0whenAWTistrainedbystandardtrainingandparaphrasingisappliedtotexts.
TheresultsshowthatourmethodisalsoapplicableforAI-generatedtexts,andadversariallytrainedAWThasbetter
robustnesstoparaphrasing.
AttributionofGenAIservices: Inthiswork,wefocusonattributionofcontenttousersforaspecificGenAIservice.
AnotherrelevantattributionproblemistotracebacktheGenAIservice(e.g.,Google‚ÄôsImagen,OpenAI‚ÄôsDALL-E3,
orStableDiffusion)thatgeneratedagivencontent. OurmethodcanalsobeappliedtosuchGenAI-service-attribution
problembyassigningadifferentwatermarktoeachGenAIservice. Moreover,wecanperformattributiontoGenAI
serviceandusersimultaneously. Specifically,wecandividethewatermarkspaceintomultiplesubspaces;andeach
GenAIserviceusesasubspaceofwatermarksandassignswatermarksinitssubspacetoitsusers. Inthisway,wecan
tracebackboththeGenAIserviceanditsuserthatgeneratedagivencontent.
8 ConclusionandFutureWork
Wefindthatwatermarkcanbeusedforuser-awaredetectionandattributionofAI-generatedcontent. Moreover,via
boththeoreticalanalysisandempiricalevaluation,wefindthatsuchdetectionandattributioninherittheaccuracy/(non-
)robustness properties of the watermarking method. For instance, learning-based watermarking methods [11] are
accurate and robust to common post-processing; and thus detection and attribution based on such a watermarking
methodarealsoaccurateandrobusttocommonpost-processing. However,sincewatermarkingisnotyetrobustto
adversarialpost-processinginthewhite-boxsetting[16],detectionandattributionarenotyetrobustinsuchadversarial
settings. Wealsofindthatselectingdissimilarwatermarksfortheusersenhancesattributionperformance. Animportant
futureworkistodeveloprobustwatermarkingmethodsinadversarialsettings.
References
1. Dhaliwal, S. Elon Musk isn‚Äôt dating GM‚Äôs Mary Barra: he has this to say though on the photos. https:
//www.benzinga.com/news/23/03/31505898/elon-musk-isnt-dating-gms-mary-barra-he-has-
this-to-say-though-on-the-photos.2023.
2. Escalante-De Mattei, S. US Copyright Office: AI Generated Works Are Not Eligible for Copyright. https:
//www.artnews.com/art-news/news/ai-generator-art-text-us-copyright-policy-1234661683.
2023.
3. Ramesh,A.,Dhariwal,P.,Nichol,A.,Chu,C.&Chen,M.Hierarchicaltext-conditionalimagegenerationwith
cliplatents.arXivpreprintarXiv:2204.06125(2022).
4. Gowal,S.&Kohli,P.IdentifyingAI-generatedimageswithSynthID.https://deepmind.google/discover/
blog/identifying-ai-generated-images-with-synthid.2023.
5. Rombach,R.,Blattmann,A.,Lorenz,D.,Esser,P.&Ommer,B.High-resolutionimagesynthesiswithlatent
diffusionmodels.IEEE/CVFConferenceonComputerVisionandPatternRecognition(2022).
6. Mehdi,Y.AnnouncingMicrosoftCopilot,youreverydayAIcompanion.https://blogs.microsoft.com/
blog/2023/09/21/announcing-microsoft-copilot-your-everyday-ai-companion.2023.
7. Pereira,S.&Pun,T.Robusttemplatematchingforaffineresistantimagewatermarks.IEEETransactionson
ImageProcessing(2000).
8. Bi,N.,Sun,Q.,Huang,D.,Yang,Z.&Huang,J.Robustimagewatermarkingbasedonmultibandwaveletsand
empiricalmodedecomposition.IEEETransactionsonImageProcessing(2007).
9. Wang,Q.invisible-watermarkhttps://github.com/ShieldMnt/invisible-watermark.2021.
10. Kandi,H.,Mishra,D.&Gorthi,S.R.S.Exploringthelearningcapabilitiesofconvolutionalneuralnetworksfor
robustimagewatermarking.Computers&Security(2017).
11. Zhu,J.,Kaplan,R.,Johnson,J.&Fei-Fei,L.Hidden:Hidingdatawithdeepnetworks.EuropeanConferenceon
ComputerVision(2018).
12. Luo, X., Zhan, R., Chang, H., Yang, F. & Milanfar, P. Distortion agnostic deep watermarking. IEEE/CVF
ConferenceonComputerVisionandPatternRecognition(2020).
13. Wen,B.&Aydore,S.Romark:Arobustwatermarkingsystemusingadversarialtraining.ConferenceonNeural
InformationProcessingSystemsWorkshop(2019).
14. Fernandez,P.,Couairon,G.,J√©gou,H.,Douze,M.&Furon,T.TheStableSignature:RootingWatermarksin
LatentDiffusionModels.InternationalConferenceonComputerVision(2023).
1615. Goodfellow,I.,Shlens,J.&Szegedy,C.ExplainingandHarnessingAdversarialExamples.InternationalConfer-
enceonLearningRepresentations(2015).
16. Jiang,Z.,Zhang,J.&Gong,N.Z.EvadingWatermarkbasedDetectionofAI-GeneratedContent.ACMConference
onComputerandCommunicationsSecurity(2023).
17. Brain,G.Imagen.https://imagen.research.google.2023.
18. Lanctot,J.K.,Li,M.,Ma,B.,Wang,S.&Zhang,L.Distinguishingstringselectionproblems.Informationand
Computation(2003).
19. Gramm,J.,Niedermeier,R.&Rossmanith,P.Fixed-parameteralgorithmsforcloseststringandrelatedproblems.
Algorithmica(2003).
20. Wen,Y.,Kirchenbauer,J.,Geiping,J.&Goldstein,T.Tree-RingWatermarks:FingerprintsforDiffusionImages
thatareInvisibleandRobust.ConferenceonNeuralInformationProcessingSystems(2023).
21. Kirchenbauer,J.etal.AWatermarkforLargeLanguageModels.InternationalConferenceonMachineLearning
(2023).
22. Abdelnabi,S.&Fritz,M.Adversarialwatermarkingtransformer:Towardstracingtextprovenancewithdata
hiding.IEEESymposiumonSecurityandPrivacy(2021).
23. Madry, A., Makelov, A., Schmidt, L., Tsipras, D. & Vladu, A. Towards Deep Learning Models Resistant to
AdversarialAttacks.InternationalConferenceonLearningRepresentations(2018).
24. Sadasivan,V.S.,Kumar,A.,Balasubramanian,S.,Wang,W.&Feizi,S.CanAI-GeneratedTextbeReliably
Detected?arXivpreprintarXiv:2303.11156(2023).
25. Chen,Z.-Z.,Ma,B.&Wang,L.Randomizedfixed-parameteralgorithmsforthecloseststringproblem.Algorith-
mica(2016).
26. Wang,Z.J.etal.DiffusionDB:ALarge-ScalePromptGalleryDatasetforText-to-ImageGenerativeModels.
AnnualMeetingoftheAssociationforComputationalLinguistics(2023).
27. Turc,I.&Nemade,G.MidjourneyUserPrompts&GeneratedImages(250k)https://www.kaggle.com/ds/
2349267.2022.
28. Images,D.https://dalle2.gallery.2023.
29. Lin,T.-Y.etal.Microsoftcoco:Commonobjectsincontext.EuropeanConferenceonComputerVision(2014).
30. Deng,J.etal.Imagenet:Alarge-scalehierarchicalimagedatabase.IEEE/CVFConferenceonComputerVision
andPatternRecognition(2009).
31. Sharma,P.,Ding,N.,Goodman,S.&Soricut,R.Conceptualcaptions:Acleaned,hypernymed,imagealt-text
datasetforautomaticimagecaptioning.AnnualMeetingoftheAssociationforComputationalLinguistics(2018).
32. Zhang, C., Karjauv, A., Benz, P. & Kweon, I. S. Towards robust data hiding against (jpeg) compression: A
pseudo-differentiabledeeplearningapproach.arXivpreprintarXiv:2101.00973(2020).
33. Wang,Z.,Bovik,A.C.,Sheikh,H.R.&Simoncelli,E.P.Imagequalityassessment:fromerrorvisibilityto
structuralsimilarity.IEEETransactionsonImageProcessing(2004).
34. Merity,S.,Xiong,C.,Bradbury,J.&Socher,R.Pointersentinelmixturemodels.arXivpreprintarXiv:1609.07843
(2016).
35. Damodaran,P.Parrot:ParaphrasegenerationforNLU.versionv1.0.2021.
171.00 1.00 averageTDR 1.00 1.00 averageTDR
averageTAR averageTAR
0.75 0.75 FDR 0.75 0.75 FDR
averageTDR SSIM averageTDR SSIM
0.50 a Fv Der RageTAR 0.50 0.50 a Fv Der RageTAR 0.50
SSIM SSIM
0.25 0.25 0.25 0.25
0.00 0.00 0.00 0.00
99 95 90 80 70 0.05 0.10 0.20 0.30 0.1 0.4 0.7 1.0 1.2 1.01.3 2.0 3.0 4.0
QualityFactorQ StandardDeviationœÉ StandardDeviationœÉ Parametera
(a)JPEG (b)Gaussiannoise (c)Gaussianblur (d)Brightness/Contrast
Figure10: DetectionandattributionresultswhenAI-generatedandnon-AI-generatedimagesarepost-processedby
commonpost-processingmethodswithdifferentparameters. HiDDeNistrainedusingstandardtraining.
(a)Watermarked (b)JPEG (c)Gaussiannoise (d)Gaussianblur (e)Brightness/Contrast
Figure11: Awatermarkedimageandtheversionspost-processedbyJPEGwithQ=60,GaussiannoisewithœÉ=0.3,
GaussianblurwithœÉ=1.2,andBrightness/Contrastwitha=4.0.
(a)100 (b)500 (c)1k (d)10k (e)100k
Figure12: Perturbedwatermarkedimagesobtainedbyadversarialpost-processingwithdifferentnumberofqueriesto
thedetectionAPIintheblack-boxsetting.
Table3: ThemaximumpairwisebitwiseaccuracyamongthewatermarksgeneratedbyNRGandA-BSTAfordifferent
initializations.
¬¨w initialization Randominitialization
1
NRG 0.766 0.750
A-BSTA 0.875 0.734
A ProofofTheorem1
ForC ‚àºP ,wedenotew =D(C),n =BA(w,w )n,andn =BA(w,w )nforj ‚àà{1,2,¬∑¬∑¬∑ ,s}/{i}. Thenwe
i i i j j
havethefollowing:
|w‚àí¬¨w | =n ,
i 1 i
|¬¨w ‚àíw | =BA(w ,w )n,
i j 1 i j
|w‚àíw | =n‚àín ,
j 1 j
18where¬¨w meansflippingeachbitofthewatermarkw ,|¬∑| is‚Ñì distancebetweentwobinaryvectors. Accordingto
i i 1 1
thetriangleinequality,wehave:
|w‚àíw | ‚â§|w‚àí¬¨w | +|¬¨w ‚àíw |
j 1 i 1 i j 1
=n +BA(w ,w )n.
i i j
Therefore,wederivethelowerboundofn forj ‚àà{1,2,¬∑¬∑¬∑ ,s}/{i}asfollows:
j
n =n‚àí|w‚àíw |
j j 1
‚â•n‚àín ‚àíBA(w ,w )n.
i i j
Thus,wederivethelowerboundofTDR asfollows:
i
TDR =1‚àíPr(n <œÑn‚àß max n <œÑn)
i i j
j‚àà{1,2,¬∑¬∑¬∑,s}/{i}
‚â•1‚àíPr(n <œÑn‚àß max n‚àín ‚àíBA(w ,w )n<œÑn)
i i i j
j‚àà{1,2,¬∑¬∑¬∑,s}/{i}
=1‚àíPr(n <œÑn‚àßn‚àín ‚àíŒ± n<œÑn)
i i i
=1‚àíPr(n‚àíœÑn‚àíŒ± n<n <œÑn)
i i
=Pr(n ‚â•œÑn)+Pr(n ‚â§n‚àíœÑn‚àíŒ± n),
i i i
wheren ‚àºB(n,Œ≤ )andŒ± =min BA(w ,w ).
i i i j‚àà{1,2,¬∑¬∑¬∑,s}/{i} i j
B ProofofCorollary1
According to Theorem 1, the lower bound of TDR is 1 ‚àí Pr(n ‚àí œÑn ‚àí Œ± n < n < œÑn). For an integer r ‚àà
i i i
(n‚àíœÑn‚àíŒ± n,œÑn)andn ‚àºB(n,Œ≤ ),wehavethefollowing:
i i i
Pr(n =r)=(Ô∏Ån)Ô∏Å Œ≤r(1‚àíŒ≤ )n‚àír.
i r i i
ThenwecomputethepartialderivativeoftheprobabilitywithrespecttoŒ≤ asfollows:
i
‚àÇPr(n i =r) =(Ô∏Ån)Ô∏Å Œ≤r‚àí1(1‚àíŒ≤ )n‚àír‚àí1(r(1‚àíŒ≤ )‚àí(n‚àír)Œ≤ )
‚àÇŒ≤ r i i i i
i
<(Ô∏Ån)Ô∏Å Œ≤r‚àí1(1‚àíŒ≤ )n‚àír‚àí1(œÑ ‚àíŒ≤ )n.
r i i i
Thepartialderivativeissmallerthan0whenœÑ <Œ≤ . Therefore,theprobabilityPr(n =r)decreasesasŒ≤ increases
i i i
foranyintegerr ‚àà(n‚àíœÑn‚àíŒ± n,œÑn). Thus,thelowerboundofTDR increasesasŒ≤ becomescloserto1.
i i i
C ProofofTheorem2
ForC ‚àºQ,wedenoten =BA(D(C),w )nandn =BA(D(C),w )nforj ‚àà{1,2,¬∑¬∑¬∑ ,s}. Then,wehavethe
1 1 j j
following:
FDR=1‚àíPr( max n <œÑn)
j
j‚àà{1,2,¬∑¬∑¬∑,s}
=1‚àíPr(n <œÑn‚àß max n <œÑn).
1 j
j‚àà{2,3,¬∑¬∑¬∑,s}
ToderiveanupperboundofFDR,wedenote:
|w‚àíw | =n‚àín ,
1 1 1
|w ‚àíw | =n‚àíBA(w ,w )n,
1 j 1 1 j
|w‚àíw | =n‚àín .
j 1 j
Accordingtothetriangleinequality,wehavethefollowing:
|w‚àíw | ‚â•|w ‚àíw | ‚àí|w‚àíw |
j 1 1 j 1 1 1
=n ‚àíBA(w ,w )n.
1 1 j
Therefore,wederivetheupperboundofn forj ‚àà{2,3,¬∑¬∑¬∑ ,s}asfollows:
j
n =n‚àí|w‚àíw |
j j 1
‚â§n‚àín +BA(w ,w )n.
1 1 j
19Thus,wederivetheupperboundofFDRasfollows:
FDR=1‚àíPr(n <œÑn‚àß max n <œÑn)
1 j
j‚àà{2,3,¬∑¬∑¬∑,s}
‚â§1‚àíPr(n <œÑn‚àß max n‚àín +BA(w ,w )n<œÑn))
1 1 1 j
j‚àà{2,3,¬∑¬∑¬∑,s}
=1‚àíPr(n <œÑn‚àßn‚àín +Œ± n<œÑn))
1 1 1
=1‚àíPr(n‚àíœÑn+Œ± n<n <œÑn)
1 1
=Pr(n ‚â•œÑn)+Pr(n ‚â§n‚àíœÑn+Œ± n),
1 1 1
wheren ‚àºB(n,0.5)andŒ± =max BA(w ,w ).
1 1 j‚àà{2,3,¬∑¬∑¬∑,s} 1 j
D ProofofTheorem3
ForC ‚àºQ,wedenoten =BA(D(C),w )nforj ‚àà{1,2,¬∑¬∑¬∑ ,s},andwehavethefollowing:
j j
FDR=1‚àíPr( max n <œÑn)
j
j‚àà{1,2,¬∑¬∑¬∑,s}
‚àèÔ∏Ç
=1‚àí Pr(n <œÑn).
j
j‚àà{1,2,¬∑¬∑¬∑,s}
AccordingtoDefinition4,foranyk ‚àà{1,2,¬∑¬∑¬∑ ,n}andanyj ‚àà{1,2,¬∑¬∑¬∑ ,s},thedecodingofeachbitisindependent
andtheprobabilitythatD(C)[k]matcheswithw [k]isatmost0.5+Œ≥ nomatterw [k]is1or0. Therefore,wehave
j j
thefollowing:
‚àèÔ∏Ç
FDR=1‚àí Pr(n <œÑn)
j
j‚àà{1,2,¬∑¬∑¬∑,s}
‚â§1‚àíPr(n‚Ä≤ <œÑn)s,
wheren‚Ä≤followsthebinomialdistributionwithparametersnand0.5+Œ≥,i.e.,n‚Ä≤ ‚àºB(n,0.5+Œ≥).
E ProofofCorollary2
AccordingtoTheorem3,theprobabilityPr(n‚Ä≤ <œÑn)increaseswhenŒ≥decreases. Therefore,theupperboundofFDR
decreasesasŒ≥ becomescloserto0.
F ProofofTheorem4
ForC ‚àºP ,wedenotew =D(C),n =BA(w,w )n,andn =BA(w,w )nforj ‚àà{1,2,¬∑¬∑¬∑ ,s}. Thenwehave
i i i j j
thefollowing:
|w‚àí¬¨w | =n ,
i 1 i
|¬¨w ‚àíw | =BA(w ,w )n,
i j 1 i j
|w‚àíw | =n‚àín .
j 1 j
Accordingtothetriangleinequality,wehave:
|w‚àíw | ‚â•|w‚àí¬¨w | ‚àí|¬¨w ‚àíw |
j 1 i 1 i j 1
=n ‚àíBA(w ,w )n.
i i j
Therefore,wederivetheupperboundofn forj ‚àà{1,2,¬∑¬∑¬∑ ,s}/{i}asfollows:
j
n =n‚àí|w‚àíw |
j j 1
‚â§n‚àín +BA(w ,w )n.
i i j
20Table4: DefaultparametersettingsforthetrainingofAWT.
Phase StandardTraining Fine-Tuning
Optimizer Adam
#epochs 200 10
Batchsize 16
Learningrate 3√ó10‚àí5
#warm-upiterations 6000 1000
Lengthoftext 250 250¬±16
Generationweight 1.5 1
Messageweight 10000
Reconstructionweight 1.5 2
Thus,wederivethelowerboundofTAR asfollows:
i
TAR =Pr( max n ‚â•œÑn‚àßn > max n )
i j i j
j‚àà{1,2,¬∑¬∑¬∑,s} j‚àà{1,2,¬∑¬∑¬∑,s}/{i}
‚â•Pr( max n ‚â•œÑn‚àßn > max n‚àín +BA(w ,w )n)
j i i i j
j‚àà{1,2,¬∑¬∑¬∑,s} j‚àà{1,2,¬∑¬∑¬∑,s}/{i}
n+Œ± n
=Pr( max n ‚â•œÑn‚àßn > i )
j‚àà{1,2,¬∑¬∑¬∑,s} j i 2
n+Œ± n
=Pr( max n ‚â•œÑn‚àßn > i |n ‚â•œÑn)¬∑Pr(n ‚â•œÑn)
j‚àà{1,2,¬∑¬∑¬∑,s} j i 2 i i
n+Œ± n
+Pr( max n ‚â•œÑn‚àßn > i |n <œÑn)¬∑Pr(n <œÑn)
j‚àà{1,2,¬∑¬∑¬∑,s} j i 2 i i
n+Œ± n
‚â•Pr(n > i |n ‚â•œÑn)¬∑Pr(n ‚â•œÑn)
i 2 i i
n+Œ± n
=Pr(n > i ‚àßn ‚â•œÑn)
i 2 i
1+Œ±
=Pr(n ‚â•max{‚åä in‚åã+1,œÑn}),
i 2
wheren ‚àºB(n,Œ≤ )andŒ± =max BA(w ,w ).
i i i j‚àà{1,2,¬∑¬∑¬∑,s}/{i} i j
G AdversarialTrainingofAWT
Inadversarialtraining,weemployT5-basedparaphrasertopost-processthewatermarkedtextsgeneratedbyAWT.
Duetothenon-differentiablenatureoftheparaphrasingprocess,wecannotjointlyadversariallytraintheencoderand
decodersincethegradientscannotback-propagatetotheencoder. Toaddressthechallenge,wefirstusethestandard
trainingtotrainAWTencoderanddecoder. Then,weusetheencodertogeneratewatermarkedtexts,paraphrasethem,
andusetheparaphrasedwatermarkedtextstofine-tunethedecoder. Thedetailparametersettingsoffine-tuningare
showninTable4.
21Algorithm1BSTA(w ,d,m)
s
Input: Initialwatermarkw ,recursiondepthd,andm.
s
Output: w orNotExist.
s
1: ifd<0then
2: returnNotExist
3: i‚àó ‚Üêargmax i‚àà{1,2,¬∑¬∑¬∑,s‚àí1}BA(w i,w s)
4: ifBA(w i‚àó,w s)>(m+d)/nthen
5: returnNotExist
6: elseifBA(w i‚àó,w s)‚â§m/nthen
7: returnw s
8: B ‚Üê{k|w s[k]=w i‚àó[k],k =1,2,¬∑¬∑¬∑ ,n}
9: ChooseanyB‚Ä≤ ‚äÇBwith|B‚Ä≤|=m+1
10: forallk ‚ààB‚Ä≤do
11: w s‚Ä≤ ‚Üêw s
12: w‚Ä≤[k]‚Üê¬¨w‚Ä≤[k]
s s
13: w‚Ä≤ ‚ÜêBSTA(w‚Ä≤,d‚àí1,m)
s s
14: ifw‚Ä≤ isnotNotExistthen
s
15: returnw‚Ä≤
s
16: returnNotExist
Algorithm2NRG(w ,m)
s
Input: Initialwatermarkw andm.
s
Output: w orNotExist.
s
1: F‚Üê‚àÖ
2: d‚Üêm
3: whiled>0do
4: i‚àó ‚Üêargmax i‚àà{1,2,¬∑¬∑¬∑,s‚àí1}BA(w i,w s)
5: ifBA(w i‚àó,w s)>2m/nthen
6: returnNotExist
7: elseifBA(w i‚àó,w s)‚â§m/nthen
8: returnw s
9: B ‚Üê{k|w s[k]=w i‚àó[k]‚àßk ‚àà/ F,k =1,2,¬∑¬∑¬∑ ,n}
10: l‚Üên¬∑BA(w i‚àó,w s)‚àím
11: SampleB‚Ä≤ ‚äÇBwith|B‚Ä≤|=luniformlyatrandom
12: forallk ‚ààB‚Ä≤do
13: w s[k]‚Üê¬¨w s[k]
14: d‚Üêd‚àíl
15: F ‚ÜêF ‚à™B‚Ä≤
16: returnNotExist
Algorithm3Solvingourwatermarkselectionproblem
Input: Existings‚àí1watermarksw ,w ,¬∑¬∑¬∑ ,w .
1 2 s‚àí1
Output: Watermarkw .
s
1: m‚Üêmax i‚àà{1,2,¬∑¬∑¬∑,s‚àí2}n¬∑BA(w i,w s‚àí1)
2: whilew sisNotExistdo
3: ifBSTAthen
4: w s ‚Üê¬¨w 1
5: w s ‚ÜêBSTA(w s,m,m)
6: ifNRGthen
7: w s ‚Üê¬¨w 1
8: w s ‚ÜêNRG(w s,m)
9: ifA-BSTAthen
10: w s ‚Üêsampleduniformlyatrandom
11: w s ‚ÜêBSTA(w s,d,m)
12: ifw sisNotExistthen
13: m‚Üêm+1
14: returnw s
22