Dimension-free Relaxation Times of Informed MCMC
Samplers on Discrete Spaces
Hyunwoong Chang and Quan Zhou∗
Department of Statistics, Texas A&M University
Abstract
ConvergenceanalysisofMarkovchainMonteCarlomethodsinhigh-dimensionalsta-
tistical applications is increasingly recognized. In this paper, we develop general mixing
timeboundsforMetropolis-Hastingsalgorithmsondiscretespacesbybuildinguponand
refiningsomerecenttheoreticaladvancementsinBayesianmodelselectionproblems. We
establish sufficient conditions for a class of informed Metropolis-Hastings algorithms to
attainrelaxationtimesthatareindependentoftheproblemdimension. Theseconditions
are grounded in high-dimensional statistical theory and allow for possibly multimodal
posterior distributions. We obtain our results through two independent techniques: the
multicommodity flow method and single-element drift condition analysis; we find that
the latter yields a tighter mixing time bound. Our results and proof techniques are
readily applicable to a broad spectrum of statistical problems with discrete parameter
spaces.
Keywords: Drift condition; Finite Markov chains; Informed Metropolis-Hastings; Mixing time;
Model selection; Multicommodity flow; Random walk Metropolis-Hastings; Restricted spectral gap
1 Introduction
1.1 Convergence of MCMC Algorithms
Approximating probability distributions with unknown normalizing constants is a ubiqui-
tous challenge in data science. In Bayesian statistics, the posterior probability distribution
can be obtained through the Bayes rule, but without conjugacy, calculating its normalizing
constant is a formidable challenge. In such scenarios, Markov chain Monte Carlo (MCMC)
methods are commonly employed to simulate a Markov chain whose stationary distribu-
tion coincides with the target distribution. The convergence assessment of MCMC methods
usually relies on an empirical diagnosis of Markov chain samples, such as effective sample
size [Robert et al., 1999, Gong and Flegal, 2016] and Gelman-Rubin statistic [Gelman and
Rubin, 1992], but the results can sometimes be misleading due to the intrinsic difficulty in
detecting the non-convergence [Cowles and Carlin, 1996]. For this reason, there has been a
∗Corresponding author: quan@stat.tamu.edu
1
4202
rpA
5
]OC.tats[
1v76830.4042:viXragrowing recognition of the importance of taking into account algorithmic convergence when
evaluating Bayesian statistical models. A widely used metric for assessing the convergence
of MCMC methods is the mixing time, which indicates the number of iterations required
for the sampler to get sufficiently close to the target posterior distribution in total varia-
tion distance. Most existing studies on the mixing of MCMC algorithms consider Euclidean
spaces. In particular, a very rich theory for log-concave target distributions has been devel-
oped [Dwivedi et al., 2019, Durmus and Moulines, 2019, Cheng et al., 2018, Dalalyan, 2017,
Chewi et al., 2021], providing useful insights into the sampling complexity and guidance on
the tuning of algorithm parameters. These results encompass a wide range of statistical
models owing to the Bernstein-von Mises theorem [Belloni and Chernozhukov, 2009, Tang
and Yang, 2022], which suggests that the posterior distribution becomes approximately nor-
mal (and thus log-concave) as the sample size tends to infinity. In contrast, the literature on
the complexity of MCMC samplers for discrete statistical models is limited. Further, since
every discrete space comes with its own combinatorial structure, researchers often choose to
investigate each problem on a case-by-case basis rather than formulating a unified theory
for arbitrary discrete spaces. Notable examples include variable selection [Yang et al., 2016],
community detection [Zhuo and Gao, 2021], structure learning [Zhou and Chang, 2023], and
classification and regression trees (CART) [Kim and Rockova, 2023].
Zhou and Chang [2023] undertook the endeavor to establish a general theoretical frame-
workforstudyingthecomplexityofMCMCsamplingforhigh-dimensionalstatisticalmodels
with discrete parameter spaces. They assumed a mild unimodal condition on the posterior
distribution, akin to the log-concavity assumption in continuous-space problems, and de-
rived mixing time bounds for random walk Metropolis-Hastings (MH) algorithms that were
sharper than existing ones. Here “unimodal” means that other than the global maximizer,
every state has a “neighbor” with strictly larger posterior probability, where two states are
said to be neighbors if the proposal probability from one to the other is nonzero. Selecting
this neighborhood relation often entails a trade-off, and the result of Zhou and Chang [2023]
shows that rapid mixing can be achieved if (i) the neighborhood is large enough so that the
posterior distribution becomes unimodal, and (ii) the neighborhood is not too large so that
the proposal probability of each neighboring state is not exceedingly small. Techniques from
high-dimensional statistical theory can be used to establish the unimodality in a way simi-
lar to how posterior consistency is proved, but the analysis is often highly complicated and
tailored to individual problems. We will not explore these statistical techniques in depth in
this paper; instead, our focus will be the mixing time analysis under the unimodal condition
or a weaker condition that will be introduced later.
1.2 Main Contributions of This Work
OurfirstobjectiveistoextendtheresultofZhouandChang[2023]tomoresophisticatedMH
schemes that do not use random walk proposals. We consider the informed MH algorithm
proposed in Zanella [2020], which emulates the behavior of gradient-based MCMC samplers
on Euclidean spaces [Duane et al., 1987, Roberts and Stramer, 2002, Girolami and Calder-
head, 2011] and has gained increasing attention among the MCMC practitioners [Grathwohl
et al., 2021, Zhang et al., 2022]. The proposal schemes used in the informed algorithms
2always assess the local posterior landscape surrounding the current state and then tune the
proposalprobabilitiestopreventthesamplerfromvisitingstateswithlowposteriorprobabil-
ities. However, such informed schemes do not necessarily result in faster mixing, because the
acceptance probabilities can be extremely low for proposed states, and it was shown in Zhou
et al. [2022] that, for Bayesian variable selection, naive informed MH algorithms can even
mix much more slowly than random walk MH algorithms. We will show that this acceptance
probabilityissuecanbeovercomebygeneralizingthe“thresholding”ideaintroducedinZhou
et al. [2022]. Moreover, if the posterior distribution is unimodal and tails decay sufficiently
fast, we prove that there always exists an informed MH scheme whose relaxation time can be
bounded by a constant, independent of the problem dimension, which immediately leads to
a nearly optimal bound on the mixing time. Our result significantly generalizes the finding
of Zhou et al. [2022], which only considered the high-dimensional variable selection problem.
Delving into the more technical aspects, we investigate and compare two different ap-
proaches to obtaining sharp mixing time bounds on discrete spaces: the multicommodity
flow method [Gin´e et al., 1996, Sinclair, 1992], and the single-element drift condition [Jeri-
son, 2016]. The former bounds the spectral gap of the transition matrix by identifying likely
paths connecting any two distinct states. Compared to another path argument, known as
“canonical path ensemble” and commonly used in the statistical literature [Yang et al., 2016,
Zhuo and Gao, 2021, Kim and Rockova, 2023, Chang et al., 2022], the multicommodity flow
methodismoreflexibleandcanyieldtighterbounds. Thedriftconditionmethodisbasedon
a coupling argument and stands as the most popular technique for deriving the convergence
rates of MCMC algorithms on general state spaces [Rosenthal, 1995, Roy and Hobert, 2007,
Fort et al., 2003, Johndrow et al., 2020]. A notable difference from the path method is that
this approach directly bounds the total variation distance from the stationary distribution
without analyzing the spectral gap. The existing literature suggests that both methods have
theirownuniquestrengths, andwhichmethodyieldsabettermixingtimebounddependson
the problem [Jerrum and Sinclair, 1996, Guruswami, 2000, Anil Kumar and Ramesh, 2001].
To our knowledge, the two approaches have never been compared for analyzing MCMC al-
gorithms for discrete-space statistical models. Indeed, the only works we are aware of that
use drift conditions in these contexts are Zhou et al. [2022] and Kim and Rockova [2023],
which considered variable selection and CART, respectively. We will demonstrate how the
two methods can be applied under the general framework considered in this paper, and it
will be shown that the drift condition approach yields a slightly sharper bound.
As the last major contribution of this work, we further extend our general theory beyond
unimodal settings. For multimodal target distributions, while various mixing time bounds
have been obtained [Guan and Krone, 2007, Woodard et al., 2009, Zhou and Smith, 2022],
it is generally impossible to obtain rapid mixing results where the mixing time grows only
polynomiallywithrespecttotheproblemdimension. Thisisbecausethedefinitionofmixing
timeconsiderstheworst-casescenarioregardingthechoiceoftheinitialdistribution, andthe
chain can easily get stuck if it is initialized at a local mode. When these local modes (other
than the global one) possess only negligible posterior mass and are unlikely to be visited by
the sampler given a “warm” initialization, mixing time may provide an overly pessimistic
estimate for the convergence rate. One possible remedy was described in the recent work of
Atchad´e [2021], who proposed to study initial-state-dependent mixing times using restricted
3Require
Setting Prooftechniques RandomwalkMH InformedMH
warmstart
(cid:16) (cid:17) (cid:16) (cid:17)
Pathmethod Thm1: τ =O Mlog 1 Thm2: τ =O log 1 No
πmin πmin
Unimodal
(cid:16) (cid:17)
Driftcondition Notconsidered(Remark6) Thm3: τ =O log(1/πmin) No
log(L/M)
Beyond Pathmethod+ (cid:16) (cid:17) (cid:16) (cid:17)
unimodal restrictedspectralgap
Thm4: τ x=O Mlog π(1
x)
Thm5: τ x=O log π(1
x)
Yes
Table1: Mixingtimeboundsobtainedinthispaper. Here,πisthetargetposteriordistribution,πmin=minxπ(x),M
isthemaximumneighborhoodsize,andLisaparameteroftheinformedproposalscheme. Mixingtimesτ andτx are
definedin(5)and(4)respectively,whereϵistreatedasfixed. Seetheoremstatementsfortherequiredassumptions.
spectral gap, a notion that generalizes the spectral gap of a transition matrix, and derived a
rapid mixing result for Bayesian variable selection. We extend this technique to our setting
and show that it can be integrated with the multicommodity flow method to produce sharp
mixing time bounds for both random walk and informed MH schemes.
1.3 Organization of the Paper
In Section 2, we review some recent results about the Bayesian variable selection problem,
which will be used as an illustrative example throughout this paper; this section can be
skipped for knowledgeable readers. Section 3 presents the setup for our theoretical anal-
ysis and reviews the mixing time bounds for random walk MH algorithms. In Section 4,
we consider unimodal target distributions and prove mixing time bounds for informed MH
algorithms via both the path method and drift condition analysis. Section 5 generalizes our
results to a potentially multimodal setting. Simulation studies are conducted in Section 6,
and Section 7 concludes the paper with some further discussion. A summary of the mixing
time bounds obtained in this work is presented in Table 1.
Most technical details are deferred to the appendix. In Appendix A, we review the path
method used in Zhou and Chang [2023] for bounding the spectral gaps of MH algorithms.
In Appendix B, we review the result about restricted spectral gaps obtained in Atchad´e
[2021] and develop the multicommodity flow method for bounding restricted spectral gaps.
AppendixCgivesabriefreviewofthesingle-elementdriftconditionofJerison[2016]. Proofs
for all results presented in the main text are given in Appendix D.
2 Working Example: Variable Selection
We review in this section some recent advancements in understanding the complexity of
MCMC sampling for high-dimensional spike-and-slab variable selection, one of the most rep-
resentative examples for discrete-space models in Bayesian statistics [Tadesse and Vannucci,
2021].
42.1 Target Posterior Distribution
We consider the standard linear regression model where a design matrix X ∈ Rn×p and a
response vector y ∈ Rn are assumed to satisfy
y = Xβ∗+z, z ∼ MVN(0,σ2I ),
n
where β∗ ∈ Rp is the unknown vector of regression coefficients and MVN denotes the mul-
tivariate normal distribution. Introduce the indicator vector δ = (δ ,...,δ ) ∈ {0,1}p such
1 p
thatδ = 1indicatesthatthej-thvariablehasanon-zeroeffectontheresponse. Variablese-
j
lectionisthetaskofidentifyingthetruevalueofδ,thatis,findingthesubsetofvariableswith
nonzeroregressioncoefficients. Givenδ, wecanwritey = X β +z withz ∼ MVN(0,σ2I ),
δ δ n
where X and β , respectively, denote the submatrix and subvector corresponding to those
δ δ
variables selected in δ. We will also call δ ∈ V a model, and δ = (0,0,...,0) will be referred
to as the empty model. Consider the following two choices for the space of allowed models:
V = {0,1}p, or V = {δ ∈ V: ||δ|| ≤ s}, (1)
s 1
where ||·|| denotes the L1-norm and s is a positive integer. The set V is the unrestricted
1
space, while V represents a restricted space with some sparsity constraint. Let |·| denote
s
the cardinality of a set. It is typically assumed in the high-dimensional literature that the
sparsityparametersincreasestoinfinitywithp,inwhichcaseboth|V| = 2p and|V | = O(ps)
s
grow super-polynomially with p.
Spike-and-slab variable selection is a Bayesian procedure for constructing a posterior
distribution over V or V , which we denote by π(δ). In Section 6.1, we recall one standard
s
approachtospecifyingthepriordistributionfor(δ,β,σ2),whichleadstothefollowingclosed-
form expression for π up to a normalizing constant.
1 (1+g)−(||δ||1/2)
π(δ) ∝ · . (2)
pκ||δ||1 (1+g(1−r2(δ)))n/2
In (2), κ,g are prior hyperparameters and r2(δ) = y⊤(X (X⊤X )−1X⊤)y/(y⊤y) is the
δ δ δ δ
coefficient of determination. Exact calculation of the normalizing constant is usually impos-
sible, because it would require a summation over the entire parameter space, which involves
super-polynomially many evaluations of π.
2.2 MH Algorithms for Variable Selection
To find posterior probabilities of models of interest or evaluate integrals with respect to π,
the most commonly used method is to use an MH algorithm to generate samples from π.
The transition probability from δ to δ′ in an MH scheme can be expressed by
P(δ,δ′) = K(δ,δ′)A(δ,δ′),
where K(δ,δ′) is the probability of proposing to move from δ to δ′, and the associated
acceptance probability A(δ,δ′) is given by
(cid:26) π(δ′)K(δ′,δ)(cid:27)
A(δ,δ′) = min 1, ,
π(δ)K(δ,δ′)
5ensuring that π is the stationary distribution of P.
The efficiency of the MH algorithm depends on the choice of K, and there are many
strategies for selecting the proposal neighborhood and assigning the proposal probabilities.
Recall that neighborhood refers to the support of the distribution K(δ,·) for each δ, which
we denote by N(δ). Let us begin by considering random walk proposals such that K(δ,·) is
simply the uniform distribution on N(δ). To illustrate the importance of selecting a proper
proposal neighborhood, we first present two naive choices that are bound to result in slow
convergence.
Example 1. Let the state space be V and the proposal K(δ,·) be a uniform distribution
on N(δ) = V for each δ. In this case, we get an independent MH algorithm, which is
clearly ergodic but usually mixes very slowly. For example, suppose the true model is δ∗ =
(1,0,0,...,0) and the data is extremely informative. Even if the chain is initialized at the
empty model, it takes on average 2p iterations to propose moving to δ∗.
Example 2. Let T: V → {0,1,...,2p − 1} be a one-to-one mapping defined by T(δ) =
(cid:80)p δ 2j−1. Define N(δ) = T−1({T(δ)+1,T(δ)−1}). In words, we number all elements
j=1 j
of V from 0 to 2p −1, and the proposal is a simple random walk on {0,1,...,2p −1}. The
resulting MH algorithm is also ergodic, but again the mixing is slow, since it requires at least
2p−1 steps to move from the empty model to the full model (1,1,...,1).
The neighborhood size is exponential in p in Example 1 and is a fixed constant in Exam-
ple 2. Both are undesirable, and it is better to use a neighborhood with size polynomial in
p. The following choice is common in practice:
N (δ) = {δ′ ∈ V: ||δ−δ′|| = 1, and δ ̸= δ′}.
1 1
The set N (δ) contains all the models that can be obtained from δ by either adding or
1
removing a variable. When the design matrix X contains highly correlated variables, it is
generally considered that N is too small and introducing “swap” moves is beneficial, which
1
means to remove one variable and add another one at the same time. The resulting random
walk MH algorithm is often known as the add-delete-swap sampler; denote its neighborhood
by N , which is defined by
ads
N (δ) = N (δ)∪N (δ), N (δ) = (cid:8) δ′ ∈ V: ||δ′−δ|| = 2,||δ′|| = ||δ|| (cid:9) .
ads 1 swap swap 1 1 1
We will treat N and N as neighborhood relations defined on V. When implementing the
ads 1
add-delete-swap sampler on the restricted space V , one can still propose δ′ from N (δ)
s ads
and simply reject the proposal if δ′ ∈/ V . Note that |N (δ)∩V | = O(ps).
s ads s
We end this subsection with two comments. First, a popular alternative to MH al-
gorithms is Gibbs sampling. Consider a random-scan Gibbs sampler that randomly picks
j ∈ {1,2,...,p} and updates δ from its conditional posterior distribution given the other
j
coordinates. It is not difficult to see that this updating is equivalent to randomly proposing
δ′ ∈ N (δ) and accepting δ′ with probability π(δ′)/(π(δ) + π(δ′)).1 By Peskun’s order-
1
ing [Mira, 2001], this Gibbs sampler is less efficient than the random walk MH algorithm
with proposal neighborhood N [George and McCulloch, 1997].
1
1In a general sense, this random-scan Gibbs sampler is also an MH scheme according to the original
construction in Hastings [1970].
6Second, for simplicity, we assume in this work that K(δ,·) is a uniform distribution on
N(δ) for random walk proposals. But in practice, these proposals can be implemented in a
morecomplicated, non-uniformfashion. Forexample, onecanfirstchooserandomlywhether
to add or remove a variable, and then given the type of move, a proposal of that type is
generated with uniform probability. This distinction has minimal impact on all theoretical
results we will develop.
2.3 Rapid Mixing of a Random Walk MH Algorithm
TheseminalworkofYangetal.[2016]consideredahigh-dimensionalsettingwithn,p,s → ∞
and slogp = o(n), and they proved that, under some mild assumptions, the mixing time of
theadd-delete-swapsamplerontherestrictedspaceV hasorderO(pns2logp),polynomialin
s
(n,p,s); in other words, the sampler is rapidly mixing. To provide intuition about this result
and proof techniques, which will be crucial to the understanding of the theory developed in
this work, we construct a detailed illustrative example.
Example 3. Let p = 3 and X be such that ||X ||2 = n for j = 1,2,3, XTX = −0.8n,
j 2 1 2
XTX = −0.6n and XTX = 0.9n; the three explanatory variables are highly correlated.
2 3 1 3
Let y be generated by
y = 1.25X +X +z,
1 2
where z is orthogonal to each explanatory variable, i.e., X⊤z = 0 for each j, and ||z||2 = n.
j 2
We calculate the un-normalized posterior probabilities by (2) for all models with n = 1,000,
g = p3 = 27 and κ = 1; the values are given in Table 2.
The true model, δ∗ = (1,1,0), is the global mode of π, which is expected since p is small
but n is large. Further, we indicate in Table 2 if each model is a local mode with respect
to the given search space and neighborhood relation. For example, we say δ ∈ V is a local
2
mode with respect to (V ,N ) if π(δ) > π(δ′) for every δ′ ∈ V ∩ N (δ). When there
2 ads 2 ads
is only one local mode (which must be δ∗ in this example), we say π is unimodal. Table 2
shows that π is unimodal with respect to (V ,N ), but it is multimodal with respect to
2 ads
Local mode Local mode Local mode
δ 1−r2(δ) C+logπ(δ)
w.r.t. (V,N ) w.r.t. (V ,N ) w.r.t. (V ,N )
1 2 1 2 ads
(0,0,0) 1 0 No No No
(1,0,0) 0.8704 63.98 No No No
(0,1,0) 1 -2.76 No No No
(0,0,1) 0.8236 90.46 No No No
(1,1,0) 0.64 207.70 Global mode Global mode Global mode
(1,0,1) 0.8219 88.69 No No No
(0,1,1) 0.7243 148.95 No Yes No
(1,1,1) 0.64 204.90 No – –
Table2: Log-posteriorprobabilitiesofallpossiblemodelsinExample3withn=1,000, g=p3 =27andκ=1. For
thethirdcolumn, wesettheconstantC =−logπ((0,0,0)). Foreachδ, weindicateifitisalocalmodewithrespect
tothegivensearchspaceandneighborhoodrelation.
7Figure1: Visualizationofπon(V,N1)inExample3. Foreveryδ∈V,theneighboringstatesδ′∈N1(δ)areconnected
bydottedlines. Theheightofeachbarisequalto
10(cid:112)0
π(δ). Theredbaranddottedlinesareremovediftheunderlying
spaceis(V2,N1).
(V ,N ) and the other local mode is (0,1,1). A graphical illustration is given in Figure 1.
2 1
Another interesting observation is that π(δ) does not necessarily increase as δ gets closer
to δ∗. We have π((0,0,1)) > π((0,0,0)) > π((0,1,0)), while the L1 distance from each of
the three models to δ∗ is strictly decreasing. This happens due to the correlation structure
among the three variables, and in high-dimensional settings, such collinearity is very likely
to occur between some variables. We will frequently revisit this example in later discussions.
InExample3,π isunimodalwithrespectto(V ,N ). Animportantintermediateresult
2 ads
of Yang et al. [2016] was that, with high probability, such a unimodality property still holds
in the high-dimensional regime they considered, and the global mode coincides with the true
model δ∗. This implies that the add-delete-swap sampler is unlikely to get stuck at any
δ ̸= δ∗, since there always exists some neighboring state δ′ such that A(δ,δ′) = 1 and thus
P(δ,δ′) = Ω(p−1s−1). This is the main intuition behind the rapid mixing proof of Yang et al.
[2016]. Interestingly, it was shown in Yang et al. [2016] that the unimodality is unlikely to
hold on the unrestricted space V, since local modes can easily occur on the set V\V , though
s
ithasnegligibleposteriormass. Sincetheselocalmodescaneasilytrapthesamplerforahuge
number of iterations, they had to consider the restricted space V in order to obtain a rapid
s
mixingresult. Theyalsofoundthatwithoutusingswapmoves,localmodesarelikelytooccur
at the boundary of the restricted space. (In Example 3, (0,1,1) is such a local mode.) This
isexactlythereasonwhyswapsarerequiredfortheirrapidmixingproof. Moregenerally, for
the MCMC convergence analysis of high-dimensional model selection problems with sparsity
constraints, examining the local posterior landscape near the boundary seems often a major
technical challenge [Zhou and Chang, 2023]. Nevertheless, the practical implications of this
theoretical difficulty is largely unclear. Even if we choose V as the search space, in practice,
the sampler is typically initialized within V , and if s is large enough, we will probably never
s
see the chain leave V , and thus the landscape of π on V \V is unimportant.
s s
The above discussion naturally leads to the following question: assuming a warm initial-
ization, canweobtaina“conditional”rapidmixingresultontheunrestrictedspaceV? Here,
“warm” means that the posterior probability of the model is not too small, and we use δˆ
to denote such an estimator, which can often be obtained by a frequentist variable selection
algorithm. An affirmative result was given in Pollard and Yang [2019], where a random walk
MH algorithm on V is constructed such that it proposes models from N (δ) and is allowed
1
to immediately jump back to δˆ whenever ||δ|| becomes too large. They assumed δˆ was ob-
1
8tained by the thresholded lasso method [Zhou, 2010]. An even stronger result was obtained
recently in Atchad´e [2021], who showed that by only using addition and deletion proposals,
the random walk MH algorithm on V is still rapidly mixing given a warm start. The proof
of Atchad´e [2021] utilizes a novel technique based on restricted spectral gap, which we will
discuss in detail later.
2.4 Rapid Mixing of an Informed MH Algorithm
Now consider informed proposal schemes [Zanella, 2020], which will be the focus of our
theoretical analysis. Unlike random walk proposals which draw a candidate move indiscrim-
inately from the given neighborhood, informed schemes compare the posterior probabilities
of all models in the neighborhood and then assign larger proposal probabilities to those with
larger posterior probabilities. One might conjecture that such an informed MH sampler may
behave similarly to a greedy search algorithm and can quickly find the global mode if the
target distribution is unimodal. But a naive informed proposal scheme may lead to perfor-
mance even much worse than a random walk MH sampler, as illustrated in the following
example.
Example 4. Consider Example 3 and Table 2 again. Let the informed proposal be given by
K(δ,δ′) = π(δ′)1 (δ′)/Z(δ),
N1(δ)
where Z(δ) is the normalizing constant; that is, the probability of proposing to move from
δ to δ′ ∈ N (δ) is proportional to π(δ′). Suppose that the chain is initialized at the empty
1
model δ = (0,0,0). A simple calculation yields K(δ ,δ ) ≈ 1−3×10−12 where δ = (0,0,1).
0 0 1 1
But the acceptance probability is
1/(1+e148.95+e88.69)
A(δ ,δ ) = e90.46× ≈ e−58.49 ≈ 4×10−26.
0 1 e90.46/(e90.46+e−2.76+e63.98))
Hence, we will probably never see the chain leave δ . In contrast, for the random walk MH
0
algorithm with proposal neighborhood N , the probability that the chain stays at δ is less
1 0
than 1/3.
In order to avoid scenario similar to Example 4, Zhou et al. [2022] proposed to use
informedschemeswithboundedproposalweights. Theyconstructedaninformedadd-delete-
swap sampler and showed that, under the high-dimensional setting considered by Yang et al.
[2016], the mixing time on the restricted space is O(n), thus independent of the problem
dimension parameter p. Since each iteration of informed proposal requires evaluating the
posterior probabilities of all models in the current neighborhood, the actual complexity of
their algorithm should be O(psn), comparable to the mixing time of the random walk MH
sampler. The intuition behind the proof of Zhou et al. [2022], which was based on a drift
condition argument, is similar to that of Yang et al. [2016]. The unimodality of π implies
that any δ ̸= δ∗ has one or more neighboring models with larger posterior probabilities, and
they showed that, for their sampler, the transition probability to such a “good” neighbor is
bounded from below by a universal constant.
In the remainder of this paper, we develop general theories that extend the results dis-
cussed in this section to arbitrary discrete spaces.
93 Theoretical Setup and Preliminary Results
3.1 Notation and Setup for Theoretical Analysis
Let π denote a probability distribution on a finite space X. Let X be endowed with a
neighborhood relation N: X → 2X, and we say x′ is a neighbor of x if and only if x′ ∈ N(x).
We assume N satisfies three conditions: (i) x ∈/ N(x) for each x, (ii) x ∈ N(x′) whenever
x′ ∈ N(x), and (iii) (X,N) is connected.2 For our theoretical analysis, we will assume the
triple (X,N,π) is given and analyze the convergence of MH algorithms that propose states
from N. Define
M = M(X,N) := max|N(x)|. (3)
x∈X
For most high-dimensional statistical problems, |X| grows at a super-polynomial rate with
respect to some complexity parameter p, while M only has a polynomial growth rate. Below
are some examples.
(i) Variable selection. As discussed in Section 2, we can let X = V and N = N , in
ads
which case we have M(V,N ) = O(p2). If we consider the restricted space V , we
ads s
have M(V ,N ) = O(ps).
s ads
(ii) Structure learning of Bayesian networks. Given p variables, one can let X be the
collection of all p-node Bayesian networks (i.e., labeled directed acyclic graphs). Let
N(x) be the collection of all Bayesian networks that can be obtained from x by adding,
deleting or reversing an edge [Madigan et al., 1995]. We have M = O(p2) since the
graph has at most O(p2) edges, while |X| is super-exponential in p by Robinson’s
formula [Robinson, 1977].
(iii) Ordering learning of Bayesian networks. Every Bayesian network is consistent with at
least one total ordering of the p nodes such that node i precedes node j whenever there
is an edge from i to j. To learn the ordering, we can let X be all possible orderings of
p, which is the symmetric group with degree p. Clearly, |X| = p! is super-exponential
in p. We may define N(x) as the set of all orderings that can be obtained from x by
a random transposition, which interchanges any two elements of x while keeping the
others unchanged [Chang et al., 2023, Diaconis and Shahshahani, 1981]. This yields
M = p(p−1)/2.
(iv) Community detection. Suppose there are p nodes forming K communities. One can
let X be the collection of all label assignment vectors that specify the community label
for each node, and define N(x) as the set of all assignments that differ from x by the
label of only one node [Zhuo and Gao, 2021]. We have |X| = Kp and M = p(K −1).
(v) Dyadic CART. Consider a classification or regression tree problem where the splits are
selected from p pre-specified locations. Assume p = 2K−1 for some integer K ≥ 1, and
considerthedyadicCARTalgorithm,aspecialcaseofCART,wheresplitsalwaysoccur
2“Connected” means that for any x,x′ ∈ X, there is a sequence (x = x,x ,...,x = x′) such that
0 1 k
x ∈N(x ) for i=1,...,k.
i i−1
10atmidpoints[Donoho,1997,CastilloandRoˇckov´a,2021,KimandRockova,2023]. The
search space X is the collection of all dyadic trees with depth less than or equal to K
(in a dyadic tree, every non-leaf node has 2 child nodes). One can show that |X| is
exponential in p. For x ∈ X, we define N(x) as the set of dyadic trees obtained by
either a “grow” or “prune” operation; “grow” means to add two child nodes to one leaf
node, and “prune” means to remove two leaf nodes with a common parent node. Then
M = O(p).
Let P be the transition matrix of an irreducible, aperiodic and reversible Markov chain
with stationary distribution π. For all Markov chains we will analyze, P moves on the graph
(X,N); that is, {x′: P(x,x′) > 0} = N(x). Define the total variation distance between π
and another distribution ζ by ||ζ −π|| = sup |ζ(A)−π(A)|. For ϵ ∈ (0,1/2), let
TV A⊂X
τ (P,ϵ) = min{t ∈ N : ||Pt(x,·)−π|| ≤ ϵ}, (4)
x TV
which can be seen as the “conditional” mixing time of P given the initial state x. Define the
mixing time of P by
τ(P,ϵ) = maxτ (P,ϵ). (5)
x
x∈X
It is often assumed in the literature that ϵ = 1/4, because one can show that τ(P,ϵ) ≤
⌈log ϵ−1⌉τ(P,1/4) for any ϵ ∈ (0,1/2) [Levin and Peres, 2017, Chap. 4.5]. However, since
2
such an inequality does not hold for τ , we will treat ϵ as an arbitrary constant in (0,1/2) in
x
this work. We can quantify the complexity of an MH algorithm by the product of its mixing
time and the complexity per iteration.
It is well known that mixing time can be bounded by the spectral gap [Sinclair, 1992].
Our assumption on P implies that it has real eigenvalues 1 = λ > ··· ≥ λ > −1 [Levin
1 |X|
and Peres, 2017, Lemma 12.1]. The spectral gap is defined as Gap(P) = 1−max{λ ,|λ |}
2 |X|
and satisfies the inequality
(cid:26) (cid:27)
1
τ(P,ϵ) ≤ Gap(P)−1log , (6)
ϵπ
min
where π = min π(x). The quantity Gap(P)−1 is known as the relaxation time. In
min x∈X
our mixing time bounds, we will always work with the “lazy” version of P, which is defined
by Plazy = (P + I)/2. That is, for any x ̸= x′, we set Plazy(x,x′) = P(x,x′)/2. Since
all eigenvalues of Plazy are non-negative, 1 − Gap(Plazy) always equals the second largest
eigenvalue of Plazy.
3.2 Unimodal Conditions
To characterize the modality and tail behavior of π, we introduce another parameter R:
π(y)
R = R(X,N,π) := min max , (7)
x∈X\{x∗}y∈N(x) π(x)
where x∗ = argmaxπ(x).
x∈X
Ifargmaxintheaboveequationisnotuniquelydefined, fixx∗ asoneofthemodesaccording
to any pre-specified rule. If R > 1, we say π is unimodal with respect to N, since for any
11x ̸= x∗, there is some neighboring state x′ ∈ N(x) such that π(x′) > π(x). In our subsequent
analysis of MH algorithms, we will consider unimodal targets with R > M (for random
walk MH) or R > M2 (for informed MH). These conditions ensure that the tails of π decay
sufficiently fast. To see this, for k ≥ 1, let Tail(k) = {x: Pk−1(x,x∗) = 0, Pk(x,x∗) > 0}
denote the set of states that need at least k steps to reach x∗. Then, π(Tail(k)) ≤ (M/R)k,
which decreases to 0 exponentially fast if R > M.
As discussed in Section 2, for high-dimensional variable selection, the unimodal property
has been rigorously established on X = V with N = N . A careful examination of the
s ads
proof of Yang et al. [2016] reveals that, since M is polynomial in p, the proof for R > 1 and
that for R > M2 are essentially the same; see the discussion in Section S3 of Zhou et al.
[2022]. The unimodal condition has also been proved for other high-dimensional statistical
problems,includingstructurelearningofMarkovequivalenceclasses[ZhouandChang,2023],
community detection [Zhuo and Gao, 2021], and dyadic CART [Kim and Rockova, 2023].
It should be noted that how to choose a proper N so that R > M or R > M2 can be a
very challenging question (e.g., for structure learning), which we do not elaborate on in this
paper.
In order to achieve rapid mixing, such unimodal conditions are arguably necessary, since
for general multimodal targets, the chain can get trapped at some local mode for an arbi-
trarily large amount of time. We further highlight two reasons why the unimodal analysis
is important and not as restrictive as it may seem. First, mixing time bounds for unimodal
targets are often the building blocks for more general results in multimodal scenarios. One
strategy that will be discussed shortly is to use restricted spectral gap. Another approach
is to apply state decomposition techniques [Madras and Randall, 2002, Jerrum et al., 2004,
Guan and Krone, 2007], which works for general multimodal targets; see, e.g., Zhou and
Smith [2022]. Second, as explained in Remark 4 of Zhou and Smith [2022], the condition
R > M is very similar to log-concavity on Euclidean spaces, since it implies unimodality and
exponentially decaying tails. Moreover, as we have illustrated in Example 3, for a variable
selection problem with fixed p and sufficiently large n, π is typically unimodal, but π(δ)
may not increase as δ gets closer to the mode in L1 distance. This suggests that our uni-
modal condition is conceptually more general than log-concavity, since the latter also implies
unimodality in a slice taken along any direction.
For the analysis beyond the unimodal setting, we consider a subset X ⊂ X and only
0
imposeunimodalityonX . LetN| denoteN restrictedtoX ,thatis,N| (x) = N(x)∩X .
0 X0 0 X0 0
Mimicking the definition of R, we define R| by restricting ourselves to X :
X0 0
π(x′)
R| = R(X ,N| ,π) = min max ,
X0 0 X0
x∈X0\{x∗ 0}x′∈N|X0(x) π(x)
where x∗ = argmaxπ(x).
0
x∈X0
If R| > 1, we say π is unimodal on X with respect to N. Note that R| > 1 also implies
X0 0 X0
that (X ,N) is connected. In Section 5, we will study the mixing times of MH algorithms
0
assuming R| > M (or R| > M2) for some X such that π(X ) is sufficiently large.
X0 X0 0 0
123.3 Mixing Times of Random Walk MH Algorithms
We first review the mixing time bound for random walk algorithms obtained in Zhou and
Chang [2023] under a unimodal condition. Recall that we assume the random walk proposal
scheme can be expressed as
K(x,x′) = |N(x)|−11 (x′).
N(x)
The resulting transition matrix of random walk MH can be written as
 min(cid:110) 1 , π(x′) (cid:111) , if x′ ∈ N(x),
  |N(x)| π(x)|N(x′)|

P 0(x,x′) = 1−(cid:80) x˜∈N(x)P 0(x,x˜), if x′ = x,



0, otherwise.
Yang et al. [2016] used (6) and the “canonical path ensemble” argument to bound the
mixing time of the add-delete-swap sampler for high-dimensional variable selection. As
observed in Zhou and Smith [2022] and Zhou and Chang [2023], the method of Yang et al.
[2016]isapplicabletothegeneralsettingweconsider. Theonlyassumptiononeneedsisthat
the triple (X,N,π) satisfies R > M, which ensures that, for any x ̸= x∗, we can identify a
path (x = x,x ,...,x ,x = x∗) such that π(x )/π(x ) > M for each j. A canonical
0 1 k−1 k j j−1
path ensemble is a collection of such paths, one for each x ̸= x∗, and then a spectral gap
bound can be obtained by identifying the maximum length of a canonical path and the edge
subject to the most congestion. It was shown in Zhou and Smith [2022] that the bound
of Yang et al. [2016] can be further improved by measuring the length of each path using a
metric depending on π (instead of counting the number of edges). The following result is a
direct consequence of (6) and Lemma 3 of Zhou and Smith [2022].
Theorem 1. Assume ρ = R/M > 1. Then, we have π(x∗) ≥ 1−ρ−1, Gap(Plazy)−1 ≤ c(ρ)M
0
and
(cid:26) (cid:27)
1
τ(Plazy,ϵ) ≤ c(ρ)M log ,
0 ϵπ
min
where
4
c(ρ) = . (8)
(1−ρ−1/2)3
Remark 1. Forhigh-dimensionalstatisticalmodels,wesaythatarandomwalkMHalgorithm
israpidlymixingifforfixedϵ ∈ (0,1/2),τ(Plazy,ϵ)scalespolynomiallywithsomecomplexity
0
parameter p. As discussed in Section 3.1, M is typically polynomial in p by construction.
Hence, to conclude rapid mixing from Theorem 1, it suffices to establish two conditions: (i)
logπ is polynomial in p, and (ii) ρ = R/M → ∞, which implies c(ρ) → 4. This line of
min
argument is used in most existing works on the complexity of MCMC algorithms for high-
dimensional model selection problems; see Yang et al. [2016], Zhou and Chang [2023], Zhuo
and Gao [2021] and Kim and Rockova [2023]. In particular, under common high-dimensional
assumptions, ρ often grows to infinity at a rate polynomial in p. Note that if ρ → ∞, we also
have π(x∗) → 1 by Theorem 1, which is a consistency property of the underlying statistical
model.
134 Dimension-free Relaxation Times of Informed MH Algo-
rithms
4.1 Informed MH Algorithms
InformedMHalgorithmsgenerateproposalmovesafterevaluatingtheposteriorprobabilities
of all neighboring states. Given a weighting function h : R+ → R+, we define the informed
proposal by
(cid:16) (cid:17)
π(x′)
h (cid:18) (cid:19)
K (cid:0) x,x′(cid:1) = π(x) 1 (cid:0) x′(cid:1) , where Z (x) = (cid:88) h π(x˜) ;
h Z (x) N(x) h π(x)
h
x˜∈N(x)
that is, K (x,·) draws x′ from the set N(x) with probability proportional to h(π(x′)/π(x)).
h
Intuitively, one wants to let h be non-decreasing so that states with larger posterior proba-
√
bilities receive larger proposal probabilities. Choices such as h(u) = 1+u, u or 1∧u were
analyzed in Zanella [2020]. It was observed in Zhou et al. [2022] and also illustrated by our
Example 4 that for problems such as high-dimensional variable selection, such choices could
be problematic and lead to even worse mixing than random walk MH algorithms. To gain a
deeper insight, we write down the transition matrix of the induced MH algorithm:
(cid:40) K (x,x′)min(cid:110) 1, π(x′)K h(x′,x)(cid:111) , if x′ ̸= x,
P h(cid:0) x,x′(cid:1) = h
1−(cid:80)
Pπ ((x x) ,K x˜h )(x ,,x′)
if x′ = x.
x˜̸=x h
We expect that K (x,·) proposes with high probability some x′ such that π(x′) ≫ π(x). But
h
K (x′,x), which depends on the local landscape of π on N(x′), can be arbitrarily small if h
h
is unbounded, causing the acceptance probability of the proposal move from x to x′ to be
exceedingly small.
The solution proposed in Zhou et al. [2022] was to use some h that is bounded both from
above and from below. In this work, we consider the following choice of h:

ℓ, if u < ℓ,


h(u) = clip(u,ℓ,L) := u, if ℓ ≤ u ≤ L, (9)

 L, if u > L,
where ℓ < L are some constants. Henceforth, whenever we write K or P , it is understood
h h
that h takes the form given in (9). We now revisit Example 3 and show that this bounded
weighting scheme overcomes the issue of diminishing acceptance probabilities.
Example 5. Consider Example 3. It was shown in Example 4 that if an unbounded informed
proposal is used, the algorithm can get stuck at δ = (0,0,0), since it keeps proposing
0
δ = (0,0,1) of which the acceptance probability is almost zero. Now consider an informed
1
proposal with h defined in (9) and ℓ = p = 3, L = p2 = 9. By Table 2, this yields proposal
probabilityK (δ ,δ ) = 3/7; thus, δ receiveslargerproposalprobabilitythanintherandom
h 0 1 1
walk proposal. In contrast to the scenario in Example 4, the acceptance probability of this
move equals 1, since
π(δ )K (δ ,δ ) h(e−90.46)/{h(e−90.46)+h(e58.49)+h(e−1.77)}
1 h 1 0 = e90.46
π(δ )K (δ ,δ ) h(e90.46)/{h(e90.46)+h(e−2.76)+h(e63.98)}
0 h 0 1
3/(3+32+3)
= e90.46 ≈ 9×1038 > 1.
32/(32+3+32)
14We can also numerically calculate that the spectral gaps of P (random walk MH) and
0
P are 0.334 and 0.582, respectively, which shows that the informed proposal accelerates
h
mixing. Since p is very small in this example, the advantage of the informed proposal is not
significant.
What we have observed in Example 5 is not a coincidence. The following lemma gives
simple conditions under which an informed proposal is guaranteed to have acceptance prob-
ability equal to 1.
Lemma 1. Let x′ ∈ N(x). Assume that Z (x) ≥ L and π(x′)/π(x) ≥ ℓ ≥ M. Then,
h
π(x′)K (x′,x)
h
≥ 1.
π(x)K (x,x′)
h
That is, an informed proposal from x to x′ has acceptance probability 1.
Proof. See Appendix D.
The assumption Z (x) ≥ L used in Lemma 1 is weak, and it will be satisfied if x has one
h
neighboring state z such that π(z)/π(x) ≥ L, which is true if L ≤ R.
4.2 Dimension-FreeRelaxationTimeBoundviatheMulticommodityFlow
Method
Using Lemma 1 and Theorem 2 of Zhou and Chang [2023], we can now prove a sharp mixing
time bound for informed MH algorithms under the assumption R > M2.
Theorem 2. Assume R > M2. Choose ℓ = M and M2 < L ≤ R. Then, Gap(Plazy)−1 ≤
h
2c(ρ˜), and
(cid:26) (cid:27)
1
τ(Plazy,ϵ) ≤ 2c(ρ˜)log ,
h ϵπ
min
where ρ˜= L/M2 and c(ρ) is given in (8).
Proof. See Appendix D.
Remark 2. Recall that Gap(P)−1 is called the relaxation time, which can be used to derive
the mixing time bound by (6). If we consider an asymptotic regime where L,M2 → ∞
and liminfL/M2 > 1, by Theorem 2, the relaxation time for informed MH algorithms is
bounded from below by a universal constant (independent of the problem dimension). In
particular, this relaxation time bound is improved by a factor of M, compared to that for
random-walk MH algorithms in Theorem 1. Since the spectral gap of a transition matrix
cannot be greater than 2, the order of the relaxation time bound in Theorem 2 is optimal,
and we say it is “dimension-free”.
Remark 3. Lemma 1 and Theorem 2 provide useful guidance on the choice of ℓ,L in (9).
For most problems, after specifying the proposal neighborhood N, we can simply set ℓ =
M(X,N),whichistypicallyeasytocalculateorbound. RegardingthechoiceofL,according
to Theorem 2, for unimodal targets one may use L = M2+ξ or L = (1+ξ)M2 for some small
ξ > 0. For multimodal targets, the simulation studies in Zhou et al. [2022] suggest that one
may want to choose ℓ,L such that the ratio L/ℓ is smaller; in other words, one wants to
15use a more conservative informed proposal that is not overwhelmingly in favor of the best
neighboring state.
The proof of Theorem 2 utilizes the multicommodity flow method [Sinclair, 1992], which
generalizes the canonical path ensemble argument and allows us to select multiple likely
transition routes between any two states. If one uses the canonical path ensemble, the
resulting relaxation time bound for informed MH algorithms will still involve a factor of
M as in Theorem 1. A detailed review of the multicommodity flow method is given in
Appendix A.
4.3 Better Mixing Time Bounds via the Drift Condition
The mixing time analysis we have carried out so far relies on employing path methods to
establish bounds on the spectral gap—an approach that is predominant in the literature on
finite-state Markov chains. One exception was the recent work of Zhou et al. [2022], who
used drift condition to study the mixing time of an informed add-delete-swap sampler for
Bayesian variable selection. In this section, we show that their method can also be applied
to general discrete spaces, and it can be used to improve the mixing time bound obtained in
Theorem 2 in an asymptotic setting.
We still let x∗ = argmax π(x). The strategy of the proof is to establish a drift
x∈X
condition on X \{x∗}, which means that for some V : X → [1,∞) and α ∈ (0,1),
(P V)(x) ≤ αV(x), for any x ∈ X \{x∗}, (10)
h
where (P V)(x) = (cid:80) P (x,x′)V(x′). Then, one can apply Theorem 4.5 of Jerison [2016]
h x′∈X h
to obtain a mixing time bound of the order (1−α)−1logV. The main challenge is to find
an appropriate V such that α is as small as possible. After several trials, we find that the
choice,
(cid:18) (cid:19)
logπ(x)
V(x) = π(x)1/logπmin = exp , (11)
logπ
min
yields the desired mixing rate given in Theorem 3 below. This drift function is similar to but
simpler than the one used in Zhou et al. [2022] for variable selection. By definition, V(x)
always decreases as π(x) increases since π < 1, and V is bounded on [1,e].
min
Theorem 3. Assume R > M2. Choose ℓ = M and M2 < L ≤ R. If π satisfies
min
M2logπ−1
min = o(1), (12)
Llog(L/M)
then
(cid:18) (cid:19)
4log(2e/ϵ) 1
τ(Plazy,ϵ) ≲ log .
h log(L/M) π
min
Proof. See Appendix D.
Remark 4. The order of the mixing time bound in Theorem 3 is typically better than that in
Theorem 2. To see this, let p denote the complexity parameter as introduced in Section 3.1
and assume L = pω and M = pψ for constants ω,ψ with ω > 2ψ. Then, Theorem 3 implies
(cid:32) (cid:33)
logπ−1
τ(Plazy,ϵ) ≤ O min ,
h logp
16which improves the bound in Theorem 2 by a factor of 1/logp. The additional condition on
π given in (12) is very weak. It holds as long as
min
(cid:16) (cid:17)
π ≥ exp −pω−2ψlogp .
min
In particular, (12) is satisfied if π ≥ p−Clogp for some universal constant C > 0.
min
Remark 5. The mixing time bound does not take into account the computational cost per
iteration. When implementing informed MH algorithms in practice, one should consider the
cost of posterior evaluationof all neighboringstates in each proposal. Theorems2 and 3 sug-
gest that there at least exists some informed MH algorithm whose mixing rate is fast enough
to compensate for the additional computation cost. When parallel computing resources are
available, one can reduce the cost of informed proposals significantly by parallelizing the
posterior evaluation.
Remark 6. The drift function given in (11) cannot be used to study the mixing times of
random walk MH algorithms under the unimodal setting we consider. To see this, suppose
|N(x)| = M for all x ∈ N and that there exist x ∈ X,z ∈ N(x) such that (i) π(z)/π(x) = R,
and (ii) for any z′ ∈ N(x)\{z}, π(z′)/π(x) = 1/2, which implies P (x,z′) = 1/(2M). Then,
0
(cid:88)
(P V)(x) = P (x,z)V(z)+ P (x,z′)V(x′)
0 0 0
z′∈N(x)\{z}
1 logR M −1 −log2
= V(x)elogπmin + V(x)elogπmin.
M M
Assuming M → ∞ and logR/logπ−1 = o(1), we can rewrite the above equation as
min
(cid:18) (cid:19) (cid:18) (cid:19)
(P 0V)(x) 1 logR M −1 −log2
−1 = elogπmin −1 + elogπmin −1
V(x) M M
(cid:32) (cid:33) (cid:32) (cid:33)
logR log2
=−O +O .
M logπ−1 logπ−1
min min
Hence, as long as (logR)/M = o(1), the right-hand side of the above equation is asymptot-
ically positive. Consequently, (P V)(x) is asymptotically greater than V(x), which means
0
that there does not exist α ∈ (0,1) satisfying (10).
5 Mixing Times in a Multimodal Setting
As we have seen in Section 2, when we let X be the unrestricted search space for a high-
dimensional statistical problem, we usually do not expect that π is unimodal on X. In
particular, for high-dimensional model selection problems, local modes can easily occur at
some non-sparse models. However, we can often establish the unimodality on some subset
X ⊂ X. Moreover, in reality, we typically initialize the MH algorithm at some state in X
0 0
(e.g. a sparse model), and if X is large enough, we probably will not see the chain leave X
0 0
during the entire run. This suggests that the behavior of the chain on X\X may not matter
0
if we only care about the mixing of the chain given a good initialization. In this section, we
measure the convergence of MH algorithms using the initial-state-dependent mixing time τ
x
defined in (4) and generalize the previous results to a potentially multimodal setting where
17R| > M or R| > M2. Combining the restricted spectral gap argument of Atchad´e [2021]
X0 X0
with the multicommodity flow method, we obtain the following theorem, which shows that
the mixing will be fast if the chain has a warm start and π(X \X ) is sufficiently small.
0
Theorem 4. Let X ⊂ X,x ∈ X ,η ∈ (0,1) be such that (i) ρ = R| /M > 1, (ii) π(x ) ≥ η,
0 0 0 X0 0
and (iii) π(X ) ≥ 1−ϵ2η2/5. We have
0
(cid:26) (cid:27)
1
τ (Plazy,ϵ) ≤ c(ρ)M log ,
x0 0 2ϵ2η2
where c(ρ) is given in (8).
Proof. See Appendix D.
Remark 7. WeusevariableselectiontoillustratehowTheorem4istypicallyutilizedinhigh-
dimensional settings. Set X = V and X = V . Since it was already shown in Yang et al.
0 s
[2016] that R| > M under some mild assumptions, it only remains to verify conditions (ii)
X0
and(iii)inTheorem4. Iftheycanbeestablishedforsomex ∈ X andη > 0suchthat|logη|
0 0
ispolynomialinp,thenτ (Plazy,ϵ)isalsopolynomialinp. Theexistingliterature[Narisetty
x0 0
and He, 2014] suggests that condition (iii) is likely to hold for η = p−c where c > 0 is
a relatively large fixed constant, and thus polynomial complexity of a random walk MH is
guaranteedifπ(x ) ≥ p−c. SeeAtchad´e[2021]foraproofofwarmstartundertheassumption
0
that the initial model has bounded size and no false negative.
Similarly, we can also use the argument of Atchad´e [2021] to extend Theorem 2 to the
multimodal setting. However, this time we need an additional assumption on the behavior
of π at the boundary of the set X . It is given in (13) below and is used to ensure that
0
K (x,X \X ) is sufficiently small for any x at the boundary of X .
h 0 0
Theorem 5. Let X ⊂ X,x ∈ X ,η ∈ (0,1) be such that R| > M2, π(x ) ≥ η, and
0 0 0 X0 0
π(X ) ≥ 1−ϵ2η2/5. Choose ℓ = M and M2 < L ≤ R| . If
0 X0
π(x′) L
max max < , (13)
x∈X0x′∈N(x)\X0 π(x) M
we have
(cid:26) (cid:27)
1
τ (Plazy,ϵ) ≤ 2c(ρ˜)log ,
x0 h 2ϵ2η2
where ρ˜= L/M2 and c(ρ) is given in (8).
Proof. See Appendix D.
6 Numerical Examples
6.1 Bayesian Variable Selection
We consider the Bayesian variable selection model studied in Yang et al. [2016], which as-
sumes
y = X β +z, z ∼ MVN(0,ϕ−1I ),
δ δ n
18and uses the following prior distribution on (β,ϕ,δ):
β | δ ∼ MVN(0,gϕ−1(X⊤X )−1),
δ δ δ
π (ϕ) ∝ ϕ−1,
0
π (δ) ∝ p−κ||δ||1.
0
By integrating out the model parameters (β ,σ2), we obtain the marginal posterior distri-
δ
bution π(δ) given in (2), which is a function of r2(δ),||δ|| and prior hyperparameters. Since
1
X⊤X is singular if ||δ|| > n, we will work with the search space V defined in (1), which
δ δ 1 n
is equivalent to setting π(δ) = 0 for any δ such that ||δ|| > n.
1
Throughout our simulation studies, we set κ = 1, g = p3, sample size n = 200 and
number of variables p = 500. We always generate y by y = Xβ∗+z with z ∼ MVN(0,I ).
n
The first 5 elements of β∗ are set to
(cid:114)
logp
β∗ = (8,−12,8,8,−12),
[5] n
where we use the notation [k] = {1,2,...,k}; all the other elements of β are set to zero. Let
δ∗ ∈ V denote the true model, which satisfies δ∗ = 1 . We let all rows of the design
n j {j∈[5]}
matrix X be i.i.d from MVN(0,Σ), and consider two choices the covariance matrix Σ:
(i) (moderate correlation) Σ = e−2|j−k| for j ̸= k;
jk
(ii) (high correlation) Σ = e−|j−k|/4 for j ̸= k.
jk
We set Σ = 1 for j ∈ [p] in both cases.
jj
In all the data sets (X,y) we have simulated, regardless of the simulation setting, we
find that δ∗ is always the global mode of π with significant posterior mass. Hence, we use
the number of iterations needed to reach δ∗ as an indicator of the mixing of the chain [Peres
and Sousi, 2015]. We compare three different MCMC methods.
(a) RWMH: the random walk MH algorithm described in Section 3.3.
(b) IMH: the informed MH algorithm described in Section 4 with ℓ = p and L = p3.
(c) IMH-unclipped: the informed MH algorithm described in Section 4 with ℓ = 0 and
L = ∞.
For all three algorithms, we use N as the proposal neighborhood; that is, the algorithms
1
only propose the next model by adding or deleting a variable. For each integer m ∈ [n]∪{0},
we use
∆m = {δ ∈ V : ||δ|| = m},
1
to denote the set of all models involving m variables. The initial model will be sampled
from ∆m uniformly for some m. We always run RWMH for 10,000 iterations and run each
informed MH algorithm for 1,500 iterations. We report the following metrics.
• Success: the number of runs where the algorithm samples the true model.
• H : the median number of iterations needed to sample the true model for the first
true
time.
• Time: the median wall time measured in seconds.
• T : the median wall time (in seconds) needed to sample the true model for the first
true
time.
196.1.1 Moderately correlated design
We first generate one data set (X,y) where the covariance matrix of X exhibits moderate
correlation. WeinitializeRWMHandIMHatmodelsuniformlysampledfrom∆m andstudy
theeffectofmonthemixing. Foreachchoiceofm, werunthealgorithms100times. Results
are presented in Figure 2 and Table 3.
We first observe that the mixing of the chain depends on the initialization, and local
modes are likely to occur among non-sparse models. As illustrated by Figure 2, when the
chain is initialized at some δ ∈ ∆n = ∆200, it always gets stuck and barely moves. This is
probably because a randomly generated δ ∈ ∆n is likely to be a local mode on (V ,N ). As
n 1
argued in Yang et al. [2016], δ ∈ ∆n yields a perfect fit with r2(δ) = 1, and for a neighboring
model δ′ ∈ N (δ)∩V to have a larger posterior probability, it must achieve a nearly perfect
1 n
fit, which is unlikely. If we sample the initial model from ∆m for smaller m, the performance
of the algorithms gets improved dramatically, as shown in both Figure 2 and Table 3. This
aligns well with the theory developed in Section 5: π seems to be (at least approximately)
unimodal on (V ,N ) for some s much smaller than n, and given a warm start, both RWMH
s 1
and IMH mix quickly.
Another observation from Figure 2 and Table 3 is that, compared to RWMH, IMH needs
a better initialization to achieve fast mixing. Specifically, for RWMH, we need m ≤ 180 for
most runs to be “successful” (i.e., find the true model δ∗), and for IMH, we need m ≤ 170.
We believe this is because informed algorithms, which behave similarly to gradient-based
samplers on Euclidean spaces, have a stronger tendency to move to nearest local modes than
RWMH. Consequently, the performance of IMH is more sensitive to the initialization. This
observation also partially explains why the condition (13) is required in Theorem 5, which
is not needed when we analyze RWMH.
Next, we consider a more realistic initialization scheme, where all samplers are started at
someδuniformlydrawnfrom∆20. Wegenerate100replicatesof(X,y)underthemoderately
correlated setting, and compare the performance of RWMH, IMH and IMH-unclipped. The
result is summarized in Table 4. Both RWMH and IMH hit δ∗ within the specified total
number of iterations, and IMH achieves this in much fewer iterations. This is expected, since
Theorem 1 and Theorem 3 suggest that IMH mixes faster by a factor with the order of M
(for this variable selection problem, M = p = 500).
We also note that IMH-unclipped exhibits very poor performance in Table 4, which
is expected according to the reasoning explained in Example 4. It shows that selecting
appropriatevaluesforℓandLin(9)iscrucialtotheperformanceofinformedMHalgorithms
in applications like variable selection.
Initialization ∆0 ∆100 ∆150 ∆170 ∆180 ∆190 ∆200
Success 99 100 100 100 99 36 0
RWMH
T 1548 2322 2584 2602 2620 – –
true
Success 100 100 100 97 7 0 0
IMH
T 5 103 155 179 – – –
true
Table3: Numberofsuccessesandmediantime(inseconds)neededtohitδ∗ from100MCMCrunsforonesimulated
dataset.
20Initialization
−1 D 180
D 190
D 200
−2
−3
10 100 500 1000 5000 10000
Iterations
Initialization
D 170
−1
D 180
D 200
−2
−3
5 10 50 100 500 1500
Iterations
Figure2: ViolinplotsvisualizingMCMCtrajectoriesforonesimulateddataset. Eachviolingivesthedistributionof
thelog-posteriorprobability(scaledby10−3)ofthesampledmodelacross100runs. Thetoppanelisfortherandom
walk MH algorithm, and the lower is for the informed MH algorithm. Algorithms are initialized at models uniformly
sampledfrom∆m,andeachcolorrepresentsonechoiceofm. Theblackdottedlineindicatesthescaledlog-posterior
probabilityofthetruemodel.
RWMH IMH IMH-unclipped
Success 100 100 0
H 1811 27 –
true
Time 13.6 9.3 35.3
T 9.1 7.5 –
true
Table 4: Results for 100 replicates with moderately correlated design. Each algorithm is initialized at δ uniformly
sampledfrom∆20.
6.1.2 Highly correlated design
Whenthedesignmatrixexhibitsahighdegreeofcollinearity, weexpectthatπ canbehighly
multimodal, and local modes may occur on (V ,N ) even for small s. Hence, unlike in the
s 1
moderately correlated setting where we only need to initialize the sampler at a sufficiently
sparse model, we may need to impose much stronger assumptions on the initialization so
that the samplers can quickly find the true model.
To investigate this, we generate 100 replicates of (X,y) under the highly correlated
setting, and consider two initialization schemes studied in Atchad´e [2021]. We denote them
by δbad and δgood. Both δbad and δgood include 50 randomly sampled variables that are not
21in δ∗ (i.e., false positives), and for each j ∈ [5], δgood = 1 while δbad = 0. Hence, δbad
j j
satisfies ||δbad|| = 50 and has 5 false negatives, and δgood satisfies ||δgood|| = 55 with no
1 1
false negative. Table 5 summarizes the results. When started at δbad, both samplers fail to
find δ∗ in most replicates, and IMH is still more sensitive to nearby local modes as in the
simulation study with moderately correlated design. When started at δgood, both algorithms
recover δ∗ quickly, and IMH has a slightly higher success rate than RWMH. This result
suggests that π is probably highly multimodal among models with false negatives (recall
that in Example 3, the posterior probability can decrease when we add some variable that is
in the true model), and the identification of δ∗ requires a warm start that already includes
δ∗ as a submodel.
RWMH IMH
Initialization δbad δgood δbad δgood
Success 27 95 3 100
H – 2198 – 51
true
Time 13.2 13.5 13.1 19.6
T – 9.5 – 8.7
true
Table 5: Results for 100 replicates with highly correlated design. See the main text for how δbad and δgood are
generated.
6.2 Bayesian Community Detection
Consider the community detection problem with only two communities, where the goal is to
estimate the community assignment vector z ∈ {1,2}p from an observed undirected graph
represented by a symmetric adjacency matrix A ∈ {0,1}p×p. Here z ∈ {1,2} denotes the
j
community assignment of the j-th node. We construct a posterior distribution by following
the model and prior distribution used in Zhuo and Gao [2021] and Legramanti et al. [2022]:
ind
A | Q,z ∼ Bernoulli(Q ), ∀i,j ∈ [p] and i < j,
ij zizj
iid
Q ∼ Uniform(0,1), ∀u,v ∈ [p] and u ≤ v,
uv
π (z) ∝ 1, ∀z ∈ {1,2}p,
0
where π (z) denotes the prior distribution of z and Q is the edge connection probability
0 uv
between one node from community u and another from community v. By integrating out
Q, we obtain a posterior distribution π on the finite space {1,2}p. Note that due to label
switching, we have π(z) = π(z˜), where z˜ is defined by z˜ = 3−z .
j j
In the simulation, we set p = 1,000 and let the true community assignment vector z∗ be
given by z∗ = 1 if 1 ≤ j ≤ p/2 and z∗ = 2 otherwise. We generate the observed graph by
j j
sampling each A (with i < j) independently from Bernoulli(p ) when z = z and from
ij within i j
Bernoulli(p ) when z ̸= z . We use p = 10−1 and p = 10−8 so that the two
between i j within between
communities are well separated in the observed graph.
WeconsiderbothrandomwalkMH(RWMH)andinformedMH(IMH)algorithms,whose
proposal neighborhood is defined as N(z) = {z′ : d (z,z′) = 1}, where d is the Hamming
H H
distance. In words, the proposal only changes the community assignment of one node. For
IMH, this time we use ℓ = p−1 and L = p3 (reason will be explained later). We simulate
22100 data sets, and for each data set we run RWMH for 20,000 iterations and IMH for 2,000
iterations. We consider two different initialization schemes, denoted by zbad and zgood. The
assignment vector zbad is randomly generated such that half of the community assignments
are incorrect, while zgood is generated with only one third of the assignments being incorrect.
We summarize the results in Table 6 where the four metrics are defined similarly to those
used in Section 6.1. Note that we treat both z∗ and z˜∗ as the true model, where z˜∗ = 3−z∗
j j
for each j ∈ [p].
The result confirms our theoretical findings in Section 5 regarding the effect of initial-
ization on the mixing. When we initialize the samplers at zbad, fewer than 50 % of the
runs reach the true assignment vector up to label switching, while all chains find the true
assignment within a reasonable number of iterations when zgood is used for initialization. In
Figure 3, we plot the scaled log-posterior trajectories of 100 MCMC runs for one simulated
data set. The figure shows that some runs initialized at zbad get trapped near it, and when
the chain is initialized at zgood, it exhibits much faster mixing.
We have also tried IMH with ℓ = p and L = p3 and observed that in all 100 replicates
with initial state zbad, the sampler fails to find the true assignment vector and gets stuck
around zbad. We have numerically examined the posterior landscape around zbad and found
that the ratio π(z′)/π(zbad), where z′ = argmax π(z), is always very small (often
z∈N(zbad)
around1). Hence,aninformedproposalwithℓ = p = 1,000onlyproposesz′ withprobability
1/p (and may get rejected due to small acceptance rates). For comparison, using ℓ = p−1
assigns larger proposal probability to z′ and sometimes does help IMH move away from zbad,
as shown in Figure 3.
Figure 3: Log-posterior probability ×10−4 versus the number of iterations in 100 MCMC runs, initialized at zbad
(gray)orzgood (blue). Theredlineindicatesthelogposteriorprobabilityofthetrueassignment. Theleftpanelisfor
RWMH,andtherightisforIMH.
23RWMH IMH
Initialization zbad zgood zbad zgood
Success 41 100 49 100
H – 10901 – 333
true
Time 8.4 6.8 76.1 75.5
T – 5.6 – 13.4
true
Table6: Resultsfor100replicatesofthecommunitydetectionproblem. Seethemaintextforhowzbad andzgood are
generated.
7 Discussion and Concluding Remarks
Our theory suggests that an MH algorithm converges fast if it is initialized within a set X
0
such that π(X ) is large and π is unimodal on X with respect to the given neighborhood
0 0
relation N. In practice, it is difficult to determine if π is indeed unimodal with respect to N,
and thus a larger proposal neighborhood is sometimes preferred to prevent the chain from
gettingstuckatlocalmodes. Forexample, invariableselection, onecanenlargetheproposal
neighborhood by allowing adding or removing multiple variables simultaneously, which is a
common practice in the literature [Lamnisos et al., 2009, Guan and Stephens, 2011, Titsias
and Yau, 2017, Zhou and Guan, 2019, Liang et al., 2022, Griffin et al., 2021]. However, using
a too large neighborhood is not desirable either, which is sometimes called the “Goldilocks
principle” [Rosenthal, 2011]. Our theory suggests that we should try to use the smallest
neighborhood that leaves π unimodal on X . Developing diagnostics related to the unimodal
0
condition could be an interesting direction for future work and provide guidance on choosing
the neighborhood size in adaptive methods [Griffin et al., 2021, Liang et al., 2022].
One important technical contribution of this work is that we have demonstrated how to
use multicommodity flow method and single-element drift condition to derive mixing time
bounds in the context of discrete-space statistical models. To our knowledge, both meth-
ods have been rarely considered in the literature on high-dimensional Bayesian statistics.
For random walk MH algorithms, the canonical path ensemble method may already provide
a nearly optimal spectral gap bound, but for informed MH algorithms, the use of multi-
commodity flow is crucial to obtaining the dimension-free estimate of the relaxation time.
Regarding the drift condition analysis, general theoretical results have been obtained for
random walk or gradient-based MH algorithms on Euclidean spaces. In particular, the drift
function V(x) = π(x)−1/2 (π denotes the Lebesgue density) has been used to prove geomet-
ric ergodicity [Roberts and Tweedie, 1996, Jarner and Hansen, 2000] and to derive explicit
convergence rate bounds in the recent work of Bhattacharya and Jones [2023]. This choice
of V is conceptually similar to the one we introduce in (11), V(x) = π(x)1/logπmin, where the
exponent is chosen deliberately to optimize the mixing time bound. It would be interesting
to investigate whether one can also improve the mixing time estimates on Euclidean spaces
by using a different exponent (though our choice will not be applicable since π becomes
min
zero on unbounded spaces).
Both our theory and simulation studies suggest that informed MH algorithms require
stronger assumptions on the posterior distribution or initialization scheme to achieve fast
mixing. An open question is whether informed samplers still have theoretical guarantees
under the regime M < R < M2, which is not covered by our results such as Theorem 2.
24Note that by Theorem 1, random walk MH algorithms mix rapidly in this case.
Finally, we point out that MH sampling schemes may not be the most efficient way to
utilize informed proposals. The informed importance tempering algorithm proposed in Zhou
andSmith[2022]andLietal.[2023],whichgeneralizesthetemperedGibbssamplerofZanella
and Roberts [2019], allows one to always accept informed proposals and use importance
weighting to correct for the bias. It was shown in Li et al. [2023] that this technique can
also be applied to multiple-try Metropolis algorithms [Liu et al., 2000, Chang et al., 2022,
Gagnon et al., 2023], making them rejection-free. These multiple-try methods enable the
calculation of an informed proposal only on a random subset of N(x), with the subset’s size
adjustable according to available computing resources, which makes them highly flexible and
easily applicable to general state spaces.
Acknowledgement
The authors were supported by NSF grants DMS-2311307 and DMS-2245591. They would
like to thank Yves Atchad´e for helpful discussion about restricted spectral gap.
25Appendix
A Review of Path Methods
A.1 Spectral Gap and Path Methods
Let P ∈ [0,1]|X|×|X| denote the transition probability matrix of an irreducible, aperiodic and
reversible Markov chain on the finite state space X. Let π denote the stationary distribution
and define π(f) = (cid:80) π(x)f(x) for any f: X → R. Recall that we define the spectral gap of
x
P as
Gap(P) = 1−max{λ ,|λ |},
2 |X|−1
and the relation between spectral gap and mixing time is described by the inequality (6). In
words, ifGap(P)isclosetozero, thechainrequiresalargenumberofstepstogetclosetothe
stationary distribution in total variation distance. Path methods are a class of techniques
for finding bounds on Gap(P) by examining likely trajectories of the Markov chain. They
are based on the following variational definition of Gap(P) [Levin and Peres, 2017, Lemma
13.6]:
E(f)
Gap(P) = min , (14)
f:X→R Var π(f)
s.t. Varπ(f)̸=0
where Var (f) = (cid:80) (f(x)−π(f))2π(x), and E is the Dirichlet form associated to the
π x∈X
pair (P,π), defined as
E(f) = ⟨(I−P)f,f⟩ ,
π
where the inner product is defined by
(cid:88)
⟨f ,f ⟩ = f (x)f (x)π(x).
1 2 π 1 2
x∈X
We have the following equivalent characterizations of E(f) and Var (f) [Levin and Peres,
π
2017, Lemma 13.6],
1 (cid:88)
E(f) = |f(x)−f(x′)|2P(x,x′)π(x), (15)
2
x,x′∈X
1 (cid:88)
Var (f) = |f(x)−f(x′)|2π(x)π(x′). (16)
π
2
x,x′∈X
Given a sequence γ = (x = x,x ,...,x ,x = x′), we write e ∈ γ with e = (x ,x )
0 1 k−1 k j−1 j
for j = 1,...,k, and we say e is an edge of γ. We say γ is a path if γ does not contain
duplicate edges. Let E¯ be the edge set for P, which is defined by
E¯ = {(x,x′) ∈ X2: x ̸= x′,P(x,x′) > 0}.
Given E ⊂ E¯, let
Γ (x,x′) = {paths from x to x′ with all edges in E},
E
26and let Γ = ∪ Γ (x,x′). Define Q: E¯ → (0,∞) by
E x̸=x′ E
Q(e) = π(x)P(x,x′), if e = (x,x′).
We now present Proposition 1, which provides a bound on the spectral gap using paths and
generalizes the multicommodity flow method of Sinclair [1992].
Proposition 1 (Theorem 3.2.9 in Gin´e et al. [1996]). Let E ⊂ E¯, w: E → (0,∞), and for
γ ∈ Γ , define its w-length by
E
(cid:88)
|γ| = w(e). (17)
w
e∈γ
Let a function ϕ: Γ → [0,∞) satisfy that
E
(cid:88)
ϕ(γ) = π(x)π(x′), for any x ̸= x′. (18)
γ∈ΓE(x,x′)
Then Gap(P) ≥ 1/A(E,w,ϕ), where
(cid:26)(cid:80) |γ| ϕ(γ)(cid:27)
A(E,w,ϕ) = max γ∈ΓE:e∈γ w . (19)
e∈E Q(e)w(e)
In Proposition 1, w is called a weight function, and ϕ is called a flow function. Proposi-
tion 1 directly follows from (15), (16) and the following lemma, which will be used later for
proving a similar result for restricted spectral gap in Section B (see Proposition 2).
Lemma 2. Let E ⊂ E¯, w: E → (0,∞) and ϕ: Γ → [0,∞). For any f: X → R, we have
E
(cid:88) (cid:88)
|f(x′)−f(x)|2Φ(x,x′) ≤ A(E,w,ϕ) Q((x,x′))|f(x′)−f(x)|2,
x,x′∈X (x,x′)∈E
where A(E,w,ϕ) is given by (19) and

(cid:80) ϕ(γ), if Γ (x,x′) ̸= ∅,
Φ(x,x′) = γ∈ΓE(x,x′) E
0, otherwise.
Proof. Given e = (z,z′), let df(e) = f(z′)−f(z) denote the increment of f along e. For any
γ ∈ Γ (x,x′), we can write
E
(cid:88) (cid:88)(cid:112) df(e)
|f(x′)−f(x)|2 = df(e) = w(e) .
(cid:112)
w(e)
e∈γ e∈γ
By the Cauchy-Schwarz inequality,
(cid:88)
(df(e))2
|f(x′)−f(x)|2 ≤ |γ| .
w
w(e)
e∈γ
Hence,
(cid:88) (cid:88)
(df(e))2
ϕ(γ)|γ| ≥ |f(x′)−f(x)|2Φ(x,x′).
w
w(e)
γ∈ΓE(x,x′) e∈γ
27We sum over x,x′ ∈ X, which yields
(cid:88) (cid:88) (cid:88)
(df(e))2
|f(x′)−f(x)|2Φ(x,x′) ≤ ϕ(γ)|γ|
w
w(e)
x,x′∈X γ∈ΓE e∈γ
(cid:88)
(df(e))2
(cid:88)
= |γ| ϕ(γ)
w
w(e)
e∈E γ:γ∈ΓE
s.t. e∈γ
 
 
 
(cid:88) 1 (cid:88) 
= |γ| ϕ(γ) Q(e)(df(e))2
w
Q(e)w(e)
 
e∈E  γ:γ∈ΓE  
s.t. e∈γ
(cid:88)
≤ A(E,w,ϕ) Q(e)(df(e))2,
e∈E
which completes the proof.
Remark 8. Observe that in Lemma 2, one can replace Q with any function that maps from
E to (0,∞). The conclusion still holds and the proof is identical.
Proof of Proposition 1. By (16),
(cid:88)
|f(x′)−f(x)|2Φ(x,x′) = 2Var (f),
π
x,x′∈X
and by (15),
(cid:88)
Q((x,x′))|f(x′)−f(x)|2 ≤ 2E(f).
(x,x′)∈E
The result then follows from (14).
A.2 Review of the Mixing Time Bound in Zhou and Chang [2023]
In this section, we review the proof techniques used in Zhou and Chang [2023] to derive
the mixing time bound under the unimodal condition. Similar arguments will be used
later in Section B.3 for proving some results of this work. Let the triple (X,N,π) sat-
isfy R(X,N,π) > M(X,N), where R and M are defined in (7) and (3) respectively, and
recall that we always assume
N(x) = {x′ ∈ X: P(x,x′) > 0}.
We begin by constructing the functions ϕ and w for utilizing Proposition 1.
A.2.1 Constructing a flow ϕ
Assume that π is unimodal on (X,N). We first present a general method for construct-
ing flows by identifying likely paths leading to x∗ = argmax π(x), and derive a simple
x∈X
upper bound on the maximum load of any edge. For this result, we only need to require
R(X,N,π) > 1.
28Lemma 3(LemmaB2ofZhouandChang[2023]). Suppose(X,N,π)satisfiesR = R(X,N,π) >
1. Let S ∈ (1,R]. Define
N (x) = (cid:8) x′ ∈ N(x) : π(x′)/π(x) ≥ S(cid:9) , (20)
S
and let
E = {(x,x′): x ∈ N (x′) or x′ ∈ N (x)} (21)
S S S
be the resulting edge set. Write Γ = Γ . There exists a flow ϕ: Γ → [0,∞) such that for
S ES S
any x ̸= x′,
(cid:88)
ϕ(γ) = π(x)π(x′),
γ∈ΓS(x,x′)
and for any x ̸= x′ and (z,z′) ∈ E with z′ ∈ N (z),
S S
(cid:88) P(z, z′)
ϕ(γ) ≤ π(x)π(x′). (22)
P(z, N (z))
S
γ:γ∈ΓS(x,x′)
s.t. (z,z′)∈γ
Proof. Define an auxiliary transition matrix P on X ×X by
S




P(P x,(x N, Sx (′) x))1 NS(x)(x′), if N S(x) ̸= ∅,

P S(x,x′) = 0, if N S(x) = ∅, (23)



 1−(cid:80) P (x,x˜), if x = x′.
x˜̸=x S
←
Given γ = (x ,x ,...,x ), let γ= (x ,x ,...,x ) be the reversed path of γ. We first
0 1 k k k−1 0
construct a normalized flow function, denoted by fS : Γ → [0,1], as follows.
S
(1) If x∗ does not occur in γ or x∗ occurs at least twice in γ, let fS(γ) = 0.
(2) If x = x∗, let fS(γ) = (cid:81)k P (x ,x ).
k i=1 S i−1 i
←
(3) If x = x∗, let fS(γ) = fS(γ).
0
(4) Define fS(γ) = fS(γ )fS(γ ) if x = x∗ for some 1 ≤ j ≤ k − 1, where γ =
1 2 j 1
(x ,...,x ,x∗) and γ = (x∗,x ,...,x ).
0 j−1 2 j+1 k
Then, the following properties hold for fS by Lemma B2 in Zhou and Chang [2023]. For
any x,x′ ∈ X with x ̸= x′, we have
(cid:88)
fS(γ) = 1,
γ∈ΓS(x,x′)
and for e = (z,z′) with z′ ∈ N (z),
S
(cid:88)
fS(γ) ≤ P (z,z′).
S
γ:γ∈ΓS(x,x′)
s.t. e=(z,z′)∈γ
The flow ϕ is then obtained by
ϕ(γ) = fS(γ)π(x)π(x′), if γ ∈ Γ (x,x′),
S
which satisfies (18) and (22).
29Remark 9. This result can be generalized by replacing N with any N˜ such that
S
(i) N˜(x) ̸= ∅ for any x ̸= x∗,
(ii) π(y) > π(x) whenever y ∈ N˜(x).
One can then define a transition matrix P˜ analogously to P , which is a Markov chain with
S
absorbing state x∗. The same argument then completes the proof.
A.2.2 Defining a weight function w
Consider E defined in Lemma 3. For e = (z,z′) ∈ E such that z′ ∈ N (z), we define
S S S
w(e) = w(← e) = π(z)−q, (24)
←
where q ∈ (0,1) is a constant and e= (z′,z). Let Γ be as defined in Lemma 3 with S > 1.
S
For any γ ∈ Γ (x,x′) with ϕ(γ) > 0, we have
S
π(x)−q +π(x′)−q
|γ| ≤ . (25)
w 1−S−q
To obtain (25), we first decompose γ to two sub-paths γ ,γ such that γ ∈ Γ(x,x∗) and
1 2 1
γ ∈ Γ(x∗,x′), which exists by our construction of ϕ. Letting γ = (x = x ,x ,...,x = x∗),
2 1 0 1 k
we obtain by the geometric series calculation that
(cid:88)k−1 (cid:88)k−1 π(x)−q
|γ | = π(x )−q ≤ π(x)−qS−q ≤ .
1 w j 1−S−q
j=0 j=0
Calculating |γ | in the same manner and using |γ| = |γ | +|γ | , we get (25).
2 w w 1 w 2 w
A.2.3 Spectral gap bound
Using ϕ and w constructed above, we can now derive a spectral gap bound.
Lemma 4. Suppose the triple (X,N,π) satisfies
R = R(X,N,π) > M(X,N) = M,
and let x∗ = argmax π(x). Let E ,ϕ be as given in Lemma 3 with S ∈ (M,R] and w be
x∈X S
given by (24). Then,
c(S/M) 1
A(E ,w,ϕ) ≤ max ,
S
2 z∈X\{x∗} P(z,N S(z))
where A is given by (19) and c(u) = 4(1−u−1/2)−3.
Proof. We first fix e = (z,z′) ∈ E with z′ ∈ N (z). The case with z ∈ N (z′) can be
S S S
analyzed in the same manner by symmetry. Observe that
1 (cid:88) 1 (cid:88) (cid:88)
ϕ(γ)|γ| = ϕ(γ)|γ| .
w w
Q(e)w(e) Q(e)w(e)
γ:γ∈ΓS x̸=x′γ:γ∈ΓS(x,x′)
s.t. e∈γ s.t. e∈γ
30For fixed x,x′ ∈ X with x ̸= x′,
1 (cid:88) π(x)−q +π(x′)−q (cid:88)
ϕ(γ)|γ| ≤ ϕ(γ)
Q(e)w(e) w π(z)1−q(1−S−q)P(z,z′)
γ:γ∈ΓS(x,x′) γ:γ∈ΓS(x,x′)
s.t. e∈γ s.t. e∈γ
π(x)1−qπ(x′)+π(x)π(x′)1−q 1
≤ ,
π(z)1−q(1−S−q) P(z,N (z))
S
wherethefirstinequalityisfrom(25)andthelastinequalityisdueto(22)withthedefinition
in (23).
Let Λ(z) = {x: π(x) < π(z), ∃γ ∈ Γ (z,x) s.t. ϕ(γ) > 0} ∪ {z} denote the set of
S
ancestors of z in the graph (X,E ) (each edge is directed towards the state with larger
S
posterior probability). Note that
(cid:88)
ϕ(γ) > 0
γ∈ΓS(x,x′):e∈γ
only if x or x′ belongs to Λ(z). Hence, summing over distinct (x,x′) and using π(x) ≤ 1 for
any x, we get
1 (cid:88) (cid:88) (cid:88) 2π(x)1−qπ(x′)1−q 1
ϕ(γ)|γ| ≤ .
Q(e)w(e) w π(z)1−q(1−S−q)P(z,N (z))
S
γ:γ∈ΓS x∈Λ(z)x′∈X
s.t. e∈γ
Using S > M, a routine geometric series calculation gives
(cid:88) (cid:88)
π(z)1−q
π(x)1−qπ(x′)1−q ≤ .
(1−MS−(1−q))2
x∈Λ(z)x′∈X
(See also Lemma 3 of Zhou and Smith [2022].) Finally, set q = log(S/M)/(2logS) so that
S−q = MS−(1−q); note that q ∈ (0,1) since S > M ≥ 1. We then obtain the asserted result
by taking maximum over e ∈ E .
S
B Path Methods for Restricted Spectral Gaps
B.1 Restricted Spectral Gap
Ifthereareisolatedlocalmodes, thespectralgapoftheMarkovchaincanbeextremelyclose
to 0. This remains true even when all local modes (otherthan the global one) have negligible
probability mass are highly unlikely to be visited by the chain if it is properly initialized. As
a result, calculating the standard spectral gap bound yields an overly conservative estimate
of the mixing time. To address this issue, we work with the restricted spectral gap, which
was considered in Atchad´e [2021].
We still use the notation introduced in Appendix A. Given a function f: X → R, let
(cid:32) (cid:33)1/m
(cid:88)
||f|| = |f(x)|mπ(x) , for m ∈ (2,∞].
Lm(π)
x∈X
Given X ⊂ X, define the X -restricted spectral gap by
0 0
(cid:80) (f(x)−f(y))2P(x,y)π(x)
Gap (P) = inf
x,y∈X0
.
X0
f:Varπ(f)>0
(cid:80) x,y∈X0(f(x)−f(y))2π(x)π(y)
31We note that if X = X, Gap (P) coincides with Gap(P). The following lemma is from
0 X0
Atchad´e [2021], which shows that we can use restricted spectral gap to bound the mixing
time given a sufficiently good initial distribution.
Lemma 5. Let ϵ ∈ (0,1/2) and π be another distribution on X. Define f = π /π. Choose
0 0 0
any m ∈ (2,∞], and let B ∈ [1,∞) be such that ||f || ≤ B. If X ⊂ X satisfies
0 Lm(π) 0
(cid:18) ϵ2 (cid:19)1+ m2 −2
π(X ) ≥ 1− ,
0 5B2
then ||π Pt−π|| ≤ ϵ for any t such that
0 TV
log(B2/2ϵ2)
t ≥ .
Gap (P)
X0
Proof. This follows from Lemma 1 and Lemma 2 of Atchad´e [2021] and the argument after
Lemma2inAtchad´e[2021]. NotethatAtchad´e[2021]usedadifferentscalinginthedefinition
of the total variation distance.
B.2 Multicommodity Flow Bounds
Given a subset X ⊆ X, recall that we write
0
N| (x) = {x′ ∈ X : P(x,x′) > 0},
X0 0
for each x ∈ X . Similarly, let
0
E¯ = (cid:8) (x,x′) ∈ X2: x ̸= x′ and P(x,x′) > 0(cid:9)
0 0
denote the edge set of P restricted to X . Given E ⊂ E¯ , let Γ (x,x′) = Γ (x,x′) and
0 0 0 0 E0
Γ = Γ denote the corresponding path sets. We provide the following proposition that
0 E0
extends the argument used in Proposition 1 to the restricted spectral gap.
Proposition 2. Let E ⊂ E¯ , w: E → (0,∞), and for γ ∈ Γ , define |γ| as in (17). Let
0 0 0 0 w
ϕ: Γ → [0,∞) satisfy that
0
(cid:88)
ϕ(γ) = π(x)π(x′), ∀x,x′ ∈ X , x ̸= x′. (26)
0
γ∈Γ0(x,x′)
Then Gap (P) ≥ 1/A(E ,w,ϕ), where A is defined by (19).
X0 0
Proof. By Lemma 2, for any f: X → R,
(cid:88) (cid:88)
|f(x′)−f(x)|2Φ(x,x′) ≤ A(E ,w,ϕ) Q((x,x′))|f(x′)−f(x)|2,
0
x,x′∈X (x,x′)∈E0
where Φ(x,x′) = (cid:80) ϕ(γ). If x ∈/ X or x′ ∈/ X , Γ (x,x′) = ∅ and thus Φ(x,x′) = 0.
γ∈ΓE(x,x′) 0 0 0
Hence,
(cid:88) (cid:88)
|f(x)−f(x′)|2Φ(x,x′) = |f(x)−f(x′)|2Φ(x,x′)
x,x′∈X x,x′∈X0
(cid:88)
= |f(x)−f(x′)|2π(x)π(x′).
x,x′∈X0
32Further, since E ⊂ X2,
0 0
(cid:88) (cid:88)
Q((x,x′))|f(x)−f(x′)|2 ≤ |f(x)−f(x′)|2P(x,x′)π(x).
(x,x′)∈E0 x,x′∈X0
The result then follows from the definition of the restricted spectral gap Gap (P).
X0
B.3 ApplicationoftheMulticommodityFlowMethodundertheRestricted
Unimodal Condition
In this section, we assume R| > M and show that the multicommodity flow method
X0
reviewed in Section A.2 is also applicable to bounding the restricted spectral gap. For
S ∈ (M,R| ], we define
X0
N|S (x) = (cid:8) x′ ∈ N| (x) : π(x′)/π(x) ≥ S(cid:9) ,
X0 X0
and
E0 = {(x,x′) : x ∈ N|S (x′) or x′ ∈ N|S (x)}. (27)
S X0 X0
Let Γ0 = Γ denote the resulting path set.
S E0
S
Lemma 6. Suppose the triple (X ,N| ,π) satisfies
0 X0
R| = R(X ,N| ,π) > M(X,N) = M,
X0 0 X0
and let x∗ = argmax π(x). Let E0 be given by (27) with S ∈ (M,R| ]. Then, there
0 x∈X0 S X0
exist w: E0 → (0,∞), ϕ: Γ0 → [0,∞) such that ϕ satisfies (26) and
S S
c(S/M) 1
A(E0,w,ϕ) ≤ max , (28)
S 2 z∈X0\{x∗ 0} P(z,N|S X0(z))
where A is given by (19) and c(u) = 4(1−u−1/2)−3.
Proof. Let P| denote the restriction of P to X ; that is, P| (x,x′) = P(x,x′) if x,x′ ∈ X
X0 0 X0 0
and x ̸= x′. Apply Lemma 3 to P| on (X ,N| ), which is allowed since R| > 1. We
X0 0 X0 X0
then obtain a flow ϕ: Γ0 → [0,∞) such that (26) is satisfied and
S
(cid:88)
ϕ(γ) ≤
P| X0(z,z′)
π(x)π(x′)
P| (z, N|S (z))
γ:γ∈Γ0(x,x′) X0 X0
S
s.t. (z,z′)∈γ
P(z,z′)
= π(x)π(x′)
P(z, N|S (z))
X0
for any x,x′ ∈ X with x ̸= x′ and (z,z′) ∈ E0 with z′ ∈ N|S (z).
0 S X0
The asserted bound on A(E0,w,ϕ) can be derived by repeating the argument used for
S
proving Lemma 4 on the restricted space (X ,N| ). Note that the only difference is that
0 X0
π is no longer a probability measure on (X ,N| ). But this does not affect the proof since
0 X0
the proof of Lemma 4 only relies on max π(x) ≤ 1.
x
33C Review of Single-element Drift Condition
Thedrift-and-minorizationmethodisoneofthemostfrequentlyusedtechniquesforderiving
the convergence rates of Markov chains on general state spaces. It directly bounds the total
variation distance from the stationary distribution without using the spectral gap. For our
purpose, we only need to use the single-element drift condition considered in Jerison [2016],
which is particularly useful on discrete spaces.
Definition 1 (single-element drift condition). The transition matrix P satisfies a single-
element drift condition if there exist an element x∗ ∈ X, a function V : X → [1,∞),
and constants 0 < α < 1 such that (PV)(x) ≤ αV(x) for all x ∈ X \{x∗}.
Note that in Jerison [2016], the single-element drift condition is proposed for general-
state-space Markov chains, and one needs to further require that (PV)(x∗) < ∞ (this holds
trivially in our case since X is finite). Given this drift condition, we can bound the mixing
time using the following result of Jerison [2016]. Recall that we assume P is reversible and
thus its eigenvalues are all real.
Lemma 7 (Theorem 4.5 of Jerison [2016]). Suppose P has non-negative eigenvalues and
satisfies the single-element drift condition given in Definition 1. Then, for all t ≥ 0,x ∈ X,
(cid:13) (cid:13)Pt(x,·)−π(cid:13) (cid:13) ≤ 2V(x)αt+1.
TV
Therefore, we have
(cid:18) (cid:19)
1 2V(x)
τ (P,ϵ) ≤ log .
x
1−α ϵ
Proof. This directly follows from Theorem 4.5 of Jerison [2016] and the inequality logα <
α−1 for α ∈ (0,1)
D Proofs
Proof of Lemma 1. Since Z (x) ≥ L, we have
h
K
(cid:0) x,x′(cid:1)
=
h(π(x′)/π(x))
≤
h(π(x′)/π(x))
,
h
Z (x) L
h
K
(cid:0) x′,x(cid:1)
=
h(π(x)/π(x′))
≥
ℓ
,
h Z (x′) ML
h
where the second equality follows from h ∈ [ℓ,L] and |N(x′)| ≤ M. Combining the two
inequalities, we get
π(x′)K (x′,x) π(x′)/π(x) ℓ
h
≥ .
π(x)K (x,x′) h(π(x′)/π(x))M
h
Since π(x′)/π(x) ≥ ℓ and h(u) ≤ u for any u ≥ ℓ, we have
π(x′)K (x′,x) ℓ
h
≥ ≥ 1,
π(x)K (x,x′) M
h
where the last inequality follows by assumption.
34Proof of Theorem 2. Applying Lemma 4 with S = L/M, we get
c(ρ)
(cid:26) (cid:27)−1
A(E ,w,ϕ) ≤ min Plazy(x,N (x)) ,
S 2 x∈X\{x∗} h S
where E is defined by (21). We prove in Lemma 8 below that for x ̸= x∗, P (x,N (x)) ≥
S h S
1/2, and thus Plazy(x,N (x)) ≥ 1/4. We conclude the proof by applying Proposition 1 and
h S
inequality (6).
Lemma 8. Let S = L/M. Under the setting of Theorem 2, we have P (x,N (x)) ≥ 1/2 for
h S
each x ̸= x∗, where N (x) is defined in (20).
S
Proof. Fix any x ̸= x∗. By the definition of R, there exists some x′ ∈ N(x) such that
π(x′)/π(x) ≥ R ≥ L. Hence, Z (x) ≥ L. Using S = L/M > ℓ = M and Lemma 1, we see
h
that the acceptance probability for every x′ ∈ N (x) equals one. Therefore, it only remains
S
to prove that K (x,N (x)) ≥ 1/2. On one hand, R ≥ L and x ̸= x∗ implies that
h S
(cid:88)
(cid:18) π(x′)(cid:19)
ZS(x) := h ≥ L.
h π(x)
x′∈NS(x)
On the other hand, since |N(x)| ≤ M, we have
(cid:88)
(cid:18) π(x′)(cid:19)
Z (x)−ZS(x) = h ≤ Mℓ = M2.
h h π(x)
x′∈N(x)\NS(x)
Since L > M2, K (x,N (x)) = ZS(x)/Z (x) ≥ 1/2, which completes the proof.
h S h h
Proof of Theorem 3. For x ̸= x∗,
(cid:88)
(P V)(x) = P (x,x)V(x)+ P (x,x′)V(x′).
h h h
x′∈N(x)
Using P (x,x) = 1−(cid:80) P (x,x′), we can rewrite the above equation as
h z∈N(x) h
(P hV)(x)
= 1+
(cid:88)
P (x,x′)D(x,x′),
h
V(x)
x′∈N(x)
where we define
 
π(x′)
V(x′) log
π(x)
D(x,x) = −1 = exp −1.
V(x) logπ
min
Since D(x,x′) ≤ 0 whenever π(x′) ≥ π(x), we have
(P V)(x)
h
≤ 1+A +A , (29)
1 2
V(x)
(cid:88) (cid:88)
where A := P (x,x′)D(x,x′), A := P (x,x′)D(x,x′),
1 h 2 h
x′∈NS(x) x′:x′∈N(x)
s.t. π(x′)≤π(x)
with S = L/M and N is given by (20). We now consider the two cases separately.
S
35Case 1: x′ ∈ N (x). Using e−a −1 ≤ −a/2 for a ∈ [0,1] and the definition of N (x), we
S S
obtain that
log(π(x′)/π(x)) log(L/M)
D(x,x′) ≤ ≤ .
2logπ 2logπ
min min
By Lemma 8, P (x,N (x)) ≥ 1/2. Hence,
h S
log(L/M)
A ≤ . (30)
1
4logπ
min
Case 2: π(x′) ≤ π(x). For D(x,x′), we simply use the worst-case bound D(x,x′) ≤ e−1.
Since π(x′) ≤ π(x) and ℓ = M, we have h(π(x′)/π(x)) = M. It follows that
M M
P (x,x′) ≤ K (x,x′) = ≤ ,
h h
Z (x) L
h
where the last inequality follows from the assumption L ≤ R. Since |N(x)| ≤ M, we get
M2
A ≤ (e−1). (31)
2
L
Combining (29), (30) and (31), we get
log(L/M) M2
1−α ≥ − − (e−1).
4logπ L
min
By Lemma 7,
(cid:18) (cid:19)
1 2e
τ(P ,ϵ) ≤ log ,
h
1−α ϵ
which yields the asserted result.
Proof of Theorem 4. Let δ be the Dirac measure which assigns unit probability mass to
x0
some x ∈ X, and define f = δ /π. Hence, we can write f (x) = 1 (x)/π(x).
0 0 x0 0 {x=x0}
Applying Lemma 5 with m = ∞, we obtain that
(cid:26) (cid:27)
1 1
τ (Plazy,ϵ) ≤ log ,
x0 0 Gap (Plazy) 2ϵ2η2
X0 0
if π(X ) ≥ 1−ϵ2η2/5. Now, we show that the restricted spectral gap is bounded as
0
1
Gap (Plazy) ≥ .
X0 0 Mc(ρ)
We use Lemma 4 with the restricted edge set E0 defined in (27) and Proposition 2. By
S
setting S = R| in (28), we obtain
X0
c(ρ)
(cid:26) (cid:27)−1
A(E0,w,ϕ) ≤ min Plazy(x,N|S (x)) .
S 2 x∈X0\{x∗ 0} 0 X0
For any x ∈ X \{x∗}, define
0 0
xˆ = arg max π(x′).
x′∈N|S (x)
X0
The definition of R| implies that π(xˆ)/π(x) ≥ R| ≥ M. Hence,
X0 X0
Plazy(x,N|S (x)) ≥ Plazy(x,xˆ) ≥ 1/(2M).
0 X0 0
Using Proposition 2 yields the conclusion.
36Proof of Theorem 5. As in the proof of Theorem 4, we use Lemma 5 to get
(cid:26) (cid:27)
1 1
τ (Plazy,ϵ) ≤ log ,
x0 h Gap (Plazy) 2ϵ2η2
X0 h
ifπ(X ) ≥ 1−ϵ2η2/5. WeuseLemma4withS = L/M, andtheboundgivenin(28)becomes
0
c(ρ˜)
(cid:26) (cid:27)−1
A(E0,w,ϕ) ≤ · min Plazy(x,N|S (x)) .
S 2 x∈X0\{x∗ 0} h X0
By the condition given in (13), for any x ∈ X and x′ ∈ X \ X , we have x′ ∈/ N (x).
0 0 S
Hence, N (x) = N|S (x), and we can apply Lemma 8 to get Plazy(x,N (x)) ≥ 1/4 for every
S X0 h S
x ∈ X \{x∗}. The conclusion then follows from Proposition 2.
0 0
References
VS Anil Kumar and Hariharan Ramesh. Coupling vs. conductance for the Jerrum–Sinclair
chain. Random Structures & Algorithms, 18(1):1–17, 2001.
Yves F Atchad´e. Approximate spectral gaps for Markov chain mixing times in high dimen-
sions. SIAM Journal on Mathematics of Data Science, 3(3):854–872, 2021.
Alexandre Belloni and Victor Chernozhukov. On the computational complexity of MCMC-
based estimators in large samples. The Annals of Statistics, 37(4):2011–2055, 2009.
Riddhiman Bhattacharya and Galin L Jones. Explicit constraints on the geometric rate of
convergence of random walk Metropolis-Hastings. arXiv preprint arXiv:2307.11644, 2023.
Ismael Castillo and Veronika Roˇckov´a. Uncertainty quantification for Bayesian CART. The
Annals of Statistics, 49(6):3482–3509, 2021.
Hyunwoong Chang, Changwoo Lee, Zhao Tang Luo, Huiyan Sang, and Quan Zhou. Rapidly
mixing multiple-try Metropolis algorithms for model selection problems. Advances in
Neural Information Processing Systems, 35:25842–25855, 2022.
Hyunwoong Chang, James Cai, and Quan Zhou. Order-based structure learning without
score equivalence. Biometrika, 2023. doi: https://doi.org/10.1093/biomet/asad052.
Xiang Cheng, Niladri S Chatterji, Peter L Bartlett, and Michael I Jordan. Underdamped
Langevin MCMC: a non-asymptotic analysis. In Conference on learning theory, pages
300–323. PMLR, 2018.
Sinho Chewi, Chen Lu, Kwangjun Ahn, Xiang Cheng, Thibaut Le Gouic, and Philippe
Rigollet. Optimal dimension dependence of the Metropolis-adjusted Langevin algorithm.
In Conference on Learning Theory, pages 1260–1300. PMLR, 2021.
Mary Kathryn Cowles and Bradley P Carlin. Markov chain Monte Carlo convergence diag-
nostics: a comparative review. Journal of the American statistical Association, 91(434):
883–904, 1996.
37Arnak S Dalalyan. Theoretical guarantees for approximate sampling from smooth and log-
concavedensities. JournaloftheRoyalStatisticalSocietySeriesB:StatisticalMethodology,
79(3):651–676, 2017.
Persi Diaconis and Mehrdad Shahshahani. Generating a random permutation with random
transpositions. Zeitschrift fu¨r Wahrscheinlichkeitstheorie und verwandte Gebiete, 57(2):
159–179, 1981.
David L Donoho. CART and best-ortho-basis: a connection. The Annals of Statistics, 25
(5):1870–1911, 1997.
Simon Duane, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth. Hybrid Monte
Carlo. Physics letters B, 195(2):216–222, 1987.
Alain Durmus and Eric Moulines. High-dimensional Bayesian inference via the unadjusted
Langevin algorithm. Bernoulli, 25:2854–2882, 2019.
Raaz Dwivedi, Yuansi Chen, Martin J. Wainwright, and Bin Yu. Log-concave sampling:
Metropolis-Hastings algorithms are fast. Journal of Machine Learning Research, 20(183):
1–42, 2019.
G Fort, E Moulines, Gareth O Roberts, and JS Rosenthal. On the geometric ergodicity of
hybrid samplers. Journal of Applied Probability, 40(1):123–146, 2003.
Philippe Gagnon, Florian Maire, and Giacomo Zanella. Improving multiple-try Metropolis
with local balancing. Journal of Machine Learning Research, 24(248):1–59, 2023.
Andrew Gelman and Donald B Rubin. Inference from iterative simulation using multiple
sequences. Statistical Science, 7(4):457–472, 1992.
Edward I George and Robert E McCulloch. Approaches for Bayesian variable selection.
Statistica Sinica, pages 339–373, 1997.
Evarist Gin´e, Geoffrey R Grimmett, and Laurent Saloff-Coste. Lectures on probability theory
and statistics: E´cole d’´et´e de Probabilit´es de Saint-Flour XXVI-1996. Springer, 1996.
Mark Girolami and Ben Calderhead. Riemann manifold Langevin and Hamiltonian Monte
Carlo methods. Journal of the Royal Statistical Society Series B: Statistical Methodology,
73(2):123–214, 2011.
Lei Gong and James M Flegal. A practical sequential stopping rule for high-dimensional
Markov chain Monte Carlo. Journal of Computational and Graphical Statistics, 25(3):
684–700, 2016.
Will Grathwohl, Kevin Swersky, Milad Hashemi, David Duvenaud, and Chris Maddison.
Oops I took a gradient: scalable sampling for discrete distributions. In International
Conference on Machine Learning, pages 3831–3841. PMLR, 2021.
Jim E Griffin, KG L(cid:32) atuszyn´ski, and Mark FJ Steel. In search of lost mixing time: adaptive
Markov chain Monte Carlo schemes for Bayesian variable selection with very large p.
Biometrika, 108(1):53–69, 2021.
38Yongtao Guan and Stephen M Krone. Small-world MCMC and convergence to multi-modal
distributions: from slow mixing to fast mixing. The Annals of Applied Probability, 17(1):
284–304, 2007.
Yongtao Guan and Matthew Stephens. Bayesian variable selection regression for genome-
wide association studies and other large-scale problems. The Annals of Applied Statistics,
5(3):1780, 2011.
Venkatesan Guruswami. Rapidly mixing Markov chains: A comparison of techniques. arXiv
preprint arXiv:1603.01512, 2000.
W Keith Hastings. Monte Carlo sampling methods using Markov chains and their applica-
tions. Biometrika, 57(1):97–109, 04 1970.
SørenFiigJarnerandErnstHansen. GeometricergodicityofMetropolisalgorithms. Stochas-
tic processes and their applications, 85(2):341–361, 2000.
Daniel Jerison. The drift and minorization method for reversible Markov chains. Stanford
University, 2016.
Mark Jerrum and Alistair Sinclair. The Markov chain Monte Carlo method: an approach to
approximate counting and integration. Approximation algorithms for NP-hard problems,
pages 482–520, 1996.
Mark Jerrum, Jung-Bae Son, Prasad Tetali, and Eric Vigoda. Elementary bounds on
Poincar´e and log-Sobolev constants for decomposable Markov chains. The Annals of Ap-
plied Probability, pages 1741–1765, 2004.
JamesJohndrow,PauloOrenstein,andAnirbanBhattacharya. ScalableapproximateMCMC
algorithms for the horseshoe prior. Journal of Machine Learning Research, 21(73):1–61,
2020.
Jungeum Kim and Veronika Rockova. On mixing rates for Bayesian CART. arXiv preprint
arXiv:2306.00126, 2023.
DemetrisLamnisos,JimEGriffin,andMarkFJSteel. Transdimensionalsamplingalgorithms
for Bayesian variable selection in classification problems with many more variables than
observations. Journal of Computational and Graphical Statistics, 18(3):592–612, 2009.
Sirio Legramanti, Tommaso Rigon, Daniele Durante, and David B Dunson. Extended
stochastic block models with application to criminal networks. The Annals of Applied
Statistics, 16(4):2369, 2022.
David A Levin and Yuval Peres. Markov chains and mixing times, volume 107. American
Mathematical Society, 2017.
Guanxun Li, Aaron Smith, and Quan Zhou. Importance is important: a guide to informed
importance tempering methods. arXiv preprint arXiv:2304.06251, 2023.
39Xitong Liang, Samuel Livingstone, and Jim Griffin. Adaptive random neighbourhood in-
formedMarkovchainMonteCarloforhigh-dimensionalBayesianvariableselection. Statis-
tics and Computing, 32(5):84, 2022.
Jun S Liu, Faming Liang, and Wing Hung Wong. The multiple-try method and local op-
timization in Metropolis sampling. Journal of the American Statistical Association, 95
(449):121–134, 2000.
DavidMadigan,JeremyYork,andDenisAllard. Bayesiangraphicalmodelsfordiscretedata.
International Statistical Review/Revue Internationale de Statistique, pages 215–232, 1995.
Neal Madras and Dana Randall. Markov chain decomposition for convergence rate analysis.
The Annals of Applied Probability, pages 581–606, 2002.
Antonietta Mira. Ordering and improving the performance of Monte Carlo Markov chains.
Statistical Science, pages 340–350, 2001.
Naveen Naidu Narisetty and Xuming He. Bayesian variable selection with shrinking and
diffusing priors. The Annals of Statistics, 42(2):789–817, 2014.
Yuval Peres and Perla Sousi. Mixing times are hitting times of large sets. Journal of
Theoretical Probability, 28(2):488–519, 2015.
DavidPollardandDanaYang. RapidmixingofaMarkovchainforanexponentiallyweighted
aggregation estimator. arXiv preprint arXiv:1909.11773, 2019.
Christian P Robert, George Casella, and George Casella. Monte Carlo statistical methods,
volume 2. Springer, 1999.
Gareth O Roberts and Osnat Stramer. Langevin diffusions and Metropolis-Hastings algo-
rithms. Methodology and computing in applied probability, 4:337–357, 2002.
GarethORobertsandRichardLTweedie. Geometricconvergenceandcentrallimittheorems
formultidimensionalHastingsandMetropolisalgorithms. Biometrika, 83(1):95–110, 1996.
Robert W Robinson. Counting unlabeled acyclic digraphs. In Combinatorial Mathematics
V: Proceedings of the Fifth Australian Conference, Held at the Royal Melbourne Institute
of Technology, August 24–26, 1976, pages 28–43. Springer, 1977.
Jeffrey S Rosenthal. Minorization conditions and convergence rates for Markov chain Monte
Carlo. Journal of the American Statistical Association, 90(430):558–566, 1995.
Jeffrey S Rosenthal. Optimal proposal distributions and adaptive MCMC. In Handbook of
Bayesian Variable Selection, pages 93–111. Chapman & Hall/CRC Boca Raton, FL, 2011.
Vivekananda Roy and James P Hobert. Convergence rates and asymptotic standard errors
for Markov chain Monte Carlo algorithms for Bayesian probit regression. Journal of the
Royal Statistical Society Series B: Statistical Methodology, 69(4):607–623, 2007.
Alistair Sinclair. Improved bounds for mixing rates of Markov chains and multicommodity
flow. Combinatorics, Probability and Computing, 1(4):351–370, 1992.
40M.G. Tadesse and M. Vannucci. Handbook of Bayesian variable selection. CRC Press, 2021.
Rong Tang and Yun Yang. On the computational complexity of Metropolis-adjusted
Langevin algorithms for Bayesian posterior sampling. arXiv preprint arXiv:2206.06491,
2022.
Michalis K Titsias and Christopher Yau. The Hamming ball sampler. Journal of the Amer-
ican Statistical Association, 112(520):1598–1611, 2017.
Dawn B Woodard, Scott C Schmidler, and Mark Huber. Conditions for rapid mixing of
parallel and simulated tempering on multimodal distributions. The Annals of Applied
Probability, 19(2):617–640, 2009.
Yun Yang, Martin J Wainwright, and Michael I Jordan. On the computational complexity of
high-dimensional Bayesian variable selection. The Annals of Statistics, 44(6):2497–2532,
2016.
Giacomo Zanella. Informed proposals for local MCMC in discrete spaces. Journal of the
American Statistical Association, 115(530):852–865, 2020.
Giacomo Zanella and Gareth Roberts. Scalable importance tempering and Bayesian variable
selection. Journal of the Royal Statistical Society Series B: Statistical Methodology, 81(3):
489–517, 2019.
RuqiZhang,XingchaoLiu,andQiangLiu. ALangevin-likesamplerfordiscretedistributions.
In International Conference on Machine Learning, pages 26375–26396. PMLR, 2022.
Quan Zhou and Hyunwoong Chang. Complexity analysis of Bayesian learning of high-
dimensional DAG models and their equivalence classes. The Annals of Statistics, 51(3):
1058–1085, 2023.
Quan Zhou and Yongtao Guan. Fast model-fitting of Bayesian variable selection regression
using the iterative complex factorization algorithm. Bayesian analysis, 14(2):573, 2019.
Quan Zhou and Aaron Smith. Rapid convergence of informed importance tempering. In In-
ternationalConferenceonArtificialIntelligenceandStatistics,pages10939–10965.PMLR,
2022.
QuanZhou,JunYang,DootikaVats,GarethORoberts,andJeffreySRosenthal. Dimension-
free mixing for high-dimensional Bayesian variable selection. Journal of the Royal Statis-
tical Society Series B: Statistical Methodology, 84(5):1751–1784, 2022.
Shuheng Zhou. Thresholded Lasso for high dimensional variable selection and statistical
estimation. arXiv preprint arXiv:1002.1583, 2010.
Bumeng Zhuo and Chao Gao. Mixing time of Metropolis-Hastings for Bayesian community
detection. Journal of Machine Learning Research, 22:10–1, 2021.
41