DiffOp-net: A Differential Operator-based Fully
Convolutional Network for Unsupervised
Deformable Image Registration
Jiong Wu
J. Crayton Pruitt Family Department of Biomedical Engineering, University of
Florida, Gainesville, FL, USA
Abstract. Existing unsupervised deformable image registration meth-
ods usually rely on metrics applied to the gradients of predicted dis-
placement or velocity fields as a regularization term to ensure transfor-
mationsmoothness,whichpotentiallylimitsregistrationaccuracy.Inthis
study,weproposeanovelapproachtoenhanceunsuperviseddeformable
image registration by introducing a new differential operator into the
registration framework. This operator, acting on the velocity field and
mapping it to a dual space, ensures the smoothness of the velocity field
duringoptimization,facilitatingaccuratedeformableregistration.Inad-
dition, to tackle the challenge of capturing large deformations inside
image pairs, we introduce a Cross-Coordinate Attention module (CCA)
and embed it into a proposed Fully Convolutional Networks (FCNs)-
basedmulti-resolutionregistrationarchitecture.Evaluationexperiments
areconductedontwomagneticresonanceimaging(MRI)datasets.Com-
paredtovariousstate-of-the-artregistrationapproaches,includingatra-
ditionalalgorithmandthreerepresentativeunsupervisedlearning-based
methods,ourmethodachievessuperioraccuracies,maintainingdesirable
diffeomorphic properties, and exhibiting promising registration speed.
Keywords: Deformable image registration · Unsupervised learning ·
Differential operator · Cross-coordinate attention · Fully convolutional
network
1 Introduction
Deformable image registration is a crucial step in numerous medical image ap-
plications, addressing the inherent variations in anatomical structures due to
differences in subjects, scan times, or scanners. This process is integral for tasks
such as disease diagnosis, treatment planning, and monitoring, aiming to es-
tablish a deformation field that aligns voxels in moving images with those in
the fixed image [29,18,24]. Over the past decades, a diverse array of deformable
image registration methods has been developed [3,1,26]. Initially, methodologies
often relied on physical models, solving the registration problem by minimiz-
ing energy functions. These approaches, despite their effectiveness, were limited
4202
rpA
5
]VC.sc[
1v44240.4042:viXra2 Jiong Wu
by their computational complexity and the vast degrees of freedom within the
solution space, resulting in significant processing times [28,31].
Withtheadvancementsindeeplearning,particularlytheintegrationofFully
Convolutional Networks (FCNs) into computer vision tasks, FCNs have been
adapted for deformable image registration. This adaptation has led to signifi-
cant reductions in registration time [30,7,10]. In the context of deformable reg-
istration, two primary approaches have emerged: supervised and unsupervised
learning-basedmethods[30,8,12,20,25].Supervisedmethodsutilizegroundtruth
displacement fields or segmentation maps to guide parameter learning, whereas
unsupervised methods optimize FCNs directly using predefined loss functions,
eliminating the need for ground truth data. Given the challenges in acquiring
ground truth displacement fields and segmentation maps, current research pre-
dominantly focuses on unsupervised deformable registration methods.
In unsupervised deformable registration frameworks, the selection of loss
function plays a critical role in determining performance. Typically, the loss
functioncomprisestermsforassessingimagesimilarityandensuringsmoothness
in the predicted displacement field [2,14,4]. Despite achieving promising results,
existing methods struggle with preserving the topology of warped moving im-
ages, which is crucial for downstream tasks. To tackle this issue, several studies
haveincorporatedstationaryvelocityfield-basedsystems(SVF)intotheirregis-
tration architectures, enhancing the smoothness of the displacement field [7,13].
Furthermore, some approaches have employed Jacobian determinant regulariza-
tion on the displacement field to improve topology preservation [19,17]. Despite
theintegrationofpowerfulself-attentionneuralnetworkslikeTransformers[5,6],
registration accuracy remains constrained.
Inspiredbytraditionaldiffeomorphicimageregistrationmethods,specifically
thelargedeformationdiffeomorphicmetricmapping(LDDMM)[3,28],weintro-
duce a novel framework named DiffOp-net. This framework aims to address the
existing gaps in registration accuracy while maintaining desirable diffeomorphic
properties. Our contributions are as follows:
We introduce a differential operator into the unsupervised deformable reg-
−
istration framework, ensuring precision registration while preserving diffeo-
morphic properties.
Our model enables the handling of large deformations in image pairs by
−
employing a multi-resolution framework based on the smoothness of the
velocity field.
A cross-coordinate attention module (CCA) is proposed to further capture
−
large deformation and thus enhance registration performance.
2 Methods
2.1 Deformable Image Registration
Given an image pair, a moving image M and a fixed image F, defined on the
background space Ω R3 with the same size of n n n . The goal of
x y z
∈ × ×DiffOp-net for deformable image registration 3
the deformable image registration is to determine a deformation field ϕ : Ω
→
Ω, such that ϕ(M) is well aligned to F. In our registration framework, the
deformationfieldϕisdefinedthroughthefollowingordinarydifferentialequation
(ODE)
dϕ
t
=v(ϕ ), (1)
t
dt
where ϕ = id denotes the identity mapping such that id(x) = x, x Ω, v
0
∈
denotes stationary velocity field and can be integrated over t = [0,1] to obtain
the final transformation ϕ .
1
2.2 Differential Operator Embedding and Backpropagation
In an unsupervised learning-based deformable image registration framework,
neural networks are trained by using predefined loss functions. Let θ be the
parameters of neural network, loss function has the following form
θ
J
(ϕ;M,F)= (ϕ(M),F)+λ (ϕ), (2)
θ
J S R
where isamatchingtermusedtoevaluatethesimilaritybetweentheϕ(M)and
S
theF, isaregularizertodrivetheoptimizationtowardsasolutionthatsatis-
R
fiedsomespecificpropertiesandλisahyperparametertobalancethematching
term and regularizer . A widely used regularizer is the diffusion regularizer
S R
= ϕ 2, where denotes the nabla operator. To further improve the regis-
R ∥∇ ∥ ∇
tration performance, other studies construct a registration framework based on
SVF, the regularizer of directly acts on the velocity field with the form of
R
= v 2. The optimization towards generating a sufficient smooth velocity
R ∥∇ ∥
field can be integrated to obtain a displacement field with diffeomorphic prop-
erties. Despite the larger λ results in a much smoother displacement field, the
registration accuracy will be largely reduced.
Totacklethisproblem,inspiredbythetraditionalLDDMMalgorithm[3,28],
we introduce a differential operator into the proposed registration framework
L
which with the following form
= γ 2+Id, (3)
L − ∇
where 2 is the Laplacian operator, Id is the identity operator, and the hyper-
∇
parameter α > 0 determines the smoothness of v, the larger the value of γ the
smoother of the velocity field. After embedding into the loss function , the
θ
L J
form of can be derived as
θ
J
(cid:90) 1
2
(ϕ;M,F)= (ϕ(M),F)+λ v dt. (4)
Jθ S ∥L ∥L2
0
We can note from LDDMM [3] that is a positive-definite symmetric differ-
L
ential operator acting on the velocity field v V (V denotes a tangent space
∈
of diffeomorphisms ϕ) and mapping v into a dual space V∗ making Eq. (4) is
calculated in the dual space V∗.4 Jiong Wu
Upsample Copy
branch branch
A A A
Moving image " (& &!" ##"(&!),"$$)(… 2 14 /8 219 /6 419 /6 819 /16 619 /6 89 16 /89 16 /419 /6 2 483 !" &! trS anp sa ft oia rml X p oA ov lg Y p oA ov lg Z p A oov lg X p A oov lg Y p oA ov lg Z p A oov lg
A A A
(& &! #"$"(& )!,"$%)(… 2489696969696 96 96 483 !"#!
1/21/41/81/161/81/8 1/41/2 1/2 &!"# ! Conv3D Conv3D Conv3D
Fixed image # A A !(") Sigmoid Sigmoid Sigmoid
(",$) 2489696969696 96 483 !!
1/21/41/81/161/2N+21/2N+11/2N 1/2N &#
J<latexit sha1_base64="GtPieRWJMd76lY6tRT1o6LL7I4I=">AAACBXicbVDLSsNAFJ3UV62vqEtdBItQQUoiRQU3RUFEECrYBzQhTKbTZujkwcyNUEI3bvwVNy4Uces/uPNvnLRZaPXAhcM593LvPV7MmQTT/NIKc/MLi0vF5dLK6tr6hr651ZJRIghtkohHouNhSTkLaRMYcNqJBcWBx2nbG15kfvueCsmi8A5GMXUCPAhZnxEMSnL1XTvA4BPM0+uxa4NPAVfs2GdnN4eXB65eNqvmBMZfYuWkjHI0XP3T7kUkCWgIhGMpu5YZg5NiAYxwOi7ZiaQxJkM8oF1FQxxQ6aSTL8bGvlJ6Rj8SqkIwJurPiRQHUo4CT3VmN8tZLxP/87oJ9E+dlIVxAjQk00X9hBsQGVkkRo8JSoCPFMFEMHWrQXwsMAEVXEmFYM2+/Je0jqrWcbV2WyvXz/M4imgH7aEKstAJqqMr1EBNRNADekIv6FV71J61N+192lrQ8plt9AvaxzebhZf9</latexit> ✓( ;M,F) output
(a) (b)
Fig.1.(a)Architectureoftheproposeddifferentialoperator-basedmulti-resolutionde-
formableregistrationframework(DiffOp-net);(b)Architectureofthecross-coordinate
attention module (CCA).
Due to the velocity field v defined and predicted in the original space V,
hencethegradientofthelossfunction shouldbecalculatedandtransferred
θ
∇J
from V∗ to V to realize its backpropagation in the original space. It can be
implementedbyusingthedualoperator =( † )−1,where † isadjointof .
K L L L L
Therefore the gradient of the loss function is calculated as
(ϕ;M,F)= (∂ (ϕ(M),F) ϕ(M))+λv, (5)
θ
∇J −K S ·∇
where ϕ(M) denotes the gradient of ϕ(M) and ∂ (ϕ(M),F) denotes the
∇ S
Gateauxderivativeof (ϕ(M),F).Inthispaper,wesetthe tobethenegative
S S
of normalized cross-correlation (NCC).
2.3 Registration Framework
TheleftpanelofFigure1illustratesthearchitectureoftheproposeddifferential
operator-basedmulti-resolutiondeformableregistrationframework(DiffOp-net).
It consists of N different levels generate N velocity fields with the resolutions
gradually increased by times of 2. After integration steps, N different displace-
ment fields ϕ ,ϕ ,...,ϕ are obtained by integrating the corresponding ve-
1 2 N
{ }
locity fields over t [0,1]. Then the final displacement field ϕ is calculated by
∈
combining ϕ (i = 1,2,...,N) together. After applying ϕ on the moving im-
i
age M, we will obtain the warped transformed moving image ϕ(M). Since the
hyperparameter γ controls the smoothness of the predicted velocity fields and
the registration process in lower resolution will capture more global information
for large deformation, therefore we proposed a novel registration strategy via
embedding the different values of γ in N levels to construct a coarse-to-fine reg-
istrationpipelinetoenhancetheframeworkcaptureslargedeformationinimage
pairs.
We adopt N FCNs with each one similar to the 3D UNet architecture to
predict the velocity fields. As shown in the left panel of Figure 1, each FCN
…DiffOp-net for deformable image registration 5
consists of an encoder and a decoder. To simplify the architecture, we set N to
3 in this study. The encoder architecture at different levels is the same, i.e. the
inputted image pairs are firstly convolved by C convolutional filters. Then the
number of filters is fixed to 2C in the following 3 convolutional layers (DiffOp-
net with C = 48 as the default setting). We set the kernel size to 3 3 3
× ×
for each convolutional layer to limit the parameters and set the value of stride
in each dimension to 2 to downsample the size of the feature maps. In terms
of the decoder, deconvolution operations are adopted to upsample the feature
maps to reach the desired resolution for the velocity fields in the specific levels.
Skip connections are added in each FCN to propagate the information from the
earlier layers to the deeper ones.
2.4 Cross-coordinate Attention Module
To date, attention modules such as squeeze-and-excitation (SE) [11], BAM [22],
and CBAM [27] are widely used in computer vision tasks and introduced into
deformable image registration. However, only local relations are captured limit-
ingtheregistrationaccuracy.Inaddition,althoughsomeotherstudiesproposed
cross-attentionmechanismstoimproveregistrationperformance,highercompu-
tationalcomplexityandmemoryconsumptionresultedinlongeralignmenttime
and a limited application environment [6,23]. To alleviate the aforementioned
issues, we proposed a novel efficient cross-coordinate attention module (CCA)
to model long-range dependencies inside image pairs in registration.
As shown in the right panel of Figure 1, CCA embedded in skip connections
taking the outputs of the copying branch (denoted as X RC×H×W×D)
cop
and the outputs of decoder layer (denoted as X
RC×H×W∈
×D) as inputs.
up
∈
Thenthree1DglobalaveragepoolingoperationsrespectivelyaggregateX and
cop
X along the three axes directions into three separate directionaware feature
up
mapszh,w ,zh,d andzw,d followedbythecrossmultiplicationbetweena
cop/up cop/up cop/up
specific direction of the upsampling branch and the other two directions of the
copyingbranch.Afterthree3DconvolutionaloperationsandSigmoid functions,
featuremapsareintegratedandusedasattentionweightsonfeaturemapsX .
cop
Finally, the output Y of our CCA module can be written as
Y =X σ(cid:0) F (cid:0) zh,w zh,d zw,d(cid:1)(cid:1) σ(cid:0) F (cid:0) zh,w zh,d zw,d(cid:1)(cid:1)
cop × cop × cop× up × cop × up × cop (6)
σ(cid:0) F (cid:0) zh,w zh,d zw,d(cid:1)(cid:1) ,
× up × cop× cop
where zh,w = 1 (cid:80)D X (h,w,i), zh,d = 1 (cid:80)W X (h,j,d),
cop/up D i=1 cop/up cop/up W j=1 cop/up
zw,d = 1 (cid:80)H X (k,w,d), σ denotes the Sigmoid function and F de-
cop/up H k=1 cop/up
notes the 3D convolutional operation with the kernel size of 1 1 1.
× ×
2.5 Implementation Details
FCNs and the proposed CCA module in the proposed DiffOp-net were imple-
mentedbasedonthePytorchplatform.BecauseoflackingAutogradmechanism6 Jiong Wu
for the operators and in Pytorch, we first implemented all components of
L K
thelossfunction andthecorrespondinggradient usingCUDAandthen
θ θ
J ∇J
integrated them into Pytorch framework to realize the parameters learning in
forward and backward propagations. Besides, to balance the registration accu-
racy and the smoothness of predicted velocity fields as well as to enhance the
capturing large deformation in image pairs, we empirically set the window size
to 9 to calculate NCC, the value of λ to 1 106 and the values of γ to 0.005,
×
0.002 and 0.001 respectively in the three registration levels. Three FCNs were
trained simultaneously to reach a globally optimal solution by utilizing Adam
with the learning rate of 1 10−4 and the batch size of 1. The source code is
×
available at https://github.com/*.
3 Experiments
3.1 Experimental Setting
Dataset: To evaluate the performance of the proposed method, three publicly
available T1-weighted magnetic resonance imaging (MRI) datasets with one for
training and another two for evaluation were utilized. The training dataset con-
sists of 506 images from the ADNI 1 cohort dataset [21] wherein 500 images
are randomly selected for training and the remaining 6 images yield 5 pairs
registration for validation. We employ the MICCAI 2012 Multi-Atlas Labelling
Challenge dataset (MALC) [16] containing 35 MRIs and the Mindboggle101
dataset [15] containing 101 MRIs as the testing datasets. To be specific, 134
structures and 50 cortical structures were manually delineated for each MRI in
MALC and Mindboggle101, respectively. Finally, we randomly sampled one im-
age from each testing dataset as the fixed image and the remaining images as
the moving images to conduct the registration experiments inner each dataset.
Therefore, a total of 134 pairs of registrations (34 from MALC and 100 from
Mindboggle101) are used for performance evaluation.
Preprocessing and Evaluation Metric: We used FreeSurfer [9] to sequen-
tiallyconducttheskull-stripping,affinespatialnormalization,andintensitynor-
malization for these three datasets followed by center cropping operations to
resize each MRI to the dimension of 144 160 192. Besides, we performed
× ×
the histogram matching between a pre-selected image from the training dataset
andtheremaining641MRIs.EvaluationmetricsincludingthemeanoftheDice
similaritycoefficient(DSC),theproportionofvoxelswithnon-positiveJacobian
determinations (10−4), and their standard deviations were adopted to respec-
tivelyanalyzetheregistrationaccuracyandtopology-preservingability.Besides,
the average running time of one registration is used to evaluate the efficiency.
3.2 Results
Compared to state-of-the-arts: In the first set of experiments, we compared
the registration results of the proposed method with some other state-of-the-artDiffOp-net for deformable image registration 7
Table1.QuantitativeresultsonmeanandstandarddeviationsoftheaverageDSCand
theproportionofvoxelswithnon-positiveJacobiandeterminants(10−4),aswellasthe
average computational time (seconds) per registration on MALC and Mindboggle101
obtained from different methods.
MALC Mindboggle101
Methods
Avg.DSC |Jϕ|≤0(10−4) Time Avg.DSC |Jϕ|≤0(10−4) Time
Affine 0.438(0.058) - - 0.356(0.017) - -
SyN 0.589(0.030) 5.44(2.95) 1443 0.549(0.018) 1.82(1.37) 1337
VM-diff 0.589(0.030) 0.03(0.03) 0.698 0.556(0.025) 0.12(0.13) 0.712
LapIRN 0.577(0.027) 197.90(42.64) 0.511 0.586(0.017) 231.66(33.89) 0.507
TransMorph 0.605(0.027) 111.93(22.05) 0.556 0.610(0.019) 109.67(16.53) 0.566
Ours 0.616(0.025) 1.38(0.95) 0.432 0.617(0.020) 3.63(2.69) 0.443
approaches including a typically conventional deformable image registration al-
gorithmsSyN[1]andthreerepresentativelyunsuperviseddeformableimagereg-
istration methods, diffeomorphic version of VoxelMorph (VM-diff) [7], LapIRN
[20] and TransMorph [5]. NCC with a window size of 9 was adopted in , and
S
all the other settings are configured in their default.
The statistical results derived from the application of Affine and various de-
formableregistrationapproachesonMALCandMindboggle101datasetsarepre-
sented in Table 1. Notably, our proposed method demonstrates higher registra-
tionaccuracy,andthelowestrunningtimeaswellasthecompetitivenumberof
voxelswith J 0comparedtotheotherfourdeformableregistrationmethods
ϕ
| |≤
on both datasets. Specifically, in comparison to the conventional registration al-
gorithm,ourmethodexhibitshigheraverageDSCsonMALC(2.7%)andMind-
boggle101(6.8%).RelativetotwootherFCNs-basedapproaches,namelyVM-diff
and LapIRN, our method achieves a higher number of voxels with J 0 than
ϕ
| |≤
VM-diff, yet significantly lower compared to LapIRN. While the Transformer-
basedregistrationframeworkexhibitssuperiorperformancecomparedtoFCNs-
based approaches in average DSCs, our proposed method surpasses it, particu-
larlyontheMALCdataset,whereourmethodachieves1.1%higherthanTrans-
Morph. Moreover, the topological preservation capacity of the DiffOp-net sig-
nificantly outperforms it. Figure 2 illustrates coronal MRI slices obtained from
movingimages,fixedimages,andtransformedimagesresultingfromtheapplica-
tion of transformation fields generated by SyN, VM-diff, LapIRN, TransMorph,
and DiffOp-net. It is evident from the visual examination that the aligned im-
ages produced by our proposed method exhibit the closest to the fixed images
in both datasets.
Ablation Study: To evaluate the impact of model size on registration per-
formance and validate the effectiveness of the CCA module proposed in our
study, we conducted a second set of experiments involving the construction of
three distinct models. The first two models were generated by varying the pa-
rameter C to 16 and 32, while the third model involved the removal of CCA
modules from the DiffOp-net. All other configurations remained consistent with8 Jiong Wu
Moving Fixed SyN VoxelMorph LapIRN TransMorph DiffOp-net (ours)
Fig.2.ExampleMRslicesofsourceimage,fixedimageandresultingdeformedimage
from SyN, VM-diff, LapIRN, TransMorph and our method.
Table 2. Quantitative results on mean and standard deviations of the average DSC
andtheproportionofvoxelswithnon-positiveJacobiandeterminants(10−4)onMALC
and Mindboggle101 obtained from four models.
MALC Mindboggle101
Methods
Avg.DSC |J |≤0 (10−4) Avg.DSC |J |≤0 (10−4)
ϕ ϕ
C =16 0.611 (0.027) 2.57 (0.94) 0.604 (0.019) 5.02 (2.28)
C =32 0.614 (0.026) 2.69 (1.18) 0.612 (0.020) 5.18 (2.57)
w/o CCA 0.612 (0.026) 3.62 (1.38) 0.610 (0.190) 5.52 (1.81)
DiffOp-net 0.616 (0.025) 1.38 (0.95) 0.617 (0.020) 3.63 (2.69)
the original DiffOp-net. The experimental results are outlined in Table 2. Upon
increasing the value of C (representing model size), we observed a simultaneous
improvementinaccuraciesforbothdatasets.Crucially,ourproposedDiffOp-net
achievedtheminimalnumberofvoxelswith J 0indicatingthattheoptimal
ϕ
| |≤
registration framework is achieved at C = 48. In comparison to the framework
lacking CCA modules, our method exhibited superior performance, showcasing
increased accuracies of 0.4% and 0.7% for the MALC and Mindboggle101, re-
spectively. This underscores the effectiveness of the CCA module in capturing
large deformations, particularly within cortical regions.
4 Conclusion
Inthispaper,wepresentDiffOp-net,adifferentialoperator-basedmulti-resolution
registration framework for velocity field prediction, to improve the performance
of deformable image registration. To further effectively capture the large defor-
mation between the image pairs, we develop a novel cross-coordinate attention
module. With evaluation experiments on two datasets with different numbers
of manually delineated anatomical structures, we demonstrate that our pro-
posed model performs better than FCNs-based methods and a representative
CLAM
101elggobdniMDiffOp-net for deformable image registration 9
Transformer-based method, in addition to a typical traditional algorithm. In
our future work, we will adopt network architecture searching approaches to
identify the optimal convolutional operations under current settings.
References
1. Avants, B.B., Epstein, C.L., Grossman, M., Gee, J.C.: Symmetric diffeomorphic
imageregistrationwithcross-correlation:evaluatingautomatedlabelingofelderly
and neurodegenerative brain. Medical image analysis 12(1), 26–41 (2008)
2. Balakrishnan,G.,Zhao,A.,Sabuncu,M.R.,Guttag,J.,Dalca,A.V.:Voxelmorph:
alearningframeworkfordeformablemedicalimageregistration.IEEEtransactions
on medical imaging 38(8), 1788–1800 (2019)
3. Beg, M.F., Miller, M.I., Trouv´e, A., Younes, L.: Computing large deformation
metric mappings via geodesic flows of diffeomorphisms. International journal of
computer vision 61(2), 139–157 (2005)
4. Che, T., Wang, X., Zhao, K., Zhao, Y., Zeng, D., Li, Q., Zheng, Y., Yang, N.,
Wang, J., Li, S.: Amnet: Adaptive multi-level network for deformable registration
of 3d brain mr images. Medical Image Analysis 85, 102740 (2023)
5. Chen,J.,Frey,E.C.,He,Y.,Segars,W.P.,Li,Y.,Du,Y.:Transmorph:Transformer
for unsupervised medical image registration. Medical image analysis 82, 102615
(2022)
6. Chen,Z.,Zheng,Y.,Gee,J.C.:Transmatch:Atransformer-basedmultileveldual-
stream feature matching network for unsupervised deformable image registration.
IEEE Transactions on Medical Imaging (2023)
7. Dalca, A.V., Balakrishnan, G., Guttag, J., Sabuncu, M.R.: Unsupervised learn-
ing for fast probabilistic diffeomorphic registration. In: International Conference
on Medical Image Computing and Computer-Assisted Intervention. pp. 729–738.
Springer (2018)
8. Fan,J.,Cao,X.,Yap,P.T.,Shen,D.:Birnet:Brainimageregistrationusingdual-
supervisedfullyconvolutionalnetworks.Medicalimageanalysis54,193–206(2019)
9. Fischl, B.: Freesurfer. Neuroimage 62(2), 774–781 (2012)
10. Fu,Y.,Lei,Y.,Wang,T.,Curran,W.J.,Liu,T.,Yang,X.:Deeplearninginmedical
imageregistration:areview.PhysicsinMedicine&Biology65(20),20TR01(2020)
11. Hu,J.,Shen,L.,Sun,G.:Squeeze-and-excitationnetworks.In:Proceedingsofthe
IEEEconferenceoncomputervisionandpatternrecognition.pp.7132–7141(2018)
12. Hu, X., Kang, M., Huang, W., Scott, M.R., Wiest, R., Reyes, M.: Dual-stream
pyramidregistrationnetwork.In:InternationalConferenceonMedicalImageCom-
puting and Computer-Assisted Intervention. pp. 382–390. Springer (2019)
13. Jia, X., Bartlett, J., Chen, W., Song, S., Zhang, T., Cheng, X., Lu, W., Qiu, Z.,
Duan, J.: Fourier-net: Fast image registration with band-limited deformation. In:
Proceedings of the AAAI Conference on Artificial Intelligence. vol. 37, pp. 1015–
1023 (2023)
14. Kang, M., Hu, X., Huang, W., Scott, M.R., Reyes, M.: Dual-stream pyramid reg-
istration network. Medical image analysis 78, 102379 (2022)
15. Klein, A., Tourville, J.: 101 labeled brain images and a consistent human cortical
labeling protocol. Frontiers in neuroscience 6, 171 (2012)
16. Landman,B.,Warfield,S.:Miccai2012workshoponmulti-atlaslabeling,in:Miccai
grand challenge and workshop on multi-atlas labeling, createspace independent
publishing platform, nice, france (2012)10 Jiong Wu
17. Liu, R., Li, Z., Fan, X., Zhao, C., Huang, H., Luo, Z.: Learning deformable image
registrationfromoptimization:perspective,modules,bileveltrainingandbeyond.
IEEE Transactions on Pattern Analysis and Machine Intelligence 44(11), 7688–
7704 (2021)
18. Liu,Y.,Li,X.,Li,R.,Huang,S.,Yang,X.:Amulti-viewassistedregistrationnet-
work for mri registration pre-and post-therapy. Medical & Biological Engineering
& Computing pp. 1–11 (2023)
19. Mok,T.C.,Chung,A.:Fastsymmetricdiffeomorphicimageregistrationwithcon-
volutional neural networks. In: Proceedings of the IEEE conference on computer
vision and pattern recognition. pp. 4644–4653 (2020)
20. Mok,T.C.,Chung,A.C.:Largedeformationdiffeomorphicimageregistrationwith
laplacianpyramidnetworks.In:InternationalConferenceonMedicalImageCom-
puting and Computer-Assisted Intervention. pp. 211–221. Springer (2020)
21. Mueller, S.G., Weiner, M.W., Thal, L.J., Petersen, R.C., Jack, C.R., Jagust,
W., Trojanowski, J.Q., Toga, A.W., Beckett, L.: Ways toward an early diagno-
sis in alzheimer’s disease: the alzheimer’s disease neuroimaging initiative (adni).
Alzheimer’s & Dementia 1(1), 55–66 (2005)
22. Park,J.,Woo,S.,Lee,J.Y.,Kweon,I.S.:Bam:Bottleneckattentionmodule.arXiv
preprint arXiv:1807.06514 (2018)
23. Shi, J., He, Y., Kong, Y., Coatrieux, J.L., Shu, H., Yang, G., Li, S.: Xmorpher:
Fulltransformerfordeformablemedicalimageregistrationviacrossattention.In:
International Conference on Medical Image Computing and Computer-Assisted
Intervention. pp. 217–226. Springer (2022)
24. Tang, X., Qin, Y., Wu, J., Zhang, M., Zhu, W., Miller, M.I.: Shape and diffusion
tensor imaging based integrative analysis of the hippocampus and the amygdala
in alzheimer’s disease. Magnetic resonance imaging 34(8), 1087–1099 (2016)
25. Tian, L., Greer, H., Vialard, F.X., Kwitt, R., Est´epar, R.S.J., Rushmore, R.J.,
Makris, N., Bouix, S., Niethammer, M.: Gradicon: Approximate diffeomorphisms
via gradient inverse consistency. In: Proceedings of the IEEE conference on com-
puter vision and pattern recognition. pp. 18084–18094 (2023)
26. Vercauteren, T., Pennec, X., Perchant, A., Ayache, N.: Diffeomorphic demons:
Efficient non-parametric image registration. NeuroImage 45(1), S61–S72 (2009)
27. Woo, S., Park, J., Lee, J.Y., Kweon, I.S.: Cbam: Convolutional block attention
module. In: Proceedingsof the European conference on computer vision (ECCV).
pp. 3–19 (2018)
28. Wu,J.,Tang,X.:Alargedeformationdiffeomorphicframeworkforfastbrainimage
registration via parallel computing and optimization. Neuroinformatics pp. 1–16
(2019)
29. Yang, S.D., Zhao, Y.Q., Zhang, F., Liao, M., Yang, Z., Wang, Y.J., Yu, L.L.: An
abdominal registration technology for integration of nanomaterial imaging-aided
diagnosis and treatment. Journal of Biomedical Nanotechnology 17(5), 952–959
(2021)
30. Yang, X., Kwitt, R., Styner, M., Niethammer, M.: Quicksilver: Fast predictive
image registration–a deep learning approach. NeuroImage 158, 378–396 (2017)
31. Zhang, M., Fletcher, P.T.: Fast diffeomorphic image registration via fourier-
approximated lie algebras. International Journal of Computer Vision 127, 61–73
(2019)