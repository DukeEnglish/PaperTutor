Prepreint. Underreview.
Cleared for Takeoff? Compositional & Conditional Reasoning
maybetheAchillesHeelto(Flight-Booking)LanguageAgents
HarshKohli&HuanSun
DepartmentofComputerScienceandEngineering
TheOhioStateUniversity
Columbus,OH43201,USA
{kohli.120,sun.397}@osu.edu
Abstract
Therapidprogressoflargelanguagemodels(LLMs)hasseenthemexcel
andfrequentlysurpasshumanperformanceonstandardbenchmarks. This
hasenabledmanydownstreamapplications,suchasLLMagents,torelyon
theirsophisticatedreasoningtonavigatecomplextaskrequirements. How-
ever, LLMsareknowntounexpectedlyfalterinsimpletasksandunder
seeminglystraightforwardcircumstances-underscoringtheneedforbetter
andmorediverseevaluationsetupstomeasuretheirtruecapabilities. To
thisend,wechoosetostudycompositionalandconditionalreasoning,two
cornerstonesofhumancognition,andintroduceGroundCocoa-alexically
diversebenchmarkconnectingthesereasoningskillstothereal-worldprob-
lemofflightbooking. Ourtaskinvolvesaligningdetaileduserpreferences
withavailableflightoptionspresentedinamultiple-choiceformat. Results
indicateasignificantdisparityinperformanceamongcurrentstate-of-the-
artLLMswitheventhebestperformingmodel,GPT-4Turbo,notexceeding
67%accuracydespiteadvancedpromptingtechniques.
1 Introduction
AdvancedreasoninginLLMshassignificantlyinfluencedandeffectedtherisetopromi-
nenceoflanguageagentsadeptathandlingadiverserangeoftasks(Shenetal.,2024;Wu
etal.,2023;Schicketal.,2024;SignificantGravitas;Osika,2023). Amongthem,webagents
(Hongetal.,2023;Furutaetal.,2023;Dengetal.,2024;Zhengetal.,2024)havedemonstrated
potentialinautomatingweb-basedtaskssuchasflightbooking. Whilesuchsuccessthrough
widespreadapplicationofLLMsisindeedpromising,itnecessitatesongoingexplorationof
theircorereasoningproficiencies. Conditionalandcompositionalreasoningplayacrucial
role in our ability to understand and interact with complex systems through elaborate
decision-making(Oaksford&Chater,2010;Simon&Newell,1971). Conditionalreasoning
involvesthecomprehensionandapplicationoflogicalrulesthataretypicallystructured
in“if-then”formats. Itiscriticaltopersonaldecision-makingineverydaylifethroughan
evaluationofpotentialscenariosandanticipationofconsequences. Compositionalreason-
ing, ontheotherhand, istheabilitytocombinesolutionstosimplersub-problems, and
integratetheminastructuredmannertosolveamorecomplextask. Thiscognitiveprocess
entailsunderstandingtheinterplaybetweendifferentsub-problems. Ourpaperfocuseson
assessinghowwellcurrentLLMsencapsulatetheseessentialcognitivefunctions,whichare
integraltobothhumanintelligenceandadvancedartificialintelligencesystems. Tothatend,
weintroduceGroundCocoa1 -abenchmarkforevaluatingcompositional&conditional
reasoninginagroundingtask.
GroundCocoaismadeupofquestionsframedasuserneeds,setwithinareal-worldinspired
flightreservationscenario. Userrequirementsmightbemanyorcouldbehighlyconvoluted
-leadingtohighercompositionalandconditionalcomplexityrespectively. Weleveragea
controllablemethodtocreatesamplesofvaryingcomplexity(examplesareprovidedin
1https://osu-nlp-group.github.io/GroundCocoa/
1
4202
rpA
5
]LC.sc[
1v73240.4042:viXraPrepreint. Underreview.
Figure1: Gemini-ProandGPT-4Turboresponsesforaflightrequirementwithsingleoption
andasimplifiedschema.
AppendixB).Ourdatagenerationprocess,describedingreaterdetailinSection 2,consists
ofa5-stagepipelineincludingonlinescraping,constraintgeneration,andsymboliclogic
toimposeconditionality. Inordertotestforrobustness,weallowrequirementstofreely
condition on one another and impose no restrictions on their nature. Additionally, we
isolateasubsetofmoreatypicalqueriesthatcontainunconventionaluserneeds(e.g.,”I
wantatleast2layovers”)andevaluatetheirimpactonmodelperformance. Samplesin
GroundCocoamayalsorequirereasoningabouttime(e.g. whenconstraintsareimposed
onarrivalordeparturetimes)andarithmetic(e.g. whenconstraintsareimposedonticket
price),thus,integratinglogical,temporal,mathematical,andcompositionalreasoning.
ThestatisticsofourdatasetareshowninTable1. Ourkeyfindingsareasfollows:
1. AccuracyamongcontemporaryLLMsvariesgreatly, rangingfromalittlebetter
thanrandomguesstoabout67%onafive-optionmultiple-choicequestiontask.
Within this spectrum, GPT-4 Turbo (OpenAI, 2023) stands out, demonstrating a
superiorcapacityoftheGPTlineofmodelstoadaptandexcelinnovelreasoning
tasks. However,conditionalreasoningposesasignificantchallengetoallevaluated
models,evenonsamplesofrelativelylowercomplexity.
2. ChainofThought(COT)prompting(Weietal.,2022)leadstomixedresults,with
onlyamodestimprovementinmodelperformanceinsomecases.Priorresearchhas
notedthatalthoughCOThelpsdecomposeproblemsintosteps,LLMsincreasingly
struggleasthecomplexityoftheindividualstepsescalates(Hendrycksetal.,2021b;
Madaan & Yazdanbakhsh, 2022; Nogueira et al., 2021; Qian et al., 2023). These
assertionsholdtrueinourobservations.
3. Includingunconventionaluserrequirementsleadstoadropinaccuracyofasmuch
as6%inGPT-4Turbo,indicatingapretrainingbiastowardsmoretypicalneeds.
2 Approach
Figure2illustratesourproposedapproach. Intheprocessofgeneratinganaturallanguage
userrequirementforflightbooking,wearefacedwiththefollowingconsiderations:
ConditionalityofConstraints: Wewishtochallengecontemporarymodelsintheirability
toreasonthroughscenarioscharacterizedbyconditionalcomplexity. Thisisdonethrough
mutualdependenceofflightfeatureswhichwerefertoasslots. Intheexampleillustrated
inFigure2,thereisaninter-dependencebetweenthevaluesforpriceandticketclass. The
interplaybetweenconstraintscorrespondingtothedifferentslotsisrepresentedinlogical
formthroughaProduct-of-Sums(POS)expression. APOSexpressionconsistsofmultiple
ORoperations(sums)whicharelatercombinedthroughANDoperations(products). The
inclusion of OR operations between slots introduces conditional complexity to our user
2Prepreint. Underreview.
Figure2:StepwisedepictionofGroundCocoaquerygenerationusing2slotsand2minterms.
requirement,necessitatingconsiderationofpotentialslotvaluesinif-thenscenarios. Onthe
otherhand,agreaternumberofANDconditionsimpliesahighernumberofvariablesthata
modelhastosimultaneouslyreasonoverresultinginincreasedcompositionalcomplexity.
SatisfiabilityofPOSExpression: Whilegeneratingthelogicalformforauserrequirement,
we must ensure satisfiability of the generated POS expression. For this, we use SymPy
(Meureretal.,2017)-anopen-sourcePythonsymbolicmathematicslibrarywhichgenerates
anoptimalPOSexpressiongivenamintermtable. ThisisfurtherdescribedinSection 2.2.
FuzzinessinSlotValues: CorrespondingtoeachoccurrenceofaslotinthePOSexpression
there has to be a unique constraint. For the example in Figure 2, the two constraints
on the price slot are {<12400, <500}. These constraints are randomly imposed through
specializedrule-basedsystemscorrespondingtoeachslot. However,thesemightcausethe
finalusercriteriatobecomeimpossibletosatisfyevenifthecorrespondingPOSexpression
insatisfiable. Thus,foragenerateduserrequirementwecheckourflightdatatoensurethat
thereexistsatleastoneroutethatsatisfiesthecriteriaandatleast4thatdonot. Thisway
weensurethereisatleastonepositiveand4negativeoptionsforageneratedrequirement.
Statistics of GroundCocoa are shown in Table 1. We also include a separate validation
setwhichmaybeusedfortuninghyperparameters. Our5-stagedatacreationpipelineis
detailedinthesubsequentsections.
2.1 FlightDataCollection
Weusealistofthetop50busiestairportsbypassengertrafficderivedfromWikipedia2.
Source and destination airportsare chosenrandomly fromthis list and inputto Google
Flights3withthedeparturedatesetforApril17,2024.Asmallnumberofflightsaresampled
fromsearchresultsforeachsource-destinationpair. Thesampledflightsarechosenfrom
eachofeconomy,business,andfirstclassand,foreachflightoption,alltherelevantdetails
suchasthenumberoflayovers,price,departureandarrivaltimesetc. aresaved. Asample
flightschemawithalltheelementsisprovidedinAppendixA.Theentiredatacollection
processishandledthroughwebscrapingusingSeleniumWebdriver4.
2.2 Product-of-SumsGeneration
TogenerateaPOSexpression,wefirstrandomlyselectasmallnumberofflightfeaturesor
slots. Thecompletesetofslotsforanygivenflightisasfollows:
{airline,ticket class,departure time,arrival time,total travel time,number of layovers,average
carbon emission difference,travel date,price,layover locations,layover times}
2https://en.wikipedia.org/wiki/List_of_busiest_airports_by_passenger_traffic
3https://www.google.com/travel/flights
4https://www.selenium.dev/documentation/webdriver/
3Prepreint. Underreview.
(slot,minterm)configurations
Statistic Total
(2,2) (3,2) (4,2) (4,3) (5,2) (6,2)
TestSamples 1511 1083 710 723 451 371 4849
TestUniqueQueries 124 136 117 129 121 101 728
Val.Samples 17 17 8 5 2 3 52
Val.UniqueQueries 1 1 1 1 1 1 6
Avg.QueryLength 65.04 88.33 103.88 119.14 124.56 148.87 95.95
Avg.ContextLength - - - - - - 1252.27
VocabSize - - - - - - 4200
Table1: KeyStatisticsofGroundCocoa.
We vary the number of slots between 2 and 6 in order to generate samples of differing
complexity. Wethenrandomlygenerate2-3”minterms”-thelistofallinputcombinations
ofslotsthatgeneratea”1”. Ahighernumberofmintermsresultsinagreaterconditional
complexityandleadstomoreconvoluteduserrequirements.Theslotsymbolsandgenerated
mintermsareinputtoSymPywhichusesaredundant-groupeliminatingalgorithmtooutput
thesmallestPOSexpressionconsistentwiththemintermtable.
2.3 PrimitiveGeneration
Correspondingtoeachslot,wehavedevelopedarule-basedsystemthatrandomlyimposes
constraints on its values. These constraints are converted to natural language through
templates. SinceaPOSexpressionmaycontainanegation,wegeneratetwoprimitivesat
each turn - one for the constraint and one for its negation. A sample primitive for total
traveltimeisshowninTable2.
TravelTime TravelTimeshouldbemorethan22hoursand30minutes.
¬TravelTime TravelTimeshouldnotbemorethan22hoursand30minutes.
Table2: Sampleprimitivegeneratedfromtemplatesfortotaltraveltime.
Atthisstage,wealsoisolatesamplesthatincludeanyoneofthefollowingthreeprimitives-
(1)carbonemissionsmustbeabovetheaverageforthatroute,(2)priceoftheflightmust
beaboveaminimumthreshold,and(3)numberoflayoversontherouteshouldbegreater
thanaminimum. Whilethislistisnotexhaustive,suchsamples(henceforthreferredtoas
”atypical”queries)areabletosuccessfullyencapsulatecontrarianneedsthatareunlikelyto
manifestoftenduringpretraining.
2.4 LLMParaphrasingandHumanValidation
WecarryoutLLMparaphrasingintwodistinctstepsdescribedbelow. Theexactprompts
andanexampleofintermediateresultsareprovidedinAppendixD.Wemanuallyverify
each query to ensure it is consistent with the primitives and make changes wherever
necessary.
1. Individual primitives are substituted into each sum term and combined using
templatedrules. WethenuseGPT-4Turbotoparaphraseeachofthesumterms.
2. Next,wecombinetheindividualsumtermsintoaproduct(logicalAND).Thisis
donebymergingtheindividualparaphrasesofsumterms,separatedbyperiods.
TheresultingflightrequirementisagainparaphrasedwithGPT-4Turbo.
2.5 OptionMatching
WematchthegenerateduserrequirementswiththeflightdatacollectedinSection2.1. Each
route between the source and destination represents a potential choice in our multiple-
4Prepreint. Underreview.
choice dataset. Choices are divided into subsets containing one positive (matching the
user requirement) and four negative (not matching the user requirement) options. This
isdonetoensurethateachmultiple-choicequestionhasonlyasinglecorrectanswerfor
easeofevaluation. Manysuchsubsetsmaybecreatedfromasingleuserrequirementand,
consequently,ourdatasetconsistsofqueriesrepeatedmultipletimeswithdifferingchoices.
DetailsonthenumberofuniquequeriesandoverallsamplesisprovidedinTable1.
3 Results&Analysis
TomeasureperformanceonGroundCocoa,wetestseveralmodelsofdifferentsizesranging
fromopen-sourcetoclosed-source,includingLLAMA2-chat(Touvronetal.,2023),Mixtral
8x7B-Instruct(Jiangetal.,2024)/Mistral7BInstruct(Jiangetal.,2023),GeminiPro(Team
et al., 2023), and GPT-4 Turbo. We also test selected larger models with an in-context
exampleusingchain-of-thought(CoT)(Weietal.,2022)reasoning. Sinceourtaskinvolves
groundinguserrequirementstoeachanswerchoice,theCoTexplanationsareprovidedfor
eachflightoptiongiventheuserrequirement. Thus,ourstandardCoT(CoT-full)consistsof
5distinctexplanations. OnGPT-4,weempiricallyobservethatthelargeresultingcontext
lengthcanoftenprovedetrimentaltomodelperformancewiththemodelsoftenconfusing
betweentherequirementsandoptionsofthetestcaseandtheexemplar. Toaddressthis,we
tryadifferentpromptingstrategy(CoT-partial)withonlytwoflightchoices(1positiveand
1negative)forthein-contextexample. Duetolimitationsoncontextlength(4096tokens)we
areunabletorunLLAMA2-chat70BonCoT-full. TheexactpromptsaregiveninAppendix
C.ResultsfromourexperimentsareshowninTable3.
Regular Atypical Total
Open-sourceModels
LLAMA2-chat7B 14.56 14.66 14.60
Mistral7BInstruct 25.70 26.10 25.86
LLAMA2-chat13B 16.33 16.06 16.23
Mixtral8x7B-Instruct 45.79 42.48 44.48
Mixtral8x7B-Instruct+CoT-full 34.38 32.65 33.69
Mixtral8x7B-Instruct+CoT-partial 41.38 39.85 40.15
LLAMA2-chat70B 24.13 21.63 23.13
LLAMA2-chat70B+CoT-partial 25.73 23.97 25.03
Closed-sourceModels
GeminiPro 42.79 40.46 41.86
GeminiPro+CoT-full 41.14 40.87 41.04
GeminiPro+CoT-partial 34.82 33.85 34.44
GPT-4Turbo 64.66 58.81 62.34
GPT-4Turbo+CoT-full 65.07 61.51 63.66
GPT-4Turbo+CoT-partial 67.77 65.62 66.92
Table3: AccuracyResults(inpercentage)onGroundCocoa.
As alluded to previously, GroundCocoa presents a substantial challenge for each of the
evaluatedmodels,evenwithCoTprompting. TheCoT-partialstrategywithonly2options
andexplanationsleadstobetterresultsthanCoT-fullin2outof3caseswherewehave
experimentedwithboth,andbestresultsareobtainedusingGPT-4TurbowithCoT-partial.
It is noteworthy, though, that there exists a marked difference in performance between
GPT-4Turboandtheremainingmodels. Suchadegreeofvariationrepresentsasignificant
departurefromtheusualperformancepatternsobservedinpopularbenchmarkssuchas
MMLU(Hendrycksetal.,2021a),HellaSwag(Zellersetal.,2019),ARCReasoningChallenge
(Clarketal.,2018),WinoGrande(Sakaguchietal.,2021),andGSM-8K(Cobbeetal.,2021)
amongothers,whereresultsaremuchmorecomparable.
Beyondassessingtheoverallmodelperformance,wealsoinvestigatetheconsequencesof
varyingthecomplexityofusercriteriaandpresentingrelativelyunconventionaluserneeds.
5Prepreint. Underreview.
3.1 ImpactofIncreasingComplexity
In our analysis, we observe the performance of GPT-4 Turbo, the most effective model
fromamongthosetestedonGroundCocoa acrossdifferentlevelsofconditionalandcom-
positional complexity. In their recent work on assessing the limitations of transformer
on compositional tasks, Dziri et al. (2023) use computational graphs as approximations
of the underlying reasoning processes in such models. They define the terms reasoning
depth,thelengthofthedeepestlayerinthecomputationalgraphfromthesourcenodes,
and reasoning width, the mode of number of nodes in each layer - indicating the extent
ofmulti-hopreasoningandcompositionalparallelismrequiredtosolveagivenproblem.
ConsideringthecharacteristicsofGroundCocoa wefocusonreasoningwidth-thenumber
ofvariablesamodelhastosimultaneouslyreasonoverforagivenproblem. Intuitively,
thismayberepresentedbythenumberofslotsusedduringthegenerationofaparticular
sampleasdescribedinSection2.2. However,keepingthenumberofrowsintheminterm
tableconstantwhileincreasingtheslotsmayoftenleadtolowerconditionalcomplexityas
thenumberofslotsisincreased.
Figure3: AnexampleofPOSexpressionanditscorrespondingdependencygraph.
Inordertoeffectivelygaugethecompositionalandconditionalcomplexityofasamplein
ourdataset,wedefineadependencygraphderivedfromthePOSexpressioncorresponding
tothatsample. Verticesrepresentslotsandadependency(edge)iscreatedwhenaparticular
slotco-occurswithanotherslotwithinasumterminthePOS.AsamplePOSexpression
anditscorrespondingdependencygraphareshowninFigure3. Thegraphhas3connected
componentswiththelargestconnectedcomponent(LCC)ofsize4. Themaximumdegreeis
2whichcorrespondstothetwoconnectionsfornodesLayoverTimeandTicketClass.
Figure4: Effectofincreasingcomplexityinevaluationsamples.
Givenafixed-schemafortheflightoptions,thenumberofsumtermsinthePOSexpression
as well as the LCC in the dependency graph are indicative of the reasoning width and,
in turn, the compositional complexity of the user criteria. The LCC is the length of the
largestchainofslots-thepossiblevaluesofwhicharedependentononeanotherthrough
OR conditions (represented by edges in the dependency graph). This metric effectively
reflectsthebreadthofparallelcomputationorreasoningwidthrequiredtoaccuratelyinferthe
givenusercriteria. Sinceincreasedbranchinginthedependencygraphsuggestsagreater
conditionalcomplexityinusercriteria,wealsoanalyzemodelperformancewithincreasing
maximumdegreeofthedependencygraph. Thisgivesustheextentofconditioningona
singleslotvalue. InFigure4weobservethedeclineinmodelperformancewithincreased
complexityasindicatedbythesefactors.
3.2 QuantifyingConfusioninAnswerChoicesthroughEntropy
Numerousrecentstudieshaveexploredhowdeeplearningmodels,specificallytransformer-
basedarchitectures,achievesuccessbyexploitingshortcuts(Geirhosetal.,2020;Liuetal.,
6Prepreint. Underreview.
2022; Tang et al., 2023; Du et al., 2023) and relying on spurious correlations present in
the training data (Zhang et al., 2023; Saparov & He, 2023; Saparov et al., 2023). Most
recently,Dzirietal.(2023)utilizedrelativeinformationgainofindividualoutputelements
inpartiallycorrectanswerstoexplainsurfacepatternunderstandinginLLMs. Inthesame
vein,weemployentropyasametrictomeasuretheconfusionthatmightbecauseddueto
conditionsintheuserqueryforagivenflightoption. Wedothisinanattempttodemystify
howlanguagemodelsmaysucceedatsomeandfailatotherquerieswithsimilarlevels
ofcomplexity. Inordertoillustratethis,wetakeanexampleuserrequirement,andtwo
hypotheticalandsimplifiedflightoptionsasshowninFigure5. Additionally,weshowthe
reasoningpaththatmustbenavigatedineachcaseforasuccessfuloutcome.
Figure5: Sampleuserrequirementandtwohypotheticalflightoptions.
We observe how option B in our example leads to a more convoluted reasoning path,
whereas the model is able to bypass considerable conditional overhead in the case of
OptionA.Forthepurposeofquantifyingthismoregenerally,weobservethecompositional
primitives(valuesattachedtoindividualslotsinthePOSexpression)ineachsampleand
attachabinaryvalueindicatingiftheprimitiveissatisfied. FortheexampleinFigure5,we
showtheprimitivesandthecorrespondingvaluesofbothoptionsinFigure6. Wealsoshow
theprobabilityofaprimitivebeingsatisfied(p sat)andbeingunsatisfied(p sa¯t)bytheflight
optionunderconsideration,aswellasthefinalentropy.
Figure6: Satisfactionofindividualprimitives Figure7: Effectofincreasingentropyinan-
andcorrespondingentropy. swerchoiceofevaluationsamples.
Entropyduetousercriteriaforeachoptioncanthenbecomputedusingtheformulain
Equation1. HigheruncertaintyleadstogreaterentropyinOptionBasopposedtoOption
A,indicatingagreaterconditionaloverhead.
H(X) = −(p satlogp sat+p sa¯tlogp sa¯t) (1)
Inouranalysis,wetaketheentropyvaluesofthecorrectanswerchoiceforeachsample.
Figure 7 shows the densities of entropy values for the correct and wrong predictions of
GPT-4TurboonGroundCocoa. Whilecorrectpredictionsexceedwrongpredictionsatlower
entropyvalues,anabruptsurgeinwrongpredictionsisobservedathigherentropylevels.
Thus,entropygivesusyetanothermeasureofconditionalcomplexityfromtheperspective
of the answer choices rather than just the query, and helps explain why a model might
exhibitinconsistentresultsacrossuserqueriesofsimilarcomplexity.
7Prepreint. Underreview.
3.3 RobustnesstoUnconventionalUserNeeds
Severalcontemporarystudieshavesoughttoexaminetherobustnessoflanguagemodels
bystudyingtheirresiliencetoout-of-distributiondata(Kohetal.,2021;Wangetal.,2023)
or through adversarial attacks and input perturbations (Gardner et al., 2020; Goel et al.,
2021;Subhashetal.,2023;Sanyaletal.,2022;Yuanetal.,2023). Inourwork,wechallenge
modelsthroughatypicaluserrequirementsinordertoassessbiasfrompretrainingand
robustnesstounorthodoxandnontraditionalqueries. Wesegregatequeriesinto”Regular”
and”Atypical”groupsasdescribedinSection2.3.InTable3,wecontrastmodelperformance
onsamplesthatdescribesuchunconventionaluserneedsversusthosethatdonot. While
mostmodelsinourtestingshowadecayinperformance,theimpactismorenoticeableon
betterperformingmodelssuchasGPT-4Turbo. Thein-contextexampleusedforallqueries
whentestingwithCoTincludestwosuchprimitives(ticketprice>1800,carbonemission
aboveaverage). WeobservethatthedeclineinperformanceislesspronouncedwithCoT.
4 RelatedWork
ReasoningChallengesinNLP.Ourworkextendstheexistinglineofresearchonevalu-
atingnaturallanguageprocessing(NLP)systemsondifferentfacetsofreasoning-most
notablycommonsensequestion-answering(Talmoretal.,2019;Huangetal.,2019),physical
reasoning(Bisketal.,2020), socialinteraction(Sapetal.,2019), mathematicalreasoning
(Cobbe et al., 2021; Amini et al., 2019; Miao et al., 2020; Hendrycks et al., 2021b), story
completion (Zellers et al., 2019), temporal reasoning (Zhou et al., 2019; Tan et al., 2023)
abductivereasoning(Bhagavatulaetal.,2020)andpronounresolution(Sakaguchietal.,
2021)amongothers. Differentfromthesebenchmarks,GroundCocoaintroducesaunique
andsubstantialchallengeforLLMsintheformofconditionalandcompositionalreasoning.
Benchmarks on Propositional Logic. GroundCocoa also aligns with the considerable
bodyofworkonevaluatinglogicalreasoninginlanguagemodels. TheRuleTaker(Clark
etal.,2021)andProofWriter(Tafjordetal.,2021)datasetsproposedamodernapproach
to evaluating logical reasoning through a task involving assignment of binary labels to
candidate implications following a set of premises expressed in natural language. The
datasetsemulatealineardeductivechainofreasoningofvaryingdepthsgivenasetoffacts
andrules,withProofWriteraugmentingthistaskthroughintermediateconclusionsand
proofgeneration. LogicNLI(Tianetal.,2021)providesamorecomprehensivediagnostic
benchmarkinvolvingreasoningthroughallsevenfundamentallogics(conjunction,disjunc-
tion,negation,implication,equation,universalandexistentialquantifiers). Itcontainsan
additional”paradox”labelimplyingasituationwhereboththehypothesisaswellasits
negativepropositioncanbesimultaneouslyentailedtothepremisethroughdifferentrea-
soningpaths. Thisfacilitatesanon-linearreasoning,butisstilllimitedtotwocontradictory
reasoningpaths. TheFOLIO(Hanetal.,2022)datasetboastsahighervocabularysizedue
toahybridannotationapproachbutagainconsistsoflinearreasoningchains. Alongsimilar
lines,ProntoQA(Saparov&He,2022)proposesafirst-orderlogicbenchmarkusingalinear
ontologywhichmightbefictional. ThisisdonetopreventLLMsfrompredictingcorrect
outcomesthroughspuriouscorrelationsintheirpretrainingcorpus.
The benchmarks described here are primarily focused on the evaluation of deductive
reasoning.Incontrast,GroundCocoaoffersamorerealisticgroundingtaskwithanemphasis
onif-thenreasoningwhichleadstomanycandidatereasoningpathsforeachanswerchoice.
Whiledeductivereasoningmayinvolveabroaderrangeoflogicalstructures,conditional
reasoningisasubsetwhichdealsspecificallywiththerelationshipsandimplicationsof
conditionalstatements. Ourdatasetconsistsofalargevocabularysizeandcontextlength
persample,leadingtogreaterlinguisticdiversity,andahigherreasoningwidththanother
benchmarksinlogicalreasoning. Questionsaredesignedtotestforrobustnessagainstrare
andunconventionaluserrequirementsandbringtotheforemodelbiasfrompretraining
data. Also,unlikemostotherbenchmarks,wedonotattempttoevaluatelogicalreasoning
inisolation-ourtaskmightrequireabilitiessuchastemporalormathematicalreasoning.
CompositionalGeneralization. SamplesinGroundCocoaconsistofnovelcombination
ofprimitivesexpressedasuserrequirementsinaflight-bookingtask. Suchreasoningfalls
8Prepreint. Underreview.
undertheumbrellaofcompositionalgeneralization-anareathathasgarneredincreasing
interestinthescientificcommunityrecently. Hosseinietal.(2022)highlighttherelative
generalizationgapwithin-contextlearningbetweenin-distributionandout-of-distribution
samplesinvarioussemanticparsingtasks. Dzirietal.(2023)demonstrateshowtransformer-
based LLMs may solve compositional tasks by reducing them to linearized subgraph
matching. Byestablishingacomputationalgraphforeachproblem,theauthorsareable
to define computational complexity by metrics such as the reasoning depth and width
whichcorrespondtolevelsinmulti-hopreasoningandaverageparallelismrespectively.
Unsurprisingly,increasedtaskcomplexityleadstoarapiddecayinmodelperformance
undervarioussettings.
Ourfindingslargelyconcurwithpreviousliteratureoncompositionalreasoning. However,
resultsonGroundCocoarevealthateventhemostadvancedLLMsstruggleatrelatively
lowlevelsofcompositionalcomplexitywhenjuxtaposedwithconditionalreasoningand
grounding. While Dziri et al. (2023) demonstrated their results using problems such as
multi-digitmultiplication,dynamicprogramming,andEinstein’spuzzle-wereleaseanew
datasetthatisanchoredonapractical,realworlduse-caseofparsingcomplexusercriteria
andgroundingtoafixedschemarepresentingaflightoption. GroundCocoacontainsahigh
semanticcoverageandwepositthatitwouldbeofinteresttotheNLPcommunityasahard
evaluationsettobenchmarkcompositionalgeneralizationinLLMs.
Dialogue-StateTracking. Finally,whileourtaskisreminiscentofasingleturninadialogue
statetrackingsystem,itgoesonestepfurthertotestalanguagemodel’sgroundingabilityto
matchaflightschemawiththeuserquery. Mostschema-guideddialoguedatasets(Rastogi
etal.,2020;Leeetal.,2022)consistoffixedslotvaluesandthefilteringofavailableoptions
ishandledthroughexternalsystems(e.g. api’s). SlotvaluesinGroundCocoaarefuzzydue
toconditionalconstraintsontheprimitives. InFigure5,TicketPricemaytakeondifferent
values based on TicketClass. GroundCocoa consists of examples with varying levels of
compositionalcomplexityduetolongandcomplexuserrequirements. Thisdifferentiatesit
fromthemajorityofschema-guideddialoguedatasetswheretheprimaryobjectiveisgoal
andslotidentification,andtaggingofslotvalues. Thesetasks,whilechallengingintheir
ownrespect,donotengageamodels’compositionalreasoningabilitytothesameextent.
5 Conclusion
ModernLLMshavedemonstratedremarkableadvancementsinmanytasksincludingthose
thatareinherentlycompositionalandnecessitateconditionalreasoningsuchasmathemati-
calproblemsolving,andcodegenerationandinterpretation. However,discerninggenuine
reasoningfrommererotelearningandshallowunderstandingcontinuestobeafocalpoint
ofstudy. WhileLLMshavebecomeexceedinglyadeptatansweringquestionsofseemingly
greatercomplexity,weshowthattheycanstruggleonthesameskillswhenpresentedwith
anunfamiliartasksetting. Whileproblemsizedoeshaveanimpact,eventhelesscomplex
samplesinourdatasetarechallengingtothebestlanguagemodelstoday.
Beyond introducing a new benchmark dataset, we conduct a thorough analysis of the
effectsofincreasingcomplexity,includingadvancedpromptingtechniques,androbustness
to atypical queries. Our results uncover a substantial disparity in the performance of
competinglanguagemodels,adistinctionthatisnotaspronouncedinmostotherevaluation
benchmarksandhighlightstheirrespectiveabilitiesintacklingnovelchallenges. Ourdata
generationprocessislargelyautomatic,withhumanvalidationatthelaststep. Inaddition
tothedatasetandtheevaluationscript,wereleasecodeforthedatagenerationwhichcan
beeasilyextendedtogeneratemoreexamples,andincreasediversity(throughdifferent
slots)aswellascomplexity. Withminormodifications,thetaskcanbefurthercomplicated
by incorporating queries with multiple answers and questions that require other forms
oflogicalreasoningsuchasaggregation(e.g.,”Givemethecheapestflightmatchingmy
criteria?”), existential quantification (e.g., ”Is there a first class seat under $5000?”) etc.,
whichweleaveforfuturework.
9Prepreint. Underreview.
References
AidaAmini,SaadiaGabriel,ShanchuanLin,RikKoncel-Kedziorski,YejinChoi,andHan-
naneh Hajishirzi. MathQA: Towards interpretable math word problem solving with
operation-basedformalisms. InJillBurstein,ChristyDoran,andThamarSolorio(eds.),
Proceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforCom-
putationalLinguistics: HumanLanguageTechnologies,Volume1(LongandShortPapers),pp.
2357–2367,Minneapolis,Minnesota,June2019.AssociationforComputationalLinguistics.
doi: 10.18653/v1/N19-1245. URLhttps://aclanthology.org/N19-1245.
ChandraBhagavatula,RonanLeBras,ChaitanyaMalaviya,KeisukeSakaguchi,AriHoltz-
man, Hannah Rashkin, Doug Downey, Wen tau Yih, and Yejin Choi. Abductive com-
monsensereasoning. InInternationalConferenceonLearningRepresentations,2020. URL
https://openreview.net/forum?id=Byg1v1HKDB.
YonatanBisk,RowanZellers,JianfengGao,YejinChoi,etal. Piqa: Reasoningaboutphysical
commonsense in natural language. In Proceedings of the AAAI conference on artificial
intelligence,volume34,pp.7432–7439,2020.
PeterClark,IsaacCowhey,OrenEtzioni,TusharKhot,AshishSabharwal,CarissaSchoenick,
andOyvindTafjord.Thinkyouhavesolvedquestionanswering?tryarc,theai2reasoning
challenge. arXivpreprintarXiv:1803.05457,2018.
Peter Clark, Oyvind Tafjord, and Kyle Richardson. Transformers as soft reasoners over
language. InProceedingsoftheTwenty-NinthInternationalConferenceonInternationalJoint
ConferencesonArtificialIntelligence,pp.3882–3890,2021.
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz
Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher
Hesse,andJohnSchulman. Trainingverifierstosolvemathwordproblems. arXivpreprint
arXiv:2110.14168,2021.
XiangDeng,YuGu,BoyuanZheng,ShijieChen,SamStevens,BoshiWang,HuanSun,and
YuSu. Mind2web: Towardsageneralistagentfortheweb. AdvancesinNeuralInformation
ProcessingSystems,36,2024.
MengnanDu,FengxiangHe,NaZou,DachengTao,andXiaHu. Shortcutlearningoflarge
languagemodelsinnaturallanguageunderstanding. Commun.ACM,67(1):110–120,dec
2023. ISSN0001-0782. doi: 10.1145/3596490. URLhttps://doi.org/10.1145/3596490.
NouhaDziri, XimingLu, MelanieSclar, XiangLorraineLi, LiweiJiang, BillYuchenLin,
SeanWelleck,PeterWest,ChandraBhagavatula,RonanLeBras,JenaD.Hwang,Soumya
Sanyal,XiangRen,AllysonEttinger,ZaidHarchaoui,andYejinChoi. Faithandfate: Lim-
itsoftransformersoncompositionality. InThirty-seventhConferenceonNeuralInformation
ProcessingSystems,2023. URLhttps://openreview.net/forum?id=Fkckkr3ya8.
HirokiFuruta,Kuang-HueiLee,OfirNachum,YutakaMatsuo,AleksandraFaust,Shixi-
angShaneGu,andIzzeddinGur. Multimodalwebnavigationwithinstruction-finetuned
foundationmodels. InTheTwelfthInternationalConferenceonLearningRepresentations,2023.
MattGardner,YoavArtzi,VictoriaBasmov,JonathanBerant,BenBogin,SihaoChen,Pradeep
Dasigi,DheeruDua,YanaiElazar,AnanthGottumukkala,etal. Evaluatingmodels’local
decision boundaries via contrast sets. In Findings of the Association for Computational
Linguistics: EMNLP2020,pp.1307–1323,2020.
RobertGeirhos,Jo¨rn-HenrikJacobsen,ClaudioMichaelis,RichardZemel,WielandBrendel,
Matthias Bethge, and Felix A Wichmann. Shortcut learning in deep neural networks.
NatureMachineIntelligence,2(11):665–673,2020.
Karan Goel, Nazneen Fatema Rajani, Jesse Vig, Zachary Taschdjian, Mohit Bansal, and
ChristopherRe´. Robustnessgym: Unifyingthenlpevaluationlandscape. InProceedings
of the 2021 Conference of the North American Chapter of the Association for Computational
Linguistics: HumanLanguageTechnologies: Demonstrations,pp.42–55,2021.
10Prepreint. Underreview.
SimengHan,HaileySchoelkopf,YilunZhao,ZhentingQi,MartinRiddell,LukeBenson,
LucySun,EkaterinaZubova,YujieQiao,MatthewBurtell,DavidPeng,JonathanFan,
YixinLiu,BrianWong,MalcolmSailor,AnsongNi,LinyongNan,JungoKasai,TaoYu,
RuiZhang,ShafiqJoty,AlexanderR.Fabbri,WojciechKryscinski,XiVictoriaLin,Caiming
Xiong,andDragomirRadev. Folio: Naturallanguagereasoningwithfirst-orderlogic.
arXivpreprintarXiv:2209.00840,2022. URLhttps://arxiv.org/abs/2209.00840.
DanHendrycks,CollinBurns,StevenBasart,AndyZou,MantasMazeika,DawnSong,and
JacobSteinhardt. Measuringmassivemultitasklanguageunderstanding. InInternational
ConferenceonLearningRepresentations,2021a. URLhttps://openreview.net/forum?id=
d7KBjmI3GmQ.
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang,
DawnSong,andJacobSteinhardt. Measuringmathematicalproblemsolvingwiththe
mathdataset. NeurIPS,2021b.
WenyiHong,WeihanWang,QingsongLv,JiazhengXu,WenmengYu,JunhuiJi,YanWang,
ZihanWang,YuxiaoDong,MingDing,andJieTang. Cogagent: Avisuallanguagemodel
forguiagents,2023.
ArianHosseini,AnkitVani,DzmitryBahdanau,AlessandroSordoni,andAaronCourville.
On the compositional generalization gap of in-context learning. In Jasmijn Bastings,
YonatanBelinkov,YanaiElazar,DieuwkeHupkes,NaomiSaphra,andSarahWiegreffe
(eds.),ProceedingsoftheFifthBlackboxNLPWorkshoponAnalyzingandInterpretingNeural
NetworksforNLP,pp.272–280,AbuDhabi,UnitedArabEmirates(Hybrid),December
2022.AssociationforComputationalLinguistics.doi:10.18653/v1/2022.blackboxnlp-1.22.
URLhttps://aclanthology.org/2022.blackboxnlp-1.22.
LifuHuang,RonanLeBras,ChandraBhagavatula,andYejinChoi. CosmosQA:Machine
readingcomprehensionwithcontextualcommonsensereasoning. InKentaroInui,Jing
Jiang,VincentNg,andXiaojunWan(eds.),Proceedingsofthe2019ConferenceonEmpirical
MethodsinNaturalLanguageProcessingandthe9thInternationalJointConferenceonNatural
Language Processing (EMNLP-IJCNLP), pp. 2391–2401, Hong Kong, China, November
2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1243. URL
https://aclanthology.org/D19-1243.
AlbertQJiang,AlexandreSablayrolles,ArthurMensch,ChrisBamford,DevendraSingh
Chaplot,DiegodelasCasas,FlorianBressand,GiannaLengyel,GuillaumeLample,Lucile
Saulnier,etal. Mistral7b. arXivpreprintarXiv:2310.06825,2023.
Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary,
ChrisBamford,DevendraSinghChaplot,DiegodelasCasas,EmmaBouHanna,Florian
Bressand,etal. Mixtralofexperts. arXivpreprintarXiv:2401.04088,2024.
PangWeiKoh,ShioriSagawa,HenrikMarklund,SangMichaelXie,MarvinZhang,Akshay
Balsubramani,WeihuaHu,MichihiroYasunaga,RichardLanasPhillips,IrenaGao,etal.
Wilds: A benchmark of in-the-wild distribution shifts. In International Conference on
MachineLearning,pp.5637–5664.PMLR,2021.
HarrisonLee,RaghavGupta,AbhinavRastogi,YuanCao,BinZhang,andYonghuiWu.
Sgd-x: Abenchmarkforrobustgeneralizationinschema-guideddialoguesystems. In
ProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pp.10938–10946,
2022.
BingbinLiu,JordanTAsh,SurbhiGoel,AkshayKrishnamurthy,andCyrilZhang. Trans-
formerslearnshortcutstoautomata. InTheEleventhInternationalConferenceonLearning
Representations,2022.
AmanMadaanandAmirYazdanbakhsh. Textandpatterns: Foreffectivechainofthought,
ittakestwototango. arXivpreprintarXiv:2209.07686,2022.
11Prepreint. Underreview.
AaronMeurer,ChristopherP.Smith,MateuszPaprocki,OndrˇejCˇert´ık,SergeyB.Kirpichev,
Matthew Rocklin, Amit Kumar, Sergiu Ivanov, Jason K. Moore, Sartaj Singh, Thilina
Rathnayake, SeanVig, BrianE.Granger, RichardP.Muller, FrancescoBonazzi, Harsh
Gupta,ShivamVats,FredrikJohansson,FabianPedregosa,MatthewJ.Curry,AndyR.
Terrel,Sˇteˇpa´nRoucˇka,AshutoshSaboo,IsuruFernando,SumithKulal,RobertCimrman,
andAnthonyScopatz. Sympy: symboliccomputinginpython. PeerJComputerScience,3:
e103,January2017. ISSN2376-5992. doi: 10.7717/peerj-cs.103. URLhttps://doi.org/
10.7717/peerj-cs.103.
Shen-yunMiao,Chao-ChunLiang,andKeh-YihSu. Adiversecorpusforevaluatingand
developingEnglishmathwordproblemsolvers. InDanJurafsky, JoyceChai, Natalie
Schluter,andJoelTetreault(eds.),Proceedingsofthe58thAnnualMeetingoftheAssociationfor
ComputationalLinguistics,pp.975–984,Online,July2020.AssociationforComputational
Linguistics. doi: 10.18653/v1/2020.acl-main.92. URLhttps://aclanthology.org/2020.
acl-main.92.
RodrigoNogueira,ZhiyingJiang,andJimmyLin. Investigatingthelimitationsoftrans-
formerswithsimplearithmetictasks. arXivpreprintarXiv:2102.13019,2021.
Mike Oaksford and Nick Chater. Cognition and conditionals: Probability and logic in
humanthought. 2010. URLhttps://api.semanticscholar.org/CorpusID:124383943.
OpenAI. Gpt-4technicalreport. ArXiv,abs/2303.08774,2023. URLhttps://arxiv.org/
abs/2303.08774.
Anton Osika. gpt-engineer, April 2023. URL https://github.com/gpt-engineer-org/
gpt-engineer.
Jing Qian, Hong Wang, Zekun Li, Shiyang Li, and Xifeng Yan. Limitations of language
modelsinarithmeticandsymbolicinduction. pp.9285–9298,012023. doi: 10.18653/v1/
2023.acl-long.516.
Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan.
Towards scalable multi-domain conversational agents: The schema-guided dialogue
dataset. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp.
8689–8696,2020.
KeisukeSakaguchi,RonanLeBras,ChandraBhagavatula,andYejinChoi. Winogrande: An
adversarialwinogradschemachallengeatscale. Commun.ACM,64(9):99–106,aug2021.
ISSN0001-0782. doi: 10.1145/3474381. URLhttps://doi.org/10.1145/3474381.
SoumyaSanyal,ZeyiLiao,andXiangRen. RobustLR:Adiagnosticbenchmarkforevalu-
atinglogicalrobustnessofdeductivereasoners. InYoavGoldberg,ZornitsaKozareva,
andYueZhang(eds.),Proceedingsofthe2022ConferenceonEmpiricalMethodsinNatural
LanguageProcessing,pp.9614–9631,AbuDhabi,UnitedArabEmirates,December2022.
AssociationforComputationalLinguistics. doi: 10.18653/v1/2022.emnlp-main.653. URL
https://aclanthology.org/2022.emnlp-main.653.
MaartenSap,HannahRashkin,DerekChen,RonanLeBras,andYejinChoi. SocialIQa:
Commonsensereasoningaboutsocialinteractions.InKentaroInui,JingJiang,VincentNg,
andXiaojunWan(eds.),Proceedingsofthe2019ConferenceonEmpiricalMethodsinNatural
LanguageProcessingandthe9thInternationalJointConferenceonNaturalLanguageProcessing
(EMNLP-IJCNLP),pp.4463–4473,HongKong,China,November2019.Associationfor
ComputationalLinguistics. doi: 10.18653/v1/D19-1454. URLhttps://aclanthology.
org/D19-1454.
Abulhair Saparov and He He. Language models are greedy reasoners: A systematic
formalanalysisofchain-of-thought. InTheEleventhInternationalConferenceonLearning
Representations,2022.
Abulhair Saparov and He He. Language models are greedy reasoners: A systematic
formalanalysisofchain-of-thought. InTheEleventhInternationalConferenceonLearning
Representations,2023. URLhttps://openreview.net/forum?id=qFVVBzXxR2V.
12Prepreint. Underreview.
Abulhair Saparov, Richard Yuanzhe Pang, Vishakh Padmakumar, Nitish Joshi,
SeyedMehranKazemi,NajoungKim,andHeHe.Testingthegeneraldeductivereasoning
capacityoflargelanguagemodelsusingOODexamples. CoRR,abs/2305.15269,2023.
doi: 10.48550/arXiv.2305.15269. URLhttps://doi.org/10.48550/arXiv.2305.15269.
TimoSchick,JaneDwivedi-Yu,RobertoDess`ı,RobertaRaileanu,MariaLomeli,EricHambro,
LukeZettlemoyer,NicolaCancedda,andThomasScialom. Toolformer: Languagemodels
canteachthemselvestousetools. AdvancesinNeuralInformationProcessingSystems,36,
2024.
YongliangShen,KaitaoSong,XuTan,DongshengLi,WeimingLu,andYuetingZhuang.
Hugginggpt: Solvingaitaskswithchatgptanditsfriendsinhuggingface. Advancesin
NeuralInformationProcessingSystems,36,2024.
Significant Gravitas. AutoGPT. URL https://github.com/Significant-Gravitas/
AutoGPT.
HerbertA.SimonandAllenNewell. Humanproblemsolving: Thestateofthetheoryin
1970. AmericanPsychologist,26:145–159,1971. URLhttps://api.semanticscholar.org/
CorpusID:14405801.
VarshiniSubhash,AnnaBialas,WeiweiPan,andFinaleDoshi-Velez. Whydouniversal
adversarialattacksworkonlargelanguagemodels?: Geometrymightbetheanswer. In
TheSecondWorkshoponNewFrontiersinAdversarialMachineLearning,2023.
Oyvind Tafjord, Bhavana Dalvi, and Peter Clark. Proofwriter: Generating implications,
proofs,andabductivestatementsovernaturallanguage. InFindingsoftheAssociationfor
ComputationalLinguistics: ACL-IJCNLP2021,pp.3621–3634,2021.
AlonTalmor,JonathanHerzig,NicholasLourie,andJonathanBerant. CommonsenseQA:A
questionansweringchallengetargetingcommonsenseknowledge.InJillBurstein,Christy
Doran,andThamarSolorio(eds.),Proceedingsofthe2019ConferenceoftheNorthAmerican
ChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume
1(LongandShortPapers),pp.4149–4158,Minneapolis,Minnesota,June2019.Association
forComputationalLinguistics.doi:10.18653/v1/N19-1421.URLhttps://aclanthology.
org/N19-1421.
QingyuTan,HweeTouNg,andLidongBing. Towardsbenchmarkingandimprovingthe
temporalreasoningcapabilityoflargelanguagemodels. InAnnaRogers,JordanBoyd-
Graber,andNaoakiOkazaki(eds.),Proceedingsofthe61stAnnualMeetingoftheAssociation
forComputationalLinguistics(Volume1: LongPapers),pp.14820–14835,Toronto,Canada,
July2023.AssociationforComputationalLinguistics. doi: 10.18653/v1/2023.acl-long.828.
URLhttps://aclanthology.org/2023.acl-long.828.
RuixiangTang,DehanKong,LongtaoHuang,andHuiXue. Largelanguagemodelscan
belazylearners: Analyzeshortcutsinin-contextlearning. pp.4645–4657,012023. doi:
10.18653/v1/2023.findings-acl.284.
GeminiTeam,RohanAnil,SebastianBorgeaud,YonghuiWu,Jean-BaptisteAlayrac,Jiahui
Yu,RaduSoricut,JohanSchalkwyk,AndrewMDai,AnjaHauth,etal. Gemini: afamily
ofhighlycapablemultimodalmodels. arXivpreprintarXiv:2312.11805,2023.
JidongTian,YitianLi,WenqingChen,LiqiangXiao,HaoHe,andYaohuiJin. Diagnosing
the first-order logical reasoning ability through LogicNLI. In Proceedings of the 2021
Conference on Empirical Methods in Natural Language Processing, pp. 3738–3747, Online
andPuntaCana,DominicanRepublic,November2021.AssociationforComputational
Linguistics. doi: 10.18653/v1/2021.emnlp-main.303. URLhttps://aclanthology.org/
2021.emnlp-main.303.
HugoTouvron,LouisMartin,KevinStone,PeterAlbert,AmjadAlmahairi,YasmineBabaei,
Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2:
Openfoundationandfine-tunedchatmodels. arXivpreprintarXiv:2307.09288,2023.
13Prepreint. Underreview.
JindongWang,HUXixu,WenxinHou,HaoChen,RunkaiZheng,YidongWang,LinyiYang,
WeiYe,HaojunHuang,XiuboGeng,etal. Ontherobustnessofchatgpt: Anadversarial
andout-of-distributionperspective. InICLR2023WorkshoponTrustworthyandReliable
Large-ScaleMachineLearningModels,2023.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V
Le,DennyZhou,etal. Chain-of-thoughtpromptingelicitsreasoninginlargelanguage
models. AdvancesinNeuralInformationProcessingSystems,35:24824–24837,2022.
ChenfeiWu,ShengmingYin,WeizhenQi,XiaodongWang,ZechengTang,andNanDuan.
Visual chatgpt: Talking, drawing and editing with visual foundation models. arXiv
preprintarXiv:2303.04671,2023.
ZhangdieYuan,SongboHu,IvanVulic´,AnnaKorhonen,andZaiqiaoMeng. Canpretrained
language models (yet) reason deductively? In Proceedings of the 17th Conference of the
EuropeanChapteroftheAssociationforComputationalLinguistics,pp.1439–1454,2023.
RowanZellers,AriHoltzman,YonatanBisk,AliFarhadi,andYejinChoi. Hellaswag: Can
amachinereallyfinishyoursentence? InProceedingsofthe57thAnnualMeetingofthe
AssociationforComputationalLinguistics,pp.4791–4800,2019.
HonghuaZhang,LiunianHaroldLi,TaoMeng,Kai-WeiChang,andGuyVandenBroeck.
Ontheparadoxoflearningtoreasonfromdata. InProceedingsofthe32ndInternational
JointConferenceonArtificialIntelligence(IJCAI),aug2023. URLhttp://starai.cs.ucla.
edu/papers/ZhangIJCAI23.pdf.
BoyuanZheng,BoyuGou,JihyungKil,HuanSun,andYuSu. Gpt-4v(ision)isageneralist
webagent,ifgrounded. arXivpreprintarXiv:2401.01614,2024.
Ben Zhou, Daniel Khashabi, Qiang Ning, and Dan Roth. “going on a vacation” takes
longerthan“goingforawalk”: Astudyoftemporalcommonsenseunderstanding. In
Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
andthe9thInternationalJointConferenceonNaturalLanguageProcessing(EMNLP-IJCNLP).
AssociationforComputationalLinguistics,2019.
14Prepreint. Underreview.
A SampleFlightSchema
Figure8: SchemaforBritishAirwaysflightbetweenMexicoCityandParison04/24/2024
B Samplesfromdifferentslot/mintermconfigurations
B.1 2slots,2minterms
Figure9: SamplequeryinGroundCocoawith2slotsand2minterms.
B.2 3slots,2minterms
Figure10: SamplequeryinGroundCocoawith3slotsand2minterms.
B.3 4slots,2minterms
Figure11: SamplequeryinGroundCocoawith4slotsand2minterms.
B.4 4slots,3minterms
Figure12: SamplequeryinGroundCocoawith4slotsand3minterms.
15Prepreint. Underreview.
B.5 5slots,2minterms
Figure13: SamplequeryinGroundCocoawith5slotsand2minterms.
B.6 6slots,2minterms
Figure14: SamplequeryinGroundCocoawith6slotsand2minterms.
C PromptsusedinModelEvaluation
Figure15: EvaluationpromptwithoutCoT.
16Prepreint. Underreview.
Figure16: EvaluationpromptusingCoT-partial.
17Prepreint. Underreview.
D End-to-EndGenerationProcess
Figure17: End-to-Endquerygenerationwith2slotsand2minterms.
18