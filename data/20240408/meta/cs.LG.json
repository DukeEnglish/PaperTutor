[
    {
        "title": "Watermark-based Detection and Attribution of AI-Generated Content",
        "authors": "Zhengyuan JiangMoyang GuoYuepeng HuNeil Zhenqiang Gong",
        "links": "http://arxiv.org/abs/2404.04254v1",
        "entry_id": "http://arxiv.org/abs/2404.04254v1",
        "pdf_url": "http://arxiv.org/pdf/2404.04254v1",
        "summary": "Several companies--such as Google, Microsoft, and OpenAI--have deployed\ntechniques to watermark AI-generated content to enable proactive detection.\nHowever, existing literature mainly focuses on user-agnostic detection.\nAttribution aims to further trace back the user of a generative-AI service who\ngenerated a given content detected as AI-generated. Despite its growing\nimportance, attribution is largely unexplored. In this work, we aim to bridge\nthis gap by providing the first systematic study on watermark-based, user-aware\ndetection and attribution of AI-generated content. Specifically, we\ntheoretically study the detection and attribution performance via rigorous\nprobabilistic analysis. Moreover, we develop an efficient algorithm to select\nwatermarks for the users to enhance attribution performance. Both our\ntheoretical and empirical results show that watermark-based detection and\nattribution inherit the accuracy and (non-)robustness properties of the\nwatermarking method.",
        "updated": "2024-04-05 17:58:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.04254v1"
    },
    {
        "title": "Growing Q-Networks: Solving Continuous Control Tasks with Adaptive Control Resolution",
        "authors": "Tim SeydePeter WernerWilko SchwartingMarkus WulfmeierDaniela Rus",
        "links": "http://arxiv.org/abs/2404.04253v1",
        "entry_id": "http://arxiv.org/abs/2404.04253v1",
        "pdf_url": "http://arxiv.org/pdf/2404.04253v1",
        "summary": "Recent reinforcement learning approaches have shown surprisingly strong\ncapabilities of bang-bang policies for solving continuous control benchmarks.\nThe underlying coarse action space discretizations often yield favourable\nexploration characteristics while final performance does not visibly suffer in\nthe absence of action penalization in line with optimal control theory. In\nrobotics applications, smooth control signals are commonly preferred to reduce\nsystem wear and energy efficiency, but action costs can be detrimental to\nexploration during early training. In this work, we aim to bridge this\nperformance gap by growing discrete action spaces from coarse to fine control\nresolution, taking advantage of recent results in decoupled Q-learning to scale\nour approach to high-dimensional action spaces up to dim(A) = 38. Our work\nindicates that an adaptive control resolution in combination with value\ndecomposition yields simple critic-only algorithms that yield surprisingly\nstrong performance on continuous control tasks.",
        "updated": "2024-04-05 17:58:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.04253v1"
    },
    {
        "title": "Evaluating Adversarial Robustness: A Comparison Of FGSM, Carlini-Wagner Attacks, And The Role of Distillation as Defense Mechanism",
        "authors": "Trilokesh Ranjan SarkarNilanjan DasPralay Sankar MaitraBijoy SomeRitwik SahaOrijita AdhikaryBishal BoseJaydip Sen",
        "links": "http://arxiv.org/abs/2404.04245v1",
        "entry_id": "http://arxiv.org/abs/2404.04245v1",
        "pdf_url": "http://arxiv.org/pdf/2404.04245v1",
        "summary": "This technical report delves into an in-depth exploration of adversarial\nattacks specifically targeted at Deep Neural Networks (DNNs) utilized for image\nclassification. The study also investigates defense mechanisms aimed at\nbolstering the robustness of machine learning models. The research focuses on\ncomprehending the ramifications of two prominent attack methodologies: the Fast\nGradient Sign Method (FGSM) and the Carlini-Wagner (CW) approach. These attacks\nare examined concerning three pre-trained image classifiers: Resnext50_32x4d,\nDenseNet-201, and VGG-19, utilizing the Tiny-ImageNet dataset. Furthermore, the\nstudy proposes the robustness of defensive distillation as a defense mechanism\nto counter FGSM and CW attacks. This defense mechanism is evaluated using the\nCIFAR-10 dataset, where CNN models, specifically resnet101 and Resnext50_32x4d,\nserve as the teacher and student models, respectively. The proposed defensive\ndistillation model exhibits effectiveness in thwarting attacks such as FGSM.\nHowever, it is noted to remain susceptible to more sophisticated techniques\nlike the CW attack. The document presents a meticulous validation of the\nproposed scheme. It provides detailed and comprehensive results, elucidating\nthe efficacy and limitations of the defense mechanisms employed. Through\nrigorous experimentation and analysis, the study offers insights into the\ndynamics of adversarial attacks on DNNs, as well as the effectiveness of\ndefensive strategies in mitigating their impact.",
        "updated": "2024-04-05 17:51:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.04245v1"
    },
    {
        "title": "Physical Property Understanding from Language-Embedded Feature Fields",
        "authors": "Albert J. ZhaiYuan ShenEmily Y. ChenGloria X. WangXinlei WangSheng WangKaiyu GuanShenlong Wang",
        "links": "http://arxiv.org/abs/2404.04242v1",
        "entry_id": "http://arxiv.org/abs/2404.04242v1",
        "pdf_url": "http://arxiv.org/pdf/2404.04242v1",
        "summary": "Can computers perceive the physical properties of objects solely through\nvision? Research in cognitive science and vision science has shown that humans\nexcel at identifying materials and estimating their physical properties based\npurely on visual appearance. In this paper, we present a novel approach for\ndense prediction of the physical properties of objects using a collection of\nimages. Inspired by how humans reason about physics through vision, we leverage\nlarge language models to propose candidate materials for each object. We then\nconstruct a language-embedded point cloud and estimate the physical properties\nof each 3D point using a zero-shot kernel regression approach. Our method is\naccurate, annotation-free, and applicable to any object in the open world.\nExperiments demonstrate the effectiveness of the proposed approach in various\nphysical property reasoning tasks, such as estimating the mass of common\nobjects, as well as other properties like friction and hardness.",
        "updated": "2024-04-05 17:45:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.04242v1"
    },
    {
        "title": "Dynamic Conditional Optimal Transport through Simulation-Free Flows",
        "authors": "Gavin KerriganGiosue MiglioriniPadhraic Smyth",
        "links": "http://arxiv.org/abs/2404.04240v1",
        "entry_id": "http://arxiv.org/abs/2404.04240v1",
        "pdf_url": "http://arxiv.org/pdf/2404.04240v1",
        "summary": "We study the geometry of conditional optimal transport (COT) and prove a\ndynamical formulation which generalizes the Benamou-Brenier Theorem. With these\ntools, we propose a simulation-free flow-based method for conditional\ngenerative modeling. Our method couples an arbitrary source distribution to a\nspecified target distribution through a triangular COT plan. We build on the\nframework of flow matching to train a conditional generative model by\napproximating the geodesic path of measures induced by this COT plan. Our\ntheory and methods are applicable in the infinite-dimensional setting, making\nthem well suited for inverse problems. Empirically, we demonstrate our proposed\nmethod on two image-to-image translation tasks and an infinite-dimensional\nBayesian inverse problem.",
        "updated": "2024-04-05 17:41:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.04240v1"
    }
]