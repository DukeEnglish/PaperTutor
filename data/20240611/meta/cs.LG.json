[
    {
        "title": "Decentralized Personalized Federated Learning",
        "authors": "Salma KharratMarco CaniniSamuel Horvath",
        "links": "http://arxiv.org/abs/2406.06520v1",
        "entry_id": "http://arxiv.org/abs/2406.06520v1",
        "pdf_url": "http://arxiv.org/pdf/2406.06520v1",
        "summary": "This work tackles the challenges of data heterogeneity and communication\nlimitations in decentralized federated learning. We focus on creating a\ncollaboration graph that guides each client in selecting suitable collaborators\nfor training personalized models that leverage their local data effectively.\nOur approach addresses these issues through a novel, communication-efficient\nstrategy that enhances resource efficiency. Unlike traditional methods, our\nformulation identifies collaborators at a granular level by considering\ncombinatorial relations of clients, enhancing personalization while minimizing\ncommunication overhead. We achieve this through a bi-level optimization\nframework that employs a constrained greedy algorithm, resulting in a\nresource-efficient collaboration graph for personalized learning. Extensive\nevaluation against various baselines across diverse datasets demonstrates the\nsuperiority of our method, named DPFL. DPFL consistently outperforms other\napproaches, showcasing its effectiveness in handling real-world data\nheterogeneity, minimizing communication overhead, enhancing resource\nefficiency, and building personalized models in decentralized federated\nlearning scenarios.",
        "updated": "2024-06-10 17:58:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.06520v1"
    },
    {
        "title": "Data Augmentation for Multivariate Time Series Classification: An Experimental Study",
        "authors": "Romain IlbertThai V. HoangZonghua Zhang",
        "links": "http://arxiv.org/abs/2406.06518v1",
        "entry_id": "http://arxiv.org/abs/2406.06518v1",
        "pdf_url": "http://arxiv.org/pdf/2406.06518v1",
        "summary": "Our study investigates the impact of data augmentation on the performance of\nmultivariate time series models, focusing on datasets from the UCR archive.\nDespite the limited size of these datasets, we achieved classification accuracy\nimprovements in 10 out of 13 datasets using the Rocket and InceptionTime\nmodels. This highlights the essential role of sufficient data in training\neffective models, paralleling the advancements seen in computer vision. Our\nwork delves into adapting and applying existing methods in innovative ways to\nthe domain of multivariate time series classification. Our comprehensive\nexploration of these techniques sets a new standard for addressing data\nscarcity in time series analysis, emphasizing that diverse augmentation\nstrategies are crucial for unlocking the potential of both traditional and deep\nlearning models. Moreover, by meticulously analyzing and applying a variety of\naugmentation techniques, we demonstrate that strategic data enrichment can\nenhance model accuracy. This not only establishes a benchmark for future\nresearch in time series analysis but also underscores the importance of\nadopting varied augmentation approaches to improve model performance in the\nface of limited data availability.",
        "updated": "2024-06-10 17:58:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.06518v1"
    },
    {
        "title": "Distribution-Free Predictive Inference under Unknown Temporal Drift",
        "authors": "Elise HanChengpiao HuangKaizheng Wang",
        "links": "http://arxiv.org/abs/2406.06516v1",
        "entry_id": "http://arxiv.org/abs/2406.06516v1",
        "pdf_url": "http://arxiv.org/pdf/2406.06516v1",
        "summary": "Distribution-free prediction sets play a pivotal role in uncertainty\nquantification for complex statistical models. Their validity hinges on\nreliable calibration data, which may not be readily available as real-world\nenvironments often undergo unknown changes over time. In this paper, we propose\na strategy for choosing an adaptive window and use the data therein to\nconstruct prediction sets. The window is selected by optimizing an estimated\nbias-variance tradeoff. We provide sharp coverage guarantees for our method,\nshowing its adaptivity to the underlying temporal drift. We also illustrate its\nefficacy through numerical experiments on synthetic and real data.",
        "updated": "2024-06-10 17:55:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.06516v1"
    },
    {
        "title": "Random Features Approximation for Control-Affine Systems",
        "authors": "Kimia KazemianYahya SattarSarah Dean",
        "links": "http://arxiv.org/abs/2406.06514v1",
        "entry_id": "http://arxiv.org/abs/2406.06514v1",
        "pdf_url": "http://arxiv.org/pdf/2406.06514v1",
        "summary": "Modern data-driven control applications call for flexible nonlinear models\nthat are amenable to principled controller synthesis and realtime feedback.\nMany nonlinear dynamical systems of interest are control affine. We propose two\nnovel classes of nonlinear feature representations which capture control affine\nstructure while allowing for arbitrary complexity in the state dependence. Our\nmethods make use of random features (RF) approximations, inheriting the\nexpressiveness of kernel methods at a lower computational cost. We formalize\nthe representational capabilities of our methods by showing their relationship\nto the Affine Dot Product (ADP) kernel proposed by Casta\\~neda et al. (2021)\nand a novel Affine Dense (AD) kernel that we introduce. We further illustrate\nthe utility by presenting a case study of data-driven optimization-based\ncontrol using control certificate functions (CCF). Simulation experiments on a\ndouble pendulum empirically demonstrate the advantages of our methods.",
        "updated": "2024-06-10 17:54:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.06514v1"
    },
    {
        "title": "Robust Distribution Learning with Local and Global Adversarial Corruptions",
        "authors": "Sloan NietertZiv GoldfeldSoroosh Shafiee",
        "links": "http://arxiv.org/abs/2406.06509v1",
        "entry_id": "http://arxiv.org/abs/2406.06509v1",
        "pdf_url": "http://arxiv.org/pdf/2406.06509v1",
        "summary": "We consider learning in an adversarial environment, where an\n$\\varepsilon$-fraction of samples from a distribution $P$ are arbitrarily\nmodified (*global* corruptions) and the remaining perturbations have average\nmagnitude bounded by $\\rho$ (*local* corruptions). Given access to $n$ such\ncorrupted samples, we seek a computationally efficient estimator $\\hat{P}_n$\nthat minimizes the Wasserstein distance $\\mathsf{W}_1(\\hat{P}_n,P)$. In fact,\nwe attack the fine-grained task of minimizing $\\mathsf{W}_1(\\Pi_\\# \\hat{P}_n,\n\\Pi_\\# P)$ for all orthogonal projections $\\Pi \\in \\mathbb{R}^{d \\times d}$,\nwith performance scaling with $\\mathrm{rank}(\\Pi) = k$. This allows us to\naccount simultaneously for mean estimation ($k=1$), distribution estimation\n($k=d$), as well as the settings interpolating between these two extremes. We\ncharacterize the optimal population-limit risk for this task and then develop\nan efficient finite-sample algorithm with error bounded by $\\sqrt{\\varepsilon\nk} + \\rho + d^{O(1)}\\tilde{O}(n^{-1/k})$ when $P$ has bounded moments of order\n$2+\\delta$, for constant $\\delta > 0$. For data distributions with bounded\ncovariance, our finite-sample bounds match the minimax population-level optimum\nfor large sample sizes. Our efficient procedure relies on a novel trace norm\napproximation of an ideal yet intractable 2-Wasserstein projection estimator.\nWe apply this algorithm to robust stochastic optimization, and, in the process,\nuncover a new method for overcoming the curse of dimensionality in Wasserstein\ndistributionally robust optimization.",
        "updated": "2024-06-10 17:48:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.06509v1"
    }
]