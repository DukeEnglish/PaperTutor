[
    {
        "title": "Direct Preference Optimization for Suppressing Hallucinated Prior Exams in Radiology Report Generation",
        "authors": "Oishi BanerjeeHong-Yu ZhouSubathra AdithanStephen KwakKay WuPranav Rajpurkar",
        "links": "http://arxiv.org/abs/2406.06496v1",
        "entry_id": "http://arxiv.org/abs/2406.06496v1",
        "pdf_url": "http://arxiv.org/pdf/2406.06496v1",
        "summary": "Recent advances in generative vision-language models (VLMs) have exciting\npotential implications for AI in radiology, yet VLMs are also known to produce\nhallucinations, nonsensical text, and other unwanted behaviors that can waste\nclinicians' time and cause patient harm. Drawing on recent work on direct\npreference optimization (DPO), we propose a simple method for modifying the\nbehavior of pretrained VLMs performing radiology report generation by\nsuppressing unwanted types of generations. We apply our method to the\nprevention of hallucinations of prior exams, addressing a long-established\nproblem behavior in models performing chest X-ray report generation. Across our\nexperiments, we find that DPO fine-tuning achieves a 3.2-4.8x reduction in\nlines hallucinating prior exams while maintaining model performance on clinical\naccuracy metrics. Our work is, to the best of our knowledge, the first work to\napply DPO to medical VLMs, providing a data- and compute- efficient way to\nsuppress problem behaviors while maintaining overall clinical accuracy.",
        "updated": "2024-06-10 17:31:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.06496v1"
    },
    {
        "title": "Can Language Models Serve as Text-Based World Simulators?",
        "authors": "Ruoyao WangGraham ToddZiang XiaoXingdi YuanMarc-Alexandre CôtéPeter ClarkPeter Jansen",
        "links": "http://arxiv.org/abs/2406.06485v1",
        "entry_id": "http://arxiv.org/abs/2406.06485v1",
        "pdf_url": "http://arxiv.org/pdf/2406.06485v1",
        "summary": "Virtual environments play a key role in benchmarking advances in complex\nplanning and decision-making tasks but are expensive and complicated to build\nby hand. Can current language models themselves serve as world simulators,\ncorrectly predicting how actions change different world states, thus bypassing\nthe need for extensive manual coding? Our goal is to answer this question in\nthe context of text-based simulators. Our approach is to build and use a new\nbenchmark, called ByteSized32-State-Prediction, containing a dataset of text\ngame state transitions and accompanying game tasks. We use this to directly\nquantify, for the first time, how well LLMs can serve as text-based world\nsimulators. We test GPT-4 on this dataset and find that, despite its impressive\nperformance, it is still an unreliable world simulator without further\ninnovations. This work thus contributes both new insights into current LLM's\ncapabilities and weaknesses, as well as a novel benchmark to track future\nprogress as new models appear.",
        "updated": "2024-06-10 17:24:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.06485v1"
    },
    {
        "title": "Parallelizing Linear Transformers with the Delta Rule over Sequence Length",
        "authors": "Songlin YangBailin WangYu ZhangYikang ShenYoon Kim",
        "links": "http://arxiv.org/abs/2406.06484v1",
        "entry_id": "http://arxiv.org/abs/2406.06484v1",
        "pdf_url": "http://arxiv.org/pdf/2406.06484v1",
        "summary": "Transformers with linear attention (i.e., linear transformers) and\nstate-space models have recently been suggested as a viable linear-time\nalternative to transformers with softmax attention. However, these models still\nunderperform transformers especially on tasks that require in-context\nretrieval. While more expressive variants of linear transformers which replace\nthe additive outer-product update in linear transformers with the delta rule\nhave been found to be more effective at associative recall, existing algorithms\nfor training such models do not parallelize over sequence length and are thus\ninefficient to train on modern hardware. This work describes a\nhardware-efficient algorithm for training linear transformers with the delta\nrule, which exploits a memory-efficient representation for computing products\nof Householder matrices. This algorithm allows us to scale up DeltaNet to\nstandard language modeling settings. We train a 1.3B model for 100B tokens and\nfind that it outperforms recent linear-time baselines such as Mamba and GLA in\nterms of perplexity and zero-shot performance on downstream tasks (including on\ntasks that focus on recall). We also experiment with two hybrid models which\ncombine DeltaNet layers with (1) sliding-window attention layers every other\nlayer or (2) two global attention layers, and find that these hybrid models\noutperform strong transformer baselines.",
        "updated": "2024-06-10 17:24:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.06484v1"
    },
    {
        "title": "Towards a Personal Health Large Language Model",
        "authors": "Justin CosentinoAnastasiya BelyaevaXin LiuNicholas A. FurlotteZhun YangChace LeeErik SchenckYojan PatelJian CuiLogan Douglas SchneiderRobby BryantRyan G. GomesAllen JiangRoy LeeYun LiuJavier PerezJameson K. RogersCathy SpeedShyam TailorMegan WalkerJeffrey YuTim AlthoffConor HeneghanJohn HernandezMark MalhotraLeor SternYossi MatiasGreg S. CorradoShwetak PatelShravya ShettyJiening ZhanShruthi PrabhakaraDaniel McDuffCory Y. McLean",
        "links": "http://arxiv.org/abs/2406.06474v1",
        "entry_id": "http://arxiv.org/abs/2406.06474v1",
        "pdf_url": "http://arxiv.org/pdf/2406.06474v1",
        "summary": "In health, most large language model (LLM) research has focused on clinical\ntasks. However, mobile and wearable devices, which are rarely integrated into\nsuch tasks, provide rich, longitudinal data for personal health monitoring.\nHere we present Personal Health Large Language Model (PH-LLM), fine-tuned from\nGemini for understanding and reasoning over numerical time-series personal\nhealth data. We created and curated three datasets that test 1) production of\npersonalized insights and recommendations from sleep patterns, physical\nactivity, and physiological responses, 2) expert domain knowledge, and 3)\nprediction of self-reported sleep outcomes. For the first task we designed 857\ncase studies in collaboration with domain experts to assess real-world\nscenarios in sleep and fitness. Through comprehensive evaluation of\ndomain-specific rubrics, we observed that Gemini Ultra 1.0 and PH-LLM are not\nstatistically different from expert performance in fitness and, while experts\nremain superior for sleep, fine-tuning PH-LLM provided significant improvements\nin using relevant domain knowledge and personalizing information for sleep\ninsights. We evaluated PH-LLM domain knowledge using multiple choice sleep\nmedicine and fitness examinations. PH-LLM achieved 79% on sleep and 88% on\nfitness, exceeding average scores from a sample of human experts. Finally, we\ntrained PH-LLM to predict self-reported sleep quality outcomes from textual and\nmultimodal encoding representations of wearable data, and demonstrate that\nmultimodal encoding is required to match performance of specialized\ndiscriminative models. Although further development and evaluation are\nnecessary in the safety-critical personal health domain, these results\ndemonstrate both the broad knowledge and capabilities of Gemini models and the\nbenefit of contextualizing physiological data for personal health applications\nas done with PH-LLM.",
        "updated": "2024-06-10 17:16:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.06474v1"
    },
    {
        "title": "Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning",
        "authors": "Joongwon KimBhargavi ParanjapeTushar KhotHannaneh Hajishirzi",
        "links": "http://arxiv.org/abs/2406.06469v1",
        "entry_id": "http://arxiv.org/abs/2406.06469v1",
        "pdf_url": "http://arxiv.org/pdf/2406.06469v1",
        "summary": "Language agents perform complex tasks by using tools to execute each step\nprecisely. However, most existing agents are based on proprietary models or\ndesigned to target specific tasks, such as mathematics or multi-hop question\nanswering. We introduce Husky, a holistic, open-source language agent that\nlearns to reason over a unified action space to address a diverse set of\ncomplex tasks involving numerical, tabular, and knowledge-based reasoning.\nHusky iterates between two stages: 1) generating the next action to take\ntowards solving a given task and 2) executing the action using expert models\nand updating the current solution state. We identify a thorough ontology of\nactions for addressing complex tasks and curate high-quality data to train\nexpert models for executing these actions. Our experiments show that Husky\noutperforms prior language agents across 14 evaluation datasets. Moreover, we\nintroduce HuskyQA, a new evaluation set which stress tests language agents for\nmixed-tool reasoning, with a focus on retrieving missing knowledge and\nperforming numerical reasoning. Despite using 7B models, Husky matches or even\nexceeds frontier LMs such as GPT-4 on these tasks, showcasing the efficacy of\nour holistic approach in addressing complex reasoning problems. Our code and\nmodels are available at https://github.com/agent-husky/Husky-v1.",
        "updated": "2024-06-10 17:07:25 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.06469v1"
    }
]