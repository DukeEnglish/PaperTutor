DECEPTION ANALYSIS WITH ARTIFICIAL INTELLIGENCE: AN
INTERDISCIPLINARY PERSPECTIVE ∗
StefanSarkadi
,
Dept. ofInformatics
King’sCollegeLondon
London,UK
stefan.sarkadi@ekcl.ac.uk
ABSTRACT
Humansandmachinesinteractmorefrequentlythaneverandoursocietiesarebecomingincreasingly
hybrid. Aconsequenceofthishybridisationisthedegradationofsocietaltrustduetotheprevalence
of AI-enabled deception. Yet, despite our understanding of the role of trust in AI in the recent
years,westilldonothaveacomputationaltheorytobeabletofullyunderstandandexplaintherole
deceptionplaysinthiscontext. Thisisaproblembecausewhileourabilitytoexplaindeceptionin
hybridsocietiesisdelayed,thedesignofAIagentsmaykeepadvancingtowardsfullyautonomous
deceptivemachines,whichwouldposenewchallengestodealingwithdeception. Inthispaperwe
buildatimelyandmeaningfulinterdisciplinaryperspectiveondeceptiveAIandreinforcea20year
oldsocio-cognitiveperspectiveontrustanddeception,byproposingthedevelopmentofDAMAS-
aholisticMulti-AgentSystems(MAS)frameworkforthesocio-cognitivemodellingandanalysis
ofdeception. Inanutshellthispapercoversthetopicofmodellingandexplainingdeceptionusing
AI approaches from the perspectives of Computer Science, Philosophy, Psychology, Ethics, and
IntelligenceAnalysis.
Keywords DeceptionAnalysis·DeceptiveAI·IntelligenceAnalysis·Argumentation·Multi-AgentSystems
1 Introduction
History,Economics,Politics,Philosophy,CommunicationSciences,Sociology,andtheCognitiveScienceshavelooked
atdeceptionfromperspectivesthatarepredominantlyanthropocentric. Thus,thesignificantknowledgewehaveabout
deceptionrevolvesarounditshumannature. Thisacquiredknowledgeemphasisesthatdeceptionplaysanimportantrole
forhumansandthatdeceptionisamulti-layeredphenomenonwhichtakesnumerousformsduringsocialinteractions.
However,morerecently,theanthropocentricgriponunderstandingdeceptionhasweakened. Researchondeception
(anditsdetection)isexpandingbeyondhumanagents,todeceptivetechnologies,duetothecurrenthybridisationof
oursocieties. Hybridsocietiesare‘self-organizing,collectivesystems,whicharecomposedofdifferentcomponents,
forexample,naturalandartificialparts(bio-hybrid)orhumanbeingsinteractingwithandthroughtechnicalsystems
(socio-technical)’Hamannetal.[2016]. Nowadays,AItechnologiesplayacrucialroleinhybridsocieties,butresearch
inAIanddeceptionhasnotprogressedenoughtoallowustounderstandandpredicthowadvancementsinthedesign
ofAIagentswillimpacthybridsocieties.
AparticularthreattothehybridisationofsocietiesisthedevelopmentoffullyautonomousdeceptiveAIagentsthat
willbeabletoformtheirownreasonsandmethodstoperformdeception,aswellasout-thinkandoutsmarthumans
andotherAIagentsSarkadi[2021]. ByfullyautonomousdeceptiveAIagentwemeanneitherthealreadyexisting
human-scripted ‘mindless’ chatterbots which follow a pre-programmed script to deceive Mauldin [1994], nor the
‘clueless’stochasticparrotsBenderetal.[2021]whichblurtoutsentenceswithouthavinganysenseoftheirmeaning
in-context,butAIagentsinthelikesoftheconceptualmachinesthattrickthejudgesintheImitationGameTuring
[1950]. Inparticular,wemeanAIagentsinthelikesoftheonesformallydescribedbyCohenandLevesque[1985]orin
∗StefanSarkadi.DeceptionAnalysiswithArtificialIntelligence:AnInterdisciplinaryPerspective.(WorkinProgress)
,
4202
nuJ
9
]AM.sc[
1v42750.6042:viXraSarkadi. DeceptionAnalysiswithArtificialIntelligence
thelikesofHamblinmachinesStaines[2018],which,inadditiontobeingabletoreasonaboutwhattheycommunicate
toothersinvariouscontextsandsituationsandhowtheircommunicativeactionscausechangesinthemindsofothers,
alsohavedeceptivemotives.
TomakeinformeddecisionsregardingthedevelopmentanddeploymentofdeceptiveAIagentsweneedtounderstand
howtheyinteractwithhumansandwitheachother. Todothis,wecancomputationallymodelhybridsocietiesand
observetheircognitiveprocessesandemergentbehaviour. Thefocusofthispaperispreciselyonthemodellingof
artificialdeceptiveagentsinsidesocietiestostudyandexplainpotentialoutcomes.
Research in multi-agent systems (MAS) aims to build models that integrate the social, behavioural and cognitive
components of trust and deception. About 20 years ago, Castelfranchi and Tan [2001, 2002] emphasised that this
ismostimportantinhybridhuman-agentinteractions,raisingtheissuethatinorderforagents(humanorartificial)
toreasonaboutthetrustworthinessoftheircounterpartsindifferentcontexts,atheoryofbothtrustanddeceptionis
necessary. CastelfranchiandTan[2002]indicatedmultiplelevelsoftrustsuchastrustinone’sagentandmediating
agents,trustintheMASenvironmentandinfrastructure,trustinpotentialpartner(collaborator)agents,andfinallytrust
inauthorities. TheirperspectiveisreinforcedbytheonepresentedbyFalconeetal.[2001]ontrustincyber-societies,
whichisbecomingmorerelevantgiventheincreasingnumberandcomplexityofhybridinteractionsbetweenhumans
andartificialagents. Sofar,mostworkhasfocusedonmodellingvariousaspectsoftrust,independentofdeception,as
canbeobservedbycomparingthetrendinFig.1atotheoneinFig.1b. Hence,thedevelopmentofdeceptivemachines
forthepurposeofbuildingaholisticsocio-cognitivetheoryhasbeenscarce,andwhenitdidhappen,thefocuswas
mostlyonparticularandverynarrowaspectsofdeception.
Whyisthisaproblem? Becauseduetoitsemergenceinhybridsocieties,deceptioncanleadtoaTragedyofTheDigital
Commons,whereAIagentsmaliciouslyexploitandpolluteinformationsharedwithhumansandotherAIagentsGreco
andFloridi[2004],Sarkadietal.[2021a]. Ifwewanttounderstanditsconditions,consequences,when,why,how,
towhomithappensandwhoisresponsibleforit,thenmostofdeception’scomponentsandformscannotbetreated
independently.
Intherealworld,theareaofIntelligenceAnalysistriestounderstandcomplexphenomenaholistically-invarious
scenarios and contexts, and weighs the risks and impacts of these phenomena. One of the most difficult of these
phenomenatoexplainisconsideredtobetheoneofdeception. Hence,tounderstanditholistically,theIntelligence
communityhasdevelopedrigorousmethodologiesforperformingtheprocessofinferencetothebestexplanation
(IBE) Heuer [1999]. But how do analysts actually explain and make sense of complex and potentially deceptive
agentinteractions? AccordingtoFerris[1989],intelligenceanalystsandhistoriansofdeceptiontrytounderstandtwo
processes,namelywhatcausesdeceptionandwhatpreventsdeceptionfrombeingcaused. Causationandcausation
preventionofdeceptionalsoneedtobeunderstoodincontextandaspartofanoverarchingnarrative. Themainmethods
forunderstandingdeceptioninIntelligenceAnalysiscomeintheformofstructuredanalytictechniques(SATs-notto
beconfusedwithSATsolversinComputerScience!),mostnotablytheAnalysisofCompetingHypotheses(ACH)and
itsderivationsthatareusedbyintelligenceanalyststodetectdeceptionandreducecognitiveloadandbiasHeuer[1999].
However,despitebeingdesignedtoexhaustallpossiblescenariosofdeceptionanddeceptioncausationpreventionin
complexcases,thesemethodshaveprovedtoberathertedioustoperformbyanalysts-theyarecognitivelydemanding
VanGelder[2008],Popeetal.[2006].
In this paper, we aim to define an AI-based framework, namely DAMAS, which could significantly enhance the
modellingandexplanationofdeceptioninhybridsocieties,byfollowingtheperspectiveofIntelligenceAnalysis.
2 TheoriesandComponentsofDeception
Tobeabletomodelaphenomenonwithinasystem,wemustfirstunderstandwhatthatphenomenonmeans,e.g. havea
cleardefinitionofthephenomenonanditseventualunderlyingcomponents. Inthissectionwewillintroducethereader
tothemainphilosophicaldefinitionsandpsychologicalapproachesinthestudyofdeception. Thesearenecessaryfor
introducingtheanthropologicalviewondeception,namelyhowdeceptionisunderstoodinrelationtohumannature.
Whatwealsointroducearevarioustermsandcomponentsthataresummonedtodescribedeception,andwewillshow
howthesetermsmostlyrefertosocio-cognitiveprocessesinhumans. Thesetermsanddefinitionsareusedtorefer
tovariousformsofdeceptiveAIinhybridsocietiesandunderstanddeceptionfromacomputationalsocio-cognitive
perspective,crucialforproposingtheDAMASframework.
2Sarkadi. DeceptionAnalysiswithArtificialIntelligence
(a)Totalnumberofpublications(1480)includingtheterm(b)Totalnumberofpublications(10493)includingtheterm
‘deception’. ‘trust’.
Figure1: NumberofpublicationswithrespectivetermsinthetitleandabstractcategorisedinthefieldofAIfrom2000
until2022. Thesearchengineforpublicationsusediswww.dimensions.ai,theareaofresearchusedtofilterresultswas
‘0801ArtificialIntelligenceandImageProcessing’. Chartwasprintedon13thJanuary2022.
Figure2: DAMASwouldactasabridgebetweenAIexpertiseandthemethodsusedinintelligenceanalysistoexplain
deceptionholisticallyusingIBE.
3Sarkadi. DeceptionAnalysiswithArtificialIntelligence
2.1 PhilosophicalPerspectives
Philosophyhasmostlydealtwithdefinitionsofdeception. Whatisalie? Whatisbullshit? Aretheydifferent? What
makesthemdifferent? Howdoliesandbullshitdifferfromdeception? Isdeceptionintentional,e.g. musttherebe
agencyandintentbehindit? Orcandeceptionhappenwithoutintention?
Thefollowing,epistemicallyexhaustivedefinitionofdeceptionisprovidedbyChisholmandFeehan[1977],andby
Mahon[2016]:
“[...]tocauseanotherpersontoacquireafalsebelief,ortocontinuetohaveafalsebelief,ortoceaseto
haveatruebelief,orbepreventedfromacquiringatruebelief,ortoallowanotherpersontoacquire
afalsebelief,ortocontinuetohaveafalsebelief,ortoceasetohaveatruebelief,orbeprevented
fromacquiringatruebelief."
Ifwearecareful,wecanobservethatthedefinitionabovemerelyenumeratesthemodalitiesofdeception. Thatis,
itdescribesacategoryofdishonestcommunicativebehaviours,e.g. topalter,topander,toliebyomission,tolieby
commission,tellinghalf-truths,etc. thatcanbeusedtodeceive. Whileanenumerationorataxonomyofalltheways
inwhichaphenomenonmaybeinstantiatedcanbeusefultounderstandthephenomenonofdeception, according
tosomeresearchersinCommunicationTheoryitisbynomeansagoodorproperdefinitionofthephenomenonin
itselfLevine[2019]. WhatLevine[2019]suggestsisthatafunctionaldefinitionofdeceptionwouldbemoreappropriate
thanmerelylayingdownabehaviouraltaxonomy. AfunctionalperspectiveondeceptionisalsoendorsedinPhilosophy
byArtigaandPaternotte[2018]. Takingtheirsuggestionsintoaccount,afunctionaldefinitionthatweadopttodefine
deceptionandtorefertodeceptionthroughoutthepaper,withoutreducingthescopeofthediscussiontospecifictypes
ofcommunicativesocialbehaviourthatmightbeusedfordeception,isthefollowing:
Theintentionalprocessofanagent,theDeceiver,tomakeanotheragent,theTarget,tobelievesomethingistrue(false)
thattheDeceiverbelievesisfalse(true),withtheaimofachievinganulteriorgoalordesire.
To summarise, philosophical approaches of deception tend to discuss how various components, namely linguistic,
epistemic,ontological,pragmaticetc. determinetheadoptionofdifferentdefinitionsofdeception. Sofar,themost
persistentcomponenthasbeentheintenttodeceive(tocauseafalsebeliefinthetarget’smind). Basedontheintentional
componentofdeception,functionaldefinitionscanbeadoptedasageneraldefinitionofdeceptiontobeusedinAI.
2.2 Socio-CognitivePerspectives
We now turn to the Socio-Cognitive perspectives on deception, which are mainly derived from theories in Social
PsychologyandCommunicationTheory. Theseareasofresearchinformushowtounderstandhumandeception,how
to detect it, and describe what cognitive mechanisms are responsible for deceptive behaviour and communication.
Therearetwomainparadigmsinthepsychologyofdeception,namelythecue-basedapproaches,andnoncue-based
approaches.
TheaimofthispaperistoargueforthebuildingofDAMAS,whichaimstoenhancedeceptionanalysis. Inorder
tointroducethesocio-cognitivefoundationsofDAMAS,wewillmostlydiscuss(a)thenon-cuebasedtheoriesof
deception and (b) the ability of humans to model the minds of others. The reason for prioritising non-cue based
approachesovercue-basedonesisthatthelatterhaveasignificantdrawbackregardingdeceptionanalysis-theyare
biasprone. Cue-basedapproachesmostlytrytotreatpassivelyobservableinformationthatrepresentswhatliesonthe
surfaceofamuchmorecomplexsocio-cognitiveprocess. Cuescanbeeitherverbal-whatapersonsays(linguistic
behaviour)ornon-verbal-thenon-linguisticbehaviourofaperson,e.g.micro-expressions. Thistypeofapproachsolely
considersbehaviourthatisexpressedbyhumanagentsinordertoestablishwhetherthehumanisbeingdeceptiveor
not,butitfailstotakeintoaccounteverythingelse,e.g. theknowledgeinvolvedaswellasthecontextofthesituations.
This simplistic view of deception, especially the over-reliance on non-verbal cues as micro-expressions, had been
extremelypopularforsometimeduetotheworkofEkmanandFriesen[1969]. Today,however,thereisrelatively
strongconsensusinhumandeceptionresearchthatcue-basedapproachesareverylimitedandcanhelpdetectdeception
onlyslightlybetterthanchanceLevine[2015]. Notably,theworkofDePauloetal.[1996,2003],BondJrandDePaulo
[2008],hasshedsomelightonhowtheover-relianceonspecificcuesisproblematicandthatthesedonotimprove
deceptiondetection. Thismakescue-baseddeceptionresearchhighlysusceptibletocognitivebiasessuchasthetruth
biasortheconfirmationbias(a.k.a. theOthelloError)BondJrandFahey[1987].
Alternatively,non-cuebasedapproaches,insteadoftryingtosolelyfocusondeceptiondetection,theyaimtoenrichthe
understandingofvariousfactorsandcomponentsthatunderliesocialinteraction. Thefollowingnon-cuebasedtheories
areactuallytheonesthatcanprovidewithatrulysocio-cognitiveunderstandingofdeception:InformationManipulation
Theory2(IMT2)proposedbyMcCornacketal.[2014]andTruth-DefaultTheory(TDT)proposedbyLevine[2014].
4Sarkadi. DeceptionAnalysiswithArtificialIntelligence
IMT2aimstounderstandthecognitiveprocessesthatareresponsiblewithspeechproductionindeceptiveinteractions.
OneoftheargumentsproposedbyIMT2isthatthereisnodifferencew.r.t. cognitiveloadwhenhumanslieortellthe
truth. TDTdiffersfromIMT2,byfocusingonthecontextualaspectsofdeception. TDTproposesthatthereisageneral
truth-defaultstateinwhichhumansaresusceptibletodeceptionandfromwhichtheycanbetriggeredoutofdepending
ontheinformationalcontext. InadditiontoIMT2andTDT,thereisInterpersonalDeceptionTheory(IDT)proposedby
Burgoonetal.[1996],whichcanprovideuswitharichsocio-cognitiveperspective. WhileIDTiscue-basedtosome
extent,itisnotover-reliantoncues. Thistheoryisverydifferentfromstandardcue-basedapproachesanditsstrengthis
thatitaimstogiveanintegratedperspectiveonhowcuesinfluenceinter-personalinteractionsbetweenhumanagents.
Inoneway,IDTrepresentsdeceptiveinteractionsasamulti-agentsystemthatisgovernedbyrulesofmessagetransfer.
Thereisacommoncomponentthroughoutallofthenon-cuebasedperspectivesondeception,namelytheabilityto
form,simulate,andreasonaboutthemindsofothers,whichisknowninthescientificliteratureastheabilitytouse
Theory-of-Mind(ToM).Different‘flavours’ofToMhavebeenproposedtoexplainthisphenomenon. Oneflavour
isTheory-TheoryofMind(TT).TTrepresentsthetypeofToMwhereagentsalreadyhaveanunderstandingtosome
extentoftheotheragents’minds. TTcanbe,forinstance,asetoraknowledgebasethatconsistsofbeliefsofothers’
mentalattitudes. AnotherflavourisknownasSimulationTheoryofMind(ST).STrepresentsaprocessforusingthe
alreadyknownsetofothers’mentalattitudestosimulatetheirmindsinordertoseewhatotherattitudestheycanform
ortopredicttheirbehaviour. BothtypesofToMhaveemergedfromthestudyofchildrenindevelopmentalpsychology
Gopnik and Wellman [1992]. Gopnik and Wellman describe how the two competing flavours aim to explain how
childrenpredictothers’behaviour,e.g. whethertheyuselanguageassociatedtoTTsuchas‘beliefs’and‘desires’-
theoreticallanguageconstructsthatformaconceptualrepresentationofanother’smind,orwhethertheyusephenomenal
constructsassociatedtoSTbyusingtheirownmindsto‘run’asimulationofinputsandgenerateoutputsintheformof
an‘experience’. InTT,thechildheavilyreliesonaconceptualconstructsandlanguage,whereasinSTegocentrism
playsacrucialrole,asthechildheavilyreliesonprojectingone’sownmentalstatesontoanother.
EveniftherehasbeenanongoingdebatenamelybetweentheproponentsofTTandtheproponentsofSTregarding
howhumansdevelopanduseToM,theseperspectivesseemtobemergingintoahybridperspectiveonToMGoldman
etal.[2012]. WhileTTrepresentsthetypeofToMwhereagentsalreadyhaveanunderstandingtosomeextentofthe
otheragents’minds,e.g.,asetoraknowledgebasethatconsistsofbeliefsofothers’mentalattitudes,STrepresentsa
processforusingthealreadyknownsetofothers’mentalattitudestosimulatetheirmindsinordertoseewhatother
attitudestheycanformortopredicttheirbehaviour. TTandSTcanbemergedintohybridToM,whichcanbethought
ofasa‘high-level’ToMintheformofasimulationsetupinwhichanagenttakesitstarget’sbeliefs, desires, and
intentionsaspremisesforgeneratingapracticalreasoningprocessinthewayitstarget(theotheragentwho’smindis
beingmentalised)wouldGoldmanetal.[2006,2012].
Someoftheothersocio-cognitivecomponentsofdeceptionhavebeendescribedbyIMT2toconsiderhowinformation
orknowledgeismanagedinsidethedeceivers’cognitiveapparatus. Thiscognitiveapparatusinhumansrepresents
somesortofcognitiveagentarchitecturethatisabletorunvariousprocessesbefore,after,orduringcommunicative
interactions. IMT2describesitas‘aspeechproductionsysteminvolvingparallel-distributed-processingguidedby
efficiency,memory,andmeans-endsreasoning;andthisproductionprocessinvolvesarapid-fireseriesofcognitive
cycles(involvingdistinctmodulesunitedbyaconsciouswork-space),andmodificationofincrementally-constructed
discourseduringtheturn-at-talkinresponsetodynamiccurrent-state/end-statediscrepancies’. IMT2identifiestwo
maincognitiveprocessesderivedfromspeech-acttheoryofcognitionthatareresponsibleforinformationselectionand
dissemination. ThefirstprocessiscalledParsProToto,meaningthepartsforthewhole,whichasenderagentuses
toselecttheinformationthat,giventhecontextinwhichthesenderandthereceiverfindthemselves,willconveythe
sender’sintendedmeaningofthemessageinthemindofthereceiver. ThesecondprocessiscalledTotumExParte,
meaningthewholefromtheparts,whichareceiverusestoinfertheintendedmeaningofthemessagefromasender
giventhecontextinwhichthereceiverandthesenderfindthemselvesin. AccordingtoIMT2,deceiversanddeception
detectorsengageinthesetwoprocesseswhentheyinteract. Fascinatingly, IMT2hasbeeninspiredbyworkatthe
intersectionofAIandpragmaticsNewelletal.[1972],Hovy[1990],henceitsadoptionofspecialisedtermsfromAI
whendescribingthespeechproductionsystemsforhumans. UnsurprisinglytopeopleworkinginAI,IMT2seems
highlytunedtotheideaofintelligentsocially-awareAIagentsCohenandLevesque[1985].
Ontheotherhand, IDTdealswithdeceptionatadifferentlevelofabstractionfromIMT2, asitignorestheactual
informationthatismanagedbytheinternalcognitiveprocessesofhumans,andfocusesinsteadonthesocio-cognitive
factorsthatconstrainspeechproduction. Forstarters,cognitiveloadisacrucialfactorindeceptiveinteractionsthat
determinesthesuccessorfailureofthedeceiver.Fromacomputationalperspective,cognitiveloadrepresentsthenumber
andcomplexityofoperationsanagentneedstoperformonacertainquantityofinformationinordertodeceiveordetect
deception. AccordingtoIDT,thewayinwhichhumansareabletocopewithcognitiveloadvariesbetweenindividuals.
IDTidentifiescommunicativeskilloftheagentsasthemostimportantfactorthatinfluencesthisability. Agentswith
ahighcommunicativeskilltendtobebetteratmanagingthecognitiveload. Computationally, thecommunicative
5Sarkadi. DeceptionAnalysiswithArtificialIntelligence
skill might be represented either by some amount of computational resources that are available to an agent, or by
somecommunicationmechanismsthataremoreorlessefficient(probablydependingonthecircumstances/contexts)
indisseminatinginformationandthatarepartofanagent’scognitivearchitecture. Anotherimportantparameteris
the amount of leakage, that represents cues that contradict a deceptive message, and that an agent exhibits during
interactions. IDTarguesthatleakageincreaseswithcognitiveload,butdecreaseswithcommunicativeskill. Agents
withhighcommunicativeskill,beingabletomanagetheircognitiveload,canreducetheamountofleakage.
Furthermore, TDT Levine [2019] describes the contextual level of deception, which informs us that there is more
to deceptive interactions than social parameters like cognitive load and leakage when it comes to interpreting the
information received or transmitted. According to TDT, what is communicated (informational content) in a given
contextshouldbegivenmoreimportancethannon-verbalbehaviourthatmayormaynothappentobecorrelatedwith
thecommunicatedcontent. Therefore,basedonTDT,thecontextualknowledgeandinformationavailabletotheagents
thatinteractwitheachothershouldbeacrucialcomponentofcomputationaldeception. Thewaythisinformationis
usedcandeterminewhetherdeceptiveattemptsaresuccessfulornot. Thesamegoesforattemptsatdetectingdeception,
suchaspersuadinganagenttorevealdeceptivemotives. Thisinformationshouldrepresentknowledgeaboutwhatis
saidornot,whenandwhereitissaid(ornot),towhom(andnot),aswellashowitisornotinterpretedbysomeone.
Thistypeofinformationcantriggeragentsintooroutofthetruth-defaultmentalstate,whichmakesindividualsspend
lessormorecognitiveresourcesonwhatisbeingcommunicated,e.g. makesthemmoreorlesssuspicioustoothers
dependingonthecontext.
EventhoughIMT2andIDTdonotmentionToMasanexplicitcomponentofdeception,ToMseemstobeassumed
implicitly. Forinstance,asa‘high-levelsimulationtheory’,hybridToMblendsTTandSTintopracticalreasoning
Goldmanetal.[2006,2012],whichisaprocessverysimilar,ifnotidentical,totheprocessesofParsProTotoand
TotumExPartedescribedbyIMT2. Now,theonlytheoryofdeceptionoutofthethreedescribedhere,thatexplicitly
mentionsToMisTDTLevine[2019],wheredeceptionwouldbeaspecialcaseofToM.Thisseemstobeawell-founded
considerationgiventhathumansdeveloptheabilitytoformanduseToMinearlychildhood. Anotherstrongargument
forthetightlinkbetweenhumanToManddeceptionistheuseoffalse-beliefexperimentstotracktheformationof
ToMinchildrenGopnikandWellman[2012]. Basedonthis,wecanlookatthedefinitionofdeception(seeSection
2.1)andsafelysaythatintentionalexploitationoffalsebeliefformationisnothingotherthandeception,confirming
Levine’spointthatdeceptionisaparticularcaseofToMinuse.
Tosummarise,therearetwomainapproachestounderstandingdeceptioninPsychology,namelycue-basedandnon
cue-based. Whilemostcue-basedapproachessufferfromnumerousdrawbacks,includingheavybiasesindeception
detection,noncue-basedapproacheshavebeendesignedtoovercometheseandexplaindeceptiveinteractionsmore
rigorously. Hence,thesearetheapproachesthatneedtobefacilitatedbyDAMASinordertosupporttheanalysis
of deception in hybrid societies. Moreover, there is the human ability of using ToM which plays a crucial role in
deception. Inparticular,theemerginghybridflavourofToMseemstobemostappropriatetoberepresentedwithAI
approacheswithinDAMAS,especiallyregardingthepracticalreasoningprocessesinvolvedinagent-to-agentdeceptive
communication.
3 Reductionism&PreviousResearchinDeceptiveAI
TheliteratureinSocialPsychologyandCommunicationTheoryprovestobecriticalinunderstandingdeceptionas
a socio-cognitive interactive process between agents, starting from the internal cognitive mechanisms responsible
for the production of communicative behaviour, to giving an overarching perspective between the relations of the
agentsinvolvedindeceptiveinteractions. Intheprevioussection,wehaveseenthattherearemultiplesocio-cognitive
componentsofdeceptionintheliteraturethatarerelevant. ThemostcrucialofthesecomponentsareToM,thesocial
factors and the idea of agent-agent interpersonal dynamics described in IDT, the reasoning processes for speech
productiondescribedbyIMT2,andtheimportanceofcontextualfactorsandtruthbiasemphasisedbyTDT.Ifweareto
buildaholisticAIframeworktostudydeceptioninhybridsocieties,wemustdesignitsuchthatitisabletorepresent
andmodelthesecomponentsaspartofmulti-agentinteractionsandcognitiveagentarchitectures. Then,whatweneed
todowithAImethodsistocaptureandunderstandtherelationbetweenthesocio-cognitivecomponentsofdeception
andToMinsidehybridsocieties.
3.1 Multi-AgentFrameworksvsAIReductionism
Thereexistsamethodological,orbettersaidaparadigmaticlimitationtobuildingholisticframeworksformodelling
deceptioninAI.ThislimitationcomesfromthefactthatAIapproachesareusuallyhighlyreductionistic,namelythat
realworldfactorsareabstractedawayforthepurposeof“elegance”andsimplicityofAImodels. Inthehistoryof
scienceandphilosophy,reductionismhasbeenextensivelydebatedforhundredsofyearsAndersen[2001]. Inmodern
6Sarkadi. DeceptionAnalysiswithArtificialIntelligence
science,Marr[2010]starteddiscussingthelimitationsofreducingcognitivefunctionstophysicalpropertiesofneurons,
arguingthatexplanationsaboutcognitivefunctionscannotsolelyrelyonneuro-chemicalactivityPeeblesandCooper
[2015],Bickle[2015],butthatinordertobemeaningfullyunderstoodtheyalsorequirereferencestobehaviouraspart
ofanoverarchingmulti-levelanalysisMarr[2010],Krakaueretal.[2017].
AsimilarargumentcanbemadeaboutresearchinAI.Thatisifwewanttounderstandandexplainasocio-cognitive
phenomenonsuchasdeception,forwhichotherareasofscientificandhumanitiesresearchhaveidentifiedvarious
componentsthatinteractwitheachothertogiverisetoacomplexmulti-layeredprocessinsidecomplexmulti-layered
systemsthatarehybridsocieties,thenwecannotreducethesetypesofprocessestoasinglefunction. Historically,AI
hasbeenallaboutbreakingdownhumanintelligenceandmodellingitcomputationallyasfunctionsataveryabstract
levelBoden[1996]. Thisisunderstandableforinvestigatingthepropertiesofsomeprocessesinisolation. Butwhena
processconsistsofamultitudeofthesefunctionsworkingsequentiallyandinparallelatmultiplelevelsofabstraction
- from the internal cognitive reasoning mechanisms to the interaction mechanisms responsible for communication
totheemergentlarge-scalebehaviourofagentsthatareinteracting-thenjustsolelyfocusingonthepropertiesofa
singlecomputationalfunction,independentlyofothercomponents,seemstomissthepointofmodellingtheentire
phenomenonitself2. Asidefromrepresentingthefunctionsthemselves,thereistheproblemofacausalitybetween
elementsatvariouslayersofabstraction,e.g. theproblemofhowfunctionsrelatetoeachother. Inturn,thismeansthat
AImodelsneedtoaccountfordifferentkindsofarchitectures. ThisiswhytheareaofDistributedAI,andlaterABM
andMAS,emergedtobeabletostudysystemsofagents. However,evenintheseareas,mostoftheworkhaslostfocus
ofsocio-cognitivemodellingandhasturnedtobenchmarkingandoptimisationofgroupsofartificialagentsDignum
andDignum[2020].
Despitethelimitationsabove,Multi-AgentSystems(MAS)frameworkshavenumerousbenefits,ofwhichmostcrucial
forunderstandingcomplexinteractionsistheirabilitytocapturetheseinteractionsatdifferentlayersandlevelsof
abstraction. MASandagent-basedmodelling(ABM)techniquesarebeingincreasinglyappliedinthereal-worldin
finance,politics,trafficcontrol,industrialdevelopment,urbanplanning,militaryoperations,cybersecurityetc. Whynot
developaframeworkthatcanbeappliedindeceptionanalysis? Ifappropriatelydeveloped,DAMAScouldbeused
toautomatesome,ifnotmost,ofthetedioustasksperformedbydeceptionanalystsandensurebias-freeintelligence
analysisofdeception. Themainbenefitofhavingaframeworktocriticallyanalysedeceptionisthatitcanbeusedfor
high-leveldecisionmaking,especiallyinthedomainofregulatingAIandpreventingriskscomingfromdeceptiveAI
agents.
OnemethodinMAStolimitthenegativeeffectsofreductionismistomodelandintegratelayersofabstraction,which
arethefoundationsofaMASframeworkBoissieretal.[2013]. Theirintegrationaccountsforarichmulti-dimensional
worldinstantiatedthroughcomputationalrepresentationsofenvironments,agents,andorganisations. Socialinteractions
betweenagentsarecomplexandsomeofthepropertiesoftheseinteractionsandtherelationsbetweentheseproperties
canonlybedescribedbytakingintoaccountthesedifferentlayers. AsanillustrativeexamplefromMASengineering,
theJaCaMoframework Boissieretal.[2013]integratesthethreelayersofabstractionrespectivelythroughtheJason
agent oriented programming language (agent layer), the CArtAgO common artifact infrastructure for agents open
environments(environmentlayer),andtheMoiseorganisationorientedprogrammingframework(organisationlayer).
VariousMASmodelscanbethenrepresentedandimplementedusingsuchaframeworktoexploreagentsystemsatthe
levelofinteraction,consideringhowagentsinteractwiththeenvironmentandeachotheraspartofvariousorganisations
thatfollowdifferentnormsetc.
AnotherwaytodealwithreductionisminAIistoaccountformultiplemodelsandlevelsofabstractionthrougha
combinationofMASandABMapproaches,representations,andtechniques,formalorcomputational,thatcanbe
usedtodescribethepropertiesofinteractionsbetweenagents. MASapproachesfocusonmodellingtheinteraction
level,whileABMapproachesfocusonmodellingthedescriptivelevelDignumandDignum[2020]. Anexample
ofaMASmodelthatfocusesoninteractionbetweenagentsisacomputationalmodelbasedonspeech-acts. Sucha
modeldescribesand/orpredictsboththecognitiveprocessesandthebehaviourusedtoproducechangesinthebelief
basesofotheragentsthroughspeech-production. Thistypeofmodel,forinstance,canbeusedtotracktheinformation
exchangedduringadialogue,aswellasthereasoningthattheagentsperformduringthedialogue. Ontheotherhand,
anABMmodelthatfocusesondescribingemergentbehaviourdoesnotneedtorepresenteverycognitivecomponent
responsibleforproducingaspeech-act,itonlyneedstodescribeanoverallstateofasystem. Thus,itcanbeefficiently
used to represent the costs and benefits of communication and compute states of the system at different moments
throughsoftwaresimulation. Forinstance,itcancheckifanequilibriumiseverreachedforexchanginginformation
givenasetofsocialparameters.
2Thesameargumentappliestowhydefinitionsthatexplaintheentirephenomenonofdeceptionarebettersuitedthanothers
whichonlydefineaparticulartypeofdeceptivebehaviour.
7Sarkadi. DeceptionAnalysiswithArtificialIntelligence
Therefore,ifwewanttolimitscientificreductionismwhenanalysingdeception,thenitisnecessarytomodeldeception
holistically,aspartofanover-archingsocio-cognitiveprocesstakingplaceinsideamulti-agentsystemthatintegrates
multiplelayersofabstraction. Thisisnotonlyvalidforhuman-to-humaninteractions,butalsoformachine-to-human,
machine-to-machine,oranytypeofagent-to-agentinteractions. ThatiswhyweproposethedevelopmentofDAMAS.
3.2 PreviousWork
Inthelast20years,theimportanceofresearchondeceptiveAIhasbeenemphasisedintheAIcommunityduringa
seriesofevents,namelythe2015AAAIFallSymposiumonDeceptiveandCounter-DeceptiveMachines3,andthe
twoInternationalWorkshopsonDeceptiveAI4co-locatedwithECAI2020andIJCAI2021. Havinggonethroughthe
socio-cognitivecomponentsthatneedtobeconsideredwhenmodellingdeceptiveAI,wenowdescribetheworkatthe
intersectionofdeceptionandAI,groupingthemintosixcategoriestobetterunderstandwhatcomputationalaspectsand
propertiesdeceptiontheyaddress.
Withsomeexceptions,mostoftheapproachespresentedinthissectionfocusonnarrowaspectsofdeceptionandthey
arehighlyreductionistic. Whereoneapproachmanagestocaptureacertainaspect,itfailstoconsideramultitudeof
otheraspectsandcomponentsofdeception. However,theseaspectsandpropertiesalsoneedtobeunderstoodtoinform
thedevelopmentofpurpose-specificmodelsortoolsfortheholisticsocio-cognitiveframework(DAMAS).Thepurpose
ofthissectionisnottocriticisepreviouswork,buttoexplainwhyitisreductionisticandhowitcouldbenefitfrom
beingintegratedunderanagent-basedconceptualframework,namelyDAMAS.
ThereissomeworkattheintersectionofdeceptiondetectionandMachineLearningthatweleftoutinthissection
duetoitsover-relianceoncue-basedtheoriesofdeception. Theworkthatwedosummarisecoversvariousaspectsof
deceptioninAIgoingbeyondtheliteraturepresentedduringthethreeeventsmentionedabove(foraquickoverviewof
thecoveredliterature,thereadercanconsultTable1):
3.2.1 DeceptioninAgentSocieties
ResearchthatfallsinthisareaaimstomotivatetheAIcommunitytobuildatheoryoftrustanddeceptioninvirtual
societies. The main body of research mainly focuses on human-computer interaction in MAS and tries to answer
questionsthatarisefrominteractionsbetweenhumanandartificialagents,suchasWillartificialagentsdeceive?,Why
would they deceive?, Why is it important for agents to be able to reason about deception?, Why should we model
deceptiveagents? Whatarethetypesofdeceptioninvirtualcommunities? Whatistheroleofdeceptioninhuman-agent
interaction?
Recentfindingsbackupthisperspectivebyshowinghowhumansandartificialagentsinfluenceeachother’sattitudes
andbehaviour. Forexample,Melletal.[2018]focusonhowthenegotiationstrategiesofartificialagentsdetermine
humanstoendorseartificialdeception. Apparentlyandcounter-intuitively,humansalsotendtobemorecooperative
withdeceptivemachinesthanwithfriendlyones, accordingtoIshowo-Olokoetal.[2019]. Anothertypeofstudy,
presentedbyDrasetal.[2010],looksatthewaysinwhichdeceptivelanguagecanbegeneratedanddetectedinvirtual
systems.
Theseapproachescaninformusabouthowhumanscandistinguishbetweendeceptiveandnon-deceptiveAIagents
indialogues;thatdeceptiveagentsarebetteratinducingcooperation;andthemoreexperiencedhumannegotiators
become, the more likely they are to endorse deception performed by their AI agent representatives. However, the
downsideofthesemethodsisthattheystudydeceptionaspartofisolatedinteractions,despitebeingaimedatstudying
deceptionaspartofcomplexhybridsociety. Ontheotherhand,theseapproachescaninformusonthemodellingof
human-machinerelationswithinDAMAS.
3.2.2 LogicalAspectsofAgentDeception
Thisareaaimstodefinealogicaltaxonomyofdeceptivebehaviour,aswellasrepresentingandmodellingdeception
usinglogicalformalisations. Somerelevantquestionsare: Whatisthethedifferencebetweenlyinganddeceiving?,
Howdowerepresentbullshit,pandering,palteringetc.?
WorksintheareasofLogicandPhilosophyhavestronglyinfluencedthecurrentstateoftheartapproachesindeceptive
AI.Mostknownaretheworksinknowledgerepresentation,whichhavelaidthefoundationstoformalisedeceptive
communication.TheseappearinSakamaetal.[2010],inSakama[2015],andinSakamaetal.[2015],wheretheauthors
presentthelogicaldistinctionsbetweendifferenttypesofdishonestlinguisticbehaviour,andlaterintroducingamodel
3Seetheproceedingsathttps://aaai.org/Press/Reports/Symposia/Fall/fs-15-03.php.
4SeethejointproceedingsinSarkadietal.[2021b].
8Sarkadi. DeceptionAnalysiswithArtificialIntelligence
ofcausalityforthemSakama[2021];Bonnetetal.[2021]sketchalogicaltheoryofbeliefmanipulation;VanDitmarsch
[2014]introduceadynamiclogicoflyingthatconsidersliesaboutfactualpropositionsaswellasliesaboutthebeliefs
ofothers;inUckelman[2011]wheretheauthorusesthemedievalconceptofdubitatiotostudydeceptiveagents;Jones
[2015]proposesaformalmodelofself-deceptionthatisconsistentgivencertainepistemicconditionsimposedonthe
agentthatengagesinself-deception;andSmithetal.[2016]describealogic-basedaccountofanalysingconjuring
tricksasformofdeception,andidentifysubstitutableelementsandstableocclusionascrucialcomponentstoconstruct
perceivedimpossibilities.
Logic-basedaccountsofdishonestyenableustoelegantlyandrigorouslycapturecommunicativeaccountsofdeception.
However,theseformalismslacktheabilitytomodelorrepresentsocio-cognitiveaspectssuchasdegreesoftrust,bias,
andToM.Thetrade-offforusingsuchapproachesisbetweenrepresentationalpowerandrigour. Ontheotherhand,
becausetheseapproachescaninformushowtorigorouslyformalisecommunicativeactsandarguments,theycouldbe
usedtomodeldeceptiveargumentationbetweenagentsinDAMAS.
3.2.3 StrategiesforAgentDeception
ThisareastudiesdeceptivestrategiesinMAS.ThisareaisstronglyinfluencedbyEconomicsandCybersecurity,from
whichmethodssuchasriskandthreatmodellinghavebeenadoptedandadaptedtoaddressspecificscenarios. Some
relevantquestionsare: Whatarethedeceptivestrategiesandcounter-strategiesindifferentcontexts?,Howtoreduce
andmitigatedeceptiveattacks?,Howdowedesignasystemthateitherreducesorincentivisesagentdeception? etc.
Someoftheworkinthisareaexploresissuessuchasusingheuristicstocausetargetagentstoexecuteaplanthatwill
achievethedeceiver’sdesiredgoalChristianandYoung[2004];findingdeceptivestrategiesusingpath-planningMasters
andSardina[2017],Mastersetal.[2021a],Benkeetal.[2021];usingaMASsystemonaBayesiannetworktest-bedto
distinguishbetweentruthfulanddeceptiveagentsbasedonthecorrelationoftheagents’beliefsSantosandLi[2009];
modellingagentbaseddeceptiveinteractionsonsocialnetworksBarrioetal.[2015];modellingdeceptiveinteractions
tocounterreconnaissance-basedcyber-attacksSchlenkeretal.[2018];studyingtheeffectsofdeceptioninrepeated
gamesbetweenlearningagentsNguyenetal.[2019];applyingIDTinmulti-agentreinforcementlearningtoreduce
theeffectsofsocialengineeringattacksYangandYu[2018];developinganinformation-theoreticmodelofdeceptive
strategiesKoppetal.[2018];learningdeceptivestrategiesthroughbayesianbeliefmanipulationAitchisonetal.[2021];
formalisingcyber-deceptiongamesbetweenmultipleagentsusinghyper-gametheorymethodsFerguson-Walteretal.
[2019]. Additionally,giventheincreasinginterestinexplainabilityforAI,Wrightetal.[2019]discusshowagentscan
strategicallyprovideuserswithdeceptiveandrebelliousexplanations.
Theseapproachesallowustodiscoveroptimalstrategiesfordeceptivebehaviourofasingleagentandfindequilibria
whenmorethanoneagentisinvolved. Usuallythesemethodsfocusonsomeutility-based(costandreward)metric
tostudystrategies. Thedownsideoftheseapproachesisthattheyfocusmoreondescriptiveapproachesratherthan
interactional-thereisnorepresentation,architectureormodeloftheagents’knowledgethatchanges-thesearejust
implicitlyassumedinthemodellingofstrategies. Hence,intermsoftrade-off,theseapproachessacrificerepresentation
andgeneralityforsimplicityandefficiencyinspecificandwell-definedsetups. W.r.t. DAMAS,theseapproachescan
helpusidentifyscenarioswhereagentsmakefullyrational(fromautilitarianviewpoint)decisionsandoperationalise
rationalagentbehaviour.
3.2.4 ReasoninginAgentDeception
Thisarealooksatformalandinformalreasoningmechanismsresponsiblefordeception,andisstronglyinfluencedby
InformalLogicandArgumentationaswellasbysubareasofCognitiveScience. Somerelevantquestionsare: What
arethecognitivecomponentsinvolvedindeceptivereasoning?,Whattypesofreasoningmechanismsareinvolvedin
deceptiveinteractions?,Whattypeofcognitivearchitecturescanbeusedtorepresentdeceptivereasoning?,Whattype
ofknowledgeisnecessaryornotforanagenttodeceive? etc.
WorkinthisareaofdeceptiveAIhasexploredissuessuchasusinganddetectingdeceptioninargumentdebategamesby
Sakama[2012]thatareformalisedusingabstractargumentationDung[1995];usingabductivereasoningfordeception
Sakama [2011]; using argument mining for detecting deceptive reviews online Cocarascu and Toni [2016]; using
argument mining for detecting propaganda Vorakitphan et al. [2021]; using argumentation-based tools to analyse
disinformationinfakenewsDelobelleetal.[2020];lookingintowhattypeofargumentscanbeusedbyamachine
todeceiveClark[2010];modellingagentsthatusemindreadingfordeceptionIsaacandBridewell[2014];modelling
themeta-reasoningofagentsthattelldeceptivestoriesanddetectdeceptivestoriesindialogueargumentationgames
Sarkadietal.[2019a].
Thesemethodsenableusto(i)captureinformalaspectsofreasoninginvolvedinbothdeceptionanddeceptiondetection,
(ii)representthecognitiveprocessessuchasmeta-reasoning,and(iii)useautomatedtechniquestocategorisedeceptive
9Sarkadi. DeceptionAnalysiswithArtificialIntelligence
communication. Argumentminingtechniquesareusedtodetectpotentiallydeceptiveargumentsfromtext,whereas
knowledgerepresentationandreasoningtechniquesareusedtomodeltheinternalreasoningmechanismsresponsible
forproducingdeceptivecommunicationinagents. Thebenefitsoftheseapproachesisthattheycancapturethelinks
betweendeceptivecommunication,itsdetection,andtheirrespectivereasoningmechanismsandcognitivebiases. The
downsideintermsofreductionismisthattheyarenotintegratedaspartofanoverarchingsystem. Ontheotherhand,
theseapproachescanhelpusrepresentandoperationalisecomplexformsofreasoninganddecision-makingandidentify
instancesofwhereirrationalityisinvolved(irrationalasnon-utilityoriented)withinDAMAS.
3.2.5 EngineeringDeceptiveAgents
Thisarealooksintothedesign,modelling,andengineeringmethodsthatcanbeusedtocreatedeceptiveordeception-
detectiveautonomousagents. Themaindifferencebetweentheareaofengineeringofdeceptiveagentsandtheareas
coveringstrategiesandreasoningofagentsisthattheengineeringapproachaimstointegratetheseagentsintomore
complexsystems. Thisareadoesnotjustlookathowagentsreasonaboutdeception,butwhatcausesthemtoachieve
deceptionornotinagivensystem. Somerelevantquestionsare: Whatarethebestapproachestomodeldeceptive
agentsordeceptiveinteractionswithoutsacrificingexpressivity?,Howshouldthesemodelsorsystemsbedesigned
andimplemented?,Howdoweevaluatethesesystems?,Whatcanweusethesesystemsfor?,andHowdoweintegrate
differentcomponentsofdeceptiveinteractionsinordertoengineercomplexreasoningagents? etc.
Recentworkinthisareahaslookedatissuessuchas:modellingagentarchitecturesthatengageindeceptivestorytelling
duringdialoguesRatoetal.[2017];developingdeceptivechatbotsforemotionalwell-beingandmentalhealthGalindo
etal.[2021];engineeringagentsthatuselies,bullshitanddeceptionPanissonetal.[2018a];andalsothefirstattempt
inMAStointegrateIMT2,TDT,andIDTinordertomodel,implementandevaluatedeceptiveinteractionsbetween
complexreasoningagentsthatuseTheoryofMindbySarkadietal.[2019b].
These methods enable us to specify models, design agents, and implement them as prototypes to study deceptive
interactionsbetweenthem. Thebenefitsoftheseapproachesarethattheyaremodular,engineering-driven,andbased
onreasoningmechanisms. Mostbenefitscanbeseenintheapproachesthattrytointegratesocio-cognitivemodelsin
theirmulti-agentmodelswhicharegeneralenoughtobeappliedtoamultitudeofcontexts,whereasmostdownsides
w.r.t. reductionismcomefromthefactthatdespitethegenerality,interpretability,andapplicabilityofthemodels,their
domain-specificimplementationsusuallylackautomatedanduser-friendlyexplanationsoftheagentinteractions. On
theotherhand,theseapproachescanbeusedasthebuildingblocksformodellingmulti-layeredcognitiveprocesses,
architectures,andcommunicativebehaviourofagentswithinDAMAS.
3.2.6 EmbodiedDeceptiveAgents
Thisareastudiestheperformanceofdeceptiverobotagentsinthephysicalworld.Somerelevantquestionsare:Howcan
robotsdeceivehumans?,Whatstrategiescanarobotemployfordeception?,Whatkindofrobotsaremoredeceptive?
etc.ThisareaisbecomingincreasinglyrelevantgiventheadvancementofInternet-of-Thingsandtheinterconnectedness
ofphysicalagents,suchasself-drivingcarsandrobotassistants.
Researchinthisarealooksatissuessuchas: howdeceptionaboutagencyinfluencesthewaychildrentreatrobotsona
sociallevelandwhenisitacceptabletodeceivechildrenaboutthenatureoftherobotstheyinteractwithWestlundand
Breazeal[2015];howrobotscandecidetoperformphysicalactionssuchthattheymanipulatethebeliefsofhumans
whoobservethemGrayandBreazeal[2014];howtoproviderobotswiththecapacitytodeceiveWagnerandArkin
[2011];whythepropertiesofdeceptionandtransparencyinrobotsshouldbetreatedinthecontextofuservulnerability
Collins[2017]; usingbiologicallyinspiredbehaviourforrobotdeceptionShimandArkin[2012], suchassquirrel
behaviourandapplyingittoshillagentsPettinatietal.[2021]. ShimandArkin[2013]evenprovideataxonomyof
robotdeceptionandpresenttherelatedbenefitsofdeceptionforhuman-robotinteraction.
These approaches are very useful to study human biases w.r.t. the design and behaviour of robots. Regarding
reductionism, the robots are very limited in terms of reasoning and complex communication. This is perfectly
understandablesincecontrol-basedhuman-robotinteractionsinlabsneedtoisolatevariousfactorsinordertogain
significant findings. However, the findings themselves should be used to inform the design of more accurate and
complexmodelsofdeceptioninhuman-agentinteractions. Forinstance,theknowledgethataspecifictypeofembodied
AIagentismorelikelytomislead,persuadeetc. humanagentsisasocio-cognitivefactorandcanbeusedaspartof
DAMAStocomputethelikelihoodofdeceptionbeingcausedifthattypeofagentisinvolvedinsomemulti-agent
interaction.
Wehaveseeninthissectionthatresearchondeceptioninvolveslookingatvariousaspectsandcomponentsofdeception.
However, more often than not, AI does so from a highly reductionist approach. This type of reductionism can be
10Sarkadi. DeceptionAnalysiswithArtificialIntelligence
problematic,becausecomparedtootherformsofdishonestysuchaslyingorbullshitting,bothofwhichcanbeelegantly
modelledinlogicsofcommunication,deceptioninvolvesmorecomplexcognitivemechanismsthathavetobemodelled
Panisson et al. [2018a], Hyman [1990], usually in a relational manner McHugh et al. [2004]. For instance, ToM
isconsideredacriticalcomponentofdeceptionSarkadietal.[2019b],Sarkadi[2021],IsaacandBridewell[2017],
DeRosisetal.[2003],andmoreoftenthannot,modelsinAIfailtoconsiderToMasacomplexformofsocio-cognitive
process5.
Inhybridsocieties,modellingtheToMcomponenthasbothrisksandbenefits,asitallowsustogiveagentstheability
toaligntheirethicalvalueswithhumansIsaacandBridewell[2017],butthenitalsoallowsmachinestoapplyhigher
levelsofToMtooutperformhumansindeceptionandcounter-deceptionSarkadi[2021]. Whatwemeanherebyhigher
leveliseitherdeeperlevelsofrecursivityoragreaternumberofparallelsimulationinstances/brancheswhenmodelling
othermindsinthesenseofGoldman’s‘high-levelsimulation’. Asanexample,machinescouldoutperformhumans
usinghigher-levelToMbyexploitingunknownunknownsSarkadietal.[2019b]6. IntroducedpubliclyduringaUSDept.
ofDefensenewsbriefingbyDonaldRumsfeldinthecontextofIntelligenceAnalysis,theunknownunknownmeans
notknowingthatonedoesnotknowsomethingLogan[2009],Rumsfeld[2002]. Byexploitingunknownunknowns,
AIagentsdonotsimplyexploitmissinginformationduetothetarget’sinaccessibilitytosources,butalsothetarget’s
failuretoreflectontheinformationthatisorisnotavailable-eitherduetobiasorduetolimitedcognitivecapabilities
orphysicalresources(lackoftimeorlackofanalysistools). Conclusively,itisunrealistictomodeldeceptioninagent
societieswithouthavingtheproperkindofrepresentationandimplementationforthedeceptiveagents,theirinternal
cognitiveprocesses,andtheirbehaviourwithinthecomplexsysteminwhichtheyinteract.
To summarise, if we are to model deception in hybrid societies from the direction of socio-cognitive multi-agent
systems,thenanaturalstepforintegratingmultipleformsofdeceptionaspartofasingleover-archingsystemwouldbe
todevelopanexplainable(analysis-friendly)MASframework,namelyDAMAS.Inthenextsectionwewilldescribe
thedesirablepropertiesofDAMASandexplainhowitmayaccountforamultitudeofdeceptioncomponents,aspects
andagent-orientedmodelsofdeception.
4 DAMAS:AMASFrameworkforDeceptionAnalysis
Whendesigningaframeworkthataimstofacilitatetheanalysisofcomplexphenomena,suchasdeception,inhybrid
societies,itiscrucialtokeepinmindanumberofprinciples.
First,suchaframeworkshouldofferenoughrepresentationalpowerinordertoenabletheautomationofcounterfactual
reasoningaboutsocialdynamicsbetweenagents. Thisisachievedbyrepresenting(i)theenvironment, (ii)agents
andtheircommunicativeabilities,(iii)theknowledgethatagentshave(suchasnestedbeliefsandrelationsbetween
beliefsandToMofeachother),(iv)howchangesintheenvironmentinfluencetheagents’beliefs,and(v)howthe
agentsthemselvescausethesechangesintentionallyorunintentionally-alloftheseinarelationalfashionMcHugh
etal.[2004].
Second,theframeworkshouldbebothscalableandmodular. Inotherwords,itneedstobeabletosupporttheseamless
additionandintegrationofnewagent,environment,andorganisationtypes. Thatis,themodelsoftheworldshouldbe
easilyincreasedandmodifiedbasedonpotentialchangesindeceptionmodellingrequirements. Forinstance,whenever
anewdeceptionmodeloranewtypeofdeceptiveagentarchitectureisdeveloped,thenthisshouldbeeasilyadded
totheframeworkwithoutchangingthealreadyexistingmodelsoragentarchitectures. Theinteroperabilityofagents
andtoolscanguaranteethisproperty. MASframeworkssuchasJaCaMoaredesignedbasedonthesetwoprinciples,
enablinganalmostseamlessinteroperabilitybetweentheenvironment,agent,andorganisationlayersBoissieretal.
[2013].
Third,suchaframeworkshouldbeusable. Analystsshouldbeabletousetheframeworktoexplainwhyorwhynot
interactionsbetweenagentshappenthewaytheyhappen. ExplainableAI(XAI)techniquescanbeusedtoextract
5TheAIliteraturehasalsoemphasisedthepotentialbenefitsofartificialagentswithToM(thatisnotnecessarilyhigh-level
simulation),thatincludetheexplainability,theefficiency,andtheincreasedsocialperformanceofmachines.Forexample,deWeerd
etal.[2017]showhowagentswithhigherorderToM(‘higher’heremeansstrictlymeta-levelrecursivityoverasinglebelief,not
inthesenseof‘high-levelsimulation’)outperformotheragentsinnegotiation.Anotherabilityisincreasingtheseamlessnessof
cooperationbetweenhumansandrobotsWinfield[2018],BiancoandOgnibene[2020]. Suchbenefits,webelieve,mightbethe
reasonwhyconsiderableeffortsarebeingmadeintheAIcommunitytoenablemachinestoformandusemodelsofotherminds
AlbrechtandStone[2018].
6‘Reportsthatsaythatsomethinghasn’thappenedarealwaysinterestingtome,becauseasweknow,thereareknownknowns;
therearethingsweknowweknow.Wealsoknowthereareknownunknowns;thatistosayweknowtherearesomethingswedonot
know.Buttherearealsounknownunknowns—theoneswedon’tknowwedon’tknow.Andifonelooksthroughoutthehistoryofour
countryandotherfreecountries,itisthelattercategorythattendstobethedifficultones.’Rumsfeld[2002].
11Sarkadi. DeceptionAnalysiswithArtificialIntelligence
Topics Papers
AgentSocieties Melletal.[2018],Ishowo-Olokoetal.[2019],Drasetal.[2010],Sarkadi[2024]
LogicalAspects Sakamaetal.[2010],Sakama[2015],Sakamaetal.[2015],Sakama[2021],
Bonnet et al. [2021], Smith et al. [2016], Van Ditmarsch [2014], Uckelman
[2011],Jones[2015]
AgentStrategies ChristianandYoung[2004],MastersandSardina[2017],Aitchisonetal.[2021],
Benkeetal.[2021],SantosandLi[2009],Barrioetal.[2015],Schlenkeretal.
[2018],Nguyenetal.[2019],YangandYu[2018],Koppetal.[2018],Ferguson-
Walteretal.[2019],Wrightetal.[2019]
Reasoning Sakama[2012],Dung[1995],Sakama[2011],CocarascuandToni[2016],Clark
[2010],IsaacandBridewell[2014],Sarkadietal.[2019a]
Engineering Ratoetal.[2017],Galindoetal.[2021],Panissonetal.[2018a],Sarkadietal.
[2019b]
Embodiment WestlundandBreazeal[2015],GrayandBreazeal[2014],WagnerandArkin
[2011],ShimandArkin[2012,2013],Pettinatietal.[2021]
Ethics* Kampiketal.[2018],Sklaretal.[2004],IsaacandBridewell[2017],Collins
[2017],ChakrabortiandKambhampati[2019],Coeckelbergh[2018],Shimand
Arkin[2013],SharkeyandSharkey[2021],Nataleetal.[2021],Benderetal.
[2021],Sarkadietal.[2023],Sarkadi[2023a]
Table1: TheresearchcategoriesonmodellingdeceptionwithAItechniquesdescribedinsection3. Foraholistic
overviewofethicsandDeceptiveAI,seeSarkadi[2023a].
narrativesofagentdynamicsandgenerateexplanationsinahuman-interpretablemanner,e.g. bytakingintoaccountthe
principlesofcausality,counterfactuality,contrastiveness,andsocialfactorstotailortheexplanationsofagentbehaviour
basedontheuser’sbackgroundknowledge,expertise,andpreferencesMiller[2019].
TodevelopDAMASisanalogoustomakingtheknowledgeofAIexpertsaccessibletodeceptionanalysts. First,AI
expertsshouldcreateABMandMASmodelstorepresenttheworldatmultiplesocio-cognitivelayersofabstraction.
Then,thesemodelsshouldbemadeavailabletodeceptionanalyststhroughalibraryofsoftwarepackagesandXAI
tools. Inthisway,analystswouldbeabletoiterativelyengagewiththesetoolsinordertoimprovetheexistingmodels
andadaptthemtotheirneedsinordertoperformIBE.DAMAS,asaframework,wouldthenactasamediatorora
bridgebetweentheknowledgeofAIexpertsandtheexpertiseofintelligenceanalysts,whichwouldsupporttheholistic
understandingofdeceptionasasocio-cognitivephenomenoninhybridsocieties.
Bykeepingthethreedesignprinciplesinmind,weshowanoverviewofhowDAMAScansupporttheIntelligence
CommunityinFig. 2,bydrivingAIand/ordeceptionexpertsfromtheobservationofthephenomenon,toitsmodelling,
analysisandexplanation. RepresentationalpowerwouldbeprovidedbytheABMandMASmodelsdevelopedbyAI
experts. ThemodularityandscalabilityofDAMASwouldbeguaranteedbytheMASengineeringoftherepresentations
oftheworld. Asforusability,thiswouldbeachievedthroughtheuser-centricdesignofthetoolsfocusedontheneeds
ofanalyststointeractwiththeMASmodels. IntherestofthissectionwepresentthecomponentsofDAMASand
howthesewouldsupporttheentiredeceptionanalysisprocess. Wefirstdescribehowdeceptioncanbemodelledwith
MASandABMapproachesdrawingfromtheAIliteratureinsubsection4.1. Then,insubsection4.2wediscusshow
deceptioncanbeexplainedwiththeaidofuser-centricXAItoolsbasedonhybridargumentationinlinewithmethods
fromintelligenceanalysis.
4.1 ModellingDeception
ThefoundationsofDAMASrelyontheAIexpertiseincreatingholisticMASandABMmodelsofdeceptionfroma
socio-cognitiveperspective. ThereareafewMASandABMapproachesintheliteraturethattackledifferentformsof
deceptionbyconsideringamultitudeofsocio-cognitivecomponents.
Due to their nature, some of these types or forms of deception are more suitable to be modelled and studied at
theinteractionlevel(subsection4.1.1)withMASapproaches, whileothersaremoresuitedforbeingstudiedata
descriptivelevel(subsection4.1.2)withABMapproaches. Henceforth,wewillfirstcategorisetheformsofdeception
progressively,startingfromthesimplesttothemorecomplexandunusualintermsofinteraction. Then,wewillfocus
ondescribingprogressivelytheformsofdeceptionfromadescriptiveperspective,basedonthenumberofdeceptive
agents. ForbothMASandABMmodelsweindicatethekindsofdeceptionthathavebeenmodelledintheAIliterature.
12Sarkadi. DeceptionAnalysiswithArtificialIntelligence
WereflectonthesemodelsandpresentalongsidesomeofthequestionsthatremainunansweredinordertoguideAI
expertsintoformulatingnewmodelsorintoextendingexistingonesthatwouldeventuallybecomepartofDAMAS.
4.1.1 Interaction(MAS)ModelsforDAMAS
Westartbypresentingsomeformsofdeceptionthattakeplaceattheinteractionlevelandthataresuitableformodelling
withMASapproaches. ByaddingcomplexcognitivepropertiestotheMASmodels,suchastheagents’abilityto
useTheoryofMind(ToM-seesubsection2.2),thecomputationalmodellingofinteractionsbecomesricherandis
abletocapturenotjustwhatagentscommunicatebetweenthem,butalsowhatgoesoninsidetheirminds. Notably,
becauseToMisanintrinsiccomponentofdeception,inthissubsectionwewilllookcloselyattheroleToMplaysin
eachformofdeception. Moreoftenthannot,itistheToMoftheopponentthatdetermineswhattypeofdeceptiontakes
placeattheinteractionlevel,aspropertiesoftheToMthatarebeingusedbytheagentsbecomethepropertiesofthe
typeofdeceptionemployedbytheagents,whereaswhentheinteractionsarescaleduptoagreaternumberofagents
(societies),thenthesocio-cognitivefactorscomeintoplayat,whichcallsforananalysisatthedescriptivelevel. Hence,
wesuggestthefollowingdeceptionmodelstoberepresentedandengineeredinamulti-layeredfashion,andstudiedat
theinteractionlevelwithinDAMAS.
One-WayInteraction(Deception) Wecallaone-waycomputationaldeceptionaninteractionbetweentwotypesof
agents: thedeceiver,Alice,andthetarget,Bob. Alice’sgoalistomakeBobbelievesomethingthatAlicebelievesis
false.
ThedynamicsAliceandBobengageinrepresentthetwoprocessesidentifiedbyIMT2asParsProTotoandTotumEx
Parte. Aswehavementionedbefore,deceptionisaboutmakinganotherinferafalsebelief,thereforeitdoesnotreally
mattertoAlicewhetherwhatshetellsBobistrueornotaslongasAlicemanagestomakeBobinferafalsebelief. This
hereshowsthedifferencebetweenprovidingfalseinformation,whichmeanslying,andprovidingcertaininformation
thatleadstoafalseconclusion,whichmeansdeceiving. DependingonthecontextAlicefindsherselfin,sheneeds
todecidewhetherthenecessaryinformationsheneedstoprovideBobinordertodeceivehimisalieoratruth,ora
half-truth,oracombinationofthemthatismoreorlesscomplex.
AstrongfocusinAIisonthelogicalformalisationandcategorisationofone-waydeception. Forexample,Sakama
andCaminada[2010]aimtocategorisemultipleformsofone-waydeceptionandexplaintheirlogicalproperties,and
Sakamaetal.[2010]lookatthemultiplevariationsofdishonestyincludingone-waydeception,whereasCaminada
[2009]looksatthelogicalrelationbetweentruthandotherformsofdishonestysuchaslying,bullshitting7andeven
someformsofone-waydeception. Sakama[2015]alsousesdynamicepistemiclogictoformalisedeceptiveactsof
communication. Later,Sakama[2021]addsacausalmodelforepistemicdynamicsdeterminedbycommunication.
One-waydeceptionhasbeenalsostudiedfromanagent-orientedperspective. DeRosisetal.[2003]showasimulation
ofdeceptioninbeliefnetworks, whereasChristianandYoung[2004]defineamodelofaheuristicplansearchfor
findingadeceptionplan. Morerecently,Panissonetal.[2018a]definedandimplementedaBDIagentusingJason(an
agentorientedprogramminglanguage)thatcanchoosetolie,bullshitordeceiveinordertomanipulatethebeliefsof
anotheragent. ThisworkwascontinuedbySarkadietal.[2019b],Sarkadi[2021]whointegrateditwithTDT,IDTand
IMT2. There,thedeceptiveinteractionsbetweentwoBDIagentsaredefinedandimplemented,wherethedeceiver
agentsimulatesthemindofitstargettakingintoaccountthelevelsofthetarget’strust,theconfidenceinitsToMofthe
target,andthelevelofitscommunicativeskill. Theapproachintroducestheideathatdeceptioncanbeanalysedin
multi-agentsocialinteractionsnotonlyregardingitssuccess(successfulvsunsuccessful),butalsoregardingwhetherit
wasattemptedorintended(intendedvsunintended).
Acriticalquestionaboutone-waydeceptionthathasnotbeenexplicitlyexploredyetishowwouldtheinteraction
between a deceiver and its target evolve over time? For example, how would cognitive load and trust increase or
decreaseandunderwhichconditions? Also,howwouldthedeceiverandtheinterrogatorupdatetheirToMofeach
othergivenpastinteractions?
Two-WayInteraction(CounterDeception) -Comparedtoone-waydeception,counterdeceptioneliminatesthe
assumptionofBob’sunknownunknown. Insteadofplayingjustonerole,bothAliceandBobplaytherolesofthe
deceiverandthetarget. Inthiscase,thesamereasoningmechanismistakentoahigherlevel. Bob’sgoalisnowto
deceiveAliceintothinkingthathehasinferredafalsebelief. Alice’sgoalistodeceiveBobintothinkinghewasableto
deceiveheraboutdeceivinghimandsoon. ThesimplefactthatBobisawareofAlice’sdeceptiveintentions,might
giveawayBob’ssuspicion. TodeceiveAliceintothinkinghehasbeendeceived,Bobmustemulatesomebehaviourthat
makesAlicethinkhewasdeceivedbyher. However,ifBobknowsthatAliceknowsthatBobmightwanttodeceive
7Bullshitting,accordingtoFrankfurt[2009]ismakingstatementswithoutregardfortheirtruthvalue.
13Sarkadi. DeceptionAnalysiswithArtificialIntelligence
Aliceandsoon,thenwhattypeofbehaviourshouldBobsimulate—theoneindicatingthathewasdeceivedortheone
indicatingthathewasn’tdeceived—inordertodeceiveAlice?
WorkintheIntelligenceAnalysisliteraturehasledtosolidpsychologicaltheoriesofcounter-deceptionanddeception
detectionindicatingthatIntelligenceandEspionageAgenciesareoftenengaginginverycomplexcounter-deception
analysisHeuer[1999].Counterdeceptionhasalsofounditsapplicationsininterrogations.Wheninterrogatorshappento
dealwithdeceptiveormanipulativesubjects,theycanresorttocounter-deceptiontoincreasetheirchancesatsuccessful
interrogationVrijandGranhag[2012]. Forexample,theinterrogatorcanpretendtoknowsomeinformationapriori
suchthatthesubjectistrickedintogivinganswersthatrevealorconfirmthetruthoftheinformationtotheinterrogator’s
questions. Studiesshowthatinterrogatorstrainedincounter-deceptionhaveagreatersuccessatdeception-detection
Hartwigetal.[2006]. Moreover,thiseffectcanbealsoobservedinMASsimulations,wheredeceiversandinterrogators
seemtoengageinaToMarmsraceSarkadi[2023b].
Two-WayRecursiveInteraction -Intheory,counterdeceptioncanbeinfinitelyrecursive.Thepropertyofrecursivity
in counter-deception, however, depends on the type of ToM of the opponent. A recursive ToM means that agents
addlevelsofToMontopofeachother’sToMofthemselves. Forexample,“IknowthatyouknowthatIknow...ad
infinitum...someinformation”representsarecursiveToM.AnentirelyrecursiveToMwouldmeanthatthedeceptive
reasoningprocessesofadeceiver’smindwouldonlyfocusontakingacertainbelief,letussayBel (P)andinfering
i
Belk(Belk(P)) in order to gain some advantage using deception, where i and j represent different agents and k
j i
representsthelevelofToM.However,ininteractionsthatassumeanentirelyrecursiveToM,theonlyadvantagebelongs
totheagentthathasathegreaterlevelofToMasshownbyagent-basedsimulationsofgamesplayedbetweenagents
withmultipleordersofToMdeWeerdetal.[2017].
PartiallyRecursiveInteraction -Inpractice,humanagentsarerationallyboundedandarenotcapableofinfinitely
recursivereasoning. Thus,inreallife,deceptionisnotappliedtoinfinitelyrecursivementalmodels. Theremightbe
casesinwhichadeceivercouldexploititstarget’smindwithoutengaginginexpensiverecursivereasoning. Theremight
bebeliefsthatdonotexistinthetarget’sToMofthedeceiver. Ortheremightbebeliefsofthedeceiverthatthetarget
doesnotknowthatit(thetarget)doesnotknow(asinthecaseofRumsfeld’sunknownunknowns). Insuchcases,it
mightbewiserforthedeceivertoavoidspendingcognitiveresourcesonthehigher-orderreasoningofToMandexploit
othertypesofbeliefsinsidethetarget’smind. Thedeceivermight,forexample,simulatethebeliefupdatesthathappen
inthemindofthetargetinordertoseewhatnewbeliefscanbeformedandalsoexplorewhichofthesenewlyformed
beliefscanbemoreefficientlyexploited. ThistypeofToMimpliesadynamicsemanticToMmodel. Dynamicsemantic
modelsofToMinMASbasedonbelief-desire-intentionarchitecturesandagentorientedcommunicationalongwith
theiruseunderuncertaintyhavebeenintroducedandimplementedbySarkadietal.[2018],andmorerecentlydescribed
byShvoetal.[2020]. Oneinstanceofpartiallyrecursivecounter-deceptionhasalsobeenintroducedaspreliminary
workonargumentationdialoguegames,whereboththedeceiverandtheinterrogatorhaveaToMofeachotherthat
theyupdateaftereveryinteraction,inSarkadietal.[2019a]. ThedeceiverusesitsToMtobuildastorythatforcesthe
interrogatortoacceptit,andviceversa,theinterrogatorforcesthedeceivertoacceptthatithasnotfoundabelievable
story.
InternalInteraction(Self-Deception) -Theexceptiontothepresumablyintuitiverulethatdeceptionrequiresatleast
twoagents(deceiverandtarget)isthecaseofself-deception. Inorderforself-deceptiontobesuccessful,thedeceiver
mustbeabletodeceiveitself,playingboththeroleofthedeceiveranditstarget. Herewehaveaparadoxicalsituation.
AssumingthatthedeceiverneedsaToMofitstargetinordertodeceive,thenthedeceiverneedsaToMofitself. Given
thatthesameentityplaysboththeroles, thenitmustontologicallyfollowthatitsToMofitselfmustbecomplete,
i.e. thereisnoknowledgeaboutitselfthatitdoesnotknow. IftheToMiscomplete,thentheToMmustincludethe
deceiver’sdeceptiveintentionsorgoalsaswellasthetarget’sgoalofnotbeingdeceived. Obviously,thesetwotypes
ofconflictinggoalsandintentionsdetermineaninconsistentsystem. However,therearesomespecialcasesinwhich
theseparadoxicalsituationscanbeovercome. Jones[2015]managestomodelaspecificsetofcasesofself-deception
thatarelogicallyconsistentinHintikka’slogicofbelief. Theauthordoesemphasisethatsuchinconsistenciesstill
remaininsidethesystem,butbecomelatentduetothespecificcasesthatareformalised,andJonesexplainsthereasons
forthembecominglatent. AfairlynewideahasbeenproposedinbyChen[2021]tousemodelsofself-deceptionin
designingpersuasivesoftwareapplicationstonudgepeopletosleepbetter,buteventhoughitisworthmentioning,
thistypeofresearchisstillinitsinfancy. Onasimilarnote,beforeChen,BorensteinandArkin[2016]haveactually
proposedtheideathatethicalrobotscouldbeusedtonudgehumansintomakingmoreethicaldecisionsintheirlife.
Perhapsself-deceptioncanactuallydriveteamworkandcooperationinhybridsocieties? Ifso,thenhowdowemodel
interactionstoanalysetheoutcomesofpromotingself-deceptioninhumanswithAItechnologies,orevendeploying
self-deceptiveagents?
14Sarkadi. DeceptionAnalysiswithArtificialIntelligence
4.1.2 Descriptive(ABM)ModelsofHybridSocietiesforDAMAS
Intheprevioussubsectionwehavedescribedagentmodelsthatdealwithdifferentformsofdeceptionataninteraction
level. Butwhathappenswhenwegobeyondthemechanicsofinteractionandtrytomodeldeceptionatadifferentlevel
ofabstraction,e.g. whenmorethantwoagentsareinvolvedindeceptiveinteractionsthathappenaspartofadynamic
andlargedistributedsystemofagents? Tomodeldistributeddeception,weneedtolookatgroup-basedinteractions,
thatareassumedtotakeplaceinpopulationsorsocietiesofagents. Here,agentscaneitherrationallydecidetochange
therolestheyplaybasedonwhotheyinteractwith,ortheyareassignedtheirrolesthroughsomemechanism(usuallya
stochasticone).
Whileintheinteractionmodelsofdeceptionthefocuswasonthereasoninganddecisionmechanisms,herewecan
assumesuchmechanismsasagiven,andfocusonthetrade-offsofusingcombinationsofdifferentmechanisms. The
trade-offitselfshoulddependonthefactorsthatinfluencedeceptionsuchasthetypesofotheragentstheyinteractwith,
theinformationavailabletothem,theiravailableToMs,thecognitiveloadoftheagents,theircommunicativeskill,
thetrustbetweenthem,thecommunicationprotocoltheyfollow(orthespecificgametheyplay). Dependingonthe
typeofeachdistributedsystemtheagentsbelongto,thecostofdeceiving,interrogatingorcounter-deceivingmight
differ. Therefore,anoverarchingresearchquestionfordistributeddeceptionwouldbehowdoesthecostofdeception
influenceagentsinlargescaleinteractions? Weclassifydistributeddeceptioninthreetypestoseewhatotherrelevant
questionsmightdriveitsagent-basedmodellingwithDAMAS.
TypeI:Multipledeceiversandasingletarget -Theobviousproblemwouldbefordeceiverstofindawayinwhich
theyareabletomaximisethelikelihoodoftheirsuccessthroughcooperatingwitheachother. Howdotheycooperate
witheachothertodeceivetheirtarget,assumingthatallofthedeceiversshareasinglegoalintermsofwhatfalsebelief
theywanttheirtargettoinfer? Morespecifically,howdothedeceiversmanagetoexecuteParsProTotoefficiently
betweenthemselves? Whatinformationdotheyhavetodistributebetweenthemselves,whatinformationdoeseachof
thedeceivershavetowithholdandwhichinformationdoeseachofthemhavetosendandinwhatway? Whichofthem
hastolieandwhichhastotellthetruth,andinwhatsequence? AssumingtheyrequireaToMtodeceive,dotheyhave
toshareinformationabouttheirToMsofthetargetbetweenthemselves? Doesthepresenceofmoredeceiversmeana
higherlikelihoodofsuccess,ordoesithinderthedeceptiveprocessbyaddinglayersofreasoningandincreasethe
complexityofreasoninganddecisionmaking?
Type II: A single deceiver and multiple targets - A single deceiver has to account for multiple targets. This
caseshouldnotbeconfusedwithmultipleone-waydeceptionwhereasingledeceiverrepeatedlyemploysone-way
deceptionseparatelyforeachtarget. IntypeII,thedeceiverneedstotakeintoaccountatleastmorethanonetarget
whenattemptingadeceptiveact. Oneresearchquestionwouldbehowdoesthedeceiverdisseminateinformationtoits
differenttargetsgivendifferentcombinationsofconstraints? Thetargetsofthedeceivermightcooperatebysharingand
comparinginformationbetweenthemselvesinordertoprotectthemselvesfromdeceivers. Maybeonlysomeofthem
cooperateandsomeofthemdonot. Perhapsthedeceiverhasmultipletargets,butonlyoneofthemiscrucialforits
success. Thus,anotherquestionmightbehowcanthedeceiverexploitcooperationandnon-cooperationbetweenits
targetsinordertosuccessfullydeceive?
TypeIII:Multipledeceiversandmultipletargets -Itmightbeinterestingtoassumethatagentsareabletoplay
boththeroleofdeceiversandpotentialtargets. Agentsareabletodecidewhatroletoplaybycalculatingtheirpay-offs
toseewhetherisitprofitable(rational)toa)deceiveatargetorb)toriskbeingatargetitselfandblindlytrusttheagent
itinteractswithorc)trytoonlyactasatargetinordertointerrogateorcounter-deceivetheotheragent. Moreover,
isthereadifferentpay-offwhentryingtodeceivemorethanoneagent? Whatifthedeceiverneedstointeractwith
multipleagentsatthesametimeorinacertaingivensequence? Arealloftheseagentseasytargets,oraresomeof
themcounter-deceivers? Finally,howdowecontrolorgovernasocietywherethistypeofdeceptioncanhappen?
RegardingtherelatedworkinMASandABMondistributeddeceptionaswehavedefinedithere,theclosestworks
wouldbetheoneonevolutionofdeceptioninhybridsocietiesbySarkadietal.[2021a],SarkadiandLewis[2024]who
modellarge-scaleandlong-terminteractionsaspublic-goods-games,andtheworkontheprofitabilityofincompetence
byStaabandCaminada[2010]whodefineartificialagentsthatbullshittheirwaythroughsocietyinordertomaintain
theviewthatthey(theagents)arecompetent.
Tosummarise,MASapproachescanbeusedtomodeldeceptionattheinteractionlevel,e.g. whathappensinsidethe
agents’mindswhentheycommunicatewitheachother-internalcognitiveprocessesandarchitecturesresponsible
fordeceptivecommunication. Ontheotherhand,ABMmodelscanbeusedtomodeldistributeddeception,e.g. to
describethestatesandequilibriagiventheemergentbehaviourofagentsinfluencedbythesocio-cognitivefactorsof
societieswheredeceptionispossible. However,simplyhavingrichagent-basedmodelsisnotenoughfornon-experts
15Sarkadi. DeceptionAnalysiswithArtificialIntelligence
Model SomeDAMAS-compatibleapproaches
One-WayDeception SakamaandCaminada[2010],Sakamaetal.[2010],Caminada[2009],
Sakamaetal.[2015],DeRosisetal.[2003],ChristianandYoung[2004],
Panissonetal.[2018a],Sarkadietal.[2019b]
Counter-Deception Sarkadietal.[2019a]*
Self-Deception Jones[2015],Chen[2021]*
DistributedDeception StaabandCaminada[2010],Sarkadietal.[2021a],SarkadiandLewis
[2024]
Table2: Thefourtypesofagent-orienteddeceptionandexamplesofpapersthatdescribeAIapproacheswhichcanbe
usedtomodeltherespectivetypes. Thenotation*representspreliminarywork.
(policy-makers,regulatorsetc.) tounderstanddeception,andmoreimportantly,tomakeinformeddecisionsregarding
deceptivetechnologiesindifferentcontexts. Humananalystsneedtomakesenseofthesemodelsandneedtoknowhow
tousetheminordertomethodicallystudydeceptioninacriticalmanner. Thisiswheretheliteratureandmethodsfrom
IntelligenceAnalysiscouldlendtheAIcommunityahelpinghandindesigningaMASframeworkthatisscientifically
non-reductionistic,usable,andexplainable.
4.2 ExplainingDeception-HybridArgumentationToolsforDAMAS
FortheinteractionanddescriptivemodelsofDAMAStobeusedinreal-worldanalysisanddecisionmaking-ina
meaningfulmanner-DAMASshouldprovideanalysts(endusers,notjustAIscientistsandexperts)withsomemeans
ormethodstoexplainandinterprettheABMandMASdynamics. RememberthatinhistoryandIntelligenceAnalysis,
tounderstanddeceptioninameaningfulmanner,deceptioncausationandcausationpreventionneedtobeunderstood
aspartofanoverarchingnarrativeFerris[1989].
Indeceptionanalysis,counterfactualorhypotheticalreasoningdealswithquestionsthatarerelevantforestablishing
event causation and event causation prevention. A promising approach in AI to address these questions is to use
argumentation-enabledtools,whichcouldbeintegratedinDAMASforautomatedreasoning. Cybersecurityresearchis
alreadylookingathowtheareaofargumentationcanbeusedtoperformthistypeofanalysisfortaskssuchascyber
attributionSimari[2019]. Argumentation-basedapproachescanalsobeusedincriminalforensicsasproposedbyBex
andVerheij[2010]andbackedbyZenker[2019]. Theimplementationofsuchsupporttoolsforintelligenceanalysisis
notnewandisindeedfeasible,aspreviousworkbyTonioloetal.[2015]demonstrates.
Giventhesecapabilitiesofargumentation-enabledtoolstofacilitateexplanations,werecommendtoincludeinDAMAS
Bex’shybridapproachtoargumentationandstorytellingtoexplaincausationandcausationpreventionasanarrative
suchthatitisintelligibleforanalysts(seeFig. 2). Bex[2011]’sapproachhasbeendesignedtobothrepresentcausal
chains of a main story and to use arguments to anchor the main story’s sub-stories in evidence, a process named
anchoringwhichresultsinexplanations. Byapplyingthisapproach,onedoesnotonlyfindanarbitrarystoryfora
causalchainofevents,butisabletoselectthebestmainstory(outofseveralviableones)thatiscomposedofseveral
sub-stories,e.g.,performtheinferencetothebestexplanation(IBE),byexplainingthroughargumentshowthemain
story’ssub-storiesarebackedbyevidence.
DAMAS’srichsocio-cognitiverepresentationsofdeceptiondynamics,providedbytheframework’srepresentational
power,wouldallowtheextractionofcomplexchainsofstorieswheremultipleagents,events,andinteractionsbetween
agentstakeplace. Bybeingabletoextractandinterpretthesecomplexchainsofevents,intelligenceanalystswouldbe
abletoreasonmorecriticallyandmoreclearlyaboutdeceptivescenarios,byconsideringmultipleconfigurationsof
agentsatdifferentlevelsofabstraction. Inturn,thiswouldallowanalyststocontrastandcomparemultiplenarratives
andselecttheonewiththestrongestexplanatorypower-inotherwords,toperformIBE.
Representingmultiplelevelsofabstractionshouldhelpanalyststakeintoaccountthecompleteandpartialknowledge
oftheagentsinvolvedintherespectivescenarios-interactionMASlevel,aswellastheeffectofthesocialfactors
that influence deception parameters - descriptive ABM level. Subsequently, analysts could describe and contrast
thecognitiveandcommunicativedifferences,whilecomparingsimilarities,thatfollowfromtherepresentationsand
behaviourofdeceptiveandnon-deceptiveagents. Forexample,itshouldbepossibleforananalysttodistinguishalie
fromaliewithdeceptiveintentChisholmandFeehan[1977],ifcomponentsofdeceptioncouldbedescribedbythe
DAMASmodulesbytakingintoaccountrelevanttheoriesandtaxonomiesofdeceptivecommunication. Additionally,it
iscrucialfortheanalyststobeabletosayifthereisanyintentional,unintentional,orevenself-deceptionhappening
Whaley[1982],andbeabletoidentifywhetherornot‘banal’deceptionisthecase-deceptionthatarisesfromusinga
16Sarkadi. DeceptionAnalysiswithArtificialIntelligence
technologythatdoesnotdeceiveonitsown,butitisdesignedtobedeceptiveinacertaincontextNataleetal.[2021].
Agoodwaytoidentifybanaldeceptioninhybridsocietieswouldbetolookatcaseswheredeceptioniscausedby
semi-autonomousmachineswhichcannotbeattributedintentionMastersetal.[2021b],andrepresenttheseinDAMAS.
UsingBex’sapproach,theobservablebehaviourofagentsinsideDAMAScouldbeusedtotestwhetherapotential
viablemainstory(acomplexhypothesis)abouttheirbehaviourcountsasanexplanationoftheirbehaviour. Howwell
thestoryisanchoredintheevidencecouldalsobeobservedinDAMAS,e.g.,howmanyitemsofevidenceconfirm
orfalsifythestory. Furthermore,thestorycouldbeusedtoconfirmorfalsifyhowcertaineventsintherealworld
mighthaveunfolded,butmoreimportantlyitcouldexplainhowtheymighthaveunfoldedornotifsomethingelse
werethecase. Thesearepreciselythesortsofexplanationsofagentbehaviourthathumanmindstrytofigureoutin
socio-cognitiveinteractionsMalle[2006]. Onemustalsobecarefulaboutgroundingtherepresentationinrelevant
theories, as selecting bias-prone theories for this purpose leads to errors in analysing deception using AI methods
Sánchez-MonederoandDencik[2020],StarkandHutson[2021]. Anyways,Bex’shybridapproachcouldalsobeused
tofindbiasesandinconsistenciesinsideDAMASw.r.t. thetheoriesthathavebeenusedtoimplementtheMASmodels.
PerhapsthereisconsiderableevidenceoutsidetheMASthatindicatesthattheagents’behaviourshouldhavebeen
different. DAMASwouldallowthentheidentificationoftheunderlyingcausefortheunexpectedbehaviour,atwhich
levelofabstractionithappens,andwhetheritcouldbecalibratedinsidethemodelthatrepresentsthatparticularlevelof
abstraction. Subsequently,followingthefeedbackofanalysts,AIexpertscoulddirectlyrevisetheunderlyingAImodel
accordingtoanewevidence-basedtheoryandre-implementitinsidetheframework. Thisprocesswouldbefacilitated
byDAMAS’sscalabilityandmodularity.
Storiescanchangebasedonnewevidence,newcharacters,ornewrules,whichmustbeconsideredbyDAMAS.A
storycanrepresenthowanewagentcharacterentersthestory,orhowthechainofeventsmovesfromonelocation
(domain)toanother,orperhapsthenarrativestyleofthestoryallowsforreferringbacktoevidenceorargumentsthat
haveacertaintemporalproperty(usinginformationavailableatadifferenttime),e.g. somethinghappenedinthepast
thataffectedthecurrentchainofevents,orperhapsifthischainofeventscontinuesinthisdirection,somethingrelevant
tothestorywillhappeninthefuture. Again,thiswouldbefacilitatedbyfollowingtheprinciplesofscalabilityand
modularityofdesigningDAMASmodelsintunewiththeopennatureofMASsystemsvanEijketal.[1999],Pinyol
andSabater-Mir[2013]wherenewtypesofagentsorsoftwaretoolsareaddedorremovedfromthesystem.
Byrepresentingdynamicsatdifferentlayersofabstractionintheworldmodels,DAMAScouldenablethegenerationof
narrativesfrommultiplepointsofview(PoV).Inthisway,onecouldexplainaphenomenonfromthePoVofasingle
agent,fromthePoVofmultipleagentsthatcaneitherhavebeenactivelyinvolvedinacontextorhaveonlybeenpassive
observers,orperhapsfromthePoVofaBigBrotherobserver,onethathasaccesstomultipleviewpointsofagents,as
wellasextensiveknowledgeofthechainsofeventsandthedomainsinwhichtheseeventshavehappened. Hence,todo
this,DAMASshouldhavemodelsthataccountfor(i)spatialscalability,suchastheanalysisofdeceptiononlarge
scales,e.g.,invariousregulatorysystems,organisationsandsocietiesofdifferentsizeswhereagentscaninteract;and
for(ii)temporalscalability,e.g.,changesandevolutionofinteractionsbetweenagentsovertime.
ToconveythesecomplexnarrativestousersandtoassistwiththedevelopmentofXAItoolsandmodels, socially
interactiveAIagentscanbedesignedaspartofDAMAStopromoteusability. WhenbuildingDAMASXAItoolsbased
onhybridargumentation,itisdesirabletogobeyondtheidentificationofcausalrelationsandtrytoembedmechanisms
thatgenerateuser-friendlyexplanationsofdeceptiveinteractions. Butwhatisauser-friendlyexplanation?
AccordingtoMiller[2019],explanationsdonotconsistsolelyofusingabductivereasoningtofindcausalrelations,but
theymustalsoincludeasocialprocess,whichreferstothewayofconveningtheknowledgetobeexchangedbetween
explainerandexplainee. RegardingMAStools,socially-awareAImeta-agentscanbemodelledandengineeredaspart
ofDAMASsothattheycanautomaticallynarratevariouschainsofcomplexeventstoanalysts. DAMASmodelsthat
enhanceabductivereasoningshouldbedesignedastoenablethesesocially-awareAImeta-agentstoextractnarratives
directlyfromtheagentdynamicsoftheMAS.Addingargumentationcapabilitiestosocially-awaremeta-agentscould
helpanalystsalsoengageincriticalandhypotheticalthinkingaboutpossiblenarrativesusingquestion-answeringgames.
Itisherewhereresearchindialogueargumentationgamesforagentsocialinteractioncanprovidemechanismsfor
reachingsoundconclusionsMcBurneyandParsons[2009]. Thecooperationbetweenhumansandartificialagents
wouldresultinabetterunderstandingofdeceptivescenariosthroughdialecticalreasoning. Forinstance,theapproaches
describedinShvoetal.[2020],Panissonetal.[2018b],Sarkadietal.[2018],MoscaandSuch[2021],Moscaetal.
[2020]couldbecombinedtomodelthesocialprocessbetweenartificialstorytellingmeta-agentsandtheirinterlocutors
(explainees). Theseapproachesseemappropriate,becausemosthumansprefertoexplainagentbehaviourinapractical
reasoningmannerbyreferringtobeliefs,desires,intentionsetc. Malle[1999,2006]. Storytellingmeta-agentscould
model the minds of the explainees in order to narrate complex chains of events in an efficient manner - achieving
the goal of explaining the phenomenon itself by taking into account the social context in which they explain the
phenomenon. Conclusively,byinteractingwithausableDAMAS,theanalysts’workloadandtedioustasks,suchas
17Sarkadi. DeceptionAnalysiswithArtificialIntelligence
manuallyperformingSATs,wouldbereducedandsimplifiedthroughtheinteractionswithsocially-explainableAI
agents.
Tosummarise,inordertosupportdeceptionanalysis,DAMASshouldbebuiltstartingfromexistingAItechniques
thatconsidertheneedofintelligenceanalyststounderstandeventcausationandeventcausationpreventionaspart
ofoverarchingnarratives. OneapproachtoperformdeceptionanalysiswithDAMASinthismanneristocombine
AImodelsandtoolswithBex’shybridapproachofusingstoriestoperformIBEofcomplexcases. Togetherwith
richrepresentations,modularity,andscalabilityofagentdynamicsinDAMAS,multiplenarrativescouldbeextracted
fromagentdynamicstodirectlyperformIBEfordifferentcomplexandopenscenarios. Finally,ifanalysts,giventheir
expertknowledgeabouttherealworld,believethereisanalternativebestexplanationthatcanbeinferredoutsidethe
MASmodels,theyshouldbeabletointeractwithAIexpertsinordertorefinethemodelswithinDAMAS.Inthis
way,analystswouldbeabletodiscovernewagentdynamicsandfurthertesttheirhypothesesfromasocio-cognitive
perspective,supportedbyanever-improvingAIframeworkfordeceptionmodellingandanalysis.
5 Conclusion
ThefutureofhybridsocietiesmaybethreatenedbythedevelopmentofdeceptiveAI.Tounderstandtheeffectsof
deceptionbetweenagentsofhybridsocieties,whethertheseagentsarehumansormachines,inthispaperweproposed
thedevelopmentofDAMAS.DAMASisenvisionedasamulti-agentframeworkforenhancingthesocio-cognitive
modelling,explanation,andanalysisofdeceptionfromtheperspectiveofIntelligenceAnalysis
Westartedthepaperbyintroducingtwoimportantperspectivesondeception,namelythephilosophyofdeceptionanda
socio-cognitiveperspective. Thephilosophicalperspectiveaimedtodefineandexplainwhatdeceptionisandwhatitis
not,byclarifyingsubtledistinctionsintheliterature. Theroleofthesocio-cognitiveperspectivewastofamiliarisethe
readerswiththesocio-cognitivefactorsandcomponentsresponsiblefordeceptioninhumans.
Next,wearguedthatifweaimtomodeldeceptionwithAItechniques,thenwemustadoptaholisticsocio-cognitive
perspectivebecauseotherwisewewouldfallintothetrapofscientificreductionism.Wefurtherarguedthatreductionism
inAIisnotinitselfbad,butthatinordertobuildaholisticunderstanding,thentheexistingAIapproachesmustbe
integratedaspartofanoverarchingMASframework. Ourargumentechoeswhathasbeenproposedabout20years
agoregardingthedevelopmentofatheorytounderstandtheroleoftrustanddeceptioninvirtualsocieties,notablyby
Castelfranchi[2000],CastelfranchiandTan[2001,2002]. Thereasonwehavereinforcedthisperspectiveisbecause
despitethesignificantnumberofcontributionsonsocio-cognitivemodellingoftrust,thesocio-cognitivemodellingof
deceptionhasnothadthesamemomentum. HavingsurveyedtheliteratureondeceptionmodellinginAI,webelieveit
isnowthetimeforthenextstageindeceptionmodellingandanalysis.
Hence,totakethemodellingofdeceptiontothenextstage,weproposedDAMAS.Wedescribeditspotentialtobridge
thescientificmodellingandengineeringofdeceptionwithAItechniqueswiththemethodsandtechniquesusedby
intelligenceanalyststounderstandandexplaindeceptioninreal-worldcomplexcases. Ifdeveloped,DAMASwould
beabletoactasaplatformthatenables(i)AIexpertstoformulateapproachesforthesocio-cognitivemodellingof
deception; (ii)AIexpertsand/orengineerstorepresentandimplementthesemodelsinmulti-agentframeworksat
multiple layers of abstraction (environment, agent, organisation); and (iii) intelligence analysts to use XAI hybrid
argumentationtoolstoextractandanalyseagent-basednarrativesinordertoperforminferencetothebestexplanation
(IBE).
Finally,wediscussedtheimpactofbeingabletounderstanddeceptionholisticallyinhybridsocietiesandwhatare
theethicalconsiderationsofmodellingdeceptiveAI.WepointedouttheriskofreachingaTragedyoftheDigital
CommonsGrecoandFloridi[2004]anddiscussedtheneedofdevelopingaccountable,responsibleandtransparent
deceptiveAIw.r.t. ethicalguidelines,suchastheguidelinesofHLEGfortrustworthyAIHLEG,inAI[2019]andthe
onesofIEEEonEthicallyAlignedDesignChatilaandHavens[2019]. Wethenpresentedtwoargumentsthatdefend
themodellinganddevelopmentoftrustworthydeceptiveAIforthebenefitofsocietyundertheconditionoffollowing
ethicalprinciplesofsuchasvalue-alignment,transparency,andscientificdiscovery.
Toconclude,wewishtoemphasisethatdeceptiveAIhasbothdrawbacksandbenefitsandthattobeabletounderstand
whattheseareandreasonaboutthem,aholisticsocio-cognitiveapproachtomodellingdeceptioninhybridsocietiesis
necessary. WehopethatthedevelopmentofDAMASwillbethenextstepinachievingthisunderstandingsuchthat
futurehybridsocietieswillbeabletoreapthebenefitsoftrustworthydeceptiveAIandavoidtherisksassociatedwith
thefuturedevelopmentanddeploymentofmaliciousdeceptiveAI.
18Sarkadi. DeceptionAnalysiswithArtificialIntelligence
References
HeikoHamannetal.Hybridsocieties:challengesandperspectivesinthedesignofcollectivebehaviorinself-organizing
systems. FrontiersinRoboticsandAI,3:14,2016.
StefanSarkadi. Deception. PhDthesis,King’sCollegeLondon,2021.
Michael L Mauldin. Chatterbots, tinymuds, and the turing test: Entering the loebner prize competition. In AAAI,
volume94,pages16–21,1994.
EmilyMBender,TimnitGebru,AngelinaMcMillan-Major,andShmargaretShmitchell. Onthedangersofstochastic
parrots: Canlanguagemodelsbetoobig? InProceedingsofthe2021ACMConferenceonFairness,Accountability,
andTransparency,pages610–623,2021.
AlanTuring. ComputingMachineryandIntelligence. Mind,59(236):433–460,1950. URLhttp://www.jstor.org/
stable/2251299.
PhilipRCohenandHectorJLevesque. Speechactsandrationality. In23rdAnnualMeetingoftheAssociationfor
ComputationalLinguistics,pages49–60,1985.
Phillip Staines. Linguistics and the Parts of the Mind: Or how to Build a Machine Worth Talking to. Cambridge
ScholarsPublishing,2018.
CristianoCastelfranchiandYao-HuaTan. Trustanddeceptioninvirtualsocieties. Springer,2001.
CristianoCastelfranchiandYao-HuaTan. Theroleoftrustanddeceptioninvirtualsocieties. InternationalJournalof
ElectronicCommerce,6(3):55–70,2002.
Rino Falcone, Munindar Singh, and Yao-Hua Tan. Trust in cyber-societies: integrating the human and artificial
perspectives,volume2246. SpringerScience&BusinessMedia,2001.
GianMariaGrecoandLucianoFloridi. Thetragedyofthedigitalcommons. EthicsandInformationTechnology,6(2):
73–81,2004.
S¸tefanSarkadi,AlexRutherford,PeterMcBurney,SimonParsons,andIyadRahwan. Theevolutionofdeception. Royal
SocietyOpenScience,8(9):201032,2021a.
RichardsJHeuer. PsychologyofIntelligenceAnalysis. CenterfortheStudyofIntelligence,1999.
JohnFerris. Theintelligence-deceptioncomplex: Ananatomy. IntelligenceandNationalSecurity,4(4):719–734,1989.
TimVanGelder. CanwedobetterthanACH? AIPIONews,55,2008.
SimonPope, AudunJøsang, andDavidMcAnally. Formalmethodsofcounteringdeceptionandmisperceptionin
intelligenceanalysis. Proceedingsofthe11thICCRTSCoalitionCommandandControlintheNetworkedEra,2006.
RoderickMChisholmandThomasDFeehan. Theintenttodeceive. ThejournalofPhilosophy,74(3):143–159,1977.
JamesEdwinMahon. Thedefinitionoflyinganddeception. InEdwardN.Zalta,editor,TheStanfordEncyclopediaof
Philosophy.MetaphysicsResearchLab,StanfordUniversity,winter2016edition,2016.
TimothyRLevine. Duped: Truth-defaulttheoryandthesocialscienceoflyinganddeception. UniversityAlabama
Press,2019.
MarcArtigaandCédricPaternotte. Deception: afunctionalaccount. PhilosophicalStudies,175(3):579–600,2018.
PaulEkmanandWallaceV.Friesen. NonverbalLeakageandCluestoDeception†. Psychiatry,32(1):88–106,feb1969.
ISSN0033-2747. doi: 10.1080/00332747.1969.11023575. URLhttps://www.tandfonline.com/doi/full/
10.1080/00332747.1969.11023575.
TimothyRLevine.Newandimprovedaccuracyfindingsindeceptiondetectionresearch.CurrentOpinioninPsychology,
6:1–5,2015.
BellaMDePaulo,DeborahAKashy,SusanEKirkendol,MelissaMWyer,andJenniferAEpstein. Lyingineveryday
life. Journalofpersonalityandsocialpsychology,70(5):979,1996.
BellaMDePaulo,JamesJLindsay,BrianEMalone,LauraMuhlenbruck,KellyCharlton,andHarrisCooper. Cuesto
deception. Psychologicalbulletin,129(1):74,2003.
CharlesFBondJrandBellaMDePaulo. Individualdifferencesinjudgingdeception:Accuracyandbias. Psychological
bulletin,134(4):477,2008.
CharlesFBondJrandWilliamEFahey. Falsesuspicionandthemisperceptionofdeceit. BritishJournalofSocial
Psychology,26(1):41–46,1987.
19Sarkadi. DeceptionAnalysiswithArtificialIntelligence
StevenAMcCornack,KellyMorrison,JihyunEstherPaik,AmyMWisner,andXunZhu. Informationmanipulation
theory2: apropositionaltheoryofdeceptivediscourseproduction. JournalofLanguageandSocialPsychology,33
(4):348–377,2014.
TimothyR.Levine. Truth-DefaultTheory(TDT). JournalofLanguageandSocialPsychology,33(4):378–392,sep
2014. ISSN 0261-927X. doi: 10.1177/0261927X14535916. URL http://journals.sagepub.com/doi/10.
1177/0261927X14535916.
JudeeKBurgoon,DavidBBuller,KoryFloyd,andJosephGrandpre. Deceptiverealities:Sender,receiver,andobserver
perspectivesindeceptiveconversations. CommunicationResearch,23(6):724–748,1996.
AlisonGopnikandHenryMWellman. Whythechild’stheoryofmindreallyisatheory. 1992.
AlvinIGoldmanetal. Theoryofmind. TheOxfordhandbookofphilosophyofcognitivescience,pages402–424,2012.
AlvinIGoldmanetal. Simulatingminds: Thephilosophy,psychology,andneuroscienceofmindreading. Oxford
UniversityPress,2006.
AllenNewell,HerbertAlexanderSimon,etal. Humanproblemsolving,volume104. Prentice-hallEnglewoodCliffs,
NJ,1972.
EduardHHovy. Pragmaticsandnaturallanguagegeneration. ArtificialIntelligence,43(2):153–197,1990.
AlisonGopnikandHenryMWellman. Reconstructingconstructivism: Causalmodels,bayesianlearningmechanisms,
andthetheorytheory. Psychologicalbulletin,138(6):1085,2012.
HanneAndersen. Thehistoryofreductionismversusholisticapproachestoscientificresearch. Endeavour,25(4):
153–156,2001.
DavidMarr. Vision: Acomputationalinvestigationintothehumanrepresentationandprocessingofvisualinformation.
MITpress,2010.
DavidPeeblesandRichardPCooper. Thirtyyearsaftermarr’svision: Levelsofanalysisincognitivescience,2015.
JohnBickle. Marrandreductionism. Topicsincognitivescience,7(2):299–311,2015.
JohnWKrakauer,AsifAGhazanfar,AlexGomez-Marin,MalcolmAMacIver,andDavidPoeppel. Neuroscience
needsbehavior: correctingareductionistbias. Neuron,93(3):480–490,2017.
MargaretABoden. Artificialintelligence. Elsevier,1996.
VirginiaDignumandFrankDignum. Agentsaredead.longliveagents! InProceedingsofthe19thInternational
ConferenceonAutonomousAgentsandMultiAgentSystems,pages1701–1705,2020.
Olivier Boissier, Rafael H Bordini, Jomi F Hübner, Alessandro Ricci, and Andrea Santi. Multi-agent oriented
programmingwithjacamo. ScienceofComputerProgramming,78(6):747–761,2013.
StefanSarkadi,BenWright,PetaMasters,andPeterMcBurney(Eds.). DeceptiveAI,volume1296. Springer,2021b.
JohnathanMell,GaleMLucas,andJonathanGratch. Welcometotherealworld: Howagentstrategyincreaseshuman
willingnesstodeceive. InProceedingsofthe17thInternationalConferenceonAutonomousAgentsandMultiAgent
Systems,pages1250–1257.InternationalFoundationforAutonomousAgentsandMultiagentSystems,2018.
FatimahIshowo-Oloko,Jean-FrançoisBonnefon,ZakariyahSoroye,JacobCrandall,IyadRahwan,andTalalRahwan.
Behavioural evidence for a transparency–efficiency tradeoff in human–machine cooperation. Nature Machine
Intelligence,pages1–5,2019.
MarkDras,DebbieRichards,MeredithTaylor,andMaryGardiner. Generatinganddetectingdeceptivelanguagein
virtualagents. InInternationalWorkshoponInteractingwithECAsasVirtualCharacters,page38.Autonomous
AgentsandMultiagentSystems(AAMAS),2010.
ChiakiSakama,MartinCaminada,andAndreasHerzig. Alogicalaccountoflying. InEuropeanWorkshoponLogics
inArtificialIntelligence,pages286–299.Springer,2010.
ChiakiSakama. Aformalaccountofdeception. InProceedingsofthe2015AAAIFallSymposiumSeries,2015.
ChiakiSakama,MartinCaminada,andAndreasHerzig. Aformalaccountofdishonesty. LogicJournaloftheIGPL,23
(2):259–294,2015.
ChiakiSakama. Deceptioninepistemiccausallogic. InStefanSarkadi,BenjaminWright,PetaMasters,andPeter
McBurney,editors,DeceptiveAI,pages105–123,Cham,2021.SpringerInternationalPublishing. ISBN978-3-030-
91779-1.
20Sarkadi. DeceptionAnalysiswithArtificialIntelligence
GrégoryBonnet,ChristopherLeturc,EmilianoLorini,andGiovanniSartor. Influencingchoicesbychangingbeliefs:
Alogicaltheoryofinfluence,persuasion,anddeception. InStefanSarkadi,BenjaminWright,PetaMasters,and
Peter McBurney, editors, Deceptive AI, pages 124–141, Cham, 2021. Springer International Publishing. ISBN
978-3-030-91779-1.
HansVanDitmarsch. Dynamicsoflying. Synthese,191(5):745–777,2014.
SaraLUckelman. Deceitandindefeasibleknowledge: Thecaseofdubitatio. JournalofAppliedNon-ClassicalLogics,
21(3-4):503–519,2011.
Andrew J.I. Jones. On The Logic of Self-deception. South American Journal of Logic, 1:387–400, 2015. ISSN
2446-6719. URLhttp://www.sa-logic.org/sajl-v1-i2/05-Jones-SAJL.pdf.
WallySmith,FrankDignum,andLizSonenberg. Theconstructionofimpossibility: alogic-basedanalysisofconjuring
tricks. Frontiersinpsychology,7:748,2016.
DavidChristianandRMichaelYoung. Strategicdeceptioninagents. InProceedingsoftheThirdInternationalJoint
ConferenceonAutonomousAgentsandMultiagentSystems-Volume1, pages218–226.IEEEComputerSociety,
2004.
PetaMastersandSebastianSardina. Deceptivepath-planning. InIJCAI,pages4368–4375,2017.
PetaMasters,MichaelKirley,andWallySmith. Extendedgoalrecognition: Aplanning-basedmodelforstrategic
deception. InProceedingsofthe20thInternationalConferenceonAutonomousAgentsandMultiAgentSystems,
pages871–879,2021a.
LyndonBenke,MichaelPapasimeon,andTimMiller. Modellingstrategicdeceptiveplanninginadversarialmulti-agent
systems. InStefanSarkadi,BenjaminWright,PetaMasters,andPeterMcBurney,editors,DeceptiveAI,pages76–83,
Cham,2021.SpringerInternationalPublishing. ISBN978-3-030-91779-1.
EugeneSantosandDeqingLi. Ondeceptiondetectioninmultiagentsystems. IEEETransactionsonSystems,Man,and
Cybernetics-PartA:SystemsandHumans,40(2):224–235,2009.
Rafael A Barrio, Tzipe Govezensky, Robin Dunbar, Gerardo Iniguez, and Kimmo Kaski. Dynamics of deceptive
interactionsinsocialnetworks. JournalofTheRoyalSocietyInterface,12(112):20150798,2015.
Aaron Schlenker, Omkar Thakoor, Haifeng Xu, Fei Fang, Milind Tambe, Long Tran-Thanh, Phebe Vayanos, and
Yevgeniy Vorobeychik. Deceiving cyber adversaries: A game theoretic approach. In Proceedings of the 17th
InternationalConferenceonAutonomousAgentsandMultiAgentSystems,pages892–900.InternationalFoundation
forAutonomousAgentsandMultiagentSystems,2018.
ThanhThiNguyen,CuongMNguyen,DungTienNguyen,DucThanhNguyen,andSaeidNahavandi. Deeplearning
fordeepfakescreationanddetection. arXivpreprintarXiv:1909.11573,2019.
GraceHuiYangandYueYu. Useofinterpersonaldeceptiontheoryincountersocialengineering. InProceedingsofthe
2ndInternationalWorkshoponRumoursandDeceptioninSocialMedia,2018.
CarloKopp,KevinBKorb,andBruceIMills. Information-theoreticmodelsofdeception: Modellingcooperationand
diffusioninpopulationsexposedto"fakenews". PloSone,13(11):e0207383,2018.
MatthewAitchison,LyndonBenke,andPennySweetser. Learningtodeceiveinmulti-agenthiddenrolegames. In
StefanSarkadi,BenjaminWright,PetaMasters,andPeterMcBurney,editors,DeceptiveAI,pages55–75,Cham,
2021.SpringerInternationalPublishing. ISBN978-3-030-91779-1.
KimberlyFerguson-Walter,SunnyFugate,JustinMauger,andMaxineMajor. Gametheoryforadaptivedefensivecyber
deception. InProceedingsofthe6thAnnualSymposiumonHotTopicsintheScienceofSecurity,pages1–8,2019.
BenWright,MarkRoberts,DavidWAha,andBenBrumback. Whenagentstalkback: Rebelliousexplanations. In
Proceedingsofthe2019XAIPWorkshop@ICAPS,2019.
ChiakiSakama. Dishonestargumentsindebategames. COMMA,75:177–184,2012.
Phan Minh Dung. On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic
programmingandn-persongames. ArtificialIntelligence,77:321–357,1995.
ChiakiSakama. Dishonestreasoningbyabduction. InTwenty-SecondInternationalJointConferenceonArtificial
Intelligence,2011.
OanaCocarascuandFrancescaToni. Detectingdeceptivereviewsusingargumentation. InProceedingsofthe1st
InternationalWorkshoponAIforPrivacyandSecurity,pages1–8,2016.
VorakitVorakitphan,ElenaCabrio,andSerenaVillata. "Don’tdiscuss": Investigatingsemanticandargumentative
featuresforsupervisedpropagandistmessagedetectionandclassification. InRecentAdvancesinNaturalLanguage
Processing(RANLP2021),2021.
21Sarkadi. DeceptionAnalysiswithArtificialIntelligence
JérômeDelobelle,AmauryDelamaire,ElenaCabrio,RamónRuti,andSerenaVillata. Siftingtheargumentsinfake
newstoboostadisinformationanalysistool. In4thWorkshoponNaturalLanguageforArtificialIntelligence(NL4AI
2020),2020.
MicahHClark. Cognitiveillusionsandthelyingmachine: ablueprintforsophisticmendacity. PhDthesis,Rensselaer
PolytechnicInstitute,2010.
AlistairM.C.IsaacandWillBridewell. Mindreadingdeceptionindialog. CognitiveSystemsResearch, 28:12–19,
jun 2014. ISSN 13890417. doi: 10.1016/j.cogsys.2013.07.001. URL http://linkinghub.elsevier.com/
retrieve/pii/S1389041713000363.
StefanSarkadi,PeterMcBurney,andSimonParsons. Deceptivestorytellinginartificialdialoguegames. InProceedings
oftheAAAI2019SpringSymposiumSeriesonStory-EnabledIntelligence,2019a. InPress.
DiogoRato,BrianRavenet,RuiPrada,andAnaPaiva. Strategicallymisleadingtheuser: Buildingadeceptivevirtual
suspect. InProceedingsofthe16thConferenceonAutonomousAgentsandMultiAgentSystems,pages1711–1713,
2017.
MauricioJ.OsorioGalindo,LuisA.MontielMoreno,DavidRojas-Velázquez,andJuanCarlosNieves. E-friend: A
logical-basedaiagentsystemchat-botforemotionalwell-beingandmentalhealth. InStefanSarkadi,Benjamin
Wright,PetaMasters,andPeterMcBurney,editors,DeceptiveAI,pages87–104,Cham,2021.SpringerInternational
Publishing. ISBN978-3-030-91779-1.
Alison R. Panisson, Stefan Sarkadi, Peter McBurney, Simon Parsons, and Rafael H. Bordini. Lies, bullshit, and
deceptioninagent-orientedprogramminglanguages. InProceedingsofthe20thInternationalTRUSTWorkshop@
IJCAI/AAMAS/ECAI/ICML,pages50–61,Stockholm,Sweden,2018a.CEURWorkshopProceedings.
StefanSarkadi, AlisonR.Panisson, RafaelH.Bordini, PeterMcBurney, SimonParsons, andMartinD.Chapman.
Modellingdeceptionusingtheoryofmindinmulti-agentsystems. AICommunications,32(4):287–302,2019b.
Jacqueline Kory Westlund and Cynthia Breazeal. Deception, secrets, children, and robots: What’s acceptable. In
Workshop on The Emerging Policy and Ethics of Human-Robot Interaction, held in conjunction with the 10th
ACM/IEEEInternationalConferenceonHuman-RobotInteraction,2015.
JesseGrayandCynthiaBreazeal. Manipulatingmentalstatesthroughphysicalaction. InternationalJournalofSocial
Robotics,6(3):315–327,2014.
AlanRWagnerandRonaldCArkin.Actingdeceptively:Providingrobotswiththecapacityfordeception.International
JournalofSocialRobotics,3(1):5–26,2011.
EmilyCCollins. Vulnerableusers: deceptiverobotics. ConnectionScience,29(3):223–229,2017.
JaeeunShimandRonaldCArkin. Biologically-inspireddeceptivebehaviorforarobot. InInternationalConferenceon
SimulationofAdaptiveBehavior,pages401–411.Springer,2012.
MichaelJ.Pettinati,RonaldC.Arkin,andAkshayKrishnan. Wolvesinsheep’sclothing: Usingshillagentstomisdirect
multi-robotteams. InStefanSarkadi,BenjaminWright,PetaMasters,andPeterMcBurney,editors,DeceptiveAI,
pages41–54,Cham,2021.SpringerInternationalPublishing. ISBN978-3-030-91779-1.
JaeeunShimandRonaldCArkin. Ataxonomyofrobotdeceptionanditsbenefitsinhri. In2013IEEEInternational
ConferenceonSystems,Man,andCybernetics,pages2328–2335.IEEE,2013.
MichaelRHyman.Deceptioninadvertising:Aproposedcomplexofdefinitionsforresearchers,lawyers,andregulators.
InternationalJournalofAdvertising,9(3):259–270,1990.
LouiseMcHugh,YvonneBarnes-Holmes,andDermotBarnes-Holmes. Arelationalframeaccountofthedevelopment
of complex cognitive phenomena: Perspective-taking, false belief understanding, and deception. International
JournalofPsychologyandPsychologicalTherapy,4:303–324,2004.
Alistair Isaac and Will Bridewell. White lies on silver tongues: Why robots need to deceive (and how). Oxford
UniversityPress,2017.
FiorellaDeRosis,ValeriaCarofiglio,GiuseppeGrassano,andCristianoCastelfranchi. Cancomputersdeliberately
deceive? A simulation tool and its application to Turing’s imitation game. Computational Intelligence, 19(3):
235–263,2003.
HarmendeWeerd,RinekeVerbrugge,andBartVerheij. Negotiatingwithotherminds: theroleofrecursivetheoryof
mindinnegotiationwithincompleteinformation. AutonomousAgentsandMulti-AgentSystems,31(2):250–287,
2017.
AlanFTWinfield. Experimentsinartificialtheoryofmind: Fromsafetytostory-telling. FrontiersinRoboticsandAI,
5:75,2018.
22Sarkadi. DeceptionAnalysiswithArtificialIntelligence
FrancescaBiancoandDimitriOgnibene. Frompsychologicalintentionrecognitiontheoriestoadaptivetheoryofmind
forrobots: Computationalmodels. InCompanionofthe2020ACM/IEEEInternationalConferenceonHuman-Robot
Interaction,pages136–138,2020.
StefanoVAlbrechtandPeterStone. Autonomousagentsmodellingotheragents: Acomprehensivesurveyandopen
problems. ArtificialIntelligence,258:66–95,2018.
DonaldRumsfeld. USDepartmentofDefensenewsbriefing,February12,2002. USDoDPressConferenceTranscript,
url=https://www.nato.int/docu/speech/2002/s020606g.htm,2002.
DavidCLogan. Knownknowns,knownunknowns,unknownunknownsandthepropagationofscientificenquiry.
Journalofexperimentalbotany,60(3):712–714,2009.
S¸tefan Sarkadi. Self-governing hybrid societies and deception. ACM Transactions on Autonomous and Adaptive
Systems,19(2):1–24,2024.
TimotheusKampik,JuanCarlosNieves,andHelenaLindgren. Coercionanddeceptioninpersuasivetechnologies. In
20thInternationalTrustWorkshop(co-locatedwithAAMAS/IJCAI/ECAI/ICML2018),Stockholm,Sweden,14July,
2018,pages38–49.CEUR-WS,2018.
Elizabeth Sklar, Simon Parsons, and Mathew Davies. When is it okay to lie? a simple model of contradiction in
agent-baseddialogues. InArgMAS,pages251–261.Springer,2004.
TathagataChakrabortiandSubbaraoKambhampati. (when)canaibotslie? InProceedingsofthe2019AAAI/ACM
ConferenceonAI,Ethics,andSociety,pages53–59,2019.
MarkCoeckelbergh. Howtodescribeandevaluate“deception”phenomena: recastingthemetaphysics,ethics,and
politicsofictsintermsofmagicandperformanceandtakingarelationalandnarrativeturn. EthicsandInformation
Technology,20(2):71–85,2018.
Amanda Sharkey and Noel Sharkey. We need to talk about deception in social robotics! Ethics and Information
Technology,23(3):309–316,2021.
SimoneNataleetal. Deceitfulmedia: ArtificialIntelligenceandsociallifeaftertheTuringTest. OxfordUniversity
Press,USA,2021.
StefanSarkadi, PeidongMei, andEdmondAwad. Shouldmyagentlieforme? AstudyonattitudesofUS-based
participantstowardsdeceptiveAIinselectedfuture-of-workscenarios. InProc.ofthe22ndInternationalConference
onAutonomousAgentsandMultiagentSystems(AAMAS2023).IFAAMAS,2023.
S¸tefanSarkadi. Deceptiveaiandsociety. IEEETechnologyandsocietymagazine,42(4):77–86,2023a.
TimMiller. Explanationinartificialintelligence: Insightsfromthesocialsciences. ArtificialIntelligence,267:1–38,
2019.
ChiakiSakamaandMartinCaminada. Themanyfacesofdeception. ProceedingsoftheThirtyYearsofNonmonotonic
Reasoning(NonMon@30),2010.
MartinCaminada. Truth,liesandbullshit;distinguishingclassesofdishonesty. InSocialSimulationWorkshopatthe
InternationalJointConferenceonArtificialIntelligence(SS@IJCAI.Citeseer,2009.
HarryGFrankfurt. Onbullshit. PrincetonUniversityPress,2009.
Aldert Vrijand Pär AndersGranhag. Eliciting cuesto deception and truth: Whatmatters are thequestions asked.
JournalofAppliedResearchinMemoryandCognition,1(2):110–117,2012.
MariaHartwig,PärAndersGranhag,LeifAStrömwall,andOlaKronkvist. Strategicuseofevidenceduringpolice
interviews: Whentrainingtodetectdeceptionworks. LawandHumanBehavior,30(5):603–619,2006.
S¸tefanSarkadi. Anarmsraceintheory-of-mind: Deceptiondrivestheemergenceofhigher-leveltheory-of-mindin
agentsocieties. In2023IEEEInternationalConferenceonAutonomicComputingandSelf-OrganizingSystems
(ACSOS),pages1–10.IEEE,2023b.
StefanSarkadi,AlisonR.Panisson,RafaelH.Bordini,PeterMcBurney,andSimonParsons. Towardsanapproachfor
modellinguncertaintheoryofmindinmulti-agentsystems. InProceedingsofthe6thInternationalConferenceon
AgreementTechnologies,pages3–17,Bergen,Norway,2018.Springer.
Maayan Shvo, Toryn Q Klassen, and Sheila A McIlraith. Towards the role of theory of mind in explanation. In
InternationalWorkshoponExplainable,TransparentAutonomousAgentsandMulti-AgentSystems,pages75–93.
Springer,2020.
Hung-ChiaoChen. Deceptivedreams: Nudgingforbettersleep. InStefanSarkadi,BenjaminWright,PetaMasters,
andPeterMcBurney,editors,DeceptiveAI,pages27–37,Cham,2021.SpringerInternationalPublishing. ISBN
978-3-030-91779-1.
23Sarkadi. DeceptionAnalysiswithArtificialIntelligence
JasonBorensteinandRonArkin. Roboticnudges: theethicsofengineeringamoresociallyjusthumanbeing. Science
andengineeringethics,22(1):31–46,2016.
StefanSarkadiandPeterRLewis. Thetrianglesofdishonesty: Modellingtheevolutionoflies,bullshit,anddeception
inagentsocieties. InProc.ofthe23rdInternationalConferenceonAutonomousAgentsandMultiagentSystems
(AAMAS2024).InternationalFoundationforAutonomousAgentsandMultiagentSystems(IFAAMAS),2024.
EugenStaabandMartinCaminada. Ontheprofitabilityofincompetence. InInternationalWorkshoponMulti-Agent
SystemsandAgent-BasedSimulation,pages76–92.Springer,2010.
GerardoISimari. Fromdatatoknowledgeengineeringforcybersecurity. InProceedingsofthe28thInternationalJoint
ConferenceonArtificialIntelligence,pages6403–6407.AAAIPress,2019.
FlorisJBexandBartVerheij.Storyschemesforargumentationaboutthefactsofacrime.In2010AAAIFallSymposium
Series,2010.
FrankZenker. FromStories-viaArguments,Scenarios,andCases-toProbabilities: CommentaryonFlorisJ.Bex’s"
TheHybridTheoryofStoriesandArgumentsAppliedtotheSimonshavenCase"andBartVerheij’s"Analyzingthe
SimonshavenCaseWithandWithoutProbabilities". Topicsincognitivescience,2019.
Alice Toniolo, Timothy J Norman, Anthony Etuk, Federico Cerutti, Robin Wentao Ouyang, Mani Srivastava, Nir
Oren,TimothyDropps,JohnAAllen,andPaulSullivan. Supportingreasoningwithdifferenttypesofevidencein
intelligenceanalysis. InProceedingsofthe2015InternationalConferenceonAutonomousAgentsandMultiagent
Systems,pages781–789,2015.
Floris J Bex. Arguments, stories and criminal evidence: A formal hybrid theory, volume 92. Springer Science &
BusinessMedia,2011.
BartonWhaley. Towardageneraltheoryofdeception. TheJournalofStrategicStudies,5(1):178–192,1982.
PetaMasters,WallySmith,LizSonenberg,andMichaelKirley. CharacterisingdeceptioninAI:ASurvey. InStefan
Sarkadi,BenjaminWright,PetaMasters,andPeterMcBurney,editors,DeceptiveAI,pages3–16,Cham,2021b.
SpringerInternationalPublishing. ISBN978-3-030-91779-1.
BertramFMalle. Howthemindexplainsbehavior: Folkexplanations,meaning,andsocialinteraction. MITpress,
2006.
JavierSánchez-MonederoandLinaDencik. Thepoliticsofdeceptiveborders:‘biomarkersofdeceit’andthecaseof
iborderctrl. Information,Communication&Society,pages1–18,2020.
LukeStarkandJevanHutson. Physiognomicartificialintelligence. AvailableatSSRN3927300,2021.
RogierMvanEijk,FrankSdeBoer,WiebeVanDerHoek,andJohn-JulesCMeyer. Openmulti-agentsystems: Agent
communicationandintegration. InInternationalWorkshoponAgentTheories,Architectures,andLanguages,pages
218–232.Springer,1999.
IsaacPinyolandJordiSabater-Mir. Computationaltrustandreputationmodelsforopenmulti-agentsystems: areview.
ArtificialIntelligenceReview,40(1):1–25,2013.
PeterMcBurneyandSimonParsons. Dialoguegamesforagentargumentation. InGuillermoSimariandIyadRahwan,
editors,ArgumentationinArtificialIntelligence,pages261–280.SpringerUS,2009.
AlisonR.Panisson,StefanSarkadi,PeterMcBurney,SimonParsons,andRafaelH.Bordini. Ontheformalsemantics
of theory of mind in agent communication. In Proceedings of the 6th International Conference on Agreement
Technologies,pages18–32,Bergen,Norway,2018b.Springer.
Francesca Mosca and Jose Such. Elvira: an explainable agent for value and utility-driven multiuser privacy. In
InternationalConferenceonAutonomousAgentsandMultiagentSystems(AAMAS),2021.
FrancescaMosca,S¸tefanSarkadi,JoseMSuch,andPeterMcBurney.AgentEXPRI:Licencetoexplain.InInternational
WorkshoponExplainable,TransparentAutonomousAgentsandMulti-AgentSystems,pages21–38.Springer,2020.
BertramFMalle. Howpeopleexplainbehavior: Anewtheoreticalframework. Personalityandsocialpsychology
review,3(1):23–48,1999.
Cristiano Castelfranchi. Artificial liars: Why computers will (necessarily) deceive us and each other. Ethics and
InformationTechnology,2(2):113–119,2000.
HLEG,inAI. EthicsguidelinesfortrustworthyAI. B-1049Brussels,2019.
Raja Chatila and John C Havens. The IEEE global initiative on ethics of autonomous and intelligent systems. In
Roboticsandwell-being,pages11–16.Springer,2019.
24