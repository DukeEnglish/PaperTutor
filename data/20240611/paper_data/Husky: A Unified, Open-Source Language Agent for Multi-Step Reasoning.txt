HUSKY: A Unified, Open-Source Language Agent
for Multi-Step Reasoning
JoongwonKim† BhargaviParanjape‡ TusharKhot§ HannanehHajishirzi†§
†UniversityofWashington ‡MetaAI §AllenInstituteforAI
update action generator generate
solution history action
Step 1: … [finish]
Output: … [code]
… [math]
Step N-1: … [search]
Output: … [commonsense]
Step N: [step desc.]
Output: [tool output] step desc.
generate (+execute) expert model delegate
[tool]
Figure1: Schematicof HUSKY. HUSKY iteratesbetweenactiongenerationwhereitgeneratesa
toolcallandthecorrespondinghigh-levelstepdescription,andactionexecutionwhereitusesthe
tool-associatedexpertmodeltoexecutetheaction,repeatingthisuntilitarrivesattheterminalstate.
Abstract
Languageagentsperformcomplextasksbyusingtoolstoexecuteeachsteppre-
cisely. However,mostexistingagentsarebasedonproprietarymodelsordesigned
totargetspecifictasks,suchasmathematicsormulti-hopquestionanswering. We
introduceHUSKY,aholistic,open-sourcelanguageagentthatlearnstoreasonover
aunifiedactionspacetoaddressadiversesetofcomplextasksinvolvingnumerical,
tabular,andknowledge-basedreasoning. HUSKYiteratesbetweentwostages: 1)
generatingthenextactiontotaketowardssolvingagiventaskand2)executingthe
actionusingexpertmodelsandupdatingthecurrentsolutionstate. Weidentifya
thoroughontologyofactionsforaddressingcomplextasksandcuratehigh-quality
datatotrainexpertmodelsforexecutingtheseactions. Ourexperimentsshowthat
HUSKYoutperformspriorlanguageagentsacross14evaluationdatasets. More-
over,weintroduceHUSKYQA,anewevaluationsetwhichstresstestslanguage
agentsformixed-toolreasoning,withafocusonretrievingmissingknowledgeand
performingnumericalreasoning. Despiteusing7Bmodels, HUSKY matchesor
evenexceedsfrontierLMssuchasGPT-4onthesetasks,showcasingtheefficacy
ofourholisticapproachinaddressingcomplexreasoningproblems. Ourcodeand
modelsareavailableathttps://github.com/agent-husky/Husky-v1.
1 Introduction
Recentadvancesinthecapabilitiesoflargelanguagemodels(LLMs)haveledtothedevelopmentof
languageagentstoaddresscomplex,multi-steptasks[16,54,52,41,57].AsLLMsarelimitedintheir
computationalorfactualaccuracies[30,24,26],languageagentsprovideacompellingalternativeby
interactingwithexternaltoolstosolvecomplextasksstep-by-step[11,34,14]. Asignificantnumber
Preprint.Underreview.
4202
nuJ
01
]IA.sc[
1v96460.6042:viXraPrompt If a map is designed such that 1 square inch represents 100 square miles, how much larger in square inches will
Texas be compared to Washington on this map, to the nearest integer?
solution history (input to step 2) solution history (input to step 3)
Step 1: Find the area of Texas in square miles. Step 1: Find the area of Texas in square miles.
Output: The area of Texas is 268,597 square miles. Output: The area of Texas is 268,597 square miles.
Step 2: Find the area of Washington in square miles.
Output: The area of Washington is 71,362 square miles. Step 3
Stage 1: Predict step+tool with action generator Stage 1: Predict step+tool with action generator
[search] Find the area of Washington in square miles. [code] Compute the difference in area between Texas and Washington on the map.
Stage 2: Generate query and execute action Stage 2: Generate code and execute action
# define the actual area of both states
area of washington in square miles area_texas = 268597
area_washington = 71362
# compute the map area of texas and california
map_texas = area_texas / 100
map_washington = area_washington / 100
# compute the area difference on the map
map_area_diff = round(map_texas - map_washington)
print(map_area_diff)
71,362 The area of Washington is 71,362 square miles. 1972 Texas will be 1,972 square inches larger than Washington on this map.
Figure2:OverviewofHUSKY. HUSKYsolvesmulti-steptasksfornumerical,tabularandknowledge-
basedreasoningbyjointlypredictingthenexthigh-levelstepandtoolwithanactiongenerator,and
executingtheactionwiththeassignedexpertmodel. Thisprocessrepeatsuntilitarrivesatthefinal
answer. Asshownabove,HUSKYemploysmultipleLMsinparalleltosolveacomplextask,withthe
actiongeneratorcoordinatingtheexpertmodels,similartohowseveralHuskiespullasleightogether.
ofexistinglanguageagentsemployproprietarymodelsthroughAPIcalls[29,40,20],whichare
difficulttoscaleduetotheassociatedcostsandlatencies. Meanwhile,recentopen-sourceLLMs
focusonspecifictaskssuchasmulti-hopQA[4,22]oremployconvolutedproceduresfortraining
datacurationandagentinference[55,33]. InthisworkweintroduceHUSKY,aunified,open-source
languageagentthatsolvescomplex,multi-stepreasoningtasksbydecomposingeachtaskintoaseries
ofexecutableactionsandperformingeachactionwithatooluntilitreachesaterminalstate. Unlike
other previous language agents that build on open LMs [4, 55], HUSKY provides a distinctively
generalizableyetefficientapproachtotrainanddeployopenlanguageagentsonawidevarietyof
taskswhilemaintainingaunifiedactionspace.
HUSKYjointlyaddressesnumerical,tabularandknowledge-basedreasoningtasksintwostages: 1)
actiongenerationwheretheactiongeneratorpredictstheactionwhichconsistsofthehigh-level
step to take and the tool to execute, and 2) action execution where the designated expert model
andtoolperformstheactionandupdatesthesolutionstate. Ouragentuseshighlyperformant7B
LMs[45,17,13,39]toinitializetheactiongeneratorandexpertmodelsinordertotestthecurrent
limitsofopenlanguageagents. HUSKY,asitupdatesitssolutionstatewithapre-definedontologyof
actionsuntilitarrivesataterminalstate,canbeviewedasamodern,LLM-basedreformulationof
classicalplanningsystemssuchasSTRIPS[9].
AsshowninFigure1,HUSKYiteratesbetweenthetwostagesuntilitarrivesataterminalstate. The
firstmoduleinHUSKYistheactiongenerator. Giventheinputquestionandthesolutiongenerated
sofar,theactiongeneratorjointlypredictsthenexthigh-levelsteptotakeandtheassociatedtool. The
toolsformingtheontologyofouractionsare[code],[math],[search]and[commonsense]. Ifthe
finalanswertothequestionhasbeenreachedinthesolutionhistory,thentheactiongeneratorreturns
the answer. Based on the tool assigned by the action generator, HUSKY calls the corresponding
tool,executesthetoolandre-writesthetooloutputsoptionallyintonaturallanguage. Eachtoolis
associatedwithanexpertmodel-acodegeneratorfor[code],amathreasonerfor[math],aquery
generatorfor[search]andacommonsensereasonerfor[commonsense].
TotrainHUSKY,weuseasimplifiedandgeneralizeablepipelinewherewefew-shotpromptateacher
modeltogeneratetool-integratedsolutiontrajectories,whicharecrucialtoendowingtooluseabilities
toHUSKY. Werearrangeoursetofsolutiontrajectoriestobuildtrainingdatafortheactiongenerator
andallexpertmodelsinHUSKY. Ourinferenceprocedurerequiresnoassumptionaboutaspecific
task,allowingustousethesameactiongeneratorandexpertmodelsacrossalldownstreamtasks.
2Additionally,weextensivelyevaluateHUSKYusingtasksthatrequireleveragingmultipletools. We
present decontextualized versions of DROP [7] and IIRC [8] where the question is re-written to
beunderstoodwithoutitspassageintheoriginaldataset. Moreover,webuild HUSKYQA,anew
benchmarkthatteststheabilitiesofmodelsandagentstocombineknowledge-basedandnumerical
reasoningtosolvecomplexqueries. HUSKYmatchesoroutperformsfrontiermodels[28]onthese
evaluation sets, demonstrating existing gaps in frontier models for mixed-tool reasoning and the
potentialofopenlanguageagentsthataretrainedonhigh-qualityinstancesofplanningandtooluse.
OurexperimentsindicatethatHUSKYgeneralizesacrossmultipletasksbetterthanotherlanguage
agentsincludingFIREACT[4]andLUMOS[55],andoutperformsotheragentsintasksoftheirown
expertise. Forexample,HUSKYoutperformsLUMOSonGSM-8K[6]bymorethan20pointsand
FIREACTonHotpotQA[53]by5points. HUSKYalsooutperformsFINMA[51]onFinQA[5]by
9pointsandCRITIC-70B[11]onTabMWP[21]by1.8points. Finally,HUSKYoutperformsCoT-
promptedgpt-4-0125-preview[28]onourdecontextualizedsubsetsofDROPandIIRCby3and5
points,usingonly7Bmodels. OnHUSKYQA,HUSKYwitha13Bactiongeneratorscoreswithin1
pointsbehindgpt-4o. OurexperimentsalsohintthatHUSKYcanbeextendedtoaddressawider
varietyoftaskswithoutperformancelossbyscalingtheactionspaceandthenumberofexpertmodels.
TheseresultsshowcaseourrobustrecipefordevelopingHUSKY,anopen-sourcelanguageagentthat
generalizesandachievescompetitiveperformanceacrossawidearrayofmulti-stepreasoningtasks.
2 RelatedWork
Languageagents. Languageagentshaverecentlygainedpopularityforsolvingcomplextasks.
Theseagentsutilizelanguagemodelstoperformspecializedtaskssuchasgeneratingahigh-levelplan
tosolvethetask[52,20],orassigningaspecifictooltoexecutethegivenstepofthesolution[54,55].
Suchagentscanlargelybeclassifiedintotwocategoriesdependingonthepropertyoftheunderlying
LMusedtoperformplanningandtoolassignment–closed-sourceandopen-sourceagents.
EarliergenerationsoflanguageagentshaveusedproprietaryLMs[28]toperformcorereasoning
operationsforsolvingmulti-stepproblems. Thisincludesgeneratingaparticularactiontotakegiven
thecurrentsolutionstate[54,29],writingentiresequencesoftoolstoexecute[40,20],orperforming
self-reflection[23,42]toevaluatethesolutiongeneratedsofar.Suchagentsharnesstherawreasoning
capabilitiesofproprietarymodelstodecomposeacomplextaskintosimplersubtasksandfaithfully
executeeachsubtask. However,theseagentsystemsincurhighcostsandlackinefficiencydueto
theAPIcostsandlatenciesassociatedwithproprietarymodels. Thelackofcontrollabilityofsuch
modelsalsohindersscientificanalysesintobuildingperformantandefficientlanguageagentsystems.
Morerecentworkhasaddressedthislimitationbyadaptingopen-sourceLMstoperformreasoning
operationsforsolvingcomplextasks[4,55,33]. Suchagentsareoftentrainedonsolutiontrajecto-
riesgeneratedbyateachermodel[12,47,4,55],effectivelydistillingthereasoningandtooluse
capabilitiesoftheteacherintoasmaller,openlanguagemodel[50]. Whiledemonstratingsuccess
inaddressingcomplexproblems,currentopenagentsareonlyspecializedforspecificdatasetsor
taskdomains[12,47,4,22],requiremultifacetedroundsofdatacuration[33]orinvolvemultiple
layersofinferencewithtask-specifictoolsets[55]whichhampersgeneralizabilityandefficiency. In
contrast,HUSKYworksacrossmultipletasksofvaryingdomainsandinvolvesaverystraightforward
datacurationprocedurewhichcanbehandledviafew-shotprompting. Moreover,HUSKY,being
looselyinspiredbyclassicalplanningsystems[9],featuresanintuitivetwo-stageinferencepipeline
whichinvolvesgeneratingandexecutingactionstakenfromacarefully-definedontologyoftools.
Tooluse. Languageagentsutilizetoolstoaddressspecifictaskswithbetterprecision[38,29,31].
Thiscaninvolveusingcodeinterpretersfornumericalcomputations[12,47]orretrievers/search
enginesforfactualgrounding[3,1]. Agentsareoftenevaluatedonmulti-stepreasoningtaskssuchas
math[6,15]orquestion-answering [53,10]. Whilesuchtasksmeasuremulti-stepreasoningabilities,
inpracticetheycanoftenbesolvedwithsingletypesoftoolsandarenotsuitableformeasuringan
agent’scapabilitytoutilizemultipletools. Meanwhile,thereexistbenchmarksthatfeaturethousands
ofhighlytask-specificAPIs[34,19]orabroadscopeoftoolssuchasPDFreaders[25],butsuch
benchmarkseither1)requireshallowformsofreasoningduetothesyntheticcombinationofdifferent
APIs,or2)requireawideontologyoftoolsthatbringsthescopeoutofthiswork. Inthisworkwe
introduceanewsetofevaluationstomeasuretheabilityoflanguageagentstosimultaneouslyretrieve
missinginformationandperformcomplexnumericalreasoning.
3Tool Model Input Output Functionality
[code] M x,h,s c Generatescodeforprecisecomputations.
c
[math] M x,h,s o Performsmathematicalreasoning.
m
[search] M x,h,s q Writessearchquerytoretrieveknowledge.
q
[commonsense] M x,h,s o Performscommonsensereasoning.
r
Table1: ToolsusedbyHUSKY. Alltoolsacceptthesameinputformat(taskinstructionx,solution
historyhandcurrentsteps). The[math]and[commonsense]toolsdirectlygeneratetheoutputto
thestep,andthe[code]and[search]toolsgenerateinputstobeexecutedbythecodeinterpreterand
searchengine,respectively. NotethatM ,M andM arefinetunedmodels,andM isnot.
m c q r
3 HUSKY: AModularFrameworkforSolvingMulti-StepReasoningTasks
WeintroduceHUSKY,withitsoverviewshowninFigure2. HUSKYisalanguageagentwhichsolves
complex,multi-stepreasoningtasksbyiteratingbetweentwostages: 1)predictingthenextaction
totake,and2)executingtheactionwiththedesignatedexpertmodel. Thisprocessisrepeatedby
HUSKY until the agent arrives at a terminal state. During the first stage, the action generator A
jointlypredictseachstepsandtooltforsolvingthetask,withtrepresentedbyspecialtokensas
summarizedinTable1. Thesecondstageinvolvesexecutingeachstepwithanexpertmodel,which
iseither1)amodelthatdirectlygeneratestheoutputtoeachstep([math],[commonsense]),or2)a
modelthatgeneratestheinputstobeexecutedbytheactualtools([code],[search]). Theterminal
stateisrecognizedbyAwhichreturnsthefinalanswerifitisfoundinthesolutionhistory.
3.1 ProblemFormulationandOverview
Givenataskinstructionxandthesolutionhistoryhgeneratedsofar,wetrainanactiongeneratorA
topredictthenextstepsanditsassociatedtoolt. WealsotrainexpertmodelsM whichacceptx,h
t
andsasinputsandfunctionasthetooltorthepreprocessorsfort. Inthisworkweuset∈{c,m,q},
whichareLM-basedmodulesthatgeneratecodesnippets,mathsolutionsandsearchqueries. Each
toolassignedbyAisrepresentedasaspecialtoken(Table1),whichisusedtorouteHUSKYtothe
correctexpertmodelforactionexecution.
Inferenceoverview. Figure 2providesanoverviewoftheinferenceproceduretakenbyHUSKY.
Duringinference,HUSKYassumesthattheactiongeneratorA,theexpertmodelsM m,M c,M
q
andthebasereasoningmodelM
r
areready. Giventheinputx, HUSKYiteratesoveratwo-stage
pipeline. ThefirststageinvolvesAgeneratingthenextsteps totakealongwithitstoolt forstepi,
i i
andthesecondstageinvolvesusinganexpertmodelroutedfromt togeneratetheoutputo . The
i i
mathandcommonsensereasoners(M ,M )directlygeneratethenaturallanguageoutputo ,while
m r i
thecodeandquerygenerators(M ,M )generateaninputc toacodeinterpreter,orq toasearch
c q i i
engine. Inthelattercase,M isusedtore-writethetool-executedoutputintothenaturallanguage
r
outputo . Afterthisstage,s ando areconcatenatedtothesolutionhistoryfromstepi−1suchthat
i i i
h ="h \ns \no "andtheprocessrepeatsagainforstepi+1withxandh asinputstoA. This
i i−1 i i i
processrepeatsuntilAidentifiesthefinalanswertoxinh.
Trainingoverview. AllmodulesinHUSKY(A,M m,M
c
andM q)aretrainedusingsynthetic
data(Section3.2.1)1. RefertoFigure3foravisualizationofhowthetrainingdataisconstructed.
Given a set of seed training tasks, a teacher LM is first used to construct a set of tool-integrated
solutiontrajectories. Eachstepiofthetrajectoryconsistsofthehigh-levelsteps toexecute,the
i
associatedtoolt chosenfromthetoolsetinTable1,thetool-executedoutputifapplicable–c for
i i
code,q forsearch–andthenaturallanguageoutputo ,whichisdirectlygeneratedformathand
i i
commonsense reasoning, and re-written from the tool-executed output for code and search. For
eachinput,oursystemgeneratesthetool-integratedsolutionsuntilt ∈{[code],[search]}iscalled.
i
Our system executes the tool and integrates its natural language output o back into the solution
i
1WedonotspecificallytrainM tomaintainitsfunctionalityasageneral-purposereasoneraddressingany
r
casewhere[code],[math]or[search]arenotused. Instead,weusefew-shotpromptingsothatadditional
reasoningoperationsthatappearwithnewtasks,suchastablelookups,canbequicklyaddedasdemonstrations.
4Prompt If a map is designed such that 1 inch represents 100 square miles, how much larger in square inches will Texas be compared to Washington on this map, in nearest integer?
Teacher S m T ` a ` ` 2 ` T` ` ` `o r 6 ht ` ` ` `i ee g ol o 8 ee ap o ul , s : 5 a o to1 . [ p 9 rs g f: eu 7 e l tI ae ted a xe r oc an fh s Tti ] ef iy n x at sh sqe u i sa a r 2re e 6a 8m o ,5if l e 9T s 7e x sa qs u ain r es q mu ia ler se . S T T ` # a a # w m m`e o r r t ` ad c a ae ee px o soe p pa ap ya l h: mf _ __ _ t s i3 h i[ n t wnt w c p ee: oa e g o aua xxC nn td st t asa od h eo e hh ss n e m ]W i i t nn =h =ap gga e ac 2u tts oot rm6t h u ee nn8i a a a n 5t ==l p _h g 9 a te t a7 a e7o r r1e r xd n ee3a ai af ao 6 sf _oe n 2 o / wfr e ft 1b ahn t 0o e sec 0t hx he m a i n si san gt p a a ta o. t ner nde s /a 1 b 0e 0tween S S O S O N W S S Oo t t eu u o tae e uel xt t lsp p tu p p pu pt h t u u 1 2 t usi 1i it t no : : to: : t : : ge n I I T T n I Td d t dp oh h h e e hh e ne e on n ei nis srt t oa a ti i at itf fo f fnr ry y o ryie e e r n r tt ta ay t ah yh h a h : ee e :o o l e o f f a fma a a T W n Tr r re ae e s eeax pa a w xasa . a eo o hs o srf f i fn i : iT Ws T sg Ce e t2 a 2x o o x6 s 6a n m a8 h 8s si, pi ,sn5 i 5iun ng9 7 9t t7 es 1 7so q , qns t3 su h uq q6ia e anu u2r r a de a s esr i rq fem q ef mu e u mi a mr il a le e eri r iels n lsee e. c . s m sm e. .i il ile nes s a. . rea betwa e cc e onti d o T een x g ag s e e a nn n ede r r aa tt oo rr
LM S s T ` a ` ` 7 ` T` ` ` `q o r 1 ht ` ` ` `ee g ou o , e3ap o ua l : 6 a o tr o2 [ pe 2 rs g f: eu e lm wI ae td a aie r ol ce sn fh hst Wi ]. if ny ag st th o he n in a ginr te osa nq uo isaf 7rW e 1 a ,m 3s 6ih le 2in s sg qto un a rin e # m m p ` ` 1 ` T W` ` ` r 9 h` ` `c a a i aon 7 eo p p sut 2 m (_ _ hdtm pa w iip nfu fr aau gee tpst trae oe_h_ nnait ndh cr ogi ee ef nf t a oa i= _ n tnr h d e r ) a eo ia f r fu me )d n a ai df f pb(e m er ise ta w n p 1ec _ ,9ee te 7n o x 2 Tn a e s st qxh - a ue s a m ra ea n ip d n ches. S O C m C a a m mr rt u ou a a ae ee r dt p p pa ap p r e _ __ _ eu2 : t wt wnt ee: : a t a xxI T d sasS ahe hh ssten ie i nn == t pa gi g f a: 2ry tt e oo rC 6 et a nn8h o a 5e o =m = _9 f ta ap 7 e7Wr ru 1 xe ea t 3 aa e as 6 s _o h t 2h / wf i n e 1 aW g 0 sdta 0 ho ifs in f neh gi ri sn e t og n7 nt c1o e, /n 3 1 i6 ni 0n 2 0 a s s rq equ aua a br re ee t m wm ei il le ees n. Texas and Washington on the
miles. The answer is: <answer>1972</answer>. m pra inp t(_ mar ae pa __ ad ri eff a = _ dro iffu )nd(map_texas - map_washington)
Figure3: TrainingdatasynthesisforHUSKY. AteacherLMisfew-shotpromptedtogeneratean
initialtrajectoryforaquestiongiveninatrainingtask. Then,eachsolutionisparsedtoextractsteps
andtheiroutputs,whichareusedtoconstructtrainingsetsforA,M ,M andM .
m c q
trajectoryuntilthesolutionreachesthefinalanswer. Thesolutiontrajectoryisthenusedasaseed
datasetfromwhichtraininginstancesforA,M ,M andM areextracted(Section3.2.2). For
m c q
theactiongeneratorA,theindividualstepsandtheirnaturallanguageoutputsareextractedtoform
a training instance. At step i, the prompt is formatted as a concatenation of x and h where
i−1
h = s \no \ns \no \n···\ns \no ,andthecompletionisthenextsteps . Meanwhile,
i−1 1 1 2 2 i−1 i−1 i
forM ,M andM ,thepromptisformattedasaconcatenationofx,h ands ,andthecompletion
c m q i i
isacodesnippet,mathsolutionorasearchquery.
3.2 HUSKYTraining
Wedescribeindetailtheprocedureforobtainingsyntheticdatausedtotrain(A,M ,M andM ).
m c q
Thetrainingdataisobtainedintwostages: 1)synthesizingtool-integratedsolutiontrajectorieswitha
teacherLM,and2)extractingtrainingpromptsforeachmodulefromthetool-integratedsolutions.
3.2.1 SynthesizingTool-IntegratedSolutions
AsHUSKYisanewlanguageagentframework,theredoesnotexisttrainingdatatoperformnext
steppredictionandtoolcalls,alongwithcode,mathorsearchquerygenerationforHUSKY. Previous
studieshavedemonstratedthatsmallermodelscanlearnfromdistillingthegeneratedoutputsoflarger
teacher modelsthathavebetterreasoningcapabilities[50,48]andhavedistilledtheirmulti-step
tooluseabilitiesintoopenLMstoadaptthemaslanguageagents[4,56,55]. Therefore,wefollow
existingapproachesandutilizeateacherLMT tofirstsynthesizetool-integratedsolutiontrajectories
foragivensetoftrainingtasks. Thesehigh-qualitysolutiontrajectoriesserveastheblueprintfrom
whichweautomaticallyextractandrearrangetheircomponentstobuildtrainingsetsforA,M ,
m
M andM –weuseeachsolutiontrajectorytosynthesizetrainingexamplesformultiplemodules.
c q
Datasynthesis. RefertoFigure3foranexampleofthetool-integratedsolutionandthemodule-
specifictrainingdataextractedfromthetrajectory. Oursolutiontrajectoryisformattedasasequence
ofstepss (i∈[1...]),thetoolt assignedtoeachstepi,andtheoutputo fromsolvingeachstepi.
i i i
Eachiterationofthesolutionbeginswiththehigh-levelsteptotake,writtenas"Stepi: s "fortheith
i
step,whichisthenfollowedbyatoolcallformattedas"Tool: t ". Thetoolt ischosenfromTable1.
i i
Ift ∈{[code],[search]},itisaccompaniedbyacodesnippetc orasearchqueryq generatedby
i i i
T andenclosedwithintheiridentifiertagspythonorgooglealongwithquotationmarks. c orq is
i i
thenexecutedbyacodeinterpreterorasearchengine,anditsoutputisrewrittenbyT intonatural
language. FormathorcommonsensereasoningwhoseexecutionoutputistheLM-generatedoutput,
t isdirectlyfollowedbyT’sgeneratedoutput. WegenerateeachsolutionwithT untilitidentifies
i
thefinalanswertoxwithitsidentifiertag<answer>.
Wefew-shotpromptT togeneratesuchtool-integratedsolutionsforalltraininginstancesintheset
oftrainingtaskswedesignatefordevelopingHUSKY. Aftergeneratingthetrajectories,weevaluate
thefinalanswerwithrespecttothelabelinthetrainingsetandkeepthesolutioninstanceswiththe
correctanswer. Weprovideexampletrajectoriesandfew-shotpromptsinAppendixEandJ.
53.2.2 TrainingHUSKYmodules
Weusethetool-integratedsolutiontrajectoriesasablueprinttoconstructtrainingdataforallmodules
inHUSKYthatrequiretraining.
Actiongenerator. TheinputtotheactiongeneratorAatstepiconsistsofthetaskinstructionxand
thesolutionhistoryh concatenatedas"{x}\n{h }"="x\n[s ]\n[o ]\n...\n[s ]\n[o ]".
i−1 i−1 1 1 i−1 i−1
Giventhisinput,Ageneratesanoutput"[t ]s ". Forexample,ifx="Findthebirthdayofthefirst
i i
presidentoftheUnitedStates",thenapossibleoutputfromAwouldbe"[search]Identifythefirst
presidentoftheUnitedStates."Weextractthestepsandtheiroutputsfromthesolutiontrajectoryvia
regexmatchingandorganizethemaccordingtotheformatabovetotrainA.
Expertmodels. Theinputtoeachexpertmodelconsistsofthetaskinstructionxandthesolution
history h , as well as the current step, s . Given this input, M returns code snippet c , M
i−1 i c i m
returnsamathsolutionm ,andM returnsasearchqueryq astheiroutputs. Forexample,given
i q i
thetaskinstructionabove,M wouldbetrainedtogenerateq =firstpresidentoftheunitedstates.
q i
Again,weextractthestepsandthetool-specificoutputsfromthesolutiontrajectoryandformatthem
accordinglytobuildthetrainingdatafortheexpertmodels.
We finetune all HUSKY modules independently on their respective training datasets, jointly con-
structedfromalltrainingtasks,usingthestandardnexttokenpredictionobjective.
3.3 HUSKYInference
WeintegratethemodulestrainedaccordingtotheprocedureaboveintoHUSKYtosolvenew,multi-
steptasksatinferencetime. Figure2providesanexampleof HUSKY performinginferencefora
complex,multi-steptask.
Fortaskinstructioninputx,HUSKYfirstassignstheactiongeneratorAtogeneratethefirststeps
1
thatneedstobetaken,aswellasitscorrespondingtoolt . WiththeexampletaskgiveninFigure2,
1
Areturns"[search]FindtheareaofTexasinsquaremiles."Inmanycases,thesolutionhistoryhis
providedalongwithxtoA. Forexample,thesolutionhistoryh ="Step1: FindtheareaofTexas
1
insquaremiles.\nOutput: TheareaofTexasis268,597squaremiles"isprovidedtoA,whichreturns
"[search]FindtheareaofWashingtoninsquaremiles."forstep2.
Giventhecurrentsteps
i
andtoolt
i
generatedbyA,HUSKYthenusesthetooltokent
i
toassign
a expert model M. The connections between t and M are: [code] token to the code generator
M , [math] token to the math reasoner M , [search] token to the query generator M and
c m q
[commonsense]tokentothecommonsensereasonerM . WhileM andM directlygenerate
r m r
thenaturallanguageoutputstothecurrentstep,M andM generatethecodesnippetandsearch
c q
query,whicharethenfedintoacodeinterpreterandasearchengine. Astheoutputsfromthesecode
interpretersandwebbrowsersareneithercontextualizeduponxorsnorarenaturallanguage,we
few-shotpromptM tore-writethetool-executedoutput. Forexample,giventhestep"Compute
r
thedifferenceinareabetweenTexasandWashingtononthemap."inFigure2anditsPythonoutput
1972,M generates"Texaswillbe1,972squareincheslargerthanWashingtononthismap."
r
Afteraniterationofthetwo-stageprocessabove,thecurrentsteps anditsnaturallanguageoutput
i
o isconcatenatedtothesolutionhistoryh tobefedasinputtothenextiterationoftheinference
i i−1
alongwithx. ThisprocedureisrepeateduntilAidentifiesthefinalanswertoxinitssolutionhistory
h ,atwhichpointitarrivesattheterminalstateandreturns"Theanswerisa."forthegivenanswera
i
andterminatestheprocess. IntheexampleinFigure2,Arecognizes1,972tobetheanswerafter
HUSKYcompletesstep3andreturns1,972asthefinalanswer.
3.4 HUSKYEvaluation
Evaluating HUSKY is a process of performing inference with HUSKY modules upon complex,
multi-stepreasoningquestionsandscoringthefinalanswersusingtheappropriatemetricforeach
dataset. Whiletherearenumerousdatasetsthatinvolvemulti-stepreasoningintheirsolutionssuchas
mathematicsormulti-hopQA[6,15,53,46],notmanydatasetsrequiretheuseofdiversetools. To
complementthisdeficiency,webuildHUSKYQA,anumericalreasoningdatasetwithincomplete
informationthatthelanguageagentmustfirstidentifyinordertosolvetheproblem.
6Forexample,considerthequestionIfamapisdesignedsuchthat1inchrepresents100squaremiles,
howmuchlargerinsquareincheswillTexasbecomparedtoWashingtononthismap,tothenearest
integer?. Whilethisquestionfundamentallyrequiresmathematicalreasoningtosolvecorrectly,the
informationabouttheareaofTexasandWashingtonisomittedandmustberetrievedbytheagent.
Tobuild HUSKYQA, wefirstgeneratesynthetic, factoidquestionsfromaseedlistof40diverse,
manuallycuratedsetoftopicsspanningeconomics,geography,sports,science,etc. Forthequestion
above,thetopicwouldbegeography(statearea)andthefactoidquestionswouldbeWhatisthearea
ofTexas? andWhatistheareaofWashington? Then,wesearchtheWebtoidentifytheanswerto
eachfactoidquestionandconvertthequestion-answerpairintoafactoidstatement. Accordingto
therunningexample,thestatementswouldbeTheareaofTexasis268,597squaremiles. andThe
areaofWashingtonis71,362squaremiles. Finally,wefew-shotpromptGPT-4togeneratesynthetic
questionsfrompairsoffactoidstatementsinthesametopicset.
Theresultingquestionsareconditionedupontheinformationfromthepairoffactoidstatementsused
togeneratethequestion,andrequiremathematicalreasoningatmiddle-schoolorhigh-schoollevelto
solvecorrectly. WelabelallanswersinHUSKYQAautomatically,andvalidateallouranswersinthe
testsetof292exampleswithhumanannotations. WeprovidemoredetailsinAppendixG.
WealsoprovidedecontextualizedversionsofasubsetofDROP[7]andIIRC[8],whichwerefertoas
DROP*andIIRC*. DROPandIIRCconsistofquestionscontextualizedonWikipediapassagesthat
requiremulti-stepreasoningwithknowledge-basedandnumericaloperations. Wedecontextualize
eachquestionbyfew-shotpromptinggpt-3.5-turbotointegratequestion-specificinformationfrom
thepassage. MoredetailsregardingDROP*andIIRC*canbefoundinAppendixF.
4 Experiments
4.1 TasksandDatasets
WetrainandevaluateHUSKY,alongwithotherbaselinelanguageagents,onadiversesetoftasks
thatrequiremulti-stepreasoningandbenefitfromtooluse. Abouthalfofthetasksareusedtotrain
HUSKYmodulesbasedontheirtool-integratedsolutiontrajectories,whiletheothersareheldoutand
introducedatinferencetime. Alltasksareevaluatedinazero-shotmanner.
Numericalreasoningtasks. Weincludemathematicsdatasetswithdifficultiesrangingfromelemen-
taryschooltohighschoolcompetition-mathproblems,includingGSM-8K[6],MATH[15],andthe
GoogleDeepMindmathematics[37]andMathQA[2]taskstakenfromtheLILAbenchmark[27].For
GoogleDeepMindmathematics,wemeasuretheperformanceontheAlgebra,BasicMath,Calculus,
Mulplication/DivisionandNumberTheorysubsets,andthesamefortheGain,General,Geometry,
PhysicsandProbabilitysubsetsinMathQA.WeuseGSM-8KandMATHfortrainingandholdout
theothersforevaluation. GSM-8KandMATHcontribute7.4Kand6.3Kcorrrectsolutiontrajectories
fromtheirtrainingsets,resultinginatotalof13.7Ktool-integratedsolutiontrajectories.
Tabularreasoningtasks.WeuseTabMWP,atabularmath-wordproblemdataset[21],FinQA[5]and
TAT-QA[58]whicharebothfinancequestion-answeringdatasets,andasubsetoftestquestionsfrom
MultimodalQA[44]whichrequiremulti-hopreasoningandunderstandingofbothtextandtabular
modalities. WeuseTabMWPandFinQAforbothtrainingandevaluation,andweholdoutTAT-QA
andMultimodalQA(MMQA)forevaluation. Wecollect2.6KcorrectsolutionsfromTabMWPand
4.6KsolutionsfromFinQA,resultinginatotalof7.2Ktool-integratedsolutiontrajectories.
Knowledge-basedreasoningtasks. WeincorporateHotpotQA[53],CWQ[43]andMusique[46]
whichcontaincomplexquerieswithmulti-stepsolutions,Bamboogle[32]whichcontainquestions
thatcanonlybesolveviamultipleGooglesearches,andStrategyQA[10]whichinvolvesretrieving
andreasoningovermultiplefacts. WeholdoutBamboogleandHotpotQAforevaluation,useCWQ
andMusiqueonlyfortraining,anduseStrategyQAforbothtrainingandevaluation. Wecollectabout
2.8KsolutionseachfromCWQandMusiQueand1.3KsolutionsfromStrategyQA,resultingina
totalof7Ktool-integratedtrajectories.
textbfMixed-toolreasoning tasks. While the datasetsabove involve diversemulti-step reasoning
strategies,theyoftencanbesolvedwithasingletypeoftoolandriskcontaminationbyproprietary
models. Thereforeweaddthreecustomtasksthatbettermeasurethemodeloragent’sabilityto
invokemultipletools. TheseconsistofourmodifiedversionsofDROPandIIRC,wherethequestions
7aredecontextualizedfromthepassages,aswellasHUSKYQA(Section3.4). WeuseDROP[7]and
IIRC[8]forbothtrainingandevaluation,andcollect3Ksolutiontrajectoriesfromeachdatasetfor
training. ForHUSKYQA,wesplitthedatasetbytopicandassign8manuallyselectedtopicstothe
evaluationsetandtheresttothetrainingset,whichyieldsatotalof1.3Ktool-integratedtrajectories.
RefertoAppendixCforadetailedbreakdownofthestatisticsregardingthesolutiontrajectories.
4.2 Models
Actiongenerator. WeuseLLAMA-2-7Band13B[45],andLLAMA-3-8Bfortrainingtheaction
generatorA. UsingthetaskslistedinSection4.1,weremovethesolutiontrajectorieswithincorrect
answersandcollectatotalof110KtraininginstancesforAacrossnumerical,tabular,knowledge-
basedandmixed-toolreasoningtasks. Wefullyfinetuneonthismulti-tasktrainingset[36].
Codegenerator. WechooseDEEPSEEKCODER-7B-INSTRUCT-V1.5[13]asthestartingpointfor
finetuningM ,duetoitsrobustcodingabilitiesat7Bparameters. AsdescribedinSection3.2,we
c
extractallcodeusedinthesolutiontrajectoriesthatreturnthecorrectanswers,andremoveanycode
thatfailstocompile. Wecollectatotalof44Kcodeinstancesandfullyfinetuneonthistrainingset.
Mathreasoner. Weselect DEEPSEEKMATH-7B-INSTRUCT [39]asthemodeltofinetuneM
m
from,duetoitsadvancedmathematicalreasoningcapabilities. InasimilarmannertoM ,weextract
c
allmathsolutionsinthetool-integratedtrajectorieswiththecorrectanswers. Thisresultsinatotalof
30Kmathsolutioninstances,uponwhichwefullyfinetuneM .
m
Querygenerator. Asthereisnomodelspecializedforsearchquerygenerationinparticular,we
use LLAMA-2-7B [45]asthebasemodelforfinetuningM q. Again,weextractallsearchquery
instancesinthetool-integratedtrajectoriesresultinginthecorrectanswers. WefullyfinetuneM on
q
atotalof22Ksearchqueryinstances.
RefertoAppendixHforexamplesofthetrainingdataforeachmodule.
4.3 Baselines
Numerical,tabularandknowledge-basedreasoningtasks. WeevaluateHUSKYalongwithother
existing open-source language agents including REACT [54], REWOO [52], CHAMELEON [20],
FIREACT [4]and LUMOS [55]on11differenttasksfornumerical, tabularandknowledge-based
reasoning.Ourbaselinesconsistoftwocategories.1)few-shotpromptedagents(REACT,REWOO,
CHAMELEON): We construct few-shot prompts specific to each task category and generate the
correspondingoutputsusingTULU-2-7Bduringinference. Wegeneratethoughtsandactionsstep-
by-stepforREACTandplansinasinglepassforREWOOandCHAMELEON. 2)finetunedagents
(FIREACT,LUMOS): weexecutethemodelcheckpointsaccordingtotheiroriginalprompts. Tokeep
comparisonsfair,wemapeachtoolcallmadebytheagentstoacorrespondingHUSKYmoduleand
executethemodule. Forexample,wemapaCALCULATORcallmadebytheagenttoM ctoperform
computation. Byfixatingthetoolset,wecontrolfortheconfoundingerrorassociatedwiththetools
employedbyeachagentanddirectlycomparetheagents’planningandtoolusecapabilities.
Mixed-toolreasoningtasks. Whilelanguageagentseffectivelyaddressvariousmulti-stepreasoning
tasks,manysuchtaskscanbesolvedbystate-of-the-artproprietarymodelswithChain-of-Thought
(CoT)[49]withbetterperformance.Thisisduetoacombinationoftheirsuperiorityincorereasoning
capabilities,long-contexthandling,andtrainingdatacoveragewithpossibilitiesofcontamination.
Assuch,wemeasuretheperformanceofgpt-3.5-turboandgpt-4-turbo2 alongwith REACT,
LUMOS and HUSKY on our set of mixed-tool reasoning tasks consisting of DROP*, IIRC* and
HUSKYQA. Weusethesameinferenceprocedureforthelanguageagentsastheotherevaluation
tasks,andwemeasuretheperformanceofproprietarymodelsusingChain-of-Thought.
5 Results
WeevaluateHUSKYandotherbaselineagentsystemsacross14differentevaluationtasksandpresent
theresultsinTable2. Overall,wefindthatHUSKYconsistentlyoutperformsallotherbaselineagents
whileusingajointlytrainedactiongeneratorandthesamesetoftoolsforalloftheevaluationtasks.
2Weusegpt-3.5-turbo-0125,gpt-4-0125-preview,gpt-4-turbo-0409andgpt-4o.
8Wedivideouranalysesaccordingtothemaintypeofreasoningemployedbyeachtask,spanning
numerical,tabular,knowledge-basedandmixedreasoning.
Agent Numericalreasoning Tabularreasoning
GSM8K MATH GDMMath. MathQA TabMWP FinQA TAT-QA MMQA
acc acc acc acc EM EM EM EM/F1
CoT 28.8 3.1 10.8 5.2 48.6 8.7 19.9 39.8/43.1
Tulu2-7B
REACTTulu2-7B 55.4 21.0 27.8 31.9 72 7.6 15.0 34.0/39.3
REWOO
Tulu2-7B
52.2 28.7 53.7 25.4 67.0 14.7 38.2 32.6/37.5
CHAMELEONTulu2-7B 64.4 30.3 41.9 39.3 71.0 14.7 36.5 39.2/44.6
FIREACTLlama2-7B 56.1 19.7 29.6 22.6 29.2 8.2 12.7 44.2/49.6
LUMOSLlama2-7B 54.9 30.3 42.4 30.7 70.9 18.7 41.0 37.9/41.3
HUSKYLlama2-7B 77.9 40.9 58.2 49.1 77.6 20.8 42.2 46.7/52.5
HUSKYLlama2-13B 79.4 41.9 57.9 51.2 75.6 20.0 42.3 41.2/48.2
HUSKYLlama3-8B 79.9 42.1 55.8 51.0 76.6 20.9 41.8 43.7/50.5
(a)Numericalandtabularreasoningtaskresults
Agent Knowledge-basedreasoning Agent/Model Mixed-toolreasoning
BamboogleHotpotQAStrat.QA DROP* IIRC* HUSKYQA
EM/F1 EM/F1 acc EM/F1 EM/F1 acc
CoT
Tulu2-7B
28.0/37.7 20.5/29.0 68.0 REACTTulu2-7B 15.0/19.825.5/31.1 7.19
REACTTulu2-7B 37.6/48.7 24.4/34.0 62.0 LUMOSLlama2-7B 21.0/23.330.5/35.1 9.59
REWOO
Tulu2-7B
33.6/42.4 22.1/29.4 58.0 gpt-3.5-turbo-012520.0/24.624.5/30.6 15.1
CHAMELEONTulu2-7B 39.2/50.8 24.8/34.7 60.7 gpt-4-0125-preview22.0/25.528.0/33.7 20.2
FIREACTLlama2-7B 36.8/45.6 27.7/37.8 63.0 gpt-4-turbo-0409 25.0/29.527.5/32.9 25.3
LUMOSLlama2-7B 52.0/64.5 26.8/36.3 66.3 gpt-4o 28.0/32.131.0/37.3 26.0
HUSKYLlama2-7B 54.4/65.8 32.7/46.6 70.0 HUSKYLlama2-7B 26.0/30.933.0/37.9 20.9
HUSKYLlama2-13B 56.0/66.8 35.1/48.8 71.3 HUSKYLlama2-13B 27.5/32.132.5/37.2 25.0
HUSKYLlama3-8B 58.4/70.2 33.7/49.0 67.3 HUSKYLlama3-8B 26.0/31.233.5/39.1 20.9
(b)Knowledge-basedreasoningtaskresults (c)Mixed-toolreasoningtaskresults
Table2: Overallresultsacross14differentevaluationtasks. HUSKYoutperformsorisonparwith
existinglanguageagentswhileusinganactiongeneratorjointlytrainedacrossdifferenttasksonthe
numerical,tabularandknowledge-basedreasoningtasks,andmatchesoroutperformsstate-of-the-art
proprietarymodelsonthemixedreasoningtasks. Taskswhosetrainingsetsareusedfortraining
HUSKYareindicatedin red,andunseentasksintroducedduringevaluationareindicatedin blue.
5.1 ResultsforNumerical,TabularandKnowledge-basedReasoning
Numerical reasoning tasks. The first four columns of Table 2a demonstrate the results for the
numericalreasoningtasks,whichincludeGSM-8K,MATH,Google-DeepMindMathematicsand
MathQA.WhilethetrainingsetsofGSM-8KandMATHareincorporatedtocreatethetool-integrated
trajectories,theGoogle-DeepMindMathematicsandMathQAdatasetsareunseentasksintroduced
duringevaluation. HUSKYdemonstratessignificantperformanceimprovementsoverotherlanguage
agentsby10to20pointsacrossallfourtasks,indicatingitsabilitytocallandexecutethecorrect
toolsrequiredtosolveeachstepofagivenmathquestion. Notably,itshowsconsistencyinitshigh
performanceevenforunseenmathtasks. Ofthebaselinelanguageagents,CHAMELEONdeliversthe
highestandmostconsistentperformance,corroboratingapriorstudyindicatingthatagentstendto
performbetterinmathtaskswithsingle-passplanningratherthaniterativeplanning[55].
HUSKY’ssuperiorperformanceonnumericaltaskscanbeattributedtoitseffectiveusageofM
m
basedonDeepSeekMath-7B-Instruct[39]. AsnumericalreasoningtaskscanbesolvedwithCoTand
bypassstepwiseexecution,wecomparetheperformanceofusingastate-of-the-artCoTpromptand
ouriterativeexecutionswithM asshowninTable3. ForGSM-8KandMATH,weobservethat
m
CoTslightlyedgesoverHUSKY. WehypothesizethatDeepSeekMath-7B-Instructisspecializedin
thetwotasksbyextensivelyincorporatingtheirtrainingdataduringinstructiontuninginCoTformat.
9Agent GSM8K MATH GDMMathematics MathQA
alg basic calc muldiv numth gain gen geom phys prob
CoT 83.2 42.1 39.61 44.33 28.25 64.13 44.39 55.5 53.28 57.26 51.23 45.18
DeepSeekMath-7B-Inst
HUSKYLlama2-7B 77.86 40.94 43.66 62.0 44.61 86.77 53.87 56.78 51.74 46.15 45.9 44.85
HUSKYLlama2-13B 79.38 41.92 46.22 68.33 44.24 78.03 52.42 57.29 55.56 52.51 51.02 39.53
HUSKYLlama3-8B 79.91 42.12 43.66 58.0 46.47 83.86 47.2 58.57 53.8 49.57 47.34 45.85
Table3: EffectsofstepwiseexecutiononnumericalreasoningtaskscomparedtoChain-of-Thought
(CoT).WhileusingtheoptimizedCoTpromptwithDeepSeekMath-7B-Instructevenoutperforms
agentexecutionsonGSM-8KandMATH,theagentexecutionsoutperformCoTinmanycaseswhere
theevaluationtaskhasnotbeenobservedinthemodel’sinstructiontuningstage.
Ontheotherhand,eightoutoftensubtasksinGoogle-DeepMindmathematicsandMathQAbenefit
fromstepwiseexecution–theseresultsindicatethatnumericalreasoningtasksunseenduringtraining
canoftenbemoreaccuratelysolvedbyiterativelyaddressingsimplersubproblems.
Tabularreasoningtasks. ThelatterfourcolumnsofTable2adisplaytheresultsforthetabular
reasoningtasks. NotethatTabMWPandFinQAareintegratedfortrainingHUSKY,whileTAT-QA
andMultimodalQAarenewlyintroducedduringevaluation. Again,HUSKYconsistentlyoutperforms
allotherbaselineagentsacrossallfourtasksduetoitsexposuretotabulardataduringtraining. Some
baselineagentsdemonstratecompetitiveperformanceonsomebenchmarks,suchasFIREACTfor
MMQAorLUMOSforFinQAandTAT-QA,thoughtheperformanceneverthelessslightlylagsbehind
thatofHUSKY.
Knowledge-basedreasoningtasks. Table2bsummarizestheevaluationresultsofthelanguage
agentsonthreedifferentknowledgereasoningtasks. TheobservedtaskforHUSKYincludesStrate-
gyQA,whiletheunseentasksincludeBamboogleandHotpotQA.HUSKYoutperformsotherlanguage
agentsacrossallevaluationtasks,evenoutperformingtask-specificagentswithoutincorporatingthe
taskinitsowntrainingdata. Forexample,HUSKYoutperformsFIREACTonHotpotQAbyfiveEM
pointsdespitehavingneverseenHotpotQAwhileFIREACThasbeentrainedonthedataset. HUSKY
achievescompetitivescoresacrossallknowledge-basedtaskswithoutusinghighlytask-specifictools
suchasaWikipediapassageretriever,capturingbothprecisionandefficiencyduringitsinference.
RefertoAppendixIforexamplesofsolutionsgeneratedbyHUSKY.
5.2 ResultsforMixed-ToolReasoning
Table2cdemonstratesevaluationresultsonthemixedreasoningtasks,whichconsistofDROP*,
IIRC*andHUSKYQA.Despiteonlyusingopen-source7BLMsforitsmodules,HUSKYoutperforms
allotherlanguageagentsandproprietarymodelsexceptforgpt-4oonDROP*,andoutperforms
allbaselinesforIIRC*. SimilarlyforHUSKYQA,HUSKYoutperformsotherlanguageagentsbya
significantmargin. Italsooutperformsgpt-3.5-turboandonparwithgpt-4-0125-previewwith
a7Bactiongeneratorandonparwithgpt-4-turbo-0409witha13Bactiongenerator.
TheseresultsshowcaseHUSKY’sabilitytoiterativelysolvecomplexquestionsviaprecisedecompo-
sitionofthetaskintosimplersubtaskswithappropriatetoolchoices. WhileHUSKYhasintegrated
asubsetofHUSKYQAintoitstraining,thissplitisdonebydifferentreal-worldtopics,indicating
thatHUSKYlearnstogeneralizethemulti-toolreasoningstrategyacrossvariousdomainssuchas
geography,sports,chemistryandmore. Ourexperimentresultsshowthatitispossibletodevelop
open-sourceagentsthatcompetewiththebestproprietarymodelsforsolvingcomplexquestions
throughacarefulfine-tuningprocedurethatendowsadvancedplanningandmulti-tooluseabilities.
RefertoAppendixIforexamplesofsolutionsgeneratedbyHUSKY.
6 Analysis
HavingshowcasedHUSKY’smulti-stepreasoningcapabilitiesacross14differenttasks,wefurther
examinedesignchoicesthataffectHUSKY’sperformance. Ouranalysisissummarizedasfollows.
(1) Cross-domain generalization: we investigate whether the action generator responsible for
decomposingtheproblemintosimplerstepsbenefitsfromdomain-specificorcross-domaintraining.
10Actiongenerator Numerical(Acc) Tabular(EM) Knowledge(EM)
GDMMath. MathQA TAT-QA MMQA Bamboogle HotpotQA
Domain-Specific 58.07 48.82 44.85 40.06 55.2 34.1
Joint(110K) 58.18 49.08 42.2 46.69 54.4 32.7
Table4: Comparisonbetween HUSKY w/actiongeneratortrainedondomain-specifictasks, and
HUSKYw/actiongeneratorjointlytrainedonalltasksintheoriginaltrainingset.
(2) Tool choice: we study the effect of tool capabilities on HUSKY’s downstream performance.
(3) HUSKY Llama3-8B-all: we share a variant of HUSKY that is built upon the same base model
(Llama-3-8B)fortheactiongeneratorandthespecializedmodulesM ,M andM .
c m q
6.1 Cross-taskGeneralization
OnenotablefeatureofHUSKYisitsuseofanactiongeneratorthatisjointlytrainedacrossdifferent
tasksinvolvingnumerical,tabularandknowledge-basedreasoningtopredictthenextsteptotake.
Inconstrast,manyexistinglanguageagentsareeitherfinetunedontaskswithinaspecificdomain
(e.g.,FIREACT),orprovidedifferentmoduleseachtrainedonaspecificdomain(e.g.,LUMOS). We
explorethisdesignchoiceinamoresystematicwaybytrainingvariantsofHUSKY’sactiongenerator
separatelyonnumerical,tabularandknowledgereasoningtasksandcomparingtheirperformanceon
in-domaintaskstothejointlytrainedactiongenerator.
Table4showstheresultsofouranalyses. Fornumericalreasoningtasks,weobservethatthecross-
domainactiongeneratorscoreequallytothedomain-specificactiongenerator. Ontheotherhand,our
resultsonBamboogleandHotpotQAindicatethatknowledge-basedreasoningtasksslightlybenefit
fromdomain-specifictraining. Theresultsfortabulartasksaremixed,withMultimodalQAgreatly
benefittingfromjointtrainingofAwhileTAT-QAslightlydecreasesinperformance.
Theseresultshintthatthebenefitofdomain-specificorcross-domaintrainingfortheactiongenerator
dependsonthedomainofthedownstreamtaskbeingevaluatedupon. However,thedifferencein
the metrics is small enough to conclude that joint training across different task domains mostly
preservetheactiongenerator’sperformanceineachdomain, indicatingapositivesignaltowards
scalingHUSKYwithanevenlargerandmorediversearrayoftasks.
Table5: Ablationsforthecodegenerator(M )andthemathreasoner(M ). Foreachtool,weuse
c m
asetoffivetasksthatdisplayhighfrequenciesofinvokingthetool,changethetoolswithdifferent
modelsandrunHUSKY. Weuseasubsetof1KexamplesforMATHtoreducetheinferencetime.
(a)Resultsforcodegenerator(M )
c
Tool MATH(1K) GDMMath. TabMWP FinQA TAT-QA
CodeTulu-7B 25.6 54.54 42.6 6.88 40.53
Llama-3-8B 39.4 57.05 74.5 20.74 41.23
DeepSeekCoder-7B-Instruct-v1.5 41.8 58.18 77.6 20.83 42.2
(b)Resultsformathreasoner(M )
m
Tool GSM8K MATH(1K) GDMMath. MathQA HuskyQA
Tulu-2-7B 49.28 23.5 49.05 17.63 14.04
Llama-3-8B 67.7 33.3 52.59 31.3 18.15
DeepSeekMath-7B-Instruct 77.86 41.8 58.18 49.08 20.89
6.2 ToolChoice
AnotherkeycomponentofHUSKYisthetoolsormodulesusedforexecutingeachsteppredicted
bytheactiongenerator. Weconductourablationsbyswitchingoutthemodelsusedforthecode
generatorM candthemathreasonerM mwhilekeepingeverythingelseinHUSKYfixed. Weablate
11Table6: Resultsfor HUSKY Llama3-8B-all, whichsharesLlama-3-8BasthebasemodelforA, M c,
M andM . Theperformanceremainscompetitivedespiteswitchingoutthecodeandmathexpert
m q
LMsintoageneral-purposebaseLMforfine-tuningthetoolmodules.
Numericalreasoning Tabularreasoning
Agent GSM8K MATH GDMMath. MathQA TabMWP FinQA TAT-QA MMQA
acc acc acc acc EM EM EM EM/F1
HUSKYLlama3-8B 79.91 42.12 55.84 51.03 76.6 20.92 41.78 43.65/50.45
HUSKYLlama3-8B-all 70.58 30.0 46.03 31.27 74.1 23.21 42.9 42.82/49.91
Knowledgereasoning Mixed-toolreasoning
Agent Bamboogle HotpotQA StrategyQA DROP* IIRC* HUSKYQA
EM/F1 EM/F1 acc EM/F1 EM/F1 acc
HUSKYLlama3-8B 58.4/70.2 33.7/48.98 67.33 26.0/31.24 33.5/39.12 20.89
HUSKYLlama3-8B-all 56.0/68.94 33.5/48.14 68.67 25.0/29.47 34.5/40.25 17.12
M withCodeTulu-7BandLlama-3-8BinadditiontoDeepSeekCoder-7B-Instruct-v1.5,andwe
c
ablateM withTulu-2-7BandLlama-3-8BinadditiontoDeepSeekMath-7B-Instruct.
m
Table5showstheresultsofourablations. Forcodegenerators,weconfirmthatDeepSeekCoder-
7B-Instruct-v1.5providesthebestinitializationforM withitsstate-of-the-artcodingcapabilities.
c
Llama-3-8Balsodemonstratesstrongcodingcapabilitiesthatbringstheagent’sperformancevery
closetothebestsystem’sperformanceacrossallablationtasks. Formathreasoners,wealsofindthat
DeepSeekMath-7B-Instructresultsinthebestperformancefortheagent. Weobserveasignificant
performancegapwithTulu-2-7Bduetoitsrelativelackofmathreasoningcapabilities. Llama-3-
8B closes this gap about halfway through according to our evaluation results, but it still lacks in
comparisontoDeepSeekMathwhichispre-trainedandfine-tunedspecificallyformathtasks.
6.3 HUSKYLlama3-8B-all
WhileHUSKYbenefitsfromcarefuldecisionsaboutwhichmodelstousefortools,insomecasesit
isdifficulttoknowinadvancewhichmodelservesasthebestcandidateforanewtoolfunctionality
requestedbyauser. ThereforewebuildavariantofHUSKYwheretheactiongeneratorandthetools
M ,M andM arealltrainedfromLlama-3-8B,astate-of-the-artLMinthe7-8Bsizefamily.
c m q
OurresultsaresummarizedinTable6. HUSKYLlama3-8B-alldemonstratessimilarperformancetothat
ofHUSKYLlama3-8Bonmostdownstreamtasks,exceptfornumericalreasoningtasksduetoitslack
ofamath-specializedmodelsuchasDeepSeekMath-InstructforM .
m
Theseresultsdemonstratethatfine-tuningallHUSKYmodulesusingafixedbaseLMwithstrong
reasoningcapabilitiesyieldsrobustperformancesacrossawidearrayoftasks,bypassingtheneed
toidentifyanddownloadspecializedmodelstofine-tuneeachmodulefrom. WeexpectHUSKY’s
performancestofurtherimprovewithscalingintermsoftheparametercount,aswellasintegrating
newopenLMswithstrongerreasoningcapabilitiesastheycontinuetobereleased.
7 Conclusion
WeintroduceHUSKY,aunified,open-sourcelanguageagentthatjointlysolvesmulti-stepreasoning
taskswhichrequirenumerical,tabular,knowledge-based,andmixed-toolreasoning. First,wetrain
anactiongeneratorthatiterativelypredictsthehigh-levelstepsandtheassociatedtoolsforsolving
tasksacrossdifferentdomains. WealsofinetunestrongbaseLMswithhighqualitytrainingdatato
integratehighlyperformantexpertmodelsintoHUSKY. Moreover,wedevelopHUSKYQAandother
evaluationsetsthatstress-testlanguageagents’abilitiestoaddressmixed-tool,multi-stepreasoning
tasks,andshowexistinggapsinfrontiermodelssuchasGPT-4forsuchtasks. Weperformadditional
experimentstoprovidescientificinsightsontheeffectsofmodelchoiceanddatasetcompositionon
HUSKY’sperformance. Here,wediscoverthatfurtherscalingtheactionspaceandexpertmodelswill
allowHUSKYtoaddressanevenwiderrangeoftasks. Ourworkpresentsarobustrecipeforbuilding
open-sourcelanguageagentsthatgeneralizeacrossdifferenttypesofmulti-stepreasoningtasks.
12References
[1] RenatAksitov,SobhanMiryoosefi,ZonglinLi,DaliangLi,SheilaBabayan,KavyaKopparapu,
ZacharyFisher,RuiqiGuo,SushantPrakash,PraneshSrinivasan,ManzilZaheer,FelixX.Yu,
andSanjivKumar. Restmeetsreact: Self-improvementformulti-stepreasoningLLMagent.
CoRR,abs/2312.10003,2023. doi: 10.48550/ARXIV.2312.10003. URLhttps://doi.org/
10.48550/arXiv.2312.10003.
[2] AidaAmini,SaadiaGabriel,ShanchuanLin,RikKoncel-Kedziorski,YejinChoi,andHannaneh
Hajishirzi. Mathqa: Towardsinterpretablemathwordproblemsolvingwithoperation-based
formalisms. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of
the 2019 Conference of the North American Chapter of the Association for Computational
Linguistics: HumanLanguageTechnologies,NAACL-HLT2019,Minneapolis,MN,USA,June
2-7,2019,Volume1(LongandShortPapers),pages2357–2367.AssociationforComputational
Linguistics, 2019. doi: 10.18653/V1/N19-1245. URL https://doi.org/10.18653/v1/
n19-1245.
[3] AkariAsai,ZeqiuWu,YizhongWang,AvirupSil,andHannanehHajishirzi. Self-rag: Learning
toretrieve,generate,andcritiquethroughself-reflection. CoRR,abs/2310.11511,2023. doi:
10.48550/ARXIV.2310.11511. URLhttps://doi.org/10.48550/arXiv.2310.11511.
[4] BaianChen,ChangShu,EhsanShareghi,NigelCollier,KarthikNarasimhan,andShunyuYao.
Fireact: Toward language agent fine-tuning. CoRR, abs/2310.05915, 2023. doi: 10.48550/
ARXIV.2310.05915. URLhttps://doi.org/10.48550/arXiv.2310.05915.
[5] Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon,
ReemaMoussa,MattBeane,Ting-HaoHuang,BryanR.Routledge,andWilliamYangWang.
Finqa:Adatasetofnumericalreasoningoverfinancialdata.InMarie-FrancineMoens,Xuanjing
Huang,LuciaSpecia,andScottWen-tauYih,editors,Proceedingsofthe2021Conferenceon
EmpiricalMethodsinNaturalLanguageProcessing,EMNLP2021,VirtualEvent/PuntaCana,
DominicanRepublic,7-11November,2021,pages3697–3711.AssociationforComputational
Linguistics,2021. doi: 10.18653/V1/2021.EMNLP-MAIN.300. URLhttps://doi.org/10.
18653/v1/2021.emnlp-main.300.
[6] KarlCobbe,VineetKosaraju,MohammadBavarian,MarkChen,HeewooJun,LukaszKaiser,
MatthiasPlappert,JerryTworek,JacobHilton,ReiichiroNakano,ChristopherHesse,andJohn
Schulman. Trainingverifierstosolvemathwordproblems. CoRR,abs/2110.14168,2021. URL
https://arxiv.org/abs/2110.14168.
[7] Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt
Gardner. DROP: A reading comprehension benchmark requiring discrete reasoning over
paragraphs.InJillBurstein,ChristyDoran,andThamarSolorio,editors,Proceedingsofthe2019
ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:
HumanLanguageTechnologies,NAACL-HLT2019,Minneapolis,MN,USA,June2-7,2019,
Volume1(LongandShortPapers),pages2368–2378.AssociationforComputationalLinguistics,
2019. doi: 10.18653/V1/N19-1246. URLhttps://doi.org/10.18653/v1/n19-1246.
[8] JamesFerguson,MattGardner,HannanehHajishirzi,TusharKhot,andPradeepDasigi. IIRC:A
datasetofincompleteinformationreadingcomprehensionquestions. InBonnieWebber,Trevor
Cohn, Yulan He, and Yang Liu, editors, Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020,
pages1137–1147.AssociationforComputationalLinguistics,2020. doi: 10.18653/V1/2020.
EMNLP-MAIN.86. URLhttps://doi.org/10.18653/v1/2020.emnlp-main.86.
[9] RichardFikesandNilsJ.Nilsson. STRIPS:Anewapproachtotheapplicationoftheorem
provingtoproblemsolving. Artif.Intell.,2(3/4):189–208,1971. doi: 10.1016/0004-3702(71)
90010-5. URLhttps://doi.org/10.1016/0004-3702(71)90010-5.
[10] MorGeva,DanielKhashabi,EladSegal,TusharKhot,DanRoth,andJonathanBerant. Did
aristotle use a laptop? A question answering benchmark with implicit reasoning strategies.
Trans.Assoc.Comput.Linguistics,9:346–361,2021. doi: 10.1162/TACL\_A\_00370. URL
https://doi.org/10.1162/tacl_a_00370.
13[11] ZhibinGou,ZhihongShao,YeyunGong,YelongShen,YujiuYang,NanDuan,andWeizhu
Chen. CRITIC:largelanguagemodelscanself-correctwithtool-interactivecritiquing. CoRR,
abs/2305.11738, 2023. doi: 10.48550/ARXIV.2305.11738. URL https://doi.org/10.
48550/arXiv.2305.11738.
[12] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Minlie Huang, Nan
Duan,andWeizhuChen. Tora: Atool-integratedreasoningagentformathematicalproblem
solving. CoRR, abs/2309.17452, 2023. doi: 10.48550/ARXIV.2309.17452. URL https:
//doi.org/10.48550/arXiv.2309.17452.
[13] DayaGuo,QihaoZhu,DejianYang,ZhendaXie,KaiDong,WentaoZhang,GuantingChen,
Xiao Bi, Y. Wu, Y. K. Li, Fuli Luo, Yingfei Xiong, and Wenfeng Liang. Deepseek-coder:
When the large language model meets programming - the rise of code intelligence. CoRR,
abs/2401.14196, 2024. doi: 10.48550/ARXIV.2401.14196. URL https://doi.org/10.
48550/arXiv.2401.14196.
[14] Shibo Hao, Tianyang Liu, Zhen Wang, and Zhiting Hu. Toolkengpt: Augmenting frozen
language models with massive tools via tool embeddings. In Alice Oh, Tristan Nau-
mann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Ad-
vances in Neural Information Processing Systems 36: Annual Conference on Neural In-
formation Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December
10 - 16, 2023, 2023. URL http://papers.nips.cc/paper_files/paper/2023/hash/
8fd1a81c882cd45f64958da6284f4a3f-Abstract-Conference.html.
[15] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric
Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solv-
ing with the MATH dataset. In Joaquin Vanschoren and Sai-Kit Yeung, editors,
Proceedings of the Neural Information Processing Systems Track on Datasets and
Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual,
2021. URL https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/
hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html.
[16] WenlongHuang,PieterAbbeel,DeepakPathak,andIgorMordatch. Languagemodelsaszero-
shotplanners: Extractingactionableknowledgeforembodiedagents. InKamalikaChaudhuri,
StefanieJegelka,LeSong,CsabaSzepesvári,GangNiu,andSivanSabato,editors,International
ConferenceonMachineLearning,ICML2022,17-23July2022,Baltimore,Maryland,USA,
volume162ofProceedingsofMachineLearningResearch,pages9118–9147.PMLR,2022.
URLhttps://proceedings.mlr.press/v162/huang22a.html.
[17] HamishIvison,YizhongWang,ValentinaPyatkin,NathanLambert,MatthewE.Peters,Pradeep
Dasigi,JoelJang,DavidWadden,NoahA.Smith,IzBeltagy,andHannanehHajishirzi. Camels
inachangingclimate: EnhancingLMadaptationwithtulu2. CoRR,abs/2311.10702,2023.
doi: 10.48550/ARXIV.2311.10702. URLhttps://doi.org/10.48550/arXiv.2311.10702.
[18] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu,
JosephGonzalez,HaoZhang,andIonStoica. Efficientmemorymanagementforlargelanguage
modelservingwithpagedattention. InJasonFlinn,MargoI.Seltzer,PeterDruschel,Antoine
Kaufmann, and Jonathan Mace, editors, Proceedings of the 29th Symposium on Operating
SystemsPrinciples,SOSP2023,Koblenz,Germany,October23-26,2023,pages611–626.ACM,
2023. doi: 10.1145/3600006.3613165. URLhttps://doi.org/10.1145/3600006.3613165.
[19] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li,
Fei Huang, and Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented
llms. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Proceedings of the 2023
ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,EMNLP2023,Singapore,
December 6-10, 2023, pages 3102–3116. Association for Computational Linguistics, 2023.
URLhttps://aclanthology.org/2023.emnlp-main.187.
[20] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-
ChunZhu,andJianfengGao. Chameleon: Plug-and-playcompositionalreasoningwithlarge
languagemodels. InAliceOh,TristanNaumann,AmirGloberson,KateSaenko,MoritzHardt,
andSergeyLevine,editors,AdvancesinNeuralInformationProcessingSystems36: Annual
14ConferenceonNeuralInformationProcessingSystems2023,NeurIPS2023,NewOrleans,LA,
USA,December10-16,2023,2023. URLhttp://papers.nips.cc/paper_files/paper/
2023/hash/871ed095b734818cfba48db6aeb25a62-Abstract-Conference.html.
[21] Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit,
Peter Clark, and Ashwin Kalyan. Dynamic prompt learning via policy gradient for semi-
structured mathematical reasoning. In The Eleventh International Conference on Learning
Representations,ICLR2023,Kigali,Rwanda,May1-5,2023.OpenReview.net,2023. URL
https://openreview.net/pdf?id=DHyHRBwJUTN.
[22] YuboMa,ZhibinGou,JunhengHao,RuochenXu,ShuohangWang,LiangmingPan,Yujiu
Yang, Yixin Cao, Aixin Sun, Hany Hassan Awadalla, and Weizhu Chen. Sciagent: Tool-
augmented language models for scientific reasoning. CoRR, abs/2402.11451, 2024. doi:
10.48550/ARXIV.2402.11451. URLhttps://doi.org/10.48550/arXiv.2402.11451.
[23] Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegr-
effe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bod-
hisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and
Peter Clark. Self-refine: Iterative refinement with self-feedback. In Alice Oh, Tristan
Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Ad-
vances in Neural Information Processing Systems 36: Annual Conference on Neural In-
formation Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December
10 - 16, 2023, 2023. URL http://papers.nips.cc/paper_files/paper/2023/hash/
91edff07232fb1b55a505a9e9f6c0ff3-Abstract-Conference.html.
[24] AlexMallen,AkariAsai,VictorZhong,RajarshiDas,DanielKhashabi,andHannanehHa-
jishirzi. When not to trust language models: Investigating effectiveness of parametric and
non-parametricmemories. InAnnaRogers,JordanL.Boyd-Graber,andNaoakiOkazaki,edi-
tors,Proceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics
(Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 9802–9822.
AssociationforComputationalLinguistics,2023. doi: 10.18653/V1/2023.ACL-LONG.546.
URLhttps://doi.org/10.18653/v1/2023.acl-long.546.
[25] GrégoireMialon,ClémentineFourrier,CraigSwift,ThomasWolf,YannLeCun,andThomas
Scialom. GAIA:abenchmarkforgeneralAIassistants. CoRR,abs/2311.12983,2023. doi:
10.48550/ARXIV.2311.12983. URLhttps://doi.org/10.48550/arXiv.2311.12983.
[26] SewonMin,KalpeshKrishna,XinxiLyu,MikeLewis,Wen-tauYih,PangWeiKoh,Mohit
Iyyer,LukeZettlemoyer,andHannanehHajishirzi. Factscore: Fine-grainedatomicevaluation
offactualprecisioninlongformtextgeneration. InHoudaBouamor,JuanPino,andKalika
Bali,editors,Proceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguage
Processing,EMNLP2023,Singapore,December6-10,2023,pages12076–12100.Association
for Computational Linguistics, 2023. doi: 10.18653/V1/2023.EMNLP-MAIN.741. URL
https://doi.org/10.18653/v1/2023.emnlp-main.741.
[27] Swaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang, Sean Welleck, Chitta Baral,
TanmayRajpurohit,OyvindTafjord,AshishSabharwal,PeterClark,andAshwinKalyan. LILA:
Aunifiedbenchmarkformathematicalreasoning. InYoavGoldberg,ZornitsaKozareva,and
Yue Zhang, editors, Proceedings of the 2022 Conference on Empirical Methods in Natural
LanguageProcessing,EMNLP2022,AbuDhabi,UnitedArabEmirates,December7-11,2022,
pages5807–5832.AssociationforComputationalLinguistics,2022. doi: 10.18653/V1/2022.
EMNLP-MAIN.392. URLhttps://doi.org/10.18653/v1/2022.emnlp-main.392.
[28] OpenAI. GPT-4technicalreport. CoRR,abs/2303.08774,2023. doi: 10.48550/ARXIV.2303.
08774. URLhttps://doi.org/10.48550/arXiv.2303.08774.
[29] BhargaviParanjape,ScottM.Lundberg,SameerSingh,HannanehHajishirzi,LukeZettlemoyer,
andMarcoTúlioRibeiro. ART:automaticmulti-stepreasoningandtool-useforlargelanguage
models. CoRR, abs/2303.09014, 2023. doi: 10.48550/ARXIV.2303.09014. URL https:
//doi.org/10.48550/arXiv.2303.09014.
15[30] Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve
simple math word problems? In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer,
Dilek Hakkani-Tür, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and
YichaoZhou,editors,Proceedingsofthe2021ConferenceoftheNorthAmericanChapterof
theAssociationforComputationalLinguistics: HumanLanguageTechnologies,NAACL-HLT
2021,Online,June6-11,2021,pages2080–2094.AssociationforComputationalLinguistics,
2021. doi: 10.18653/V1/2021.NAACL-MAIN.168. URLhttps://doi.org/10.18653/v1/
2021.naacl-main.168.
[31] ShishirG.Patil,TianjunZhang,XinWang,andJosephE.Gonzalez. Gorilla: Largelanguage
modelconnectedwithmassiveapis. CoRR,abs/2305.15334,2023. doi: 10.48550/ARXIV.2305.
15334. URLhttps://doi.org/10.48550/arXiv.2305.15334.
[32] Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, and Mike Lewis.
Measuringandnarrowingthecompositionalitygapinlanguagemodels. InHoudaBouamor,
JuanPino,andKalikaBali,editors,FindingsoftheAssociationforComputationalLinguis-
tics: EMNLP 2023, Singapore, December 6-10, 2023, pages 5687–5711. Association for
Computational Linguistics, 2023. doi: 10.18653/V1/2023.FINDINGS-EMNLP.378. URL
https://doi.org/10.18653/v1/2023.findings-emnlp.378.
[33] ShuofeiQiao,NingyuZhang,RunnanFang,YujieLuo,WangchunshuZhou,YuchenEleanor
Jiang, Chengfei Lv, and Huajun Chen. AUTOACT: automatic agent learning from scratch
viaself-planning. CoRR,abs/2401.05268, 2024. doi: 10.48550/ARXIV.2401.05268. URL
https://doi.org/10.48550/arXiv.2401.05268.
[34] YujiaQin,ShihaoLiang,YiningYe,KunlunZhu,LanYan,YaxiLu,YankaiLin,XinCong,
XiangruTang,BillQian,SihanZhao,RunchuTian,RuobingXie,JieZhou,MarkGerstein,
DahaiLi,ZhiyuanLiu,andMaosongSun.Toolllm:Facilitatinglargelanguagemodelstomaster
16000+ real-world apis. CoRR, abs/2307.16789, 2023. doi: 10.48550/ARXIV.2307.16789.
URLhttps://doi.org/10.48550/arXiv.2307.16789.
[35] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. Zero: memory opti-
mizationstowardtrainingtrillionparametermodels. InChristineCuicchi,IreneQualters,and
WilliamT.Kramer,editors,ProceedingsoftheInternationalConferenceforHighPerformance
Computing,Networking,StorageandAnalysis,SC2020,VirtualEvent/Atlanta,Georgia,USA,
November9-19,2020,page20.IEEE/ACM,2020. doi: 10.1109/SC41405.2020.00024. URL
https://doi.org/10.1109/SC41405.2020.00024.
[36] VictorSanh,AlbertWebson,ColinRaffel,StephenH.Bach,LintangSutawika,ZaidAlyafeai,
AntoineChaffin,ArnaudStiegler,ArunRaja,MananDey,MSaifulBari,CanwenXu,Urmish
Thakker,ShanyaSharmaSharma,ElizaSzczechla,TaewoonKim,GunjanChhablani,NihalV.
Nayak,DebajyotiDatta,JonathanChang,MikeTian-JianJiang,HanWang,MatteoManica,
ShengShen,ZhengXinYong,HarshitPandey,RachelBawden,ThomasWang,TrishalaNeeraj,
JosRozen,AbheeshtSharma,AndreaSantilli,ThibaultFévry,JasonAlanFries,RyanTeehan,
TevenLeScao,StellaBiderman,LeoGao,ThomasWolf,andAlexanderM.Rush. Multitask
promptedtrainingenableszero-shottaskgeneralization. InTheTenthInternationalConference
onLearningRepresentations,ICLR2022,VirtualEvent,April25-29,2022.OpenReview.net,
2022. URLhttps://openreview.net/forum?id=9Vrb9D0WI4.
[37] DavidSaxton,EdwardGrefenstette,FelixHill,andPushmeetKohli. Analysingmathematical
reasoningabilitiesofneuralmodels. In7thInternationalConferenceonLearningRepresen-
tations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019. URL
https://openreview.net/forum?id=H1gR5iR5FX.
[38] TimoSchick,JaneDwivedi-Yu,RobertoDessì,RobertaRaileanu,MariaLomeli,EricHambro,
LukeZettlemoyer,NicolaCancedda,andThomasScialom. Toolformer: Languagemodelscan
teachthemselvestousetools. InAliceOh,TristanNaumann,AmirGloberson,KateSaenko,
MoritzHardt,andSergeyLevine,editors,AdvancesinNeuralInformationProcessingSystems
36:AnnualConferenceonNeuralInformationProcessingSystems2023,NeurIPS2023,NewOr-
leans,LA,USA,December10-16,2023,2023.URLhttp://papers.nips.cc/paper_files/
paper/2023/hash/d842425e4bf79ba039352da0f658a906-Abstract-Conference.html.
16[39] ZhihongShao,PeiyiWang,QihaoZhu,RunxinXu,JunxiaoSong,MingchuanZhang,Y.K.
Li,Y.Wu,andDayaGuo. Deepseekmath: Pushingthelimitsofmathematicalreasoningin
openlanguagemodels. CoRR,abs/2402.03300,2024. doi: 10.48550/ARXIV.2402.03300. URL
https://doi.org/10.48550/arXiv.2402.03300.
[40] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang.
Hugginggpt: Solving AI tasks with chatgpt and its friends in hugging face. In Alice Oh,
Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, edi-
tors, Advances in Neural Information Processing Systems 36: Annual Conference on Neu-
ral Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, Decem-
ber10-16,2023,2023. URLhttp://papers.nips.cc/paper_files/paper/2023/hash/
77c33e6a367922d003ff102ffb92b658-Abstract-Conference.html.
[41] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.
Reflexion: language agents with verbal reinforcement learning. In Alice Oh, Tristan
Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Ad-
vances in Neural Information Processing Systems 36: Annual Conference on Neural In-
formation Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December
10 - 16, 2023, 2023. URL http://papers.nips.cc/paper_files/paper/2023/hash/
1b44b878bb782e6954cd888628510e90-Abstract-Conference.html.
[42] Kumar Shridhar, Koustuv Sinha, Andrew Cohen, Tianlu Wang, Ping Yu, Ram Pasunuru,
MrinmayaSachan,JasonWeston,andAsliCelikyilmaz. TheARTofLLMrefinement: Ask,
refine, and trust. CoRR, abs/2311.07961, 2023. doi: 10.48550/ARXIV.2311.07961. URL
https://doi.org/10.48550/arXiv.2311.07961.
[43] Alon Talmor and Jonathan Berant. The web as a knowledge-base for answering complex
questions. InMarilynA.Walker,HengJi,andAmandaStent,editors,Proceedingsofthe2018
ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:
HumanLanguageTechnologies,NAACL-HLT2018,NewOrleans,Louisiana,USA,June1-6,
2018, Volume 1 (Long Papers), pages 641–651. Association for Computational Linguistics,
2018. doi: 10.18653/V1/N18-1059. URLhttps://doi.org/10.18653/v1/n18-1059.
[44] Alon Talmor, Ori Yoran, Amnon Catav, Dan Lahav, Yizhong Wang, Akari Asai, Gabriel
Ilharco,HannanehHajishirzi,andJonathanBerant. Multimodalqa:complexquestionanswering
overtext, tablesandimages. In9thInternationalConferenceonLearningRepresentations,
ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL https:
//openreview.net/forum?id=ee6W5UgQLa.
[45] HugoTouvron,LouisMartin,KevinStone,PeterAlbert,AmjadAlmahairi,YasmineBabaei,
Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas
Blecher,CristianCanton-Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu,JudeFernandes,
JeremyFu,WenyinFu,BrianFuller,CynthiaGao,VedanujGoswami,NamanGoyal,Anthony
Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian
Khabsa,IsabelKloumann,ArtemKorenev,PunitSinghKoura,Marie-AnneLachaux,Thibaut
Lavril,JenyaLee,DianaLiskovich,YinghaiLu,YuningMao,XavierMartinet,TodorMihaylov,
PushkarMishra,IgorMolybog,YixinNie,AndrewPoulton,JeremyReizenstein,RashiRungta,
KalyanSaladi,AlanSchelten,RuanSilva,EricMichaelSmith,RanjanSubramanian,Xiao-
qingEllenTan,BinhTang,RossTaylor,AdinaWilliams,JianXiangKuan,PuxinXu,Zheng
Yan,IliyanZarov,YuchenZhang,AngelaFan,MelanieKambadur,SharanNarang,Aurélien
Rodriguez,RobertStojnic,SergeyEdunov,andThomasScialom. Llama2: Openfoundation
andfine-tunedchatmodels. CoRR,abs/2307.09288,2023. doi: 10.48550/ARXIV.2307.09288.
URLhttps://doi.org/10.48550/arXiv.2307.09288.
[46] Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. MuSiQue:
Multihopquestionsviasingle-hopquestioncomposition. Trans.Assoc.Comput.Linguistics,
10:539–554,2022. doi: 10.1162/TACL\_A\_00475. URLhttps://doi.org/10.1162/tacl_
a_00475.
[47] KeWang,HouxingRen,AojunZhou,ZimuLu,SichunLuo,WeikangShi,RenruiZhang,Linqi
Song, MingjieZhan,andHongshengLi. Mathcoder: Seamlesscodeintegrationinllmsfor
17enhancedmathematicalreasoning. CoRR,abs/2310.03731,2023. doi: 10.48550/ARXIV.2310.
03731. URLhttps://doi.org/10.48550/arXiv.2310.03731.
[48] YizhongWang,YeganehKordi,SwaroopMishra,AlisaLiu,NoahA.Smith,DanielKhashabi,
and Hannaneh Hajishirzi. Self-instruct: Aligning language models with self-generated in-
structions. InAnnaRogers,JordanL.Boyd-Graber,andNaoakiOkazaki,editors,Proceed-
ingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:
Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 13484–13508. Associa-
tion for Computational Linguistics, 2023. doi: 10.18653/V1/2023.ACL-LONG.754. URL
https://doi.org/10.18653/v1/2023.acl-long.754.
[49] JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,BrianIchter,FeiXia,EdH.Chi,
QuocV.Le,andDennyZhou. Chain-of-thoughtpromptingelicitsreasoninginlargelanguage
models. InSanmiKoyejo,S.Mohamed,A.Agarwal,DanielleBelgrave,K.Cho,andA.Oh,
editors,AdvancesinNeuralInformationProcessingSystems35: AnnualConferenceonNeural
InformationProcessingSystems2022,NeurIPS2022,NewOrleans,LA,USA,November28-
December9,2022,2022. URLhttp://papers.nips.cc/paper_files/paper/2022/hash/
9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html.
[50] PeterWest,ChandraBhagavatula,JackHessel,JenaD.Hwang,LiweiJiang,RonanLeBras,
Ximing Lu, Sean Welleck, and Yejin Choi. Symbolic knowledge distillation: from general
languagemodelstocommonsensemodels. InMarineCarpuat,Marie-CatherinedeMarneffe,
andIvánVladimirMezaRuíz,editors,Proceedingsofthe2022ConferenceoftheNorthAmeri-
canChapteroftheAssociationforComputationalLinguistics: HumanLanguageTechnologies,
NAACL 2022, Seattle, WA, United States, July 10-15, 2022, pages 4602–4625. Association
for Computational Linguistics, 2022. doi: 10.18653/V1/2022.NAACL-MAIN.341. URL
https://doi.org/10.18653/v1/2022.naacl-main.341.
[51] QianqianXie, WeiguangHan, XiaoZhang, YanzhaoLai, MinPeng, AlejandroLopez-Lira,
andJiminHuang. PIXIU:Alargelanguagemodel,instructiondataandevaluationbenchmark
forfinance. CoRR,abs/2306.05443,2023. doi: 10.48550/ARXIV.2306.05443. URLhttps:
//doi.org/10.48550/arXiv.2306.05443.
[52] BinfengXu,ZhiyuanPeng,BowenLei,SubhabrataMukherjee,YuchenLiu,andDongkuan
Xu. Rewoo: Decouplingreasoningfromobservationsforefficientaugmentedlanguagemodels.
CoRR,abs/2305.18323,2023. doi: 10.48550/ARXIV.2305.18323. URLhttps://doi.org/
10.48550/arXiv.2305.18323.
[53] ZhilinYang,PengQi,SaizhengZhang,YoshuaBengio,WilliamW.Cohen,RuslanSalakhut-
dinov, and Christopher D. Manning. Hotpotqa: A dataset for diverse, explainable multi-
hop question answering. In Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun’ichi
Tsujii, editors, Proceedings of the 2018 Conference on Empirical Methods in Natural Lan-
guage Processing, Brussels, Belgium, October 31 - November 4, 2018, pages 2369–2380.
Association for Computational Linguistics, 2018. doi: 10.18653/V1/D18-1259. URL
https://doi.org/10.18653/v1/d18-1259.
[54] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. Narasimhan, and
Yuan Cao. React: Synergizing reasoning and acting in language models. In The Eleventh
InternationalConferenceonLearningRepresentations,ICLR2023,Kigali,Rwanda,May1-5,
2023.OpenReview.net,2023. URLhttps://openreview.net/pdf?id=WE_vluYUL-X.
[55] Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Chandu, Kai-Wei Chang, and
Bill Yuchen Lin. Lumos: Learning agents with unified data, modular design, and open-
source llms. CoRR, abs/2311.05657, 2023. doi: 10.48550/ARXIV.2311.05657. URL
https://doi.org/10.48550/arXiv.2311.05657.
[56] Aohan Zeng, Mingdao Liu, Rui Lu, Bowen Wang, Xiao Liu, Yuxiao Dong, and Jie Tang.
Agenttuning: Enablinggeneralizedagentabilitiesforllms. CoRR,abs/2310.12823,2023. doi:
10.48550/ARXIV.2310.12823. URLhttps://doi.org/10.48550/arXiv.2310.12823.
[57] AndyZhou,KaiYan,MichalShlapentokh-Rothman,HaohanWang,andYu-XiongWang. Lan-
guage agent tree search unifies reasoning acting and planning in language models. CoRR,
18abs/2310.04406, 2023. doi: 10.48550/ARXIV.2310.04406. URL https://doi.org/10.
48550/arXiv.2310.04406.
[58] Fengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv,
Fuli Feng, and Tat-Seng Chua. TAT-QA: A question answering benchmark on a hybrid of
tabularandtextualcontentinfinance. InChengqingZong,FeiXia,WenjieLi,andRoberto
Navigli,editors,Proceedingsofthe59thAnnualMeetingoftheAssociationforComputational
Linguistics and the 11th International Joint Conference on Natural Language Processing,
ACL/IJCNLP2021,(Volume1:LongPapers),VirtualEvent,August1-6,2021,pages3277–3287.
AssociationforComputationalLinguistics,2021. doi: 10.18653/V1/2021.ACL-LONG.254.
URLhttps://doi.org/10.18653/v1/2021.acl-long.254.
19A DatasetDetails
Weutilizethefollowinglistofdatasetsinthiswork,acrossbothtrainingandevaluation.
• GSM-8K[6]: Weusethepubliclyavailabletrainsplitasthepartofthetrainingsetforgenerating
tool-integratedsolutiontrajectories,andthetestsplitaspartoftheevaluationset.
• MATH[15]: Weusethepubliclyavailabletrainsplitasthepartofthetrainingsetforgenerating
tool-integratedsolutiontrajectories,andthetestsplitaspartoftheevaluationset.
• GoogleDeepMindMathematics[37]:Weusetheentiretrainandtestsplitaspartoftheevaluation
set. Weusethealgebra,basicmath,calculus,multiplication-divisionandnumbertheorysubsets.
Wedonotusethedatasetfortraining.
• MathQA[2]: Weusethepubliclyavailabletestsplitaspartoftheevaluationset. Weusethegain,
general,geometry,physicsandprobabilitysubsets. Wedonotusethedatasetfortraining.
• TabMWP[21]: Weusethepubliclyavailabletrainsplitaspartofthetrainingsetorgenerating
tool-integratedsolutiontrajectories,andthe1Kversionofthetestsplitaspartoftheevaluationset.
• FinQA [5]: We use the publicly available train split as part of the training set or generating
tool-integratedsolutiontrajectories,andthetestsplitaspartoftheevaluationset.
• TAT-QA[58]: Weusethepubliclyavailabletestsplitaspartoftheevaluationset. Wedonotuse
thedatasetfortraining.
• MultimodalQA [44]: We use part of the publicly available development split as part of the
evaluationset. Wefilterforcompositionalquestionsthatusebothtextandtablemodalities. Wedo
notusethedatasetfortraining.
• ComplexWebQuestions[43]: Weusepartofthepubliclyavailabletrainsplitasthepartofthe
trainingsetforgeneratingtool-integratedsolutiontrajectories. Weonlyusethedatasetfortraining.
• MusiQue[46]: Weusepartofthepubliclyavailabletrainsplitasthepartofthetrainingsetfor
generatingtool-integratedsolutiontrajectories. Weonlyusethedatasetfortraining.
• Bamboogle[32]: Weusethetestsplitaspartoftheevaluationset. Wedonotusethedatasetfor
training.
• HotpotQA[53]: Weusepartofthetestsplitaspartoftheevaluationset. Weuse1,000examples
forthetestsplit. Wedonotusethedatasetfortraining.
• StrategyQA [10]: We use the publicly available train split as the part of the training set for
generatingtool-integratedsolutiontrajectories,andpartofthetestsplitaspartoftheevaluationset.
• DROP [7]: We use part of the publicly available train split as the part of the training set for
generatingtool-integratedsolutiontrajectories,andasubsetofthetestsplitforevaluation. We
decontextualizeallquestionstobeunderstoodindependentlyfromtheirassociatedpassagesinthe
originaldataset.
• IIRC[8]:Weusepartofthepubliclyavailabletrainsplitasthepartofthetrainingsetforgenerating
tool-integratedsolutiontrajectories,andasubsetofthetestsplitforevaluation. Wedecontextualize
allquestionstobeunderstoodindependentlyfromtheirassociatedpassagesintheoriginaldataset.
• HUSKYQA(ours): Weuseourfulltrainingsplitonlyforfinetuningtheactiongeneratoronly. We
usehuman-verifiedexamplesinthetestsplitaspartoftheevaluationset.
B ToolDetails
B.1 Code
WeuseaPythoninterpreterwithPython3.9,andprependthefollowingsetofimportstatements
whichenumerateadefaultlistoflibrariesforHUSKYtouse.
20import math
1
import numpy as np
2
import sympy
3
from datetime import datetime
4
from math import comb, gcd, lcm
5
from scipy.optimize import minimize
6
from sympy import symbols, Eq, solve, expand, factor, simplify, Matrix
7
from sympy.solvers.inequalities import solve_univariate_inequality
8
from sympy.core.relational import LessThan
9
Wepost-processtheexecutionresultsbyroundingallfloatoutputsuptofourdigitsafterthedecimal.
B.2 Search
WeusethePythonlibraryforSERPAPI(v0.1.5)toobtainGoogleSearchresultsforsearchqueries.
Wefirstsearchfortheanswerboxandextractthesnippetwithintheboxifitexists. Otherwise,we
takethetopmostorganicsearchresultandextractthetitleandthesnippetfromthesearchresult.
Figure4: VisualizationofaGoogleSearchresult(equallyreturnedbySERPAPI)forthesearch
query"whenwasgeorgewashingtonborn". Weusetheinformationpresentedintheredbox.
C TrainingDetails
C.1 DatasetCompositionforTool-IntegratedSolutionTrajectories
Table7summarizesthedatasetcompositionofthesolutiontrajectoriescollectedfortrainingvarious
modulesinHUSKY,aswellasthecompositionfortrainingtheactiongeneratorA. Weuseasubset
ofthetrainingsetsfortasksthatrequireknowledge-basedreasoning, includingCWQ,MusiQue,
StrategyQA,DROPandIIRC,duetoratelimitsimposedbySERPAPI.
C.2 TrainingHyperparameters
Foralltrainingruns,weusetheDeepSpeedZeRO-3Optimizer[35]inBF16precisionover3epochs
withalearningrateof5e-6,weightdecay1e-2,alinearschedulerforthelearningrate,maxlengthof
2048,warmupratioof0.03,andatotalbatchsizeof32.
Actiongenerator. Weusetheprovidedhyperparameterconfigurationandfine-tuneLlama-2-7Band
13Bacross2NVIDIAA10080GBGPUs,andLlama-3-8Bacross4NVIDIAA10080GBGPUs.
Codegenerator. Weusetheprovidedhyperparameterconfigurationandfine-tuneCodeTulu-7Band
DeepSeekCoder-7B-Instruct-v1.5across2NVIDIAA10080GBGPUs,andLlama-3-8Bacross4
NVIDIAA10080GBGPUs.
Mathreasoner. Weusetheprovidedhyperparameterconfigurationandfine-tuneTulu-2-7Band
DeepSeekMath-7B-Instructacross2NVIDIAA10080GBGPUs,andLlama-3-8Bacross4NVIDIA
A10080GBGPUs.
Querygenerator. Weusetheprovidedhyperparameterconfigurationandfine-tuneLlama-2-7B
across2NVIDIAA10080GBGPUs,andLlama-3-8Bacross4NVIDIAA10080GBGPUs.
21Dataset #Solutions #CorrectSolutions #Actions
GSM-8K 7500 7436 22595
MATH 7475 6338 21368
TabMWP 3000 2550 6839
FinQA 6203 4568 14314
CWQ 6000 2840 7359
MusiQue 6000 2777 9198
StrategyQA 1603 1279 4743
DROP 6330 2932 9347
IIRC 6000 3067 9265
HUSKYQA 1350 1350 6302
Total 51,461 35,137 111,330
Table7: Numberofsolutiontrajectories,successfultrajectoriesandactionexamplescollectedfrom
eachtrainingdatasetspanningnumerical,tabular,knowledge-basedandmixedreasoning.
D EvaluationDetails
D.1 Inference
Algorithm1presentsadetailedoverviewoftheinferenceprocedure. Werunallmoduleswithbatch
size16,temperature0(0.3forthenon-finetunedM ),andastrictmaximumof10iterationsfor
r
solvingeachproblem. Inpractice,wetakeadistinctivelyefficientapproachtoexecutingouragent
modulesbyrunningallmodulesinparallelandusevLLM[18]toperformefficientinference.
Algorithm1HUSKYInference
Require: inputx,actiongeneratorA,modulesM ,M ,M ,M
c m q r
1: stepindexi=0,solutionhistoryh 0 =∅
2: whileA(x,h i)̸=[finish]ANDi<10do
3: s i,t i =A(x,h i)
4: ift i =[code]then
5: c i =M c(x,h i,s i)
6: e i =PYTHON(c i)
7: o i =M r(x,s i,c i,e i)
8: elseift i =[math]then
9: o i =M m(x,h i,s i)
10: elseift i =[search]then
11: q i =M q(x,h i,s i)
12: e i =GOOGLE(q i)
13: o i =M r(s i,e i)
14: elseift i =[commonsense]then
15: o i =M r(x,h i,s i)
16: elseift i =[finish]then
17: a=EXTRACT(s i)
18: endif
19: i+=1,h i ="h i−1\ns i\no i"
20: endwhile
21: return a
D.2 EvaluationDatasetsandMetrics
Weshareadditionaldetailsintohowthedatasetsareevaluated. Allrandomseedsareinitializedat42.
• GSM-8K, MATH, Bamboogle, FinQA, TAT-QA: We use the full test split containing 1,319
examples,5,000examples,125examplesand1,133examples,respectively.
• TabMWP:Weusethe1Kversionofthetestsplit,whichcontains1,000examples.
22Table8: GPT-4resultsacrossourevaluationtasks,comparedtoHUSKY.
Numericalreasoning Tabularreasoning
Agent GSM8K MATH GDMMath. MathQA TabMWP FinQA TAT-QA MMQA
acc acc acc acc EM EM EM EM/F1
HUSKYLlama2-7B 77.9 40.9 58.2 49.1 77.6 20.8 42.2 46.7/52.5
HUSKYLlama2-13B 79.4 41.9 57.9 51.2 75.6 20.0 42.3 41.2/48.2
HUSKYLlama3-8B 79.9 42.1 55.8 51.0 76.6 20.9 41.8 43.7/50.5
GPT-4 92.0 52.9 47.5 43.4 96.2 33.0 73.1 66.0/72.5
Knowledgereasoning Mixed-toolreasoning
Agent Bamboogle HotpotQA Strat.QA DROP* IIRC* HUSKYQA
EM/F1 EM/F1 acc EM/F1 EM/F1 acc
HUSKYLlama2-7B 54.4/65.8 32.7/46.6 70.0 26.0/30.9 33.0/37.9 20.9
HUSKYLlama2-13B 56.0/66.8 35.1/48.8 71.3 27.5/32.1 32.5/37.2 25.0
HUSKYLlama3-8B 58.4/70.2 33.7/49.0 67.3 26.0/31.2 33.5/39.1 20.9
GPT-4 52.8/68.41 39.4/53.1 71.0 22.0/25.5 28.0/33.73 20.2
• StrategyQA:Weuseasubsetof300randomlyselectedexamplesfromthetestsplit,following
[55]. Weusethesamesubsetforallourevaluations.
• HotpotQA:Weuseasubsetof1,000randomlyselectedexamplesfromthetestsplit,following
[55]. Weusethesamesubsetforallourevaluations.
• Google-DeepMind Mathematics: We combine both the train and test splits from the algebra
(1,679),basicmath(300),calculus(269),muldiv(446)andnumbertheory(1,034)subsets.
• MathQA:Weusethefulltestsplitforthegain(391),general(777),geometry(117)andphysics
(488)subsets,andwecombineboththetrainandtestsplitsfortheprobability(301)subsetdueto
itslackoftestexamples.
• MultimodalQA:Weuse362examplesinthedevelopmentsetthatarelabeledascompositional
questionsusingbothtextandtablemodalities.
• DROP*: Weuse200examplesfromthetestsplitaspartoftheevaluationset,andwedecontextu-
alizethequestionstoremovethesolution’sdependencyontheinputpassage.
• IIRC*:Weuse200examplesfromthetestsplitaspartoftheevaluationset,andwedecontextualize
thequestionstoremovethesolution’sdependencyontheinputpassage.
• HUSKYQA: Weuse292examplesfromthetestsplitthatareevaluatedbyhumanstobewell-
formedquestionswiththelabeledanswersmatchinghumanoutputs.
D.3 GPT-4performance
Table8liststheGPT-4performancesacrossallevaluationtasksforreference.Wereportourreplicated
resultswithgpt-4-0125-previewforallevaluationtasksexceptGSM-8KandMATH,forwhich
weusethereportednumbersfromDeepSeekMath[39]tosaveAPIcosts.
E Tool-IntegratedSolutionTrajectories
E.1 Inference
Weusegpt-4-0125-previewtogeneratethetool-integratedsolutiontrajectoriesforalldatasetsas
summarizedinTable7. Ourinferenceconsistsoftwoprompts: thefirstpromptgeneratesthesolution
trajectory(refertoSectionE.3)untila[code]or[search]toolcall,andthesecondpromptre-writes
thetool-executedoutputintonaturallanguage. Wegenerateallsolutiontrajectorieswithmaxlength
4096,maxnewtokens1024andtemperature0.3. Wegeneratealltool-executedoutputrewriteswith
maxlength2048,maxnewtokens256andtemperature0.3. Wedeviseaseparatesolutiontrajectory
generationpromptforeachdataset(orgroupsofdatasets),aswellasaseparatetool-executionwriter
promptfornumerical,tabularandknowledge-basedreasoningtasks,respectively.
23E.2 Instructions
We provide instructions for generating the tool-integrated solution trajectories for each category
in Figures 5, 6, 7 and 8. Refer to Section J for the complete set of prompts with the few-shot
demonstrations.
Given a math problem, integrate step-by-step reasoning and Python code to obtain the solution. Make
sure to generate 1) the next step to be taken, 2) the tool to be used (either [code] or
[math]), and 3) the associated code or math solution for that step.
- The format should be "Step N:" for the Nth step. The first sentence in each step should be a
high-level summary of what to do for that step. It should begin with an imperative verb such as
"calculate", "compute", "determine", "find" or "identify", and end with a newline character.
- If this sentence involves writing equations, define the variables in this sentence as well. For
example, instead of "Write equations for the problem.", write "Write equations for the problem,
using $x$ to represent the number of apples and $y$ to represent the number of oranges.
- After the step, choose between [code] and [math] to either return a code-based solution for the
step, or a math-based solution for the step.
- For the code-based solution, write the code between lines occupied by the expressions '```python'
and '```'.
- For the code-based solution, do not attempt to predict the executed output of the code - just write
the code.
- For the code-based solution, do not use variables that are undefined within the same code snippet.
If the variable is mentioned in an earlier code snippet, then copy the value of the variable
over to the current code snippet.
- For the math-based solution, present the final result for the step in LaTeX using '\\boxed{}'
without any units.
- If the final answer ANS has been reached in the output of the previous step, simply return "The
answer is: <answer>ANS</answer>.", with the final answer between the tags <answer> and
</answer>. Do not write the unit between the tags.
- Utilize the 'pi' symbol and 'Rational' from sympy for $\pi$ and fractions, and simplify all
fractions and square roots without converting them to decimal values.
- Do not generate more than one code snippet at a time.
- Example imports are provided below. Import any of these packages in the code snippet, as well as
additional packages as needed.
import math
import numpy as np
import sympy
from math import comb, gcd, lcm
from scipy.optimize import minimize
from sympy import symbols, Eq, solve, expand, factor, Matrix
from sympy.solvers.inequalities import solve_univariate_inequality
from sympy.core.relational import LessThan
Below are a few examples of the generated output. Adhere to the format shown in the examples.
Figure5: Instructionfornumericalreasoningtasks
Given a question input that contains some passage, a table and the actual question, integrate
step-by-step reasoning and Python code to obtain the solution. Make sure to generate 1) the
next step to be taken, 2) the tool to be used (either [code] or [commonsense]), and 3) the
associated code or text solution for that step.
- The format should be "Step N:" for the Nth step. The first sentence in each step should be a
high-level summary of what to do for that step. It should begin with an imperative verb such as
"identify", "find", "calculate", "compute" or "determine", and end with a newline character.
- After the step, choose between [code] and [commonsense] to either return a code-based solution or a
commonsense-based solution for the step.
- Use the [code] tool to convert stem-and-leaf plots into lists, or to perform precise computations
with large numbers or decimals.
- Use the [commonsense] tool for all other tasks, such as identifying values from the table or
performing commonsense reasoning such as comparing two numbers.
- For the code-based solution, write the code between lines occupied by the expressions '```python'
and '```'.
- For the code-based solution, do not attempt to predict the executed output of the code - just write
the code.
- Use the Fraction class in the fractions library for code-based solutions if the question asks to
return a fraction.
- For the code-based solution, do not use variables that are undefined within the same code snippet.
If the variable is mentioned in an earlier code snippet, then copy the value of the variable
over to the current code snippet.
- If the final answer ANS has been reached in the output of the previous step, simply return "The
answer is: <answer>ANS</answer>.", with the final answer between the tags <answer> and
</answer>.
Below are a few examples of the generated output. Adhere to the format shown in the examples.
Figure6: Instructionfortabularreasoningtasks
24Given a factoid question, integrate step-by-step reasoning and search queries to obtain the solution.
Make sure to generate 1) the next step to be taken, 2) the tool to be used ([search], [code] or
[commonsense]), and 3) the associated search query or text solution for that step.
- The format should be "Step N:" for the Nth step. The first sentence in each step should be a
high-level summary of what to do for that step. It should begin with an imperative verb such as
"search", "recall", "determine", "find" or "identify", and end with a newline character.
- After the step, choose between [search], [code] and [commonsense] to either return a search-based
solution, a code-based solution, or a commonsense-based solution for the step.
- Use the search tool to obtain answers for questions that cannot be answered by your own knowledge.
- For the search-based solution, write the search query between lines occupied by the expressions
'```google' and '```'.
- For the commonsense-based solution, present the final result for the step between the tags
'<output>' and '</output>'.
- If the search result does not solve the current step, then retry that step with an improved query.
- If the final answer ANS has been reached in the output of the previous step, simply return "The
answer is: <answer>ANS</answer>.", with the final answer between the tags <answer> and
</answer>.
- Do not generate more than one search query at a time.
Below are a few examples of the generated output. Adhere to the format shown in the examples.
Figure7: Instructionforknowledge-basedreasoningtasks
Given an input question, integrate step-by-step reasoning with math problem-solving, Python code and
search queries to obtain the solution. Make sure to generate 1) the next step to be taken, 2)
the tool to be used ([math], [code], [search] or [commonsense]), and 3) the associated search
math, code, search or commonsense-based solution for that step.
- The format should be "Step N:" for the Nth step. The first sentence in each step should be a
high-level summary of what to do for that step. It should begin with an imperative verb such as
"search", "find", "calculate", "compute", "determine" or "identify", and end with a newline
character.
- After the step, choose between [math], [search], [code] and [commonsense] to return a math-based
solution, a search-based solution, a code-based solution, or a commonsense reasoning-based
solution.
- Use the [math] tool to perform mathematical reasoning, given that all the necessary information is
provided in the question and the solution history so far.
- Use the [search] tool to obtain information that is not provided in the question and cannot be
answered by your own knowledge.
- For the search-based solution, write the search query between lines occupied by the expressions
'```google' and '```'.
- Use the [code] tool to perform precise numerical computations with large numbers or decimals, to
count long lists of numbers or perform operations between two different dates.
- For the code-based solution, write the code between lines occupied by the expressions '```python'
and '```'.
- For the code-based solution, do not attempt to predict the executed output of the code - just write
the code.
- For the code-based solution, do not use variables that are undefined within the same code snippet.
If the variable is mentioned in an earlier code snippet, then copy the value of the variable
over to the current code snippet.
- Do not generate more than one code snippet at a time.
- Use the [commonsense] tool for all other common reasoning tasks (e.g., comparing two numbers) that
do not require the usage of math/search/code.
- If the step contains a short answer in its output, present the short answer to the step between the
tags '<output>' and '</output>'.
- If the final answer "ANS" has been reached in the output of the previous step, simply return "The
answer is: <answer>ANS</answer>.", with the final answer between the tags <answer> and
</answer>.
- Example imports are provided below. Import any of these packages in the code snippet, as well as
additional packages as needed.
import math
import numpy as np
import sympy
from math import comb, gcd, lcm
from scipy.optimize import minimize
from sympy import symbols, Eq, solve, expand, factor, Matrix
from sympy.solvers.inequalities import solve_univariate_inequality
from sympy.core.relational import LessThan
Below are a few examples of the generated output. Adhere to the format shown in the examples.
Figure8: Instructionformixedreasoningtasks
25E.3 Examples
Question: A line passes through $(2,2,1)$ and $(5,1,-2).$ A point on this line has an $x$-coordinate
of 4. Find the $z$-coordinate of the point.
Solution:
Step1: Calculate the direction vector of the line.
Tool: [code]
```python
import numpy as np
# define the coordinates of the two points
point1 = np.array([2, 2, 1])
point2 = np.array([5, 1, -2])
# calculate the direction vector
direction_vector = point2 - point1
# print the output
out = direction_vector
print(out)
```
```output
[ 3 -1 -3]
```
The direction vector of the line is [3, -1, -3].
Step2: Find the parameter $t$ when the $x$-coordinate is 4.
Tool: [code]
```python
from sympy import symbols, Eq, solve
# define the symbol for the parameter
t = symbols('t')
# define the initial x-coordinate and the direction vector's x-component
x_initial = 2
direction_x = 3
# equation for the x-coordinate at point t
eq = Eq(x_initial + direction_x*t, 4)
# solve for t
t_value = solve(eq, t)[0]
# print the output
out = t_value
print(out)
```
```output
2/3
```
The parameter $t$ when the $x$-coordinate is 4 is $2/3.
Step3: Compute the $z$-coordinate of the point when $t = 2/3$.
Tool: [code]
```python
from sympy import Rational
# define the initial z-coordinate and the direction vector's z-component
z_initial = 1
direction_z = -3
# compute the z-coordinate at point t
z_coordinate = z_initial + direction_z * Rational(2, 3)
# print the output
out = z_coordinate
print(out)
```
```output
-1.0
```
The $z$-coordinate of the point on the line when $t = 2/3$ is -1.0.
The answer is: <answer>-1.0</answer>.
Figure9: Exampletool-integratedsolutiontrajectoryfromMATH
26Question: table of contents the following discussion of nonoperating income and expense excludes the
results of the merger in order to provide a more meaningful year-over-year comparison .
interest expense , net of capitalized interest decreased $ 249 million in 2014 from 2013
primarily due to a $ 149 million decrease in special charges recognized year-over-year as
further described below , as well as refinancing activities that resulted in $ 100 million less
interest expense recognized in 2014 . ( 1 ) in 2014 , we recognized $ 33 million of special
charges relating to non-cash interest accretion on bankruptcy settlement obligations . in 2013
, we recognized $ 138 million of special charges relating to post-petition interest expense on
unsecured obligations pursuant to the plan and penalty interest related to american 2019s 10.5%
( 10.5 % ) secured notes and 7.50% ( 7.50 % ) senior secured notes . in addition , in 2013 we
recorded special charges of $ 44 million for debt extinguishment costs incurred as a result of
the repayment of certain aircraft secured indebtedness , including cash interest charges and
non-cash write offs of unamortized debt issuance costs . ( 2 ) as a result of the 2013
refinancing activities and the early extinguishment of american 2019s 7.50% ( 7.50 % ) senior
secured notes in 2014 , we recognized $ 100 million less interest expense in 2014 as compared
to 2013 . other nonoperating expense , net in 2014 consisted of $ 114 million of net foreign
currency losses , including a $ 43 million special charge for venezuelan foreign currency
losses , and $ 56 million in other nonoperating special charges primarily due to early debt
extinguishment costs related to the prepayment of our 7.50% ( 7.50 % ) senior secured notes and
other indebtedness . the foreign currency losses were driven primarily by the strengthening of
the u.s . dollar relative to other currencies during 2014 , principally in the latin american
market , including a 48% ( 48 % ) decrease in the value of the venezuelan bolivar and a 14% (
14 % ) decrease in the value of the brazilian real . other nonoperating expense , net in 2013
consisted principally of net foreign currency losses of $ 56 million and early debt
extinguishment charges of $ 29 million . reorganization items , net reorganization items refer
to revenues , expenses ( including professional fees ) , realized gains and losses and
provisions for losses that are realized or incurred as a direct result of the chapter 11 cases
. the following table summarizes the components included in reorganization items , net on aag
2019s consolidated statement of operations for the year ended december 31 , 2013 ( in millions
) : . ( 1 ) in exchange for employees 2019 contributions to the successful reorganization ,
including agreeing to reductions in pay and benefits , we agreed in the plan to provide each
employee group a deemed claim , which was used to provide a distribution of a portion of the
equity of the reorganized entity to those employees . each employee group received a deemed
claim amount based upon a portion of the value of cost savings provided by that group through
reductions to pay and benefits as well as through certain work rule changes . the total value
of this deemed claim was approximately $ 1.7 billion . ( 2 ) amounts include allowed claims (
claims approved by the bankruptcy court ) and estimated allowed claims relating to ( i ) the
rejection or modification of financings related to aircraft and ( ii ) entry of orders treated
as unsecured claims with respect to facility agreements supporting certain issuances of special
facility revenue bonds . the debtors recorded an estimated claim associated with the rejection
or modification of a financing .
['', '2013']
['labor-related deemed claim ( 1 )', '$ 1733']
['aircraft and facility financing renegotiations and rejections ( 2 ) ( 3 )', '325']
['fair value of conversion discount ( 4 )', '218']
['professional fees', '199']
['other', '180']
['total reorganization items net', '$ 2655']
what is the percent of the labor-related deemed claim as part of the total reorganization items net
in 2013
Solution:
Step1: Identify the total value of labor-related deemed claim in 2013.
Tool: [commonsense]
According to the table, the labor-related deemed claim in 2013 is $1733 million.
Step2: Identify the total reorganization items net in 2013.
Tool: [commonsense]
According to the table, the total reorganization items net in 2013 is $2655 million.
Step3: Calculate the percentage of the labor-related deemed claim as part of the total reorganization
items net in 2013.
Tool: [code]
```python
labor_related_claim = 1733
total_reorganization_items = 2655
percentage = (labor_related_claim / total_reorganization_items) * 100
# print the output
print(percentage)
```
```output
65.2731
```
The labor-related deemed claim constitutes 65.2731 percent of the total reorganization items net in
2013.
The answer is: <answer>65.2731%</answer>.
Figure10: Exampletool-integratedsolutiontrajectoryfromFinQA
27Question: When did the organization that gives out the Frank P. Brown Medal open?
Solution:
Step1: Identify the organization that gives out the Frank P. Brown Medal.
Tool: [search]
```google
organization that gives out the Frank P. Brown Medal
```
```output
The Frank P. Brown Medal was formerly awarded by the Franklin Institute for excellence in science,
engineering, and structures. It was established by the 1938 will of Franklin Pierce Brown, a
member of the Master Plumbers Association.
```
The organization that gives out the Frank P. Brown Medal is <output>the Franklin Institute</output>.
Step2: Find the year the Franklin Institute was founded.
Tool: [search]
```google
year the Franklin Institute was founded
```
```output
On February 5, 1824, Samuel Vaughan Merrick and William H. Keating founded The Franklin Institute of
the State of Pennsylvania for the Promotion of the Mechanic Arts.
```
The Franklin Institute was founded in <output>1824</output>.
The answer is: <answer>1824</answer>.
Figure11: Exampletool-integratedsolutiontrajectoryfromMusiQue
Question: Would Kurt Cobain have benefited from Project Semicolon?
Solution:
Step1: Understand what Project Semicolon is.
Tool: [search]
```google
what is Project Semicolon?
```
```output
About Project Semicolon Organization: Project Semicolon is a compassionate online community that
centers around mental health awareness and suicide prevention. Our platform serves as a safe ...
```
Project Semicolon is an organization focused on mental health awareness and suicide prevention.
Step2: Determine the main issues Kurt Cobain faced.
Tool: [search]
```google
what issues did Kurt Cobain face?
```
```output
He was also prone to alcoholism, suffered from depression, and regularly used drugs and inhalants.
Cobain had two uncles who killed themselves using guns. On March 4, 1994, Cobain was
hospitalized in Rome following an overdose of Rohypnol (Flunitrazepam) and alcohol.
```
The main issues Kurt Cobain faced were alcoholism, depression, and regular use of drugs and inhalants.
Step3: Determine if Project Semicolon's focus aligns with the issues Kurt Cobain faced.
Tool: [commonsense]
Project Semicolon focuses on mental health awareness and suicide prevention. Kurt Cobain faced issues
such as alcoholism, depression, and regular use of drugs and inhalants. Given the alignment
between Cobain's issues and Project Semicolon's focus, it is plausible that Kurt Cobain could
have benefited from Project Semicolon.
The answer is: <answer>yes</answer>.
Figure12: Exampletool-integratedsolutiontrajectoryfromStrategyQA
28Question: How many yards longer was Marcedes Lewis's longest touchdown compared to his shortest in the
game between the Dallas Cowboys and the Jaguars where David Buehler hit a 34-yard field goal?
Solution:
Step1: Identify the date of the game between the Dallas Cowboys and the Jaguars where David Buehler
hit a 34-yard field goal.
Tool: [search]
```google
precise date of the game between the Dallas Cowboys and the Jaguars where David Buehler hit a 34-yard
field goal
```
```output
Jaguars 35-17 Cowboys (1 Nov, 2010) Final Score: Dallas Cowboys. FG. 10:51. David Buehler 34 Yard
Field Goal is Good. 9 plays, 39 yards, 4:14. 0 ; Jacksonville Jaguars. TD. 7:55. Mike
Sims-Walker 10 Yard Pass ...
```
The game between the Dallas Cowboys and the Jaguars, where David Buehler hit a 34-yard field goal,
took place on <output>November 1, 2010</output>.
Step2: Retrieve information about the game.
Tool: [search]
```google
game between the Dallas Cowboys and the Jaguars on November 1, 2010
```
```output
['Quarter', 'Time', 'Tm', 'Detail', 'JAX', 'DAL']
['1','10:46','Cowboys','David Buehler 34 yard field goal','0','3']
['1','7:50','Jaguars','Mike Sims-Walker 10 yard pass from David Garrard (Josh Scobee kick)','7','3']
['2','9:43','Jaguars','Marcedes Lewis 42 yard pass from David Garrard (Josh Scobee kick)','14','3']
['3','12:14','Jaguars','Mike Thomas 15 yard pass from David Garrard (Josh Scobee kick)','21','3']
['3','9:01','Jaguars','Marcedes Lewis 9 yard pass from David Garrard (Josh Scobee kick)','28','3']
['4','12:29','Cowboys','Marion Barber III 1 yard rush (David Buehler kick)','28','10']
['4','5:50','Jaguars','David Garrard 2 yard rush (Josh Scobee kick)','35','10']
['4','2:29','Cowboys','Jason Witten 8 yard pass from Jon Kitna (David Buehler kick)','35','17']
```
Step3: Calculate the difference in yards between Marcedes Lewis's longest and shortest touchdowns in
the game.
Tool: [code]
```python
longest_touchdown = 42
shortest_touchdown = 9
yard_difference = longest_touchdown - shortest_touchdown
print(yard_difference)
```
```output
33.0
```
Marcedes Lewis's longest touchdown was 33 yards longer than his shortest touchdown in the game
between the Dallas Cowboys and the Jaguars.
The answer is: <answer>33</answer> yards.
Figure13: Exampletool-integratedsolutiontrajectoryfromDROP*
29F DROP*andIIRC*
F.1 Questionre-writing
WedecontextualizeasubsetofquestionsfromDROPandIIRCusinggpt-3.5-turbo-0125with
max length 2048, max new tokens 128 and temperature 0.3. We provide few-shot prompts for
decontextualizingbothDROPandIIRCbelow.
Given a passage that describes a sports game, rewrite the old question by integrating specific
information from the passage such that the user can answer the new question without reading the
passage and using Google Search instead.
- Indicate the two teams that played in the given game, using the phrase "the game between A and B"
for teams A and B.
- Choose one piece of information from the passage and add it to the question to better specify the
game between the two teams.
- This information should be related to statistical details of the game related to a single player
regarding 1) scoring a field goal or 2) a TD run.
- This information should NOT be related to other aspects of the game such as passing, injuries or
other celebratory events.
- Make sure that the new information added does not directly answer the question itself.
- Make sure that the new question is grammatical.
Below are a few examples of the generated output. Adhere to the format shown in the examples.
---
Passage: This game involved a scary moment, after Seattle's Ricardo Lockette was hit during a kick
return. He lied on the ground, motionless, for about 7 minutes before he was taken off the
field on a cart. X-rays later revealed that Lockette had a broken neck. The injury ended his
career. The Cowboys would only kick field goals in this game, as Dan Bailey was 4 for 4 on
field goals. Dallas lead 12-10 with under 2 minutes to go. However, the Seahawks would march
down the field and would take a 13-12 lead after Steven Hauschka drilled a 24-yard field goal.
Dallas tried to come back, but Seattle forced a turnover on downs to end the game.
Old question: How many total points were scored in the game?
New question: How many total points were scored in the game between the Dallas Cowboys and the
Seattle Seahawks where Steven Hauschka scored a 24-yard field goal?
---
Passage: Hoping to rebound from their loss to the Patriots, the Raiders stayed at home for a Week 16
duel with the Houston Texans. Oakland would get the early lead in the first quarter as
quarterback JaMarcus Russell completed a 20-yard touchdown pass to rookie wide receiver Chaz
Schilens. The Texans would respond with fullback Vonta Leach getting a 1-yard touchdown run,
yet the Raiders would answer with kicker Sebastian Janikowski getting a 33-yard and a 30-yard
field goal. Houston would tie the game in the second quarter with kicker Kris Brown getting a
53-yard and a 24-yard field goal. Oakland would take the lead in the third quarter with wide
receiver Johnnie Lee Higgins catching a 29-yard touchdown pass from Russell, followed up by an
80-yard punt return for a touchdown. The Texans tried to rally in the fourth quarter as Brown
nailed a 40-yard field goal, yet the Raiders' defense would shut down any possible attempt.
Old question: Who scored the first touchdown of the game?
New question: Who scored the first touchdown of the game between the Oakland Raiders and the Houston
Texans where Vonta Leach got a 1-yard touchdown run in the first quarter?
---
Passage: Still searching for their first win, the Bengals flew to Texas Stadium for a Week 5
interconference duel with the Dallas Cowboys. In the first quarter, Cincinnati trailed early
as Cowboys kicker Nick Folk got a 30-yard field goal, along with RB Felix Jones getting a
33-yard TD run. In the second quarter, Dallas increased its lead as QB Tony Romo completed a
4-yard TD pass to TE Jason Witten. The Bengals would end the half with kicker Shayne Graham
getting a 41-yard and a 31-yard field goal. In the third quarter, Cincinnati tried to rally as
QB Carson Palmer completed an 18-yard TD pass to WR T. J. Houshmandzadeh. In the fourth
quarter, the Bengals got closer as Graham got a 40-yard field goal, yet the Cowboys answered
with Romo completing a 57-yard TD pass to WR Terrell Owens. Cincinnati tried to come back as
Palmer completed a 10-yard TD pass to Houshmandzadeh (with a failed 2-point conversion), but
Dallas pulled away with Romo completing a 15-yard TD pass to WR Patrick Crayton.
Old question: Which team scored the final TD of the game?
New question: Which team scored the final TD of the game between the Cincinnati Bengals and the
Dallas Cowboys where Nick Folk scored a 30-yard field goal in the first quarter?
---
Passage: Trying to snap a six-game losing skid, the Lions returned home for an NFC North rematch
the-now 2-time NFC North champion Chicago Bears. In the first quarter, the Bears struck first
with kicker Robbie Gould nailing a 36-yard field goal. Afterwards, the Lions took the lead
with QB Jon Kitna completing a 23-yard TD pass to TE Dan Campbell. In the second quarter,
Chicago bounced back with QB Rex Grossman completing a 13-yard TD pass to WR Bernard Berrian.
Afterwards, RB Adrian Peterson got a 2-yard TD run. In the third quarter, Detroit retook the
lead with Kitna completing a 20-yard TD pass to WR Mike Furrey and a 2-yard TD pass to WR Roy
Williams. However, in the fourth quarter, the inconsistency that continues to plague the Lions
showed as the Bears won with Gould getting a 36-yard field goal, a 39-yard field goal, and a
44-yard field goal and on a dropped pass by Mike Williams in the endzone on the last play of
the game. With their seventh-straight loss, the Lions fell to 2-13 as they were swept by their
division rivals.
Old question: How many field goals did Robbie Gould make in the 4th quarter?
New question: How many field goals did Robbie Gould make in the 4th quarter in the game between the
Detroit Lions and the Chicago Bears where he nailed a 36-yard field goal in the first quarter?
Figure14: Few-shotpromptfordecontextualizingDROP(sports)
30Given a passage that describes a historical event, rewrite the old question by integrating specific
information from the passage such that the events in the question are less ambiguous and the
user can answer the new question without reading the passage and using Google Search instead.
- Replace ambiguous entities (e.g., "the city") with the specific entity (e.g., "New York City") from
the passage.
- For historical events which happened multiple times (e.g., Battle of Hastings), add more details
(e.g., Battle of Hastings in the 11th century) to narrow it down to a single event.
- Do NOT generate questions that include the years for both of the historical events. If necessary,
add the year to the event that is more ambiguous without the year description.
- Make sure that any new information added does not directly answer the question itself.
- Make sure that the new question asks for the same information as the old question in the passage.
- Leave the question as it is if it is already specific enough to solve on its own without the
passage.
- Make sure that the new question is grammatical.
Below are a few examples of the generated output. Adhere to the format shown in the examples.
---
Passage: In 1085, Guadalajara was retaken by the Christian forces of Alfonso VI . The chronicles say
that the Christian army was led by Alvar Fanez de Minaya, one of the lieutenants of El Cid.
From 1085 until the Battle of Las Navas de Tolosa in 1212, the city suffered wars against the
Almoravid and the Almohad Empires. In spite of the wars, the Christian population could
definitely settle down in the area thanks to the repopulation with people from the North who
received their first fuero in 1133 from Alfonso VII.In 1219, the king Fernando III gave a new
fuero to the city .During the reign of Alfonso X of Castile, the protection of the king allowed
the city to develop its economy by protecting merchants and allowing markets.
Old question: How many years after the people of the North received their first fuero from Alfonso
VII did king Fernando III give a new fuero to the city?
New question: How many years after the people of the North in Guadalajara received their first fuero
from Alfonso VII did king Fernando III give a new fuero to Guadalajara?
---
Passage: The Lithuanian Civil War of 1432-1438 was a conflict over the succession to the throne of
the Grand Duchy of Lithuania, after Vytautas the Great died in 1430 without leaving an heir.
The war was fought on the one side by \u0160vitrigaila, allied with the Teutonic Knights, and
on the other by Sigismund K\u0119stutaitis, backed by the Kingdom of Poland. The war threatened
to sever the Union of Krewo, the personal union between Poland and Lithuania.
\u0160vitrigaila's alliance with the Grand Master of the Teutonic Order, Paul von Rusdorf,
launched the Polish-Teutonic War but failed to secure victory for \u0160vitrigaila. When
Sigismund captured power in Lithuania by staging a coup in 1432, Lithuania split into two
opposing camps, and there began three years of devastating hostilities. To prevent the Knights
from continuing their support of \u0160vitrigaila, Poland backed a Hussite invasion of Prussia
in 1433. The war ended in a decisive defeat for \u0160vitrigaila and his ally, the Livonian
branch of the Teutonic Knights, at the Battle of Pabaiskas in September 1435. \u0160vitrigaila
eventually surrendered in 1437; Sigismund K\u0119stutaitis ruled Lithuania for only eight years
before he was assassinated in 1440.
Old question: How many years did the Lithuanian Civil War last?
New question: How many years did the Lithuanian Civil War that started in 1432 last?
---
Passage: Before Hunyadi could assemble his forces, the army of Mehmed II arrived at Belgrade. The
siege began on July 4, 1456. Szil\u00e1gyi could rely on a force of only 5,000-7,000 men in the
castle. Mehmed set up his siege on the neck of the headland and started heavily bombarding the
city's walls on June 29. He arrayed his men in three sections: The Rumelian corps had the
majority of his 300 cannons, while his fleet of 200 river war vessels had the rest of them. The
Rumelians were arrayed on the right wing and the Anatolian corps were arrayed on the left. In
the middle were the personal guards of the Sultan, the Janissaries, and his command post. The
Anatolian corps and the Janissaries were both heavy infantry troops. Mehmed posted his river
vessels mainly to the northwest of the city to patrol the marshes and ensure that the fortress
was not reinforced. They also kept an eye on the Sava river to the southwest to avoid the
infantry from being outflanked by Hunyadi's army. The zone from the Danube eastwards was
guarded by the Sipahi, the Sultan's feudal heavy cavalry corps, to avoid being outflanked on
the right.
Old question: Which event happened first, the siege, or Hunyadi assembling his forces?
New question: Which event happened first, the siege of Belgrade by the army of Mehmed II or the
assembly of Hunyadi's forces to aid Belgrade?
---
Passage: Since the end of World War II, in part due to industrial size and the onset of the Cold War,
the United States has often been a proponent of reduced tariff-barriers and free trade. The
U.S. helped establish the General Agreement on Tariffs and Trade and later the World Trade
Organization ; although it had rejected an earlier version in the 1950s . Since the 1970s, U.S.
governments have negotiated managed-trade agreements, such as the North American Free Trade
Agreement in the 1990s, the Dominican Republic-Central America Free Trade Agreement in 2006,
and a number of bilateral agreements . In Europe, six countries formed the European Coal and
Steel Community in 1951 which became the European Economic Community in 1958. Two core
objectives of the EEC were the development of a common market, subsequently renamed the single
market, and establishing a customs union between its member states. After expanding its
membership, the EEC became the European Union in 1993. The European Union, now the world's
largest single market, has concluded free trade agreements with many countries around the world.
Old question: What Trade agreement happened first, North American Free Trade Agreement or Dominican
Republic-Central America Free Trade Agreement?
New question: What Trade agreement happened first, North American Free Trade Agreement or Dominican
Republic-Central America Free Trade Agreement?
---
Figure15: Few-shotpromptfordecontextualizingDROP(history)
31Passage: The French king, John II, had been held captive in England. The Treaty of Br\u00e9tigny set
his ransom at 3\u00a0million\u00a0crowns and allowed for hostages to be held in lieu of John.
The hostages included two of his sons, several princes and nobles, four inhabitants of Paris,
and two citizens from each of the nineteen principal towns of France. While these hostages were
held, John returned to France to try and raise funds to pay the ransom. In 1362 John's son
Louis of Anjou, a hostage in English-held Calais, escaped captivity. So, with his stand-in
hostage gone, John felt honor-bound to return to captivity in England. The French crown had
been at odds with Navarre since 1354, and in 1363 the Navarrese used the captivity of John II
in London and the political weakness of the Dauphin to try to seize power. Although there was
no formal treaty, Edward III supported the Navarrese moves, particularly as there was a
prospect that he might gain control over the northern and western provinces as a consequence.
With this in mind, Edward deliberately slowed the peace negotiations. In 1364, John II died in
London, while still in honourable captivity. Charles V succeeded him as king of France. On 7
May 1364, one month after the dauphin's accession and three days before his coronation as
Charles V, the Navarrese suffered a crushing defeat at the Battle of Cocherel.
Old question: How many years passed between the French being at odds with Navarre and the Navarrese
attempting to seize power?
New question: How many years passed between the French being at odds with Navarre in 1354 and the
Navarrese attempting to seize power using the weakness of John II?
---
Passage: News of the two battles reached England in August. After several months of negotiations, the
government of the Duke of Newcastle decided to send an army expedition the following year to
dislodge the French. They chose Major General Edward Braddock to lead the expedition. Word of
the British military plans leaked to France well before Braddock's departure for North America.
In response, King Louis XV dispatched six regiments to New France under the command of Baron
Dieskau in 1755. The British sent out their fleet in February 1755, intending to blockade
French ports, but the French fleet had already sailed. Admiral Edward Hawke detached a fast
squadron to North America in an attempt to intercept them. In a second British action, Admiral
Edward Boscawen fired on the French ship Alcide on June 8, 1755, capturing her and two troop
ships. The British harassed French shipping throughout 1755, seizing ships and capturing
seamen. These actions contributed to the eventual formal declarations of war in spring 1756.
Old question: How many months were there between the blockade on the French ports and Admiral firing
on Alcide
New question: How many months were there between the British attempt to blockade the French ports in
1755 and Admiral Edward Boscawen firing on the French ship Alcide?
---
Passage: Upper Austria had been rebellious for centuries, with 62 known uprisings between 1356 and
1849, 14 of which occurred in the 16th century. However, the Peasants' War of 1626 was the
costliest in terms of human life and damage to livestock and property. The war caused Martin
Aichinger to lose his farm and begin roaming the country. He eventually became a religious
leader who led a popular revolt against aristocratic rule. His revolutionary ideas frightened
the rulers so much that they tried to arrest him, leading to another series of uprisings that
ended in the Battle on the Frankenberg in 1636. All of Aichinger's followers were slaughtered
during the battle, including the remaining women and children who had been in hiding.
Old question: How many years after the Peasants' War was the Battle on the Frankenberg?
New question: How many years after the Peasants' War of 1626 was the Battle on the Frankenberg?
---
Passage: In the United States, conscription began in 1917 and was generally well received, with a few
pockets of opposition in isolated rural areas. The administration decided to rely primarily on
conscription, rather than voluntary enlistment, to raise military manpower for when only 73,000
volunteers enlisted out of the initial 1 million target in the first six weeks of the war. In
1917 10 million men were registered. This was deemed to be inadequate, so age ranges were
increased and exemptions reduced, and so by the end of 1918 this increased to 24 million men
that were registered with nearly 3 million inducted into the military services. The draft was
universal and included blacks on the same terms as whites, although they served in different
units. In all 367,710 black Americans were drafted , compared to 2,442,586 white . Forms of
resistance ranged from peaceful protest to violent demonstrations and from humble
letter-writing campaigns asking for mercy to radical newspapers demanding reform. The most
common tactics were dodging and desertion, and many communities sheltered and defended their
draft dodgers as political heroes. Many socialists were jailed for \"obstructing the
recruitment or enlistment service\". The most famous was Eugene Debs, head of the Socialist
Party of America, who ran for president in 1920 from his prison cell. In 1917 a number of
radicals and anarchists challenged the new draft law in federal court, arguing that it was a
direct violation of the Thirteenth Amendment's prohibition against slavery and involuntary
servitude. The Supreme Court unanimously upheld the constitutionality of the draft act in the
Selective Draft Law Cases on January 7, 1918.
Old question: How many years after conscription began did Eugene Debs run for president?
New question: How many years after conscription began in the United States for World War I did Eugene
Debs run for president?
---
Figure16: Few-shotpromptfordecontextualizingDROP(history-continued)
32Given a Wikipedia passage and its title, rewrite the old question by integrating specific information
from the passage such that the events in the question are less ambiguous and the user can
answer the new question without reading the passage and using Google Search instead.
- For individuals that cannot be uniquely identified by their names, include small pieces of
information that help to narrow the individual down.
- Make sure that any new information added does not directly answer the question itself.
- Make sure that the new question asks for the same information as the old question in the passage.
- Leave the question as it is if it is already specific enough to solve on its own without the
passage.
- Do NOT mention "the passage" in the new question.
- Make sure that the new question requires multiple steps of reasoning to solve. For example, if the
question asks about the birth date of a person, do NOT include the actual name of the person
but other details of the person instead.
- Make sure that the new question is grammatical.
Below are a few examples of the generated output. Adhere to the format shown in the examples.
---
Title: Fredell Lack
Passage: Fredell Lack was born in Tulsa, Oklahoma, the oldest of three children of Jewish Eastern
European (Latvian) immigrants, Abram I. Lack and Sarah Stillman Lack (who was a sister of noted
painter Ary Stillman). She began violin lessons at age six, studying with Tosca Berger. When
Fredell was 10, she moved with her family to Houston, Texas. There she studied with Josephine
Boudreaux, the concertmaster of the Houston Symphony. At age 11, she first soloed with
orchestra, performing the Wieniawski Concerto No. 2 with the Tulsa Philharmonic. At 12, Lack
was accepted into the New York City studio of the legendary violinist and pedagogue Louis
Persinger, whose other students included such artists as Yehudi Menuhin, Isaac Stern, and
Ruggiero Ricci. She moved to New York and completed her pre-college schooling at the Bentley
School while continuing her violin lessons with Persinger. At 17, she made her professional
solo debut, playing the Mendelssohn Violin Concerto with the St. Louis Symphony. Subsequently
she received a full scholarship to the Juilliard School in New York. She continued studying
violin with Persinger there and also was deeply influenced by her study of chamber music with
Felix Salmond. She received the Diploma from Juilliard at age 21.
Question: What is the population of the city where Lack was born?
Rewrite: What is the population of the city where Fredell Lack was born?
---
Title: John Ford filmography
Passage: John Ford (1894\u20131973) was an American film director whose career spanned from 1913 to
1971. During this time he directed more than 140 films. Born in Maine, Ford entered the
filmmaking industry shortly after graduating from high school with the help of his older
brother, Francis Ford, who had established himself as a leading man and director for Universal
Studios. After working as an actor, assistant director, stuntman, and prop man \u2013 often for
his brother \u2013 Universal gave Ford the opportunity to direct in 1917. Initially working in
short films, he quickly moved into features, largely with Harry Carey as his star. In 1920 Ford
left Universal and began working for the Fox Film Corporation. During the next ten years he
directed more than 30 films, including the westerns The Iron Horse (1924) and 3 Bad Men (1926),
both starring George O'Brien, the war drama Four Sons and the Irish romantic drama Hangman's
House (both 1928 and both starring Victor McLaglen). In the same year of these last two films,
Ford directed his first all-talking film, the short Napoleon's Barber. The following year he
directed his first all-talking feature, The Black Watch.
Question: How old was Francis Ford when John Ford started his career in filmmaking?
Rewrite: How old was Francis Ford, John Ford's older brother, when John Ford started his career in
filmmaking?
---
Title: George Glossop Walker
Passage: Walker's debut match for Derbyshire in the 1881 season was against Yorkshire when he never
had the chance to bowl and scored 2 runs in each innings. He did not play again in that season
nor in the 1882 season, and only played in two games in the 1883 season. In the 1884 and 1885
season, when William Cropper lead the bowling, he played more frequently and in 1885 took
7\u2013105 against Nottinghamshire in one match and 5\u201387 in the other. In 1886 Walker was
selected for two Gentlemen of England teams, in one of which against Australia he was in the
team with his hero W.G. Grace. For the county he took 6\u201326 against Marylebone Cricket Club
(MCC), and 7\u201338 and 5\u201375 in the same match against Surrey. In the 1887 season Walker
took 5\u201354 for Derbyshire against Lancashire and 5\u201349 against Surrey. He continued
playing regularly for the Derbyshire club between 1888 and 1893 when it was without first-class
status. In 1894 took 7\u2013108 for Gentlemen against Players with W. G. Grace in the side
again although he never had the opportunity to bowl against him in any of his first-class
games. He also took 5\u201324 for Derbyshire against Lancashire. In the 1896 season he took
9\u201385 against Leicestershire although his average was deteriorating. He played four games
in the 1897 season and six in the 1898 season by which time his bowling made little impression,
while Billy Bestwick was beginning to star.
Question: How many total games did Walker play in during the 1884 and 1885 seasons?
Rewrite: How many total games did George Glossop Walker play in during the 1884 and 1885 seasons?
---
Title: 446th Operations Group
Passage: The group was occasionally diverted from strategic missions to carry out air support and
interdiction missions. It supported Operation Overlord, the invasion of Normandy by attacking
transportation targets, including bridges, along with airfields and strong points in France. On
D Day, the squadron and the rest of the 446th Group led the first heavy bomber mission of the
day. The 446th aided ground forces at Caen and Saint-L\u00f4 during July by hitting bridges,
gun batteries, and enemy troops. During Operation Market Garden, the attempt to seize a
bridgehead across the Rhine in the Netherlands, the 704th dropped supplies to allied troops
near Nijmegen. It struck lines of communications during the Battle of the Bulge. During
Operation Varsity in March 1945, it supplied ground and airborne troops near Wesel. The
squadron flew its last combat mission on 25 April 1945 against Salzburg, Austria. The group had
flown 273 missions and had lost 58 aircraft during the war,\n
Question: When did the operation during which the 704th dropped supplies to allied troops near
Nijmegen begin?
Rewrite: When did the operation during which the 704th dropped supplies to allied troops near
Nijmegen begin?
---
Figure17: Few-shotpromptfordecontextualizingIIRC
33Title: Heartbreak on a Full Moon
Passage: After selling 25,000 copies and earning 68,000 album-equivalent units within three days,
Heartbreak on a Full Moon debuted at number three on the US Billboard 200, becoming Brown's
ninth consecutive top 10 album on the chart. The album was Brown's seventh solo album to debut
at number one on the Billboard Top R&B/Hip-Hop Albums chart. On November 8, 2017, Heartbreak on
a Full Moon was certified gold by the Recording Industry Association of America for combined
sales and album-equivalent units of over 500,000 units in the United States (in this case,
250,000 double album sets, which are double-counted by the RIAA). Brown became the first R&B
male artist that went gold in a week since Usher's Confessions in 2004. In its second chart
week, the album remained at number three on Billboard 200, with 73,000 album-equivalent units.
In Australia, it entered the ARIA Albums Chart at number five, becoming his first top ten in
the nation since X in 2014. In the United Kingdom, the album debuted at number 10 on the UK
Albums Chart, Brown's sixth non-consecutive top 10 album on the chart. The album was eventually
certified Silver by the British Phonographic Industry (BPI) for sales of over 60,000 copies in
the UK. In New Zealand, the album debuted at number three on the RMNZ Albums Chart, giving
Brown his seventh top ten album on the chart. Until June 2018, the album has accumulated over
3\u00a0billion streams worldwide.
Question: When was the company that certified the song's \"gold\" status founded?
Rewrite: When was the company that certified the \"gold\" status of Heartbreak on a Full Moon founded?
---
Title: Rail transport in Israel
Passage: Rail infrastructure in what is now Israel was first envisioned and realized during the
Ottoman period. Sir Moses Montefiore, in 1839, was an early proponent of trains in the land of
Israel. However, the first railroad in Eretz Yisrael, was the Jaffa-Jerusalem railway, which
opened on September 26, 1892. A trip along the line took 3 hours and 30 minutes. The line was
initiated by the Jewish entrepreneur Joseph Navon and built by the French at 1\u00a0m gauge.
The second line in what is now Israel was the Jezreel Valley railway from Haifa to Beit
She\u2019an, which had been built in 1904 as part of the Haifa-Daraa branch, a 1905-built
feeder line of the Hejaz Railway which ran from Medina to Damascus. At the time, the Ottoman
Empire ruled the Levant, but was a declining power and would succumb in World War I. During the
Ottoman era, the network grew: Nablus, Kalkiliya, and Beersheba all gained train stations. The
First World War brought yet another rail line: the Ottomans, with German assistance, laid
tracks from Beersheba to Kadesh Barnea, somewhere on the Sinai Peninsula. (This line ran
through trains from Afula through Tulkarm.) This resulted in the construction of the eastern
and southern railways.
Question: Was the first railroad line in Israel longer than the second line?
Rewrite: Was the first railroad line in Israel longer than the second railroad line in Israel?
---
Title: List of Indianapolis Colts starting quarterbacks
Passage: In 1998 the Colts, for the 4th time in 15 years, held the 1st overall pick in the draft and
for the 3rd time in 15 years selected a quarterback \u2013 this time University of Tennessee's
Peyton Manning. Manning started the first game of his rookie season and started every single
Colts game since until the start of the 2011 season, when a recurring neck injury sidelined
him. Despite a difficult rookie season, where he threw a league high 28 interceptions, Manning
and the Colts responded by finishing 13\u20133 in 1999. The 10 game turnaround from the
previous year set an NFL record. Even with this turnaround, the Colts lost in the playoffs. The
following years would be marked by a near constant pattern. The Colts and Manning successes in
the regular season were matched only by their failures in the post season. Manning was named to
the Pro Bowl in 1999, 2000, 2002, 2003 and 2004, as well as winning the NFL MVP award in both
2003 and 2004. In 2004 Manning set a then NFL record when he threw 49 touchdowns in a single
season. In spite of this the team failed in the playoffs, including early round exits in 1999,
2000, 2002 and 2005. In both 2003 and 2004 the Colts would lose to eventual Super Bowl winning
New England Patriots in the AFC Championship Game and the Divisional Round respectively. In
2006 the Colts and Manning were finally able to beat the Patriots and their quarterback Tom
Brady in the AFC Championship Game on their way to a victory in Super Bowl XLI against the
Chicago Bears. Manning was named the Super Bowl MVP. The Colts and Manning would continue to
have success, with Manning winning two further MVP awards in 2008 and 2009. In 2009 the Colts
would return to the Super Bowl where they would lose to the New Orleans Saints.
Question: Who was the head coach of the team that the Colts lost to in the 2009 Superbowl?
Rewrite: Who was the head coach of the team that the Colts lost to in the 2009 Superbowl?
---
Title: 2008 Arizona Cardinals season
Passage: The 2008 Arizona Cardinals season was the 89th season for the team in the National Football
League and their 21st season in Arizona. The season marked the Cardinals' first Super Bowl
appearance, coming as a result of their victory against the Philadelphia Eagles in the NFC
Championship. The Cardinals slogan for the season was \"Shock The World!\" Riding the back of
quarterback Kurt Warner, who had gone from being a backup for the St. Louis Rams in 1999 to
leading the Greatest Show on Turf to a Super Bowl XXXIV victory, and franchise wide receiver
Larry Fitzgerald, the Cardinals went on a playoff run for the ages after having won just one
playoff game in the last sixty years, as Warner once again recreated the magic he had captured
with the Rams. (Coincidentally, both teams were based in St Louis at one point or another, only
to relocate to different cities.)
Question: How many Super Bowls did the team the Cardinals beat to make their first appearance in the
Super Bowl win?
Rewrite: How many Super Bowls did the team the Arizona Cardinals beat in the 2008 season to make
their first appearance in the Super Bowl win?
---
Figure18: Few-shotpromptfordecontextualizingIIRC(continued)
34F.2 Examples
Weprovideexamplesofquestionre-writeswhichresultinDROP*andIIRC*.
Passage: Hoping to rebound from their loss to the Patriots, the Raiders stayed at home for a Week 16
duel with the Houston Texans. Oakland would get the early lead in the first quarter as
quarterback JaMarcus Russell completed a 20-yard touchdown pass to rookie wide receiver Chaz
Schilens. The Texans would respond with fullback Vonta Leach getting a 1-yard touchdown run,
yet the Raiders would answer with kicker Sebastian Janikowski getting a 33-yard and a 30-yard
field goal. Houston would tie the game in the second quarter with kicker Kris Brown getting a
53-yard and a 24-yard field goal. Oakland would take the lead in the third quarter with wide
receiver Johnnie Lee Higgins catching a 29-yard touchdown pass from Russell, followed up by an
80-yard punt return for a touchdown. The Texans tried to rally in the fourth quarter as Brown
nailed a 40-yard field goal, yet the Raiders' defense would shut down any possible attempt.
old_question: Who scored the first touchdown of the game?
new_question: Who scored the first touchdown of the game between the Oakland Raiders and the Houston
Texans where Sebastian Janikowski got a 33-yard and a 30-yard field goal?
Figure19: Examplequestionre-writefromDROP(sports)
Passage: In 1905, 1,003 Korean immigrants, which included 802 men and 231 women and children,
departed from the port of Chemulpo, Incheon aboard the ship Ilford to Salina Cruz, Oaxaca,
Mexico. The journey took 45 days, after which they took a train to Coatzacoalcos, Veracruz. In
the Veracruz port, another boat was taken to the port of Progreso with the final destination
being the capital city of M\u00e9rida, Yucatan. They arrived in May 1905, with previously
signed contracts for four years' work as indentured laborers on the Yucat\u00e1n henequen
haciendas. Many of these Koreans were distributed throughout the Yucat\u00e1n in 32 henequen
haciendas. The town of Motul, Yucatan, located in the heart of the henequen zone, was a
destination for many of the Korean immigrants. Subsequently, in 1909, at the end of their
contracts, they began a new stage in which they scattered even further Thus, the majority of
those who came were single men who made or remade their family lives with Yucatecan especially
Maya women. While Korean girls were much more subject to marriages arranged by Korean parents,
males had greater freedom when it came to making a family. This rapid intermarriage by Koreans,
coupled with geographic dispersal, prevented the establishment of close social networks among
these migrants and therefore provided the basis for Korean descendants among the Yucatan
Peninsula. After that 1905 ship, no further entries of Koreans into Mexico were recorded, until
many years later, leading to a new community of Koreans with completely different
characteristics from those who entered in 1905. These descendants have started the Museo
Conmemorativo de la Inmigraci\u00f3n Coreana a Yucat\u00e1n, a museum for the remembrance of
their ancestors journey.
old question: How many years did the immigrants have to work as indentured laborers?
new_question: How many years did the Korean immigrants have to work as indentured laborers on the
Yucat\u00e1n henequen haciendas after arriving in 1905?
Figure20: Examplequestionre-writefromDROP(history)
Title: 1965 New Zealand Grand Prix
Passage: It was the 12th New Zealand Grand Prix, doubled as the opening round of the 1965 Tasman
Series. The race attracted 19 starters, including several overseas based drivers and teams. A
large contingent of cars from Australia competed, including Frank Gardner competing for Alec
Mildren Racing. Lex Davison and Leo Geoghegan brought across their own teams, while 1962
Formula One world champion, British racer Graham Hill race a Brabham for David McKay's Scuderia
Veloce team. Star attraction though was the appearance of Team Lotus with their lead driver,
1963 World Champion, Jim Clark. Local honour was upheld by Bruce McLaren, who in an early
iteration of the later McLaren team brought a pair of factory supported Coopers to race with
American racer, the 1961 World Champion Phil Hill as his number two. The race was won by Graham
Hill, his first victory in the NZGP. Gardner finished second to be the first 'antipodean' while
first New Zealander was domestic series racer Jim Palmer in a career highlight as Brabham
racing cars clean swept the podium.
old question: How many more wins did the 1961 World Champion have than the 1963 world champion?
new_question: How many more wins did the 1961 World Champion have than the 1963 World Champion in the
1965 New Zealand Grand Prix?
Figure21: Examplequestionre-writefromIIRC
35topic subtopics
price house,car,marketvalue(soccerplayer),networth(football/basketball/baseballplayer)
population country,state,city,college,company
economics GDP(country),revenue(company),income(household)
buildings stadium(capacity),skyscraper(height),skyscraper(numberoffloors),bridges(length)
geography country(area),state(area),river(length),lake(area),sea(area)
sports soccer(goals),football(touchdowns),basketball(points),baseball(homeruns)
history foundingyear(country)
politics numberofsenators(country)
animals numberoflegs,lifespan
books numberofchapters,numberofpages
instruments numberofstrings/keyboards/holes
astronomy planet(numberofmoons)
chemistry meltingpoint(solid),boilingpoint(liquid),atomicnumber
biology humananatomy(numberofX’s)
law maximumsentence(federallaw)
Table9: Listofseedtopicsandsub-topicsforHUSKYQA.
G HUSKYQA
G.1 DatasetConstruction
Weconstruct HUSKYQA fromamanuallycuratedlistof40topicsasshowninTable9. Wefirst
generate10factoidquestionsforeachtopic-subtopicpairinTable9usinggpt-3.5-turbo-0125.
Figure22showsourfew-shotpromptforobtainingtheseedquestions.
Next,weuseSERPAPItoobtaintheanswertoeachfactoidquestion,similarlytohowweuseSERP
APIinAppendixB.2. Wethenusethefew-shotpromptprovidedinFigure23togenerateafactoid
statementforeach(question,answer)pairinHUSKYQA.
Finally,wegeneratecomplexnumericalreasoningquestionsfrompairsoffactoidstatementswithin
thesame(topic,subtopic)category. Weusealluniquepairsofthe10factoidstatementswithineach
category,resultingin45candidatefinalquestionsfromeachcategoryandatotalof1,800questions
acrossallcategories. WeusethepromptprovidedinFigure24togeneratethefinalquestions.
Thefinalquestionsaregeneratedsuchthattheanswerwithineachfactoidstatementisnotprovided
inthefinalquestionandmustbedeterminedseparatelybeforesolvingthefinalquestion. Asaresult,
ourfinalquestionscontainpiecesofmissinginformationthatmustfirstbeidentifiedbytheagent,and
thenmustbeintegratedinnumericalreasoningfortheagenttosolvethefinalquestionssuccessfully.
Wesplitthetrainandtestsetbytopics. Ourtestsetincludesatotalof8topics–population(country),
economics (revenue - company), buildings (skyscraper - height), geography (state - area), sports
(soccer-goals),politics(numberofsenators-country),books(numberofchapters)andchemistry
(meltingpoint-solid). Bysplittingthedatasetacrossseparatetopics,weensurethattheanymodel
oragenttrainedonthedatasethasnotseeninformationrelatedtotopicsintheevaluationsetandis
forcedtogeneralizetotopicsoutsideofitstrainingset.
Wecollectatotalof1,350questionsforthetrainsetwhichisonlyusedtoprovideexamplesforthe
actiongenerator(seeTable7)upongeneratingthesolutiontrajectory,and450questionsforthetest
set. Afterfilteringthequestionsinthetestsetwithhumanannotatorscheckingthesoundnessofthe
questionaswellaslabelingthecorrectanswertoeachquestion,wehave292questionsremaining.
G.2 Examples
WeprovideexamplesintheHUSKYQAevaluationsetinTable10.
36Given a topic, generate a list of 10 related factual questions that result in numerical answers. The
questions should be of the same topic but should not be the exact same questions. Make sure
that the units are the same for the answers to the questions.
Below are a few examples of the generated output. Adhere to the format shown in the examples.
---
Topic: geography (state - area)
Questions
Q1: What is the area of California in square miles?
Q2: What is the area of Texas in square miles?
Q3: What is the area of New York in square miles?
Q4: What is the area of Florida in square miles?
Q5: What is the area of Washington in square miles?
Q6: What is the area of Arizona in square miles?
Q7: What is the area of Wyoming in square miles?
Q8: What is the area of Colorado in square miles?
Q9: What is the area of Pennsylvania in square miles?
Q10: What is the area of Ohio in square miles?
---
Topic: price (car)
Questions
Q1: What is the MSRP of the 2024 Hyundai Kona in U.S. dollars?
Q2: What is the MSRP of the 2024 Toyota Camry in U.S. dollars?
Q3: What is the MSRP of the 2024 Honda Accord in U.S. dollars?
Q4: What is the MSRP of the 2024 Chevrolet Trax in U.S. dollars?
Q5: What is the MSRP of the 2024 Lucid Air in U.S. dollars?
Q6: What is the MSRP of the 2024 Hyundai Sonata in U.S. dollars?
Q7: What is the MSRP of the 2024 Kia Seltos in U.S. dollars?
Q8: What is the MSRP of the 2024 Honda Ridgeline in U.S. dollars?
Q9: What is the MSRP of the 2024 Kia Telluride in U.S. dollars?
Q10: What is the MSRP of the 2024 Ford F-150 in U.S. dollars?
---
Topic: sports (soccer)
Questions
Q1: How many goals did Kylian Mbappe score in Ligue 1 during the 2023-2024 season?
Q2: How many goals did Erling Haaland score in the Premier League during the 2022-2023 season?
Q3: How many goals did Kevin De Bruyne score in the Premier League during the 2022-2023 season?
Q4: How many goals did Harry Kane score in Bundesliga during the 2023-2024 season?
Q5: How many goals did Son Heung-min score in the Premier League during the 2023-2024 season?
Q6: How many goals did Vinicius Jr. score in La Liga during the 2023-2024 season?
Q7: How many goals did Leroy Sane score in Bundesliga during the 2022-2023 season?
Q8: How many goals did Jude Bellingham score in La Liga during the 2023-2024 season?
Q9: How many goals did Florian Wirtz score in Bundesliga during the 2023-2024 season?
Q10: How many goals did Cole Palmer score in the Premier League during the 2023-2024 season?
---
Topic: price (house)
Questions
Q1: What is the median house price in New York in 2024?
Q2: What is the median house price in California in 2024?
Q3: What is the median house price in Texas in 2024?
Q4: What is the median house price in Florida in 2024?
Q5: What is the median house price in Georgia in 2024?
Q6: What is the median house price in Massachusetts in 2024?
Q7: What is the median house price in Pennsylvania in 2024?
Q8: What is the median house price in Washington in 2024?
Q9: What is the median house price in Illinois in 2024?
Q10: What is the median house price in Colorado in 2024?
---
Figure22: Few-shotpromptforgeneratingseedquestionsforHUSKYQA
Given a factual question and the corresponding answer, rewrite the answer into a complete sentence.
Below are a few examples of the generated output. Adhere to the format shown in the examples.
---
Question: What is the area of Texas in square miles?
Answer: 268,597 square miles
Rewrite: The area of Texas is 268,597 square miles.
---
Question: What is the MSRP of the 2024 Hyundai Kona in U.S. dollars?
Answer: $24,250
Rewrite: The MSRP of the 2024 Hyundai Kona in U.S. dollars is $24,250.
---
Question: How many goals did Kylian Mbappe score in Ligue 1 during the 2023-2024 season?
Answer: 26 goals
Rewrite: Kylian Mbappe scored 26 goals in Ligue 1 during the 2023-2024 season.
---
Question: What is the median house price in New York in 2024 in U.S. dollars?
Answer: $785,000
Rewrite: The median house price in New York in 2024 in U.S. dollars is $785,000.
---
Figure23: Few-shotpromptforgeneratingfactoidstatementsforHUSKYQA
37Given two pieces of factual statements, create a math question of moderate difficulty (at the level
of middle school or high school math) that integrates the numbers from each statement.
Below are a few examples of the generated output. Adhere to the format shown in the examples.
---
Fact 1: The median value of a home in the United States in 2000 was $119,600.
Fact 2: The median value of a home in the United States in 2020 was $452,400.
Question: Joe bought a house in the year 2000 at the median price of the United States that year.
Then, he sold the house at the median price in 2020. How much did the price of the house
increase over this period on average per year?
---
Fact 1: George Washington was born in 1732.
Fact 2: Abraham Lincoln was born in 1809.
Question: How many years between the year George Washington was born and the year Abraham Lincoln was
born are multiples of 4?
---
Fact 1: The Camp Nou has a capacity of 99,354.
Fact 2: The Santiago Bernabeu has a capacity of 81,044.
Question: FC Barcelona decides to allocate 85,000 seats for its home fans during its soccer match
against Real Madrid, leaving the rest of the seats for the away fans. Real Madrid agrees to
allocate the same number of away seats during its home match against FC Barcelona at the
Santiago Bernabeu. How many seats are available in the Santiago Bernabeu for the home fans?
---
Fact 1: New York City had a population of 8.336 million as of 2022.
Fact 2: New York City had a population of 8.042 million as of 2002.
Question: If New York City grew by equal numbers of people between the years 2002 and 2022, what
would have been its population in 2006?
---
Figure24: Few-shotpromptforgeneratingfinalquestionsforHUSKYQA
topic subtopic Question
price market value - AsoccerteamwantstopurchasebothLionelMessiandKevinDeBruyne. Iftheyalreadyhave
soccerplayer 20,000,000eurosandcansave15,000,000euroseveryyear,howmanyyearswillittakeforthemto
haveenoughmoneytobuybothplayers?
population country Ifaplanecancarry300passengersandistaskedwithtransporting1percentofthedifferencebetween
thepopulationsofIndonesiaandBrazilin2022toaglobalconference,howmanyflightswillittaketo
transportallthesepassengers?
economics revenue (com- IfAmazondecidedtoinvestanamountequaltoTesla’stotalrevenuein2021intonewprojects,what
pany) percentageofAmazon’stotalrevenuefor2021wouldthisinvestmentrepresent?
buildings skyscraper IfamodeloftheWillisTowerismadeatascaleof1:100andamodeloftheOneWorldTradeCenter
(height) ismadeatthesamescale,byhowmanyfeetisthemodeloftheOneWorldTradeCentertallerthanthe
modeloftheWillisTower?
buildings stadium (capac- IfafootballmatchbetweentheDallasCowboysandaninternationalteamwasorganizedwherethey
ity) decidedtosplitthecapacityevenlybetweenhomeandawayfansintheAT&TStadium,andthena
rematchwasscheduledattheAllianzArenawiththesameticketallocationpolicy,howmanyfewer
seatswouldbeavailableforeachteam’sfansintheAllianzArenacomparedtotheAT&TStadium?
sports soccer(goals) IfKylianMbappeandErlingHaalandcontinuetoscoreattheir2022-2023seasonratesforthenext3
seasons,howmanymoregoalswillHaalandhavescoredthanMbappeafterthese3seasons?
politics number of sena- Ifaconferenceisbeingheldwhereonly40percentofUnitedStatessenatorsand25percentofMexican
tors(country) senatorsareinvited,howmanysenatorsintotalwillattendtheconference?
books numberofchap- IfabookclubdecidestoreadP¨rideandPrejudiceänd1¨984b¨acktoback,dedicating3daystodiscuss
ters eachchapterofP¨rideandPrejudiceänd4daystodiscusseachchapterof1¨984¨,howmanytotaldays
willthebookclubspendonbothbooks?
chemistry melting point Ablacksmithdecidestocreateanalloyconsistingof60percentironand40percentcopperbymass.
(solid) Ifthemeltingpointofthealloyisdirectlyproportionaltothemeltingpointsoftheindividualmetals
basedontheirpercentagesinthealloy,whatisthemeltingpointofthealloy?",Findthemeltingpoint
ofironindegreesCelsius.
geography state(area) IfamapdesignerwantstocreateasinglepageinanatlaswithbothCaliforniaandNewYorkatthe
samescale,andthepagehasanareaof310squareinches,howmanysquareinchesofthepagewould
NewYorktakeupifCaliforniatakesupitsproportionalshare?
Table10: ExamplequestionsinHUSKYQA.
38H TrainingDataExamples
H.1 ActionGenerator
WeprovideexamplesofthetrainingdatafortheactiongeneratorinFigures25and26.
Prompt
Given the input question and the solution history that consists of steps for solving the input
question and their corresponding outputs, decide whether the solution history has already
solved the original question. If the original question has not been solved yet, assign a tool
(either [math], [code], [search] or [commonsense]) and generate the next step that needs to be
answered to solve the original question. Do not generate a step that has already been written
in the solution history. Otherwise, if the original question has already been solved, return
the [finish] tool, along with the final answer to the original question based on the solution
history.
- [math] is for: 1) solving math questions, writing or re-organizing equations, performing abstract
reasoning such as case-by-case analysis, or identifying the conditions given in the question.
- [code] is for: 1) computing large numbers (at least 100), fractions or decimals. 2) counting or
averaging long lists of numbers. 3) performing date-related operations, such as counting the
number of days between two dates.
- [search] is for: retrieving specific knowledge from the Web to answer questions related to history,
sports, culture, geography, medicine, science, etc.
- [commonsense] is for: applying commonsense knowledge to reason about a relatively simple step, such
as comparing two numbers or recalling a widely-known fact.
- [finish] is for: indicating that the question has been solved, and it is followed by the answer to
the question.
---
Question: A triangle in a Cartesian coordinate plane has vertices (5, -2), (10, 5) and (5, 5). How
many square units are in the area of the triangle? Express your answer as a decimal to the
nearest tenth.
Solution history:
Step: Calculate the base and height of the triangle.
Output: The base of the triangle is 5 units, and the height is 7 units.
Next step or final answer:
Completion
[math] Calculate the area of the triangle using the base and height.
Figure25: Exampletrainingdatafortheactiongenerator(math)
Prompt
Given the input question and the solution history that consists of steps for solving the input
question and their corresponding outputs, decide whether the solution history has already
solved the original question. If the original question has not been solved yet, assign a tool
(either [math], [code], [search] or [commonsense]) and generate the next step that needs to be
answered to solve the original question. Do not generate a step that has already been written
in the solution history. Otherwise, if the original question has already been solved, return
the [finish] tool, along with the final answer to the original question based on the solution
history.
- [math] is for: 1) solving math questions, writing or re-organizing equations, performing abstract
reasoning such as case-by-case analysis, or identifying the conditions given in the question.
- [code] is for: 1) computing large numbers (at least 100), fractions or decimals. 2) counting or
averaging long lists of numbers. 3) performing date-related operations, such as counting the
number of days between two dates.
- [search] is for: retrieving specific knowledge from the Web to answer questions related to history,
sports, culture, geography, medicine, science, etc.
- [commonsense] is for: applying commonsense knowledge to reason about a relatively simple step, such
as comparing two numbers or recalling a widely-known fact.
- [finish] is for: indicating that the question has been solved, and it is followed by the answer to
the question.
---
Question: How many world championships have been won by the team that the Reds outscored 22-8 in the
1976 World Series?
Solution history:
Step: Identify the team that the Reds outscored 22-8 in the 1976 World Series.
Output: The team that the Reds outscored 22-8 in the 1976 World Series is the New York Yankees.
Next step or final answer:
Completion
[search] Find the number of World Championships won by the New York Yankees.
Figure26: Exampletrainingdatafortheactiongenerator(knowledge)
39H.2 CodeGenerator
WeprovideexamplesofthetrainingdataforthecodegeneratorinFigures27and28.
Prompt
Given the input question, the solution history that consists of steps for solving the input question
and their corresponding outputs, and the current step that must be addressed to solve the input
question, write code that solves the current step.
- Write the code in Python.
- Do not attempt to write code that directly answers the question. Write code that answers the given
step.
- For math questions, utilize the 'pi' symbol and 'Rational' from the sympy package for $\\pi$ and
fractions, and simplify all fractions and square roots without converting them to decimal
values.
- Example imports are provided below. Import any of these packages, as well as additional packages as
needed.
```imports omitted```
---
Question: Al, Betty, and Clare split $\\$1000$ among them to be invested in different ways. Each
begins with a different amount. At the end of one year they have a total of $\\$1500$. Betty
and Clare have both doubled their money, whereas Al has managed to lose $\\$100$. What was Al's
original portion?
Solution history:
Step: Write equations based on the given information, using $A$ to represent Al's original portion,
$B$ to represent Betty's original portion, and $C$ to represent Clare's original portion.
Output: The total initial amount is $A + B + C = 1000$. After one year, the total amount is $A - 100
+ 2B + 2C = 1500$. Betty and Clare have both doubled their money, whereas Al has lost $100.
\\boxed{A + B + C = 1000, A - 100 + 2B + 2C = 1500}$
Current step: Solve the system of equations to find Al's original portion.
Code:
Completion
from sympy import symbols, Eq, solve
A, B, C = symbols('A B C')
eq1 = Eq(A + B + C, 1000)
eq2 = Eq(A - 100 + 2*B + 2*C, 1500)
solution = solve((eq1, eq2), (A, B, C))
out = solution[A]
print(out)
Figure27: Exampletrainingdataforthecodegenerator(math)
Prompt
Given the input question, the solution history that consists of steps for solving the input question
and their corresponding outputs, and the current step that must be addressed to solve the input
question, write code that solves the current step.
- Write the code in Python.
- Do not attempt to write code that directly answers the question. Write code that answers the given
step.
- For math questions, utilize the 'pi' symbol and 'Rational' from the sympy package for $\\pi$ and
fractions, and simplify all fractions and square roots without converting them to decimal
values.
- Example imports are provided below. Import any of these packages, as well as additional packages as
needed.
```imports omitted```
---
Question: How many months did the Anglo-French offensive of the Battle of the Somme in 1916 last?
Solution history:
Step: Find the start and end dates of the Anglo-French offensive of the Battle of the Somme in 1916.
Output: The Anglo-French offensive of the Battle of the Somme in 1916 started on July 1 and ended on
November 18, 1916.
Current step: Calculate the number of months that elapsed between July 1, 1916, and November 18, 1916.
Code:
Completion
from datetime import datetime
# define the start and end dates
start_date = datetime(1916, 7, 1)
end_date = datetime(1916, 11, 18)
# calculate the difference in months
total_months = (end_date.year - start_date.year) * 12 + end_date.month - start_date.month
print(total_months)
Figure28: Exampletrainingdataforthecodegenerator(knowledge)
40H.3 MathReasoner
WeprovideanexampleofthetrainingdataforthemathreasonerinFigure29.
Prompt
Given the original question, the solution history that consists of steps for solving the input
question and their corresponding outputs, and the current step that must be addressed to solve
the input question, answer the current step by reasoning step-by-step.
- Make sure to answer the subquestion and not the original question.
- Do not attempt to directly answer the original question unless the subquestion asks for the same
thing as the original question.
- Present the answer \"ANS\" to the subquestion in LaTeX using the format 'The answer is
\\boxed{ANS}.' without any units in the box.
---
Question: Simplify
$\\left(\\dfrac{-1+i\\sqrt{3}}{2}\\right)^6+\\left(\\dfrac{-1-i\\sqrt{3}}{2}\\right)^6.$
Solution history:
None
Current step: Recognize that the expressions are complex conjugates and use De Moivre's theorem to
simplify the expression.
Solution:
Completion
The given expressions $\\left(\\dfrac{-1+i\\sqrt{3}}{2}\\right)^6$ and
$\\left(\\dfrac{-1-i\\sqrt{3}}{2}\\right)^6$ are indeed complex conjugates of each other. The
complex number $\\dfrac{-1+i\\sqrt{3}}{2}$ can be recognized as the polar form $re^{i\\theta}$
where $r=\\sqrt{\\left(\\frac{-1}{2}\\right)^2+\\left(\\frac{\\sqrt{3}}{2}\\right)^2}=1$ and
$\\theta=\\frac{2\\pi}{3}$, since it corresponds to the cosine and sine of $\\frac{2\\pi}{3}$
in the complex plane.
By De Moivre's theorem, $(re^{i\\theta})^n = r^n e^{in\\theta}$. Since $r=1$, $r^n=1^n=1$ for any
integer $n$. Therefore, we can simplify the expressions as follows:
1. $\\left(\\dfrac{-1+i\\sqrt{3}}{2}\\right)^6 = e^{i\\cdot 6 \\cdot \\frac{2\\pi}{3}} = e^{i4\\pi} =
\\cos(4\\pi) + i\\sin(4\\pi) = 1 + i\\cdot 0 = 1$.
2. Similarly, the complex conjugate $\\left(\\dfrac{-1-i\\sqrt{3}}{2}\\right)^6$ can be seen as
having an angle of $-\\frac{2\\pi}{3}$ (or equivalently, $2\\pi - \\frac{2\\pi}{3} =
\\frac{4\\pi}{3}$ when considering positive angles in the standard form). Therefore, it
simplifies to $e^{i\\cdot 6 \\cdot (-\\frac{2\\pi}{3})} = e^{i\\cdot 6 \\cdot \\frac{4\\pi}{3}}
= e^{i4\\pi} = \\cos(4\\pi) + i\\sin(4\\pi) = 1 + i\\cdot 0 = 1$.
Adding these two results together, we get $1 + 1 = 2$.
The answer is $\\boxed{2}$.
Figure29: Exampletrainingdataforthemathreasoner
H.4 QueryGenerator
WeprovideanexampleofthetrainingdataforthequerygeneratorinFigure30.
Prompt
Given the input question, the solution history that consists of steps for solving the input question
and their corresponding outputs, and the current step that needs to be taken to solve the
question, write a concise, informative Google Search query for obtaining information regarding
the current step.
---
Question: In which county is the school where Matt Langel worked with Dunphy in 2006?
Solution history:
Step: Identify the school where Matt Langel worked with Dunphy in 2006.
Output: The school where Matt Langel worked with Dunphy in 2006 is the University of Pennsylvania.
Current step: Determine in which county the University of Pennsylvania is located.
Completion
University of Pennsylvania located in which county
Figure30: Exampletrainingdataforthequerygenerator
41I HUSKY InferenceExamples
WeprovideexamplesofHUSKYinferenceinFigures31,32,33and34.
I.1 NumericalReasoning
Question: Find the sum of all integers that satisfy these conditions: \\[\n|x|+1>7\\text{ and
}|x+1|\\le7.\n\\]
Solution:
Step 1: [math] Translate the given inequalities into mathematical expressions that can be solved.
1. For the first inequality, $|x| + 1 > 7$, we subtract 1 from both sides to get $|x| > 6$. This
means that the absolute value of $x$ must be greater than 6. In terms of real numbers, this
translates to $x > 6$ or $x < -6$.
2. For the second inequality, $|x + 1| \\le 7$, we consider the definition of absolute value, which
states that $|x + 1| \\le 7$ means that $-7 \\le x + 1 \\le 7$. Subtracting 1 from all parts of
the inequality gives $-8 \\le x \\le 6$.
Combining these two sets of conditions, we find that $x$ must satisfy both $x > 6$ and $-8 \\le x
\\le 6$. The intersection of these conditions is $-8 \\le x \\le 6$, which means $x$ can range
from -8 to 6, inclusive.
Therefore, the answer is $\\boxed{-8 \\le x \\le 6}$.
Step 2: [math] Identify the integers that satisfy the given conditions.
The conditions given are $-8 \\le x \\le 6$. This means that $x$ can be any integer from -8 up to 6,
inclusive.
To list all the integers that satisfy these conditions, we start from the smallest integer that is
greater than -8, which is -8 itself, and go up to the largest integer that is less than or
equal to 6, which is 6.
Therefore, the integers that satisfy the given conditions are $\\boxed{-8, -7, -6, -5, -4, -3, -2,
-1, 0, 1, 2, 3, 4, 5, 6}$.
Step 3: [code] Compute the sum of all integers that satisfy the conditions.
```python
integer_list = [-8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6]
out = sum(integer_list)
print(out)
```
The sum of all integers that satisfy the given conditions is -15.
The answer is: -15.
Figure31: ExampleHUSKYsolution(numerical,MATH)
I.2 TabularReasoning
Question: undesignated hedges was $ 41.2 million and $ 42.1 million , respectively . the fair value of
these hedging instruments in the company 2019s consolidated balance sheets as of october 29 ,
2011 and october 30 , 2010 was immaterial . interest rate exposure management 2014 on june 30 ,
2009 , the company entered into interest rate swap transactions related to its outstanding 5.0%
( 5.0 % ) senior unsecured notes where the company swapped the notional amount of its $ 375
million of fixed rate debt at 5.0% ( 5.0 % ) into floating interest rate debt through july 1 ,
2014 . ... (omitted) ... the total notional amounts of derivative instruments designated as
hedging instruments as of october 29 , 2011 and october 30 , 2010 were $ 375 million of
interest rate swap agreements accounted for as fair value hedges and $ 153.7 million and $
139.9 million , respectively , of cash flow hedges denominated in euros , british pounds and
analog devices , inc . notes to consolidated financial statements 2014 ( continued ) .
['statement of income classification', 'statement of income loss on swaps', 'statement of income gain
on note', 'statement of income net income effect', 'statement of income gain on swaps', 'loss
on note', 'net income effect']
['other income', '$ -4614 ( 4614 )', '$ 4614', '$ 2014', '$ 20692', '$ -20692 ( 20692 )', '$ 2014']
what is the percentage change in cash flow hedges in 2011 compare to the 2010?
Solution:
Step 1: [commonsense] Identify the notional amounts of cash flow hedges for 2011 and 2010.
The notional amounts of cash flow hedges for 2011 and 2010 are $153.7 million and $139.9 million,
respectively.
Step 2: [code] Calculate the percentage change in cash flow hedges from 2010 to 2011.
```python
cash_flow_hedges_2010 = 139.9
cash_flow_hedges_2011 = 153.7
percentage_change = ((cash_flow_hedges_2011 - cash_flow_hedges_2010) / cash_flow_hedges_2010) * 100
# print the output
print(percentage_change)
```
The percentage change in cash flow hedges from 2010 to 2011 is 9.8642.
The answer is: 9.8642 percent.
Figure32: ExampleHUSKYsolution(tabular,FinQA)
42I.3 Knowledge-basedReasoning
Question: When was the company that built the first steam locomotive to carry passengers on a public
rail line founded?
Solution:
Step 1: [search] Identify the company that built the first steam locomotive to carry passengers on a
public rail line.
```google
company that built the first steam locomotive to carry passengers on a public rail line
```
The first steam locomotive to carry passengers on a public rail line was built by Robert Stephenson
and Company.
Step 2: [search] Find when Robert Stephenson and Company was founded.
```google
when was Robert Stephenson and Company founded
```
Robert Stephenson and Company was founded in 1823.
The answer is: 1823.
Figure33: ExampleHUSKYsolution(knowledge,Bamboogle)
I.4 MixedReasoning
Question: A scientist has a 10 kg block of aluminum and decides to melt it down to create a mixture
with zinc, aiming for the final mixture to have a melting point exactly halfway between the
melting points of pure aluminum and pure zinc. What weight of zinc (in kg) must the scientist
add to the aluminum to achieve this goal, assuming the melting point of the mixture can be
linearly interpolated between the melting points of pure aluminum and zinc?
(Note: This question simplifies the complexities of alloy formation and assumes the melting point
between mixtures of aluminum and zinc can be linearly interpolated based on their proportions
by weight.)
Solution:
Step 1: [search] Find the melting point of aluminum in Celsius.
```google
aluminum melting point
```
The melting point of aluminum is 660 degrees Celsius.
Step 2: [search] Find the melting point of zinc in Celsius.
```google
zinc melting point
```
The melting point of zinc is 419.5 degrees Celsius.
Step 3: [math] Compute the desired melting point of the mixture.
To find the desired melting point of the mixture, we need to find the midpoint between the melting
points of pure aluminum and pure zinc. The melting point of aluminum is 660 degrees Celsius,
and the melting point of zinc is 419.5 degrees Celsius.
The midpoint between two numbers can be found by adding the two numbers together and dividing by 2.
Therefore, the desired melting point of the mixture is:
\\[\\frac{660 + 419.5}{2} = \\frac{1079.5}{2} = 539.75\\]
Thus, the desired melting point of the mixture is $\\boxed{539.75}$ degrees Celsius.
Step 4: [math] Determine the proportion of zinc required to achieve the desired melting point.
To determine the proportion of zinc required to achieve the desired melting point, we can use the
concept of weighted averages. The formula for weighted averages is given by:
\\[\\text{Average} = \\frac{w_1 \\cdot x_1 + w_2 \\cdot x_2}{w_1 + w_2}\\]
where $w_1$ and $w_2$ are the weights of the two substances, and $x_1$ and $x_2$ are their respective
values (in this case, melting points). We want the average melting point of the mixture to be
539.75 degrees Celsius, and we know the melting points of aluminum and zinc are 660 and 419.5
degrees Celsius, respectively. Let $w_1$ be the weight of aluminum (10 kg) and $w_2$ be the
weight of zinc to be added. We can set up the equation:
\\[539.75 = \\frac{10 \\cdot 660 + w_2 \\cdot 419.5}{10 + w_2}\\]
Solving for $w_2$, we get:
\\[539.75(10 + w_2) = 6600 + 419.5w_2\\]
\\[5397.5 + 539.75w_2 = 6600 + 419.5w_2\\]
\\[120.25w_2 = 1202.5\\]
\\[w_2 = \\frac{1202.5}{120.25} = 10\\]
Therefore, the scientist must add $\\boxed{10}$ kg of zinc to achieve the desired melting point.
Figure34: ExampleHUSKYsolution(mixed,HUSKYQA)
43J Tool-IntegratedSolutionTrajectoryPrompts
We provide examples of few-shot prompts for the set of training tasks used for generating the
tool-integratedsolutiontrajectoriesinFigures35,36,37,38,39,40,41and42.
Question: A bowling ball cannot weigh more than 16 pounds and must have a diameter of $8
\\frac{1}{2}$ inches. How many square inches are in the surface area of a bowling ball before
the finger holes are drilled? Express your answer as a common fraction in terms of $\\pi$.
Solution history:
None
Next solution:
Step 1: Compute the radius of the bowling ball.
Tool: [code]
```python
import sympy
# define the diameter
diameter = sympy.Rational(17, 2)
# compute the radius of the bowling ball
radius = diameter / 2
# print the output
out = radius
print(out)
```
---
Question: Tom has a red marble, a green marble, a blue marble, and three identical yellow marbles.
How many different groups of two marbles can Tom choose?
Solution history:
Step 1: Compute the number of ways Tom can choose two yellow marbles.
Tool: [math]
Since the yellow marbles are identical, there is only \\boxed{1} way for Tom to choose two yellow
marbles.
Step 2: Compute the number of ways Tom can choose two marbles of different colors.
Tool: [code]
```python
from math import comb
# define the number of colors and the number of ways to choose 2 colors
num_colors = 4
num_ways = comb(num_colors, 2)
# print the output
out = num_ways
print(out)
```
```output
6
```
There are 6 ways Tom can choose two marbles of different colors.
Next solution:
Step 3: Compute the total number of different groups of two marbles Tom can choose.
Tool: [math]
The total number of distinct pairs of marbles Tom can choose is $1+6= \\boxed{7}$.
---
Question: The points $(9, -5)$ and $(-3, -1)$ are the endpoints of a diameter of a circle. What is
the sum of the coordinates of the center of the circle?
Solution history:
Step 1: Compute the coordinates of the center of the circle.
Tool: [code]
```python
# define the coordinates of the endpoints
x1, y1 = 9, -5
x2, y2 = -3, -1
# compute the coordinates of the center of the circle
center_x = (x1 + x2) / 2
center_y = (y1 + y2) / 2
# print the output
out = (center_x, center_y)
print(out)
```
```output
(3.0, -3.0)
```
The coordinates of the center of the circle are (3.0, -3.0).
Next solution:
Figure35: Few-shotpromptforGSM-8K/MATHsolutiontrajectories(1)
44Step 2: Compute the sum of the coordinates of the center of the circle.
Tool: [code]
```python
# define the coordinates of the center of the circle (based on outputs from step 1)
x_center, y_center = 3, -3
# compute the sum of the coordinates
sum_coordinates = x_center + y_center
# print the output
out = sum_coordinates
print(out)
```
---
Question: Find the number of $x$-intercepts on the graph of $y = \\sin \\frac{1}{x}$ (evaluated in
terms of radians) in the interval $(0.0001, 0.001).$
Solution history:
Step 1: Identify the conditions for the function to have $x$-intercepts.
Tool: [math]
The intercepts occur where $\\sin \\frac{1}{x}= 0$, that is, where $x = \\frac{1}{k\\pi}$ and $k$ is
a nonzero integer. $\\boxed{x = \\frac{1}{k\\pi}}$
Step 2: Solve the inequality for the given interval.
Tool: [math]
Solving \\[0.0001 < \\frac{1}{k\\pi} < 0.001\\] yields \\[\\frac{1000}{\\pi} < k <
\\frac{10{,}000}{\\pi}.\\] $\\boxed{\\frac{1000}{\\pi} < k < \\frac{10{,}000}{\\pi}}$
Step 3: Compute the number of $x$-intercepts in the given interval.
Tool: [code]
```python
# define the lower and upper bounds
lower_bound = 1000/sympy.pi
upper_bound = 10000/sympy.pi
# compute the number of x-intercepts
num_intercepts = math.floor(upper_bound) - math.ceil(lower_bound) + 1
# print the output
out = num_intercepts
print(out)
```
```output
2865
```
There are 2865 $x$-intercepts in the interval $(0.0001, 0.001).$
Next solution:
The answer is: <answer>2865</answer>.
---
Question: A rectangular band formation is a formation with $m$ band members in each of $r$ rows,
where $m$ and $r$ are integers. A particular band has less than 100 band members. The director
arranges them in a rectangular formation and finds that he has two members left over. If he
increases the number of members in each row by 1 and reduces the number of rows by 2, there are
exactly enough places in the new formation for each band member. What is the largest number of
members the band could have?
Solution history:
None
Next solution:
Step 1: Write equations based on the given information, using $m$ to represent the number of members
in each row and $r$ to represent the number of rows.
Tool: [math]
The total number of band members can be represented by $mr + 2$. When the director increases the
number of members in each row by 1 and reduces the number of rows by 2, the total becomes
$(m+1)(r-2)$. The equation is $\\boxed{mr + 2 = (m+1)(r-2)}$.
---
Question: Let \\[f(x) = \\left\\{\n\\begin{array}{cl} ax+3, &\\text{ if }x>2, \\\\\nx-5 &\\text{ if }
-2 \\le x \\le 2, \\\\\n2x-b &\\text{ if } x <-2.\n\\end{array}\n\\right.\\]Find $a+b$ if the
piecewise function is continuous (which means that its graph can be drawn without lifting your
pencil from the paper).
Solution history:
Figure36: Few-shotpromptforGSM-8K/MATHsolutiontrajectories(2)
45Step 1: Determine the value of $a$ by setting the first two pieces of the function equal to each
other at $x=2$.
Tool: [code]
```python
from sympy import symbols, Eq, solve
# define the variables from the given question
x, a, b = symbols('x a b')
# define the first two pieces of the function
piece1 = a*x + 3
piece2 = x - 5
# set them equal to each other at x=2
eq = Eq(piece1.subs(x, 2), piece2.subs(x, 2))
# solve for a
solution_a = solve(eq, a)
# print the output
out = solution_a[0]
print(out)
```
```output
-3
```
The value of $a$ is -3.
Next solution:
Step 2: Determine the value of $b$ by setting the last two pieces of the function equal to each other
at $x=-2$.
Tool: [code]
```python
from sympy import symbols, Eq, solve
# define the variables from the given question
x, b = symbols('x b')
# define the equation
eq = Eq(x-5, 2*x-b)
# substitute x = -2 in the equation
eq = eq.subs(x, -2)
# solve the equation for b
b_value = solve(eq, b)[0]
# print the output
out = b_value
print(out)
```
---
Figure37: Few-shotpromptforGSM-8K/MATHsolutiontrajectories(3)
Question: ['Stem', 'Leaf ']
['3', ['3', '3', '3', '5', '5']]
['4', ['6']]
['5', ['4', '5', '7', '8']]
['6', ['7', '8']]
['7', ['2', '3', '7', '9']]
['8', ['6', '8', '9']]
The members of the local garden club tallied the number of plants in each person's garden. How many
gardens have at least 47 plants?
Solution history:
None
Next solution:
Step 1: Convert the Stem and Leaf plot into a list of numbers.
Tool: [code]
```python
def stem_leaf_to_list(stem_leaf_plot):
stem_leaf_plot = "\n".split(stem_leaf_plot)
result = []
for row in stem_leaf_plot[1:]: # Skip the header row
stem = row[0]
leaves = row[1]
for leaf in leaves:
number = int(stem + leaf) # Concatenate stem and leaf, then convert to integer
result.append(number)
return result
stem_leaf_plot_input = "['Stem', 'Leaf ']\n['3', ['3', '3', '3', '5', '5']]\n['4', ['6']]\n['5',
['4', '5', '7', '8']]\n['6', ['7', '8']]\n['7', ['2', '3', '7', '9']]\n['8', ['6', '8', '9']]"
out = st''em_leaf_to_list(stem_leaf_plot_input)
print(out)
```
---
Figure38: Few-shotpromptforTabMWPsolutiontrajectories(1)
46Question: ['Donation level', 'Number of donors']
['Gold', '15']
['Silver', '68']
['Bronze', '58']
The Burlington Symphony categorizes its donors as gold, silver, or bronze depending on the amount
donated. What fraction of donors are at the bronze level? Simplify your answer.
Solution history:
Step 1: Identify the number of donors at the bronze level.
Tool: [commonsense]
According to the table, there are 58 donors at the bronze level.
Step 2: Identify the total number of donors.
Tool: [code]
```python
num_gold = 15
num_silver = 68
num_bronze = 58
num_total = num_gold + num_silver + num_bronze
print(num_total)
```
```output
141
```
There are a total of 141 donors.
Next solution:
Step 3: Compute the fraction of donors at the bronze level.
Tool: [code]
```python
from fractions import Fraction
num_bronze = 58
num_total = 141
fraction_bronze = Fraction(num_bronze, num_total).limit_denominator()
print(fraction_bronze)
```
---
Question: ['Day', 'Number of tickets']
['Friday', '71']
['Saturday', '74']
['Sunday', '75']
['Monday', '72']
The transportation company tracked the number of train tickets sold in the past 4 days. On which day
were the fewest train tickets sold?
Solution history:
None
Next solution:
Step 1: Identify the day the fewest train tickets were sold.
Tool: [commonsense]
According to the table, the smallest number of tickets sold on a particular day is 71. The
corresponding day is Friday.
---
Question: '[\'Column 1\', \'Column 2\']
[\'shiny metal bead\', \'$0.04\']
[\'shiny red bead\', \'$0.05\']
[\'star-shaped silver bead\', \'$0.05\']
["brown cat\'s eye bead", \'$0.09\']
[\'orange glass bead\', \'$0.02\']
[\'round silver bead\', \'$0.04\']
Emmy has $0.05. Does she have enough to buy an orange glass bead and a round silver bead?
Solution history:
Step 1: Identify the price of an orange glass bead.
Tool: [commonsense]
According to the table, an orange glass bead costs $0.02.
Step 2: Identify the price of a round silver bead.
Tool: [commonsense]
According to the table, a round silver bead costs $0.04.
Next solution:
Step 3: Determine whether Emmy has enough to buy an orange glass bead and a round silver bead.
Tool: [code]
```python
emmy_budget = 0.05
price_orange_glass_bead = 0.02
price_round_silver_bead = 0.04
emmy_cost = price_orange_glass_bead + price_round_silver_bead
emmy_leftover = emmy_budget - emmy_cost
if emmy_leftover >= 0:
print("Emmy has enough money.")
else:
print("Emmy does not have enough money.")
```
---
Figure39: Few-shotpromptforTabMWPsolutiontrajectories(2)
47Question: ['Month', 'Number of magazines']
['November', '3,874']
['December', '1,300']
['January', '7,828']
['February', '5,211']
A magazine editor looked at her sales figures for the past 4 months. How many more copies were sold
in February than in November?
Solution history:
Step 1: Identify the number of magazine copies sold in November.
Tool: [commonsense]
According to the table, 3,874 copies were sold in November.
Step 2: Identify the number of magazine copies sold in February.
Tool: [commonsense]
According to the table, 5,211 copies were sold in February.
Step 3: Compute the difference between the number of copies sold in November and February.
Tool: [code]
```python
copies_november = 3874
copies_february = 5211
diff_copies = copies_february - copies_november
print(diff_copies)
```
```output
1337
```
Next solution:
The answer is: <answer>1337 copies</answer>.
---
Question: ['Column 1', 'Column 2']
['2', '8']
['3', '12']
['4', '16']
['5', '20']
Terrence likes to make lemonade using the lemons from his grandmother's trees. There is a
proportional relationship between the number of pitchers of lemonade Terrence wants to make, x,
and the number of lemons he needs, y. What is the constant of proportionality? Write your
answer as a whole number or decimal.
Solution history:
None
Next solution:
Step 1: Identify the proportional constant between the pairs of numbers in the table.
Tool: [code]
```python
# copy the table from the question
table_str = "['Column 1', 'Column 2']
['2', '8']
['3', '12']
['4', '16']
['5', '20']"
# convert the string into a list of lists
table_list = "\n".split(table_str)
# exclude the headers
table_list = table_list[1:]
# iterate over the table and identify the proportional constant
prop = set()
for xy_pair in table_list:
x, y = xy_pair[0], xy_pair[1]
prop.add(y / x)
print(prop)
```
---
Figure40: Few-shotpromptforTabMWPsolutiontrajectories(3)
48Question: When did the ocean surrounding Antarctica come into existence?
Solution history:
None
Next solution:
Step 1: Identify the ocean surrounding Antarctica.
Tool: [search]
```google
the ocean surrounding Antarctica
```
---
Question: Who was the first president from the party following the Anti-Administration Party?
Solution history:
Step 1: Find which party followed the Anti-Administration Party.
Tool: [search]
```google
the party that followed the Anti-Administration Party
```
```output
Democratic-Republican Party - Wikipedia
```
The Democratic-Republican Party followed the Anti-Administration Party.
Step 2: Identify the first president of the Democratic-Republican Party.
Tool: [search]
```google
the first president from the Democratic-Republican Party
```
```output
Thomas Jefferson defeated John Adams in the 1800 presidential election, thereby becoming the first
Democratic-Republican president.
```
Thomas Jefferson was the first president from the Democratic-Republican Party.
Next solution:
Step 3: Return the answer to the question based on the outputs above.
Tool: [commonsense]
The first president from the party following the Anti-Administration Party is <output>Thomas
Jefferson</output>.
---
Question: In which county is the Manning Bowl located?
Solution history:
None
Next solution:
Step 1: Find which county Manning Bowl is located in.
Tool: [search]
```google
the county is the Manning Bowl located in
```
---
Question: What movie stars Morgan Freeman, Robert De Niro and the producer of Flatliners?
Solution history:
Step 1: Identify the producer of Flatliners.
Tool: [search]
```google
the producer of Flatliners
```
```output
Rick Bieber, Michael Douglas, Scott Rudin
```
The producers of Flatliners are Michael Douglas, Scott Rudin and Rick Bieber.
Step 2: Find which movie Morgan Freeman, Robert Deniro and Rick Bieber starred in.
Tool: [search]
```google
movies that Morgan Freeman, Robert Deniro and Rick Bieber star in
```
```output
Last Vegas showcases the first-time onscreen collaboration of four legendary actors: Michael Douglas,
Robert De Niro, Morgan Freeman, and Kevin Kline. The ...
```
The search result above does not mention Rick Bieber, so there is no movie where Morgan Freeman,
Robert Deniro and Rick Bieber starred in together.
Figure41: Few-shotpromptforMusiQuesolutiontrajectories(1)
49Step 3: Find which movie Morgan Freeman, Robert Deniro and Michael Douglas starred in.
Tool: [search]
```google
movies that Morgan Freeman, Robert Deniro and Michael Douglas star in
```
```output
Last Vegas is a 2013 American comedy film directed by Jon Turteltaub, written by Dan Fogelman and
starring Michael Douglas, Robert De Niro, Morgan Freeman, ...
```
Morgan Freeman, Robert Deniro and Michael Douglas star in Last Vegas.
Step 4: Return the answer to the question based on the outputs above.
Tool: [commonsense]
<output>Last Vegas</output> stars Morgan Freeman, Robert De Niro and the producer of Flatliners.
Next solution:
The answer is: <answer>Last Vegas</answer>.
---
Question: When was the abolishment of the studio that distributed The Game?
Solution history:
Step 1: Identify the studio that distributed The Game.
Tool: [search]
```google
the studio that distributed the movie The Game
```
```output
After a wealthy San Francisco banker is given an opportunity to participate in a mysterious game, his
life is turned upside down as he begins to question if it ...
```
I'm sorry, but it seems there was no information provided in the output regarding the studio that
distributed The Game. Therefore, I cannot complete the answer based on the given output.
Next solution:
Step 1: Search again with a clearer query to identify the studio that distributed the movie "The
Game."
Tool: [search]
```google
the Game 1997 movie distributor
```
---
Question: What percentage of households in New York City earns more than $200,000 every year?
Solution history:
Step 1: Find the number of households in New York City.
Tool: [search]
```google
number of households in New York City
```
```output
3.192 million
```
There are 3.192 million households in New York City.
Step 2: Find the number of households in New York City with income over $200,000 per year.
Tool: [search]
```google
number of households in New York City with income over $200,000 per year
```
```output
In 2020, there were about 386,292 households with an income of 200,000 U.S. dollars or more in New
York City. In comparison, approximately 263,396 households had an income of less than 10,000
U.S. dollars during the same year.
```
There were 386,292 households with income over $200,000 per year in 2020.
Next solution:
Step 3: Compute the percentage of households that earn more than $200,000 in New York City.
Tool: [code]
```python
num_households_nyc = 3192000
num_households_over_200k_nyc = 386292
percentage = (num_households_over_200k_nyc / num_households_nyc) * 100
print(percentage)
```
---
Figure42: Few-shotpromptforMusiQuesolutiontrajectories(2)
50