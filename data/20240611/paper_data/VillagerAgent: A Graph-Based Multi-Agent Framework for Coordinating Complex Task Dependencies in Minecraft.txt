VillagerAgent: A Graph-Based Multi-Agent Framework for Coordinating
Complex Task Dependencies in Minecraft
YuboDong,XukunZhu,ZhengzhePan,LinchaoZhu†,YiYang
ReLER,CCAI,ZhejiangUniversity
†Correspondingauthor
Abstract LLM Multi-Agent Framework Construction Cooperation Task
Large
In this paper, we aim to evaluate multi-agent LLMs La Mn og du ea lg se
Multi-Agent dig block
systemsagainstcomplexdependencies,includ- Cooperation build ladder
Interaction open chest
ing spatial, causal, and temporal constraints. Interactive place block
Environments
First, weconstructanewbenchmark, named MINECRAFT How do agents collectively assign tasks?
VillagerBench, within the Minecraft envi-
Farm-to-Table Cooking Task Escape Room Challenge Task
ronment. VillagerBench comprises diverse
tasks crafted to test various aspects of multi-
dig block equip item
agent collaboration, from workload distribu- craft item toggle switch
cook item open chest
tiontodynamicadaptationandsynchronized kill entity place block
task execution. Second, we introduce a Di- How do agents adapt to dynamic environments? Can agents execute tasks in a specific order?
rectedAcyclicGraphMulti-AgentFramework
Figure1: MinecraftMulti-AgentBenchmark(Villager-
(VillagerAgent)toresolvecomplexinter-agent
Bench)isthefirstmulti-scenariobenchmarkdesigned
dependencies and enhance collaborative effi-
toevaluatethecooperativecapabilitiesofmulti-agent
ciency. This solution incorporates a task de-
systemswithinthereal-worldcontextofMinecraft.
composerthatcreatesadirectedacyclicgraph
(DAG) for structured task management, an
agent controller for task distribution, and a
statemanagerfortrackingenvironmentaland theCuisineWorldgamingscenarioasabenchmark,
agent data. Our empirical evaluation on Vil- utilizingtheCollaborationScore(CoS)tomeasure
lagerBench demonstrates that VillagerAgent theefficiencyofcollaboration(Gongetal.,2023).
outperformstheexistingAgentVersemodel,re-
AgentVerse organizes its framework into four es-
ducinghallucinations andimprovingtaskde-
sentialstages: ExpertRecruitment,Collaborative
compositionefficacy. Theresultsunderscore
Decision-Making, Action Execution, and Evalu-
VillagerAgent’s potential in advancing multi-
ation, thereby effectively deploying multi-agent
agentcollaboration,offeringascalableandgen-
eralizable solution in dynamic environments. groupsthatoutperformasingleagent(Chenetal.,
Sourcecodeisopen-sourceonGitHub. 1 2023). MetaGPT, on the other hand, employs an
assemblylineapproach,designatingspecificroles
1 Introduction
to agents and efficiently breaking down complex
Multi-agentcollaborationusingLLMisachalleng- tasksintosubtasksinvolvingmanyagentsworking
ingresearchtopicthataimstoenablemultipleau- together(Hongetal.,2023). However,thesemulti-
tonomous agents to coordinate their actions and agent collaboration models either tend to restrict
achieve a common goal (Wang et al., 2023b; Xi agentstoparallel-executablesubtaskseachround,
etal.,2023;Qianetal.,2023b,a;Xieetal.,2023; even when unnecessary or bind them to a fixed
Wu et al., 2023a). The collaboration process re- pipelineandtaskstage,overlookingcomplextask
quires communication, planning, and reasoning dependencies. Thismaycauseissuesfortasksthat
among multiple intelligent agents. It has many need both sequential and parallel execution, thus
applicationsindomainssuchasrobotics,gaming limiting model generality and scalability (Gong
(Wangetal.,2023a),andsocialsimulation(Lietal., etal.,2023;Chenetal.,2023;Hongetal.,2023).
2023).
Inthispaper,wefocusonmulti-agentcollaboration
Thereareincreasinginterestsindevelopingmulti-
for problem-solving with complex dependencies.
agentsystemsusingLLMs. MindAgentintroduces
Thesedependenciescanbeofdifferenttypes,such
1https://github.com/cnsdqd-dyb/VillagerAgent asspatialdependenciesthatconstrainthelocations
4202
nuJ
9
]IA.sc[
1v02750.6042:viXraof the sub-tasks, causal dependencies that affect aDirectedAcyclicGraph(DAG)ofsubtasknodes
the availability and effects of the sub-tasks, and each round, while the Agent Controller oversees
temporaldependenciesthatimposeconstraintson theassignmentofthesesubtaskstotheBaseAgents
the timing of the sub-tasks. It is crucial to under- forexecutionandself-reflection. Meanwhile,the
standandmanagethesedependenciesforeffective State Manager is responsible for maintaining the
multi-agent collaboration, enabling the agents to statusinformationofboththeenvironmentandthe
reasonaboutthelong-termconsequencesoftheir agents.
actionsandavoidpotentialconflicts. WequantitativelyevaluateourmethodonVillager-
Bench. Wedemonstratethesuperiorperformance
First, we introduce VillagerBench, a new multi-
of VillagerAgent over AgentVerse (Chen et al.,
agentbenchmarkintheMinecraftenvironmentde-
2023) by fewer hallucinations and enhancing the
signedfortheevaluationofcomplexdependencies
effectivenessoftaskdecomposition.
(Figure7). Someofthemulti-agentresearchisbe-
ingtestedwithintheOvercooked-AI(Carrolletal.,
2 VillagerBenchDesign
2020). Nevertheless,duetolimitationsinthenum-
berofagents,scenarioflexibility,andtaskdiversity, OurVillagerBenchusesMineflayer(PrismarineJS,
there is a desire for more comprehensive frame- 2013)toestablishAgentAPIs,offeringaplatform
workstotestmulti-agentcooperation. Inspiredby to examine cooperative behaviors in multi-agent
Voyager (Wang et al., 2023a), GITM (Zhu et al., systems via tasks such as construction, cooking,
2023), and MindAgent (Gong et al., 2023), we andescaperoomchallenges(Figure1).
constructamulti-agentandmulti-taskevaluation Weevaluatemulti-agentsystemspoweredbyLLMs
frameworkwithgreaterdegreesoffreedomusing usingthreekeymetrics: Completion(C)thatmea-
Minecraft. Minecraftoffersarichanddiverseset surestheaveragetaskcompletionrate;Efficiency
oftasksthatcanbeusedtobenchmarkandevaluate (E)thatassessesthespeedoftaskexecutionandthe
multi-agentsystems,suchasbuildingandfarming. utilization of resources; and Balance (B) that ex-
Itallowsplayerstoexploredynamicenvironments aminesthedistributionofworkloadamongagents,
thatposevariouschallengesformulti-agentcollab- withhighervaluesindicatingamoreequitableas-
oration, such as resource allocation, task decom- signmentoftasks. Furtherdetailscanbefoundin
position,andcoordination. Specifically,weintro- AppendixA.
duce three tasks, i.e., Construction Cooperation,
ConstructionCooperationTask: Interpretation
Farm-to-Table Cooking and Escape Room Chal-
andAllocation. ConstructionCooperationtask
lenge. The Construction Cooperation task tests
iscenteredaroundtheagents’proficiencyininter-
agents’ aptitude for understanding task require-
pretingdetailedtaskdocumentsandefficientlyal-
mentsandorchestratingteamworkload,focusing
locatingtheworkloadamongteammembers. This
ontheevaluationofspatialdependenciesinmulti-
task necessitates a high level of comprehension
agentcollaboration. The Farm-to-Table Cooking
andcoordination,asagentsmustparsetheproject
taskassessestheiragilityinadaptingtofluctuating
specificationsandjudiciouslyassignsub-tasksto
environmentalconditions,aimingtosolvecomplex
optimizecollectiveperformance.
causaldependencies. TheEscapeRoomChallenge
task tests agents on their ability to execute tasks Agents are provided with textual architectural
bothsequentiallyandinparallel,requiringtherea- blueprints that specify the positions and orienta-
soningoftemporaldependenciesandtheabilityto tions of blocks required for construction tasks.
synchronizeactions. Building materials are supplied in chests or at a
materialfactory,whereagentsmustmineandtrans-
Second, we introduce a Directed Acyclic Graph
portthemtothebuildingsite. Furtherdetailscan
Multi-Agentframework(VillagerAgent)totackle
befoundinAppendixB.1.
complex dependencies in multi-agent collabora-
tions. Eachsubtaskisrepresentedasagraphnode Farm-to-Table Cooking Task: Environmental
intheDAG.Wedynamicallyadjustthegraphstruc- VariabilityandStrategicFlexibility. InFarm-
tureand theagent rolesaccording tothe environ- to-Table Cooking task, agents must adapt their
mentandtheagentstates. VillagerAgentconsists strategies to changing environmental conditions
oftaskdecomposer,agentcontroller,statemanager andvaryingdifficultylevels. Theyneedtogather
and base agents. The Task Decomposer generate information,sourceingredientseitherfromcontain-Scenario 1: Using the provided blueprint, please collaborate to build in Minecraft.
Task Decomposer Agent Controller State Manager
Task Graph Agent Status & Environment
Get iron_axe and find other Get iron_axe and find other
materials in the chest materials in the chest Agent State Steve opened a chest at ... and found it contains
multiple stacks of dirt, as well as ladders and then
equiped an iron_axe from it.
Alex searched around and found many logs at ...
Place logs to build base All are suitable for ... Alex is Nothing is in Alex’s bag.
structure of the building chosen as she is close to ...
Dig more materials needed : I collect ×5 I choose Steve arbitrarily, as Task Graph There are a chest at ..., a rabbit at ..., and a fur-
for the structure Agent Feedback Steve equipped an iron_axe. nace at ... near two agents.
Steve is holding an iron_axe and has five logs in
Steve’s bag. Alex is holding nothing.
The info of nearest sign is ...
Plan & Action Experience
Base Agent
Here is the Actions of the most similar task Place
Env Feedback a dirt path block at coordinates (-8, -60, 1):
Follow the steps:
Thought: Thought: [move_to_position, place_item,...]
Steve currently has an Now, Alex can attempt to The task will be done.
iron axe on hand and place the dirt path block
will begin to work on at the specified coordi-
cutting logs next. nates... To place blocks, Here is an experience task graph:
Env Interaction Action: Action: Subtasks Graph:
mine_block oak_log place_item oak_log 1.1 Collect materials from chest,
Observation: Observation: 1.2 Dig logs in the fartory parallel with 1.1
VillagerBench {'message': dig block ...', {'message': place block ...
'status': True} ...', 'status': True}
Figure2: OverviewoftheVillagerAgentframework. Ourframeworkactsasthecentralarchitectureforindividual
agents,enhancingtheircollaborativecapabilities. FeaturingaTaskDecomposerthatgeneratessubtaskDAGs,an
AgentControllerfortaskassignment,aStateManagerforstatusupdating,andBaseAgentsfortaskexecutionand
self-assessment.
ersorthroughactivitieslikeharvestingandhunting, State Manager, and Base Agents. It operates by
andadjusttheirmethodstopreparecomplexdishes. havingtheTaskDecomposergenerateaDirected
We simulate this by having agents act as farmers AcyclicGraph(DAG)ofsubtasknodeseachround,
whoaretaskedwithmakingcakeandrabbitstew based on the current state, while the Agent Con-
inMinecraft. Theserecipesarerecognizedfortheir trolleroverseestheassignmentofthesesubtasksto
high complexity in terms of ingredient synthesis, theBaseAgentsforexecutionandself-reflection.
makingthemchallengingtargetsforthetask. Fur- Meanwhile, the State Manager is responsible for
therdetailscanbefoundinAppendixB.2. maintainingthestatusinformationofboththeenvi-
ronmentandtheagents(Figure2).
EscapeRoomChallengeTask: Synchronization
andSequentialExecution. EscapeRoomChal- AgentNotations. Wedenoteeachbaseagentas
lenge task tests agents’ ability to work together A and the corresponding agent state as S . The
i i
andperformactionsinapreciseorder,focusingon agent state is a textual representation that recur-
synchronizationandtiming. Agentsmustnavigate sivelysummarizestheagent’sactions,possessions,
environmentswithobjectsthathavespecificacti- and the entities in the surrounding environment.
vationrequirements,andsuccessdependsontheir Eachagenthasanactionhistory(H )thatconsists
i
coordinatedtimingandteamwork. of the last p actions. We assume that there are k
Eachroomoffersuniquechallengesthatdemand agents in the game. The agent set can be repre-
effectiveteamcollaborationandstrategicplanning. sented as A = {A |i = 1,...,k} and the agent
i
Forexample,abasictaskmayrequiretwoagents statesetisdenotedasS = {S |i = 1,...,k}
i
topressswitchesatdifferentlocationssimultane-
TaskNotations. Wemodeltheexecutiondepen-
ously to open a door. Further details and visual
denciesofacomplextaskwithagraphofsubtasks.
representations of each scenario can be found in
EachsubtasknodeN isrepresentedbyaquadru-
AppendixB.3. j
ple, i.e, (T ,D ,C ,F ). T denotes the subtask
j j j j
3 VillagerAgent: ADirectedAcyclic description and D represents the data from doc-
GraphMulti-AgentFramework uments related to the subtask. C represents the
assignedagentsthathavebeenselectedbytheTask
3.1 Overview ManagerfromthebaseagentsetA. F denotesthe
TheVillagerAgentframeworkcomprisesfourmain executionfeedback. Wedenotethesetofsubtask
components: TaskDecomposer,AgentController, nodesasN = {N |j = 1,...,m}wheremisthe
jnumberofsubtasknodes. statesoftheagentsS,theAgentControllerdeter-
minestheallocationofagentstosubtasks:
3.2 TaskDecomposer
AC(E,N ,A,S) → [(A ,N ),...]
The Task Decomposer is responsible for manag- ready i j
ing and constructing the directed graph G. The
Inthisprocess,theAgentController(AC)queries
directed graph represents the concurrency of the
LLM to pair tasks with agents. It anticipates a
subtasks. In this graph, each node v ∈ V cor-
i
JSON-formattedresponsecontainingtheindicesof
respondstoasubtaskN ,andeachdirectededge
i
tasksandtheidentifiersoftheselectedagents. The
(v ,v )signifiesthatsubtaskN mustbecompleted
i j i
AgentControllerinitiatestheexecutionoftasksby
beforecommencingsubtaskN . Parallelexecution
j
thedesignatedagentssimultaneously.
of subtasks is permitted when there is no direct
edge dictating the execution order between them.
3.4 StateManager
The details of constructing the directed graph G
from the set of subtasks N can be found in Ap- TheStateManager(SM)isusedtoupdatetheagent
statesandtheenvironmentinformation.
pendixA.1.
AgentStateUpdate. SMupdatestheagentstate
Subtask Set Update. The Task Decomposer is
basedontheagent’sactionhistoryH :
also used to update the subtask set N. Given the i
goaltaskdescriptionT ,therelevantenvironment
g S = LLM(prompt ,S ,H ).
i a i i
stateE queriedfromtheStateManager,theagent
statesetS, andthecurrentnodesN, theTaskDe-
where prompt is the agent state update prompt.
a
composergeneratesasetofnewsubtasknodesN′.
TheagentstateS actsasalong-termmemory,in
i
contrasttotheactionhistoryH ,whichservesas
i
N′ = TD(E,T ,S,N) short-termmemory.
g
N = N′∪N EnvironmentStateRetrieval. Theglobalenvi-
ronmentstate(I)istheunionofthelocalenviron-
Duringtaskdecomposition,theTaskDecomposer mentstatefromeachagent. Thelocalenvironment
adopts a zero-shot chain-of-thought (CoT) ap- state of agent A can be obtained via the library
i
proach(Weietal.,2023). Thismethodisintegrated API,i.e.,Env(A ).
i
intotheprompt,asFigure9illustrates,toguidethe Given the task description T , the relevant envi-
g
LLMingeneratingresponsesinJSONformat,spec- ronment stateE can beretrievedfrom the global
ifytheindexoftheimmediatepredecessorforeach environmentstate(I):
subtaskasneededandspecifyJSONpathexpres-
sions for each subtask, referencing the provided E = LLM(prompt ,T ,I).
e g
dataD. Subsequently,eachsubtasknodewilluse
theseJSONpathexpressionstoquerythedatare- where prompt e is the environment state retrieval
latedtoitssubtask. prompt. prompt a,prompt e can be found in Ap-
pendix12,13.
3.3 AgentController
3.5 BaseAgentArchitecture
TheAgentControllerfocusesonanalyzingthetask
Each base agent A is responsible for executing
graphandassigningtheappropriatesubtasktothe i
its assigned subtask node N . The states of the
rightagentinanefficientmanner. j
agents associated with the predecessor nodes of
Ready-to-Execute Tasks Identification. The the current node N in DAG can be represented
j
Agent Controller identifies ready-to-execute task as S . This execution results in an updated
selected
set N . It checks all unexecuted tasks, where temporalactionhistoryandgeneratesfeedback:
ready
tasks with no remaining dependencies will be
addedtotheready-to-executetasksetN ready. (H i,F j) = Exec(N j,H i,S selected,E)
SubtaskAllocation. Basedontheenvironment UponexecutionofthesubtasknodeN ,twopro-
j
state E, ready-to-execute nodes N , and the cessesoccurwithintheagentA :
ready i4 Experiments
1.0 0.96
0.87 AgentVerse
VillagerAgent LLM Capability Test. To rigorously evaluate
0.8 0.74
the capabilities of LLMs, we conducted tests on
0.6 0.58
0.49 the VillagerBench benchmark using the Villager-
0.4 0.30 Agentframeworkbasedonthreemodels: GPT-4-
0.2 1106-preview(ope,2023),GeminiPro(gem,2023),
0.040.07
and GLM-4(Du et al., 2022). Our evaluation tar-
0.0
Completion Rate Workload BalanceContribution Rate Efficiency
getedthreetypesoftasks: 100Constructiontasks,
Figure3:ComparisonofVillagerAgentandAgentVerse 100 Farm-to-table cooking tasks, and 25 Escape
on Farm-to-Table Cooking Task. VillagerAgent out- room challenges, each executed once. We termi-
performsAgentVerseinCompletionRate(Chenetal.,
nateatestingroundifthetaskexecutionexceeds
2023).
theanticipatedtimeframeoroncethetaskhasbeen
successfullycompleted. TheparametersforLLM
reasoningcanbefoundinAppendix7.
Construcion-B Construction Cooperation Task. For the con-
Cooking-C
structiontasksrangingfrom0to99,wedeployed
Construcion-E
two agents, Alice and Bob, each equipped with
essentialAPIs,tocollaborateeffectively. Weinten-
Cooking-E
tionallyomittedtherequirementforagentstomine
blocks from the material factory, considering the
Construcion-C
inherentcomplexityofthetasks. Theblueprintpro-
videdtotheagentsisamoreconciseandreadable
Cooking-B
format,therebystreamliningthecontextandfacil-
Escape-B itatingmoreefficienttaskcompletion,asdetailed
inAppendixB.1.
Escape-C Gemini-pro
Escape-E GLM-4
GPT-4-1106-preview Farm-to-Table Cooking Task. For the Farm-
to-Table Cooking tasks, numbered 0 through 99.
Figure4: ComparisonofLLMsonVillagerBench. We
Tasks0to35arededicatedtocake-making,while
showtherelativeperformancegapagainstthebestin
tasks 36 to 99 focus on the preparation of rabbit
each scenario. GPT-4-1106-preview achieves higher
scoresacrossmostmetrics,whereasGemini-Prodemon- stew. We supply cooking recipes to serve as a
stratesbetterefficiencyintheEscapeRoomChallenge. referencefortheagents. VillagerAgentvs. Agent-
VerseinCooking: We’vetransitionedAgentVerse
BaseAgentfromtheVoyagerenvironment(Wang
etal.,2023a)toourVillagerBenchBaseAgent,en-
ReActProcedure. TheBaseAgentformulatesa
suringafaircomparisonbypreservingtheprompt
prompt that integrates its action history H , the
i
format and default settings, including the use of
current state of agents S , the assigned subtask
i
agent names Alice and Bob. Our modifications
node N , and environmental data E provided by
j
involvetheadoptionofthegpt-4-1106-previewlan-
the State Manager. Utilizing the ReAct method,
guage model, setting the temperature parameter
the agent iteratively generates actions and obser-
to0,andrefiningthefeedbackprompttosuitour
vations.(Yaoetal.,2023)Thisiterativeprocessis
ReActAgent(Figure16).
subjecttoaconstraintofamaximumof6iterations
oratotalexecutiontimelimitof120seconds.
EscapeRoomChallengeTask. We’vecrafted18
atom-basedescaperoomtasksthatsimulatepuzzle-
solving scenarios for agents. Our generator con-
Self-Reflection. Uponcompletionofthetask,the structs these tasks from the ground up, selecting
BaseAgentupdatestheactionhistoryH andthe appropriate atom tasks based on room attributes,
i
taskdescriptionT intoareflectionprompt. LLM requiredmaterials,andagentinformation,andthen
thengeneratesaresponsethatservesasfeedback automaticallyscalesthemintofull-fledgedpuzzles.
F forthesubtasknodeN . The generator also ensures task feasibility by ac-
j j
)%(
serocSConstructionTaskAvg.Score EscapeChallengeAvg.Score
Models
C(%) VHR(%) E(%/min) B(%) C(%) E(%/min) B(%)
gemini-pro 8.12 13.83 0.76 63.74 69.2 153.3 80.35
glm-4 23.16 29.36 2.37 81.12 68.17 100.8 95.3
gpt-4-1106-preview 36.45 49.05 3.88 95.38 73.29 149.4 90.03
gpt-4-1106-preview(3-agents) 52.17 61.02 6.26 89.83 69.78 227.4 67.01
Table1: GPT-4-1106-preview(ope,2023),GLM-4(Duetal.,2022)andGemini-Pro(gem,2023)resultsonCon-
struction Cooperation task and Escape Room Challenge Task. (The Escape Room Challenge Task updates to
accommodatevaryingnumbersofagents.)
countingforagentcooperationanditemdependen- wards the scenario’s objectives, such as blocks,
cies. ForconsistentLLMtesting,we’vedesignated ingredientsortriggers. Thecompletionrateiscal-
seedsforeachofthefivedifficultylevels,with25 culated based on the quantity of these indicators,
uniquetasksintotal,andsetadefaultsimultaneous providingameasureofhowmuchofthescenario
item activation wait time of 30 seconds for task has been completed defined in AppendixA. The
completion. formula for calculating the completion rate is as
follows:
Benchmarking Our VillagerAgent in
#IndicatorsDetected
Overcooked-AI. We conducted tests on Completion(C) =
#TotalIndicatorsExpected
VillagerAgent (equipped with GPT-4) within
EfficiencyofCompletion(E). Itisdefinedasthe
the Overcooked environment, following the
ratioofthetaskcompletionratetotheactualtime
methodologyusedinProAgent(Zhangetal.,2024).
takenbytheagents. Theefficiencyofcompletion
We analyzed the prompt tokens for each test.
iscomputedasfollows:
ConsistentwiththesettingsoutlinedinProAgent,
we evaluated each layout across 5 episodes, with #TaskCompletionRate
Efficiency(E) =
thehorizonsetto400. #TotalExecutionTime
BalancedAgentUtilizationScore(B). Thismet-
Influence of Agent Quantity on Cooperative
ric assesses the distribution of workload among
TaskExecution. Weanalyzedhowvaryingnum-
agents, aiming for a balanced utilization where
bers of agents (1, 2, 4, 8) affect cooperative task
each agent’s active running time is similar. The
performanceinconstructionscenarios,specifically
ideal state is one where no single agent is either
comparingthesimplesttask(task0)andacomplex
overburdenedorunderutilized.
task(task64). UsingtheGPT-4-1106-preview(ope,
t−min(t)
2023)modelwithintheVillagerAgentframework, t′ = (1)
max(t)−min(t)
eachtaskwasrepeatedsixtimes.
Balance(B) = 1−σ(t′) (2)
AssessingtheImpactofVariedAgentAbilities
Here,nisthenumberofagents,t ∈ Rn,t repre-
i
onCooperativeTaskPerformance. Weevalu-
sentstheactiverunningtimeofagenti,and¯tisthe
ate how different agent skill sets impact a com-
averageactiverunningtimeacrossallagents.
plex farm-to-table cooking task (task 99 - rabbit
stewpreparation). WithGPT-4-1106-preview(ope, BlockPlacementViewHitRate(VHR). evalu-
2023) as the base model, we tested two trios of atesthestructuralintegrityandvisualcoherenceof
agents,eachsetconsistedofthreeagents: onewith theconstructionfrommultiplevantagepoints. Itis
uniformAPIabilities(7BaseAPIsplusSmelting- calculatedastheintersectionoverunion(IoU)of
Cooking, MineBlock, and AttackTarget) and an- the constructed structure with the expected struc-
otherwithdiverseabilities(7BaseAPIswithone tureacrossapredefinedsetofviewpoints.
unique additional API per agent). Each repeated
V
1 (cid:88)
sixtimes. S = IoU(C ,E ) (3)
vhr v v
V (θ,ϕ) (θ,ϕ)
v=1
4.1 EvaluationMetrics
Here, V is the number of viewpoints, C is the
v
Completion Rate (C). For each scenario, we constructionasseenfromviewpointv,andE is
v
monitorcertainindicatorsthatsignifyprogressto- theexpectedviewfromviewpointv.Farm-to-TableCookingAvg.Score Tasks(Figure3),showinglesshallucinatorybehav-
AgentType
iorandalowerfailurerate(18.2%forVillagerA-
C(%) ACR(%) E(%/min) B(%)
gentvs. 44.4%forAgentVerse,asseeninFigure5).
Same 56.67 60.22 3.91 95.47
Diverse 36.67 30.46 2.87 92.2 Although VillagerAgent uses more tokens on av-
erage(126vs. 107forAgentVerse),itachievesa
Table2: Resultsofvariedagentabilitiesoncooperative significantlylowerTokenCost(Avg. 1.79vs. 10.3
taskperformanceonFarm-to-TableCookingTask99.
forAgentVerse),indicatingamoreefficientuseof
resourcesforhigherscores,asdetailedinTable4.
CookingTaskAvg.Score
Models
AgentCollaborationandPerformanceDynam-
C(%) ACR E(%/min) B(%)
ics. Data analysis from Table 6 shows that Vil-
AgentVersegpt 29.75 48.64 3.54 87.13
lagerAgent’staskperformanceimproveswithad-
VillagerAgent 26.05 32.92 3.35 83.15
gemini ditional agents up to a point, after which it de-
VillagerAgent 46.84 54.07 4.79 75.46
clines. Initially,moreagentscontributepositively,
glm
VillagerAgent 73.75 58.11 6.98 96.13 enhancing task handling through collective capa-
gpt(2-agents) bility. However, as agent numbers increase fur-
VillagerAgent 85.26 55.60 21.90 84.38
ther,performancegainsdiminishduetoissueslike
gpt(3-agents)
resource competition and increased management
Table 3: Performance comparison between Agent- complexityfortheLLM.Therelationshipbetween
Verse(Chenetal.,2023)andVillagerAgentontheFarm- agentcountandperformanceisthuscharacterized
to-Table Task. Note that gpt refers to GPT-4-1106- byapeakatmoderatelevelsofcollaboration,sug-
preview,geminitoGemini-Pro,andglmtoGLM-4
gesting an optimal balance for system efficiency
withoutspecifyingapreciserange.
AgentContributionRate(ACR). quantifiesthe
contribution of each agent in a Minecraft game
Diverse Abilities Hinder Coordination. The
based on the items they have crafted in farm-to-
analysis of Table 2 reveals that a trio of agents
tablecookingtasks. Thespecificdefinitionscanbe
withdistinctextraAPIsunderperformsinallevalu-
foundinAppendixA.
atedmetrics. Thisunderperformanceisattributed
totheincreasedcomplexityincoordinationwhen
4.2 EvaluationResults
agentspossessdifferentcapabilities. Forexample,
GPT-4 with VillagerAgent Achieves Optimal
theworkflowmaybedisruptedifoneagent’stask
Performance. Across the board, GPT-4-1106-
dependsonthecompletionofanother’s,leadingto
preview,whenintegratedwithVillagerAgent,con-
potentialbottlenecksandtaskfailure.
sistentlydeliveredthehighestcompletionscoresin
Despite the lower efficiency, the diverse skill set
taskallocation(Figure3),asseeninConstruction,
among agents introduces a richer complexity to
Escape Room Tasks and Farm-to-Table Cooking
the task environment, paving the way for more
(Table1,3). Itdemonstratedasuperiorunderstand-
intricatecooperativeinteractions. Whilenotopti-
ing of task requirements and agent management,
malforscoremaximization,thissetupservesasa
outperformingGLM-4andGemini-ProinViewHit
fertilegroundforinvestigatingadvancedcollabora-
Rate(VHR)andAgentContributionRate(ACR).
tivebehaviorsandstrategieswithinourbenchmark
Gemini-Pro Excels in Efficiency for Escape framework.
RoomChallenge. Inthecontextoflesscomplex
Trade-off in Token Cost. To measure the rela-
tasksthatprioritizetimingandsequence,suchas
tionshipbetweentaskcompletionperformanceand
the Escape Room Tasks, Gemini-Pro showcased
tokenusage,weintroducethefollowingformulato
its strengths. It achieved efficiency comparable
calculatethetokencost.
to GLM-4 and, in some cases, outperformed oth-
ersduetoitsfasterinferenceandresponsetimes, CompletionTokens
Cost = (4)
leadingtoahigh-efficiencyrating(Table1). (Score+ε)+ActionNum
VillagerAgent Outperforms AgentVerse. De- CompletionTokensreferstotheaveragetokenus-
spite both utilizing GPT-4, VillagerAgent outper- age to complete each action. Action Num refers
forms AgentVerse in the Farm-to-Table Cooking tothenumberofvalidactionsexecutedduringtheVillagerAgent v.s. AgentVerse
Task: Farming_20
Environment: bucket and egg in chest, wheat and sugarcane in farm
Agent num: 2
VillagerAgent AgentVerse
Plan: Discussion:
[ [Alice]: Hey Bob, to make a cake we need 3 buckets of milk, 2 sugar, 1 egg, and 3 wheat.
{ Let's check the chests for these ingredients first. If we don't find them, we'll need to gather
"id": 1, them. How about I focus on getting the milk and wheat, and you focus on finding sugar
"description": "Harvest wheat and craft into and an egg? If we find extra ingredients in the chests, we can adjust our plan accordingly.✅
wheat blocks if necessary", ✅ What do you think?
... [Bob]: Sounds good, Alice. I'll start by checking the chests for sugar and an egg. If I don't find
"assigned agents": ["Alice"] them there, I'll go look for sugarcane to make sugar and search for chickens to get an egg.
}, Let's meet back here with the ingredients we've gathered. If we both end up finding some of
{ the same ingredients, we can share them to make sure we have everything we need. Let's
"id": 2, get to it! ✅
"description": "Find sugar cane or honey bottles [Alice]: Bob, I've managed to get the 3 buckets of milk and found 2 wheat in the chests.
to craft sugar", ✅ How did your search go? Do you have the sugar and egg? If not, we should split up to find
... the remaining wheat, sugar, and egg. I can go harvest or find another wheat, and if you
"assigned agents": ["Bob"] haven't found sugar and egg yet, you could continue searching for those. Let's update each
} other on what we still need.❌hallucination: Alice hasn't done it
] [Bob]: ...
Figure5: VillagerAgentv.s. AgentVerse(Chenetal.,2023)onFarm-to-TableTask. Hallucinationexistsinagent
discussionstageofAgentVerse.
task. Thescoreisthetaskscore. Wesetepsilon=1 in the Forced Coordination scenario—a highly
topreventascorefromdroppingtozero. interdependent task requiring material sharing in
WecomputetheTokenCostofVillagerAgentand confined spaces. This superior performance is
AgentVerseontasksofvaryingdifficulty. attributedtoouruseofdirectedacyclicgraphsfor
taskmanagement,enhancingefficiencyincomplex
Difficulty Framework Tokens↓ Cost↓ cooperativetasks,asdetailedinTable5.
Easy AgentVerse 109.26 17.76 EfficiencyandTransferabilityofPrompts. we
Medium AgentVerse 108.95 6.05 compare ProAgent and VillagerAgent regarding
Hard AgentVerse 101.33 4.32 the use of prompt. The results are shown in the
Average AgentVerse 107.17 10.30 tablebelow. Ourframeworkutilizedasinglesetof
prompts to accomplish five tasks in Overcooked,
Easy VillagerAgent 122.33 1.73
whereas ProAgent employed five specific sets of
Medium VillagerAgent 126.52 1.69
prompts. Similarly, we also used a single set of
Hard VillagerAgent 131.13 2.01
prompts across three scenarios in VillagerBench.
Average VillagerAgent 126.00 1.79
WealsoobservethatVillagerAgentusesfewerto-
kensineachtest,implyingitsloweroverheadand
Table4: ComparisonofTrade-offinTokenCost
bettertransferability.
Wediscoveredthat,althoughweuseslightlymore
5 RelatedWork
tokens per action compared to AgentVerse, our
Token Cost is significantly lower. This indicates Minecraft Agents. Minecraft agents are intel-
thatthebenefitswegainintermsofscoreoutweigh ligent programs that can perform various tasks
theadditionaltokensweutilize. withintheMinecraftworld. Recently,researchers
havecometobeawareoftheextraordinarygeneral
4.3 InOvercooked-AI
planning ability of LLMs (Huang et al., 2022a).
VillagerAgent Outperforms ProAgent. In Many works (Huang et al., 2022b; Yuan et al.,
Overcooked-AI 6, our VillagerAgent (w/gpt-4), 2023;Wangetal.,2023c,a;Zhuetal.,2023)have
surpassesProAgent(Zhangetal.,2024)acrossall leveragedLLMsforenhancingthehigh-levelplan-
five scenarios: Cramped Room, Asymmetric Ad- ningabilityofMinecraftagents. InnerMonologue
vantages,CoordinationRing,ForcedCoordination, (Huangetal.,2022b)leveragedenvironmentfeed-
andCounterCircuit. Eachscenariotestsdifferent backtoimprovetheplanningabilityofLLM.Voy-
aspects of cooperative strategy and efficiency in ager(Wangetal.,2023a)developedaskilllibrary
a shared task environment. Notably excelling ofexecutablecodeforstoringandretrievingbehav-Figure6: Overcooked-AIScenarios
Layout PBT FCP MEP COLE ProAgent VillagerAgent(ours)
CrampedRoom 178.8±16.5 196.3±16.8 185±15 163.8±24.1 197.3±6.1 213.3±9.43
AsymmetricAdvantages 182.2±27.9 185.7±22.7 155.7±63.9 201.3±34.5 228.7±23 304±8.76
CoordinationRing 141.3±28 148.8±19.4 167.2±22.4 168.8±26.1 175.3±29 226.7±18.9
ForcedCoordination 15.3±17.1 44.7±36.4 23.3±19.8 24±21.8 49.7±33.1 120±16.97
CounterCircuit 64.7±45.9 58.3±37.5 74.3±39.1 95.5±25.2 126.3±32.3 148±4.38
Table5: PerformancecomparisonofVillagerAgentandProAgentacrossdifferentscenariosinOvercooked-AI.
iors. The base agent in our VillagerAgent frame- nentstocreateawiderangeoftasks(SkillForge).
work accounts for the states of other agents and Ourresearchfocusesonmulti-agent,enhancestask
featuresamodulardesign,enablingittofunction complexityusingMinecraftcommands,introduces
independentlyorincollaborationwithotheragents. moreintricatechallengeslikelong-distanceswitch
activation. The Overcooked environment is no-
MultiAgent Frameworks. MultiAgent frame-
tableforcoordinationexperiments(Carrolletal.,
works are increasingly leveraging LLMs due to
2020),whileMAgICfocusesonassessingLLMs’
their potential in complex system development
cognitiveandcollaborativeabilitiesintext-based
(Qian et al., 2023b,a; Xie et al., 2023; Wu et al.,
multi-agent settings (Xu et al., 2023). Existing
2023a). CAMEL utilizes role-play to reduce hal-
benchmarks, however, may not fully capture the
lucinations and improve collaboration (Li et al.,
capabilities of LLMs as multi-agents. Inspired
2023). MindAgent’sCuisineWorldusesaCollabo-
bymultiplesingle-agentstudiesconductedwithin
rationScoretogaugeteamefficiency(Gongetal.,
Minecraft.(Huangetal.,2022b;Yuanetal.,2023;
2023). DEPSfurtherextendedthisclosed-loopin-
Wangetal.,2023c,a;Zhuetal.,2023)OurVillager-
teractionbyintroducingdescription,explainerand
BenchleveragesMinecraft’sAPItocreatedomains
selector (Wang et al., 2023c). AgentVerse struc-
thatmimicreal-worldtasks,facilitatingmulti-agent
turesitssystemintorecruitment,decision-making,
systemevaluationandresearchadvancement.
execution, and evaluation, optimizing group per-
formance(Chenetal.,2023). MetaGPTadoptsan
assembly line method, assigning roles to stream-
linetaskcompletion(Hongetal.,2023). However, 6 Conclusion
theseframeworksoftenfacelimitationsintaskflex-
ibilityandscalability(Gongetal.,2023;Chenetal.,
In this study, we introduce VillagerBench, a
2023;Hongetal.,2023). OurVillagerAgentframe-
Minecraftmulti-agentbenchmarkplatform. Wede-
workimprovescollaborativeefficiencyforcomplex
signthreedistinctscenarioswithinVillagerBench
tasksbymodelingtaskgraphs.
to evaluate collaborative tasks, aiming to assess
LLM-as-Agent Benchmarks. Recent studies theperformanceofourVillagerAgentframework.
highlightthepotentialofLargeLanguageModels OurframeworkemploysDirectedAcyclicGraphs
(LLMs)asagentscapableoftooluse(Wangetal., (DAG)todecomposetasks,enablingefficientand
2023b; Xi et al., 2023). Emerging benchmarks coordinated execution by agents. We benchmark
aim to rigorously evaluate these models’ perfor- thecoordinationskillsofthreeLLMsusingthese
mance (Liu et al., 2023; Xu et al., 2023; Carroll metrics and demonstrate the effectiveness of our
etal.,2020;Huangetal.,2023;Wuetal.,2023b; VillagerAgent framework. We also explore how
Ruanetal.,2023). MCU(Linetal.,2023)discusses agentcountandcapabilitydiversityimpactframe-
a method that uses atomic tasks as basic compo- workperformance.Limitations Qin, Yaxi Lu, Ruobing Xie, et al. 2023. Agent-
verse: Facilitatingmulti-agentcollaborationandex-
Our VillagerAgent framework, while improving ploringemergentbehaviorsinagents. arXivpreprint
performance within the Minecraft multi-agent arXiv:2308.10848.
benchmark(VillagerBench),encountersalowover-
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding,
all taskcompletion rate. Thisis partlydue to the
JiezhongQiu,ZhilinYang,andJieTang.2022. Glm:
inherentcomplexityofthebenchmark,whichne- Generallanguagemodelpretrainingwithautoregres-
cessitatestheuseofawidearrayofAPIs,thereby siveblankinfilling.
enlargingtheexplorationspaceandcomplicating
RanGong,QiuyuanHuang,XiaojianMa,HoiVo,Zane
theexecutionoftasks,especiallywhenagentshave
Durante, Yusuke Noda, Zilong Zheng, Song-Chun
variedabilities.
Zhu,DemetriTerzopoulos,LiFei-Fei,andJianfeng
Oneoftheprimarychallengesismanagingagents Gao. 2023. Mindagent: Emergent gaming interac-
with varying capabilities, as it necessitates ad- tion.
vanced coordination and balancing strategies to
SiruiHong,MingchenZhuge,JonathanChen,Xiawu
ensureeffectiveteamwork. Ourframework’sper-
Zheng,YuhengCheng,CeyaoZhang,JinlinWang,
formance diminishes when scaling beyond eight ZiliWang,StevenKaShingYau,ZijuanLin,Liyang
agents,suggestingissueswithresourceallocation Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu,
andJürgenSchmidhuber.2023. Metagpt: Metapro-
and inter-agent communication efficiency. This
grammingforamulti-agentcollaborativeframework.
decline could be attributed to the increased con-
textlengthandthecomplexityofgeneratingtask QianHuang,JianVora,PercyLiang,andJureLeskovec.
graphsforalargernumberofagents,analogousto 2023. Benchmarking large language models as ai
aleaderstrugglingtomanageanexcessivenumber researchagents.
ofworkers.
Wenlong Huang, Pieter Abbeel, Deepak Pathak, and
Challenges in Practice. If our work were to be
Igor Mordatch. 2022a. Language models as zero-
appliedinreal-worldsettings,weanticipatefacing shotplanners: Extractingactionableknowledgefor
challenges such as the complexity of processing embodiedagents.
dynamicinformation,variabilityinagentfailures,
WenlongHuang,FeiXia,TedXiao,HarrisChan,Jacky
and issues with the interpretability of Language
Liang,PeteFlorence,AndyZeng,JonathanTompson,
LearningModels’outputs. Addressingthesechal- IgorMordatch,YevgenChebotar,PierreSermanet,
lenges may become one of the key directions for Noah Brown, Tomas Jackson, Linda Luu, Sergey
furtherresearch. Levine, Karol Hausman, and Brian Ichter. 2022b.
Innermonologue: Embodiedreasoningthroughplan-
ningwithlanguagemodels.
Acknowledgements
Guohao Li, Hasan Abed Al Kader Hammoud, Hani
ThisworkissupportedbytheNationalScienceand
Itani,DmitriiKhizbullin,andBernardGhanem.2023.
TechnologyMajorProject(2022ZD0117802). This Camel: Communicative agents for "mind" explo-
workisalsosupportedbytheGeneralProgramof ration of large language model society. In Thirty-
seventhConferenceonNeuralInformationProcess-
theNationalNaturalScienceFoundationofChina
ingSystems.
(62372403).
HaoweiLin,ZihaoWang,JianzhuMa,andYitaoLiang.
2023. Mcu: A task-centric framework for open-
References endedagentevaluationinminecraft.
2023. Gemini: Afamilyofhighlycapablemultimodal XiaoLiu,HaoYu,HanchenZhang,YifanXu,Xuanyu
models. Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen
Men,KejuanYang,ShudanZhang,XiangDeng,Ao-
2023. Gpt-4technicalreport. han Zeng, Zhengxiao Du, Chenhui Zhang, Sheng
Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie
Micah Carroll, Rohin Shah, Mark K. Ho, Thomas L. Huang, Yuxiao Dong, and Jie Tang. 2023. Agent-
Griffiths,SanjitA.Seshia,PieterAbbeel,andAnca bench: Evaluating llms as agents. arXiv preprint
Dragan. 2020. On the utility of learning about hu- arXiv: 2308.03688.
mansforhuman-aicoordination.
PrismarineJS. 2013. Prismarinejs/mineflayer: Create
Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, minecraftbotswithapowerful,stable,andhighlevel
Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia javascriptapi.Chen Qian, Xin Cong, Wei Liu, Cheng Yang, Weize LinXu,ZhiyuanHu,DaquanZhou,HongyuRen,Zhen
Chen,YushengSu,YufanDang,JiahaoLi,Juyuan Dong,KurtKeutzer,SeeKiongNg,andJiashiFeng.
Xu,DahaiLi,ZhiyuanLiu,andMaosongSun.2023a. 2023. Magic: Benchmarkinglargelanguagemodel
Communicativeagentsforsoftwaredevelopment. powered multi-agent in cognition, adaptability, ra-
tionality and collaboration. arXiv preprint arXiv:
Chen Qian, Yufan Dang, Jiahao Li, Wei Liu, Weize 2311.08562.
Chen, Cheng Yang, Zhiyuan Liu, and Maosong
Sun. 2023b. Experiential co-learning of software- Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
developingagents. Shafran,KarthikNarasimhan,andYuanCao.2023.
React: Synergizingreasoningandactinginlanguage
Yangjun Ruan, Honghua Dong, Andrew Wang, Sil- models.
viuPitis,YongchaoZhou,JimmyBa,YannDubois,
ChrisJ.Maddison,andTatsunoriHashimoto.2023. Haoqi Yuan, Chi Zhang, Hongcheng Wang, Feiyang
Identifying the risks of lm agents with an lm- Xie,PenglinCai,HaoDong,andZongqingLu.2023.
emulatedsandbox. Skillreinforcementlearningandplanningforopen-
worldlong-horizontasks.
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Man-
dlekar,ChaoweiXiao,YukeZhu,LinxiFan,andAn- Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang,
imaAnandkumar.2023a. Voyager: Anopen-ended Guanghe Li, Yihang Sun, Cheng Zhang, Zhaowei
embodiedagentwithlargelanguagemodels. Zhang, AnjiLiu, Song-ChunZhu, XiaojunChang,
JungeZhang,FengYin,YitaoLiang,andYaodong
LeiWang,ChenMa,XueyangFeng,ZeyuZhang,Hao
Yang.2024. Proagent: Buildingproactivecoopera-
Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang,
tiveagentswithlargelanguagemodels.
XuChen,YankaiLin,WayneXinZhao,ZheweiWei,
andJi-RongWen.2023b. Asurveyonlargelanguage XizhouZhu,YuntaoChen,HaoTian,ChenxinTao,Wei-
modelbasedautonomousagents. jieSu,ChenyuYang,GaoHuang,BinLi,LeweiLu,
Xiaogang Wang, Yu Qiao, Zhaoxiang Zhang, and
Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu,
Jifeng Dai. 2023. Ghost in the minecraft: Gener-
Xiaojian Ma, and Yitao Liang. 2023c. Describe,
allycapableagentsforopen-worldenvironmentsvia
explain, plan and select: Interactive planning with
large language models with text-based knowledge
largelanguagemodelsenablesopen-worldmulti-task
andmemory.
agents.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,BrianIchter,FeiXia,EdChi,QuocLe,and
DennyZhou.2023. Chain-of-thoughtpromptingelic-
itsreasoninginlargelanguagemodels.
Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu,
Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang,
ShaokunZhang,JialeLiu,AhmedHassanAwadal-
lah, Ryen W White, Doug Burger, and Chi Wang.
2023a. Autogen: Enablingnext-genllmapplications
viamulti-agentconversation.
Yue Wu, Xuan Tang, Tom M. Mitchell, and Yuanzhi
Li. 2023b. Smartplay: A benchmark for llms as
intelligentagents.
ZhihengXi,WenxiangChen,XinGuo,WeiHe,Yiwen
Ding, Boyang Hong, Ming Zhang, Junzhe Wang,
Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan,
Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran
Wang, Changhao Jiang, Yicheng Zou, Xiangyang
Liu,ZhangyueYin,ShihanDou,RongxiangWeng,
WensenCheng, QiZhang, WenjuanQin, Yongyan
Zheng,XipengQiu,XuanjingHuang,andTaoGui.
2023. Theriseandpotentialoflargelanguagemodel
basedagents: Asurvey.
TianbaoXie,FanZhou,ZhoujunCheng,PengShi,Lu-
oxuanWeng,YitaoLiu,TohJingHua,JunningZhao,
QianLiu,CheLiu,LeoZ.Liu,YihengXu,Hongjin
Su, Dongchan Shin, Caiming Xiong, and Tao Yu.
2023. Openagents: Anopenplatformforlanguage
agentsinthewild.A Metrics
A.1 TaskNodeGraphrelevantalgorithm
Convert subtask node set to Graph. Since
LLMsareautoregressive,theiroutputsforsubtasks
Algorithm1ConvertTaskListtoGraph
oftenexhibitcausalrelationships. Leveragingthis,
wecanassumethatagivenpromptsuggestssubse- 1: G ← (V,E)withV ← ∅,E ← ∅
quentsubtasksdependonorrunconcurrentlywith 2: L ← [N 1,N 2,...,N n] ▷Inputlist
earlier ones, forming the basis for transforming 3: fori ← 1tondo
themintoagraph. 4: V ← V ∪{N i} ▷Addelementasanode
Task Decomposer construct graph using algo- 5: ifP(N i) ̸= ∅then
rithm 1 to connect nodes representing subtasks: 6: forallp j ∈ P(N i)do
7: E ← E ∪{(p j,N i)} ▷Addedges
frompredecessors
1. Initialize the graph G with an empty set of 8: endfor
vertices V, an empty set of edges E and 9: elseifi > 1then
the input list of subtask nodes L containing 10: forallp k ∈ P(N i−1)do
N 1,N 2,...,N n. 11: E ← E ∪{(p k,N i)} ▷Share
predecessorswithpreviouselement
2. IterateovereachnodeN inthelistL,where
i 12: endfor
i ranges from 1 to n. Then add the current
13: endif
nodeN tothevertexsetV.
i 14: endfor
3. CheckifthecurrentnodeN haspredecessor
i
nodesP(N ):
i
• If N has predecessors, for each prede-
i
cessor node p , add an edge from p to
j j
N totheedgesetE.
i
• IfN doesnothavepredecessorsandi >
i
1, implying it may share predecessors
with the previous node N , for each
i−1
predecessor of N , p , add an edge
i−1 k
Algorithm2FindReady-to-ExecuteTasks
fromp toN totheedgesetE.
k i
Require: G = (V,E) ▷Taskgraphwithnodes
4. Repeatsteps2and3untilallnodesinthelist
andedges
havebeenprocessed.
Require: S ⊆ V ▷Setofsuccessfullyexecuted
tasks
A.2 ConstructionTaskCompleteRate(C) Require: U ⊆ V ▷Setofunexecutedtasks
ConstructionTaskCompleteRate. quantifies 1: R ← ∅ ▷Resultsetofready-to-executetasks
thealignmentoftheconstructedstructurewiththe 2: forallN i ∈ U do
providedblueprint. Itisdefinedastheratioofcor- 3: P(N i) ← {p j | (p j,N i) ∈ E} ▷Find
predecessorsofN
rectlyplacedblockstothetotalnumberofblocks i
specifiedbytheblueprint. AhigherC indicatesa 4: ifP(N i) = ∅orP(N i) ⊆ S then
closermatchtotheintendeddesign,reflectingthe 5: R ← R∪{N i} ▷Addifno
predecessorsorallpredecessorsexecuted
agents’abilitytoaccuratelyinterpretandexecute
theconstructionplan. 6: endif
7: endfor
|P (x,y,z,θ,ϕ)∩B (x,y,z,θ,ϕ)| 8: returnR
C = (5)
|B |
(x,y,z,θ,ϕ)
Here, P represents the set of placed blocks, and
B represents the set of blocks in the blueprint. θ
denotesfacingandϕdenotesaxis.Figure7: LivedemonstrationofagentsperformingtasksinVillagerBenchscenarios.
A.3 ConstructionDependencyComplexity(D)
(cid:18) (cid:19)
σ−σ
min
B (cid:18) (cid:19) S = 1− (9)
(cid:88) 1 cc σ −σ
D = +W (H −G) +D (6) max min
h i i
EP
i=1 i Here,nisthenumberofagents,I ∈ Rn,I isthe
i
Here,EP representstheeffectivepathofoneblock contributionofitemagentiprovides,andthenwe
toplacethroughthenearbyblocks,Bisthenumber standardizethescore.
of blocks, H is the height of the block, G is the
A.6 Farm-to-TableDependencyComplexity
groundheight,andD istheblockdigscoreifthis
blockneedstobedugfromthefactory. Farm-to-TableCookingDependencyComplex-
ity(D).
A.4 Farm-to-TableCookingCompletionRate n
(cid:88)
D = m ×d (10)
CompletionRate(C) quantifiestheleveloftask i i
completionbasedonthematerialsacquiredandthe i=1
actionsperformed: wherem representsthedirectmaterialsrequired
i
forcraftingthetargetfooditem,andd denotesthe
i
n m
(cid:88) (cid:88) number of processing steps required to obtain or
C = S + S (7)
rawi actionj synthesize the material m within the context of
i
i=1 j=1
thetask.
Here, S rawi is the score of the i-th raw material Inthisformulation, m i isthequantityofeachdi-
and S actionj is the score for the j-th action that rect material, and d i reflects the depth of the de-
contributestotaskprogress. pendency chain for each material, indicating the
complexityoftheprocessneededtoacquireit. The
A.5 Farm-to-TableAgentContributionRate productofm andd foreachmaterialissummed
i i
toyieldtheoveralldependencycomplexityofthe
AgentContributionRate(ACR). Thecontribu-
cookingtask.
tionscoreforeachagentwithrespecttoaspecific
materialisdefinedasfollows:
A.7 EscapeRoomChallengeCompletionRate
TheoverallACRforthetaskisthencalculatedby
aggregatingthecontributionsofallagentsforall CompletionRate(C).
requiredmaterials:
(cid:80)n (cid:0)ci
×S
(cid:1)
C = i=1 m i (11)
(cid:118)
(cid:117) (cid:117)1 (cid:88)n
(cid:80)n
i=1S i
σ = (cid:116) (I i−I avg)2 (8)
n Here,nisthenumberoftasks,c isthenumberof
i=1 i
conditionsthathavebeenmetfortaski,andS is
i
Thecooperationlevelcanthenbecalculatedas: thescoreobtainedfortaski.ConstructionAvg.Score completeoncethestructurematchestheblueprint
Config
specifications.
C(%) VHR(%) E(%/min) B(%)
Task 1p 100 100 12.96 -
0 GivenAPIs. ThefollowingAPIsareprovidedto
Task 2p 100 100 17.75 93.09
0
Task 4p 100 100 17.41 81.64 facilitatetheconstructionprocesswithinthegame.
0
Task 08p 66.63 63.33 12.45 55.67 Thesefunctionsallowtheagenttointeractwiththe
Task 1p 35.25 36.25 1.92 -
64 gameworld,suchasplacingandfetchingblocks,
Task 2p 41.67 35.62 2.34 90.77
64
Task 4p 46.67 39.38 3.28 88.91 navigatingtospecificlocations:
64
Task 8p 30.21 33.33 2.27 74.09
64
Agent.placeBlock
Table6:Evaluationontaskexecutionefficiencywithdif- Agent.fetchContainerContents
ferentagentquantities. TheBalancedAgentUtilization Agent.MineBlock
Score(B)isinapplicableforasingle-playerscenario.
Agent.scanNearbyEntities
Agent.equipItem
Agent.navigateTo
A.8 EscapeRoomChallengeDependency
Agent.withdrawItem
Complexity(D)
Agent.dismantleDirtLadder
The Escape Room Challenge Dependency Com-
Agent.erectDirtLadder
plexity(D)iscalculatedrecursivelyusingabreadth-
Agent.handoverBlock
first search approach, starting from the exit. The
complexityofeachroomisdeterminedbythenum- Blueprint. Theblueprintspecifiestheexactma-
berofconditionsthatmustbemettopassthrough terials and their respective positions required to
it. The complexity for the entire challenge is the constructthestructure. Eachlineintheblueprint
cumulative sum of the complexities of all rooms representsadifferentcomponentofthestructure,
encountered during the search. The formula for detailingthetypeofmaterial,itsorientation,and
calculating the dependency complexity (D) is as the coordinates where it should be placed. The
follows: followingistheblueprintthatmustbefollowedto
completethetask:
n
(cid:88)
D = c (12) "task_24": [
i
i=1 "[material:grass_block facing: None
positions:[start:[-9 -60 -1] end:...",
where c represents the complexity of room i,
i
"[material:oak_trapdoor facing:E
whichisthenumberofconditionsrequiredtopass
positions:[[-8 -60 -1] [-8 -60 0]]
thatroom. Thesumistakenoverallroomsnthat
material:oak_trapdoor facing:S ...]",
areencounteredinthebreadth-firstsearchfromthe
"[material:oak_trapdoor facing:W
exittotheentranceoftheescaperoomchallenge.
positions:[[-10 -60 -1] [-10 -60 0]]",
Thisapproachensuresthattheoverallcomplexity
"[material:oak_trapdoor facing:N
reflectsthedependenciesandrequirementsofeach
position:[-9 -60 -2]]",
roomwithinthecontextoftheescapescenario.
"[material:oxeye_daisy facing: None
B TaskIllustrations position:[-9 -59 0]]",
"[material:poppy facing: None
B.1 ConstructionwithBlueprints position:[-9 -59 -1]]",
"[material:dandelion facing: None
TaskDescription. Inthistask,participantsarere-
position:[-9 -59 1]]"
quiredtoworkcollaborativelytoconstructastruc-
],
tureinthegameMinecraft,followingtheprovided
blueprint. The participants have access to two
B.2 Farm-to-TableCooking
chests: one chest contains a variety of building
materials,whiletheotherchest,locatedwithinthe GivenAPIs. ThefollowingAPIsareavailableto
factory,containstools. However,thetoolsarenot assistparticipantsininteractingwiththevirtualen-
necessaryforthecompletionofthistask. Theob- vironment,whichincludesfetchingcontentsfrom
jective is to accurately replicate the blueprint in containers,miningblocks,scanningnearbyentities,
thegameenvironment,andthetaskisconsidered equippingitems,cooking,navigating,withdrawingitems, crafting, attacking targets, using items on Eachroom,measuring10x10,demandsteamwork
entities,andtransferringblocks: todecipherpuzzlesandnavigatethroughimpedi-
ments. Itisimportanttonotethatagentsmayfind
Agent.fetchContainerContents
themselvesinseparaterooms,wheredirectcollabo-
Agent.MineBlock
rationisnotfeasible. Despitethesecircumstances,
Agent.scanNearbyEntities
itisimperativetoutilizeindividualstrengthsand
Agent.equipItem
workcollectivelytoadvance. Successfulcomple-
Agent.SmeltingCooking
tionofataskinoneroomwillresultintransporta-
Agent.navigateTo
tiontothesubsequentroomorwillclearthepathto
Agent.withdrawItem
proceedbyfoot. Theroomsarearrangedalongthe
Agent.craftBlock
z-axis,withtheircentersspaced10unitsapart. The
Agent.attackTarget
ultimategoalistoreachtheexitlocatedatcoordi-
Agent.UseItemOnEntity
nates(130,-60,-140). Communication,adaptation,
Agent.handoverBlock
andteamworkareessentialtoescape. Wewishyou
Recipes. Therecipesdetailthespecificingredi- thebestofluck!
entsandquantitiesneededtocraftthefooditems.
Belowistherecipeforcraftingrabbitstew,which GivenAPIs. ThefollowingAPIsareprovidedto
requires a combination of baked potato, cooked assist agents in interacting with the environment,
rabbit,abowl,acarrot,andabrownmushroom: whichincludes placing andfetchingblocks, min-
ing,scanningnearbyentities,equippingitems,nav-
{
igating,withdrawingitems,togglingactions,and
"result": {
transferringblocks:
"name": "rabbit_stew",
"count": 1
Agent.placeBlock
},
Agent.fetchContainerContents
"ingredients": [
Agent.MineBlock
{
Agent.scanNearbyEntities
"name": "baked_potato",
Agent.equipItem
"count": 1
Agent.navigateTo
},
Agent.withdrawItem
{
Agent.ToggleAction
"name": "cooked_rabbit",
Agent.handoverBlock
"count": 1
},
{ Room Sign Hints. The escape room challenge
"name": "bowl", provides hints through signs placed within each
"count": 1 room. Agentscanreadthenearbysigntexttogain
}, cluesforsolvingtheroom’spuzzle. Onesuchhint
{ isasfollows:
"name": "carrot",
"count": 1 Step on all the pressure plates at the
}, same time to clear the stone blocks and
{ open the trapdoors for escape.
"name": "brown_mushroom",
"count": 1 In each room the agent can get nearby
} sign text. Around you, the key activated
] blocks are: a oak_pressure_plate block
} set at position [130, -60, 131] powered.
You have done the task in this room.
B.3 EscapeRoom
Task Description. Agents, you are presented Move to x=130, y=-60, z=137 to continue.
with a cooperative multi-stage escape challenge. You are at task room [130, -60, 131].C ExperimentConfiguration talkTo: Talktoanentity.
handoverBlock: Hand over an item to another
C.1 ContextLength
player.
Throughout the testing process, the total length
of context tokens does not exceed 4,000, and the
lengthofthesubsequenttextdoesnotexceed1,024 E.3 ItemManagement
tokens. Theconfigurationsforthetestsareas(Ta- equipItem: Equipaspecificitemtoadesignated
ble7) slot.
tossItem: Tossaspecificamountofitems.
D QualitativeAnalysis
withdrawItem: Withdrawitemsfromacontainer.
storeItem: Storeitemsinacontainer.
WithintheAgentVerseframework,duringthedis-
openContainer: Openthenearestcontainer.
cussionphase,Aliceexhibitsclearhallucinations
closeContainer: Closeacontainer.
in the first round, mistakenly believing that she
fetchContainerContents: Fetchdetailsofspecific
hasalreadysearchedthechestandgeneratedficti-
itemsinacontainer.
tiousfeedback. Basedonthisfabricatedfeedback,
ourprovidedBaseAgentAliceinfersthatshecan
handoverthebuckettoBobtocompletethesubse-
E.4 ProductionandCrafting
quenttasks. However,thebuckethasnotactually
MineBlock: Mineablockataspecificlocation.
beencollected. Thisprocessillustrateshowhallu-
placeBlock: Placeablockataspecificlocation.
cinationsinAgentVersecangraduallyescalateand
craftBlock: Craftitemsatacraftingtable.
impactthestabilityoftheentiredecision-making
SmeltingCooking: Cook or smelt items in a
process. (Figure8)
furnace.
Ourapproach,VillagerAgent,employscentralized
enchantItem: Enchant items at an enchanting
decisioncontrolandcorrectlygeneratessub-tasks
table.
such as collecting wheat and finding sugar dur-
repairItem: Repairitemsatananvil.
ingtheTaskGraphgenerationprocessbytheTask
trade: Tradeitemswithavillager.
Decomposer,issuinginstructionsforparallelexe-
cution.
E.5 LifeSkills
E VillagerBenchAPILibrary
sleep: Gotosleep.
E.1 MovementandNavigation
wake: Wakeup.
scanNearbyEntities: Searchforspecificitemsor eat: Eatfood.
creatureswithinaradius. drink: Drinkabeverage.
navigateTo: Move to a specific coordinate wear: Wearaniteminaspecificslot.
location.
navigateToPlayer: Move to another player’s
E.6 OtherActions
location.
erectDirtLadder: Buildadirtladderataspecified ToggleAction: Operateadoor,lever,orbutton.
locationtoreachhigherplaces. get_entity_info: Getinformationaboutanentity.
dismantleDirtLadder: Dismantleadirtladderat get_environment_info: Getinformationaboutthe
aspecifiedlocation. environment.
layDirtBeam: Placeadirtbeamfromoneposition performMovement: Perform actions like jump,
toanother. move forward, move backward, turn left, turn
removeDirtBeam: Removeadirtbeam. right.
lookAt: Lookatsomeoneorsomething.
startFishing: Startfishing.
E.2 CombatandInteraction
stopFishing: Stopfishing.
attackTarget: Attack the nearest entity with a read: Readabookorsign.
specificname. readPage: Readaspecificpageofabook.
UseItemOnEntity: Use a specific item on a write: Writeonawritablebookorsign.
specificentity.Model TotalTokens OutputTokens Temperature OtherDefaults
GPT-4-1106-preview 128,000 4,096 0 Default
Gemini-Pro 30,720 2,048 0 Default
GLM-4 128,000 >1,024 0.01 Default
Table7: Configurationofmodelsusedintheexperiment.
F VillagerBenchScenarioExamples
Herewepresentlivedemonstrationsoftwoagents
performinganescaperoomchallenge,threeagents
executing a farm-to-table cooking task, and four
agentsengagedinaconstructiontask. (Figure7)
G Prompts
G.1 TaskDecomposer
TheTaskDecomposerutilizestemplate9andtem-
plate10inVillagerBench.
G.2 AgentController
Template11isusedfortheAgentController.
G.3 StateManager
TheStateManageremploystheAgentStateSum-
marytemplate12andtheEnvironmentSummary
template13.
G.4 BaseAgent
The Base Agent uses the Execution template 14
andtheReflecttemplate15.
G.5 AgentVersePrompt
TheconfigurationforAgentVerseisdefinedintem-
plate 16.
G.6 TaskDecomposePrompt
(Overcooked-AI)
The Decompose Prompt for the Overcooked-AI
Benchmarkisoutlinedintemplate 17.VillagerAgent v.s. AgentVerse
Task: Farming_20
Environment: bucket and egg in chest, wheat and sugarcane in farm
Agent num: 2
VillagerAgent AgentVerse
Plan: Discussion:
[ [Alice]: Hey Bob, to make a cake we need 3 buckets of milk, 2 sugar, 1 egg, and 3 wheat.
{ Let's check the chests for these ingredients first. If we don't find them, we'll need to gather
"id": 1, them. How about I focus on getting the milk and wheat, and you focus on finding sugar
"description": "Harvest wheat and craft into and an egg? If we find extra ingredients in the chests, we can adjust our plan accordingly.✅
wheat blocks if necessary", ✅ What do you think?
"milestones": [ [Bob]: Sounds good, Alice. I'll start by checking the chests for sugar and an egg. If I don't find
"Navigate to wheat at [45, -59, 129] and [45, them there, I'll go look for sugarcane to make sugar and search for chickens to get an egg.
-59, 131]", Let's meet back here with the ingredients we've gathered. If we both end up finding some of
"Harvest a total of 3 wheat", the same ingredients, we can share them to make sure we have everything we need. Let's
"Craft wheat into wheat blocks if less than 3 get to it! ✅
wheat is harvested" [Alice]: Bob, I've managed to get the 3 buckets of milk and found 2 wheat in the chests.
], How did your search go? Do you have the sugar and egg? If not, we should split up to find
"retrieval paths": [ the remaining wheat, sugar, and egg. I can go harvest or find another wheat, and if you
"~/meta-data/ingredients/3" haven't found sugar and egg yet, you could continue searching for those. Let's update each
], other on what we still need.❌hallucination: Alice hasn't done it
"required subtasks": [], [Bob]: ...
"assigned agents": ["Alice"]
}, Action:
{ [...]
"id": 2, ✅
"description": "Find sugar cane or honey bottles Discussion:
to craft sugar", [Alice]: Bob, great work on finding the sugar cane and the egg. Since you've got the sugar
"milestones": [ cane, could you please craft the 2 additional sugar we need? Also, since you found iron
"Scan for sugar cane or honey bottles in the ingots, please craft the third bucket. I'll go ahead and collect the 3 wheat from the farm now.
environment or chests", Once we have all the ingredients, we can start making the cake. Let me know once you've
"Navigate to the location of sugar cane or honey crafted the sugar and the bucket. ❌hallucination: no iron ingots in chest
bottles", [Bob]: Alice, I'm on it. I'll craft the 2 additional sugar from the sugar cane and then use the
"Collect or withdraw 2 sugar canes or honey iron ingots to craft the third bucket. After that, I'll have all the items we need from my side. I'll
bottles", wait for you to collect the wheat, and then we can combine our ingredients to make the cake.
"Craft 2 sugars from the collected items" I'll let you know as soon as I've finished crafting. Let's keep up the good work!
], [Alice]: ...
"retrieval paths": [ [Bob]: ...
"~/meta-data/ingredients/1",
"~/meta-data/ingredients/2" Action:
], [...]
"required subtasks": [], {
"assigned agents": ["Bob"] "action": "handoverBlock",
} "action_input": {
] "item_name": "milk_bucket",
"item_count": 3,
Action: ...
[...] }
}
Observation: {'message': "Bob don't have enough milk_bucket in inventory", 'status':
False}
Figure 8: VillagerAgent v.s. AgentVerse: The hallucination in AgentVerse began at the discussion stage and
eventuallyextendeditsinfluencetotheexecutionstage.Task Decompose Prompt
SYSTEM
Your current mission is to leader all the players and execute a set of specified tasks within the Minecraft environment.
--- Background Information ---
Our system manages the task as a Directed Acyclic Graph (DAG).
In this turn, you need to decompose the tasks and arrange them in chronological order. Next turn we will analyse your result json to a graph.
A subtask-structure has the following json component:
{
"id": int, id of the subtask start from 1,
"description": string, description of the subtask, more detail than a name, for example, place block need position and facing, craft or collect items need
the number of items.
"milestones": list[string]. Make it detailed and specific,
"retrieval paths": list[string], [~/...] task data is a dict or list, please give the relative path to the data, for example, if the data useful is {"c": 1} dict is
{"meta-data": {"blueprint": [{"c": 1}, ]}}, the retrieval path is "~/meta-data/blueprint/0",
"required subtasks": list[int], if this subtask is directly prerequisite for other subtasks before it, list the subtask id here.
"candidate agents": list[string], name of agents. dispatch the subtask to the agents.
}
*** Important Notice ***
- The system do not allow agents communicate with each other, so you need to make sure the subtasks are independent.
- Sub-task Dispatch: Post decomposition, the next step is to distribute the sub-tasks amongst yourselves. This will require further communication, where you
consider each player's skills, resources, and availability. Ensure the dispatch facilitates smooth, ** parallel ** execution.
- Task Decomposition: These sub-tasks should be small, specific, and executable with MineFlayer code, as you will be using MineFlayer to play MineCraft.
The task decomposition will not be a one-time process but an iterative one. At regular intervals during playing the game, agents will be paused and you will
plan again based on their progress. You'll propose new sub-tasks that respond to the current circumstances. So you don't need to plan far ahead, but make
sure your proposed sub-tasks are small, simple and achievable, to ensure smooth progression. Each sub-task should contribute to the completion of the
overall task. That means, the number of sub-tasks should no more than numbers of agents. When necessary, the sub-tasks can be identical for faster task
accomplishment. Be specific for the sub-tasks, for example, make sure to specify how many materials are needed.
- In Minecraft, item can be put in agent's inventory, chest, or on the ground. You can use the item in agent's inventory or chest, but you can not use the item
on the ground unless you dig it up first.
- The block at lower place should be placed first, and the block at higher place should be placed later. [x,-60,z] is the lowest place. For example, if a task is
placing block at x -57 z, then y -60, -59 and -58 should be placed first and in order.
- Integration and Finalization: In some tasks, you will need to integrate your individual efforts. For example, when crafting complicated stuff that require
various materials, after collecting them, you need to consolidate all the materials with one of players.
- You can stop to generate the subtask-structure json if you think the task need the information from the environment, and you can not get the information
from the environment now.
USER
This is not the first time you are handling the task, so you should give part of decompose subtask-structure json feedback. Here is the query:
"""
the environment information around:
{env}
The high-level task:
{task}
Agent ability: (This is just telling you what the agent can do in one step, subtask should be harder than one step)
{agent_ability}
"""
Your response should exclusively include the identified sub-task or the next step intended for the agent to execute.
So, {num} subtasks is the maximum number of subtasks you can give.
Response should contain a list of subtask-structure JSON.
Figure9: TaskDecomposerPromptTemplateRedecompose Prompt
SYSTEM
Your current mission is to leader all the players and execute a set of specified tasks within the Minecraft environment.
--- Background Information ---
Our system manages the task as a Directed Acyclic Graph (DAG).
In this turn, you need to decompose the tasks and arrange them in chronological order. Next turn we will analyse your result json to a graph.
A subtask-structure has the following json component:
{
"id": int, id of the subtask start from 1,
"description": string, description of the subtask, more detail than a name, for example, place block need position and facing, craft or collect items need
the number of items.
"milestones": list[string]. Make it detailed and specific,
"retrieval paths": list[string], [~/...] task data is a dict or list, please give the relative path to the data, for example, if the data useful is {"c": 1} dict is
{"meta-data": {"blueprint": [{"c": 1}, ]}}, the retrieval path is "~/meta-data/blueprint/0",
"required subtasks": list[int], if this subtask is directly prerequisite for other subtasks before it, list the subtask id here.
"candidate agents": list[string], name of agents. dispatch the subtask to the agents.
}
*** Important Notice ***
- The system do not allow agents communicate with each other, so you need to make sure the subtasks are independent.
- Sub-task Dispatch: Post decomposition, the next step is to distribute the sub-tasks amongst yourselves. This will require further communication, where you
consider each player's skills, resources, and availability. Ensure the dispatch facilitates smooth, ** parallel ** execution.
- Task Decomposition: These sub-tasks should be small, specific, and executable with MineFlayer code, as you will be using MineFlayer to play MineCraft.
The task decomposition will not be a one-time process but an iterative one. At regular intervals during playing the game, agents will be paused and you will
plan again based on their progress. You'll propose new sub-tasks that respond to the current circumstances. So you don't need to plan far ahead, but make
sure your proposed sub-tasks are small, simple and achievable, to ensure smooth progression. Each sub-task should contribute to the completion of the
overall task. That means, the number of sub-tasks should no more than numbers of agents. When necessary, the sub-tasks can be identical for faster task
accomplishment. Be specific for the sub-tasks, for example, make sure to specify how many materials are needed.
- In Minecraft, item can be put in agent's inventory, chest, or on the ground. You can use the item in agent's inventory or chest, but you can not use the item
on the ground unless you dig it up first.
- The block at lower place should be placed first, and the block at higher place should be placed later. [x,-60,z] is the lowest place. For example, if a task is
placing block at x -57 z, then y -60, -59 and -58 should be placed first and in order.
- Integration and Finalization: In some tasks, you will need to integrate your individual efforts. For example, when crafting complicated stuff that require
various materials, after collecting them, you need to consolidate all the materials with one of players.
- You can stop to generate the subtask-structure json if you think the task need the information from the environment, and you can not get the information
from the environment now.
USER
This is not the first time you are handling the task, so you should give a decompose subtask-structure json feedback. Here is the query:
"""
the environment information around:
{env}
agent state:
{agent_state}
success previous subtask tracking:
{success_previous_subtask}
failure previous subtask tracking:
{failure_previous_subtask}
Agent ability: (This is just telling you what the agent can do in one step, subtask should be harder than one step)
{agent_ability}
The high-level task
{task}
"""
Your response should exclusively include the identified sub-task or the next step intended for the agent to execute.
So, {num} subtasks is the maximum number of subtasks you can give.
Response should contain a list of subtask-structure JSON.
Figure10: TaskREDecomposePromptTemplateController Prompt
SYSTEM
You are the Global Controller for Minecraft game agents. Your task is to assign tasks to agents. Create a plan that assigns tasks to suitable agents and
return a list of task-assignment JSON objects.
USER
**Background Information:**
Your objective is to select tasks and allocate them to appropriate agents based on specific criteria. Each task requires a set number of agents for
completion, as indicated by the task's "number." Only agents listed as candidates for a task are eligible to perform it. It's crucial to ensure that no agent is
assigned to more than one task at any given time.
When assigning tasks, consider the following factors:
1. **Agent's Current State:** This includes the agent's location, items in possession, health status, etc.
2. **Task Requirements:** Necessary items, task location, and other specific needs.
3. **Agent's Experience:** Previous tasks completed and overall performance history.
4. **Agent's Abilities:** Skills and capabilities relevant to the task.
**Resources Provided:**
- **Minecraft Game Environment:** `{env}`
- **Agent Experience Records:** `{experience}`
- **Current Agent States:** `{agent state}`
- **List of Available Agents:** `{free agent}`
- **List of Tasks:** `{tasks}`
**Assignment Objective:**
You are to match tasks with suitable agents from the available list and produce a series of task-assignment JSON objects. The JSON format should be as
follows:
```json
{
"reason": "Explanation of the selection process, detailing why the agent is fit for the task based on their current state and held items.",
"task_id": "The ID of the selected task.",
"agent": "Names of agents assigned to the task."
}
```
**Key Instructions:**
- Provide a step-by-step reasoning for each task assignment.
- Ensure each task is assigned to the exact number of agents required, with all agents being from the task's candidate list.
- Aim to minimize the number of unassigned agents, adhering to the rules stated above.
**Response Format:**
Submit your response as a list of task-assignment JSON objects.
Figure11: AgentControllerPromptTemplateAgent State Update Prompt
SYSTEM
You are a helpful assistant in Minecraft.
USER
You are {name}. Your task is to create a concise running summary of actions and information results in the provided text, focusing on key and potentially
important information to remember.
You will receive the current summary and the your latest actions. Combine them, adding relevant key information from the latest development in 1st person
past tense and keeping the summary concise.
The subject of the sentence should be {name}.
Summary So Far:
{summary_so_far}
Latest Development:
{latest_development}
Your Summary:
Figure12: StateManagerAgentStateUpdatePrompt
Environment Summary Prompt(one shot)
SYSTEM
You are a helpful assistant in Minecraft.
Based on the environment info and the task, extract the key information and summarize the environment info in a concise and informative way.
You should focus on the entities, blocks, and creatures in the environment, and provide a summary of the environment info.
USER
The environment info:
{"person_info": [{"name": "Tom", "position": [-1, -59, 1], "held_items": {"spruce_planks": 1}}], "blocks_info": [{"spruce_planks": [-3, -60, 0]}, {"grass_block": [-2,
-61, 0]}, {"chest": [-4, -60, 0], "facing": "W"}, {"oak Log": [-3, -61, 0]}, {"birch_slab": [-3, -60, -1]}, {"birch_slab": [-3, -60, 1]}, {"dirt": [-2, -62, 0]}, {"grass_block":
[-2, -61, -1]}, {"grass_block": [-2, -61, 1]}, {"crafting_table": [-4, -60, -1]}, {"facing": "W", "furnace": [-4, -60, 1]}, {"stone_pressure_plate": [-3, -60, 2]}],
{"juggle_button": [-3, -60, 3]}], "time": "sunrise"},
nearby_entities': [{'Alice': [42, -59, 125], 'other_entity': 'Alice'}, {'pig': [-3, -59, 0]}, {'pig': [-3, -59, 2]}]
*** The task *** : cook meat in the Minecraft.
The summary of the environment info:
Entity: Tom is located at position [-1, -59, 1] and is holding one spruce plank, Alice is located at position [42, -59, 125].
Blocks: a chest at [-4, -60, 0] facing west, a furnace at [-4, -60, 1] and other bloces.
Creatures: two pigs at [-3, -59, 0] and [-3, -59, 2].
Interactive-Items: a stone pressure plate at [-3, -60, 2], a juggle button at [-3, -60, 3].
The environment info:
{environment_info}
*** The task *** : {task}.
Return with Entity, Blocks, Creatures and Interactive-Items, and give all these position of these blocks and entities like chest, crafting table, furnace, animals,
and plants.
Figure13: StateManagerEnvironmentSummaryPromptAgent Prompt
*** The relevant data of task(not environment data)***
{relevant_data}
*** Other agents team with you ***
{other_agents}
*** {agent_name}'s state ***
{agent_state}
*** The agent's actions in the last time segment partially ***
{agent_action_list}
*** environment ***
{env}
*** The minecraft knowledge card ***
{minecraft_knowledge_card}
*** The task description ***
=====================
*** Task ***
{task_description}
*** milestone ***
{milestone_description}
At least two Action before the Final Answer.
Figure14: BaseAgentExecutionPrompt
Reflect Prompt
SYSTEM
You are in a Minecraft world. You are a agent player. You need to use the action history compared with the task description and the milestone description to
check whether the task is completed.
The check-strucutre
{
"reasoning": str, # the reasoning process
"summary": str, # the summary of the vital information of action history with detailed position number and other parameters, which not included in task
description.
"task_status": bool, # whether the task is completed
}
USER
Now you have tried to complete the task.
The task description is:
{task_description}
The milestone description is:
{milestone_description}
The action history is:
{state}
{action_history}
Please check whether the task is completed and return a check-strucutre json.
Figure15: BaseAgentReflectPromptAgentVerse Config
YAML TEMPLATE
prompts:
prompt: &prompt |-
# Role Description
You are an experienced MineCraft player. ${role_description}
Your current mission is to team up with other players and execute a set of specified tasks within the Minecraft environment.
# Requirements
It is essential that you effectively coordinate with other players to ensure the successful completion of tasks in a highly efficient manner. This collaboration
should be achieved through the following steps:
- Communication: Engage in open dialogue, discussing the specifics of the high-level task to make the goal more specific.
- Task Decomposition: After understanding the task in its entirety, you guys need to decompose the high-level task into smaller, manageable sub-tasks.
These sub-tasks should be small, specific, and executable with MineFlayer code, as you will be using MineFlayer to play MineCraft. The task decomposition
will not be a one-time process but an iterative one. At regular intervals during playing the game, you'll be paused and should discuss with others again based
on your progress. You'll propose new sub-tasks that respond to the current circumstances. So you don't need to plan far ahead, but make sure your
proposed sub-tasks are small, simple and achievable, to ensure smooth progression. Each sub-task should contribute to the completion of the overall task,
and each of you should take one subtask. That means, the number of sub-tasks should be 2. When necessary, the two sub-tasks can be identical for faster
task accomplishment. You don't need to always agree with the decomposition proposed by other players. You can propose a more reasonable one when you
find the decomposition not good. Be specific for the sub-tasks, for example, make sure to specify how many materials are needed.
- Sub-task Dispatch: Post decomposition, the next step is to distribute the sub-tasks amongst yourselves. This will require further communication, where
you consider each player's skills, resources, and availability. Ensure the dispatch facilitates smooth, ** parallel ** execution.
- Integration and Finalization: In some tasks, you will need to integrate your individual efforts. For example, when crafting complicated stuff that require
various materials, after collecting them, you need to consolidate all the materials with one of you. For these specific tasks, it is essential to discuss who
should drop their items in inventory and who should collect them to reach the final goal. For other tasks that can be done completely parallal, this step can
be ignored.
# Task Description
The high-level task: ${goal}
# Relevant Recipes
{{recipe}}
# Reminder
Remember, the key to achieving high efficiency as a group is maintaining a constant line of communication, cooperation, and coordination throughout the
entire process. Now you should discuss with the other player. There will be 4 rounds for you guys to discuss the sub-tasks and the assignment at discussion
phase. ** DO NOT imagine that you have achieved anything that is not mentioned in the chat history or have obtained anything that does not in your
inventory. ** What will you, ${agent_name}, say now? Your response should only contain the words of ${agent_name}.
# Chat History
Below is the chat history among players:
[Before Game Start. Discussion Phase.]
${chat_history}
${env_description}
[${agent_name}]:
# - Progress Monitoring and Sub-task Update: After you have made some progress, you can inform other players what you have achieved, and discuss
whether there's a need for sub-task re-assignment or update based on the changing circumstances. Do not imagine that you have achieved something that
is not mentioned in the chat history before game start.
summarization_prompt: &sum_prompt |-
Please review the following chat conversation and identify the specific latest sub-task or the next step that ${agent_name} needs to accomplish.
# Chat Conversation
${chat_history}
# Response Guidelines
Your response should exclusively include the identified sub-task or the next step intended for ${agent_name}. Ensure that you are only extracting the sub-
task or next step designated to ${agent_name}, excluding tasks assigned to other participants. Keep your response succinct and to the point.
For instance, "Gather 3 wood for making pickaxes", "Kill 3 cows", "Drop 4 sticks", "Pickup 4 sticks dropped by xxx". Remember to add the quantifier and
other important information discussed in the conversation.
...
Figure16: AgentVerseConfigDecompose Prompt (Overcooked-AI)
SYSTEM
Your current mission is to leader all the players and execute a set of specified tasks within the Overcooked environment.
--- Background Information ---
Our system manages the task as a Directed Acyclic Graph (DAG).
In this turn, you need to decompose the tasks and arrange them in chronological order. Next turn we will analyse your result json to a graph.
A subtask-structure has the following json component:
{
"id": int, id of the subtask start from 1,
"action": string, name of the action,
"required subtasks": list[int], if this subtask is directly prerequisite for other subtasks before it, list the subtask id here.
"assigned_agent": str, name of agent. dispatch the subtask to the agent.
}
*** Important Notice ***
- The system do not allow agents communicate with each other, so you need to make sure the subtasks are independent.
- Sub-task Dispatch: Post decomposition, the next step is to distribute the sub-tasks amongst yourselves. This will require further communication, where you
consider each player's skills, resources, and availability. Ensure the dispatch facilitates smooth, ** parallel ** execution.
- You can stop to generate the subtask-structure json if you think the task need the information from the environment, and you can not get the information
from the environment now.
- The pot is considered full when there are three onions in it.
- There will be dispensers, pot, serving loc and counters in the kitchen.
- Dispensers and counters are where agent could pick up objects. For example, agent can pick up onions from the onion dispenser.
- The soup will only start cooking when there are three onions in one pot.
- The team needs to put three onions in a pot to start cooking. Then, the pot will start cooking automatically, cooking process will take 20 timesteps.
- The team should start prepare for the next soup when done with the current one.
- agent cannot use move actions and don't use the location information in the observation.
- agent can only pickup and hold one thing at a time. To put the thing down agent is holding , agent should use place_obj_on_counter.
- Pay very close attention to player's states and kitchen states. For example, when agent is holding an onion, agent cannot pickup_onion. When agent has
soup in hand, agent should deliver_soup instantly.
- agent can only pickup dish when a soup is ready.
USER
This is not the first time you are handling the task, so you should give part of decompose subtask-structure json feedback. Here is the query:
"""
the environment information around:
{env}
The high-level task:
{task}
Agent actions: (This is telling you what the agent can do in one step)
{agent_ability}
"""
Your response should exclusively include the identified sub-task or the next step intended for the agent to execute.
So, Each player (Player 0 & Player 1) should have one subtask, you should feedback {num} subtask-structure JSON.
Response should contain a list of subtask-structure JSON.
Figure17: DecomposePrompt(Overcooked-AI)