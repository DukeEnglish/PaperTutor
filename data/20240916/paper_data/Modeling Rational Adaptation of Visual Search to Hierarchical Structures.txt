Modeling Rational Adaptation of Visual Search
to Hierarchical Structures
SakuSourulahti,ChristianPJanssen,JussiPPJokinen
September16,2024
Abstract
Efficientattentiondeploymentinvisualsearchislimitedbyhumanvisual
memory,yetthislimitationcanbeoffsetbyexploitingtheenvironment’sstruc-
ture. This paper introduces a computational cognitive model that simulates
howthehumanvisualsystemusesvisualhierarchiestopreventrefixationsin
sequentialattentiondeployment.Themodeladoptscomputationalrationality,
positingbehaviorsasadaptationstocognitiveconstraintsandenvironmental
structures. Incontrasttoearliermodelsthatpredictsearchperformancefor
hierarchicalinformation,ourmodeldoesnotincludepredefinedassumptions
aboutparticularsearchstrategies.Instead,ourmodel’ssearchstrategyemerges
asaresultofadaptingtotheenvironmentthroughreinforcementlearningalgo-
rithms. Inanexperimentwithhumanparticipantswetestthemodel’spredic-
tionthatstructuredenvironmentsreducevisualsearchtimescomparedtoran-
domtasks.Ourmodel’spredictionscorrespondwellwithhumansearchperfor-
manceacrossvarioussetsizesforbothstructuredandunstructuredvisuallay-
outs.Ourworkimprovesunderstandingoftheadaptivenatureofvisualsearch
inhierarchicallystructuredenvironmentsandinformsthedesignofoptimized
searchspaces.
1 INTRODUCTION
Manydailytasksrequirevisuallylocatingpertinentinformationamidstpotentially
redundant,irrelevant,ordistractingstimuli.Forinstance,findingaspecificemailin
acrowdedinbox,locatingaproductonaclutteredsupermarketshelf,oridentifying
akeyappicononasmartphone’shomescreenarealltasksthatdemandeffective
visual search strategies. This is particularly true for various interactive technolo-
gies,suchascomputerdesktops,mobileapplications,andwebsites,whosedisplays
areoftenfilledwithnumerousvisualelements. Understandinghowhumansman-
agevisualsearchtasksincomplexsearchenvironmentsiscrucialfordesigningsuch
informationspaces. Humansarecompelledtoconductvisualsearchduetothein-
formationprocessinglimitationsofourvisualsystem,whichcanonlyfixateonand
encodeasmall,foveatedsubsetofthefullvisualfieldatanygiventime[13].Topri-
oritizenovelelementsduringsearch,thevisualsystememploysamechanismthat
1
4202
peS
31
]CH.sc[
1v76980.9042:viXramarksandtherebyinhibitsreturningtoelementsalreadysearchedanddiscarded,
preventingredundantfixations[48,62].
Inhibitionofreturnissupportedbyshort-termvisualworkingmemory,which
recordspreviouslyvisitedelementsandtheirfeatures,aidingindirectingattention
tonewelements[24,35,60]. Thisvisualmemorystorageislimited,withthenature
ofmemorycapacityreportedtobebasedondiscreteunits[11,60,32]oracontinu-
ouspoolofresources[33],ortheextensionofinternalmemorytotheexternalenvi-
ronment[59].However,thememorylimitationposesaquestion:Howisitpossible
toefficientlycompleteextensivevisualsearchtaskswhenthenumberofdistractors
farexceedsthecapacityofvisualworkingmemory? Theabilitytoovercomeshort-
termmemorylimitationsduringvisualsearchcanbepartlyattributedtothemind’s
capacitytoformhierarchicalrepresentations[1,18,19,41]. Sincesuchanability
seems possible due to the flexible nature of memory to adapt to structured envi-
ronments, could this behavior emerge as a result of cognition’s adaptation to the
constraintsimposedbytheenvironment?
Thispaperinvestigatesandcomputationallymodelshowthepresenceofper-
ceivablevisualstructuresimpactvisualsearchbehavior.Weproposethathierarchi-
calvisualstructuressimplifythetask’srepresentationalcomplexity,enablingmore
effectiveutilizationoflimitedvisualmemory. Ourmodelcanbeseeninactionin
Figure1,whichshowstwostimulisidebyside. Inthefirststimulus(a),visualele-
mentsarerandomlyarrangedthroughouttheentiresearcharea,resultinginmodel
behavior where search is unstructured and previously marked distractors are re-
visited, therebylimitingefficiency. Thisisduetolimitationsinthemodel’svisual
workingmemorycapacity. Conversely,inataskwheretheelementsareperceptu-
allygrouped(b),model’ssearchprogressesfirstwithin-group,utilizingthelimited
visualworkingmemorytoexhaustthenowsmallernumberoflocalelements,be-
foremovingtoanewgroupofelements. Duetoahierarchicallystructuredvisual
working memory in the model, all elements of the previously searched group are
markedbyvirtueofbelongingtothesamegroup.
AkeyaspectofourmodelisthatthesearchbehaviordepictedinFigure1emerges
naturallyasarationaladaptationtothevisualstructureofthetaskandthelimita-
tionsofvisualworkingmemory. Unlikepredecessormodels,ourdoesnotrequire
explicit programming for search behavior [55, 20]. This approach is grounded in
computationalrationality,whichpositsthatbehavioradaptsrationallytocognitive
constraintsandtheenvironment[14,43]. Inourframework,thesearchagent’sin-
ternalcognitiveenvironmentpossessesahierarchicalstructurecapableofretaining
inshort-termmemoryeitherindividualelementsorgroupsofelements.Themodel
dynamicallyadjuststothehierarchicalnatureofitsmemoryresources,resultingin
asearchstrategythatprioritizesexhaustiveexplorationwithinagroupbeforetran-
sitioningtoothergroups.
Priorcomputationalmodelingofvisualsearchhascoveredabroadrangeofcog-
nitive processes, such as bottom-up salience [22, 23], top-down expectations [38,
49,54,46],andpreattentiveprocesses[21,63,12].Ourresearchcomplementsthese
modelsbydemonstratingthesignificanceofvisualhierarchiesandhowsearchbe-
2Figure 1: The model predicts the how eye movement trajectories adapt to visual
taskstructure. Blackrectanglesareelementsofthelayout,andbluelinesrepresent
the eye movement search path from fixation to fixation in numerical order. Left
(a): searchthroughrandomlyarrangedvisualelements. Right(b): Searchthrough
visuallystructuredelements.
haviors adapt to them. We make two contributions. First, we present evidence
thathumanvisualsearchbehaviorrationallyadaptstohierarchicalvisualstructures
withinthetaskenvironment.Second,ourcomputationalmodeliscapableofsimu-
latingeyemovementtrajectoriesacrossvisualsearchtasks,andassuchoffersatool
forinsilicoevaluationofdesigncandidatesforvarioususerinterfaces.
2 RELATED WORK
2.1 HIERARCHICAL MEMORY STRUCTURE IN VISUAL SEARCH
Extensiveresearchinthefieldofvisualattentionhasconsistentlydemonstratedthat
the preattentive phase of grouping elements significantly enhances the efficiency
of visual search processes. According to Feature-Integration Theory, information
groupingoccursataveryearlystageinthevisualprocess,effectivelyseparatingrel-
evantandirrelevantinformationfromeachotherbeforetheserialsearchprocess
[58,57]. Thisimpliesthatvisualgroupsareperceivedassingleunits,therebyfacili-
tatingthememoryofthegroup’slocation,ratherthanrequiringtheseparatereten-
tionofeachitem’slocationinmemory[8,28,45].
Visualmemoryislimitedinrememberingafixednumberofdiscreteitems’col-
orsandlocationsatthesametime[11,60,32]. However,workingmemoryhaslong
beenshowntoenableanextendedmemorystructureinwhichindividualpiecesof
informationareorganizedintolargerunits, aprocessreferredtoasvisualchunk-
ing[34].Thisenablesmoreefficientperformanceintasksrequiringvisualmemory,
3astask-redundantdetailedinformationcanbecompressedintoseparatecoherent
units[3,5]. Extendedworkingmemory,whichintegratesexternalsingleelements
intomemory,enhancesperceptionbymakingiteasiertorecallgroupedinforma-
tionasasingleunit[65]. Moreover,compressingvisualinformationseemstobea
rationalstrategyforimprovingperceptualperformancetocompensateforthelim-
itations of visual short-term memory [37]. The extensive understanding of visual
memorycapacityanditsflexibilitytodateprovidesaclearpictureofitsabilityto
efficientlydrawoninformationfromtheenvironment.
Computationalmodelsofworkingmemorythusfarwouldsuggestthathuman
attentionseekstooperateefficientlyatthegloballevelofthevisualperception,uti-
lizing a hierarchical memory system [4, 6]. Working memory is more likely com-
prisedofamulti-layeredstructuralrepresentationofvisualperceptionsratherthan
merelyacollectionofindividualitems[4],whichiscrucialforunderstandingthevi-
sualenvironment[6].Invisualperception,employingahierarchicalmemorystruc-
turefacilitatestherapidprocessingofinformation. Thisissupportedbycomputa-
tionalmodelsandwheresubjectshadtosolvethetravelingsalesmanproblemfrom
adisplay[15,30].Thesemodelsachieveoptimalperformanceevenwhenvisualob-
jects are not organized into clear structures, as visual memory naturally tends to
drawonstructuresfromtheenvironment[15,30].Thissuggeststhatthevisualsys-
temsystematicallyseekstheshortesteye-movementpath,optimizingsearchboth
globally acrossgroupsandlocally withineachgroup, tomakeefficientuseofthe
limitedcapacityofvisualmemory[30].
Since it appears that cognition seeks to optimize visual performance through
memory, it is evident that memory must retain elements that have already been
encodedtoreduceunnecessaryrevisitstothesameelements. Thisphenomenon
isalsoknownasInhibitionofReturn,whichreferstothevisualsystem’stendency
to move to a new location to maximize information availability and optimize the
searchpathwithlimitedmemorycapacity[47,48]. Thefindingsindicatethatthe
visualsystemiscapableofinhibiting4-5itemssimultaneously[53,61,11], which
might suggest a limited capacity of memory. In any case, it appears that the IOR
phenomenonhasasignificantimpactonfacilitatingthediscoveryoftheshortest
possiblevisualsearchpath[29].
Given the importance of inhibition of return in optimizing visual search, our
mainhypothesisisthatthevisualsystemstrivestousememoryefficientlytomin-
imizetheencodingofitemsaseffectivelyaspossible. Insteadofattemptingtore-
memberthelocationsofallindividualvisualitemswithlimitedmemorycapacity,
it’s possible to retain only the locations of visual areas in memory. In cognitive
research on visual attention, it has not yet been demonstrated how the cognition
adaptstoleveragevisualstructureswhenthegoalistoachievetheoptimalsearch
performance.Furthermore,researchfieldhasnotyetbeenabletodemonstratehow,
asaresultofadaptations,theincreaseinIORemergesthroughhierarchicalmem-
orytomaximizeencodedareas,especiallywhenthesearchtaskemphasizesvisual
structures.
42.2 MODELS OF VISUAL SEARCH
Computationalmodelingplaysasignificantroleinunderstandingvisualsearch,of-
feringinsightsintothecognitiveprocessesofattentionbypredictingeyemovement
behavior. Visualsearchmodelsvaryaccordingtothetaskgoalandvisualstimuli,
withtheirpredictionsusuallyrelyingontheintegrationofbottom-upandtop-down
processes. Saliencemapmodelsoffersanexplanatoryframeworkforthebottom-
upprocessbydirectingimmediateattentiontovisuallysalientfeaturesthatstand
out[15,16]. Salienceinformationbasedonthephenomenonthatstimulus-based
visualfeaturesinitiallyattractattention,withsignificantvisualelementsthencom-
petingforgazeattention. Anothercrucialaspectofthemodeledattentiveprocess
isthetop-downapproach,inwhicha’targetmap’assignsprobabilitiestofeatures
thatarevisuallyorsemanticallysimilartothetarget[38,49,54,46]. Targetmap-
basedmodelsguideeyemovementdecisionstowardsmorelikelytargetlocations.
Thisprocessinvolvesthegoal-directedaspectofattention,guidedbytheindivid-
ual’scurrentgoals,expectations,orknowledge.
Althoughmodelsofferarelativelysuccessfulpredictiveframeworkformajorcog-
nitiveattentionprocesses,itiscrucialtorecognizethatthenatureofthesearchtask
requiresanemphasisbeyondmerelytop-downandbottom-upprocesses.Mostex-
istingsearchmodelsfailtoadequatelyconsidertheimportanceofvisualstructures
invisualsearch,astargetsintraditional2Dtasksarealmostimmediatelyvisible[31].
Althoughsuchcomputationalmodelsaccountforthememoryofthemostrecent
fixationlocations[23,44,38],onlyafewmodelsemphasizetheadvantagesofstruc-
turedinformationforimprovingInhibitionofReturn.
Todate,onlyafewhierarchicalvisualsearchmodelshavebeencreatedtorepli-
catehowsemanticstructuresinfluencetoshortersearchpaths[55,20].Thesemod-
elsaregroundedincognitivearchitecturessuchasACT-R,EPIC,andACT-R/PM,and
rely on production rules to guide eye movement decision-making through deter-
minedlogic.Inthemajorityofmodels,thememoryoftherecentlocationsisdirectly
integratedintothedecision-makingprocessthroughproductionrulesorbyreduc-
ingtheprobabilitiesforthenextfixationlocation. Inparticular, thevisualsearch
ofhierarchicalmodelsmimicsacertainsearchstrategy,ratherthanthemodelitself
adapting to the optimal search strategy in certain the task environment. The ex-
planatorypoweroftheadaptivesearchmodelillustrateshow,duetocognitivecon-
straints,theinhibitionofencodedelementsemerges,asseenintheAdaptiveFea-
tureGuidanceModel[27].However,existingsearchmodelshavenotdemonstrated
howtheinhibitionofscannedlocationsisenhancedthroughrationaladaptationto
visualstructures,assumingthatvisualmemorystructureishierarchical.
Ourmodel’scognitiveapproachisbasedontheComputationalRationality,wherein
themodellearnstooptimizethesearchpathofeyemovementsbyadaptingtothe
taskenvironmentinaccordancewithcognitiveconstraintsandcapacity[14].Com-
putationalrationalitymakesasubstantialdifferencetoalmostalloftheabovemod-
elspredictinghierarchicalsearch,fromwhichthedecisiontoshiftattentionarises.
Inmodelsgroundedincognitivearchitectures,thismeansthatproductionrulesdi-
5rectlydeterminetheconstraintsforthedecision-makingofthesubsequentfixation.
Inmap-orientedmodels,anupdatedprobabilitymap(salience/targetmap)directs
eyemovementbasedonsalienceandtargetfeatures.Insuchmodels,thedecision-
makingforeyemovementdrawsonstatisticalmathematics, machinelearningal-
gorithms,orreinforcementlearning. Itisnoteworthythatdecisionmakinginour
modelemergesthroughreinforcementlearninghavingavailableenvironmentalin-
formation. Internal representation from environment includes the egocentric in-
formationonthedistancesoffixationtotheelements,groupingofelements,anda
hierarchicalrepresentationofthelocationsofvisitedelements.
Inourstudy,weassumethathumanperceptualabilitycanformcoherentstruc-
turesevenfromrandomlyplacedelements[6].Contrarytomostvisualsearchmod-
els,ourmodeldoesnotbringoutthetop-downprocessexpectationsfortargetfea-
turesorthebottom-upprocess’ssaliencefeaturestoguideattentionbecausethese
arenotessentialprocessesforthetaskenvironmentweareinterestedin.Ourmodel
aimstomaximizetheefficiencyofthesearchtaskbyutilizingahierarchicalstruc-
tureofvisualmemorywithaglobalsearchstrategyforspatiallygroupedstructures.
This is achieved through a hierarchical representation that stores entire grouped
structures rather than the locations of individual elements independently. Thus,
thephenomenonofInhibitionofReturnarisesasaresultofthemodeladaptingto
environmentalstructures,ratherthan,asinmostmodels,bydirectlyimplementing
preventionofrevisitsintothedecision-makinglogicorbyreducingprobabilitiesof
encodedlocations.
2.3 GOALS OF THE PAPER
Inthisstudy,weidentifythreedistinctmainobjectives: 1)Todemonstratethrough
empiricalobservationsthatutilizingvisualstructuresimprovesperformanceinsearch
tasks,2)Todevelopacomputationalmodelthatreplicateshumanbehaviorinstruc-
turedlayouts,3)Todemonstratethemodel’spotentialasatoolinHCIdesigntoaid
designers’decision-making.
Theaimofthestudyistodemonstratethathumanbehavioralignswithouras-
sumptionsaboutcognitionadaptingtoenvironmentalvisualstructuresusingahi-
erarchical memory structure, to gain an advantage in visual search performance.
Empiricalfindingsaimtoprovehowvisualstructurescontributetofastertargetde-
tection.Aboveall,weshowwithourmodelthattheassumedhierarchicalamemory
structurefacilitatesamoreefficientsearchstrategybyenhancingtheinhibitionof
previouslyobservedelements. Themodel’spredictionenablesfutureapplications
toassistUIdesignersinoptimizinginformationcategoriesintovisuallyappropriate
groupsizesbysimulatingtheuser’seyemovementforagivenspatiallystructured
layout.
63 MODEL DESCRIPTION
3.1 COMPUTATIONAL RATIONALITY AND REINFORCEMENT LEARNING
Avisualsearchinvolvesstrategicplanningtooptimizesearchperformancewithre-
specttothetask’sgoal[36]. Thefundamentalbasisofthemodelisthattheagent
independentlylearnstheoptimalcourseofactionthroughgoals,possibleactions,
and observed environmental states. In this way, the agent’s decision-making be-
comesstrategic,notsettlingfortheimmediatelyshortestnextfixationbutinstead
lookingfurtherintothefuture. Thedecision-makingcanbeconsidered’rational,’
asthecentralideaofthemodelistheagent’sabilitytorationallypredictthemost
favorablesuccessiveactions,aimingtoachievethemaximumbenefitfromthetask
environment [14]. However, with limited internal representation, the benefit can
onlybeachievedbyexploitingtheavailableinformationasmuchaspossible, but
atthecostofcomputationalcomplexity[14]. Theagent’sdecision-makingiscon-
strainedbythelimitedknowledgeofenvironmentalstates, possibleactionsavail-
able to the agent, the transition function between possible states and the reward
function. Computationallyrationallearningisdeterminedthroughreinforcement
learningalgorithms,wherebytheagentinteractswiththeenvironmentmakingra-
tionalchoicesbasedontheavailableinformationanditsowncomputationallimi-
tations,aimingtoachievethemaximumrewardforthetask[43].
Themodel’sdecision-makingprocessoperatesasaPartiallyObservableMarkov
decisionProcess(POMDP),withtheagent’sdecision-makingguidedbyaninternal
representation. POMDPsisanapproachformodelingsequentialdecision-making
processes,whereachievingagoalrequiresseveralconsecutivestepswhereeachstep
dependsonprevioussteps[43]. ThePOMDPdecisionprocessobservestheenvi-
ronmentpartially,limitedbyhumancognitiveconstraintsinobtaininginformation
fromtheenvironment. POMDPdescribesasequentialstochasticdecisionprocess,
wherethetuple<S,A,T,R,γ>consistsofafinitesetofstates(S),afinitesetofac-
tions(A),atransitionfunction(T),arewardfunction(R),andadiscountfactor(γ).
Theprocesscontrolsdecision-makingbyselectingthemostfavorableactionforthe
long-termgoalfromallpossibleactionsa∈Ainacertainstate,throughinteraction
withtheenvironment.ThetransitionfunctiondefinestheprobabilityT(s,a,s′)=p(s
|s,a)forthefuturestates′∈Suponselectinganactioninagivencurrentstates∈S.
A"policy"isacurrentstrategyorasetofrulesthatanagentfollowstodetermine
its actions based on the current state of the environment. The agent attempts to
optimizeitspolicyπbymaximizingthelong-termrewardandselectsactionsbyfol-
lowingthecurrentpolicy,whichdefinestheprobabilitiesforactionsinagivenstate
asπ(s,a)=p(a|s). TherewardfunctiondefinestheprobabilityR(s,a)=p(r|s,a)of
achievingarewardr ∈Rwithachosenaction,oncetheactionhasbeenexecuted.
Theagent’spolicyevolvesasitsperformanceoptimizes,andinaccordancewith
theBellmanequation,themaximumexpectedreturn(includingimmediateanddis-
countedfuturerewards)thatcanbeachievedfromstatesonward.Thisisachieved
byoptimalpolicywhichmaximizethevaluefunction:
7(cid:34) (cid:35)
V∗ (s)=max R(s,a)+γ(cid:88) T(s,a,s′ )V∗ (s′ )
a s′∈S
where,γ∈[0,1]denotestheimmediaterewardsarediscountedinrelationtothe
future. Sincethemodeladherestoanoptimalstrategyforfutureactions,itstrives
toselectactionsthatmaximizethesumoffuturerewards. Theagentistaskedwith
searchingforarandomlyselectedtargetamongthevisualelements. Thechoiceof
the next fixation is made from available actions a ∈ A, which corresponds to the
locationsofallelements.
Model’srationallearningisdeterminedbyaforementionedtheoreticaldescrip-
tion of reinforcement learning. Computation rationality entails the architectural
structureofthemodel, wheretheagent’sinternalenvironmentinteractswiththe
externalenvironment. Agent’srationalchoicesbasedonavailableinformationand
itsowncomputationallimitations,aimingtoachievethemaximumrewardforthe
task at hand [43]. In the following section, we will walk through how interaction
occurswithinthemodel’sarchitecture.
3.2 ARCHITECTURE OF MODEL
Ourmodel’sarchitecturalstructurecanberoughlydividedintoagent,internaland
externalenvironments(Figure2). Theagentisinconstantinteractionwiththeex-
ternalenvironmentindirectlythroughaninternalcognitiverepresentation,which
isagent’sbeliefstate.Theinternalenvironmentencompassesacognitivespacethat
providesapartialvisualrepresentationoftheexternalenvironment[43]. Theex-
ternalenvironmentreferstothephysicalcontextoftheinteraction, whichinthis
instancemeanthespatiallystructuredlayout.Theagentimplicitlyutilizestheinfor-
mationfromtheinternalenvironment’sstate,makingthechangesinstatesstochas-
tic.Thesechangesdependontheagent’sprobabilitiesofselectingacertainactionin
agiveninternalstate.Theagentobservesandevaluateschangesintheinternalen-
vironment’sstates,receivingpositiveandnegativerewards.Theagent’sactioncause
responsetotheexternalenvironment,leadingtoachangeinitsstate,whichmod-
ifiestherepresentationoftheinternalstatethroughtheperception. Next,wewill
delvemoredeeplyintotheinternalandexternalenvironment’smutualinteraction.
Theagentmakesobservationsfromtheinternalenvironmentanddecideswhich
elementtomoveattentiontonext.Thisprocessrequiresinformationfromtheinter-
nalenvironmenttoenabletheoptimizationofitssearchpolicies.Sincethemodel’s
internalvisualrepresentationoftheenvironmentispartial,itmeansthatpercepts
oftheexternalenvironmentareconstructedwithcognitivelylimitedcapacityfrom
stimuli[43].Internalrepresentationispredefinedintermsoftheactualexternalen-
vironment,makingthemodel’sinputinformationsymbolic.Thisimplementationis
becausethemodelaimstodemonstrateitsadaptationtotheenvironment,whereit
learnstoutilizevisualinformationforperformingsearchtasksratherthanfocusing
onhowtherepresentationisformedthroughlow-levelperceptualprocessesfrom
rawpixeldata.
8Figure2: Themodel’sarchitecture,wheretheagentmakesdecisionsbasedonthe
stateoftheexternalenvironment,butthroughtheinternalenvironment’sstate.This
internalstatechangesviatheperceptionofstimuliintoaninternalrepresentation
relativetocognitivecapacityandconstraints. Theagent’snewactionshiftsthefix-
ation to the location of a new element, and the duration taken for the saccade is
calculatedusingtheEMMAmodel,whichresultsinanegativerewardfortheagent.
Anewelement,inresponse,causesanewstatechangeintheexternalenvironment.
9Themodel’sinternalrepresentationisnotdirectlyavailablefortheagent’sdecision-
making but is used implicitly. Figure 2 illustrates the cognitive features included
in the internal representation. The model adapts to the environment by utilizing
information available to the agent about 1) location of current fixation (’Eye’), 2)
thelocationsofelements(‘Elementdistances’),3)leveragingthehierarchicalvisual
short-termmemory(‘HierarchicalVSTM’),and4)thegroupingofelements(‘Groups
of elements’). The model directs its attention to one element at a time, and the
attention’sinformationintherepresentationisupdatedeachtimetheagenttakes
a new action towards a new element’s location. The egocentric representation of
elements’locationsenablesthemodeltosearchforashorterpath. Usingthisin-
formation,themodellearnstoplanthelengthoftheeyepath,aimingtocoveras
manyelementsaspossiblewithinagiventime.Spatialrelationshipsininternalrep-
resentationhavebeensimplifiedtodistanceinformationbetweencurrentfixation
andotherelements.Thisreductionininformationissufficienttoallowthemodel’s
computationalcapacitytobeadapted.
Theagentlearnstooptimizethelengthofthesearchpathbydoingenoughcon-
secutiveobservationsoftheenvironmentandimprovingtheselectionofactionin
eachstate. Tostrategicallysolvetheoptimizationproblemforthelongtermrather
thanjustmovingtothenearestnextelement,theagentmustbeimplicitlyprovided
withinformationaboutencodedelementlocationsinshort-termmemory.Thisin-
formationultimatelyguidesdecision-makingtoinhibitalreadyscannedelements
thatwouldotherwiseleadtounnecessaryrevisitationofthesameelements. How-
ever,merelysimpleshort-termmemoryisnotsufficientforefficientlyperforming
searchtasksonlayoutswithlargernumbersofelements.Therefore,themodellever-
agesaHierarchicalVSTMtoenhancetheefficientuseofmemorybymaximizingthe
memorizationofscannedelementlocations. Thisispossibleformodelbytheele-
mentgroupinginformationofelements,whichidentifieswhichelementsbelongto
asamegroup. Whenalltheelementsofagroupareencodedwithinagivenvisual
group,thelocationinformationoftheentiregroupcanbeencodedintothehigher
hierarchicalmemorylevel. Oncetheagenthasrecognizedtheadvantageofgroup-
ing,itultimatelyseekstoplanthesearchpathprimarilyasaglobalsearchstrategy.
The internal environment defines the reward received by the agent relative to
the goal of the task, which in this instance is finding the target as fast as possi-
ble. The model’s agent receives negative rewards according to the time spent on
eyemovements. Theagent’slearningemergeswhenithasencounteredthemen-
tionedassociationsenoughtimesandachievingsufficientpositiverewardfromthe
internalrepresentation.Theagent’sadaptationforcertainstrategyisdependenton
how much greater a reward the new policy offers, such as leveraging hierarchical
memoryoverleaningsolelyonthelimitedcapacityofshort-termmemory.
Thedurationofthemodel’seyemovementshiftisestimatedusingtheEMMA
eyemovementmodel[52], whichdeterminesthetimespentonsaccadesanden-
coding.SinceEMMAdoesnotaccountforencodingdurationsfordifferenttypesof
symbols,weaddeda150msdurationtoeachfixationtofitthehumandata. Thisis
justified,asfixationtimetypicallyrangesfrom200-250mswhenreading,andover-
10allfixationdurationcanvarybetween100-500ms[50].Giventhattheaverageword
lengthislongercomparedtoour3-lettercombinations,itcanbearguedthatfixa-
tionwouldbesignificantlyshorterthan200ms.
3.3 INTERNAL REPRESENTATION
Thissectionpresentsanexampleofthemodel’ssimulation(Figure3), illustrating
howthemodel’soptimizedpolicyisreflectedinchangestotheinternalrepresenta-
tionstate. Inthissimulationexample,themodelhaslearnedtoutilizevisualstruc-
turesandisthereforeabletoefficientlymakeuseofthehierarchicalstructureofvi-
sualmemory.Ourmodel’sinternalrepresentationincludesfourobservationspaces:
1)Eyeposition2)Egocentricdistancestoelements3)Hierarchicalmemorystruc-
tureofelementlocations4)Groupingofelements.Tosimplifythefigure3,weomit-
ted the grouping information and egocentric spatial data from the internal state.
Themodellearnsapolicythataimstoplanthesearchpaththroughonegroupata
time. Thisgroupinginformationremainasstaticinformationthroughoutthetask,
asthegroupingdetailsemergeduringthepreattentivestageofthebottom-uppro-
cessintheperipheralvisualfield[58,57].
Fromthefirstfixation(a),theeyeinformationintherepresentationisupdated
totheelementforwhichtheactionisselectedaccordingtothepolicy. Atthesame
time,eachnewfixationisencodedintoshort-termmemory.Instage(c),themodel
hasencodedalltheelementsofanentiregroupintoshort-termmemory.Asaresult,
thegroup-specificinformationisencodedatahigherlevelofthehierarchicalmem-
orystructure,whichremainsinmemoryuntiltheendofthetask.Inthiscase,weas-
sumethatmemorychunksaremorelikelytoremaininlong-termmemory,andthat
oneoftheadvantagesofchunksisassumedtobetheireasierretrievalfrommem-
orycomparedtoretrievingindividualelementsfromshort-termmemory[34,9,40].
Inthelaststaged,aftertheseventhfixation,theoldestencodedelementiserased
fromshort-termmemory,andthenewfixationorelementlocationisadded.Thisis
becauseVSTMcanretainonlyalimitednumberof6encodedelements.
11Figure 3: The series of figures illustrates the change in the model’s internal state
asthesimulatedeyemovementproceedsfromelementtoelement,aimingtoen-
code one spatial group at a time. Eye-movement figures demonstrates how our
model’sencodingoccurswhenitisoptimizedtousehierarchicalVSTMoptimally.
The model’s internal state also includes static information about visual grouping
andthespatiallocations. Thegroupingofelementsisboundedbyabluedashed
linesandgroupnumbersarepresentedinthefirststage(a)oftheseriesofimages.
124 EVALUATION
4.1 METHOD
Intheexperimentaldesign,allsubjectsperformedallthevisualsearchtasks(within
subjects).Intheexperiment,participantsperformedvisualsearchtaskswherethey
had to find a target letter combination that appeared on the screen as quickly as
possiblefromthestimulusandpressthereactionbuttonassoonastheyfoundit.
Theexperimentconsistedof6differenttasks,andeachtaskincludedstimuliforfour
differentelementsizes(16,24,36,48),variedforbothstructuredandunstructured
conditions(atotalof48tasks). Thestimulusforeachsearchtaskwerealsounique,
generatedbyacomputerprogram.
4.2 PARTICIPANTS
Thestudywasonline, whichenabledahugenumberofparticipants(48subjects)
aged between 18 and 29 years. All participants were either U.S. or U.K. citizens,
ensuringfluentEnglishlanguageskillsforunderstandingtheinstructions. During
recruitment,itwasensuredthatallparticipantshadgoodvisionandnoabnormal
disabilitiesorimpairmentsthatcouldaffecttheirphysicalreactionabilities.
4.3 PROCEDURE
Before the actual tasks began, participants were asked to first accept the consent
form. Inaddition,theparticipantwentthroughtheinstructionsfortheapplication
task, which explain how each task should be perform. Participants were also in-
structedtoeliminateallextraneousdistractionstofocussolelyontheexperiment.
Theyhadtheoptiontoterminatetheirparticipationinthestudyatanypointduring
theexperiment. Atthebeginningofeachindividualvisualsearchtask,a4-second
countdowntimerappearedonthescreen,signalingparticipantstopreparebyplac-
ing their finger on the space bar (reaction button). After that, a letter combina-
tion(target)appearedonthescreenfor3seconds, whichparticipantswereasked
to memorize. The target letter combination was randomly selected from a set of
lettercombinationsinthelayoutforeachtask. Followingthis,theactualstimulus
appeared on the screen, and the participant had to press the spacebar as quickly
aspossibleuponfindingthetargetlettercombination. Thiswasimmediatelyfol-
lowedbyanewsearchtask,whichagainstartedwitha4-secondcountdown. The
experimentincludedonepracticetaskandatotalofsixmeasurabletasks.Eachtask
included search tasks for all element setsizes (16, 24, 36, and 48) combined with
structuredandunstructuredlayouts.TheorderofthetaskswasLatin-squarecoun-
terbalanced,andthelayoutofeachindividualsearchtaskwasunique.Therewasan
opportunitytotakea30-secondbreakbetweeneachtask. Overall,theexperiment
tookabout15minutes.
134.4 STIMULI
Thegenerationofstimuliforboththeexperimentandthemodelhasbeencarried
outbyacomputerprogram. Thelayoutsusedinourstudycontainlettercombina-
tionsofthesamecolor(includingthetargetstring),whichrepresentvisualelements.
Theelementsareeitherinperceptible,distinctspatialgroups(structured)orinnon-
distinguishablegroups,meaningthattheelementsareevenlydistributedacrossthe
entire layout area. We assumes that human perceptual ability can form coherent
structuresevenfromrandomlyplacedelements[6]. Thismeansthatinourmodel,
thegroupsarelessdiscernibleintheunstructuredlayoutthantheywouldbeina
structuredlayout. Intheinternalrepresentation,thismeansthatelementsbelong
toonlyonegroupinastructuredlayout, butinanunstructuredlayout, elements
canbelongtomorethanonespatialgroup. IntheAppendixA(Thegenerationof
thelayout),itisdescribedindetailhowthestructuresofthelayoutsaregenerated
andhowthespatialgroupsofthemodel’sexternalenvironmentaremappedtothe
model’sinternalrepresentation.
4.5 RESULTS
4.5.1 EXPERIMENT
Intermsoftheresults,wewereinterestedinhowthenumberofelementsinalayout
affects human search time and how this varies when visual information is either
structuredorunstructured.Secondly,wewereinterestedinhowthesearchtimeofa
modelperformingasearchtaskalignswiththehumansearchtimeforthesametask
underthesamestimuli. Theinitialassumptionabouthowthespatialstructuresof
elementsaffectsearchperformancewasbasedontwohypotheses:1)anincreasein
thenumberofelementsinthelayoutincreasessearchtime,and2)anunstructured
layoutincreasessearchtimerelativetoastructuredlayoutforagivensetsize.Next,
wewillwalkthroughhowwellthesehypotheseswererealizedbasedontheresults.
Atotalof2304trialswerecollectedfrom48subjectsinthestudy. Weusedthe
Interquartile Range (IQR) filtering method for outlier removal, after which a total
of2155trialsremainedforthestatisticalanalysisofthedata. Intotal,149outliers
were removed from the data, which is about 6.4 percent of all the original trials.
Theoriginaldistributionoftheexperimentaldataindicatedthattherewasaclear
skewnessinthesearchtimedistribution,whichwastransformedlogarithmicallyto
appearnormallydistributed(Figure4.a)[42].
Inanalysis,wewanttoaccountforrandomvariationbetweenparticipants,so
weconductedastatisticalanalysisusingalinearmixedmodel. Thismodelallows
for the evaluation of both fixed and random effects on search time. Through the
statisticsmodel,weaimtodeterminehowindependentvariables(setsizeandspa-
tialorganization)andtheirinteractionsaffectthevariationinsearchtime. Setsize
andconditionarefixedeffectsofthemodel,andthevariationbetweenparticipants
isarandomeffecttoexplainthemodel’ssearchtime.
14Figure4:Logarithmicallytransformeddistributionoftheexperimentresultsonthe
left(a).Logarithmicallytransformeddistributionofresidualsfromthelinearmixed
modelshownontheright(b).
Therandomeffectofthelinearmixedmodeldoesnotseemtocausealargestan-
darddeviationintheimpactofindividualdifferences(0.57s).Theeffectofindivid-
ualdifferencesontherandomvarianceisaverysmallfractionoftheunexplained
variance in the overall model (ICC=0.05). The model partially explains the varia-
tioninresultsintheexperiment. Althoughtheresidualvariancevalue(5485.02s²)
andtheresidualstandarddeviation(2.34s)arefairlylarge,thedistributionofresidu-
alsappearsfairlynormallydistributedwhenthedataislogarithmicallytransformed
(Figure4.b).
Firstly, figure 5 shows that search time increases as expected with the growth
of set size [58, 64]. ANOVA analysis of the linear mixed model revealed that set
sizehasasignificantincreasingeffectonsearchtime,withlargersetsizesleading
Figure5:Estimatedmarginalmeanssearchtimesforeachconditions.
15tolongersearchtimes(F(3,2101.4)=205.72,p<0.001). Secondly,theresultsindicate
thatastructuredorganizationfacilitatesfindingthetargetmorequickly. Astruc-
tured organization also has a significant effect on improving search performance
(F(1,2101)=21.25,p<0.001). However,theadvantageofastructuredorganizationin
searchperformanceappearstoimprovemoreonlywithasufficientlylargesetsize,
anditbecomesmorepronouncedwithevenlargersetsizes. Thisinteractioneffect
between set size and spatial organization is significant (F(3,2101)=6.16, p<0.001).
In Figure 5’s estimates, it can be observed that with the smallest set size (16), a
structuredorganizationdoesnotprovideanybenefitinsearchperformance,asthe
searchtimewas2.1secondsinbothconditions.Withasetsizeof36,thesearchtime
forthestructuredcondition(m=3.9s)isalreadysignificantlybettercomparedtothe
unstructuredcondition(m=5.0s).
4.5.2 MODELEVALUATION
Thecomputationalmodel’spredictionsalignwellwithhumansearchperformance
intasksinvolvingvisualstructures. Weanalyzedthecomputationalmodel’sability
topredicthumansearchtimesusingalinearregressionmodel. Inthisanalysis,the
searchtimeproducedbythemodelsimulationistheindependentvariable, while
participant’ssearchtimeisthedependentvariable.Thepredictionsoftheregression
model show that the relationship between the computational model and human
searchtimesisstrong. Accordingtotheresults,thecomputationalmodel’sability
topredictparticipants’reactiontimeswassignificant(t(6)=8.064,p<0.001).When
themodel’ssearchtimeincreasesbyonesecond,humansearchtimeincreasesby
0.43seconds.Themodel’sinterceptwasalsostatisticallysignificant(t(6)=5.591,p=
0.0014).TheanalysisrevealedahighadjustedR-squared(R²=0.90),indicatingthat
thepredictionsofourcomputationalmodelexplainabout90%ofthevariationin
humansearchtimes.Thepredictionofthelinearmodelisstatisticallyhighlysignif-
icant(F(1,6)=65.02,p<0.001),indicatingstrongpredictivepowerofthecompu-
tationalmodelwithrespecttohumanperformanceinthegiventask. Althoughthe
model’spredictionsaregenerallyaccurateforeachcondition,thereisaslightmean
errorinthelinearmodel’spredictionscomparedtotheactualsearchtimes(RMSE=
0.38seconds).
Inthecomparisonofthemodelandexperimentaldata(Figure6),itcanbeob-
servedthatthemeanswellsupportourcomputationalmodel’sabilitytopredictthe
advantageofastructuredlayoutinsearchperformanceandtheeffectofalargerset
sizeontheincreaseinsearchtime. Theimprovementinsearchtimeinthestruc-
tured condition becomes increasingly apparent as set size increases, both for the
modelandforhumans. Thissuggeststhatthemodeleffectivelycapturestheinter-
actionbetweensetsizeandthestructuredconditionininfluencingsearchperfor-
mance.
Duetothemodel’sadaptability,itiscapableofaccountingforthestochasticna-
tureoftargetdetection. Itismorelikelythatthetargetelementwillbefoundfaster
evenrandomlywithasmallersetsize,inwhichcasestructuresdonothaveenough
16Figure6:Meansearchtimesforhumanandmodeldataacrosssetsizesunderstruc-
turedandunstructuredconditions.
timetobenefitmemoryininhibitingitems.Thiscanbeobservedwithasamplesize
of16,wheresearchtimesarealmostatthesamelevelinboththestructuredandun-
structuredlayoutforboththecomputationalmodelandtheexperiment.Withlarger
setsizes,thedifferencesbetweenthestructuredandunstructuredlayoutsbecome
morepronouncedinboththemodelandtheexperiment.
However,themodel’ssearchtimeincreasessignificantlywithlargersetsizes,due
to its inability to learn the utilize of structures in larger set sizes. In other words,
themodel’scomputationallimitsforadaptationareattainedwithlargersetsizes,
although these challenges can be solved in the future. Another significant factor
contributing to the model’s excessively long search times in larger set sizes is the
limitedtwo-levelhierarchyofitsvisualmemory. Inthemodel, thisphenomenon
isemphasizedwithlargersetsizes,asthevisualmemorycanonlyformchunksof
limitedsize.ThesepointsarediscussedinmoredetailintheDiscussionsection.
The results of the simulations seem to provide support for our underlying as-
sumptionthatcognitionadaptstouseahierarchicalmemorystructure,asitmore
efficientlyimprovesmemoryrecallofpreviouslyencodedelementsandavoidsre-
visitingtoelements. Firstly,thisphenomenonissupportedbytheresultsinTable
1onsimulatedfixations,whichshowthatfixationsdecreaseduetotheeffectofa
structuredorganizationforagivensetsize. Thenumberoffixationsincreasesthe
differencebetweenthestructuredandunstructuredconditionsforlargersetsizes,
which appears to be well aligned with the results of the model on search perfor-
mance.
Secondly,theincreaseinIORpredictedbytheeffectofstructuredorganization
17supportsasmallernumberofrevisits. Thedifferenceinrevisitsbecomesmoreap-
parentonlywithlargersetsizes(36and48). Sincethedifferencesinfixationsand
revisitsbetweenstructuredandunstructuredlayoutsarestillsmall,aslightlylarger
increaseinfixationsdoesnotnecessarilyleaddirectlytoasignificantlygreaternum-
berofrevisits. Also,asexpected,anincreaseinsetsizeleadstoanincreaseinthe
numberofrevisits,asfindingthetargetnaturallytakeslonger.
Table1: Summaryoffixationsandrevisitsacrossstructuredandunstructuredcon-
ditions
SpatialOrganization SetSize Fixations Revisits RevisitsSD
Structured 16 8.6 0.2 0.8
Structured 24 12.7 1.1 2.3
Structured 36 21.9 3.5 5.4
Structured 48 36.9 12.3 17.1
Unstructured 16 8.8 0.3 1.0
Unstructured 24 12.9 1.0 2.7
Unstructured 36 27.9 9.7 14.1
Unstructured 48 38.5 16.2 23.1
Infigure7,withastructuredlayout,themodel’ssearchstrategyisoptimizedto
searchfortargetsonespatialgroupatatime.Thisshortensthelengthofthesearch
pathandsearchtimeandreducesthenumberoffixationsbyavoidingrevisitstothe
sameelements.Themodelcannotperceivestructuresasclearlyinanunstructured
layout. This leads to a situation where the model can scan through the elements
tosomeextent, groupbygroup, butnotasefficientlyaswithastructuredlayout.
Althoughourmodelseemstoaccuratelypredictthedurationofvisualsearch, we
cannotconfirmourassumptionofhumanadaptationtoahierarchicalsearchstrat-
egybasedsolelyonourexperiment.
18Figure7:Examplesoftheeyemovementsimulations,comparingthenumberoffix-
ationsandrevisitsuntiltheeyemovementhasprogressedthrough16fixationsfrom
thebeginningofthetask. Thenumberingindicatessaccadesstepbystep,thered
elementrepresentsthetargetelementbeingsearchedfor,andtheredcirclemarks
theeye’scurrentposition.
195 DISCUSSION
Ourresearchcontributestoadvancingtheunderstandingofhowspatialstructures
influencetheemergenceofsearchstrategiesinvisualsearchtasks. Cognitivelyra-
tional adaptability has been demonstrated in various interactive tasks, providing
explanatory power for how humans learn to harness environmental information,
enabledbycognitiveresources[10,27,26,25,56]. Visuallyhierarchicalstructures
enableaneffectivereductionofthesearchareaintermsofmemory. Thisbehavior
arisesasaresultofadaptation,whencognitionhaslearnedtoharnessthehierar-
chicalcapacityofvisualmemorytoeffectivelyreduceinhibitionofreturntoalready
scannedelements. Theadaptabilityofthemodelisasignificantimprovementover
previoussearchmodelsthatpredicthierarchicalsearch,asthedevelopmentofthe
searchstrategyemergesfromthetaskgoal,cognitivecapacity,andenvironmental
constraints,ratherthanbeingbasedonassumptionsaboutthelogicofthesearch
strategy.Ourmodel’ssearchstrategyislearnedthroughreinforcement,utilizingin-
directinformationfromtheenvironment. Additionally,theresearchreinforcesear-
lier findings on the hierarchical nature of visual memory structure, showing how
short-termflexiblememorycapacityenablesmemoryexpansionthroughchunking
[4,6,15,30].
5.1 CONTRIBUTION
Our model successfully predicts human eye movements in visual search tasks for
bothstructuredandunstructuredlayouts,aswellasacrossawiderangeofsetsizes.
Themodeladaptedwelltoalllayoutvariationswithouttheneedforparametertun-
ing. Inorderforourresultstoconclusivelydemonstrateoptimizationofeyemove-
mentstrategiesbyencodingonestructureatatime,ourmodelrequiresfurtherval-
idationwithhumaneyemovementbehavior.
Webelievethatcomputationalrationaldecision-makingwillenhancethemodel’s
accuracy across different conditions and explain their advantages for the search
task,shapedbycognitivecapacityandconstraints.Themodellearnstoutilizeenvi-
ronmentalinformationthroughhierarchicalmemorycapacitytoefficientlyinhibit
alreadyencodedvisualelements. Thekeydifferencebetweenourmodelandpre-
vious models of hierarchical visual search is that our model’s hierarchical search
strategyemergesasaresultofadaptation,ratherthanbeingpre-programmedwith
logicalrules. Previousmodelshaveencompassedthephenomenonofinhibitionof
return(IOR),buttheyhavenotyetbeenabletoexplainhowamodellearnstouse
hierarchicalmemorywhenadaptingtovisuallyhierarchicalstructures.
Ourresultsaddvaluetoempiricalresearch, as, contrarytotheconclusionsof
BrumbyandZhuang[7],ourfindingsindicatethatvisualgroupingitselfprovidesan
advantageinsearchperformance,evenwithoutsemanticgrouping. However,itis
noteworthythatthestimuliintheirexperiment, inadditiontolineboxgrouping,
alsoincludespatiallistgrouping,whicheffectivelyintroducesanadditionalhierar-
chicallayer. Itisthereforepossiblethattoomanyhierarchicallayerscreateextra-
20neouscognitiveload,meaningthatthecapacityofvisualmemorywouldbemore
optimalwithfewerhierarchicallayers. Sincepreviousresultshavesuggestedthat
hierarchicalstructuresguidevisualsearch[7,2,10,16,17,20],overlycomplexhier-
archiesmightunnecessarilyburdenattentionduringinformationsearch.However,
thisrequiresfurtherinvestigationtounderstandwhatlimitsvisualhierarchiesen-
ableforthecapacitytoprocessinformationeffectively,andwhentheymaypoten-
tiallyhaveanegativeeffectoninformationsearch.
5.2 LIMITATIONS
Firstly,therealbottleneckofthemodelisthelimitedvisualmemory,whichisrigid
increatingchunkedinformationinmemorywithstructuresofdifferentsizes. This
ispossiblyduetothecomputationalcomplexityofthemodelinmanagingtoomany
encodedchunksatonceforthebenefitofthesearchtask.Comparedtoourmodel,
thehumanvisualsystemislikelyfarmoredynamic,capableofperceivingstructures
duringasearchtaskandformingcoherentinformationofallsizesinmemoryina
meaningfulmanner. Thevisualsystemispossiblyabletoexpandstructuresfrom
smallerstructuresandcreatenewlevelsofhierarchicalmemorystructure.Although
thelocationsofindividualelementscanbeencodedintoshort-termmemorywitha
limitedcapacityof4–6items[11,60,32],itremainsunresolvedwhatthelimitations
ofthehierarchicalmemorystructureare.
Thirdsignificantweaknessofthemodelisthelimitationofvisualmemory’shi-
erarchical structure to more than two levels. This explains partly, why the model
increasinglydivergesfromparticipantsinsearchtimesasthenumberofelements
grows. Thedetailedanalysisofeyemovementsrevealedaweaknessinthemodel’s
abilitytolearnoptimallywithlargernumbersofelements,whereitscomputational
limitsarereached. However,itisnotablethatthemodel’shierarchicalVSTMcon-
tainsonlyalimitedtwolayers.Itismorelikelythathumanhierarchicalvisualmem-
oryissignificantlymoredynamic,capableofcontinuouslycreatingnewandmulti-
plehierarchicallayersfromsmallerstructures.
Athirdsignificantlimitationisourmodel’srestrictedabilitytoperceivevisual
structures. The model’s symbolic representation of spatial grouping presupposes
arigidassumptionregardinghowspatialarrangementisperceivedbythemodel.
ApplicationtoUIdesignwouldrequiresolvinglow-levelprocessesofvisualpercep-
tion,particularlyhowvisualstructuresareperceiveddirectlyinapixel-basedgraph-
icalinterface. Itwouldbepossibletointegratepromisingclusteringalgorithmsfor
visualgroupingprocess.
5.3 CONCLUSIONS
Atleastpartiallytacklingtheaforementionedshortcomingsinthemodelwoulden-
ablethedesignofarealapplicationasatooltoassistthedesigner’sdecision-making
attheearlystagesofthedesignprocess.Themodel’seyemovementsimulationalso
providesdesignerswitheducationalinsightsintohowcognitivelimitationsexplain
21rationaleyemovementdecision-makingforaparticularinformationstructureina
layout. AnessentialdevelopmentalstepforthemodelfromtheperspectiveofHCI
researchwouldbetoalsotakesemantichierarchyintoaccountwithvisualstruc-
tures.Thisisacrucialdesignproblemintheearlystagesofdesign:Howtoconstruct
visualstructuresinawaythattheyareasconsistentaspossiblewiththesemantic
hierarchy[7,39,51].
Ourmodeldemonstrateshowthehierarchicalvisualcapacityenablestheuti-
lizationofvisualstructuresasaresultofadaptation. Theflexiblebehaviorofvisual
memoryisacrucialareaofresearchforgainingadeeperunderstandingoftherole
ofcognitivelimitationsininformationsearch.Aswepreviouslynotedregardingthe
model’smemoryrigidlimitationsinrelationtothepresumedcognitivecapacityof
humans, a deeper understanding of the capacity of the hierarchical visual mem-
orystructurerequiresfurtherresearch.Toovercomethelimitationsofthemodel,it
wouldbeessentialtodeterminewhatkindofflexibleyetconstrainedvisualmemory
enablesefficientadaptationtoenvironmentalstructuresthatcontainlargeamounts
ofinformation.
REFERENCES
[1] AlanBaddeley. Workingmemory: lookingbackandlookingforward. Nature
reviewsneuroscience,4(10):829–839,2003.
[2] GillesBailly,AnttiOulasvirta,DuncanPBrumby,andAndrewHowes.Modelof
visualsearchandselectiontimeinlinearmenus. InProceedingsofthesigchi
conferenceonhumanfactorsincomputingsystems,pages3865–3874,2014.
[3] PaulMBays,RaquelFGCatalao,andMasudHusain. Theprecisionofvisual
working memory is set by allocation of a shared resource. Journal of vision,
9(10):7–7,2009.
[4] TimothyFBradyandGeorgeAAlvarez.Hierarchicalencodinginvisualworking
memory: Ensemblestatisticsbiasmemoryforindividualitems. Psychological
science,22(3):384–392,2011.
[5] TimothyFBrady, TaliaKonkle, andGeorgeAAlvarez. Compressioninvisual
workingmemory: usingstatisticalregularitiestoformmoreefficientmemory
representations.JournalofExperimentalPsychology:General,138(4):487,2009.
[6] Timothy F Brady and Joshua B Tenenbaum. A probabilistic model of visual
workingmemory: Incorporatinghigherorderregularitiesintoworkingmem-
orycapacityestimates. Psychologicalreview,120(1):85,2013.
[7] DuncanPBrumbyandSusanZhuang. Visualgroupinginmenuinterfaces. In
Proceedingsofthe33rdAnnualACMConferenceonHumanFactorsinComput-
ingSystems,pages4203–4206,2015.
22[8] Claus Bundesen and Leif Flemming Pedersen. Color segregation and visual
search. Perception&Psychophysics,33:487–493,1983.
[9] William G Chase and Herbert A Simon. The mind’s eye in chess. In Visual
informationprocessing,pages215–281.Elsevier,1973.
[10] Xiuli Chen, Gilles Bailly, Duncan P Brumby, Antti Oulasvirta, and Andrew
Howes. The emergence of interactive behavior: A model of rational menu
search. InProceedingsofthe33rdannualACMconferenceonhumanfactors
incomputingsystems,pages4217–4226,2015.
[11] NelsonCowan. Themagicalnumber4inshort-termmemory: Areconsider-
ationofmentalstoragecapacity. Behavioralandbrainsciences,24(1):87–114,
2001.
[12] GustavoDecoandDietmarHeinke. Attentionandspatialresolution: Atheo-
reticalandexperimentalstudyofvisualsearchinhierarchicalpatterns.Percep-
tion,36(3):335–354,2007.
[13] JohnMFindlayandIainDGilchrist. Eyeguidanceandvisualsearch. InEye
guidanceinreadingandsceneperception,pages295–312.Elsevier,1998.
[14] SamuelJGershman,EricJHorvitz,andJoshuaBTenenbaum. Computational
rationality: Aconvergingparadigmforintelligenceinbrains,minds,andma-
chines. Science,349(6245):273–278,2015.
[15] ScottMGraham,AnupamJoshi,andZygmuntPizlo. Thetravelingsalesman
problem:Ahierarchicalmodel. Memory&cognition,28:1191–1204,2000.
[16] Tim Halverson and Anthony J Hornof. The effects of semantic grouping on
visualsearch. InCHI’08ExtendedAbstractsonHumanFactorsinComputing
Systems,pages3471–3476.2008.
[17] TimHalversonandAnthonyJHornof.Acomputationalmodelof“activevision”
forvisualsearchinhuman–computerinteraction. Human–ComputerInterac-
tion,26(4):285–314,2011.
[18] MarkKHo,DavidAbel,CarlosGCorrea,MichaelLLittman,JonathanDCohen,
andThomasLGriffiths. Peopleconstructsimplifiedmentalrepresentationsto
plan. Nature,606(7912):129–136,2022.
[19] ShaulHochsteinandMeravAhissar.Viewfromthetop:Hierarchiesandreverse
hierarchiesinthevisualsystem. Neuron,36(5):791–804,2002.
[20] Anthony J Hornof. Visual search and mouse-pointing in labeled versus un-
labeledtwo-dimensionalvisualhierarchies. ACMTransactionsonComputer-
HumanInteraction(TOCHI),8(3):171–197,2001.
[21] GlynWHumphreysandHermannJMuller.Searchviarecursiverejection(serr):
A connectionist model of visual search. Cognitive Psychology, 25(1):43–110,
1993.
23[22] LaurentIttiandChristofKoch. Asaliency-basedsearchmechanismforovert
andcovertshiftsofvisualattention.Visionresearch,40(10-12):1489–1506,2000.
[23] Laurent Itti and Christof Koch. Feature combination strategies for saliency-
basedvisualattentionsystems. JournalofElectronicimaging,10(1):161–169,
2001.
[24] YuhongJiangandStephanieWWang. Whatkindofmemorysupportsvisual
marking? JournalofExperimentalPsychology: HumanPerceptionandPerfor-
mance,30(1):79,2004.
[25] Jussi Jokinen, Aditya Acharya, Mohammad Uzair, Xinhui Jiang, and Antti
Oulasvirta. Touchscreen typing as optimal supervisory control. In Proceed-
ingsofthe2021CHIconferenceonhumanfactorsincomputingsystems,pages
1–14,2021.
[26] JussiPPJokinen,TuomoKujala,andAnttiOulasvirta.Multitaskingindrivingas
optimaladaptationunderuncertainty. Humanfactors,63(8):1324–1341,2021.
[27] JussiPPJokinen,ZhenxinWang,SayanSarcar,AnttiOulasvirta,andXiangshi
Ren.Adaptivefeatureguidance:Modellingvisualsearchwithgraphicallayouts.
InternationalJournalofHuman-ComputerStudies,136:102376,2020.
[28] Daniel Kahneman, Anne Treisman, and Brian J Gibbs. The reviewing of ob-
ject files: Object-specific integration of information. Cognitive psychology,
24(2):175–219,1992.
[29] RaymondMKleinandWJosephMacInnes. Inhibitionofreturnisaforaging
facilitatorinvisualsearch. Psychologicalscience,10(4):346–352,1999.
[30] XiaohuiKong,ChristianDSchunn,andGarrickLWallstrom. Highregularities
ineye-movementpatternsrevealthedynamicsofthevisualworkingmemory
allocationmechanism. Cognitivescience,34(2):322–337,2010.
[31] Chia-LingLi, MPilarAivar, MatthewHTong, andMaryMHayhoe. Memory
shapesvisualsearchstrategiesinlarge-scaleenvironments. Scientificreports,
8(1):4324,2018.
[32] StevenJLuckandEdwardKVogel. Thecapacityofvisualworkingmemoryfor
featuresandconjunctions. Nature,390(6657):279–281,1997.
[33] Wei Ji Ma, Masud Husain, and Paul M Bays. Changing concepts of working
memory. Natureneuroscience,17(3):347–356,2014.
[34] GeorgeAMiller.Themagicalnumberseven,plusorminustwo:Somelimitson
ourcapacityforprocessinginformation. Psychologicalreview,63(2):81,1956.
[35] DanielJMitchellandRhodriCusack. Flexible,capacity-limitedactivityofpos-
teriorparietalcortexinperceptualaswellasvisualshort-termmemorytasks.
Cerebralcortex,18(8):1788–1798,2008.
24[36] JiriNajemnikandWilsonSGeisler. Optimaleyemovementstrategiesinvisual
search. Nature,434(7031):387–391,2005.
[37] MatthewRNassar,JulieCHelmers,andMichaelJFrank.Chunkingasarational
strategyforlossydatacompressioninvisualworkingmemory. Psychological
review,125(4):486,2018.
[38] VidhyaNavalpakkamandLaurentItti.Modelingtheinfluenceoftaskonatten-
tion. Visionresearch,45(2):205–231,2005.
[39] Marketta Niemelä and Pertti Saariluoma. Layout attributes and recall. Be-
haviour&informationtechnology,22(5):353–363,2003.
[40] DankoNikolic´andWolfSinger. Creationofvisuallong-termmemory. Percep-
tion&psychophysics,69(6):904–912,2007.
[41] Sei-HwanOhandMin-ShikKim. Theroleofspatialworkingmemoryinvisual
searchefficiency. Psychonomicbulletin&review,11:275–281,2004.
[42] Jason Osborne. Improving your data transformations: Applying the box-cox
transformation. PracticalAssessment,Research,andEvaluation,15(1),2010.
[43] AnttiOulasvirta, JussiPPJokinen, andAndrewHowes. Computationalratio-
nalityasatheoryofinteraction. InProceedingsofthe2022CHIConferenceon
HumanFactorsinComputingSystems,pages1–14,2022.
[44] DerrickParkhurst,KlintonLaw,andErnstNiebur.Modelingtheroleofsalience
intheallocationofovertvisualattention. Visionresearch,42(1):107–123,2002.
[45] JamesRPomerantzandWRGarner. Theroleofconfigurationandtargetdis-
criminabilityinavisualsearchtask. Memory&Cognition,1(1):64–68,1973.
[46] Marc Pomplun, Eyal M Reingold, and Jiye Shen. Area activation: A com-
putational model of saccadic selectivity in visual search. Cognitive Science,
27(2):299–312,2003.
[47] MichaelIPosner,YoavCohen,etal.Componentsofvisualorienting.Attention
andperformanceX:Controloflanguageprocesses,32:531–556,1984.
[48] MichaelIPosner,RobertDRafal,LisaSChoate,andJonathanVaughan.Inhibi-
tionofreturn:Neuralbasisandfunction.Cognitiveneuropsychology,2(3):211–
228,1985.
[49] RajeshPNRao,GregoryJZelinsky,MaryMHayhoe,andDanaHBallard. Eye
movementsiniconicvisualsearch. Visionresearch,42(11):1447–1463,2002.
[50] KeithRayner. Eyemovementsinreadingandinformationprocessing. Psycho-
logicalbulletin,85(3):618,1978.
[51] Ladislao Salmerón, José J Cañas, and Inmaculada Fajardo. Are expert users
alwaysbettersearchers?interactionofexpertiseandsemanticgroupinginhy-
pertextsearchtasks.Behaviour&informationtechnology,24(6):471–475,2005.
25[52] DarioDSalvucci.Anintegratedmodelofeyemovementsandvisualencoding.
CognitiveSystemsResearch,1(4):201–220,2001.
[53] JaniceJSnyderandAlanKingstone.Inhibitionofreturnandvisualsearch:How
manyseparatelociareinhibited? Perception&Psychophysics,62(3):452–458,
2000.
[54] YaoruSun,RobertFisher,FangWang,andHermanMartinsGomes.Acomputer
visionmodelforvisual-object-basedattentionandeyemovements. Computer
visionandimageunderstanding,112(2):126–142,2008.
[55] Leong-Hwee Teo, Bonnie John, and Marilyn Blackmon. Cogtool-explorer: A
modelofgoal-directeduserexplorationthatconsidersinformationlayout. In
ProceedingsoftheSIGCHIconferenceonhumanfactorsincomputingsystems,
pages2479–2488,2012.
[56] KashyapTodi,JussiJokinen,KrisLuyten,andAnttiOulasvirta. Individualising
graphicallayoutswithpredictivevisualsearchmodels. ACMTransactionson
InteractiveIntelligentSystems(TiiS),10(1):1–24,2019.
[57] AnneTreisman.Perceptualgroupingandattentioninvisualsearchforfeatures
and for objects. Journal of experimental psychology: human perception and
performance,8(2):194,1982.
[58] AnneMTreismanandGarryGelade. Afeature-integrationtheoryofattention.
Cognitivepsychology,12(1):97–136,1980.
[59] StefanVanderStigchel. Anembodiedaccountofvisualworkingmemory. Vi-
sualcognition,28(5-8):414–419,2020.
[60] EdwardKVogel,GeoffreyFWoodman,andStevenJLuck. Storageoffeatures,
conjunctions,andobjectsinvisualworkingmemory. Journalofexperimental
psychology:humanperceptionandperformance,27(1):92,2001.
[61] ZhiguoWangandRaymondMKlein.Searchingforinhibitionofreturninvisual
search:Areview. Visionresearch,50(2):220–228,2010.
[62] DerrickGWatsonandGlynWHumphreys. Visualmarking: prioritizingselec-
tionfornewobjectsbytop-downattentionalinhibitionofoldobjects. Psycho-
logicalreview,104(1):90,1997.
[63] JeremyMWolfe. Guidedsearch2.0arevisedmodelofvisualsearch. Psycho-
nomicbulletin&review,1:202–238,1994.
[64] JeremyMWolfe. Visualsearchincontinuous, naturalisticstimuli. Visionre-
search,34(9):1187–1195,1994.
[65] Geoffrey F Woodman, Shaun P Vecera, and Steven J Luck. Perceptual orga-
nization influences visual working memory. Psychonomic bulletin & review,
10(1):80–87,2003.
26A THE GENERATION OF THE LAYOUT
Atthebeginningofeachnewsearchtask,alayoutwasgeneratedforthemodelus-
ing an algorithm, which was also used for generating layouts for the experiment.
Layoutsweregeneratedforstructuredandunstructuredconditionsandbothcon-
ditionsforfourdifferentelementsizes(16,24,36,48). Theelementswerepartially
randomizedforthelayoutwithcertainconstraints. Inastructuredlayout, theel-
ementsarearrangedspatiallyingroupsoffourelements, butthepositionsofthe
elementsarerandomizedwithintheareaofthegroup,andtheminimumdistance
betweenelementsis1.7timesthewidthoftheelement.Intheunstructuredlayout,
elementsareotherwisearrangedrandomly,buttheminimumdistancebetweenel-
ementsisatleast2.6timesthewidthofanelement.Ingenerationalgorithm,aran-
domlocationfortheelementisdrawnasmanytimesasnecessaryuntilthemini-
mumdistancecriterionismetinrelationtootherelements.Theminimumdistance
islargerfortheunstructuredlayoutbecauseitensuresthatmererandomizationof
locationdoesnotproducetooobviousstructures.
Ingeneratingthelayout,thestructureareasarefirstdefined,withtheircentroids
spacedasevenlyaspossiblefromeachother. Subsequently,thesizeoftheareais
defined,whichforastructuredlayoutissmallenoughsothattheelementsaresuffi-
cientlyclosetoeachotherwithinthestructure(spatiallygrouped).Fortheunstruc-
turedlayout,thestructureareasaresignificantlylarger,resultinginareaspartially
overlappingeachother.Inthecaseofunstructuredlayouts,elementsprimarilybe-
longtoonegroup,butsomeelementsmaybelongtomorethanonegroupinthein-
ternalrepresentationbecausetheirlocationmayalsobelongtotheareaofanother
group.Toensurethatspatialproximityitselfdoesnotcausefastersearchtimesona
structuredlayout,spatialstructuresarearrangedsofarapartfromeachotherthat,
atthesamesetsize, theaveragedistancebetweenelementsisgreaterthanonan
unstructuredlayout.
27