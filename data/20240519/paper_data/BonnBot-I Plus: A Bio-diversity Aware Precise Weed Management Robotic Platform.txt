BonnBot-I Plus: A Bio-diversity Aware Precise Weed Management
Robotic Platform
Alireza Ahmadi1, Michael Halstead1, Claus Smitt1, and Chris McCool1,2
Abstract—In this article, we focus on the critical tasks of
plantprotectioninarablefarms,addressingamodernchallenge
in agriculture: integrating ecological considerations into the
operationalstrategyofprecisionweedingrobotslikeBonnBot-I.
Thisarticlepresentstherecentadvancementsinweedmanage-
mentalgorithmsandthereal-worldperformanceofBonnBot-I
attheUniversityofBonn’sKlein-Altendorfcampus.Wepresent
a novel Rolling-view observation model for the BonnBot-Is
weed monitoring section which leads to an average absolute
weeding performance enhancement of 3.4%. Furthermore, for
the first time, we show how precision weeding robots could
consider bio-diversity-aware concerns in challenging weeding
scenarios. We carried out comprehensive weeding experiments
in sugar-beet fields, covering both weed-only and mixed crop-
weedsituations,andintroducedanewdatasetcompatiblewith
precision weeding. Our real-field experiments revealed that
our weeding approach is capable of handling diverse weed
distributions, with a minimal loss of only 11.66% attributable
Fig. 1. An image from underneath the BonnBot-I Platform in sugar
tointerventionplanningand14.7%tovisionsystemlimitations
beet fields at Campus Klein Altendorf of the University of Bonn, prior to
highlighting required improvements of the vision system.
conducting Precision weed management. (n1-n4: Spray nozzles in purple,
L1-L4:Linearaxesinlight-green,andthedetectionareaofthefrontcamera
I. INTRODUCTION incyan).
Modernagricultureandweedcontrolaimstosupportplant linearsystemoftoolstoperformweedmanagement,depicted
growthwhileconsideringenvironmentalprotection[1].Weed in Fig. 1. We propose an alternative planning approach that
controlisatopicalexampleofthisbecauseleavingweedsin emphasizestheneedforrobotstorecognizeandadapttothe
a field can significantly impactcrop yields as the weeds will diversityofweedspecies.Bydifferentiatingweedsbasedon
compete, or even out-compete, the crops for vital nutrients their specific characteristics and competitive behaviors, the
and resources leading to potential reductions in productivity. method enhances crop protection and resource optimization
Yet, in recent years it has become clear that we need to inweeding,signifyingashifttowardsmorenature-conscious
be able to strike a balance between protecting crops (e.g. and efficient agricultural practices. These advancements on
removingweeds)andtheenvironment,inparticularreducing BonnBot-I led to the following contributions:
the usage of herbicides for weed control [2]. 1) A bio-diversity aware weed management approach.
Robotics has emerged as a potential tool to better enable 2) A rolling view strategy that improves weeding.
this trade-off, particularly for the task of weed manage- 3) Real-world experiments of multi-nozzle weeding.
ment. As early as 2002 [3] researchers have considered 4) Releasing a multi-weed arable farming sugar-beet
the potential for robotics to perform precise weed control dataset SB21.
at the individual plant level. Since then, multiple methods
This extends our prior work [9] in three key areas. First,
to perform robotic weed management have been proposed
weintroduce animproved planningmethod utilizinga novel
including physical [4], [5], chemical [6], electrical [7], and
Rolling-view observation method, enhancing performance
more recently laser-based [8]. An issue with many of the
by 3.4%. Second, we introduce a bio-diversity-aware weed
above solutions is that they either do not provide flexibility
management system, a first in the field, and assess its real-
for different tools or their implements have a large footprint
world applicability. Third, we validate our system’s effec-
that does not enable plant-specific interaction.
tiveness through real-world experiments for multi-nozzle
In this article, we outline developments on BonnBot-
weed management, demonstrating its potential to optimize
I [9] which enhance its ability to perform bio-diversity-
agricultural practices and productivity.
aware weed management. In earlier work, we developed
planning systems for BonnBot-I that moved its replicated II. RELATEDWORKS
Weeds can significantly impact crop yields by compet-
1University of Bonn, Bonn 53115 Germany. ing with them for vital nutrients and resources, leading to
{alireza.ahmadi, michael.halstead, csmitt,
cmccool}@uni-bonn.de potential reductions in productivity [10], [11]. Hence, in
2LamarrInstituteforMachineLearningandArtificialIntelligence today’s world of agriculture, the efficient management of
4202
yaM
51
]OR.sc[
1v81190.5042:viXraweeds is vital when it comes to maximizing crop yields
and ensuring global food security. Traditionally, farmers
have heavily relied on manual labor or chemical herbicides
for weed control [12]. However, these methods often en-
tail labor-intensive processes, consume significant time, and
come with potential environmental repercussions [13]. Such
uniform treatment approaches result in both soil and yield
damage [14]. Therefore pushing society toward more eco-
friendly approaches to strike a balance between protecting
crops and the environment is particularly important. This
type of eco-friendly approach will result in the reduction
of herbicides and pesticides for weed control. This concept Fig. 2. The software architecture, including sensors (purple), vision
of robotic-vision based farming seeks to revolutionize farm- perception, localization of robot base frame FR (light blue), intervention
planning,interventionplanner,andweedingaxescontrollers(orange).
ing by enabling precision treatment at the individual plant
level [3]. Selective precision weeding presents a promising
III. SELECTIVEPRECISEINTERVENTION
alternative to the conventional and often excessive use of
herbicidesforweedcontrol[9].Theinnovationsprovidedby
agricultural robotics reduce labor, prevent soil compaction, BonnBot-I[9]isaversatileagriculturalplatformdesigned
andutilizeperception-basedmonitoring,whichcutsdownon at the University of Bonn. It is equipped with a novel
the agrochemicals used, directly benefiting the yield [9]. weedingtooldesignenablinghigh-precisionplant-levelfield
interventions. In our previous work [9] we elaborated on
Advancement in field monitoring and computer vision the conceptual design of the weeding tool and its associated
appliedinagricultureisanenablingfactorforprecisionweed software components. Fig. 2 shows the software architecture
management. For example, Zhu et al. deployed an attention- of BonnBot-I, where, different sensors available in the robot
based YOLO architecture for better weed detection [15]. are supplied to the localization and crop-weed monitoring
Halstead et al. [16] developed a crop-agnostic architecture modules to enable precision interventions through the weed-
based on MaskRCNN [17] to enable monitoring in arable ing tool. The controller system uses ROS (Robot Operating
farms as well as glasshouses. Furthermore, a wide range System) to standardize node communications. The weeding
of weed management tools have been investigated including tool features four independently controlled high-resolution
mechanical [4], [5], chemical [6] or electrocution [7], and linearactuatorspositioned0.6mabovetheground,creatinga
more recently laser-based [8] implement. These offer differ- workingareaof1.39m×0.36m.Currently,theyareequipped
ent benefits and restrictions. Vahdanjoo et al. [18] presented with spot-spray nozzles (with a spray footprint of 5cm on
a comprehensive analysis of the operational, economic, and the ground) which enable them to be used independently
environmentaleffectsoftheRobotti-Intelliplatforminseed- to engage with weeds. For more details about BonnBot-I
ing and weeding management in arable farms. platform, we refer the reader to [9].
The most critical challenge in this design is to efficiently
In[19]Zhouetal.onlyfocusedonthedesignandprelimi- plan paths for intervention heads, such that we maximize
naryevaluationofatargetedsprayplatform.Allcomponents the number of well-managed weeds in a weeding scenario.
were effectively evaluated, especially regarding the response A typical weeding scenario is composed of the following
time and target spray accuracy. They conducted only an stages: (I) Weeds get detected, classified, and tracked within
indoorexperimentalsetupshowingthatthedevelopedsystem the viewable area of the down-facing detection camera in
can reduce 46.8% usage of chemicals compared to the front of the robot. The monitoring system which runs the
uniformspraymethod.Similarly,amechanicalweedingtool Mask-RCNN network for instance-based semantic segmen-
was deployed in [20] where they operated on a self-built tation and classification is used to estimate necessary phe-
roboticplatformonasingle-rowearly-grownvegetablefield. notypic information about the plants. Finally, the plants are
This hoeing mechanism brought out the roots of weeds but tracked (tracklets) through the viewable area, more details
due to limited work space and length of operation, they are can be found in [9]. (II) The tracklets, which are identified
onlydeployableonspecificcropswithcertaingrowthstages. as valid plants for management, are monitored beneath the
The effectiveness of weed management tools varies based robot using its localization system. These tracklets are then
on field conditions and plant types. While recent weeding relayed to a target-space manager, who efficiently allocates
robots surpass traditional methods in precision, still there is them among the various weeding axes for optimal handling.
a large space for improvement. As this technology evolves, (III)Eachinterventionplannerplansanoptimalpathconsid-
itexemplifieshowinnovationcantransformtraditionalfarm- ering phenotypic factors like weed type, size, harmfulness,
ing into smarter, eco-friendly agriculture. Our method with required action time, and bio-diversity considerations. (IV)
BonnBot-I addresses this by using advanced sensors and The computed paths are transmitted to the relevant axis
AI to precisely target weeds, optimizing efficiency and drivers and nozzle controllers to carry out corresponding
sustainability in agricultural practices. actions on the plants.A. Crop-Weed Monitoring Pipeline
The vision system on BonnBot-I uses instance-based se-
mantic segmentation based on the Mask-RCNN [17] archi-
tecture. We use a variant of Mask-RCNN, initially proposed
by us in [21], which provides a super-class classification
(plant versus background), a sub-class classification (crop
and weed species), bounding box location, and pixel-wise
segmentation for each object in the scene. Providing these
classification results and pixel-wise labels allows for the
vision system to drive selective intervention tasks so that
weeds are only sprayed if they meet certain requirements.
To train Mask-RCNN with sub-class labels we use our
novel dataset SB21 and two previously released crop and
weed datasets: SB20 [22] and WeedAI [23]. In each dataset,
Fig. 3. Segment-view vs Rolling-view Planning; two separate segments
several variations occur naturally, including, weed species,
T0 andT1 withdifferentweedingdistributionsareshown.Anintermediate
cropandweeddensities,illuminationvariation,andshadow- Ti issubstantiallyhelpingtheplannertooptimizetheplannedrouteofthe
ingcausedbytheplatform.Thesevariationsmakethemodel weedingaxis(green)w.r.tthebaseline(red).
abletogeneralizebettertonewscenes.Tofurthergeneralize can better align new masks with existing tracklets. We also
our approach we also include strong data augmentation. employed the dynamic radius tracking approach since it
We employ multiple data augmentation techniques such improvesthetrackingofsmallplantsinourcomplexscenes.
as luminance variation and blur, additionally, we propose an
“illuminationbox“approachwhichsimulatesself-shadowing B. Rolling-view Observation Model
effects. For all of our augmentation techniques, we set a In our previous work [9] we developed a segment-view
probability of 0.5 that they will be used on an individual observation model. This segment-view-based model allows
basis. To augment the image luminance we randomly vary us to focus on an individual field segment, enabling us
the L channel of the Lab color space between ±15. RGB to cope with their distinct weed distributions. We derive
jitter can also be selected with a random color channel the distance between the weeding equipment and individual
variation of 5% and to simulate noise in the scene we also weeds assuming a weed distribution yielded by a Poisson
randomly employ Gaussian blur with a 3×3 kernel. Finally, process with an arrival rate of η = λ × Π, where Π
as we see shadowing caused by the robot in the WeedAI denotes the weeding width illustrated in Fig. 3. To un-
datasetandtoensureconsistencywiththeothertwodatasets derstand the spacing between the weeds (δ ) we use the
x
werandomlyinsertan“illuminationbox”.This“illumination robot’smotionalongthex-axiswithinitsframeofreference
box” replicates the shadowing effect by randomly inserting (F ) depicted in Fig. 3. While this method has proven its
R
a luminance increase (in the LAB color space) over the area worth, we believe that it is less adaptable to the changing
of a random rectangular box. As the natural shadowing does weed spatial distribution patterns and thus harms overall
not produce clean edges nor perfectly horizontal boxes we performance. To overcome this we propose a rolling-view
alsoblurtheedgesoftherectangleusingGaussianblurwith observation model. This model integrates discrete camera
a kernel size of 3 × 3 and a random rotation of the box observations into a comprehensive model of the entire field.
to ±10o. These augmentation techniques aim to artificially This new approach integrates discrete camera observations
extendourdatasetswhilealsoensuringbettergeneralization. into a comprehensive model of the entire field. Expanding
Oneofthetasksweperformhereisaweedingintervention the planning scope beyond single segments, allowing for
basedoninformeddecisions.Theseinformeddecisionscome more effective weeding strategies over a larger area. A key
from the type of plant being segmented (crop or weed) and advantage of this approach is illustrated in Figure 3 which
the size of the plant (growth stage). To achieve this level highlights that the previous segment-based approach would
of information we utilize the classification scores and the treat two views independently whereas the rolling window
masks generated by Mask-RCNN, and the registered depth approach updates the planned intervention across these two
information captured from our RGB-D sensor. This enables views iteratively. This enables the planning to be optimized
us to estimate the growth stage of a plant by converting the more flexibly without increasing the planning window size.
depth to a per-pixel area and accumulating over the pixel- By simply incorporating only one intermediate frame T ,
1
wiseinstance-basedsemanticsegmentationmask,inasimilar we achieve a notable enhancement in the weeding trajec2 -
method to that described in [16]. tory and overall performance. We have implemented this
The final step in our vision system is the tracking com- algorithm using multi-threading and dynamic programming
ponent, which is based on our prior work of crop-agnostic techniques that enable the rolling-view planning to be at a
monitoringbyHalsteadetal.[16].Weexploitthedepthand frequency > 500Hz on CPU (Intel® Core™ i7-12700K).
odometry information to reproject our pixel-wise segmenta- Therollingwindowplannerusesthemostrecentinformation.
tion to perform better tracklet matching. This reprojection This means we take the prior plan and update it only ifthere are new plants that need to be treated. This rolling-
view model not only refines the weeding process and inter-
image tracking but also compensates for the vision system’s
shortcomings, like missed detections or incorrect classifica-
tions.Theaccumulationofmultipledetectionsoverthesame
area considerably increases the accuracy of our predictions.
Furthermore,byanalyzingcontinuousfieldsegments,wecan
predict more precise weeding paths, leading to improved
overall efficiency in weed management.
C. Target-Space Management Fig.4. BiodiversityinFocus:Afieldareawithlowcropdensity,susceptible
toinvasiveweeds,andthepotentialroleofDicotplantsincontrollingweed
When a robot encounters multiple targets N beneath it, growth.
the primary objective is to engage each target using one of
introducedinSec.III-Awedeterminethetype,growthstage,
itsinterventionheadsHwhiletherobotisinmotion.Hence,
and distance of weeds in a cropping area. We introduce
beforethesetargetsentertheworkspaceoftheweedingtool,
the ’harmfulness’ factor κ, illustrated in Eq. (1), for each
it’s crucial to plan the motion for each intervention head.
weed type, ranking them based on their threat to the nearby
Consideringsetsofweedsinanygivenworkspacemotivates
crops. It is important to acknowledge that currently, there
a multi-query approach to the problem. We consider weeds
is no definitive method for assessing plant-wise harmfulness
to be presented as a set that motivates us to assign them to
effects in actual fields on different crops. However, in this
the H intervention heads.
work, we aim to build upon existing heuristics to facilitate
Hence, we use a high-level planner to distribute tar-
incorporatingthisinformationintofutureweedingstrategies.
gets between different intervention heads while ensuring
Hence, we derived this factor from phenotypic data, which
that all the targets will be visited at least once and the
helps our robots discern various weeding scenarios. It ranks
workload is properly balanced between all weeding axes.
weeds based on their threat to crops, using a methodology
In [9], we propose the Distance-based Target Assignment,
inspired by Dentika et al. [14], who proposed a similar
Static Work-space Division-based Target Assignment, and
conceptforpathogen-hostanddiseaseriskimposedbyweeds
Dynamic Work-space Division-based Target Assignment. In
on the crops, and was derived from comprehensive on-site
this paper, we will only use the static work-space division-
experiments and is formulated below:
based target assignment approach which based on our real
field experiments offers stable and reliable performance. α β ∆(w,p)
κ(w,p)= w w (1)
α
D. Bio-Diversity-Aware Plant-level Treatment p
Weed harmfulness is influenced by aggressiveness, com- In Eq. (1), the harmfulness effect κ(w,p) of weed w on
petition for water, and leaf size, affecting nearby crops. plant p is calculated where, α w and α p denote the size of
Species like barnyardgrass, pigweed, and lambsquarters can weed w and crop p in mm2, respectively. This is reflecting
significantlyoutcompetecropsforlight,water,andnutrients, thecompetitiverelationshipbetweenaweedanditsadjacent
reducingyieldandquality[11].Inmoisture-limitedenviron- crop, based on their sizes. Also, β w is the harmfulness
ments, this competition becomes more critical. Understand- factor of each specific weed category, noting that certain
ingthesefactorsisessentialforeffectiveweedmanagement, weeds should be eliminated from the field regardless of
recognizing that not all weeds are detrimental; some can their size or specific location. Furthermore, the ∆(w,p) is
enhance soil fertility and moisture retention. An example the Euclidean distance between crop p to weed w. This
scenario is depicted in Fig. 4 where dicots are considered acknowledges that weeds situated far from crops may not
beneficial. pose a significant threat, thus requiring no intervention. This
Therefore, robots must recognize and adapt to bio- approach promotes eco-friendly interventions by prioritizing
diversity when managing these varied weed threats. In this the most harmful weeds, thereby enhancing biodiversity and
case, a generalized approach to weed management won’t resource conservation.
suffice due to the diverse competitive behaviors of differ-
E. Intervention Heads Route Planning
ent weeds. We propose a novel weeding method enabling
BonnBot-Itoconsiderbio-diversityfactorsbydifferentiating We need to generate H independent and efficient routes
between weed species and their phenotypic characteristics, toguidetheinterventionheads,takingintoaccountassigned
assessingtheirthreatlevelsbasedoncompetitivenessfactors, targets, the intervention head’s position, the robot’s linear
and acting accordingly. This ensures not only the well-being speed,andthespeedandaccelerationlimitsofitslinearaxes.
and productivity of crops but also resource optimization To do this, the intervention controller embeds all the details
concerning weeding actions (i.e. spraying). about each plant in a uni-directional graph, including its
Relying upon the phenotypic information, we aim to type, segmentation, estimated size, boundaries, plant center,
facilitate our robots’ understanding of different weeding andcorrespondingbio-diversitycharacteristics.Inthisgraph,
scenarios in the real field. Using the monitoring technique each node represents a detected plant and every edge scoresthe motion feasibility between two nodes. As introduced
in [9], the probability of visiting the j-th weed with i-th
weeding nozzle is computed as follows,
(cid:32) (cid:33)
γ δx
P =P < ij , (2)
ij ϑ δy
ij
Fig.5. ExampleimageofdatasetSB21(left)andmulti-classannotations
where ϑ and γ denote the maximum velocity of linear axes representingdifferenttypesofcropsandweedsusingdifferentcolors(right).
and maximum linear velocity of the robot, δx and δy denote
IV. EXPERIMENTALSETUP
the relative distance between the i-th nozzle to the j-th
weed. In this scheme, we define each edge to consist of Similar to our prior work [9], we consider that the robot
a feasibility score Γ using the logistic function Eq. (3) of moves with constant speed γ = 0.5m/s along a crop row
jk
motion between nodes (weeds) j and k. with weed density of λ weeds/m2 and we set the velocity
of the linear actuators to ϑ = 5m/s. All experiments are
1
Γ = , (3) conducted using 4 linear axes.
jk 1+e−ω(Sjk)
A. Real-Field Models
where S is the favorability score in seconds
jk
The field models are sourced from the crop monitoring
δx δy methoddetailedSec.III-Aandcompiledintoarepresentative
S = jk − jk, (4)
jk γ ϑ row format. We generate models from three real-world
fields captured on either sugar-beet or corn crops at CKA
and the weighting parameter ω adjusts how quickly the across two years. This creates complex scenes to evaluate as
favorability score makes the Γ change from the boundary there are large differences in the weed densities across the
jk
score (0.5) to being very likely (1.0). The boundary score datasets. These models contain four distinct weed densities:
occurs when S = 0 and represents when there is just low (CN20), moderate (SB20-S2), high (SB20-S1, SB21-
jk
enough time for the tool to transition from node j to k. S1), and very high (SB21-S2). To evaluate the performance
In a greedy algorithm, every potential route is calculated of conducted operation both in simulation and real-fields
by permuting all nodes in the graph, considering the edge we use the number of untreated weeds and from now on
directions in the node graph. The best route is the one that we call it loss (in percentage). Furthermore, the traveled
visits a high number of nodes with high feasibility. The distance (in meters) of the linear axis could provide us with
best performed method utilized in [9] was nOTSP which useful information about the load balance and effectiveness
is a modification of the conventional traveling salesman of planning.
problem.Theplanningstrategiesgenerateasetofmpossible
trajectories T⃗ = [T⃗ ,...,T⃗ ], where each T⃗ represents B. SB21 Dataset
0 m−1 t
an organized list of weed locations in the trajectory, con- We utilized BonnBot-I to create a series of distinct
sisting of q t elements in form of T⃗ t = [w 0,...,w qt−1]. datasets tailored for precision agricultural applications. In
Usingthefollowingcriteriawecalculatethesuccesscriterion our prior works, the datasets were acquired at sugar-beet
C⃗=[C 0,...,C m−1] for each trajectory in T⃗. (SB20)[22]andcorn(CN20)[9]fieldswithintheUniversity
of Bonn’s Klein-Altendorf campus (CKA). Both datasets


1 q (cid:80)t−1
Γ(n ,n ), for all Γ≥ρ featuredsparselyannotatedvideo sequences withnooverlap
C⃗(T⃗,ρ)= q t r=0 r r+1 (5) between annotated frames. In this work, we introduce a new
 0 otherwise sugar-beet dataset (SB21) captured at CKA during 2021.
SB21 is comprised of 84 RGB-D frames of crops and 12
whereρ=0.6isacutoffthresholdappliedtoeachfeasibility
distinctweedcategories,totaling942instancesofsugarbeet
score ensuring the planner only considers trajectories with
and 4989 instances of weeds. The images are divided into
all reachable targets. To incorporate the harmfulness factor,
train,validation,andevaluationsetswithrespectively56,14,
we use the T⃗ where C > 0, and pick the trajectory with
t and14images.Annotationsincludepixel-wisesegmentation
maximum total harmfulness score K using,
onaninstancebasis,boundingboxes,andstemlocationsfor
each instance. Similar to SB20 and CN20, the images are
argmaxK(T⃗); where K(T⃗
)=q (cid:88)t−1
κ(cid:16) T⃗ (r)(cid:17) (6) augmented with robot pose and velocity information from
t t
t BonnBot-I. The data structures proposed here enable the
r=0
creation of real temporal sequences, where only the final
and κ is the harmfulness factor, Eq. (1), of the r-th node frame in the sequence is labeled, as detailed in [22], thereby
r
in T⃗ . This leads to the best trajectory being the one that reestablishing temporal relationships between annotated and
t
has the largest number of reachable targets and high-priority non-annotated frames. Fig. 5 provides an example of an
weeds. annotated image from the SB21 dataset.V. EXPERIMENTALEVALUATIONS beneficial dicots and only intervening where it is essential
for crop health while preserving and promoting biodiversity.
In this section, we present the outcomes of various exper-
This weed classification approach is particularly crucial
iments conducted both in simulated and real-world settings.
in challenging scenarios. These scenarios can include high
A. Segment-view observations vs Rolling-view observations weed density, restricted robot velocity, restricted linear axis
speed,orherbicideusagelimitations.Hence,thesystemmust
First, we illustrate the efficiency of the weeding system
manage certain losses while achieving optimal performance.
onreal-fieldmodels,showcasingthenOTSPapproachintwo
To test our system’s resilience and capability under extreme
distinctobservationmodes,Segment-view(baseline)andour
conditions, we devised an experiment where the robot oper-
novelRolling-viewobservations.Ourevaluationsareapplied
ates at a speed two times the normal γ =1.0m/s.
to the test rows within the three datasets (CN20, SB20,
In this analysis, we utilized the field models from our
and SB21). Tab. I summarizes the difference in planning
previous experiment but with two modifications. First, we
performance and traveled distance of weeding axes between
designate two priority levels where a low-priority for weed-
the two observation models (Segment-view (baseline) and
ingisgiventopotentiallybeneficialdicotsandahigh-priority
Rolling-view) deployed on the real-field models. Below we
is given to all other weeds. To represent the priority levels
brieflydescribetheresultsinTab.Iintermsofweeddensity,
we give a weight of 0.1 and 1.0 for low- and high-priority
from low to very high.
respectively. Second, the occurrence of high-priority weeds
Lowweeddensity:bothmethodsdemonstratecomparable
wassettobeone-tenthofthatoflow-priority.Consequently,
performance in areas with lower weed density achieving
this setup required the bio-diversity-aware system to adjust
zero loss on CN20 and leaving no untreated weeds in
its weeding trajectories to prioritize the less frequent, high-
the fields. The Rolling-view model, however, required less
priorityweeds,evenifitmeantpotentiallyoverlookingsome
travel distance compared to the Segment-view. However, the
of the low-priority weeds. In the following, we compare the
varianceinthetraveleddistanceoftheweedingaxesseemsto
bio-diversity-aware(Bio-Div.)approachwithabaseline(not-
be lower when using Segment-view planning. This suggests
bio-diversity-aware)methodunderextremeconditionsonthe
a more balanced distribution of targets across the different
same real-field models used in the previous experiment. The
implements.Moderateweeddensity:Similartolowdensity,
weeding loss for the Bio-Div. the approach is very similar
both models achieved 0.0% loss, with no noticeable differ-
to the baseline. It leaves no untreated weed in the fields,
enceinweedingefficiency.However,theRolling-viewmodel
indicatingitscomparableeffectivenessinscenarioswithlow
had a slightly higher travel distance (1.9±0.9m) than the
to moderate weed densities. However, in cases of very high
Segment-view(1.4±0.2m).Highandveryhighweedden-
weeddensities(SB21-S1,SB21-S2),thereisaminor(<2%)
sity: In this scenario, the Rolling-view model outperformed
increase in weeding loss with the Bio-Div. approach. This
the Segment-view model. The Rolling-view achieved only
suggests a small trade-off in performance at extremely high
a 6.4% loss compared to the Segment-view’s 11.9% loss.
weed densities. The average traveled distance of axes using
Additionally,theRolling-viewrequiredasubstantiallylower
both observation methods is generally similar or marginally
traveldistancethantheSegment-view,showingtheefficiency
higher(<0.2monaverage)fortheBio-Div.approachacross
of the Rolling-view method in more complex situations.
all field models, reflecting the method’s thoroughness in
Overall, the Rolling-view planning method surpasses the
targeting specific weed priorities and achieving bio-diversity
baselinewithanaverageabsoluteimprovementof3.5%over
considerations. Additionally, to enhance our evaluation of
all the field models with a maximum and minimum absolute
the operation’s specifics, we detailed the treatment percent-
improvement of 5.5% on SB20-S1 and 1.7% on SB21-S2,
age for each weed type individually and their results are
respectively.
presented in Tab. II.
B. Bio-diversity aware weeding operation When considering the low-priority weeds, the Bio-Div.
method achieves slightly reduced performance when com-
The bio-diversity-aware system should accurately differ-
pared to the baseline. On the other hand, this reduced
entiate between crops and weeds. This includes detecting
TABLEII
TABLEI
WEEDINGPERFORMANCES(TREATMENTPERCENTAGE)OFBONNBOT-I
WEEDINGPERFORMANCEOFBONNBOT-IWITHTWOOBSERVATION
WITHBASELINEWEEDINGANDBIO-DIVERSITY-AWARESCHEMESON
MODELSSEGMENT-VIEWANDROLLING-VIEWDENOTINGWEEDING
REAL-FIELDMODELS.
LOSS(%)ANDTRAVELEDDISTANCE(m)OFTHELINEARAXIS.
Weed1(LowPriority) Weed2(HighPriority)
Weed-density Segment-view Rolling-view FieldModel (not-Bio-Div.) (Bio-Div.) (not-Bio-Div.) (Bio-Div.)
- Avg/m2 (%) (m) (%) (m) (%) (%) (%) (%)
CN20 low 3.1 0.0 2.7±0.2 0.0 2.0±1.6 CN20 73.3 73.3 56.6 56.6
SB20-S1 moderate 8.2 0.0 1.4±0.2 0.0 1.9±0.9 SB20-S1 47.5 44.3 56.0 60.2
SB20-S2 high 15.4 11.9 10.1±0.9 6.4 4.1±2.1 SB20-S2 42.5 40.5 53.5 63.5
SB21-S1 high 22.3 17.2 6.1±5.3 14.1 2.8±2.6 SB21-S1 18.0 15.2 19.1 38.8
SB21-S2 veryhigh 81.2 38.2 13.4±8.2 36.5 5.2±3.1 SB21-S2 7.0 5.1 7.0 17.4Fig. 6. Real-field intervention examples; Different spray footprints of BonnBot-I weeding operation in campus CKA of the University of Bonn, with
differentweeddensitiesandvariousweedtypes.
performance could be interpreted as a positive point, where
keeping low-priority weeds in the field could benefit the
ecosystem and align with bio-diversity purposes. However,
the benefit of this approach is evident in the ability of the
Bio-Div.approachtoachievestrongerperformancewhentar-
geting higher-threat weeds. Our approach is able to improve
performance on all but the lowest weed distribution (CN20)
where performance is identical. This illustrates the Bio-Div. Fig.7. BonnBot-ISimulation;Anexamplefieldwithweeddensityλ≊12
with planned trajectories of three linear axes depicted in different colors
approach’s effectiveness in prioritizing and managing high-
(blue,green,andorange).Alldotsthatliealongoneofthelinesareweeds
priority weeds. that will be treated, while all the dots that do not lie upon a line are not
abletobetreated.
C. Real-World Intervention Performance
interventions in the real fields.
In [9] we only evaluated the weeding performance on
The trial fields contained regions with low (< 5) to
recorded data and considered non-overlapping segments of
high weed (> 10) densities, therefore offering challenging
observationsforrunningtheexperiments.Tofurtherevaluate
scenariosfortestingBonnBot-Iweedingcapabilities.Intotal
the whole system’s performance, we deployed BonnBot-I
our two fields contain 1038 weeds, the sugar-beets in the
in a series of unseen fields with different weed distribu-
crop-weedfieldshadplantsinthefour-tosix-leafstage(ap-
tions,illuminationconditions,andcultivars.Theexperiments
proximately three to six weeks old). Tab. III summarizes the
were conducted on various days, under a mix of weather
performanceofBonnBot-Iinbothweed-onlyandcrop-weed
conditions including partial cloudiness and sunshine, and
regions. Initial evaluations in the crop-weed region showed,
on different types of soil ranging from solid and compact
that BonnBot-I has treated 23 crops falsely which counts as
to relatively muddy. Additionally, the plants tested were
atotalof4%ofvisitedcropsinthefield.Furthermore,ofthe
at various growth stages, from the two-leaf stage up to
totalweedsinthefields,weaccuratelydetected886.Ofthese
the eight-leaf stage. The field experiments with the real
detected weeds BonnBot-I did not perform an intervention
robot were conducted at the CKA, covering nearly 100
on 121 of them.
squaremetersofsugar-beetfield.Thisevaluationoutlinesthe
Consequently, the weeding loss attributable to planning
most important metrics associated with the operation of the
or intervention constraints stands at 11.6%. This loss could
robot. These metrics include the number of missed weeds,
beaddressedbyfine-tuningplanningstrategies,addingmore
the number of partially treated weeds, and the number of
weeding axes, increasing the velocity of the linear axis, or
accurately treated weeds. We quantitatively evaluated our
decreasing the robot’s linear velocity. The remaining 152
performanceontwodifferentweedingscenarios:crop-weed;
weeds(1038−886)weremissedbecauseofsystemicissues,
and weed-only.
notably the vision system’s performance under difficult real-
During all evaluations, we used the Rolling-view obser-
time and challenging lighting conditions. Hence, the overall
vation model enabling more accurate planning in real-world
scenarios. An example of this planning approach is depicted TABLEIII
in Fig. 7 where only three linear axes are utilized (indicated REAL-WORLDWEEDINGPERFORMANCEOFBONNBOT-IINWEED-ONLY
by the three colors). The weed-only field model was used to ANDCROP-WEEDREGIONS.
evaluate our intervention approach independently of vision
systemfailures(i.e.classifyingaweedascroporviceversa). Crop Weed
FieldModel FalseHits TotalWeeds Acc.Hits Par.Hits Missed
Our quantitative analysis is based on visually interpreting
Weed-Only - 473 183 192 98
the footage captured on a camera mounted at the rear of
BonnBot-I. Fig. 6 demonstrates the footprint of weeding Crop-Weed 4% 565 177 213 175loss of the system added up to 26.3% of the total number of many’s Excellence Strategy - EXC 2070 – 390732324.
weed plants in the fields (including the detected-and-missed
REFERENCES
and not-detected instances).
Further examination showed that in the weed-only region, [1] M. L. Zingsheim and T. F. Do¨ring, “What weeding robots need to
know about ecology,” Agriculture, Ecosystems & Environment, vol.
from the total of 98 missed weeds, a total of 39 plants 364,p.108861,2024.
remained untreated solely because of the vision system’s [2] I.Heap,“Globalperspectiveofherbicide-resistantweeds,”Pestman-
inability to detect them. Similarly, in the crop-weed re-
agementscience,vol.70,no.9,pp.1306–1315,2014.
[3] B. L. Steward, L. F. Tian, and L. Tang, “Distance–based control
gion, 113 weeds were missed due to vision system failure systemformachinevision–basedselectivespraying,”Transactionsof
highlighting the limitations of the vision system and the theASAE,vol.45,no.5,p.1255,2002.
challenges encountered in real-field conditions. This loss [4] O.Bawden,J.Kulk,R.Russell,C.McCool,A.English,F.Dayoub,
C. Lehnert, and T. Perez, “Robot for weed species plant-specific
could be reduced by improving the vision system and using management,” Journal of Field Robotics, vol. 34, pp. 1179–1199,
more advanced DNN architecture in the future. 2017.
Inthereal-worldfieldtrialsofBonnBot-I765weedswere [5] C.-L. Chang, B.-X. Xie, and S.-C. Chung, “Mechanical control with
adeeplearningmethodforpreciseweedingonafarm,”Agriculture,
successfully treated. Of the treated weeds, on average 47% vol.11,no.11,p.1049,2021.
were considered to be treated in a highly accurate manner, [6] X. Wu, S. Aravecchia, P. Lottes, C. Stachniss, and C. Pradalier,
183 and 177 weeds in weed-only and crop-weed regions, “Roboticweedcontrolusingautomatedweedandcropclassification,”
JournalofFieldRobotics,vol.37,no.2,pp.322–340,2020.
respectively. This means the spray footprint was centered [7] J. Ascard, P. Hatcher, B. Melander, M. Upadhyaya, and R. Black-
on the weed. The remaining 53% were treated successfully shaw, “10 thermal weed control,” Non-chemical weed management:
but with less accuracy, with an offset of nearly 2cm. They
principles,conceptsandtechnology,pp.155–175,2007.
[8] Y. Xiong, Y. Ge, Y. Liang, and S. Blackmore, “Development of
are considered to be partial treatments as they still cover a prototype robot and fast path-planning algorithm for static laser
a large proportion of the weed. This reduced performance weeding,” Computers and Electronics in Agriculture, vol. 142, pp.
494–503,2017.
is likely linked to the variable conditions encountered in
[9] A. Ahmadi, M. Halstead, and C. McCool, “Bonnbot-i: A precise
real-field settings. Factors such as slight weather changes, weedmanagementandcropmonitoringplatform,”in2022IEEE/RSJ
like unexpected wind gusts, can alter spray distribution by International Conference on Intelligent Robots and Systems (IROS).
IEEE,2022,pp.9202–9209.
a few centimeters or move plant leaves, thereby impacting
[10] E.-C. Oerke, “Crop losses to pests,” The Journal of Agricultural
the accuracy of weed detection and treatment. While these Science,vol.144,no.1,pp.31–43,2006.
errors occurred due to several factors we still consider this [11] R.L.Zimdahl,“Weed-cropcompetition:areview,”2007.
[12] D. Slaughter, D. Giles, and D. Downey, “Autonomous robotic weed
to be a successful treatment of the weeds in the field.
controlsystems:Areview,”Computersandelectronicsinagriculture,
vol.61,no.1,pp.63–78,2008.
VI. CONCLUSION
[13] A.Guglielmini,A.Verdu´,andE.Satorre,“Competitiveabilityoffive
In this paper, we introduced advancements in weed man- common weed species in competition with soybean,” International
journalofpestmanagement,vol.63,no.1,pp.30–36,2017.
agement, enhancing the capabilities of BonnBot-I for con- [14] P. Dentika, H. Ozier-Lafontaine, and L. Penet, “Weeds as pathogen
ducting precise bio-diversity-aware weeding of sugar-beet hostsanddiseaseriskforcropsinthewakeofareduceduseofherbi-
fields. We introduce an advanced planning method that cides:Evidencefromyam(dioscoreaalata)fieldsandcolletotrichum
pathogensinthetropics,”JournalofFungi,vol.7,no.4,p.283,2021.
employs a rolling-view technique, leading to an average [15] H. Zhu, Y. Zhang, D. Mu, L. Bai, X. Wu, H. Zhuang, and H. Li,
absolute performance enhancement of 3.4%. Furthermore, “Research on improved yolox weed detection based on lightweight
our experiments in real-fields with real-robot demonstrated
attentionmodule,”CropProtection,vol.177,p.106563,2024.
[16] M.Halstead,A.Ahmadi,C.Smitt,O.Schmittmann,andC.Mccool,
that BonnBot-I weeding strategy could be effective only “Cropagnosticmonitoringdrivenbydeeplearning,”FrontiersinPlant
by having a loss of 11.66% due to planning or intervention Science,p.2937,2021.
constraints. We present, for the first time, a concept of bio- [17] K. He, G. Gkioxari, P. Dolla´r, and R. Girshick, “Mask r-cnn,” in
ProceedingsoftheIEEEinternationalconferenceoncomputervision,
diversity-aware weed management and assess its practicality 2017,pp.2961–2969.
in real-world scenarios. Our approach not only improves [18] M. Vahdanjoo, R. Gislum, and C. A. G. Sørensen, “Operational,
the precision and effectiveness of agricultural robots but economic, and environmental assessment of an agricultural robot in
seedingandweedingoperations,”AgriEngineering,vol.5,no.1,pp.
also emphasizes the necessity of incorporating ecological 299–324,2023.
considerations into crop management. In conclusion, our [19] M. Zhou, H. Jiang, Z. Bing, H. Su, and A. Knoll, “Design and
research indicates that performance variations in weeding evaluation of the target spray platform,” International Journal of
Advanced Robotic Systems, vol. 18, no. 2, p. 1729881421996146,
technologies are often due to dynamic real-field conditions, 2021.
such as unexpected weather shifts impacting weed detection [20] C.-L. Chang, B.-X. Xie, and S.-C. Chung, “Mechanical control
and treatment accuracy. Future work will aim to enhance with a deep learning method for precise weeding on a farm,”
Agriculture, vol. 11, no. 11, 2021. [Online]. Available: https:
these systems’ adaptability to such environmental factors, //www.mdpi.com/2077-0472/11/11/1049
focusing on developing more robust and responsive vision [21] M.Halstead,C.McCool,S.Denman,T.Perez,andC.Fookes,“Fruit
systemstoensureconsistentandeffectiveweedmanagement
quantityandripenessestimationusingaroboticvisionsystem,”IEEE
RoboticsandAutomationLetters,vol.3,no.4,pp.2995–3002,2018.
in diverse agricultural settings. [22] A.Ahmadi,M.Halstead,andC.McCool,“Virtualtemporalsamples
for recurrent neural networks: applied to semantic segmentation in
ACKNOWLEDGEMENTS agriculture,”inGermanconferenceonpatternrecognition,2021.
[23] M.Halstead,P.Zimmer,andC.McCool,“Across-domainchallenge
This work was funded by the Deutsche Forschungsge- withpanopticsegmentationinagriculture,”TheInternationalJournal
meinschaft(DFG,GermanResearchFoundation)underGer- ofRoboticsResearch,vol.0,no.0,p.0,2024.