
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>From Interaction to Impact: Towards Safer AI Agents Through Understanding and Evaluating UI Operation Impacts</h3>
                <p>Authors: Zhuohao Jerry ZhangEldon SchoopJeffrey NicholsAnuj MahajanAmanda Swearngin</p>
                <p><a href="http://arxiv.org/abs/2410.09006v1">Link to paper</a></p>
                <p>With advances in generative AI there is increasing work towards creatingautonomous agents that can manage daily tasks by operating user interfacesUIs. While prior research has studied the mechanics of how AI agents mightnavigate UIs and understand UI structure the effects of agents and theirautonomous actions-particularly those that may be risky or irreversible-remainunder-explored. In this work we investigate the real-world impacts andconsequences of UI actions by AI agents. We began by developing a taxonomy ofthe impacts of UI actions through a series of workshops with domain experts.Following this we conducted a data synthesis study to gather realistic UIscreen traces and action data that users perceive as impactful. We then usedour impact categories to annotate our collected data and data repurposed fromexisting UI navigation datasets. Our quantitative evaluations of differentlarge language models LLMs and variants demonstrate how well different LLMscan understand the impacts of UI actions that might be taken by an agent. Weshow that our taxonomy enhances the reasoning capabilities of these LLMs forunderstanding the impacts of UI actions but our findings also revealsignificant gaps in their ability to reliably classify more nuanced or complexcategories of impact.</p>
                <p>Last Updated: 2024-10-11 17:24:00 UTC</p>
                <button class="interpret-button" data-id="2410.09006v1">Interpret</button>
                <div id="interpretation-2410.09006v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>UniGlyph: A Seven-Segment Script for Universal Language Representation</h3>
                <p>Authors: G. V. Bency SherinA. Abijesh EuphrineA. Lenora MoreenL. Arun Jose</p>
                <p><a href="http://arxiv.org/abs/2410.08974v1">Link to paper</a></p>
                <p>UniGlyph is a constructed language conlang designed to create a universaltransliteration system using a script derived from seven-segment characters.The goal of UniGlyph is to facilitate cross-language communication by offeringa flexible and consistent script that can represent a wide range of phoneticsounds. This paper explores the design of UniGlyph detailing its scriptstructure phonetic mapping and transliteration rules. The system addressesimperfections in the International Phonetic Alphabet IPA and traditionalcharacter sets by providing a compact versatile method to represent phoneticdiversity across languages. With pitch and length markers UniGlyph ensuresaccurate phonetic representation while maintaining a small character set.Applications of UniGlyph include artificial intelligence integrations such asnatural language processing and multilingual speech recognition enhancingcommunication across different languages. Future expansions are discussedincluding the addition of animal phonetic sounds where unique scripts areassigned to different species broadening the scope of UniGlyph beyond humancommunication. This study presents the challenges and solutions in developingsuch a universal script demonstrating the potential of UniGlyph to bridgelinguistic gaps in cross-language communication educational phonetics andAI-driven applications.</p>
                <p>Last Updated: 2024-10-11 16:46:09 UTC</p>
                <button class="interpret-button" data-id="2410.08974v1">Interpret</button>
                <div id="interpretation-2410.08974v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Zero-Shot Pupil Segmentation with SAM 2: A Case Study of Over 14 Million Images</h3>
                <p>Authors: Virmarie MaquilingSean Anthony ByrneDiederick C. NiehorsterMarco CarminatiEnkelejda Kasneci</p>
                <p><a href="http://arxiv.org/abs/2410.08926v1">Link to paper</a></p>
                <p>We explore the transformative potential of SAM 2 a vision foundation modelin advancing gaze estimation and eye tracking technologies. By significantlyreducing annotation time lowering technical barriers through its ease ofdeployment and enhancing segmentation accuracy SAM 2 addresses criticalchallenges faced by researchers and practitioners. Utilizing its zero-shotsegmentation capabilities with minimal user input-a single click per video-wetested SAM 2 on over 14 million eye images from diverse datasets includingvirtual reality setups and the worlds largest unified dataset recorded usingwearable eye trackers. Remarkably in pupil segmentation tasks SAM 2 matchesthe performance of domain-specific models trained solely on eye imagesachieving competitive mean Intersection over Union mIoU scores of up to 93without fine-tuning. Additionally we provide our code and segmentation masksfor these widely used datasets to promote further research.</p>
                <p>Last Updated: 2024-10-11 15:50:53 UTC</p>
                <button class="interpret-button" data-id="2410.08926v1">Interpret</button>
                <div id="interpretation-2410.08926v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning</h3>
                <p>Authors: Majeed KazemitabaarOliver HuangSangho SuhAustin Z. HenleyTovi Grossman</p>
                <p><a href="http://arxiv.org/abs/2410.08922v1">Link to paper</a></p>
                <p>Novice programmers are increasingly relying on Large Language Models LLMsto generate code for learning programming concepts. However this interactioncan lead to superficial engagement giving learners an illusion of learning andhindering skill development. To address this issue we conducted a systematicdesign exploration to develop seven cognitive engagement techniques aimed atpromoting deeper engagement with AI-generated code. In this paper we describeour design process the initial seven techniques and results from abetween-subjects study N82. We then iteratively refined the top techniquesand further evaluated them through a within-subjects study N42. We evaluatethe friction each technique introduces their effectiveness in helping learnersapply concepts to isomorphic tasks without AI assistance and their success inaligning learners perceived and actual coding abilities. Ultimately ourresults highlight the most effective technique: guiding learners through thestep-by-step problem-solving process where they engage in an interactivedialog with the AI prompting what needs to be done at each stage before thecorresponding code is revealed.</p>
                <p>Last Updated: 2024-10-11 15:49:42 UTC</p>
                <button class="interpret-button" data-id="2410.08922v1">Interpret</button>
                <div id="interpretation-2410.08922v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective</h3>
                <p>Authors: Pooriya JamieReyhaneh HajihashemiSharareh Alipour</p>
                <p><a href="http://arxiv.org/abs/2410.08899v1">Link to paper</a></p>
                <p>Integrating large language models LLMs like ChatGPT is revolutionizing thefield of computer science education. These models offer new possibilities forenriching student learning and supporting teaching assistants TAs inproviding prompt feedback and supplementary learning resources. This researchdelves into the use of ChatGPT in a data structures and algorithms DSAcourse particularly when combined with TA supervision. The findingsdemonstrate that incorporating ChatGPT with structured prompts and active TAguidance enhances students understanding of intricate algorithmic conceptsboosts engagement and elevates academic performance. However challenges existin addressing academic integrity and the limitations of LLMs in tacklingcomplex problems. The study underscores the importance of active TA involvementin reducing students reliance on AI-generated content and amplifying theoverall educational impact. The results suggest that while LLMs can beadvantageous for education their successful integration demands continuousoversight and a thoughtful balance between AI and human guidance.</p>
                <p>Last Updated: 2024-10-11 15:18:48 UTC</p>
                <button class="interpret-button" data-id="2410.08899v1">Interpret</button>
                <div id="interpretation-2410.08899v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>PEAR: A Robust and Flexible Automation Framework for Ptychography Enabled by Multiple Large Language Model Agents</h3>
                <p>Authors: Xiangyu YinChuqiao ShiYimo HanYi Jiang</p>
                <p><a href="http://arxiv.org/abs/2410.09034v1">Link to paper</a></p>
                <p>Ptychography is an advanced computational imaging technique in X-ray andelectron microscopy. It has been widely adopted across scientific researchfields including physics chemistry biology and materials science as wellas in industrial applications such as semiconductor characterization. Inpractice obtaining high-quality ptychographic images requires simultaneousoptimization of numerous experimental and algorithmic parameters.Traditionally parameter selection often relies on trial and error leading tolow-throughput workflows and potential human bias. In this work we develop thePtychographic Experiment and Analysis Robot PEAR a framework thatleverages large language models LLMs to automate data analysis inptychography. To ensure high robustness and accuracy PEAR employs multiple LLMagents for tasks including knowledge retrieval code generation parameterrecommendation and image reasoning. Our study demonstrates that PEARsmulti-agent design significantly improves the workflow success rate even withsmaller open-weight models such as LLaMA 3.1 8B. PEAR also supports variousautomation levels and is designed to work with customized local knowledgebases ensuring flexibility and adaptability across different researchenvironments.</p>
                <p>Last Updated: 2024-10-11 17:50:59 UTC</p>
                <button class="interpret-button" data-id="2410.09034v1">Interpret</button>
                <div id="interpretation-2410.09034v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The Dynamics of Social Conventions in LLM populations: Spontaneous Emergence, Collective Biases and Tipping Points</h3>
                <p>Authors: Ariel Flint AsheryLuca Maria AielloAndrea Baronchelli</p>
                <p><a href="http://arxiv.org/abs/2410.08948v1">Link to paper</a></p>
                <p>Social conventions are the foundation for social and economic life. Aslegions of AI agents increasingly interact with each other and with humanstheir ability to form shared conventions will determine how effectively theywill coordinate behaviors integrate into society and influence it. Here weinvestigate the dynamics of conventions within populations of Large LanguageModel LLM agents using simulated interactions. First we show that globallyaccepted social conventions can spontaneously arise from local interactionsbetween communicating LLMs. Second we demonstrate how strong collective biasescan emerge during this process even when individual agents appear to beunbiased. Third we examine how minority groups of committed LLMs can drivesocial change by establishing new social conventions. We show that once theseminority groups reach a critical size they can consistently overturnestablished behaviors. In all cases contrasting the experimental results withpredictions from a minimal multi-agent model allows us to isolate the specificrole of LLM agents. Our results clarify how AI systems can autonomously developnorms without explicit programming and have implications for designing AIsystems that align with human values and societal goals.</p>
                <p>Last Updated: 2024-10-11 16:16:38 UTC</p>
                <button class="interpret-button" data-id="2410.08948v1">Interpret</button>
                <div id="interpretation-2410.08948v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>PILLAR: an AI-Powered Privacy Threat Modeling Tool</h3>
                <p>Authors: Majid MollaeefarAndrea BissoliSilvio Ranise</p>
                <p><a href="http://arxiv.org/abs/2410.08755v1">Link to paper</a></p>
                <p>The rapid evolution of Large Language Models LLMs has unlocked newpossibilities for applying artificial intelligence across a wide range offields including privacy engineering. As modern applications increasinglyhandle sensitive user data safeguarding privacy has become more critical thanever. To protect privacy effectively potential threats need to be identifiedand addressed early in the system development process. Frameworks like LINDDUNoffer structured approaches for uncovering these risks but despite theirvalue they often demand substantial manual effort expert input and detailedsystem knowledge. This makes the process time-consuming and prone to errors.Current privacy threat modeling methods such as LINDDUN typically rely oncreating and analyzing complex data flow diagrams DFDs and systemdescriptions to pinpoint potential privacy issues. While these approaches arethorough they can be cumbersome relying heavily on the precision of the dataprovided by users. Moreover they often generate a long list of threats withoutclear guidance on how to prioritize them leaving developers unsure of where tofocus their efforts. In response to these challenges we introduce PILLARPrivacy risk Identification with LINDDUN and LLM Analysis Report a new toolthat integrates LLMs with the LINDDUN framework to streamline and enhanceprivacy threat modeling. PILLAR automates key parts of the LINDDUN processsuch as generating DFDs classifying threats and prioritizing risks. Byleveraging the capabilities of LLMs PILLAR can take natural languagedescriptions of systems and transform them into comprehensive threat modelswith minimal input from users reducing the workload on developers and privacyexperts while improving the efficiency and accuracy of the process.</p>
                <p>Last Updated: 2024-10-11 12:13:03 UTC</p>
                <button class="interpret-button" data-id="2410.08755v1">Interpret</button>
                <div id="interpretation-2410.08755v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Edge AI Collaborative Learning: Bayesian Approaches to Uncertainty Estimation</h3>
                <p>Authors: Gleb RadchenkoVictoria Andrea Fill</p>
                <p><a href="http://arxiv.org/abs/2410.08651v1">Link to paper</a></p>
                <p>Recent advancements in edge computing have significantly enhanced the AIcapabilities of Internet of Things IoT devices. However these advancementsintroduce new challenges in knowledge exchange and resource managementparticularly addressing the spatiotemporal data locality in edge computingenvironments. This study examines algorithms and methods for deployingdistributed machine learning within autonomous network-capable AI-enablededge devices. We focus on determining confidence levels in learning outcomesconsidering the spatial variability of data encountered by independent agents.Using collaborative mapping as a case study we explore the application of theDistributed Neural Network Optimization DiNNO algorithm extended withBayesian neural networks BNNs for uncertainty estimation. We implement a 3Denvironment simulation using the Webots platform to simulate collaborativemapping tasks decouple the DiNNO algorithm into independent processes forasynchronous network communication in distributed learning and integratedistributed uncertainty estimation using BNNs. Our experiments demonstrate thatBNNs can effectively support uncertainty estimation in a distributed learningcontext with precise tuning of learning hyperparameters crucial for effectiveuncertainty assessment. Notably applying Kullback-Leibler divergence forparameter regularization resulted in a 12-30 reduction in validation lossduring distributed BNN training compared to other regularization strategies.</p>
                <p>Last Updated: 2024-10-11 09:20:16 UTC</p>
                <button class="interpret-button" data-id="2410.08651v1">Interpret</button>
                <div id="interpretation-2410.08651v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Kaleidoscope: Learnable Masks for Heterogeneous Multi-agent Reinforcement Learning</h3>
                <p>Authors: Xinran LiLing PanJun Zhang</p>
                <p><a href="http://arxiv.org/abs/2410.08540v1">Link to paper</a></p>
                <p>In multi-agent reinforcement learning MARL parameter sharing is commonlyemployed to enhance sample efficiency. However the popular approach of fullparameter sharing often leads to homogeneous policies among agents potentiallylimiting the performance benefits that could be derived from policy diversity.To address this critical limitation we introduce emphKaleidoscope a noveladaptive partial parameter sharing scheme that fosters policy heterogeneitywhile still maintaining high sample efficiency. Specifically Kaleidoscopemaintains one set of common parameters alongside multiple sets of distinctlearnable masks for different agents dictating the sharing of parameters. Itpromotes diversity among policy networks by encouraging discrepancy among thesemasks without sacrificing the efficiencies of parameter sharing. This designallows Kaleidoscope to dynamically balance high sample efficiency with a broadpolicy representational capacity effectively bridging the gap between fullparameter sharing and non-parameter sharing across various environments. Wefurther extend Kaleidoscope to critic ensembles in the context of actor-criticalgorithms which could help improve value estimations.Our empiricalevaluations across extensive environments including multi-agent particleenvironment multi-agent MuJoCo and StarCraft multi-agent challenge v2demonstrate the superior performance of Kaleidoscope compared with existingparameter sharing approaches showcasing its potential for performanceenhancement in MARL. The code is publicly available aturlhttps://github.com/LXXXXR/Kaleidoscope.</p>
                <p>Last Updated: 2024-10-11 05:22:54 UTC</p>
                <button class="interpret-button" data-id="2410.08540v1">Interpret</button>
                <div id="interpretation-2410.08540v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Linear Convergence of Diffusion Models Under the Manifold Hypothesis</h3>
                <p>Authors: Peter PotaptchikIskander AzangulovGeorge Deligiannidis</p>
                <p><a href="http://arxiv.org/abs/2410.09046v1">Link to paper</a></p>
                <p>Score-matching generative models have proven successful at sampling fromcomplex high-dimensional data distributions. In many applications thisdistribution is believed to concentrate on a much lower d-dimensionalmanifold embedded into D-dimensional space this is known as the manifoldhypothesis. The current best-known convergence guarantees are either linear inD or polynomial superlinear in d. The latter exploits a novel integrationscheme for the backward SDE. We take the best of both worlds and show that thenumber of steps diffusion models require in order to converge inKullback-LeiblerKL divergence is linear up to logarithmic terms in theintrinsic dimension d. Moreover we show that this linear dependency issharp.</p>
                <p>Last Updated: 2024-10-11 17:58:30 UTC</p>
                <button class="interpret-button" data-id="2410.09046v1">Interpret</button>
                <div id="interpretation-2410.09046v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Analyzing Neural Scaling Laws in Two-Layer Networks with Power-Law Data Spectra</h3>
                <p>Authors: Roman WorschechBernd Rosenow</p>
                <p><a href="http://arxiv.org/abs/2410.09005v1">Link to paper</a></p>
                <p>Neural scaling laws describe how the performance of deep neural networksscales with key factors such as training data size model complexity andtraining time often following power-law behaviors over multiple orders ofmagnitude. Despite their empirical observation the theoretical understandingof these scaling laws remains limited. In this work we employ techniques fromstatistical mechanics to analyze one-pass stochastic gradient descent within astudent-teacher framework where both the student and teacher are two-layerneural networks. Our study primarily focuses on the generalization error andits behavior in response to data covariance matrices that exhibit power-lawspectra. For linear activation functions we derive analytical expressions forthe generalization error exploring different learning regimes and identifyingconditions under which power-law scaling emerges. Additionally we extend ouranalysis to non-linear activation functions in the feature learning regimeinvestigating how power-law spectra in the data covariance matrix impactlearning dynamics. Importantly we find that the length of the symmetricplateau depends on the number of distinct eigenvalues of the data covariancematrix and the number of hidden units demonstrating how these plateaus behaveunder various configurations. In addition our results reveal a transition fromexponential to power-law convergence in the specialized phase when the datacovariance matrix possesses a power-law spectrum. This work contributes to thetheoretical understanding of neural scaling laws and provides insights intooptimizing learning performance in practical scenarios involving complex datastructures.</p>
                <p>Last Updated: 2024-10-11 17:21:42 UTC</p>
                <button class="interpret-button" data-id="2410.09005v1">Interpret</button>
                <div id="interpretation-2410.09005v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Hierarchical Universal Value Function Approximators</h3>
                <p>Authors: Rushiv Arora</p>
                <p><a href="http://arxiv.org/abs/2410.08997v1">Link to paper</a></p>
                <p>There have been key advancements to building universal approximators formulti-goal collections of reinforcement learning value functions -- keyelements in estimating long-term returns of states in a parameterized manner.We extend this to hierarchical reinforcement learning using the optionsframework by introducing hierarchical universal value function approximatorsH-UVFAs. This allows us to leverage the added benefits of scaling planningand generalization expected in temporal abstraction settings. We developsupervised and reinforcement learning methods for learning embeddings of thestates goals options and actions in the two hierarchical value functions:Qs g o theta and Qs g o a theta. Finally we demonstrategeneralization of the HUVFAs and show they outperform corresponding UVFAs.</p>
                <p>Last Updated: 2024-10-11 17:09:26 UTC</p>
                <button class="interpret-button" data-id="2410.08997v1">Interpret</button>
                <div id="interpretation-2410.08997v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Optimal Downsampling for Imbalanced Classification with Generalized Linear Models</h3>
                <p>Authors: Yan ChenJose BlanchetKrzysztof DembczynskiLaura Fee NernAaron Flores</p>
                <p><a href="http://arxiv.org/abs/2410.08994v1">Link to paper</a></p>
                <p>Downsampling or under-sampling is a technique that is utilized in the contextof large and highly imbalanced classification models. We study optimaldownsampling for imbalanced classification using generalized linear modelsGLMs. We propose a pseudo maximum likelihood estimator and study itsasymptotic normality in the context of increasingly imbalanced populationsrelative to an increasingly large sample size. We provide theoreticalguarantees for the introduced estimator. Additionally we compute the optimaldownsampling rate using a criterion that balances statistical accuracy andcomputational efficiency. Our numerical experiments conducted on bothsynthetic and empirical data further validate our theoretical results anddemonstrate that the introduced estimator outperforms commonly availablealternatives.</p>
                <p>Last Updated: 2024-10-11 17:08:13 UTC</p>
                <button class="interpret-button" data-id="2410.08994v1">Interpret</button>
                <div id="interpretation-2410.08994v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Online-to-PAC generalization bounds under graph-mixing dependencies</h3>
                <p>Authors: Baptiste AbélèsEugenio ClericoGergely Neu</p>
                <p><a href="http://arxiv.org/abs/2410.08977v1">Link to paper</a></p>
                <p>Traditional generalization results in statistical learning require a trainingdata set made of independently drawn examples. Most of the recent efforts torelax this independence assumption have considered either purely temporalmixing dependencies or graph-dependencies where non-adjacent verticescorrespond to independent random variables. Both approaches have their ownlimitations the former requiring a temporal ordered structure and the latterlacking a way to quantify the strength of inter-dependencies. In this work webridge these two lines of work by proposing a framework where dependenciesdecay with graph distance. We derive generalization bounds leveraging theonline-to-PAC framework by deriving a concentration result and introducing anonline learning framework incorporating the graph structure. The resultinghigh-probability generalization guarantees depend on both the mixing rate andthe graphs chromatic number.</p>
                <p>Last Updated: 2024-10-11 16:49:01 UTC</p>
                <button class="interpret-button" data-id="2410.08977v1">Interpret</button>
                <div id="interpretation-2410.08977v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>SceneCraft: Layout-Guided 3D Scene Generation</h3>
                <p>Authors: Xiuyu YangYunze ManJun-Kun ChenYu-Xiong Wang</p>
                <p><a href="http://arxiv.org/abs/2410.09049v1">Link to paper</a></p>
                <p>The creation of complex 3D scenes tailored to user specifications has been atedious and challenging task with traditional 3D modeling tools. Although somepioneering methods have achieved automatic text-to-3D generation they aregenerally limited to small-scale scenes with restricted control over the shapeand texture. We introduce SceneCraft a novel method for generating detailedindoor scenes that adhere to textual descriptions and spatial layoutpreferences provided by users. Central to our method is a rendering-basedtechnique which converts 3D semantic layouts into multi-view 2D proxy maps.Furthermore we design a semantic and depth conditioned diffusion model togenerate multi-view images which are used to learn a neural radiance fieldNeRF as the final scene representation. Without the constraints of panoramaimage generation we surpass previous methods in supporting complicated indoorspace generation beyond a single room even as complicated as a wholemulti-bedroom apartment with irregular shapes and layouts. Through experimentalanalysis we demonstrate that our method significantly outperforms existingapproaches in complex indoor scene generation with diverse textures consistentgeometry and realistic visual quality. Code and more results are available at:https://orangesodahub.github.io/SceneCraft</p>
                <p>Last Updated: 2024-10-11 17:59:58 UTC</p>
                <button class="interpret-button" data-id="2410.09049v1">Interpret</button>
                <div id="interpretation-2410.09049v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>MiRAGeNews: Multimodal Realistic AI-Generated News Detection</h3>
                <p>Authors: Runsheng HuangLiam DuganYue YangChris Callison-Burch</p>
                <p><a href="http://arxiv.org/abs/2410.09045v1">Link to paper</a></p>
                <p>The proliferation of inflammatory or misleading fake news content hasbecome increasingly common in recent years. Simultaneously it has becomeeasier than ever to use AI tools to generate photorealistic images depictingany scene imaginable. Combining these two -- AI-generated fake news content --is particularly potent and dangerous. To combat the spread of AI-generated fakenews we propose the MiRAGeNews Dataset a dataset of 12500 high-quality realand AI-generated image-caption pairs from state-of-the-art generators. We findthat our dataset poses a significant challenge to humans 60 F-1 andstate-of-the-art multi-modal LLMs  24 F-1. Using our dataset we train amulti-modal detector MiRAGe that improves by 5.1 F-1 over state-of-the-artbaselines on image-caption pairs from out-of-domain image generators and newspublishers. We release our code and data to aid future work on detectingAI-generated content.</p>
                <p>Last Updated: 2024-10-11 17:58:02 UTC</p>
                <button class="interpret-button" data-id="2410.09045v1">Interpret</button>
                <div id="interpretation-2410.09045v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Alberta Wells Dataset: Pinpointing Oil and Gas Wells from Satellite Imagery</h3>
                <p>Authors: Pratinav SethMichelle LinBrefo Dwamena YawJade BoutotMary KangDavid Rolnick</p>
                <p><a href="http://arxiv.org/abs/2410.09032v1">Link to paper</a></p>
                <p>Millions of abandoned oil and gas wells are scattered across the worldleaching methane into the atmosphere and toxic compounds into the groundwater.Many of these locations are unknown preventing the wells from being pluggedand their polluting effects averted. Remote sensing is a relatively unexploredtool for pinpointing abandoned wells at scale. We introduce the firstlarge-scale benchmark dataset for this problem leveraging medium-resolutionmulti-spectral satellite imagery from Planet Labs. Our curated datasetcomprises over 213000 wells abandoned suspended and active from Alberta aregion with especially high well density sourced from the Alberta EnergyRegulator and verified by domain experts. We evaluate baseline algorithms forwell detection and segmentation showing the promise of computer visionapproaches but also significant room for improvement.</p>
                <p>Last Updated: 2024-10-11 17:49:50 UTC</p>
                <button class="interpret-button" data-id="2410.09032v1">Interpret</button>
                <div id="interpretation-2410.09032v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>CVAM-Pose: Conditional Variational Autoencoder for Multi-Object Monocular Pose Estimation</h3>
                <p>Authors: Jianyu ZhaoWei QuanBogdan J. Matuszewski</p>
                <p><a href="http://arxiv.org/abs/2410.09010v1">Link to paper</a></p>
                <p>Estimating rigid objects poses is one of the fundamental problems incomputer vision with a range of applications across automation and augmentedreality. Most existing approaches adopt one network per object class strategydepend heavily on objects 3D models depth data and employ a time-consumingiterative refinement which could be impractical for some applications. Thispaper presents a novel approach CVAM-Pose for multi-object monocular poseestimation that addresses these limitations. The CVAM-Pose method employs alabel-embedded conditional variational autoencoder network to implicitlyabstract regularised representations of multiple objects in a singlelow-dimensional latent space. This autoencoding process uses only imagescaptured by a projective camera and is robust to objects occlusion and sceneclutter. The classes of objects are one-hot encoded and embedded throughout thenetwork. The proposed label-embedded pose regression strategy interprets thelearnt latent space representations utilising continuous pose representations.Ablation tests and systematic evaluations demonstrate the scalability andefficiency of the CVAM-Pose method for multi-object scenarios. The proposedCVAM-Pose outperforms competing latent space approaches. For example it isrespectively 25 and 20 better than AAE and Multi-Path methods when evaluatedusing the mathrmAR_VSD metric on the Linemod-Occluded dataset. It alsoachieves results somewhat comparable to methods reliant on 3D models reportedin BOP challenges. Code available: https://github.com/JZhao12/CVAM-Pose</p>
                <p>Last Updated: 2024-10-11 17:26:27 UTC</p>
                <button class="interpret-button" data-id="2410.09010v1">Interpret</button>
                <div id="interpretation-2410.09010v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Semantic Score Distillation Sampling for Compositional Text-to-3D Generation</h3>
                <p>Authors: Ling YangZixiang ZhangJunlin HanBohan ZengRunjia LiPhilip TorrWentao Zhang</p>
                <p><a href="http://arxiv.org/abs/2410.09009v1">Link to paper</a></p>
                <p>Generating high-quality 3D assets from textual descriptions remains a pivotalchallenge in computer graphics and vision research. Due to the scarcity of 3Ddata state-of-the-art approaches utilize pre-trained 2D diffusion priorsoptimized through Score Distillation Sampling SDS. Despite progress craftingcomplex 3D scenes featuring multiple objects or intricate interactions is stilldifficult. To tackle this recent methods have incorporated box or layoutguidance. However these layout-guided compositional methods often struggle toprovide fine-grained control as they are generally coarse and lackexpressiveness. To overcome these challenges we introduce a novel SDSapproach Semantic Score Distillation Sampling SemanticSDS designed toeffectively improve the expressiveness and accuracy of compositional text-to-3Dgeneration. Our approach integrates new semantic embeddings that maintainconsistency across different rendering views and clearly differentiate betweenvarious objects and parts. These embeddings are transformed into a semanticmap which directs a region-specific SDS process enabling precise optimizationand compositional generation. By leveraging explicit semantic guidance ourmethod unlocks the compositional capabilities of existing pre-trained diffusionmodels thereby achieving superior quality in 3D content generationparticularly for complex objects and scenes. Experimental results demonstratethat our SemanticSDS framework is highly effective for generatingstate-of-the-art complex 3D content. Code:https://github.com/YangLing0818/SemanticSDS-3D</p>
                <p>Last Updated: 2024-10-11 17:26:00 UTC</p>
                <button class="interpret-button" data-id="2410.09009v1">Interpret</button>
                <div id="interpretation-2410.09009v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models</h3>
                <p>Authors: Qin LiuChao ShangLing LiuNikolaos PappasJie MaNeha Anna JohnSrikanth DossLluis MarquezMiguel BallesterosYassine Benajiba</p>
                <p><a href="http://arxiv.org/abs/2410.09047v1">Link to paper</a></p>
                <p>The safety alignment ability of Vision-Language Models VLMs is prone to bedegraded by the integration of the vision module compared to its LLM backbone.We investigate this phenomenon dubbed as safety alignment degradation inthis paper and show that the challenge arises from the representation gap thatemerges when introducing vision modality to VLMs. In particular we show thatthe representations of multi-modal inputs shift away from that of text-onlyinputs which represent the distribution that the LLM backbone is optimized for.At the same time the safety alignment capabilities initially developed withinthe textual embedding space do not successfully transfer to this newmulti-modal representation space. To reduce safety alignment degradation weintroduce Cross-Modality Representation Manipulation CMRM an inference timerepresentation intervention method for recovering the safety alignment abilitythat is inherent in the LLM backbone of VLMs while simultaneously preservingthe functional capabilities of VLMs. The empirical results show that ourframework significantly recovers the alignment ability that is inherited fromthe LLM backbone with minimal impact on the fluency and linguistic capabilitiesof pre-trained VLMs even without additional training. Specifically the unsaferate of LLaVA-7B on multi-modal input can be reduced from 61.53 to as low as3.15 with only inference-time intervention.  WARNING: This paper contains examples of toxic or harmful language.</p>
                <p>Last Updated: 2024-10-11 17:59:31 UTC</p>
                <button class="interpret-button" data-id="2410.09047v1">Interpret</button>
                <div id="interpretation-2410.09047v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Transforming In-Vehicle Network Intrusion Detection: VAE-based Knowledge Distillation Meets Explainable AI</h3>
                <p>Authors: Muhammet Anil YagizPedram MohajerAnsariMert D. PesePolat Goktas</p>
                <p><a href="http://arxiv.org/abs/2410.09043v1">Link to paper</a></p>
                <p>In the evolving landscape of autonomous vehicles ensuring robust in-vehiclenetwork IVN security is paramount. This paper introduces an advancedintrusion detection system IDS called KD-XVAE that uses a VariationalAutoencoder VAE-based knowledge distillation approach to enhance bothperformance and efficiency. Our model significantly reduces complexityoperating with just 1669 parameters and achieving an inference time of 0.3 msper batch making it highly suitable for resource-constrained automotiveenvironments. Evaluations in the HCRL Car-Hacking dataset demonstrateexceptional capabilities attaining perfect scores Recall Precision F1 Scoreof 100 and FNR of 0 under multiple attack types including DoS FuzzingGear Spoofing and RPM Spoofing. Comparative analysis on the CICIoV2024 datasetfurther underscores its superiority over traditional machine learning modelsachieving perfect detection metrics. We furthermore integrate Explainable AIXAI techniques to ensure transparency in the models decisions. The VAEcompresses the original feature space into a latent space on which thedistilled model is trained. SHAPSHapley Additive exPlanations values provideinsights into the importance of each latent dimension mapped back to originalfeatures for intuitive understanding. Our paper advances the field byintegrating state-of-the-art techniques addressing critical challenges in thedeployment of efficient trustworthy and reliable IDSes for autonomousvehicles ensuring enhanced protection against emerging cyber threats.</p>
                <p>Last Updated: 2024-10-11 17:57:16 UTC</p>
                <button class="interpret-button" data-id="2410.09043v1">Interpret</button>
                <div id="interpretation-2410.09043v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>SimpleStrat: Diversifying Language Model Generation with Stratification</h3>
                <p>Authors: Justin WongYury OrlovskiyMichael LuoSanjit A. SeshiaJoseph E. Gonzalez</p>
                <p><a href="http://arxiv.org/abs/2410.09038v1">Link to paper</a></p>
                <p>Generating diverse responses from large language models LLMs is crucial forapplications such as planning/search and synthetic data generation wherediversity provides distinct answers across generations. Prior approaches relyon increasing temperature to increase diversity. However contrary to popularbelief we show not only does this approach produce lower quality individualgenerations as temperature increases but it depends on models next-tokenprobabilities being similar to the true distribution of answers. We proposemethod an alternative approach that uses the language model itself topartition the space into strata. At inference a random stratum is selected anda sample drawn from within the strata. To measure diversity we introduceCoverageQA a dataset of underspecified questions with multiple equallyplausible answers and assess diversity by measuring KL Divergence between theoutput distribution and uniform distribution over valid ground truth answers.As computing probability per response/solution for proprietary models isinfeasible we measure recall on ground truth solutions. Our evaluation showusing SimpleStrat achieves higher recall by 0.05 compared to GPT-4o and 0.36average reduction in KL Divergence compared to Llama 3.</p>
                <p>Last Updated: 2024-10-11 17:54:14 UTC</p>
                <button class="interpret-button" data-id="2410.09038v1">Interpret</button>
                <div id="interpretation-2410.09038v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Mentor-KD: Making Small Language Models Better Multi-step Reasoners</h3>
                <p>Authors: Hojae LeeJunho KimSangKeun Lee</p>
                <p><a href="http://arxiv.org/abs/2410.09037v1">Link to paper</a></p>
                <p>Large Language Models LLMs have displayed remarkable performances acrossvarious complex tasks by leveraging Chain-of-Thought CoT prompting. Recentlystudies have proposed a Knowledge Distillation KD approach reasoningdistillation which transfers such reasoning ability of LLMs throughfine-tuning language models of multi-step rationales generated by LLM teachers.However they have inadequately considered two challenges regardinginsufficient distillation sets from the LLM teacher model in terms of 1 dataquality and 2 soft label provision. In this paper we propose Mentor-KD whicheffectively distills the multi-step reasoning capability of LLMs to smaller LMswhile addressing the aforementioned challenges. Specifically we exploit amentor intermediate-sized task-specific fine-tuned model to augmentadditional CoT annotations and provide soft labels for the student model duringreasoning distillation. We conduct extensive experiments and confirmMentor-KDs effectiveness across various models and complex reasoning tasks.</p>
                <p>Last Updated: 2024-10-11 17:53:27 UTC</p>
                <button class="interpret-button" data-id="2410.09037v1">Interpret</button>
                <div id="interpretation-2410.09037v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>PEAR: A Robust and Flexible Automation Framework for Ptychography Enabled by Multiple Large Language Model Agents</h3>
                <p>Authors: Xiangyu YinChuqiao ShiYimo HanYi Jiang</p>
                <p><a href="http://arxiv.org/abs/2410.09034v1">Link to paper</a></p>
                <p>Ptychography is an advanced computational imaging technique in X-ray andelectron microscopy. It has been widely adopted across scientific researchfields including physics chemistry biology and materials science as wellas in industrial applications such as semiconductor characterization. Inpractice obtaining high-quality ptychographic images requires simultaneousoptimization of numerous experimental and algorithmic parameters.Traditionally parameter selection often relies on trial and error leading tolow-throughput workflows and potential human bias. In this work we develop thePtychographic Experiment and Analysis Robot PEAR a framework thatleverages large language models LLMs to automate data analysis inptychography. To ensure high robustness and accuracy PEAR employs multiple LLMagents for tasks including knowledge retrieval code generation parameterrecommendation and image reasoning. Our study demonstrates that PEARsmulti-agent design significantly improves the workflow success rate even withsmaller open-weight models such as LLaMA 3.1 8B. PEAR also supports variousautomation levels and is designed to work with customized local knowledgebases ensuring flexibility and adaptability across different researchenvironments.</p>
                <p>Last Updated: 2024-10-11 17:50:59 UTC</p>
                <button class="interpret-button" data-id="2410.09034v1">Interpret</button>
                <div id="interpretation-2410.09034v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models</h3>
                <p>Authors: Qin LiuChao ShangLing LiuNikolaos PappasJie MaNeha Anna JohnSrikanth DossLluis MarquezMiguel BallesterosYassine Benajiba</p>
                <p><a href="http://arxiv.org/abs/2410.09047v1">Link to paper</a></p>
                <p>The safety alignment ability of Vision-Language Models VLMs is prone to bedegraded by the integration of the vision module compared to its LLM backbone.We investigate this phenomenon dubbed as safety alignment degradation inthis paper and show that the challenge arises from the representation gap thatemerges when introducing vision modality to VLMs. In particular we show thatthe representations of multi-modal inputs shift away from that of text-onlyinputs which represent the distribution that the LLM backbone is optimized for.At the same time the safety alignment capabilities initially developed withinthe textual embedding space do not successfully transfer to this newmulti-modal representation space. To reduce safety alignment degradation weintroduce Cross-Modality Representation Manipulation CMRM an inference timerepresentation intervention method for recovering the safety alignment abilitythat is inherent in the LLM backbone of VLMs while simultaneously preservingthe functional capabilities of VLMs. The empirical results show that ourframework significantly recovers the alignment ability that is inherited fromthe LLM backbone with minimal impact on the fluency and linguistic capabilitiesof pre-trained VLMs even without additional training. Specifically the unsaferate of LLaVA-7B on multi-modal input can be reduced from 61.53 to as low as3.15 with only inference-time intervention.  WARNING: This paper contains examples of toxic or harmful language.</p>
                <p>Last Updated: 2024-10-11 17:59:31 UTC</p>
                <button class="interpret-button" data-id="2410.09047v1">Interpret</button>
                <div id="interpretation-2410.09047v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>MiRAGeNews: Multimodal Realistic AI-Generated News Detection</h3>
                <p>Authors: Runsheng HuangLiam DuganYue YangChris Callison-Burch</p>
                <p><a href="http://arxiv.org/abs/2410.09045v1">Link to paper</a></p>
                <p>The proliferation of inflammatory or misleading fake news content hasbecome increasingly common in recent years. Simultaneously it has becomeeasier than ever to use AI tools to generate photorealistic images depictingany scene imaginable. Combining these two -- AI-generated fake news content --is particularly potent and dangerous. To combat the spread of AI-generated fakenews we propose the MiRAGeNews Dataset a dataset of 12500 high-quality realand AI-generated image-caption pairs from state-of-the-art generators. We findthat our dataset poses a significant challenge to humans 60 F-1 andstate-of-the-art multi-modal LLMs  24 F-1. Using our dataset we train amulti-modal detector MiRAGe that improves by 5.1 F-1 over state-of-the-artbaselines on image-caption pairs from out-of-domain image generators and newspublishers. We release our code and data to aid future work on detectingAI-generated content.</p>
                <p>Last Updated: 2024-10-11 17:58:02 UTC</p>
                <button class="interpret-button" data-id="2410.09045v1">Interpret</button>
                <div id="interpretation-2410.09045v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>AttnGCG: Enhancing Jailbreaking Attacks on LLMs with Attention Manipulation</h3>
                <p>Authors: Zijun WangHaoqin TuJieru MeiBingchen ZhaoYisen WangCihang Xie</p>
                <p><a href="http://arxiv.org/abs/2410.09040v1">Link to paper</a></p>
                <p>This paper studies the vulnerabilities of transformer-based Large LanguageModels LLMs to jailbreaking attacks focusing specifically on theoptimization-based Greedy Coordinate Gradient GCG strategy. We first observea positive correlation between the effectiveness of attacks and the internalbehaviors of the models. For instance attacks tend to be less effective whenmodels pay more attention to system prompts designed to ensure LLM safetyalignment. Building on this discovery we introduce an enhanced method thatmanipulates models attention scores to facilitate LLM jailbreaking which weterm AttnGCG. Empirically AttnGCG shows consistent improvements in attackefficacy across diverse LLMs achieving an average increase of 7 in theLlama-2 series and 10 in the Gemma series. Our strategy also demonstratesrobust attack transferability against both unseen harmful goals and black-boxLLMs like GPT-3.5 and GPT-4. Moreover we note our attention-scorevisualization is more interpretable allowing us to gain better insights intohow our targeted attention manipulation facilitates more effectivejailbreaking. We release the code athttps://github.com/UCSC-VLAA/AttnGCG-attack.</p>
                <p>Last Updated: 2024-10-11 17:55:09 UTC</p>
                <button class="interpret-button" data-id="2410.09040v1">Interpret</button>
                <div id="interpretation-2410.09040v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>SimpleStrat: Diversifying Language Model Generation with Stratification</h3>
                <p>Authors: Justin WongYury OrlovskiyMichael LuoSanjit A. SeshiaJoseph E. Gonzalez</p>
                <p><a href="http://arxiv.org/abs/2410.09038v1">Link to paper</a></p>
                <p>Generating diverse responses from large language models LLMs is crucial forapplications such as planning/search and synthetic data generation wherediversity provides distinct answers across generations. Prior approaches relyon increasing temperature to increase diversity. However contrary to popularbelief we show not only does this approach produce lower quality individualgenerations as temperature increases but it depends on models next-tokenprobabilities being similar to the true distribution of answers. We proposemethod an alternative approach that uses the language model itself topartition the space into strata. At inference a random stratum is selected anda sample drawn from within the strata. To measure diversity we introduceCoverageQA a dataset of underspecified questions with multiple equallyplausible answers and assess diversity by measuring KL Divergence between theoutput distribution and uniform distribution over valid ground truth answers.As computing probability per response/solution for proprietary models isinfeasible we measure recall on ground truth solutions. Our evaluation showusing SimpleStrat achieves higher recall by 0.05 compared to GPT-4o and 0.36average reduction in KL Divergence compared to Llama 3.</p>
                <p>Last Updated: 2024-10-11 17:54:14 UTC</p>
                <button class="interpret-button" data-id="2410.09038v1">Interpret</button>
                <div id="interpretation-2410.09038v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Mentor-KD: Making Small Language Models Better Multi-step Reasoners</h3>
                <p>Authors: Hojae LeeJunho KimSangKeun Lee</p>
                <p><a href="http://arxiv.org/abs/2410.09037v1">Link to paper</a></p>
                <p>Large Language Models LLMs have displayed remarkable performances acrossvarious complex tasks by leveraging Chain-of-Thought CoT prompting. Recentlystudies have proposed a Knowledge Distillation KD approach reasoningdistillation which transfers such reasoning ability of LLMs throughfine-tuning language models of multi-step rationales generated by LLM teachers.However they have inadequately considered two challenges regardinginsufficient distillation sets from the LLM teacher model in terms of 1 dataquality and 2 soft label provision. In this paper we propose Mentor-KD whicheffectively distills the multi-step reasoning capability of LLMs to smaller LMswhile addressing the aforementioned challenges. Specifically we exploit amentor intermediate-sized task-specific fine-tuned model to augmentadditional CoT annotations and provide soft labels for the student model duringreasoning distillation. We conduct extensive experiments and confirmMentor-KDs effectiveness across various models and complex reasoning tasks.</p>
                <p>Last Updated: 2024-10-11 17:53:27 UTC</p>
                <button class="interpret-button" data-id="2410.09037v1">Interpret</button>
                <div id="interpretation-2410.09037v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models</h3>
                <p>Authors: Qin LiuChao ShangLing LiuNikolaos PappasJie MaNeha Anna JohnSrikanth DossLluis MarquezMiguel BallesterosYassine Benajiba</p>
                <p><a href="http://arxiv.org/abs/2410.09047v1">Link to paper</a></p>
                <p>The safety alignment ability of Vision-Language Models VLMs is prone to bedegraded by the integration of the vision module compared to its LLM backbone.We investigate this phenomenon dubbed as safety alignment degradation inthis paper and show that the challenge arises from the representation gap thatemerges when introducing vision modality to VLMs. In particular we show thatthe representations of multi-modal inputs shift away from that of text-onlyinputs which represent the distribution that the LLM backbone is optimized for.At the same time the safety alignment capabilities initially developed withinthe textual embedding space do not successfully transfer to this newmulti-modal representation space. To reduce safety alignment degradation weintroduce Cross-Modality Representation Manipulation CMRM an inference timerepresentation intervention method for recovering the safety alignment abilitythat is inherent in the LLM backbone of VLMs while simultaneously preservingthe functional capabilities of VLMs. The empirical results show that ourframework significantly recovers the alignment ability that is inherited fromthe LLM backbone with minimal impact on the fluency and linguistic capabilitiesof pre-trained VLMs even without additional training. Specifically the unsaferate of LLaVA-7B on multi-modal input can be reduced from 61.53 to as low as3.15 with only inference-time intervention.  WARNING: This paper contains examples of toxic or harmful language.</p>
                <p>Last Updated: 2024-10-11 17:59:31 UTC</p>
                <button class="interpret-button" data-id="2410.09047v1">Interpret</button>
                <div id="interpretation-2410.09047v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Linear Convergence of Diffusion Models Under the Manifold Hypothesis</h3>
                <p>Authors: Peter PotaptchikIskander AzangulovGeorge Deligiannidis</p>
                <p><a href="http://arxiv.org/abs/2410.09046v1">Link to paper</a></p>
                <p>Score-matching generative models have proven successful at sampling fromcomplex high-dimensional data distributions. In many applications thisdistribution is believed to concentrate on a much lower d-dimensionalmanifold embedded into D-dimensional space this is known as the manifoldhypothesis. The current best-known convergence guarantees are either linear inD or polynomial superlinear in d. The latter exploits a novel integrationscheme for the backward SDE. We take the best of both worlds and show that thenumber of steps diffusion models require in order to converge inKullback-LeiblerKL divergence is linear up to logarithmic terms in theintrinsic dimension d. Moreover we show that this linear dependency issharp.</p>
                <p>Last Updated: 2024-10-11 17:58:30 UTC</p>
                <button class="interpret-button" data-id="2410.09046v1">Interpret</button>
                <div id="interpretation-2410.09046v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Alberta Wells Dataset: Pinpointing Oil and Gas Wells from Satellite Imagery</h3>
                <p>Authors: Pratinav SethMichelle LinBrefo Dwamena YawJade BoutotMary KangDavid Rolnick</p>
                <p><a href="http://arxiv.org/abs/2410.09032v1">Link to paper</a></p>
                <p>Millions of abandoned oil and gas wells are scattered across the worldleaching methane into the atmosphere and toxic compounds into the groundwater.Many of these locations are unknown preventing the wells from being pluggedand their polluting effects averted. Remote sensing is a relatively unexploredtool for pinpointing abandoned wells at scale. We introduce the firstlarge-scale benchmark dataset for this problem leveraging medium-resolutionmulti-spectral satellite imagery from Planet Labs. Our curated datasetcomprises over 213000 wells abandoned suspended and active from Alberta aregion with especially high well density sourced from the Alberta EnergyRegulator and verified by domain experts. We evaluate baseline algorithms forwell detection and segmentation showing the promise of computer visionapproaches but also significant room for improvement.</p>
                <p>Last Updated: 2024-10-11 17:49:50 UTC</p>
                <button class="interpret-button" data-id="2410.09032v1">Interpret</button>
                <div id="interpretation-2410.09032v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Variance reduction combining pre-experiment and in-experiment data</h3>
                <p>Authors: Zhexiao LinPablo Crespo</p>
                <p><a href="http://arxiv.org/abs/2410.09027v1">Link to paper</a></p>
                <p>Online controlled experiments A/B testing are essential in data-drivendecision-making for many companies. Increasing the sensitivity of theseexperiments particularly with a fixed sample size relies on reducing thevariance of the estimator for the average treatment effect ATE. Existingmethods like CUPED and CUPAC use pre-experiment data to reduce variance buttheir effectiveness depends on the correlation between the pre-experiment dataand the outcome. In contrast in-experiment data is often more stronglycorrelated with the outcome and thus more informative. In this paper weintroduce a novel method that combines both pre-experiment and in-experimentdata to achieve greater variance reduction than CUPED and CUPAC withoutintroducing bias or additional computation complexity. We also establishasymptotic theory and provide consistent variance estimators for our method.Applying this method to multiple online experiments at Etsy we reachsubstantial variance reduction over CUPAC with the inclusion of only a fewin-experiment covariates. These results highlight the potential of our approachto significantly improve experiment sensitivity and accelerate decision-making.</p>
                <p>Last Updated: 2024-10-11 17:45:29 UTC</p>
                <button class="interpret-button" data-id="2410.09027v1">Interpret</button>
                <div id="interpretation-2410.09027v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents</h3>
                <p>Authors: Maksym AndriushchenkoAlexandra SoulyMateusz DziemianDerek DuenasMaxwell LinJustin WangDan HendrycksAndy ZouZico KolterMatt FredriksonEric WinsorJerome WynneYarin GalXander Davies</p>
                <p><a href="http://arxiv.org/abs/2410.09024v1">Link to paper</a></p>
                <p>The robustness of LLMs to jailbreak attacks where users design prompts tocircumvent safety measures and misuse model capabilities has been studiedprimarily for LLMs acting as simple chatbots. Meanwhile LLM agents -- whichuse external tools and can execute multi-stage tasks -- may pose a greater riskif misused but their robustness remains underexplored. To facilitate researchon LLM agent misuse we propose a new benchmark called AgentHarm. The benchmarkincludes a diverse set of 110 explicitly malicious agent tasks 440 withaugmentations covering 11 harm categories including fraud cybercrime andharassment. In addition to measuring whether models refuse harmful agenticrequests scoring well on AgentHarm requires jailbroken agents to maintaintheir capabilities following an attack to complete a multi-step task. Weevaluate a range of leading LLMs and find 1 leading LLMs are surprisinglycompliant with malicious agent requests without jailbreaking 2 simpleuniversal jailbreak templates can be adapted to effectively jailbreak agentsand 3 these jailbreaks enable coherent and malicious multi-step agentbehavior and retain model capabilities. We publicly release AgentHarm to enablesimple and reliable evaluation of attacks and defenses for LLM-based agents. Wepublicly release the benchmark athttps://huggingface.co/ai-safety-institute/AgentHarm.</p>
                <p>Last Updated: 2024-10-11 17:39:22 UTC</p>
                <button class="interpret-button" data-id="2410.09024v1">Interpret</button>
                <div id="interpretation-2410.09024v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-10-14</p>
        </div>
    
        </div>
    </body>
    </html>
    