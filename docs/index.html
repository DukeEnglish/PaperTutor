
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>Reducing Transformer Key-Value Cache Size with Cross-Layer Attention</h3>
                <p>Authors: William BrandonMayank MishraAniruddha NrusimhaRameswar PandaJonathan Ragan Kelly</p>
                <p><a href="http://arxiv.org/abs/2405.12981v1">Link to paper</a></p>
                <p>Key-value KV caching plays an essential role in accelerating decoding fortransformer-based autoregressive large language models LLMs. However theamount of memory required to store the KV cache can become prohibitive at longsequence lengths and large batch sizes. Since the invention of the transformertwo of the most effective interventions discovered for reducing the size of theKV cache have been Multi-Query Attention MQA and its generalizationGrouped-Query Attention GQA. MQA and GQA both modify the design of theattention block so that multiple query heads can share a single key/value headreducing the number of distinct key/value heads by a large factor while onlyminimally degrading accuracy. In this paper we show that it is possible totake Multi-Query Attention a step further by also sharing key and value headsbetween adjacent layers yielding a new attention design we call Cross-LayerAttention CLA. With CLA we find that it is possible to reduce the size ofthe KV cache by another 2x while maintaining nearly the same accuracy asunmodified MQA. In experiments training 1B- and 3B-parameter models fromscratch we demonstrate that CLA provides a Pareto improvement over thememory/accuracy tradeoffs which are possible with traditional MQA enablinginference with longer sequence lengths and larger batch sizes than wouldotherwise be possible</p>
                <p>Last Updated: 2024-05-21 17:59:29 UTC</p>
                <button class="interpret-button" data-id="2405.12981v1">Interpret</button>
                <div id="interpretation-2405.12981v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer Selection in Large Language Models</h3>
                <p>Authors: Zhangyue YinQiushi SunQipeng GuoZhiyuan ZengXiaonan LiTianxiang SunCheng ChangQinyuan ChengDing WangXiaofeng MouXipeng QiuXuanJing Huang</p>
                <p><a href="http://arxiv.org/abs/2405.12939v1">Link to paper</a></p>
                <p>Recent advancements in Chain-of-Thought prompting have facilitatedsignificant breakthroughs for Large Language Models LLMs in complex reasoningtasks. Current research enhances the reasoning performance of LLMs by samplingmultiple reasoning chains and ensembling based on the answer frequency.However this approach fails in scenarios where the correct answers are in theminority. We identify this as a primary factor constraining the reasoningcapabilities of LLMs a limitation that cannot be resolved solely based on thepredicted answers. To address this shortcoming we introduce a hierarchicalreasoning aggregation framework AoR Aggregation of Reasoning which selectsanswers based on the evaluation of reasoning chains. Additionally AoRincorporates dynamic sampling adjusting the number of reasoning chains inaccordance with the complexity of the task. Experimental results on a series ofcomplex reasoning tasks show that AoR outperforms prominent ensemble methods.Further analysis reveals that AoR not only adapts various LLMs but alsoachieves a superior performance ceiling when compared to current methods.</p>
                <p>Last Updated: 2024-05-21 17:12:19 UTC</p>
                <button class="interpret-button" data-id="2405.12939v1">Interpret</button>
                <div id="interpretation-2405.12939v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs</h3>
                <p>Authors: Bilgehan SelPriya ShanmugasundaramMohammad KachueeKun ZhouRuoxi JiaMing Jin</p>
                <p><a href="http://arxiv.org/abs/2405.12933v1">Link to paper</a></p>
                <p>Large Language Models LLMs have shown remarkable capabilities in tasks suchas summarization arithmetic reasoning and question answering. However theyencounter significant challenges in the domain of moral reasoning and ethicaldecision-making especially in complex scenarios with multiple stakeholders.This paper introduces the Skin-in-the-Game SKIG framework aimed at enhancingmoral reasoning in LLMs by exploring decisions consequences from multiplestakeholder perspectives. Central to SKIGs mechanism is simulatingaccountability for actions which alongside empathy exercises and riskassessment is pivotal to its effectiveness. We validate SKIGs performanceacross various moral reasoning benchmarks with proprietary and opensource LLMsand investigate its crucial components through extensive ablation analyses.</p>
                <p>Last Updated: 2024-05-21 17:04:44 UTC</p>
                <button class="interpret-button" data-id="2405.12933v1">Interpret</button>
                <div id="interpretation-2405.12933v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Code-mixed Sentiment and Hate-speech Prediction</h3>
                <p>Authors: Anjali YadavTanya GargMatej KlemenMatej UlcarBasant AgarwalMarko Robnik Sikonja</p>
                <p><a href="http://arxiv.org/abs/2405.12929v1">Link to paper</a></p>
                <p>Code-mixed discourse combines multiple languages in a single text. It iscommonly used in informal discourse in countries with several officiallanguages but also in many other countries in combination with English orneighboring languages. As recently large language models have dominated mostnatural language processing tasks we investigated their performance incode-mixed settings for relevant tasks. We first created four new bilingualpre-trained masked language models for English-Hindi and English-Slovenelanguages specifically aimed to support informal language. Then we performedan evaluation of monolingual bilingual few-lingual and massivelymultilingual models on several languages using two tasks that frequentlycontain code-mixed text in particular sentiment analysis and offensivelanguage detection in social media texts. The results show that the mostsuccessful classifiers are fine-tuned bilingual models and multilingual modelsspecialized for social media texts followed by non-specialized massivelymultilingual and monolingual models while huge generative models are notcompetitive. For our affective problems the models mostly perform slightlybetter on code-mixed data compared to non-code-mixed data.</p>
                <p>Last Updated: 2024-05-21 16:56:36 UTC</p>
                <button class="interpret-button" data-id="2405.12929v1">Interpret</button>
                <div id="interpretation-2405.12929v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation</h3>
                <p>Authors: Xingyuan PanLuyang HuangLiyan KangZhicheng LiuYu LuShanbo Cheng</p>
                <p><a href="http://arxiv.org/abs/2405.12915v1">Link to paper</a></p>
                <p>Large Language Models LLMs have demonstrated remarkable abilities ingeneral scenarios. Instruction finetuning empowers them to align with humans invarious tasks. Nevertheless the Diversity and Quality of the instruction dataremain two main challenges for instruction finetuning. With regard to this inthis paper we propose a novel gradient-based method to automatically selecthigh-quality and diverse instruction finetuning data for machine translation.Our key innovation centers around analyzing how individual training examplesinfluence the model during training. Specifically we select training examplesthat exert beneficial influences on the model as high-quality ones by means ofInfluence Function plus a small high-quality seed dataset. Moreover to enhancethe diversity of the training data we maximize the variety of influences theyhave on the model by clustering on their gradients and resampling. Extensiveexperiments on WMT22 and FLORES translation tasks demonstrate the superiorityof our methods and in-depth analysis further validates their effectiveness andgeneralization.</p>
                <p>Last Updated: 2024-05-21 16:38:13 UTC</p>
                <button class="interpret-button" data-id="2405.12915v1">Interpret</button>
                <div id="interpretation-2405.12915v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Online Learning of Halfspaces with Massart Noise</h3>
                <p>Authors: Ilias DiakonikolasVasilis KontonisChristos TzamosNikos Zarifis</p>
                <p><a href="http://arxiv.org/abs/2405.12958v1">Link to paper</a></p>
                <p>We study the task of online learning in the presence of Massart noise.Instead of assuming that the online adversary chooses an arbitrary sequence oflabels we assume that the context mathbfx is selected adversarially butthe label y presented to the learner disagrees with the ground-truth label ofmathbfx with unknown probability at most eta. We study the fundamentalclass of gamma-margin linear classifiers and present a computationallyefficient algorithm that achieves mistake bound eta T  oT. Our mistakebound is qualitatively tight for efficient algorithms: it is known that even inthe offline setting achieving classification error better than eta requiressuper-polynomial time in the SQ model.  We extend our online learning model to a k-arm contextual bandit settingwhere the rewards -- instead of satisfying commonly used realizabilityassumptions -- are consistent in expectation with some linear rankingfunction with weight vector mathbfwast. Given a list of contextsmathbfx_1ldots mathbfx_k if mathbfwcdot mathbfx_i mathbfw cdot mathbfx_j the expected reward of action i must belarger than that of j by at least Delta. We use our Massart online learnerto design an efficient bandit algorithm that obtains expected reward at least1-1/k Delta T - oT bigger than choosing a random action at every round.</p>
                <p>Last Updated: 2024-05-21 17:31:10 UTC</p>
                <button class="interpret-button" data-id="2405.12958v1">Interpret</button>
                <div id="interpretation-2405.12958v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Learning the Infinitesimal Generator of Stochastic Diffusion Processes</h3>
                <p>Authors: Vladimir R. KosticKarim LouniciHelene HalconruyTimothee DevergneMassimiliano Pontil</p>
                <p><a href="http://arxiv.org/abs/2405.12940v1">Link to paper</a></p>
                <p>We address data-driven learning of the infinitesimal generator of stochasticdiffusion processes essential for understanding numerical simulations ofnatural and physical systems. The unbounded nature of the generator posessignificant challenges rendering conventional analysis techniques forHilbert-Schmidt operators ineffective. To overcome this we introduce a novelframework based on the energy functional for these stochastic processes. Ourapproach integrates physical priors through an energy-based risk metric in bothfull and partial knowledge settings. We evaluate the statistical performance ofa reduced-rank estimator in reproducing kernel Hilbert spaces RKHS in thepartial knowledge setting. Notably our approach provides learning boundsindependent of the state space dimension and ensures non-spurious spectralestimation. Additionally we elucidate how the distortion between the intrinsicenergy-induced metric of the stochastic diffusion and the RKHS metric used forgenerator estimation impacts the spectral learning bounds.</p>
                <p>Last Updated: 2024-05-21 17:13:13 UTC</p>
                <button class="interpret-button" data-id="2405.12940v1">Interpret</button>
                <div id="interpretation-2405.12940v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language</h3>
                <p>Authors: James RequeimaJohn BronskillDami ChoiRichard E. TurnerDavid Duvenaud</p>
                <p><a href="http://arxiv.org/abs/2405.12856v1">Link to paper</a></p>
                <p>Machine learning practitioners often face significant challenges in formallyintegrating their prior knowledge and beliefs into predictive models limitingthe potential for nuanced and context-aware analyses. Moreover the expertiseneeded to integrate this prior knowledge into probabilistic modeling typicallylimits the application of these models to specialists. Our goal is to build aregression model that can process numerical data and make probabilisticpredictions at arbitrary locations guided by natural language text whichdescribes a users prior knowledge. Large Language Models LLMs provide auseful starting point for designing such a tool since they 1 provide aninterface where users can incorporate expert insights in natural language and2 provide an opportunity for leveraging latent problem-relevant knowledgeencoded in LLMs that users may not have themselves. We start by exploringstrategies for eliciting explicit coherent numerical predictive distributionsfrom LLMs. We examine these joint predictive distributions which we call LLMProcesses over arbitrarily-many quantities in settings such as forecastingmulti-dimensional regression black-box optimization and image modeling. Weinvestigate the practical details of prompting to elicit coherent predictivedistributions and demonstrate their effectiveness at regression. Finally wedemonstrate the ability to usefully incorporate text into numericalpredictions improving predictive performance and giving quantitative structurethat reflects qualitative descriptions. This lets us begin to explore the richgrounded hypothesis space that LLMs implicitly encode.</p>
                <p>Last Updated: 2024-05-21 15:13:12 UTC</p>
                <button class="interpret-button" data-id="2405.12856v1">Interpret</button>
                <div id="interpretation-2405.12856v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Wav-KAN: Wavelet Kolmogorov-Arnold Networks</h3>
                <p>Authors: Zavareh BozorgaslHao Chen</p>
                <p><a href="http://arxiv.org/abs/2405.12832v1">Link to paper</a></p>
                <p>In this paper  we introduce Wav-KAN an innovative neural networkarchitecture that leverages the Wavelet Kolmogorov-Arnold Networks Wav-KANframework to enhance interpretability and performance. Traditional multilayerperceptrons MLPs and even recent advancements like Spl-KAN face challengesrelated to interpretability training speed robustness computationalefficiency and performance. Wav-KAN addresses these limitations byincorporating wavelet functions into the Kolmogorov-Arnold network structureenabling the network to capture both high-frequency and low-frequencycomponents of the input data efficiently. Wavelet-based approximations employorthogonal or semi-orthogonal basis and also maintains a balance betweenaccurately representing the underlying data structure and avoiding overfittingto the noise. Analogous to how water conforms to the shape of its containerWav-KAN adapts to the data structure resulting in enhanced accuracy fastertraining speeds and increased robustness compared to Spl-KAN and MLPs. Ourresults highlight the potential of Wav-KAN as a powerful tool for developinginterpretable and high-performance neural networks with applications spanningvarious fields. This work sets the stage for further exploration andimplementation of Wav-KAN in frameworks such as PyTorch TensorFlow and alsoit makes wavelet in KAN in wide-spread usage like nowadays activation functionslike ReLU sigmoid in universal approximation theory UAT.</p>
                <p>Last Updated: 2024-05-21 14:36:16 UTC</p>
                <button class="interpret-button" data-id="2405.12832v1">Interpret</button>
                <div id="interpretation-2405.12832v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Refined Graph Encoder Embedding via Self-Training and Latent Community Recovery</h3>
                <p>Authors: Cencheng ShenJonathan LarsonHa TrinhCarey E. Priebe</p>
                <p><a href="http://arxiv.org/abs/2405.12797v1">Link to paper</a></p>
                <p>This paper introduces a refined graph encoder embedding method enhancing theoriginal graph encoder embedding using linear transformation self-trainingand hidden community recovery within observed communities. We provide thetheoretical rationale for the refinement procedure demonstrating how and whyour proposed method can effectively identify useful hidden communities viastochastic block models and how the refinement method leads to improved vertexembedding and better decision boundaries for subsequent vertex classification.The efficacy of our approach is validated through a collection of simulated andreal-world graph data.</p>
                <p>Last Updated: 2024-05-21 13:48:07 UTC</p>
                <button class="interpret-button" data-id="2405.12797v1">Interpret</button>
                <div id="interpretation-2405.12797v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>OmniGlue: Generalizable Feature Matching with Foundation Model Guidance</h3>
                <p>Authors: Hanwen JiangArjun KarpurBingyi CaoQixing HuangAndre Araujo</p>
                <p><a href="http://arxiv.org/abs/2405.12979v1">Link to paper</a></p>
                <p>The image matching field has been witnessing a continuous emergence of novellearnable feature matching techniques with ever-improving performance onconventional benchmarks. However our investigation shows that despite thesegains their potential for real-world applications is restricted by theirlimited generalization capabilities to novel image domains. In this paper weintroduce OmniGlue the first learnable image matcher that is designed withgeneralization as a core principle. OmniGlue leverages broad knowledge from avision foundation model to guide the feature matching process boostinggeneralization to domains not seen at training time. Additionally we propose anovel keypoint position-guided attention mechanism which disentangles spatialand appearance information leading to enhanced matching descriptors. Weperform comprehensive experiments on a suite of 7 datasets with varied imagedomains including scene-level object-centric and aerial images. OmniGluesnovel components lead to relative gains on unseen domains of 20.9 withrespect to a directly comparable reference model while also outperforming therecent LightGlue method by 9.5 relatively.Code and model can be found athttps://hwjiang1510.github.io/OmniGlue</p>
                <p>Last Updated: 2024-05-21 17:59:22 UTC</p>
                <button class="interpret-button" data-id="2405.12979v1">Interpret</button>
                <div id="interpretation-2405.12979v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Personalized Residuals for Concept-Driven Text-to-Image Generation</h3>
                <p>Authors: Cusuh HamMatthew FisherJames HaysNicholas KolkinYuchen LiuRichard ZhangTobias Hinz</p>
                <p><a href="http://arxiv.org/abs/2405.12978v1">Link to paper</a></p>
                <p>We present personalized residuals and localized attention-guided sampling forefficient concept-driven generation using text-to-image diffusion models. Ourmethod first represents concepts by freezing the weights of a pretrainedtext-conditioned diffusion model and learning low-rank residuals for a smallsubset of the models layers. The residual-based approach then directly enablesapplication of our proposed sampling technique which applies the learnedresiduals only in areas where the concept is localized via cross-attention andapplies the original diffusion weights in all other regions. Localized samplingtherefore combines the learned identity of the concept with the existinggenerative prior of the underlying diffusion model. We show that personalizedresiduals effectively capture the identity of a concept in 3 minutes on asingle GPU without the use of regularization images and with fewer parametersthan previous models and localized sampling allows using the original model asstrong prior for large parts of the image.</p>
                <p>Last Updated: 2024-05-21 17:59:01 UTC</p>
                <button class="interpret-button" data-id="2405.12978v1">Interpret</button>
                <div id="interpretation-2405.12978v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>BiomedParse: a biomedical foundation model for image parsing of everything everywhere all at once</h3>
                <p>Authors: Theodore ZhaoYu GuJianwei YangNaoto UsuyamaHo Hin LeeTristan NaumannJianfeng GaoAngela CrabtreeBrian PieningCarlo BifulcoMu WeiHoifung PoonSheng Wang</p>
                <p><a href="http://arxiv.org/abs/2405.12971v1">Link to paper</a></p>
                <p>Biomedical image analysis is fundamental for biomedical discovery in cellbiology pathology radiology and many other biomedical domains. Holisticimage analysis comprises interdependent subtasks such as segmentationdetection and recognition of relevant objects. Here we propose BiomedParse abiomedical foundation model for imaging parsing that can jointly conductsegmentation detection and recognition for 82 object types across 9 imagingmodalities. Through joint learning we can improve accuracy for individualtasks and enable novel applications such as segmenting all relevant objects inan image through a text prompt rather than requiring users to laboriouslyspecify the bounding box for each object. We leveraged readily availablenatural-language labels or descriptions accompanying those datasets and useGPT-4 to harmonize the noisy unstructured text information with establishedbiomedical object ontologies. We created a large dataset comprising over sixmillion triples of image segmentation mask and textual description. On imagesegmentation we showed that BiomedParse is broadly applicable outperformingstate-of-the-art methods on 102855 test image-mask-label triples across 9imaging modalities everything. On object detection which aims to locate aspecific object of interest BiomedParse again attained state-of-the-artperformance especially on objects with irregular shapes everywhere. Onobject recognition which aims to identify all objects in a given image alongwith their semantic types we showed that BiomedParse can simultaneouslysegment and label all biomedical objects in an image all at once. In summaryBiomedParse is an all-in-one tool for biomedical image analysis by jointlysolving segmentation detection and recognition for all major biomedical imagemodalities paving the path for efficient and accurate image-based biomedicaldiscovery.</p>
                <p>Last Updated: 2024-05-21 17:54:06 UTC</p>
                <button class="interpret-button" data-id="2405.12971v1">Interpret</button>
                <div id="interpretation-2405.12971v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Face Adapter for Pre-Trained Diffusion Models with Fine-Grained ID and Attribute Control</h3>
                <p>Authors: Yue HanJunwei ZhuKeke HeXu ChenYanhao GeWei LiXiangtai LiJiangning ZhangChengjie WangYong Liu</p>
                <p><a href="http://arxiv.org/abs/2405.12970v1">Link to paper</a></p>
                <p>Current face reenactment and swapping methods mainly rely on GAN frameworksbut recent focus has shifted to pre-trained diffusion models for their superiorgeneration capabilities. However training these models is resource-intensiveand the results have not yet achieved satisfactory performance levels. Toaddress this issue we introduce Face-Adapter an efficient and effectiveadapter designed for high-precision and high-fidelity face editing forpre-trained diffusion models. We observe that both face reenactment/swappingtasks essentially involve combinations of target structure ID and attribute.We aim to sufficiently decouple the control of these factors to achieve bothtasks in one model. Specifically our method contains: 1 A Spatial ConditionGenerator that provides precise landmarks and background 2 A Plug-and-playIdentity Encoder that transfers face embeddings to the text space by atransformer decoder. 3 An Attribute Controller that integrates spatialconditions and detailed attributes. Face-Adapter achieves comparable or evensuperior performance in terms of motion control precision ID retentioncapability and generation quality compared to fully fine-tuned facereenactment/swapping models. Additionally Face-Adapter seamlessly integrateswith various StableDiffusion models.</p>
                <p>Last Updated: 2024-05-21 17:50:12 UTC</p>
                <button class="interpret-button" data-id="2405.12970v1">Interpret</button>
                <div id="interpretation-2405.12970v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Comprehensive Multimodal Deep Learning Survival Prediction Enabled by a Transformer Architecture: A Multicenter Study in Glioblastoma</h3>
                <p>Authors: Ahmed GomaaYixing HuangAmr HagagCharlotte SchmitterDaniel HöflerThomas WeissmannKatharina BreiningerManuel SchmidtJenny StritzelbergerDaniel DelevRoland CorasArnd DörflerOliver SchnellBenjamin FreyUdo S. GaiplSabine SemrauChristoph BertRainer FietkauFlorian Putz</p>
                <p><a href="http://arxiv.org/abs/2405.12963v1">Link to paper</a></p>
                <p>Background: This research aims to improve glioblastoma survival prediction byintegrating MR images clinical and molecular-pathologic data in atransformer-based deep learning model addressing data heterogeneity andperformance generalizability. Method: We propose and evaluate atransformer-based non-linear and non-proportional survival prediction model.The model employs self-supervised learning techniques to effectively encode thehigh-dimensional MRI input for integration with non-imaging data usingcross-attention. To demonstrate model generalizability the model is assessedwith the time-dependent concordance index Cdt in two training setups usingthree independent public test sets: UPenn-GBM UCSF-PDGM and RHUH-GBM eachcomprising 378 366 and 36 cases respectively. Results: The proposedtransformer model achieved promising performance for imaging as well asnon-imaging data effectively integrating both modalities for enhancedperformance UPenn-GBM test-set imaging Cdt 0.645 multimodal Cdt 0.707 whileoutperforming state-of-the-art late-fusion 3D-CNN-based models. Consistentperformance was observed across the three independent multicenter test setswith Cdt values of 0.707 UPenn-GBM internal test set 0.672 UCSF-PDGMfirst external test set and 0.618 RHUH-GBM second external test set. Themodel achieved significant discrimination between patients with favorable andunfavorable survival for all three datasets logrank p 1.9times10-89.7times10-3 and 1.2times10-2. Conclusions: The proposedtransformer-based survival prediction model integrates complementaryinformation from diverse input modalities contributing to improvedglioblastoma survival prediction compared to state-of-the-art methods.Consistent performance was observed across institutions supporting modelgeneralizability.</p>
                <p>Last Updated: 2024-05-21 17:44:48 UTC</p>
                <button class="interpret-button" data-id="2405.12963v1">Interpret</button>
                <div id="interpretation-2405.12963v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Tutorly: Turning Programming Videos Into Apprenticeship Learning Environments with LLMs</h3>
                <p>Authors: Wengxi LiRoy PeaNick HaberHari Subramonyam</p>
                <p><a href="http://arxiv.org/abs/2405.12946v1">Link to paper</a></p>
                <p>Online programming videos including tutorials and streamcasts are widelypopular and contain a wealth of expert knowledge. However effectivelyutilizing these resources to achieve targeted learning goals can bechallenging. Unlike direct tutoring video content lacks tailored guidancebased on individual learning paces personalized feedback and interactiveengagement necessary for support and monitoring. Our work transformsprogramming videos into one-on-one tutoring experiences using the cognitiveapprenticeship framework. Tutorly developed as a JupyterLab Plugin allowslearners to 1 set personalized learning goals 2 engage inlearning-by-doing through a conversational LLM-based mentor agent 3 receiveguidance and feedback based on a student model that steers the mentor moves. Ina within-subject study with 16 participants learning exploratory data analysisfrom a streamcast Tutorly significantly improved their performance from 61.9to 76.6 based on a post-test questionnaire. Tutorly demonstrates the potentialfor enhancing programming video learning experiences with LLM and learnermodeling.</p>
                <p>Last Updated: 2024-05-21 17:17:34 UTC</p>
                <button class="interpret-button" data-id="2405.12946v1">Interpret</button>
                <div id="interpretation-2405.12946v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Enabling Additive Manufacturing Part Inspection of Digital Twins via Collaborative Virtual Reality</h3>
                <p>Authors: Vuthea ChheangSaurabh NarainGarrett HootenRobert CerdaBrian AuBrian WestonBrian GieraPeer-Timo BremerHaichao Miao</p>
                <p><a href="http://arxiv.org/abs/2405.12931v1">Link to paper</a></p>
                <p>Digital twins DTs are an emerging capability in additive manufacturingAM set to revolutionize design optimization inspection in situ monitoringand root cause analysis. AM DTs typically incorporate multimodal data streamsranging from machine toolpaths and in-process imaging to X-ray CT scans andperformance metrics. Despite the evolution of DT platforms challenges remainin effectively inspecting them for actionable insights either individually orin a multidisciplinary team setting. Quality assurance manufacturingdepartments pilot labs and plant operations must collaborate closely toreliably produce parts at scale. This is particularly crucial in AM wherecomplex structures require a collaborative and multidisciplinary approach.Additionally the large-scale data originating from different modalities andtheir inherent 3D nature pose significant hurdles for traditional 2Ddesktop-based inspection methods. To address these challenges and increase thevalue proposition of DTs we introduce a novel virtual reality VR frameworkto facilitate collaborative and real-time inspection of DTs in AM. Thisframework includes advanced features for intuitive alignment and visualizationof multimodal data visual occlusion management streaming large-scalevolumetric data and collaborative tools substantially improving theinspection of AM components and processes to fully exploit the potential of DTsin AM.</p>
                <p>Last Updated: 2024-05-21 16:59:21 UTC</p>
                <button class="interpret-button" data-id="2405.12931v1">Interpret</button>
                <div id="interpretation-2405.12931v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Panmodal Information Interaction</h3>
                <p>Authors: Chirag ShahRyen W. White</p>
                <p><a href="http://arxiv.org/abs/2405.12923v1">Link to paper</a></p>
                <p>The emergence of generative artificial intelligence GenAI is transforminginformation interaction. For decades search engines such as Google and Binghave been the primary means of locating relevant information for the generalpopulation. They have provided search results in the same standard format theso-called 10 blue links. The recent ability to chat via natural languagewith AI-based agents and have GenAI automatically synthesize answers inreal-time grounded in top-ranked results is changing how people interact withand consume information at massive scale. These two information interactionmodalities traditional search and AI-powered chat coexist in current searchengines either loosely coupled e.g. as separate options/tabs or tightlycoupled e.g. integrated as a chat answer embedded directly within atraditional search result page. We believe that the existence of these twodifferent modalities and potentially many others is creating an opportunityto re-imagine the search experience capitalize on the strengths of manymodalities and develop systems and strategies to support seamless flow betweenthem. We refer to these as panmodal experiences. Unlike monomodal experienceswhere only one modality is available and/or used for the task at hand panmodalexperiences make multiple modalities available to users multimodal directlysupport transitions between modalities crossmodal and seamlessly combinemodalities to tailor task assistance transmodal. While our focus is searchand chat with learnings from insights from a survey of over 100 individualswho have recently performed common tasks on these two modalities we alsopresent a more general vision for the future of information interaction usingmultiple modalities and the emergent capabilities of GenAI.</p>
                <p>Last Updated: 2024-05-21 16:49:14 UTC</p>
                <button class="interpret-button" data-id="2405.12923v1">Interpret</button>
                <div id="interpretation-2405.12923v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>From Human-to-Human to Human-to-Bot Conversations in Software Engineering</h3>
                <p>Authors: Ranim KhojahFrancisco Gomes de Oliveira NetoPhilipp Leitner</p>
                <p><a href="http://arxiv.org/abs/2405.12712v1">Link to paper</a></p>
                <p>Software developers use natural language to interact not only with otherhumans but increasingly also with chatbots. These interactions have differentproperties and flow differently based on what goal the developer wants toachieve and who they interact with. In this paper we aim to understand thedynamics of conversations that occur during modern software development afterthe integration of AI and chatbots enabling a deeper recognition of theadvantages and disadvantages of including chatbot interactions in addition tohuman conversations in collaborative work. We compile existing conversationattributes with humans and NLU-based chatbots and adapt them to the context ofsoftware development. Then we extend the comparison to include LLM-poweredchatbots based on an observational study. We present similarities anddifferences between human-to-human and human-to-bot conversations alsodistinguishing between NLU- and LLM-based chatbots. Furthermore we discuss howunderstanding the differences among the conversation styles guides thedeveloper on how to shape their expectations from a conversation andconsequently support the communication within a software team. We conclude thatthe recent conversation styles that we observe with LLM-chatbots can notreplace conversations with humans due to certain attributes regarding socialaspects despite their ability to support productivity and decrease thedevelopers mental load.</p>
                <p>Last Updated: 2024-05-21 12:04:55 UTC</p>
                <button class="interpret-button" data-id="2405.12712v1">Interpret</button>
                <div id="interpretation-2405.12712v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>GeckoGraph: A Visual Language for Polymorphic Types</h3>
                <p>Authors: Shuai FuTim DwyerPeter J. Stuckey</p>
                <p><a href="http://arxiv.org/abs/2405.12699v1">Link to paper</a></p>
                <p>Polymorphic types are an important feature in most strongly typed programminglanguages. They allow functions to be written in a way that can be used withdifferent data types while still enforcing the relationship and constraintsbetween the values. However programmers often find polymorphic types difficultto use and understand and tend to reason using concrete types. We proposeGeckoGraph a graphical notation for types. GeckoGraph aims to accompanytraditional text-based type notation and to make reading understanding andcomparing types easier. We conducted a large-scale human study using GeckoGraphcompared to text-based type notation. To our knowledge this is the largestcontrolled user study on functional programming ever conducted. The results ofthe study show that GeckoGraph helps improve programmers ability to succeed inthe programming tasks we designed especially for novice programmers.</p>
                <p>Last Updated: 2024-05-21 11:46:51 UTC</p>
                <button class="interpret-button" data-id="2405.12699v1">Interpret</button>
                <div id="interpretation-2405.12699v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>Energy Rank Alignment: Using Preference Optimization to Search Chemical Space at Scale</h3>
                <p>Authors: Shriram ChennakesavaluFrank HuSebastian IbarraranGrant M. Rotskoff</p>
                <p><a href="http://arxiv.org/abs/2405.12961v1">Link to paper</a></p>
                <p>Searching through chemical space is an exceptionally challenging problembecause the number of possible molecules grows combinatorially with the numberof atoms. Large autoregressive models trained on databases of chemicalcompounds have yielded powerful generators but we still lack robust strategiesfor generating molecules with desired properties. This molecular search problemclosely resembles the alignment problem for large language models though formany chemical tasks we have a specific and easily evaluable reward function.Here we introduce an algorithm called energy rank alignment ERA thatleverages an explicit reward function to produce a gradient-based objectivethat we use to optimize autoregressive policies. We show theoretically thatthis algorithm is closely related to proximal policy optimization PPO anddirect preference optimization DPO but has a minimizer that converges to anideal Gibbs-Boltzmann distribution with the reward playing the role of anenergy function. Furthermore this algorithm is highly scalable does notrequire reinforcement learning and performs well relative to DPO when thenumber of preference observations per pairing is small. We deploy this approachto align molecular transformers to generate molecules with externally specifiedproperties and find that it does so robustly searching through diverse partsof chemical space. While our focus here is on chemical search we also obtainexcellent results on an AI supervised task for LLM alignment showing that themethod is scalable and general.</p>
                <p>Last Updated: 2024-05-21 17:35:20 UTC</p>
                <button class="interpret-button" data-id="2405.12961v1">Interpret</button>
                <div id="interpretation-2405.12961v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Strategic Deployment of Honeypots in Blockchain-based IoT Systems</h3>
                <p>Authors: Daniel CommeySena HounsinouGarth V. Crosby</p>
                <p><a href="http://arxiv.org/abs/2405.12951v1">Link to paper</a></p>
                <p>This paper addresses the challenge of enhancing cybersecurity inBlockchain-based Internet of Things BIoTs systems which are increasinglyvulnerable to sophisticated cyberattacks. It introduces an AI-powered systemmodel for the dynamic deployment of honeypots utilizing an Intrusion DetectionSystem IDS integrated with smart contract functionalities on IoT nodes. Thismodel enables the transformation of regular nodes into decoys in response tosuspicious activities thereby strengthening the security of BIoT networks. Thepaper analyses strategic interactions between potential attackers and theAI-enhanced IDS through a game-theoretic model specifically Bayesian games.The model focuses on understanding and predicting sophisticated attacks thatmay initially appear normal emphasizing strategic decision-making optimizedhoneypot deployment and adaptive strategies in response to evolving attackpatterns.</p>
                <p>Last Updated: 2024-05-21 17:27:00 UTC</p>
                <button class="interpret-button" data-id="2405.12951v1">Interpret</button>
                <div id="interpretation-2405.12951v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs</h3>
                <p>Authors: Bilgehan SelPriya ShanmugasundaramMohammad KachueeKun ZhouRuoxi JiaMing Jin</p>
                <p><a href="http://arxiv.org/abs/2405.12933v1">Link to paper</a></p>
                <p>Large Language Models LLMs have shown remarkable capabilities in tasks suchas summarization arithmetic reasoning and question answering. However theyencounter significant challenges in the domain of moral reasoning and ethicaldecision-making especially in complex scenarios with multiple stakeholders.This paper introduces the Skin-in-the-Game SKIG framework aimed at enhancingmoral reasoning in LLMs by exploring decisions consequences from multiplestakeholder perspectives. Central to SKIGs mechanism is simulatingaccountability for actions which alongside empathy exercises and riskassessment is pivotal to its effectiveness. We validate SKIGs performanceacross various moral reasoning benchmarks with proprietary and opensource LLMsand investigate its crucial components through extensive ablation analyses.</p>
                <p>Last Updated: 2024-05-21 17:04:44 UTC</p>
                <button class="interpret-button" data-id="2405.12933v1">Interpret</button>
                <div id="interpretation-2405.12933v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Panmodal Information Interaction</h3>
                <p>Authors: Chirag ShahRyen W. White</p>
                <p><a href="http://arxiv.org/abs/2405.12923v1">Link to paper</a></p>
                <p>The emergence of generative artificial intelligence GenAI is transforminginformation interaction. For decades search engines such as Google and Binghave been the primary means of locating relevant information for the generalpopulation. They have provided search results in the same standard format theso-called 10 blue links. The recent ability to chat via natural languagewith AI-based agents and have GenAI automatically synthesize answers inreal-time grounded in top-ranked results is changing how people interact withand consume information at massive scale. These two information interactionmodalities traditional search and AI-powered chat coexist in current searchengines either loosely coupled e.g. as separate options/tabs or tightlycoupled e.g. integrated as a chat answer embedded directly within atraditional search result page. We believe that the existence of these twodifferent modalities and potentially many others is creating an opportunityto re-imagine the search experience capitalize on the strengths of manymodalities and develop systems and strategies to support seamless flow betweenthem. We refer to these as panmodal experiences. Unlike monomodal experienceswhere only one modality is available and/or used for the task at hand panmodalexperiences make multiple modalities available to users multimodal directlysupport transitions between modalities crossmodal and seamlessly combinemodalities to tailor task assistance transmodal. While our focus is searchand chat with learnings from insights from a survey of over 100 individualswho have recently performed common tasks on these two modalities we alsopresent a more general vision for the future of information interaction usingmultiple modalities and the emergent capabilities of GenAI.</p>
                <p>Last Updated: 2024-05-21 16:49:14 UTC</p>
                <button class="interpret-button" data-id="2405.12923v1">Interpret</button>
                <div id="interpretation-2405.12923v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Topic Modelling Case Law Using a Large Language Model and a New Taxonomy for UK Law: AI Insights into Summary Judgment</h3>
                <p>Authors: Holli SargeantAhmed IzzidienFelix Steffek</p>
                <p><a href="http://arxiv.org/abs/2405.12910v1">Link to paper</a></p>
                <p>This paper addresses a critical gap in legal analytics by developing andapplying a novel taxonomy for topic modelling summary judgment cases in theUnited Kingdom. Using a curated dataset of summary judgment cases we use theLarge Language Model Claude 3 Opus to explore functional topics and trends. Wefind that Claude 3 Opus correctly classified the topic with an accuracy of87.10. The analysis reveals distinct patterns in the application of summaryjudgments across various legal domains. As case law in the United Kingdom isnot originally labelled with keywords or a topic filtering option the findingsnot only refine our understanding of the thematic underpinnings of summaryjudgments but also illustrate the potential of combining traditional andAI-driven approaches in legal classification. Therefore this paper provides anew and general taxonomy for UK law. The implications of this work serve as afoundation for further research and policy discussions in the field of judicialadministration and computational legal research methodologies.</p>
                <p>Last Updated: 2024-05-21 16:30:25 UTC</p>
                <button class="interpret-button" data-id="2405.12910v1">Interpret</button>
                <div id="interpretation-2405.12910v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>Review on modeling the societal impact of infrastructure disruptions due to disasters</h3>
                <p>Authors: Yongsheng YangHuan LiuAli MostafaviHirokazu Tatano</p>
                <p><a href="http://arxiv.org/abs/2405.12732v1">Link to paper</a></p>
                <p>Infrastructure systems play a critical role in providing essential productsand services for the functioning of modern society however they arevulnerable to disasters and their service disruptions can cause severe societalimpacts. To protect infrastructure from disasters and reduce potential impactsgreat achievements have been made in modeling interdependent infrastructuresystems in past decades. In recent years scholars have gradually shifted theirresearch focus to understanding and modeling societal impacts of disruptionsconsidering the fact that infrastructure systems are critical because of theirrole in societal functioning especially under situations of modern societies.Exploring how infrastructure disruptions impair society to enhance resilientcity has become a key field of study. By comprehensively reviewing relevantstudies this paper demonstrated the definition and types of societal impact ofinfrastructure disruptions and summarized the modeling approaches into fourtypes: extended infrastructure modeling approaches empirical approachesagent-based approaches and big data-driven approaches. For each approach thispaper organized relevant literature in terms of modeling ideas advantages anddisadvantages. Furthermore the four approaches were compared according toseveral criteria including the input data types of societal impact andapplication scope. Finally this paper illustrated the challenges and futureresearch directions in the field.</p>
                <p>Last Updated: 2024-05-21 12:37:45 UTC</p>
                <button class="interpret-button" data-id="2405.12732v1">Interpret</button>
                <div id="interpretation-2405.12732v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Reinforcement Learning Enabled Peer-to-Peer Energy Trading for Dairy Farms</h3>
                <p>Authors: Mian Ibad Ali ShahEnda BarrettKarl Mason</p>
                <p><a href="http://arxiv.org/abs/2405.12716v1">Link to paper</a></p>
                <p>Farm businesses are increasingly adopting renewables to enhance energyefficiency and reduce reliance on fossil fuels and the grid. This shift aims todecrease dairy farms dependence on traditional electricity grids by enablingthe sale of surplus renewable energy in Peer-to-Peer markets. However thedynamic nature of farm communities poses challenges requiring specializedalgorithms for P2P energy trading. To address this the Multi-AgentPeer-to-Peer Dairy Farm Energy Simulator MAPDES has been developed providinga platform to experiment with Reinforcement Learning techniques. Thesimulations demonstrate significant cost savings including a 43 reduction inelectricity expenses a 42 decrease in peak demand and a 1.91 increase inenergy sales compared to baseline scenarios lacking peer-to-peer energy tradingor renewable energy sources.</p>
                <p>Last Updated: 2024-05-21 12:19:17 UTC</p>
                <button class="interpret-button" data-id="2405.12716v1">Interpret</button>
                <div id="interpretation-2405.12716v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Learning to connect in action: Measuring and understanding the emergence of boundary spanners in volatile times</h3>
                <p>Authors: Vittorio NespecaTina ComesFrances Brazier</p>
                <p><a href="http://arxiv.org/abs/2405.11998v1">Link to paper</a></p>
                <p>Collective intelligence of diverse groups is key for tackling many of todaysgrand challenges such as fostering resilience and climate adaptation.Information exchange across such diverse groups is crucial for collectiveintelligence especially in volatile environments. To facilitate inter-groupinformation exchange Informational Boundary Spanners IBSs as pivotalinformation exchange hubs are promising. However the mechanisms that drivethe emergence of IBSs remain poorly understood. To address this gap there isfirst a need for a method to identify and measure the emergence of IBSs.Second an Agent-Based Modelling ABM framework is not available tosystematically study mechanisms for the emergence of IBSs in volatileenvironments. Third even though the ability to learn who provides high-qualityinformation is thought to be essential to explain the emergence of IBSs arigorous test of this mechanism is missing. The learning mechanism isformalized using an ABM framework with the models outputs analyzed using theproposed IBS emergence measurement method. To illustrate both the method andthe learning mechanism we present a case study focused on information sharingin the volatile environment of a disaster. The study shows that learningconstitutes a mechanism for the emergence of effective IBSs in alow-volatility environments characterised by low uncertainty and b inhigh-volatility environments characterised by rapid change if the number ofinter-group connections is sufficient. With the method and model this paperaims to lay the foundations for exploring mechanisms for the emergence of IBSsthat facilitate inter-group information exchange. This article advancescollective intelligence by providing the essential elements for measuring andunderstanding the emergence of IBSs and exploring the effect of learning ontheir emergence in volatile environments.</p>
                <p>Last Updated: 2024-05-20 13:09:52 UTC</p>
                <button class="interpret-button" data-id="2405.11998v1">Interpret</button>
                <div id="interpretation-2405.11998v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Safe by Design Autonomous Driving Systems</h3>
                <p>Authors: Marius BozgaJoseph Sifakis</p>
                <p><a href="http://arxiv.org/abs/2405.11995v1">Link to paper</a></p>
                <p>Developing safe autonomous driving systems is a major scientific andtechnical challenge. Existing AI-based end-to-end solutions do not offer thenecessary safety guarantees while traditional systems engineering approachesare defeated by the complexity of the problem. Currently there is anincreasing interest in hybrid design solutions integrating machine learningcomponents when necessary while using model-based components for goalmanagement and planning.  We study a method for building safe by design autonomous driving systemsbased on the assumption that the capability to drive boils down to thecoordinated execution of a given set of driving operations. The assumption issubstantiated by a compositionality result considering that autopilots aredynamic systems receiving a small number of types of vistas as input eachvista defining a free space in its neighborhood. It is shown that safe drivingfor each type of vista in the corresponding free space implies safe drivingfor any possible scenario under some easy-to-check conditions concerning thetransition between vistas. The designed autopilot comprises distinct controlpolicies one per type of vista articulated in two consecutive phases. Thefirst phase consists of carefully managing a potentially risky situation byvirtually reducing speed while the second phase consists of exiting thesituation by accelerating.  The autopilots designed use for their predictions simple functionscharacterizing the acceleration and deceleration capabilities of the vehicles.They cover the main driving operations including entering a main roadovertaking crossing intersections protected by traffic lights or signals anddriving on freeways. The results presented reinforce the case for hybridsolutions that incorporate mathematically elegant and robust decision methodsthat are safe by design.</p>
                <p>Last Updated: 2024-05-20 12:58:25 UTC</p>
                <button class="interpret-button" data-id="2405.11995v1">Interpret</button>
                <div id="interpretation-2405.11995v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Equilibria in multiagent online problems with predictions</h3>
                <p>Authors: Gabriel IstrateCosmin BonchişVictor Bogdan</p>
                <p><a href="http://arxiv.org/abs/2405.11873v1">Link to paper</a></p>
                <p>We study the power of competitive algorithms with predictions in amultiagent setting. For this we introduce a multiagent version of theski-rental problem. In this problem agents can collaborate by pooling resourcesto get a group license for some asset. If the license price is not met agentshave to rent the asset individually for the day at a unit price. Otherwise thelicense becomes available forever to everyone at no extra cost. Our maincontribution is a best-response analysis of a single-agent competitivealgorithm that assumes perfect knowledge of other agents actions but noknowledge of its own renting time. We then analyze the setting when agentshave a predictor for their own active time yielding a tradeoff betweenrobustness and consistency. We investigate the effect of using such a predictorin an equilibrium as well as the new equilibria formed in this way.</p>
                <p>Last Updated: 2024-05-20 08:30:11 UTC</p>
                <button class="interpret-button" data-id="2405.11873v1">Interpret</button>
                <div id="interpretation-2405.11873v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>Reducing Transformer Key-Value Cache Size with Cross-Layer Attention</h3>
                <p>Authors: William BrandonMayank MishraAniruddha NrusimhaRameswar PandaJonathan Ragan Kelly</p>
                <p><a href="http://arxiv.org/abs/2405.12981v1">Link to paper</a></p>
                <p>Key-value KV caching plays an essential role in accelerating decoding fortransformer-based autoregressive large language models LLMs. However theamount of memory required to store the KV cache can become prohibitive at longsequence lengths and large batch sizes. Since the invention of the transformertwo of the most effective interventions discovered for reducing the size of theKV cache have been Multi-Query Attention MQA and its generalizationGrouped-Query Attention GQA. MQA and GQA both modify the design of theattention block so that multiple query heads can share a single key/value headreducing the number of distinct key/value heads by a large factor while onlyminimally degrading accuracy. In this paper we show that it is possible totake Multi-Query Attention a step further by also sharing key and value headsbetween adjacent layers yielding a new attention design we call Cross-LayerAttention CLA. With CLA we find that it is possible to reduce the size ofthe KV cache by another 2x while maintaining nearly the same accuracy asunmodified MQA. In experiments training 1B- and 3B-parameter models fromscratch we demonstrate that CLA provides a Pareto improvement over thememory/accuracy tradeoffs which are possible with traditional MQA enablinginference with longer sequence lengths and larger batch sizes than wouldotherwise be possible</p>
                <p>Last Updated: 2024-05-21 17:59:29 UTC</p>
                <button class="interpret-button" data-id="2405.12981v1">Interpret</button>
                <div id="interpretation-2405.12981v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Can We Treat Noisy Labels as Accurate?</h3>
                <p>Authors: Yuxiang ZhengZhongyi HanYilong YinXin GaoTongliang Liu</p>
                <p><a href="http://arxiv.org/abs/2405.12969v1">Link to paper</a></p>
                <p>Noisy labels significantly hinder the accuracy and generalization of machinelearning models particularly due to ambiguous instance features. Traditionaltechniques that attempt to correct noisy labels directly such as those usingtransition matrices often fail to address the inherent complexities of theproblem sufficiently. In this paper we introduce EchoAlign a transformativeparadigm shift in learning from noisy labels. Instead of focusing on labelcorrection EchoAlign treats noisy labels tildeY as accurate andmodifies corresponding instance features X to achieve better alignment withtildeY. EchoAligns core components are 1 EchoMod: Employingcontrollable generative models EchoMod precisely modifies instances whilemaintaining their intrinsic characteristics and ensuring alignment with thenoisy labels. 2 EchoSelect: Instance modification inevitably introducesdistribution shifts between training and test sets. EchoSelect maintains asignificant portion of clean original instances to mitigate these shifts. Itleverages the distinct feature similarity distributions between original andmodified instances as a robust tool for accurate sample selection. Thisintegrated approach yields remarkable results. In environments with 30instance-dependent noise even at 99 selection accuracy EchoSelect retainsnearly twice the number of samples compared to the previous best method.Notably on three datasets EchoAlign surpasses previous state-of-the-arttechniques with a substantial improvement.</p>
                <p>Last Updated: 2024-05-21 17:49:10 UTC</p>
                <button class="interpret-button" data-id="2405.12969v1">Interpret</button>
                <div id="interpretation-2405.12969v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The future of cosmological likelihood-based inference: accelerated high-dimensional parameter estimation and model comparison</h3>
                <p>Authors: Davide PirasAlicja PolanskaAlessio Spurio ManciniMatthew A. PriceJason D. McEwen</p>
                <p><a href="http://arxiv.org/abs/2405.12965v1">Link to paper</a></p>
                <p>We advocate for a new paradigm of cosmological likelihood-based inferenceleveraging recent developments in machine learning and its underlyingtechnology to accelerate Bayesian inference in high-dimensional settings.Specifically we combine i emulation where a machine learning model istrained to mimic cosmological observables e.g. CosmoPower-JAX iidifferentiable and probabilistic programming e.g. JAX and NumPyrorespectively iii scalable Markov chain Monte Carlo MCMC samplingtechniques that exploit gradients e.g. Hamiltonian Monte Carlo and ivdecoupled and scalable Bayesian model selection techniques that compute theBayesian evidence purely from posterior samples e.g. the learned harmonic meanimplemented in harmonic. This paradigm allows us to carry out a completeBayesian analysis including both parameter estimation and model selection ina fraction of the time of traditional approaches. First we demonstrate theapplication of this paradigm on a simulated cosmic shear analysis for a StageIV survey in 37- and 39-dimensional parameter spaces comparing LambdaCDMand a dynamical dark energy model w_0w_aCDM. We recover posterior contoursand evidence estimates that are in excellent agreement with those computed bythe traditional nested sampling approach while reducing the computational costfrom 8 months on 48 CPU cores to 2 days on 12 GPUs. Second we consider a jointanalysis between three simulated next-generation surveys each performing a3x2pt analysis resulting in 157- and 159-dimensional parameter spaces.Standard nested sampling techniques are simply not feasible in thishigh-dimensional setting requiring a projected 12 years of compute time on 48CPU cores on the other hand the proposed approach only requires 8 days ofcompute time on 24 GPUs. All packages used in our analyses are publiclyavailable.</p>
                <p>Last Updated: 2024-05-21 17:45:36 UTC</p>
                <button class="interpret-button" data-id="2405.12965v1">Interpret</button>
                <div id="interpretation-2405.12965v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Comprehensive Multimodal Deep Learning Survival Prediction Enabled by a Transformer Architecture: A Multicenter Study in Glioblastoma</h3>
                <p>Authors: Ahmed GomaaYixing HuangAmr HagagCharlotte SchmitterDaniel HöflerThomas WeissmannKatharina BreiningerManuel SchmidtJenny StritzelbergerDaniel DelevRoland CorasArnd DörflerOliver SchnellBenjamin FreyUdo S. GaiplSabine SemrauChristoph BertRainer FietkauFlorian Putz</p>
                <p><a href="http://arxiv.org/abs/2405.12963v1">Link to paper</a></p>
                <p>Background: This research aims to improve glioblastoma survival prediction byintegrating MR images clinical and molecular-pathologic data in atransformer-based deep learning model addressing data heterogeneity andperformance generalizability. Method: We propose and evaluate atransformer-based non-linear and non-proportional survival prediction model.The model employs self-supervised learning techniques to effectively encode thehigh-dimensional MRI input for integration with non-imaging data usingcross-attention. To demonstrate model generalizability the model is assessedwith the time-dependent concordance index Cdt in two training setups usingthree independent public test sets: UPenn-GBM UCSF-PDGM and RHUH-GBM eachcomprising 378 366 and 36 cases respectively. Results: The proposedtransformer model achieved promising performance for imaging as well asnon-imaging data effectively integrating both modalities for enhancedperformance UPenn-GBM test-set imaging Cdt 0.645 multimodal Cdt 0.707 whileoutperforming state-of-the-art late-fusion 3D-CNN-based models. Consistentperformance was observed across the three independent multicenter test setswith Cdt values of 0.707 UPenn-GBM internal test set 0.672 UCSF-PDGMfirst external test set and 0.618 RHUH-GBM second external test set. Themodel achieved significant discrimination between patients with favorable andunfavorable survival for all three datasets logrank p 1.9times10-89.7times10-3 and 1.2times10-2. Conclusions: The proposedtransformer-based survival prediction model integrates complementaryinformation from diverse input modalities contributing to improvedglioblastoma survival prediction compared to state-of-the-art methods.Consistent performance was observed across institutions supporting modelgeneralizability.</p>
                <p>Last Updated: 2024-05-21 17:44:48 UTC</p>
                <button class="interpret-button" data-id="2405.12963v1">Interpret</button>
                <div id="interpretation-2405.12963v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Energy Rank Alignment: Using Preference Optimization to Search Chemical Space at Scale</h3>
                <p>Authors: Shriram ChennakesavaluFrank HuSebastian IbarraranGrant M. Rotskoff</p>
                <p><a href="http://arxiv.org/abs/2405.12961v1">Link to paper</a></p>
                <p>Searching through chemical space is an exceptionally challenging problembecause the number of possible molecules grows combinatorially with the numberof atoms. Large autoregressive models trained on databases of chemicalcompounds have yielded powerful generators but we still lack robust strategiesfor generating molecules with desired properties. This molecular search problemclosely resembles the alignment problem for large language models though formany chemical tasks we have a specific and easily evaluable reward function.Here we introduce an algorithm called energy rank alignment ERA thatleverages an explicit reward function to produce a gradient-based objectivethat we use to optimize autoregressive policies. We show theoretically thatthis algorithm is closely related to proximal policy optimization PPO anddirect preference optimization DPO but has a minimizer that converges to anideal Gibbs-Boltzmann distribution with the reward playing the role of anenergy function. Furthermore this algorithm is highly scalable does notrequire reinforcement learning and performs well relative to DPO when thenumber of preference observations per pairing is small. We deploy this approachto align molecular transformers to generate molecules with externally specifiedproperties and find that it does so robustly searching through diverse partsof chemical space. While our focus here is on chemical search we also obtainexcellent results on an AI supervised task for LLM alignment showing that themethod is scalable and general.</p>
                <p>Last Updated: 2024-05-21 17:35:20 UTC</p>
                <button class="interpret-button" data-id="2405.12961v1">Interpret</button>
                <div id="interpretation-2405.12961v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-05-23</p>
        </div>
    
        </div>
    </body>
    </html>
    