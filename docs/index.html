
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo</h3>
                <p>Authors: Stephen ZhaoRob BrekelmansAlireza MakhzaniRoger Grosse</p>
                <p><a href="http://arxiv.org/abs/2404.17546v1">Link to paper</a></p>
                <p>Numerous capability and safety techniques of Large Language Models LLMsincluding RLHF automated red-teaming prompt engineering and infilling canbe cast as sampling from an unnormalized target distribution defined by a givenreward or potential function over the full sequence. In this work we leveragethe rich toolkit of Sequential Monte Carlo SMC for these probabilisticinference problems. In particular we use learned twist functions to estimatethe expected future value of the potential at each timestep which enables usto focus inference-time computation on promising partial sequences. We proposea novel contrastive method for learning the twist functions and establishconnections with the rich literature of soft reinforcement learning. As acomplementary application of our twisted SMC framework we present methods forevaluating the accuracy of language model inference techniques using novelbidirectional SMC bounds on the log partition function. These bounds can beused to estimate the KL divergence between the inference and targetdistributions in both directions. We apply our inference evaluation techniquesto show that twisted SMC is effective for sampling undesirable outputs from apretrained model a useful component of harmlessness training and automatedred-teaming generating reviews with varied sentiment and performinginfilling tasks.</p>
                <p>Last Updated: 2024-04-26 17:18:32 UTC</p>
                <button class="interpret-button" data-id="2404.17546v1">Interpret</button>
                <div id="interpretation-2404.17546v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Using Neural Implicit Flow To Represent Latent Dynamics Of Canonical Systems</h3>
                <p>Authors: Imran NasimJoaõ Lucas de Sousa Almeida</p>
                <p><a href="http://arxiv.org/abs/2404.17535v1">Link to paper</a></p>
                <p>The recently introduced class of architectures known as Neural Operators hasemerged as highly versatile tools applicable to a wide range of tasks in thefield of Scientific Machine Learning SciML including data representation andforecasting. In this study we investigate the capabilities of Neural ImplicitFlow NIF a recently developed mesh-agnostic neural operator forrepresenting the latent dynamics of canonical systems such as theKuramoto-Sivashinsky KS forced Korteweg-de Vries fKdV and Sine-GordonSG equations as well as for extracting dynamically relevant information fromthem. Finally we assess the applicability of NIF as a dimensionality reductionalgorithm and conduct a comparative analysis with another widely recognizedfamily of neural operators known as Deep Operator Networks DeepONets.</p>
                <p>Last Updated: 2024-04-26 17:01:38 UTC</p>
                <button class="interpret-button" data-id="2404.17535v1">Interpret</button>
                <div id="interpretation-2404.17535v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Large Language Model Agent as a Mechanical Designer</h3>
                <p>Authors: Yayati JadhavAmir Barati Farimani</p>
                <p><a href="http://arxiv.org/abs/2404.17525v1">Link to paper</a></p>
                <p>Conventional mechanical design paradigms rely on experts systematicallyrefining concepts through experience-guided modification and FEA to meetspecific requirements. However this approach can be time-consuming and heavilydependent on prior knowledge and experience. While numerous machine learningmodels have been developed to streamline this intensive and expert-driveniterative process these methods typically demand extensive training data andconsiderable computational resources. Furthermore methods based on deeplearning are usually restricted to the specific domains and tasks for whichthey were trained limiting their applicability across different tasks. Thiscreates a trade-off between the efficiency of automation and the demand forresources. In this study we present a novel approach that integratespre-trained LLMs with a FEM module. The FEM module evaluates each design andprovides essential feedback guiding the LLMs to continuously learn plangenerate and optimize designs without the need for domain-specific training.We demonstrate the effectiveness of our proposed framework in managing theiterative optimization of truss structures showcasing its capability to reasonabout and refine designs according to structured feedback and criteria. Ourresults reveal that these LLM-based agents can successfully generate trussdesigns that comply with natural language specifications with a success rate ofup to 90 which varies according to the applied constraints. By employingprompt-based optimization techniques we show that LLM based agents exhibitoptimization behavior when provided with solution-score pairs to iterativelyrefine designs to meet specifications. This ability of LLM agents to produceviable designs and optimize them based on their inherent reasoning capabilitieshighlights their potential to develop and implement effective design strategiesautonomously.</p>
                <p>Last Updated: 2024-04-26 16:41:24 UTC</p>
                <button class="interpret-button" data-id="2404.17525v1">Interpret</button>
                <div id="interpretation-2404.17525v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>On the Use of Large Language Models to Generate Capability Ontologies</h3>
                <p>Authors: Luis Miguel Vieira da SilvaAljosha KöcherFelix GehlhoffAlexander Fay</p>
                <p><a href="http://arxiv.org/abs/2404.17524v1">Link to paper</a></p>
                <p>Capability ontologies are increasingly used to model functionalities ofsystems or machines. The creation of such ontological models with allproperties and constraints of capabilities is very complex and can only be doneby ontology experts. However Large Language Models LLMs have shown that theycan generate machine-interpretable models from natural language text input andthus support engineers / ontology experts. Therefore this paper investigateshow LLMs can be used to create capability ontologies. We present a study with aseries of experiments in which capabilities with varying complexities aregenerated using different prompting techniques and with different LLMs. Errorsin the generated ontologies are recorded and compared. To analyze the qualityof the generated ontologies a semi-automated approach based on RDF syntaxchecking OWL reasoning and SHACL constraints is used. The results of thisstudy are very promising because even for complex capabilities the generatedontologies are almost free of errors.</p>
                <p>Last Updated: 2024-04-26 16:41:00 UTC</p>
                <button class="interpret-button" data-id="2404.17524v1">Interpret</button>
                <div id="interpretation-2404.17524v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Enhancing Legal Compliance and Regulation Analysis with Large Language Models</h3>
                <p>Authors: Shabnam Hassani</p>
                <p><a href="http://arxiv.org/abs/2404.17522v1">Link to paper</a></p>
                <p>This research explores the application of Large Language Models LLMs forautomating the extraction of requirement-related legal content in the foodsafety domain and checking legal compliance of regulatory artifacts. WithIndustry 4.0 revolutionizing the food industry and with the General DataProtection Regulation GDPR reshaping privacy policies and data processingagreements there is a growing gap between regulatory analysis and recenttechnological advancements. This study aims to bridge this gap by leveragingLLMs namely BERT and GPT models to accurately classify legal provisions andautomate compliance checks. Our findings demonstrate promising resultsindicating LLMs significant potential to enhance legal compliance andregulatory analysis efficiency notably by reducing manual workload andimproving accuracy within reasonable time and financial constraints.</p>
                <p>Last Updated: 2024-04-26 16:40:49 UTC</p>
                <button class="interpret-button" data-id="2404.17522v1">Interpret</button>
                <div id="interpretation-2404.17522v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>An exactly solvable model for emergence and scaling laws</h3>
                <p>Authors: Yoonsoo NamNayara FonsecaSeok Hyeong LeeArd Louis</p>
                <p><a href="http://arxiv.org/abs/2404.17563v1">Link to paper</a></p>
                <p>Deep learning models can exhibit what appears to be a sudden ability to solvea new problem as training time T training data D or model size Nincreases a phenomenon known as emergence. In this paper we present aframework where each new ability a skill is represented as a basis function.We solve a simple multi-linear model in this skill-basis finding analyticexpressions for the emergence of new skills as well as for scaling laws of theloss with training time data size model size and optimal compute C. Wecompare our detailed calculations to direct simulations of a two-layer neuralnetwork trained on multitask sparse parity where the tasks in the dataset aredistributed according to a power-law. Our simple model captures using a singlefit parameter the sigmoidal emergence of multiple new skills as training timedata size or model size increases in the neural network.</p>
                <p>Last Updated: 2024-04-26 17:45:32 UTC</p>
                <button class="interpret-button" data-id="2404.17563v1">Interpret</button>
                <div id="interpretation-2404.17563v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Structured Conformal Inference for Matrix Completion with Applications to Group Recommender Systems</h3>
                <p>Authors: Ziyi LiangTianmin XieXin TongMatteo Sesia</p>
                <p><a href="http://arxiv.org/abs/2404.17561v1">Link to paper</a></p>
                <p>We develop a conformal inference method to construct joint confidence regionsfor structured groups of missing entries within a sparsely observed matrix.This method is useful to provide reliable uncertainty estimation forgroup-level collaborative filtering for example it can be applied to helpsuggest a movie for a group of friends to watch together. Unlike standardconformal techniques which make inferences for one individual at a time ourmethod achieves stronger group-level guarantees by carefully assembling astructured calibration data set mimicking the patterns expected among the testgroup of interest. We propose a generalized weighted conformalization frameworkto deal with the lack of exchangeability arising from such structuredcalibration and in this process we introduce several innovations to overcomecomputational challenges. The practicality and effectiveness of our method aredemonstrated through extensive numerical experiments and an analysis of theMovieLens 100K data set.</p>
                <p>Last Updated: 2024-04-26 17:42:29 UTC</p>
                <button class="interpret-button" data-id="2404.17561v1">Interpret</button>
                <div id="interpretation-2404.17561v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Tabular Data Contrastive Learning via Class-Conditioned and Feature-Correlation Based Augmentation</h3>
                <p>Authors: Wei CuiRasa HosseinzadehJunwei MaTongzi WuYi SuiKeyvan Golestan</p>
                <p><a href="http://arxiv.org/abs/2404.17489v1">Link to paper</a></p>
                <p>Contrastive learning is a model pre-training technique by first creatingsimilar views of the original data and then encouraging the data and itscorresponding views to be close in the embedding space. Contrastive learninghas witnessed success in image and natural language data thanks to thedomain-specific augmentation techniques that are both intuitive and effective.Nonetheless in tabular domain the predominant augmentation technique forcreating views is through corrupting tabular entries via swapping values whichis not as sound or effective. We propose a simple yet powerful improvement tothis augmentation technique: corrupting tabular data conditioned on classidentity. Specifically when corrupting a specific tabular entry from an anchorrow instead of randomly sampling a value in the same feature column from theentire table uniformly we only sample from rows that are identified to bewithin the same class as the anchor row. We assume the semi-supervised learningsetting and adopt the pseudo labeling technique for obtaining class identitiesover all table rows. We also explore the novel idea of selecting features to becorrupted based on feature correlation structures. Extensive experiments showthat the proposed approach consistently outperforms the conventional corruptionmethod for tabular data classification tasks. Our code is available athttps://github.com/willtop/Tabular-Class-Conditioned-SSL.</p>
                <p>Last Updated: 2024-04-26 15:43:49 UTC</p>
                <button class="interpret-button" data-id="2404.17489v1">Interpret</button>
                <div id="interpretation-2404.17489v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Conformal Prediction with Learned Features</h3>
                <p>Authors: Shayan KiyaniGeorge PappasHamed Hassani</p>
                <p><a href="http://arxiv.org/abs/2404.17487v1">Link to paper</a></p>
                <p>In this paper we focus on the problem of conformal prediction withconditional guarantees. Prior work has shown that it is impossible to constructnontrivial prediction sets with full conditional coverage guarantees. A wealthof research has considered relaxations of full conditional guarantees relyingon some predefined uncertainty structures. Departing from this line ofthinking we propose Partition Learning Conformal Prediction PLCP aframework to improve conditional validity of prediction sets through learninguncertainty-guided features from the calibration data. We implement PLCPefficiently with alternating gradient descent utilizing off-the-shelf machinelearning models. We further analyze PLCP theoretically and provide conditionalguarantees for infinite and finite sample sizes. Finally our experimentalresults over four real-world and synthetic datasets show the superiorperformance of PLCP compared to state-of-the-art methods in terms of coverageand length in both classification and regression scenarios.</p>
                <p>Last Updated: 2024-04-26 15:43:06 UTC</p>
                <button class="interpret-button" data-id="2404.17487v1">Interpret</button>
                <div id="interpretation-2404.17487v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Differentiable Pareto-Smoothed Weighting for High-Dimensional Heterogeneous Treatment Effect Estimation</h3>
                <p>Authors: Yoichi ChikaharaKansei Ushiyama</p>
                <p><a href="http://arxiv.org/abs/2404.17483v1">Link to paper</a></p>
                <p>There is a growing interest in estimating heterogeneous treatment effectsacross individuals using their high-dimensional feature attributes. Achievinghigh performance in such high-dimensional heterogeneous treatment effectestimation is challenging because in this setup it is usual that some featuresinduce sample selection bias while others do not but are predictive ofpotential outcomes. To avoid losing such predictive feature informationexisting methods learn separate feature representations using the inverse ofprobability weighting IPW. However due to the numerically unstable IPWweights they suffer from estimation bias under a finite sample setup. Todevelop a numerically robust estimator via weighted representation learning wepropose a differentiable Pareto-smoothed weighting framework that replacesextreme weight values in an end-to-end fashion. Experimental results show thatby effectively correcting the weight values our method outperforms theexisting ones including traditional weighting schemes.</p>
                <p>Last Updated: 2024-04-26 15:34:04 UTC</p>
                <button class="interpret-button" data-id="2404.17483v1">Interpret</button>
                <div id="interpretation-2404.17483v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>A Semi-Automatic Approach to Create Large Gender- and Age-Balanced Speaker Corpora: Usefulness of Speaker Diarization & Identification</h3>
                <p>Authors: Rémi UroDavid DoukhanAlbert RilliardLaëtitia LarcherAnissa-Claire AdgharouamaneMarie TahonAntoine Laurent</p>
                <p><a href="http://arxiv.org/abs/2404.17552v1">Link to paper</a></p>
                <p>This paper presents a semi-automatic approach to create a diachronic corpusof voices balanced for speakers age gender and recording period accordingto 32 categories 2 genders 4 age ranges and 4 recording periods. Corporawere selected at French National Institute of Audiovisual INA to obtain atleast 30 speakers per category a total of 960 speakers only 874 have be foundyet. For each speaker speech excerpts were extracted from audiovisualdocuments using an automatic pipeline consisting of speech detectionbackground music and overlapped speech removal and speaker diarization used topresent clean speaker segments to human annotators identifying target speakers.This pipeline proved highly effective cutting down manual processing by afactor of ten. Evaluation of the quality of the automatic processing and of thefinal output is provided. It shows the automatic processing compare toup-to-date process and that the output provides high quality speech for mostof the selected excerpts. This method shows promise for creating large corporaof known target speakers.</p>
                <p>Last Updated: 2024-04-26 17:30:36 UTC</p>
                <button class="interpret-button" data-id="2404.17552v1">Interpret</button>
                <div id="interpretation-2404.17552v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo</h3>
                <p>Authors: Stephen ZhaoRob BrekelmansAlireza MakhzaniRoger Grosse</p>
                <p><a href="http://arxiv.org/abs/2404.17546v1">Link to paper</a></p>
                <p>Numerous capability and safety techniques of Large Language Models LLMsincluding RLHF automated red-teaming prompt engineering and infilling canbe cast as sampling from an unnormalized target distribution defined by a givenreward or potential function over the full sequence. In this work we leveragethe rich toolkit of Sequential Monte Carlo SMC for these probabilisticinference problems. In particular we use learned twist functions to estimatethe expected future value of the potential at each timestep which enables usto focus inference-time computation on promising partial sequences. We proposea novel contrastive method for learning the twist functions and establishconnections with the rich literature of soft reinforcement learning. As acomplementary application of our twisted SMC framework we present methods forevaluating the accuracy of language model inference techniques using novelbidirectional SMC bounds on the log partition function. These bounds can beused to estimate the KL divergence between the inference and targetdistributions in both directions. We apply our inference evaluation techniquesto show that twisted SMC is effective for sampling undesirable outputs from apretrained model a useful component of harmlessness training and automatedred-teaming generating reviews with varied sentiment and performinginfilling tasks.</p>
                <p>Last Updated: 2024-04-26 17:18:32 UTC</p>
                <button class="interpret-button" data-id="2404.17546v1">Interpret</button>
                <div id="interpretation-2404.17546v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Large Language Model Agent as a Mechanical Designer</h3>
                <p>Authors: Yayati JadhavAmir Barati Farimani</p>
                <p><a href="http://arxiv.org/abs/2404.17525v1">Link to paper</a></p>
                <p>Conventional mechanical design paradigms rely on experts systematicallyrefining concepts through experience-guided modification and FEA to meetspecific requirements. However this approach can be time-consuming and heavilydependent on prior knowledge and experience. While numerous machine learningmodels have been developed to streamline this intensive and expert-driveniterative process these methods typically demand extensive training data andconsiderable computational resources. Furthermore methods based on deeplearning are usually restricted to the specific domains and tasks for whichthey were trained limiting their applicability across different tasks. Thiscreates a trade-off between the efficiency of automation and the demand forresources. In this study we present a novel approach that integratespre-trained LLMs with a FEM module. The FEM module evaluates each design andprovides essential feedback guiding the LLMs to continuously learn plangenerate and optimize designs without the need for domain-specific training.We demonstrate the effectiveness of our proposed framework in managing theiterative optimization of truss structures showcasing its capability to reasonabout and refine designs according to structured feedback and criteria. Ourresults reveal that these LLM-based agents can successfully generate trussdesigns that comply with natural language specifications with a success rate ofup to 90 which varies according to the applied constraints. By employingprompt-based optimization techniques we show that LLM based agents exhibitoptimization behavior when provided with solution-score pairs to iterativelyrefine designs to meet specifications. This ability of LLM agents to produceviable designs and optimize them based on their inherent reasoning capabilitieshighlights their potential to develop and implement effective design strategiesautonomously.</p>
                <p>Last Updated: 2024-04-26 16:41:24 UTC</p>
                <button class="interpret-button" data-id="2404.17525v1">Interpret</button>
                <div id="interpretation-2404.17525v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>On the Use of Large Language Models to Generate Capability Ontologies</h3>
                <p>Authors: Luis Miguel Vieira da SilvaAljosha KöcherFelix GehlhoffAlexander Fay</p>
                <p><a href="http://arxiv.org/abs/2404.17524v1">Link to paper</a></p>
                <p>Capability ontologies are increasingly used to model functionalities ofsystems or machines. The creation of such ontological models with allproperties and constraints of capabilities is very complex and can only be doneby ontology experts. However Large Language Models LLMs have shown that theycan generate machine-interpretable models from natural language text input andthus support engineers / ontology experts. Therefore this paper investigateshow LLMs can be used to create capability ontologies. We present a study with aseries of experiments in which capabilities with varying complexities aregenerated using different prompting techniques and with different LLMs. Errorsin the generated ontologies are recorded and compared. To analyze the qualityof the generated ontologies a semi-automated approach based on RDF syntaxchecking OWL reasoning and SHACL constraints is used. The results of thisstudy are very promising because even for complex capabilities the generatedontologies are almost free of errors.</p>
                <p>Last Updated: 2024-04-26 16:41:00 UTC</p>
                <button class="interpret-button" data-id="2404.17524v1">Interpret</button>
                <div id="interpretation-2404.17524v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Comprehensive Evaluation on Event Reasoning of Large Language Models</h3>
                <p>Authors: Zhengwei TaoZhi JinYifan ZhangXiancai ChenXiaoying BaiYue FangHaiyan ZhaoJia LiChongyang Tao</p>
                <p><a href="http://arxiv.org/abs/2404.17513v1">Link to paper</a></p>
                <p>Event reasoning is a fundamental ability that underlies many applications. Itrequires event schema knowledge to perform global reasoning and needs to dealwith the diversity of the inter-event relations and the reasoning paradigms.How well LLMs accomplish event reasoning on various relations and reasoningparadigms remains unknown. To mitigate this disparity we comprehensivelyevaluate the abilities of event reasoning of LLMs. We introduce a novelbenchmark EV2 for EValuation of EVent reasoning. EV2 consists of two levels ofevaluation of schema and instance and is comprehensive in relations andreasoning paradigms. We conduct extensive experiments on EV2. We find that LLMshave abilities to accomplish event reasoning but their performances are farfrom satisfactory. We also notice the imbalance of event reasoning abilities inLLMs. Besides LLMs have event schema knowledge however theyre not alignedwith humans on how to utilize the knowledge. Based on these findings weintroduce two methods to guide the LLMs to utilize the event schema knowledge.Both methods achieve improvements.</p>
                <p>Last Updated: 2024-04-26 16:28:34 UTC</p>
                <button class="interpret-button" data-id="2404.17513v1">Interpret</button>
                <div id="interpretation-2404.17513v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>Tunnel Try-on: Excavating Spatial-temporal Tunnels for High-quality Virtual Try-on in Videos</h3>
                <p>Authors: Zhengze XuMengting ChenZhao WangLinyu XingZhonghua ZhaiNong SangJinsong LanShuai XiaoChangxin Gao</p>
                <p><a href="http://arxiv.org/abs/2404.17571v1">Link to paper</a></p>
                <p>Video try-on is a challenging task and has not been well tackled in previousworks. The main obstacle lies in preserving the details of the clothing andmodeling the coherent motions simultaneously. Faced with those difficulties weaddress video try-on by proposing a diffusion-based framework named TunnelTry-on. The core idea is excavating a focus tunnel in the input video thatgives close-up shots around the clothing regions. We zoom in on the region inthe tunnel to better preserve the fine details of the clothing. To generatecoherent motions we first leverage the Kalman filter to construct smooth cropsin the focus tunnel and inject the position embedding of the tunnel intoattention layers to improve the continuity of the generated videos. Inaddition we develop an environment encoder to extract the context informationoutside the tunnels as supplementary cues. Equipped with these techniquesTunnel Try-on keeps the fine details of the clothing and synthesizes stable andsmooth videos. Demonstrating significant advancements Tunnel Try-on could beregarded as the first attempt toward the commercial-level application ofvirtual try-on in videos.</p>
                <p>Last Updated: 2024-04-26 17:55:26 UTC</p>
                <button class="interpret-button" data-id="2404.17571v1">Interpret</button>
                <div id="interpretation-2404.17571v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>MaPa: Text-driven Photorealistic Material Painting for 3D Shapes</h3>
                <p>Authors: Shangzhan ZhangSida PengTao XuYuanbo YangTianrun ChenNan XueYujun ShenHujun BaoRuizhen HuXiaowei Zhou</p>
                <p><a href="http://arxiv.org/abs/2404.17569v1">Link to paper</a></p>
                <p>This paper aims to generate materials for 3D meshes from text descriptions.Unlike existing methods that synthesize texture maps we propose to generatesegment-wise procedural material graphs as the appearance representation whichsupports high-quality rendering and provides substantial flexibility inediting. Instead of relying on extensive paired data i.e. 3D meshes withmaterial graphs and corresponding text descriptions to train a material graphgenerative model we propose to leverage the pre-trained 2D diffusion model asa bridge to connect the text and material graphs. Specifically our approachdecomposes a shape into a set of segments and designs a segment-controlleddiffusion model to synthesize 2D images that are aligned with mesh parts. Basedon generated images we initialize parameters of material graphs and fine-tunethem through the differentiable rendering module to produce materials inaccordance with the textual description. Extensive experiments demonstrate thesuperior performance of our framework in photorealism resolution andeditability over existing methods. Project page:https://zhanghe3z.github.io/MaPa/</p>
                <p>Last Updated: 2024-04-26 17:54:38 UTC</p>
                <button class="interpret-button" data-id="2404.17569v1">Interpret</button>
                <div id="interpretation-2404.17569v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>ChangeBind: A Hybrid Change Encoder for Remote Sensing Change Detection</h3>
                <p>Authors: Mubashir NomanMustansar FiazHisham Cholakkal</p>
                <p><a href="http://arxiv.org/abs/2404.17565v1">Link to paper</a></p>
                <p>Change detection CD is a fundamental task in remote sensing RS which aimsto detect the semantic changes between the same geographical regions atdifferent time stamps. Existing convolutional neural networks CNNs basedapproaches often struggle to capture long-range dependencies. Whereas recenttransformer-based methods are prone to the dominant global representation andmay limit their capabilities to capture the subtle change regions due to thecomplexity of the objects in the scene. To address these limitations wepropose an effective Siamese-based framework to encode the semantic changesoccurring in the bi-temporal RS images. The main focus of our design is tointroduce a change encoder that leverages local and global featurerepresentations to capture both subtle and large change feature informationfrom multi-scale features to precisely estimate the change regions. Ourexperimental study on two challenging CD datasets reveals the merits of ourapproach and obtains state-of-the-art performance.</p>
                <p>Last Updated: 2024-04-26 17:47:14 UTC</p>
                <button class="interpret-button" data-id="2404.17565v1">Interpret</button>
                <div id="interpretation-2404.17565v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Exploring the Distinctiveness and Fidelity of the Descriptions Generated by Large Vision-Language Models</h3>
                <p>Authors: Yuhang HuangZihan WuChongyang GaoJiawei PengXu Yang</p>
                <p><a href="http://arxiv.org/abs/2404.17534v1">Link to paper</a></p>
                <p>Large Vision-Language Models LVLMs are gaining traction for theirremarkable ability to process and integrate visual and textual data. Despitetheir popularity the capacity of LVLMs to generate precise fine-grainedtextual descriptions has not been fully explored. This study addresses this gapby focusing on textitdistinctiveness and textitfidelity assessing howmodels like Open-Flamingo IDEFICS and MiniGPT-4 can distinguish betweensimilar objects and accurately describe visual features. We proposed theTextual Retrieval-Augmented Classification TRAC framework which byleveraging its generative capabilities allows us to delve deeper intoanalyzing fine-grained visual description generation. This research providesvaluable insights into the generation quality of LVLMs enhancing theunderstanding of multimodal language models. Notably MiniGPT-4 stands out forits better ability to generate fine-grained descriptions outperforming theother two models in this aspect. The code is provided aturlhttps://anonymous.4open.science/r/Explore_FGVDs-E277.</p>
                <p>Last Updated: 2024-04-26 16:59:26 UTC</p>
                <button class="interpret-button" data-id="2404.17534v1">Interpret</button>
                <div id="interpretation-2404.17534v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Geometry-aware Reconstruction and Fusion-refined Rendering for Generalizable Neural Radiance Fields</h3>
                <p>Authors: Tianqi LiuXinyi YeMin ShiZihao HuangZhiyu PanZhan PengZhiguo Cao</p>
                <p><a href="http://arxiv.org/abs/2404.17528v1">Link to paper</a></p>
                <p>Generalizable NeRF aims to synthesize novel views for unseen scenes. Commonpractices involve constructing variance-based cost volumes for geometryreconstruction and encoding 3D descriptors for decoding novel views. Howeverexisting methods show limited generalization ability in challenging conditionsdue to inaccurate geometry sub-optimal descriptors and decoding strategies.We address these issues point by point. First we find the variance-based costvolume exhibits failure patterns as the features of pixels corresponding to thesame point can be inconsistent across different views due to occlusions orreflections. We introduce an Adaptive Cost Aggregation ACA approach toamplify the contribution of consistent pixel pairs and suppress inconsistentones. Unlike previous methods that solely fuse 2D features into descriptorsour approach introduces a Spatial-View Aggregator SVA to incorporate 3Dcontext into descriptors through spatial and inter-view interaction. Whendecoding the descriptors we observe the two existing decoding strategies excelin different areas which are complementary. A Consistency-Aware Fusion CAFstrategy is proposed to leverage the advantages of both. We incorporate theabove ACA SVA and CAF into a coarse-to-fine framework termed Geometry-awareReconstruction and Fusion-refined Rendering GeFu. GeFu attainsstate-of-the-art performance across multiple datasets. Code is available athttps://github.com/TQTQliu/GeFu .</p>
                <p>Last Updated: 2024-04-26 16:46:28 UTC</p>
                <button class="interpret-button" data-id="2404.17528v1">Interpret</button>
                <div id="interpretation-2404.17528v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>An exactly solvable model for emergence and scaling laws</h3>
                <p>Authors: Yoonsoo NamNayara FonsecaSeok Hyeong LeeArd Louis</p>
                <p><a href="http://arxiv.org/abs/2404.17563v1">Link to paper</a></p>
                <p>Deep learning models can exhibit what appears to be a sudden ability to solvea new problem as training time T training data D or model size Nincreases a phenomenon known as emergence. In this paper we present aframework where each new ability a skill is represented as a basis function.We solve a simple multi-linear model in this skill-basis finding analyticexpressions for the emergence of new skills as well as for scaling laws of theloss with training time data size model size and optimal compute C. Wecompare our detailed calculations to direct simulations of a two-layer neuralnetwork trained on multitask sparse parity where the tasks in the dataset aredistributed according to a power-law. Our simple model captures using a singlefit parameter the sigmoidal emergence of multiple new skills as training timedata size or model size increases in the neural network.</p>
                <p>Last Updated: 2024-04-26 17:45:32 UTC</p>
                <button class="interpret-button" data-id="2404.17563v1">Interpret</button>
                <div id="interpretation-2404.17563v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Federated Transfer Component Analysis Towards Effective VNF Profiling</h3>
                <p>Authors: Xunzheng ZhangBShadi MoazzeniJuan Marcelo Parra-UllauriReza NejabatiDimitra Simeonidou</p>
                <p><a href="http://arxiv.org/abs/2404.17553v1">Link to paper</a></p>
                <p>The increasing concerns of knowledge transfer and data privacy challenge thetraditional gather-and-analyse paradigm in networks. Specifically theintelligent orchestration of Virtual Network Functions VNFs requiresunderstanding and profiling the resource consumption. However profiling allkinds of VNFs is time-consuming. It is important to consider transferring thewell-profiled VNF knowledge to other lack-profiled VNF types while keeping dataprivate. To this end this paper proposes a Federated Transfer ComponentAnalysis FTCA method between the source and target VNFs. FTCA first trainsGenerative Adversarial Networks GANs based on the source VNF profiling dataand the trained GANs model is sent to the target VNF domain. Then FTCArealizes federated domain adaptation by using the generated source VNF data andless target VNF profiling data while keeping the raw data locally. Experimentsshow that the proposed FTCA can effectively predict the required resources forthe target VNF. Specifically the RMSE index of the regression model decreasesby 38.5 and the R-squared metric advances up to 68.6.</p>
                <p>Last Updated: 2024-04-26 17:31:41 UTC</p>
                <button class="interpret-button" data-id="2404.17553v1">Interpret</button>
                <div id="interpretation-2404.17553v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Semi-Automatic Approach to Create Large Gender- and Age-Balanced Speaker Corpora: Usefulness of Speaker Diarization & Identification</h3>
                <p>Authors: Rémi UroDavid DoukhanAlbert RilliardLaëtitia LarcherAnissa-Claire AdgharouamaneMarie TahonAntoine Laurent</p>
                <p><a href="http://arxiv.org/abs/2404.17552v1">Link to paper</a></p>
                <p>This paper presents a semi-automatic approach to create a diachronic corpusof voices balanced for speakers age gender and recording period accordingto 32 categories 2 genders 4 age ranges and 4 recording periods. Corporawere selected at French National Institute of Audiovisual INA to obtain atleast 30 speakers per category a total of 960 speakers only 874 have be foundyet. For each speaker speech excerpts were extracted from audiovisualdocuments using an automatic pipeline consisting of speech detectionbackground music and overlapped speech removal and speaker diarization used topresent clean speaker segments to human annotators identifying target speakers.This pipeline proved highly effective cutting down manual processing by afactor of ten. Evaluation of the quality of the automatic processing and of thefinal output is provided. It shows the automatic processing compare toup-to-date process and that the output provides high quality speech for mostof the selected excerpts. This method shows promise for creating large corporaof known target speakers.</p>
                <p>Last Updated: 2024-04-26 17:30:36 UTC</p>
                <button class="interpret-button" data-id="2404.17552v1">Interpret</button>
                <div id="interpretation-2404.17552v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo</h3>
                <p>Authors: Stephen ZhaoRob BrekelmansAlireza MakhzaniRoger Grosse</p>
                <p><a href="http://arxiv.org/abs/2404.17546v1">Link to paper</a></p>
                <p>Numerous capability and safety techniques of Large Language Models LLMsincluding RLHF automated red-teaming prompt engineering and infilling canbe cast as sampling from an unnormalized target distribution defined by a givenreward or potential function over the full sequence. In this work we leveragethe rich toolkit of Sequential Monte Carlo SMC for these probabilisticinference problems. In particular we use learned twist functions to estimatethe expected future value of the potential at each timestep which enables usto focus inference-time computation on promising partial sequences. We proposea novel contrastive method for learning the twist functions and establishconnections with the rich literature of soft reinforcement learning. As acomplementary application of our twisted SMC framework we present methods forevaluating the accuracy of language model inference techniques using novelbidirectional SMC bounds on the log partition function. These bounds can beused to estimate the KL divergence between the inference and targetdistributions in both directions. We apply our inference evaluation techniquesto show that twisted SMC is effective for sampling undesirable outputs from apretrained model a useful component of harmlessness training and automatedred-teaming generating reviews with varied sentiment and performinginfilling tasks.</p>
                <p>Last Updated: 2024-04-26 17:18:32 UTC</p>
                <button class="interpret-button" data-id="2404.17546v1">Interpret</button>
                <div id="interpretation-2404.17546v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Using Neural Implicit Flow To Represent Latent Dynamics Of Canonical Systems</h3>
                <p>Authors: Imran NasimJoaõ Lucas de Sousa Almeida</p>
                <p><a href="http://arxiv.org/abs/2404.17535v1">Link to paper</a></p>
                <p>The recently introduced class of architectures known as Neural Operators hasemerged as highly versatile tools applicable to a wide range of tasks in thefield of Scientific Machine Learning SciML including data representation andforecasting. In this study we investigate the capabilities of Neural ImplicitFlow NIF a recently developed mesh-agnostic neural operator forrepresenting the latent dynamics of canonical systems such as theKuramoto-Sivashinsky KS forced Korteweg-de Vries fKdV and Sine-GordonSG equations as well as for extracting dynamically relevant information fromthem. Finally we assess the applicability of NIF as a dimensionality reductionalgorithm and conduct a comparative analysis with another widely recognizedfamily of neural operators known as Deep Operator Networks DeepONets.</p>
                <p>Last Updated: 2024-04-26 17:01:38 UTC</p>
                <button class="interpret-button" data-id="2404.17535v1">Interpret</button>
                <div id="interpretation-2404.17535v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>A multi-agent model of hierarchical decision dynamics</h3>
                <p>Authors: Paul Kinsler</p>
                <p><a href="http://arxiv.org/abs/2404.17477v1">Link to paper</a></p>
                <p>Decision making can be difficult when there are many actors or agents whomay be coordinating or competing to achieve their various ideas of the optimumoutcome. Here I present a simple decision making model with an explicitlyhierarchical binary-tree structure and evaluate how this might cooperate totake actions that match its various evaluations of the uncertain state of theworld. Key features of agent behaviour are a the separation of its decisionmaking process into three distinct steps: observation judgement and actionand b the evolution of coordination by the sharing of judgements.</p>
                <p>Last Updated: 2024-04-26 15:26:43 UTC</p>
                <button class="interpret-button" data-id="2404.17477v1">Interpret</button>
                <div id="interpretation-2404.17477v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Real-World Deployment of a Hierarchical Uncertainty-Aware Collaborative Multiagent Planning System</h3>
                <p>Authors: Martina Stadler KurtzSamuel PrenticeYasmin VeysLong QuangCarlos Nieto-GrandaMichael NovitzkyEthan StumpNicholas Roy</p>
                <p><a href="http://arxiv.org/abs/2404.17438v1">Link to paper</a></p>
                <p>We would like to enable a collaborative multiagent team to navigate at longlength scales and under uncertainty in real-world environments. In practiceplanning complexity scales with the number of agents in the team with thelength scale of the environment and with environmental uncertainty. Enablingtractable planning requires developing abstract models that can representcomplex high-quality plans. However such models often abstract awayinformation needed to generate directly-executable plans for real-world agentsin real-world environments as planning in such detail especially in thepresence of real-world uncertainty would be computationally intractable. Inthis paper we describe the deployment of a planning system that used ahierarchy of planners to execute collaborative multiagent navigation tasks inreal-world unknown environments. By developing a planning system that wasrobust to failures at every level of the planning hierarchy we enabled theteam to complete collaborative navigation tasks even in the presence ofimperfect planning abstractions and real-world uncertainty. We deployed ourapproach on a Clearpath Husky-Jackal team navigating in a structured outdoorenvironment and demonstrated that the system enabled the agents tosuccessfully execute collaborative plans.</p>
                <p>Last Updated: 2024-04-26 14:22:50 UTC</p>
                <button class="interpret-button" data-id="2404.17438v1">Interpret</button>
                <div id="interpretation-2404.17438v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>On the Road to Clarity: Exploring Explainable AI for World Models in a Driver Assistance System</h3>
                <p>Authors: Mohamed RoshdiJulian PetzoldMostafa WahbyHussein EbrahimMladen BerekovicHeiko Hamann</p>
                <p><a href="http://arxiv.org/abs/2404.17350v1">Link to paper</a></p>
                <p>In Autonomous Driving AD transparency and safety are paramount as mistakesare costly. However neural networks used in AD systems are generallyconsidered black boxes. As a countermeasure we have methods of explainable AIXAI such as feature relevance estimation and dimensionality reduction.Coarse graining techniques can also help reduce dimensionality and findinterpretable global patterns. A specific coarse graining method isRenormalization Groups from statistical physics. It has previously been appliedto Restricted Boltzmann Machines RBMs to interpret unsupervised learning. Werefine this technique by building a transparent backbone model forconvolutional variational autoencoders VAE that allows mapping latent valuesto input features and has performance comparable to trained black box VAEs.Moreover we propose a custom feature map visualization technique to analyzethe internal convolutional layers in the VAE to explain internal causes of poorreconstruction that may lead to dangerous traffic scenarios in AD applications.In a second key contribution we propose explanation and evaluation techniquesfor the internal dynamics and feature relevance of prediction networks. We testa long short-term memory LSTM network in the computer vision domain toevaluate the predictability and in future applications potentially safety ofprediction models. We showcase our methods by analyzing a VAE-LSTM world modelthat predicts pedestrian perception in an urban traffic situation.</p>
                <p>Last Updated: 2024-04-26 11:57:17 UTC</p>
                <button class="interpret-button" data-id="2404.17350v1">Interpret</button>
                <div id="interpretation-2404.17350v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Agentive Permissions in Multiagent Systems</h3>
                <p>Authors: Qi Shi</p>
                <p><a href="http://arxiv.org/abs/2404.17053v1">Link to paper</a></p>
                <p>This paper proposes to distinguish four forms of agentive permissions inmultiagent settings. The main technical results are the complexity analysis ofmodel checking the semantic undefinability of modalities that capture theseforms of permissions through each other and a complete logical systemcapturing the interplay between these modalities.</p>
                <p>Last Updated: 2024-04-25 21:27:39 UTC</p>
                <button class="interpret-button" data-id="2404.17053v1">Interpret</button>
                <div id="interpretation-2404.17053v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>AutoGenesisAgent: Self-Generating Multi-Agent Systems for Complex Tasks</h3>
                <p>Authors: Jeremy Harper</p>
                <p><a href="http://arxiv.org/abs/2404.17017v1">Link to paper</a></p>
                <p>The proliferation of large language models LLMs and their integration intomulti-agent systems has paved the way for sophisticated automation in variousdomains. This paper introduces AutoGenesisAgent a multi-agent system thatautonomously designs and deploys other multi-agent systems tailored forspecific tasks. AutoGenesisAgent comprises several specialized agents includingSystem Understanding System Design Agent Generator and several others thatcollectively manage the lifecycle of creating functional multi-agent systemsfrom initial concept to deployment. Each agent in AutoGenesisAgent has distinctresponsibilities ranging from interpreting input prompts to optimizing systemperformance culminating in the deployment of a ready-to-use system. Thisproof-of-concept study discusses the design implementation and lessonslearned from developing AutoGenesisAgent highlighting its capability togenerate and refine multi-agent systems autonomously thereby reducing the needfor extensive human oversight in the initial stages of system design. Keywords:multi-agent systems large language models system design automation agentarchitecture autonomous systems software deployment</p>
                <p>Last Updated: 2024-04-25 20:20:51 UTC</p>
                <button class="interpret-button" data-id="2404.17017v1">Interpret</button>
                <div id="interpretation-2404.17017v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>A Novel Context driven Critical Integrative Levels (CIL) Approach: Advancing Human-Centric and Integrative Lighting Asset Management in Public Libraries with Practical Thresholds</h3>
                <p>Authors: Jing LinNina MyllyPer Olof HedekvistJingchun Shen</p>
                <p><a href="http://arxiv.org/abs/2404.17554v1">Link to paper</a></p>
                <p>This paper proposes the context driven Critical Integrative Levels CIL anovel approach to lighting asset management in public libraries that alignswith the transformative vision of human-centric and integrative lighting. Thisapproach encompasses not only the visual aspects of lighting performance butalso prioritizes the physiological and psychological well-being of libraryusers. Incorporating a newly defined metric Mean Time of Exposure MTOE theapproach quantifies user-light interaction enabling tailored lightingstrategies that respond to diverse activities and needs in library spaces. Casestudies demonstrate how the CIL matrix can be practically applied offeringsignificant improvements over conventional methods by focusing on optimizeduser experiences from both visual impacts and non-visual effects.</p>
                <p>Last Updated: 2024-04-26 17:33:24 UTC</p>
                <button class="interpret-button" data-id="2404.17554v1">Interpret</button>
                <div id="interpretation-2404.17554v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>"ChatGPT Is Here to Help, Not to Replace Anybody" -- An Evaluation of Students' Opinions On Integrating ChatGPT In CS Courses</h3>
                <p>Authors: Bruno Pereira CiprianoPedro Alves</p>
                <p><a href="http://arxiv.org/abs/2404.17443v1">Link to paper</a></p>
                <p>Large Language Models LLMs like GPT and Bard are capable of producing codebased on textual descriptions with remarkable efficacy. Such technology willhave profound implications for computing education raising concerns aboutcheating excessive dependence and a decline in computational thinking skillsamong others. There has been extensive research on how teachers should handlethis challenge but it is also important to understand how students feel aboutthis paradigm shift. In this research 52 first-year CS students were surveyedin order to assess their views on technologies with code-generationcapabilities both from academic and professional perspectives. Our findingsindicate that while students generally favor the academic use of GPT theydont over rely on it only mildly asking for its help. Although most studentsbenefit from GPT some struggle to use it effectively urging the need forspecific GPT training. Opinions on GPTs impact on their professional livesvary but there is a consensus on its importance in academic practice.</p>
                <p>Last Updated: 2024-04-26 14:29:16 UTC</p>
                <button class="interpret-button" data-id="2404.17443v1">Interpret</button>
                <div id="interpretation-2404.17443v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Child Speech Recognition in Human-Robot Interaction: Problem Solved?</h3>
                <p>Authors: Ruben JanssensEva VerhelstGiulio Antonio AbboQiaoqiao RenMaria Jose Pinto BernalTony Belpaeme</p>
                <p><a href="http://arxiv.org/abs/2404.17394v1">Link to paper</a></p>
                <p>Automated Speech Recognition shows superhuman performance for adult Englishspeech on a range of benchmarks but disappoints when fed childrens speech.This has long sat in the way of child-robot interaction. Recent evolutions indata-driven speech recognition including the availability of Transformerarchitectures and unprecedented volumes of training data might mean abreakthrough for child speech recognition and social robot applications aimedat children. We revisit a study on child speech recognition from 2017 and showthat indeed performance has increased with newcomer OpenAI Whisper doingmarkedly better than leading commercial cloud services. While transcription isnot perfect yet the best model recognises 60.3 of sentences correctly barringsmall grammatical differences with sub-second transcription time running on alocal GPU showing potential for usable autonomous child-robot speechinteractions.</p>
                <p>Last Updated: 2024-04-26 13:14:28 UTC</p>
                <button class="interpret-button" data-id="2404.17394v1">Interpret</button>
                <div id="interpretation-2404.17394v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training</h3>
                <p>Authors: Lakmal MeegahapolaHamza HassouneDaniel Gatica-Perez</p>
                <p><a href="http://dx.doi.org/10.1145/3659591">Link to paper</a></p>
                <p>Over the years multimodal mobile sensing has been used extensively forinferences regarding health and well being behavior and context. However asignificant challenge hindering the widespread deployment of such models inreal world scenarios is the issue of distribution shift. This is the phenomenonwhere the distribution of data in the training set differs from thedistribution of data in the real world the deployment environment. Whileextensively explored in computer vision and natural language processing andwhile prior research in mobile sensing briefly addresses this concern currentwork primarily focuses on models dealing with a single modality of data suchas audio or accelerometer readings and consequently there is little researchon unsupervised domain adaptation when dealing with multimodal sensor data. Toaddress this gap we did extensive experiments with domain adversarial neuralnetworks DANN showing that they can effectively handle distribution shifts inmultimodal sensor data. Moreover we proposed a novel improvement over DANNcalled M3BAT unsupervised domain adaptation for multimodal mobile sensing withmulti-branch adversarial training to account for the multimodality of sensordata during domain adaptation with multiple branches. Through extensiveexperiments conducted on two multimodal mobile sensing datasets threeinference tasks and 14 source-target domain pairs including both regressionand classification we demonstrate that our approach performs effectively onunseen domains. Compared to directly deploying a model trained in the sourcedomain to the target domain the model shows performance increases up to 12AUC area under the receiver operating characteristics curves onclassification tasks and up to 0.13 MAE mean absolute error on regressiontasks.</p>
                <p>Last Updated: 2024-04-26 13:09:35 UTC</p>
                <button class="interpret-button" data-id="2404.17391v1">Interpret</button>
                <div id="interpretation-2404.17391v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>How Could AI Support Design Education? A Study Across Fields Fuels Situating Analytics</h3>
                <p>Authors: Ajit JainAndruid KerneHannah FowlerJinsil SeoGalen NewmanNic LupferAaron Perrine</p>
                <p><a href="http://arxiv.org/abs/2404.17390v1">Link to paper</a></p>
                <p>We use the process and findings from a case study of design educatorspractices of assessment and feedback to fuel theorizing about how to make AIuseful in service of human experience. We build on Suchmans theory of situatedactions. We perform a qualitative study of 11 educators in 5 fields who teachdesign processes situated in project-based learning contexts. Throughqualitative data gathering and analysis we derive codes: design processassessment and feedback challenges and computational support.  We twice invoke creative cognitions family resemblance principle. First toexplain how design instructors already use assessment rubrics and second toexplain the analogous role for design creativity analytics: no particular traitis necessary or sufficient each only tends to indicate good design work. Humanteachers remain essential. We develop a set of situated design creativityanalytics--Fluency Flexibility Visual Consistency Multiscale Organizationand Legible Contrast--to support instructors efforts by providing on-demandlearning objectives-based assessment and feedback to students.  We theorize a methodology which we call situating analytics firstly becausemaking AI support living human activity depends on aligning what analyticsmeasure with situated practices. Further we realize that analytics can becomemost significant to users by situating them through interfaces that integratethem into the material contexts of their use. Here this means situating designcreativity analytics into actual design environments. Through the case studywe identify situating analytics as a methodology for explaining analytics tousers because the iterative process of alignment with practice has thepotential to enable data scientists to derive analytics that make sense as partof and support situated human experiences.</p>
                <p>Last Updated: 2024-04-26 13:06:52 UTC</p>
                <button class="interpret-button" data-id="2404.17390v1">Interpret</button>
                <div id="interpretation-2404.17390v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-04-29</p>
        </div>
    
        </div>
    </body>
    </html>
    