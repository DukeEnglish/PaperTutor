
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>3D-GRAND: Towards Better Grounding and Less Hallucination for 3D-LLMs</h3>
                <p>Authors: Jianing YangXuweiyi ChenNikhil MadaanMadhavan IyengarShengyi QianDavid F. FouheyJoyce Chai</p>
                <p><a href="http://arxiv.org/abs/2406.05132v1">Link to paper</a></p>
                <p>The integration of language and 3D perception is crucial for developingembodied agents and robots that comprehend and interact with the physicalworld. While large language models LLMs have demonstrated impressive languageunderstanding and generation capabilities their adaptation to 3D environments3D-LLMs remains in its early stages. A primary challenge is the absence oflarge-scale datasets that provide dense grounding between language and 3Dscenes. In this paper we introduce 3D-GRAND a pioneering large-scale datasetcomprising 40087 household scenes paired with 6.2 million densely-groundedscene-language instructions. Our results show that instruction tuning with3D-GRAND significantly enhances grounding capabilities and reduceshallucinations in 3D-LLMs. As part of our contributions we propose acomprehensive benchmark 3D-POPE to systematically evaluate hallucination in3D-LLMs enabling fair comparisons among future models. Our experimentshighlight a scaling effect between dataset size and 3D-LLM performanceemphasizing the critical role of large-scale 3D-text datasets in advancingembodied AI research. Notably our results demonstrate early signals foreffective sim-to-real transfer indicating that models trained on largesynthetic data can perform well on real-world 3D scans. Through 3D-GRAND and3D-POPE we aim to equip the embodied AI community with essential resources andinsights setting the stage for more reliable and better-grounded 3D-LLMs.Project website: https://3d-grand.github.io</p>
                <p>Last Updated: 2024-06-07 17:59:59 UTC</p>
                <button class="interpret-button" data-id="2406.05132v1">Interpret</button>
                <div id="interpretation-2406.05132v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal Large Language Models</h3>
                <p>Authors: Xiongtao ZhouJie HeYuhua KeGuangyao ZhuVíctor Gutiérrez-BasultoJeff Z. Pan</p>
                <p><a href="http://arxiv.org/abs/2406.05130v1">Link to paper</a></p>
                <p>Multimodal large language models MLLMs fine-tuned with multimodalinstruction datasets have demonstrated remarkable capabilities in multimodaltasks. However fine-tuning all parameters of MLLMs has become challenging asthey usually contain billions of parameters. To address this issue we studyparameter-efficient fine-tuning PEFT methods for MLLMs. We aim to identifyeffective methods for enhancing the performance of MLLMs in scenarios whereonly a limited number of parameters are trained. This paper conducts empiricalstudies using four popular PEFT methods to fine-tune the LLM component ofopen-source MLLMs. We present a comprehensive analysis that encompasses variousaspects including the impact of PEFT methods on various models parameters andlocation of the PEFT module size of fine-tuning data model stability based onPEFT methods MLLMs generalization and hallucination. We evaluated four PEFTmethods on seven datasets from two different categories: unseen and seendatasets. Across all experiments we show that the adapter is thebest-performing PEFT method. At the same time fine-tuning the connector layersleads to improved performance in most MLLMs. Code and data are available athttps://github.com/alenai97/PEFT-MLLM.git.</p>
                <p>Last Updated: 2024-06-07 17:58:11 UTC</p>
                <button class="interpret-button" data-id="2406.05130v1">Interpret</button>
                <div id="interpretation-2406.05130v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Multi-Head RAG: Solving Multi-Aspect Problems with LLMs</h3>
                <p>Authors: Maciej BestaAles KubicekRoman NiggliRobert GerstenbergerLucas WeitzendorfMingyuan ChiPatrick IffJoanna GajdaPiotr NyczykJürgen MüllerHubert NiewiadomskiMarcin ChrapekMichał PodstawskiTorsten Hoefler</p>
                <p><a href="http://arxiv.org/abs/2406.05085v1">Link to paper</a></p>
                <p>Retrieval Augmented Generation RAG enhances the abilities of Large LanguageModels LLMs by enabling the retrieval of documents into the LLM context toprovide more accurate and relevant responses. Existing RAG solutions do notfocus on queries that may require fetching multiple documents withsubstantially different contents. Such queries occur frequently but arechallenging because the embeddings of these documents may be distant in theembedding space making it hard to retrieve them all. This paper introducesMulti-Head RAG MRAG a novel scheme designed to address this gap with asimple yet powerful idea: leveraging activations of Transformers multi-headattention layer instead of the decoder layer as keys for fetchingmulti-aspect documents. The driving motivation is that different attentionheads can learn to capture different data aspects. Harnessing the correspondingactivations results in embeddings that represent various facets of data itemsand queries improving the retrieval accuracy for complex queries. We providean evaluation methodology and metrics synthetic datasets and real-world usecases to demonstrate MRAGs effectiveness showing improvements of up to 20 inrelevance over standard RAG baselines. MRAG can be seamlessly integrated withexisting RAG frameworks and benchmarking tools like RAGAS as well as differentclasses of data stores.</p>
                <p>Last Updated: 2024-06-07 16:59:38 UTC</p>
                <button class="interpret-button" data-id="2406.05085v1">Interpret</button>
                <div id="interpretation-2406.05085v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>On Ambiguity and the Expressive Function of Law: The Role of Pragmatics in Smart Legal Ecosystems</h3>
                <p>Authors: Pompeu Casanovas</p>
                <p><a href="http://arxiv.org/abs/2406.05084v1">Link to paper</a></p>
                <p>This is a long paper an essay on ambiguity pragmatics legal ecosystemsand the expressive function of law. It is divided into two parts and fifteensections. The first part Pragmatics addresses ambiguity from the perspectiveof linguistic and cognitive pragmatics in the legal field. The second partComputing deals with this issue from the point of view of human-centereddesign and artificial intelligence specifically focusing on the notion andmodelling of rules and what it means to comply with the rules. This isnecessary for the scaffolding of smart legal ecosystems SLE. I will developthis subject with the example of the architecture information flows and smartecosystem of OPTIMAI an EU project of Industry 4.0 for zero-defectmanufacturing Optimizing Manufacturing Processes through ArtificialIntelligence and Virtualization.</p>
                <p>Last Updated: 2024-06-07 16:58:15 UTC</p>
                <button class="interpret-button" data-id="2406.05084v1">Interpret</button>
                <div id="interpretation-2406.05084v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>I2EDL: Interactive Instruction Error Detection and Localization</h3>
                <p>Authors: Francesco TaioliStefano RosaAlberto CastelliniLorenzo NataleAlessio Del BueAlessandro FarinelliMarco CristaniYiming Wang</p>
                <p><a href="http://arxiv.org/abs/2406.05080v1">Link to paper</a></p>
                <p>In the Vision-and-Language Navigation in Continuous Environments VLN-CEtask the human user guides an autonomous agent to reach a target goal via aseries of low-level actions following a textual instruction in naturallanguage. However most existing methods do not address the likely case whereusers may make mistakes when providing such instruction e.g. turn leftinstead of turn right. In this work we address a novel task of InteractiveVLN in Continuous Environments IVLN-CE which allows the agent to interactwith the user during the VLN-CE navigation to verify any doubts regarding theinstruction errors. We propose an Interactive Instruction Error Detector andLocalizer I2EDL that triggers the user-agent interaction upon the detectionof instruction errors during the navigation. We leverage a pre-trained moduleto detect instruction errors and pinpoint them in the instruction bycross-referencing the textual input and past observations. In such way theagent is able to query the user for a timely correction without demanding theusers cognitive load as we locate the probable errors to a precise part ofthe instruction. We evaluate the proposed I2EDL on a dataset of instructionscontaining errors and further devise a novel metric the Success weighted byInteraction Number SIN to reflect both the navigation performance and theinteraction effectiveness. We show how the proposed method can ask focusedrequests for corrections to the user which in turn increases the navigationsuccess while minimizing the interactions.</p>
                <p>Last Updated: 2024-06-07 16:52:57 UTC</p>
                <button class="interpret-button" data-id="2406.05080v1">Interpret</button>
                <div id="interpretation-2406.05080v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Linearization Turns Neural Operators into Function-Valued Gaussian Processes</h3>
                <p>Authors: Emilia MagnaniMarvin PförtnerTobias WeberPhilipp Hennig</p>
                <p><a href="http://arxiv.org/abs/2406.05072v1">Link to paper</a></p>
                <p>Modeling dynamical systems e.g. in climate and engineering sciences oftennecessitates solving partial differential equations. Neural operators are deepneural networks designed to learn nontrivial solution operators of suchdifferential equations from data. As for all statistical models thepredictions of these models are imperfect and exhibit errors. Such errors areparticularly difficult to spot in the complex nonlinear behaviour of dynamicalsystems. We introduce a new framework for approximate Bayesian uncertaintyquantification in neural operators using function-valued Gaussian processes.Our approach can be interpreted as a probabilistic analogue of the concept ofcurrying from functional programming and provides a practical yet theoreticallysound way to apply the linearized Laplace approximation to neural operators. Ina case study on Fourier neural operators we show that even for a discretizedinput our method yields a Gaussian closure--a structured Gaussian processposterior capturing the uncertainty in the output function of the neuraloperator which can be evaluated at an arbitrary set of points. The method addsminimal prediction overhead can be applied post-hoc without retraining theneural operator and scales to large models and datasets. We showcase theefficacy of our approach through applications to different types of partialdifferential equations.</p>
                <p>Last Updated: 2024-06-07 16:43:54 UTC</p>
                <button class="interpret-button" data-id="2406.05072v1">Interpret</button>
                <div id="interpretation-2406.05072v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Progressive Entropic Optimal Transport Solvers</h3>
                <p>Authors: Parnian KassraieAram-Alexandre PooladianMichal KleinJames ThorntonJonathan Niles-WeedMarco Cuturi</p>
                <p><a href="http://arxiv.org/abs/2406.05061v1">Link to paper</a></p>
                <p>Optimal transport OT has profoundly impacted machine learning by providingtheoretical and computational tools to realign datasets. In this context giventwo large point clouds of sizes n and m in mathbbRd entropic OTEOT solvers have emerged as the most reliable tool to either solve theKantorovich problem and output a ntimes m coupling matrix or to solve theMonge problem and learn a vector-valued push-forward map. While the robustnessof EOT couplings/maps makes them a go-to choice in practical applications EOTsolvers remain difficult to tune because of a small but influential set ofhyperparameters notably the omnipresent entropic regularization strengthvarepsilon. Setting varepsilon can be difficult as it simultaneouslyimpacts various performance metrics such as compute speed statisticalperformance generalization and bias. In this work we propose a new class ofEOT solvers ProgOT that can estimate both plans and transport maps. We takeadvantage of several opportunities to optimize the computation of EOT solutionsby dividing mass displacement using a time discretization borrowinginspiration from dynamic OT formulations and conquering each of these stepsusing EOT with properly scheduled parameters. We provide experimental evidencedemonstrating that ProgOT is a faster and more robust alternative to standardsolvers when computing couplings at large scales even outperforming neuralnetwork-based approaches. We also prove statistical consistency of our approachfor estimating optimal transport maps.</p>
                <p>Last Updated: 2024-06-07 16:33:08 UTC</p>
                <button class="interpret-button" data-id="2406.05061v1">Interpret</button>
                <div id="interpretation-2406.05061v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Root Cause Analysis of Outliers with Missing Structural Knowledge</h3>
                <p>Authors: Nastaran OkatiSergio Hernan Garrido MejiaWilliam Roy OrchardPatrick BlöbaumDominik Janzing</p>
                <p><a href="http://arxiv.org/abs/2406.05014v1">Link to paper</a></p>
                <p>Recent work conceptualized root cause analysis RCA of anomalies viaquantitative contribution analysis using causal counterfactuals in structuralcausal models SCMs. The framework comes with three practical challenges: 1it requires the causal directed acyclic graph DAG together with an SCM 2it is statistically ill-posed since it probes regression models in regions oflow probability density 3 it relies on Shapley values which arecomputationally expensive to find.  In this paper we propose simplified efficient methods of root causeanalysis when the task is to identify a unique root cause instead ofquantitative contribution analysis. Our proposed methods run in linear order ofSCM nodes and they require only the causal DAG without counterfactuals.Furthermore for those use cases where the causal DAG is unknown we justifythe heuristic of identifying root causes as the variables with the highestanomaly score.</p>
                <p>Last Updated: 2024-06-07 15:24:38 UTC</p>
                <button class="interpret-button" data-id="2406.05014v1">Interpret</button>
                <div id="interpretation-2406.05014v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The Price of Implicit Bias in Adversarially Robust Generalization</h3>
                <p>Authors: Nikolaos TsilivisNatalie FrankNathan SrebroJulia Kempe</p>
                <p><a href="http://arxiv.org/abs/2406.04981v1">Link to paper</a></p>
                <p>We study the implicit bias of optimization in robust empirical riskminimization robust ERM and its connection with robust generalization. Inclassification settings under adversarial perturbations with linear models westudy what type of regularization should ideally be applied for a givenperturbation set to improve robust generalization. We then show that theimplicit bias of optimization in robust ERM can significantly affect therobustness of the model and identify two ways this can happen either throughthe optimization algorithm or the architecture. We verify our predictions insimulations with synthetic data and experimentally study the importance ofimplicit bias in robust ERM with deep neural networks.</p>
                <p>Last Updated: 2024-06-07 14:44:37 UTC</p>
                <button class="interpret-button" data-id="2406.04981v1">Interpret</button>
                <div id="interpretation-2406.04981v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Multi-View Stochastic Block Models</h3>
                <p>Authors: Vincent Cohen-AddadTommaso d'OrsiSilvio LattanziRajai Nasser</p>
                <p><a href="http://arxiv.org/abs/2406.04860v1">Link to paper</a></p>
                <p>Graph clustering is a central topic in unsupervised learning with a multitudeof practical applications. In recent years multi-view graph clustering hasgained a lot of attention for its applicability to real-world instances whereone has access to multiple data sources. In this paper we formalize a newfamily of models called textitmulti-view stochastic block models thatcaptures this setting.  For this model we first study efficient algorithms that naively work on theunion of multiple graphs. Then we introduce a new efficient algorithm thatprovably outperforms previous approaches by analyzing the structure of eachgraph separately. Furthermore we complement our results with aninformation-theoretic lower bound studying the limits of what can be done inthis model. Finally we corroborate our results with experimental evaluations.</p>
                <p>Last Updated: 2024-06-07 11:45:31 UTC</p>
                <button class="interpret-button" data-id="2406.04860v1">Interpret</button>
                <div id="interpretation-2406.04860v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>3D-GRAND: Towards Better Grounding and Less Hallucination for 3D-LLMs</h3>
                <p>Authors: Jianing YangXuweiyi ChenNikhil MadaanMadhavan IyengarShengyi QianDavid F. FouheyJoyce Chai</p>
                <p><a href="http://arxiv.org/abs/2406.05132v1">Link to paper</a></p>
                <p>The integration of language and 3D perception is crucial for developingembodied agents and robots that comprehend and interact with the physicalworld. While large language models LLMs have demonstrated impressive languageunderstanding and generation capabilities their adaptation to 3D environments3D-LLMs remains in its early stages. A primary challenge is the absence oflarge-scale datasets that provide dense grounding between language and 3Dscenes. In this paper we introduce 3D-GRAND a pioneering large-scale datasetcomprising 40087 household scenes paired with 6.2 million densely-groundedscene-language instructions. Our results show that instruction tuning with3D-GRAND significantly enhances grounding capabilities and reduceshallucinations in 3D-LLMs. As part of our contributions we propose acomprehensive benchmark 3D-POPE to systematically evaluate hallucination in3D-LLMs enabling fair comparisons among future models. Our experimentshighlight a scaling effect between dataset size and 3D-LLM performanceemphasizing the critical role of large-scale 3D-text datasets in advancingembodied AI research. Notably our results demonstrate early signals foreffective sim-to-real transfer indicating that models trained on largesynthetic data can perform well on real-world 3D scans. Through 3D-GRAND and3D-POPE we aim to equip the embodied AI community with essential resources andinsights setting the stage for more reliable and better-grounded 3D-LLMs.Project website: https://3d-grand.github.io</p>
                <p>Last Updated: 2024-06-07 17:59:59 UTC</p>
                <button class="interpret-button" data-id="2406.05132v1">Interpret</button>
                <div id="interpretation-2406.05132v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>DVOS: Self-Supervised Dense-Pattern Video Object Segmentation</h3>
                <p>Authors: Keyhan NajafianFarhad MalekiIan StavnessLingling Jin</p>
                <p><a href="http://arxiv.org/abs/2406.05131v1">Link to paper</a></p>
                <p>Video object segmentation approaches primarily rely on large-scalepixel-accurate human-annotated datasets for model development. In Dense VideoObject Segmentation DVOS scenarios each video frame encompasses hundreds ofsmall dense and partially occluded objects. Accordingly the labor-intensivemanual annotation of even a single frame often takes hours which hinders thedevelopment of DVOS for many applications. Furthermore in videos with densepatterns following a large number of objects that move in different directionsposes additional challenges. To address these challenges we proposed asemi-self-supervised spatiotemporal approach for DVOS utilizing adiffusion-based method through multi-task learning. Emulating real videosoptical flow and simulating their motion we developed a methodology tosynthesize computationally annotated videos that can be used for training DVOSmodels The model performance was further improved by utilizing weakly labeledcomputationally generated but imprecise data. To demonstrate the utility andefficacy of the proposed approach we developed DVOS models for wheat headsegmentation of handheld and drone-captured videos capturing wheat crops infields of different locations across various growth stages spanning fromheading to maturity. Despite using only a few manually annotated video framesthe proposed approach yielded high-performing models achieving a Dice score of0.82 when tested on a drone-captured external test set. While we showed theefficacy of the proposed approach for wheat head segmentation its applicationcan be extended to other crops or DVOS in other domains such as crowd analysisor microscopic image analysis.</p>
                <p>Last Updated: 2024-06-07 17:58:36 UTC</p>
                <button class="interpret-button" data-id="2406.05131v1">Interpret</button>
                <div id="interpretation-2406.05131v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>PatchSVD: A Non-uniform SVD-based Image Compression Algorithm</h3>
                <p>Authors: Zahra GolpayeganiNizar Bouguila</p>
                <p><a href="http://dx.doi.org/10.5220/0012488500003654">Link to paper</a></p>
                <p>Storing data is particularly a challenge when dealing with image data whichoften involves large file sizes due to the high resolution and complexity ofimages. Efficient image compression algorithms are crucial to better managedata storage costs. In this paper we propose a novel region-based lossy imagecompression technique called PatchSVD based on the Singular ValueDecomposition SVD algorithm. We show through experiments that PatchSVDoutperforms SVD-based image compression with respect to three popular imagecompression metrics. Moreover we compare PatchSVD compression artifacts withthose of Joint Photographic Experts Group JPEG and SVD-based imagecompression and illustrate some cases where PatchSVD compression artifacts arepreferable compared to JPEG and SVD artifacts.</p>
                <p>Last Updated: 2024-06-07 17:57:40 UTC</p>
                <button class="interpret-button" data-id="2406.05129v1">Interpret</button>
                <div id="interpretation-2406.05129v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Towards Semantic Equivalence of Tokenization in Multimodal LLM</h3>
                <p>Authors: Shengqiong WuHao FeiXiangtai LiJiayi JiHanwang ZhangTat-Seng ChuaShuicheng Yan</p>
                <p><a href="http://arxiv.org/abs/2406.05127v1">Link to paper</a></p>
                <p>Multimodal Large Language Models MLLMs have demonstrated exceptionalcapabilities in processing vision-language tasks. One of the crux of MLLMs liesin vision tokenization which involves efficiently transforming input visualsignals into feature representations that are most beneficial for LLMs.However existing vision tokenizers essential for semantic alignment betweenvision and language remain problematic. Existing methods aggressively fragmentvisual input corrupting the visual semantic integrity. To address this thispaper proposes a novel dynamic Semantic-Equivalent Vision Tokenizer SeTokwhich groups visual features into semantic units via a dynamic clusteringalgorithm flexibly determining the number of tokens based on image complexity.The resulting vision tokens effectively preserve semantic integrity and captureboth low-frequency and high-frequency visual features. The proposed MLLMSetokim equipped with SeTok significantly demonstrates superior performanceacross various tasks as evidenced by our experimental results. The projectpage is at https://chocowu.github.io/SeTok-web/.</p>
                <p>Last Updated: 2024-06-07 17:55:43 UTC</p>
                <button class="interpret-button" data-id="2406.05127v1">Interpret</button>
                <div id="interpretation-2406.05127v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Energy Propagation in Scattering Convolution Networks Can Be Arbitrarily Slow</h3>
                <p>Authors: Hartmut FührMax Getter</p>
                <p><a href="http://arxiv.org/abs/2406.05121v1">Link to paper</a></p>
                <p>We analyze energy decay for deep convolutional neural networks employed asfeature extractors such as Mallats wavelet scattering transform. Fortime-frequency scattering transforms based on Gabor filters it has beenestablished that energy decay is exponential for arbitrary square-integrableinput signals. Our main results allow to prove that this is wrong for waveletscattering in arbitrary dimensions. In this setting the energy decay of thescattering transform acting on a generic square-integrable signal turns out tobe arbitrarily slow. The fact that this behavior holds for dense subsets ofL2mathbbRd emphasizes that fast energy decay is generally not a stableproperty of signals.  We complement these findings with positive results allowing to conclude fastup to exponential energy decay for generalized Sobolev spaces that aretailored to the frequency localization of the underlying filter bank.  Both negative and positive results highlight that energy decay in scatteringnetworks critically depends on the interplay of the respective frequencylocalizations of the signal on the one hand and of the employed filters on theother.</p>
                <p>Last Updated: 2024-06-07 17:52:23 UTC</p>
                <button class="interpret-button" data-id="2406.05121v1">Interpret</button>
                <div id="interpretation-2406.05121v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Categorizing Sources of Information for Explanations in Conversational AI Systems for Older Adults Aging in Place</h3>
                <p>Authors: Niharika MathurTamara ZubatiyElizabeth Mynatt</p>
                <p><a href="http://arxiv.org/abs/2406.05111v1">Link to paper</a></p>
                <p>As the permeability of AI systems in interpersonal domains like the homeexpands their technical capabilities of generating explanations are requiredto be aligned with user expectations for transparency and reasoning. This paperpresents insights from our ongoing work in understanding the effectiveness ofexplanations in Conversational AI systems for older adults aging in place andtheir family caregivers. We argue that in collaborative and multi-userenvironments like the home AI systems will make recommendations based on ahost of information sources to generate explanations. These sources may be moreor less salient based on user mental models of the system and the specifictask. We highlight the need for cross technological collaboration between AIsystems and other available sources of information in the home to generatemultiple explanations for a single user query. Through example scenarios in acaregiving home setting this paper provides an initial framework forcategorizing these sources and informing a potential design space for AIexplanations surrounding everyday tasks in the home.</p>
                <p>Last Updated: 2024-06-07 17:42:41 UTC</p>
                <button class="interpret-button" data-id="2406.05111v1">Interpret</button>
                <div id="interpretation-2406.05111v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Classification Metrics for Image Explanations: Towards Building Reliable XAI-Evaluations</h3>
                <p>Authors: Benjamin FreszLena LörcherMarco Huber</p>
                <p><a href="http://dx.doi.org/10.1145/3630106.3658537">Link to paper</a></p>
                <p>Decision processes of computer vision models - especially deep neuralnetworks - are opaque in nature meaning that these decisions cannot beunderstood by humans. Thus over the last years many methods to providehuman-understandable explanations have been proposed. For image classificationthe most common group are saliency methods which provide super-pixelwisefeature attribution scores for input images. But their evaluation still poses aproblem as their results cannot be simply compared to the unknown groundtruth. To overcome this a slew of different proxy metrics have been definedwhich are - as the explainability methods themselves - often built on intuitionand thus are possibly unreliable. In this paper new evaluation metrics forsaliency methods are developed and common saliency methods are benchmarked onImageNet. In addition a scheme for reliability evaluation of such metrics isproposed that is based on concepts from psychometric testing. The used code canbe found athttps://github.com/lelo204/ClassificationMetricsForImageExplanations .</p>
                <p>Last Updated: 2024-06-07 16:37:50 UTC</p>
                <button class="interpret-button" data-id="2406.05068v1">Interpret</button>
                <div id="interpretation-2406.05068v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Designs for Enabling Collaboration in Human-Machine Teaming via Interactive and Explainable Systems</h3>
                <p>Authors: Rohan PalejaMichael MunjeKimberlee ChangReed JensenMatthew Gombolay</p>
                <p><a href="http://arxiv.org/abs/2406.05003v1">Link to paper</a></p>
                <p>Collaborative robots and machine learning-based virtual agents areincreasingly entering the human workspace with the aim of increasingproductivity and enhancing safety. Despite this we show in a ubiquitousexperimental domain Overcooked-AI that state-of-the-art techniques forhuman-machine teaming HMT which rely on imitation or reinforcement learningare brittle and result in a machine agent that aims to decouple the machine andhumans actions to act independently rather than in a synergistic fashion. Toremedy this deficiency we develop HMT approaches that enable iterativemixed-initiative team development allowing end-users to interactively reprograminterpretable AI teammates. Our 50-subject study provides several findings thatwe summarize into guidelines. While all approaches underperform a simplecollaborative heuristic a critical negative result for learning-basedmethods we find that white-box approaches supported by interactivemodification can lead to significant team development outperforming white-boxapproaches alone and black-box approaches are easier to train and result inbetter HMT performance highlighting a tradeoff between explainability andinteractivity versus ease-of-training. Together these findings present threeimportant directions: 1 Improving the ability to generate collaborative agentswith white-box models 2 Better learning methods to facilitate collaborationrather than individualized coordination and 3 Mixed-initiative interfacesthat enable users who may vary in ability to improve collaboration.</p>
                <p>Last Updated: 2024-06-07 15:17:06 UTC</p>
                <button class="interpret-button" data-id="2406.05003v1">Interpret</button>
                <div id="interpretation-2406.05003v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Expansion of situations theory for exploring shared awareness in human-intelligent autonomous systems</h3>
                <p>Authors: Scott A. HumrMustafa CananMustafa Demir</p>
                <p><a href="http://dx.doi.org/10.1504/IJSSE.2025.10058953">Link to paper</a></p>
                <p>Intelligent autonomous systems are part of a system of systems that interactwith other agents to accomplish tasks in complex environments. Howeverintelligent autonomous systems integrated system of systems add additionallayers of complexity based on their limited cognitive processes specificallyshared situation awareness that allows a team to respond to novel tasks.Intelligent autonomous systems lack of shared situation awareness adverselyinfluences team effectiveness in complex task environments such as militarycommand-and-control. A complementary approach of shared situation awarenesscalled situations theory is beneficial for understanding the relationshipbetween system of systems shared situation awareness and effectiveness. Thecurrent study elucidates a conceptual discussion on situations theory toinvestigate the development of an system of systems shared situationalawareness when humans team with intelligent autonomous system agents. To groundthe discussion the reviewed studies expanded situations theory within thecontext of a system of systems that result in three major conjectures that canbe beneficial to the design and development of future systems of systems.</p>
                <p>Last Updated: 2024-06-07 14:21:01 UTC</p>
                <button class="interpret-button" data-id="2406.04956v1">Interpret</button>
                <div id="interpretation-2406.04956v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Modular Framework for Flexible Planning in Human-Robot Collaboration</h3>
                <p>Authors: Valerio BelcaminoMariya KilinaLinda LastricoAlessandro CarfìFulvio Mastrogiovanni</p>
                <p><a href="http://arxiv.org/abs/2406.04907v1">Link to paper</a></p>
                <p>This paper presents a comprehensive framework to enhance Human-RobotCollaboration HRC in real-world scenarios. It introduces a formalism to modelarticulated tasks requiring cooperation between two agents through a smallerset of primitives. Our implementation leverages Hierarchical Task NetworksHTN planning and a modular multisensory perception pipeline which includesvision human activity recognition and tactile sensing. To showcase thesystems scalability we present an experimental scenario where two humansalternate in collaborating with a Baxter robot to assemble four pieces offurniture with variable components. This integration highlights promisingadvancements in HRC suggesting a scalable approach for complex cooperativetasks across diverse applications.</p>
                <p>Last Updated: 2024-06-07 12:58:38 UTC</p>
                <button class="interpret-button" data-id="2406.04907v1">Interpret</button>
                <div id="interpretation-2406.04907v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>3D-GRAND: Towards Better Grounding and Less Hallucination for 3D-LLMs</h3>
                <p>Authors: Jianing YangXuweiyi ChenNikhil MadaanMadhavan IyengarShengyi QianDavid F. FouheyJoyce Chai</p>
                <p><a href="http://arxiv.org/abs/2406.05132v1">Link to paper</a></p>
                <p>The integration of language and 3D perception is crucial for developingembodied agents and robots that comprehend and interact with the physicalworld. While large language models LLMs have demonstrated impressive languageunderstanding and generation capabilities their adaptation to 3D environments3D-LLMs remains in its early stages. A primary challenge is the absence oflarge-scale datasets that provide dense grounding between language and 3Dscenes. In this paper we introduce 3D-GRAND a pioneering large-scale datasetcomprising 40087 household scenes paired with 6.2 million densely-groundedscene-language instructions. Our results show that instruction tuning with3D-GRAND significantly enhances grounding capabilities and reduceshallucinations in 3D-LLMs. As part of our contributions we propose acomprehensive benchmark 3D-POPE to systematically evaluate hallucination in3D-LLMs enabling fair comparisons among future models. Our experimentshighlight a scaling effect between dataset size and 3D-LLM performanceemphasizing the critical role of large-scale 3D-text datasets in advancingembodied AI research. Notably our results demonstrate early signals foreffective sim-to-real transfer indicating that models trained on largesynthetic data can perform well on real-world 3D scans. Through 3D-GRAND and3D-POPE we aim to equip the embodied AI community with essential resources andinsights setting the stage for more reliable and better-grounded 3D-LLMs.Project website: https://3d-grand.github.io</p>
                <p>Last Updated: 2024-06-07 17:59:59 UTC</p>
                <button class="interpret-button" data-id="2406.05132v1">Interpret</button>
                <div id="interpretation-2406.05132v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LLavaGuard: VLM-based Safeguards for Vision Dataset Curation and Safety Assessment</h3>
                <p>Authors: Lukas HelffFelix FriedrichManuel BrackKristian KerstingPatrick Schramowski</p>
                <p><a href="http://arxiv.org/abs/2406.05113v1">Link to paper</a></p>
                <p>We introduce LlavaGuard a family of VLM-based safeguard models offering aversatile framework for evaluating the safety compliance of visual content.Specifically we designed LlavaGuard for dataset annotation and generativemodel safeguarding. To this end we collected and annotated a high-qualityvisual dataset incorporating a broad safety taxonomy which we use to tune VLMson context-aware safety risks. As a key innovation LlavaGuards new responsescontain comprehensive information including a safety rating the violatedsafety categories and an in-depth rationale. Further our introducedcustomizable taxonomy categories enable the context-specific alignment ofLlavaGuard to various scenarios. Our experiments highlight the capabilities ofLlavaGuard in complex and real-world applications. We provide checkpointsranging from 7B to 34B parameters demonstrating state-of-the-art performancewith even the smallest models outperforming baselines like GPT-4. We make ourdataset and model weights publicly available and invite further research toaddress the diverse needs of communities and contexts.</p>
                <p>Last Updated: 2024-06-07 17:44:32 UTC</p>
                <button class="interpret-button" data-id="2406.05113v1">Interpret</button>
                <div id="interpretation-2406.05113v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Provably Better Explanations with Optimized Aggregation of Feature Attributions</h3>
                <p>Authors: Thomas DeckerAnanta R. BhattaraiJindong GuVolker TrespFlorian Buettner</p>
                <p><a href="http://arxiv.org/abs/2406.05090v1">Link to paper</a></p>
                <p>Using feature attributions for post-hoc explanations is a common practice tounderstand and verify the predictions of opaque machine learning models.Despite the numerous techniques available individual methods often produceinconsistent and unstable results putting their overall reliability intoquestion. In this work we aim to systematically improve the quality of featureattributions by combining multiple explanations across distinct methods ortheir variations. For this purpose we propose a novel approach to deriveoptimal convex combinations of feature attributions that yield provableimprovements of desired quality criteria such as robustness or faithfulness tothe model behavior. Through extensive experiments involving various modelarchitectures and popular feature attribution techniques we demonstrate thatour combination strategy consistently outperforms individual methods andexisting baselines.</p>
                <p>Last Updated: 2024-06-07 17:03:43 UTC</p>
                <button class="interpret-button" data-id="2406.05090v1">Interpret</button>
                <div id="interpretation-2406.05090v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Robust Reward Design for Markov Decision Processes</h3>
                <p>Authors: Shuo WuHaoxiang MaJie FuShuo Han</p>
                <p><a href="http://arxiv.org/abs/2406.05086v1">Link to paper</a></p>
                <p>The problem of reward design examines the interaction between a leader and afollower where the leader aims to shape the followers behavior to maximizethe leaders payoff by modifying the followers reward function. Currentapproaches to reward design rely on an accurate model of how the followerresponds to reward modifications which can be sensitive to modelinginaccuracies. To address this issue of sensitivity we present a solution thatoffers robustness against uncertainties in modeling the follower including 1how the follower breaks ties in the presence of nonunique best responses 2inexact knowledge of how the follower perceives reward modifications and 3bounded rationality of the follower. Our robust solution is guaranteed to existunder mild conditions and can be obtained numerically by solving amixed-integer linear program. Numerical experiments on multiple test casesdemonstrate that our solution improves robustness compared to the standardapproach without incurring significant additional computing costs.</p>
                <p>Last Updated: 2024-06-07 17:01:45 UTC</p>
                <button class="interpret-button" data-id="2406.05086v1">Interpret</button>
                <div id="interpretation-2406.05086v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Multi-Head RAG: Solving Multi-Aspect Problems with LLMs</h3>
                <p>Authors: Maciej BestaAles KubicekRoman NiggliRobert GerstenbergerLucas WeitzendorfMingyuan ChiPatrick IffJoanna GajdaPiotr NyczykJürgen MüllerHubert NiewiadomskiMarcin ChrapekMichał PodstawskiTorsten Hoefler</p>
                <p><a href="http://arxiv.org/abs/2406.05085v1">Link to paper</a></p>
                <p>Retrieval Augmented Generation RAG enhances the abilities of Large LanguageModels LLMs by enabling the retrieval of documents into the LLM context toprovide more accurate and relevant responses. Existing RAG solutions do notfocus on queries that may require fetching multiple documents withsubstantially different contents. Such queries occur frequently but arechallenging because the embeddings of these documents may be distant in theembedding space making it hard to retrieve them all. This paper introducesMulti-Head RAG MRAG a novel scheme designed to address this gap with asimple yet powerful idea: leveraging activations of Transformers multi-headattention layer instead of the decoder layer as keys for fetchingmulti-aspect documents. The driving motivation is that different attentionheads can learn to capture different data aspects. Harnessing the correspondingactivations results in embeddings that represent various facets of data itemsand queries improving the retrieval accuracy for complex queries. We providean evaluation methodology and metrics synthetic datasets and real-world usecases to demonstrate MRAGs effectiveness showing improvements of up to 20 inrelevance over standard RAG baselines. MRAG can be seamlessly integrated withexisting RAG frameworks and benchmarking tools like RAGAS as well as differentclasses of data stores.</p>
                <p>Last Updated: 2024-06-07 16:59:38 UTC</p>
                <button class="interpret-button" data-id="2406.05085v1">Interpret</button>
                <div id="interpretation-2406.05085v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>Massively Multiagent Minigames for Training Generalist Agents</h3>
                <p>Authors: Kyoung Whan ChoeRyan SullivanJoseph Suárez</p>
                <p><a href="http://arxiv.org/abs/2406.05071v1">Link to paper</a></p>
                <p>We present Meta MMO a collection of many-agent minigames for use as areinforcement learning benchmark. Meta MMO is built on top of Neural MMO amassively multiagent environment that has been the subject of two previousNeurIPS competitions. Our work expands Neural MMO with several computationallyefficient minigames. We explore generalization across Meta MMO by learning toplay several minigames with a single set of weights. We release theenvironment baselines and training code under the MIT license. We hope thatMeta MMO will spur additional progress on Neural MMO and more generally willserve as a useful benchmark for many-agent generalization.</p>
                <p>Last Updated: 2024-06-07 16:41:05 UTC</p>
                <button class="interpret-button" data-id="2406.05071v1">Interpret</button>
                <div id="interpretation-2406.05071v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Online Frequency Scheduling by Learning Parallel Actions</h3>
                <p>Authors: Anastasios GiovanidisMathieu LeconteSabrine ArouaTor KvernvikDavid Sandberg</p>
                <p><a href="http://arxiv.org/abs/2406.05041v1">Link to paper</a></p>
                <p>Radio Resource Management is a challenging topic in future 6G networks wherenovel applications create strong competition among the users for the availableresources. In this work we consider the frequency scheduling problem in amulti-user MIMO system. Frequency resources need to be assigned to a set ofusers while allowing for concurrent transmissions in the same sub-band.Traditional methods are insufficient to cope with all the involved constraintsand uncertainties whereas reinforcement learning can directly learnnear-optimal solutions for such complex environments. However the schedulingproblem has an enormous action space accounting for all the combinations ofusers and sub-bands so out-of-the-box algorithms cannot be used directly. Inthis work we propose a scheduler based on action-branching over sub-bandswhich is a deep Q-learning architecture with parallel decision capabilities.The sub-bands learn correlated but local decision policies and altogether theyoptimize a global reward. To improve the scaling of the architecture with thenumber of sub-bands we propose variations Unibranch Graph NeuralNetwork-based that reduce the number of parameters to learn. The paralleldecision making of the proposed architecture allows to meet short inferencetime requirements in real systems. Furthermore the deep Q-learning approachpermits online fine-tuning after deployment to bridge the sim-to-real gap. Theproposed architectures are evaluated against relevant baselines from theliterature showing competitive performance and possibilities of onlineadaptation to evolving environments.</p>
                <p>Last Updated: 2024-06-07 16:14:51 UTC</p>
                <button class="interpret-button" data-id="2406.05041v1">Interpret</button>
                <div id="interpretation-2406.05041v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models</h3>
                <p>Authors: Rui YeRui GeXinyu ZhuJingyi ChaiYaxin DuYang LiuYanfeng WangSiheng Chen</p>
                <p><a href="http://arxiv.org/abs/2406.04845v1">Link to paper</a></p>
                <p>Federated learning has enabled multiple parties to collaboratively trainlarge language models without directly sharing their data FedLLM. Followingthis training paradigm the community has put massive efforts from diverseaspects including framework performance and privacy. However an unpleasantfact is that there are currently no realistic datasets and benchmarks forFedLLM and previous works all rely on artificially constructed datasetsfailing to capture properties in real-world scenarios. Addressing this wepropose FedLLM-Bench which involves 8 training methods 4 training datasetsand 6 evaluation metrics to offer a comprehensive testbed for the FedLLMcommunity. FedLLM-Bench encompasses three datasets e.g. user-annotatedmultilingual dataset for federated instruction tuning and one dataset e.g.user-annotated preference dataset for federated preference alignment whosescale of client number ranges from 38 to 747. Our datasets incorporate severalrepresentative diversities: language quality quantity instruction lengthembedding and preference capturing properties in real-world scenarios. Basedon FedLLM-Bench we conduct experiments on all datasets to benchmark existingFL methods and provide empirical insights e.g. multilingual collaboration.We believe that our FedLLM-Bench can benefit the FedLLM community by reducingrequired efforts providing a practical testbed and promoting faircomparisons. Code and datasets are available athttps://github.com/rui-ye/FedLLM-Bench.</p>
                <p>Last Updated: 2024-06-07 11:19:30 UTC</p>
                <button class="interpret-button" data-id="2406.04845v1">Interpret</button>
                <div id="interpretation-2406.04845v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Software Engineering for Collective Cyber-Physical Ecosystems</h3>
                <p>Authors: Roberto CasadeiGianluca AguzziGiorgio AudritoFerruccio DamianiDanilo PianiniGiordano ScarsoGianluca TortaMirko Viroli</p>
                <p><a href="http://arxiv.org/abs/2406.04780v1">Link to paper</a></p>
                <p>Todays distributed and pervasive computing addresses large-scalecyber-physical ecosystems characterised by dense and large networks of devicescapable of computation communication and interaction with the environment andpeople. While most research focusses on treating these systems as compositesi.e. heterogeneous functional complexes recent developments in fields suchas self-organising systems and swarm robotics have opened up a complementaryperspective: treating systems as collectives i.e. uniform collaborativeand self-organising groups of entities. This article explores the motivationsstate of the art and implications of this collective computing paradigm insoftware engineering discusses its peculiar challenges and outlines a pathfor future research touching on aspects such as macroprogramming collectiveintelligence self-adaptive middleware learning synthesis andexperimentation of collective behaviour.</p>
                <p>Last Updated: 2024-06-07 09:28:22 UTC</p>
                <button class="interpret-button" data-id="2406.04780v1">Interpret</button>
                <div id="interpretation-2406.04780v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Quantifying Misalignment Between Agents</h3>
                <p>Authors: Aidan KieransAvijit GhoshHananel HazanShiri Dori-Hacohen</p>
                <p><a href="http://arxiv.org/abs/2406.04231v1">Link to paper</a></p>
                <p>Growing concerns about the AI alignment problem have emerged in recent yearswith previous work focusing mainly on 1 qualitative descriptions of thealignment problem 2 attempting to align AI actions with human interests byfocusing on value specification and learning and/or 3 focusing on a singleagent or on humanity as a singular unit. Recent work in sociotechnical AIalignment has made some progress in defining alignment inclusively but thefield as a whole still lacks a systematic understanding of how to specifydescribe and analyze misalignment among entities which may include individualhumans AI agents and complex compositional entities such as corporationsnation-states and so forth. Previous work on controversy in computationalsocial science offers a mathematical model of contention among populations ofhumans. In this paper we adapt this contention model to the alignmentproblem and show how misalignment can vary depending on the population ofagents human or otherwise being observed the domain in question and theagents probability-weighted preferences between possible outcomes. Our modeldeparts from value specification approaches and focuses instead on the morassof complex interlocking sometimes contradictory goals that agents may have inpractice. We apply our model by analyzing several case studies ranging fromsocial media moderation to autonomous vehicle behavior. By applying our modelwith appropriately representative value data AI engineers can ensure thattheir systems learn values maximally aligned with diverse human interests.</p>
                <p>Last Updated: 2024-06-06 16:31:22 UTC</p>
                <button class="interpret-button" data-id="2406.04231v1">Interpret</button>
                <div id="interpretation-2406.04231v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>3D-GRAND: Towards Better Grounding and Less Hallucination for 3D-LLMs</h3>
                <p>Authors: Jianing YangXuweiyi ChenNikhil MadaanMadhavan IyengarShengyi QianDavid F. FouheyJoyce Chai</p>
                <p><a href="http://arxiv.org/abs/2406.05132v1">Link to paper</a></p>
                <p>The integration of language and 3D perception is crucial for developingembodied agents and robots that comprehend and interact with the physicalworld. While large language models LLMs have demonstrated impressive languageunderstanding and generation capabilities their adaptation to 3D environments3D-LLMs remains in its early stages. A primary challenge is the absence oflarge-scale datasets that provide dense grounding between language and 3Dscenes. In this paper we introduce 3D-GRAND a pioneering large-scale datasetcomprising 40087 household scenes paired with 6.2 million densely-groundedscene-language instructions. Our results show that instruction tuning with3D-GRAND significantly enhances grounding capabilities and reduceshallucinations in 3D-LLMs. As part of our contributions we propose acomprehensive benchmark 3D-POPE to systematically evaluate hallucination in3D-LLMs enabling fair comparisons among future models. Our experimentshighlight a scaling effect between dataset size and 3D-LLM performanceemphasizing the critical role of large-scale 3D-text datasets in advancingembodied AI research. Notably our results demonstrate early signals foreffective sim-to-real transfer indicating that models trained on largesynthetic data can perform well on real-world 3D scans. Through 3D-GRAND and3D-POPE we aim to equip the embodied AI community with essential resources andinsights setting the stage for more reliable and better-grounded 3D-LLMs.Project website: https://3d-grand.github.io</p>
                <p>Last Updated: 2024-06-07 17:59:59 UTC</p>
                <button class="interpret-button" data-id="2406.05132v1">Interpret</button>
                <div id="interpretation-2406.05132v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Compositional Curvature Bounds for Deep Neural Networks</h3>
                <p>Authors: Taha EntesariSina SharifiMahyar Fazlyab</p>
                <p><a href="http://arxiv.org/abs/2406.05119v1">Link to paper</a></p>
                <p>A key challenge that threatens the widespread use of neural networks insafety-critical applications is their vulnerability to adversarial attacks. Inthis paper we study the second-order behavior of continuously differentiabledeep neural networks focusing on robustness against adversarial perturbations.First we provide a theoretical analysis of robustness and attack certificatesfor deep classifiers by leveraging local gradients and upper bounds on thesecond derivative curvature constant. Next we introduce a novel algorithm toanalytically compute provable upper bounds on the second derivative of neuralnetworks. This algorithm leverages the compositional structure of the model topropagate the curvature bound layer-by-layer giving rise to a scalable andmodular approach. The proposed bound can serve as a differentiable regularizerto control the curvature of neural networks during training thereby enhancingrobustness. Finally we demonstrate the efficacy of our method onclassification tasks using the MNIST and CIFAR-10 datasets.</p>
                <p>Last Updated: 2024-06-07 17:50:15 UTC</p>
                <button class="interpret-button" data-id="2406.05119v1">Interpret</button>
                <div id="interpretation-2406.05119v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The Expanding Scope of the Stability Gap: Unveiling its Presence in Joint Incremental Learning of Homogeneous Tasks</h3>
                <p>Authors: Sandesh KamathAlbin Soutif-CormeraisJoost van de WeijerBogdan Raducanu</p>
                <p><a href="http://arxiv.org/abs/2406.05114v1">Link to paper</a></p>
                <p>Recent research identified a temporary performance drop on previously learnedtasks when transitioning to a new one. This drop is called the stability gapand has great consequences for continual learning: it complicates the directemployment of continually learning since the worse-case performance attask-boundaries is dramatic it limits its potential as an energy-efficienttraining paradigm and finally the stability drop could result in a reducedfinal performance of the algorithm. In this paper we show that the stabilitygap also occurs when applying joint incremental training of homogeneous tasks.In this scenario the learner continues training on the same data distributionand has access to all data from previous tasks. In addition we show that inthis scenario there exists a low-loss linear path to the next minima but thatSGD optimization does not choose this path. We perform further analysisincluding a finer batch-wise analysis which could provide insights towardspotential solution directions.</p>
                <p>Last Updated: 2024-06-07 17:44:48 UTC</p>
                <button class="interpret-button" data-id="2406.05114v1">Interpret</button>
                <div id="interpretation-2406.05114v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LLavaGuard: VLM-based Safeguards for Vision Dataset Curation and Safety Assessment</h3>
                <p>Authors: Lukas HelffFelix FriedrichManuel BrackKristian KerstingPatrick Schramowski</p>
                <p><a href="http://arxiv.org/abs/2406.05113v1">Link to paper</a></p>
                <p>We introduce LlavaGuard a family of VLM-based safeguard models offering aversatile framework for evaluating the safety compliance of visual content.Specifically we designed LlavaGuard for dataset annotation and generativemodel safeguarding. To this end we collected and annotated a high-qualityvisual dataset incorporating a broad safety taxonomy which we use to tune VLMson context-aware safety risks. As a key innovation LlavaGuards new responsescontain comprehensive information including a safety rating the violatedsafety categories and an in-depth rationale. Further our introducedcustomizable taxonomy categories enable the context-specific alignment ofLlavaGuard to various scenarios. Our experiments highlight the capabilities ofLlavaGuard in complex and real-world applications. We provide checkpointsranging from 7B to 34B parameters demonstrating state-of-the-art performancewith even the smallest models outperforming baselines like GPT-4. We make ourdataset and model weights publicly available and invite further research toaddress the diverse needs of communities and contexts.</p>
                <p>Last Updated: 2024-06-07 17:44:32 UTC</p>
                <button class="interpret-button" data-id="2406.05113v1">Interpret</button>
                <div id="interpretation-2406.05113v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Large Generative Graph Models</h3>
                <p>Authors: Yu WangRyan A. RossiNamyong ParkHuiyuan ChenNesreen K. AhmedPuja TrivediFranck DernoncourtDanai KoutraTyler Derr</p>
                <p><a href="http://arxiv.org/abs/2406.05109v1">Link to paper</a></p>
                <p>Large Generative Models LGMs such as GPT Stable Diffusion Sora and Sunoare trained on a huge amount of language corpus images videos and audio thatare extremely diverse from numerous domains. This training paradigm overdiverse well-curated data lies at the heart of generating creative and sensiblecontent. However all previous graph generative models e.g. GraphRNN MDVAEMoFlow GDSS and DiGress have been trained only on one dataset each timewhich cannot replicate the revolutionary success achieved by LGMs in otherfields. To remedy this crucial gap we propose a new class of graph generativemodel called Large Graph Generative Model LGGM that is trained on a largecorpus of graphs over 5000 graphs from 13 different domains. We empiricallydemonstrate that the pre-trained LGGM has superior zero-shot generativecapability to existing graph generative models. Furthermore our pre-trainedLGGM can be easily fine-tuned with graphs from target domains and demonstrateeven better performance than those directly trained from scratch behaving as asolid starting point for real-world customization. Inspired by StableDiffusion we further equip LGGM with the capability to generate graphs giventext prompts Text-to-Graph such as the description of the network name anddomain i.e. The power-1138-bus graph represents a network of buses in apower distribution system. and network statistics i.e. The graph has alow average degree suitable for modeling social media interactions.. ThisText-to-Graph capability integrates the extensive world knowledge in theunderlying language model offering users fine-grained control of the generatedgraphs. We release the code the model checkpoint and the datasets athttps://lggm-lg.github.io/.</p>
                <p>Last Updated: 2024-06-07 17:41:47 UTC</p>
                <button class="interpret-button" data-id="2406.05109v1">Interpret</button>
                <div id="interpretation-2406.05109v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-06-10</p>
        </div>
    
        </div>
    </body>
    </html>
    