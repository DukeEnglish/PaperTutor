
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>VIRIS: Simulating indoor airborne transmission combining architectural design and people movement</h3>
                <p>Authors: Yidan XueWassim JabiThomas E. WoolleyKaterina Kaouri</p>
                <p><a href="http://arxiv.org/abs/2408.11772v1">Link to paper</a></p>
                <p>A Viral Infection Risk Indoor Simulator VIRIS has been developed to quicklyassess and compare mitigations for airborne disease spread. This agent-basedsimulator combines people movement in an indoor space viral transmissionmodelling and detailed architectural design and it is powered by topologicpyan open-source Python library. VIRIS generates very fast predictions of theviral concentration and the spatiotemporal infection risk for individuals asthey move through a given space. The simulator is validated with data from acourtroom superspreader event. A sensitivity study for unknown parameter valuesis also performed. We compare several non-pharmaceutical interventions NPIsissued in UK government guidance for two indoor settings: a care home and asupermarket. Additionally we have developed the user-friendly VIRIS web appthat allows quick exploration of diverse scenarios of interest andvisualisation allowing policymakers architects and space managers to easilydesign or assess infection risk in an indoor space.</p>
                <p>Last Updated: 2024-08-21 16:54:22 UTC</p>
                <button class="interpret-button" data-id="2408.11772v1">Interpret</button>
                <div id="interpretation-2408.11772v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Bayesian Optimization Framework for Efficient Fleet Design in Autonomous Multi-Robot Exploration</h3>
                <p>Authors: David Molina ConchaJiping LiHaoran YinKyeonghyeon ParkHyun-Rok LeeTaesik LeeDhruv SirohiChi-Guhn Lee</p>
                <p><a href="http://arxiv.org/abs/2408.11751v1">Link to paper</a></p>
                <p>This study addresses the challenge of fleet design optimization in thecontext of heterogeneous multi-robot fleets aiming to obtain feasible designsthat balance performance and costs. In the domain of autonomous multi-robotexploration reinforcement learning agents play a central role offeringadaptability to complex terrains and facilitating collaboration among robots.However modifying the fleet composition results in changes in the learnedbehavior and training multi-robot systems using multi-agent reinforcementlearning is expensive. Therefore an exhaustive evaluation of each potentialfleet design is infeasible. To tackle these hurdles we introduce BayesianOptimization for Fleet Design BOFD a framework leveraging multi-objectiveBayesian Optimization to explore fleets on the Pareto front of performance andcost while accounting for uncertainty in the design space. Moreover weestablish a sub-linear bound for cumulative regret supporting BOFDsrobustness and efficacy. Extensive benchmark experiments in synthetic andsimulated environments demonstrate the superiority of our framework overstate-of-the-art methods achieving efficient fleet designs with minimal fleetevaluations.</p>
                <p>Last Updated: 2024-08-21 16:22:51 UTC</p>
                <button class="interpret-button" data-id="2408.11751v1">Interpret</button>
                <div id="interpretation-2408.11751v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation</h3>
                <p>Authors: Patrick BenjaminAlessandro Abate</p>
                <p><a href="http://arxiv.org/abs/2408.11607v1">Link to paper</a></p>
                <p>Recent works have provided algorithms by which decentralised agents whichmay be connected via a communication network can learn equilibria inMean-Field Games from a single non-episodic run of the empirical system.However these algorithms are given for tabular settings: this computationallylimits the size of players observation space meaning that the algorithms arenot able to handle anything but small state spaces nor to generalise beyondpolicies depending on the ego players state to so-calledpopulation-dependent policies. We address this limitation by introducingfunction approximation to the existing setting drawing on the MunchausenOnline Mirror Descent method that has previously been employed only infinite-horizon episodic centralised settings. While this permits us toinclude the populations mean-field distribution in the observation for eachplayers policy it is arguably unrealistic to assume that decentralised agentswould have access to this global information: we therefore additionally providenew algorithms that allow agents to estimate the global empirical distributionbased on a local neighbourhood and to improve this estimate via communicationover a given network. Our experiments showcase how the communication networkallows decentralised agents to estimate the mean-field distribution forpopulation-dependent policies and that exchanging policy information helpsnetworked agents to outperform both independent and even centralised agents infunction-approximation settings by an even greater margin than in tabularsettings.</p>
                <p>Last Updated: 2024-08-21 13:32:46 UTC</p>
                <button class="interpret-button" data-id="2408.11607v1">Interpret</button>
                <div id="interpretation-2408.11607v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Subgoal-based Hierarchical Reinforcement Learning for Multi-Agent Collaboration</h3>
                <p>Authors: Cheng XuChangtian ZhangYuchen ShiRan WangShihong DuanYadong WanXiaotong Zhang</p>
                <p><a href="http://arxiv.org/abs/2408.11416v1">Link to paper</a></p>
                <p>Recent advancements in reinforcement learning have made significant impactsacross various domains yet they often struggle in complex multi-agentenvironments due to issues like algorithm instability low sampling efficiencyand the challenges of exploration and dimensionality explosion. Hierarchicalreinforcement learning HRL offers a structured approach to decompose complextasks into simpler sub-tasks which is promising for multi-agent settings. Thispaper advances the field by introducing a hierarchical architecture thatautonomously generates effective subgoals without explicit constraintsenhancing both flexibility and stability in training. We propose a dynamic goalgeneration strategy that adapts based on environmental changes. This methodsignificantly improves the adaptability and sample efficiency of the learningprocess. Furthermore we address the critical issue of credit assignment inmulti-agent systems by synergizing our hierarchical architecture with amodified QMIX network thus improving overall strategy coordination andefficiency. Comparative experiments with mainstream reinforcement learningalgorithms demonstrate the superior convergence speed and performance of ourapproach in both single-agent and multi-agent environments confirming itseffectiveness and flexibility in complex scenarios. Our code is open-sourcedat: urlhttps://github.com/SICC-Group/GMAH.</p>
                <p>Last Updated: 2024-08-21 08:22:11 UTC</p>
                <button class="interpret-button" data-id="2408.11416v1">Interpret</button>
                <div id="interpretation-2408.11416v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Deep Reinforcement Learning for Decentralized Multi-Robot Control: A DQN Approach to Robustness and Information Integration</h3>
                <p>Authors: Bin WuC Steve Suh</p>
                <p><a href="http://arxiv.org/abs/2408.11339v1">Link to paper</a></p>
                <p>The superiority of Multi-Robot Systems MRS in various complex environmentsis unquestionable. However in complex situations such as search and rescueenvironmental monitoring and automated production robots are often requiredto work collaboratively without a central control unit. This necessitates anefficient and robust decentralized control mechanism to process localinformation and guide the robots behavior. In this work we propose a newdecentralized controller design method that utilizes the Deep Q-Network DQNalgorithm from deep reinforcement learning aimed at improving the integrationof local information and robustness of multi-robot systems. The designedcontroller allows each robot to make decisions independently based on its localobservations while enhancing the overall systems collaborative efficiency andadaptability to dynamic environments through a shared learning mechanism.Through testing in simulated environments we have demonstrated theeffectiveness of this controller in improving task execution efficiencystrengthening system fault tolerance and enhancing adaptability to theenvironment. Furthermore we explored the impact of DQN parameter tuning onsystem performance providing insights for further optimization of thecontroller design. Our research not only showcases the potential application ofthe DQN algorithm in the decentralized control of multi-robot systems but alsooffers a new perspective on how to enhance the overall performance androbustness of the system through the integration of local information.</p>
                <p>Last Updated: 2024-08-21 04:49:49 UTC</p>
                <button class="interpret-button" data-id="2408.11339v1">Interpret</button>
                <div id="interpretation-2408.11339v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>GRAB: A Challenging GRaph Analysis Benchmark for Large Multimodal Models</h3>
                <p>Authors: Jonathan RobertsKai HanSamuel Albanie</p>
                <p><a href="http://arxiv.org/abs/2408.11817v1">Link to paper</a></p>
                <p>Large multimodal models LMMs have exhibited proficiencies across manyvisual tasks. Although numerous well-known benchmarks exist to evaluate modelperformance they increasingly have insufficient headroom. As such there is apressing need for a new generation of benchmarks challenging enough for thenext generation of LMMs. One area that LMMs show potential is graph analysisspecifically the tasks an analyst might typically perform when interpretingfigures such as estimating the mean intercepts or correlations of functionsand data series. In this work we introduce GRAB a graph analysis benchmarkfit for current and future frontier LMMs. Our benchmark is entirely syntheticensuring high-quality noise-free questions. GRAB is comprised of 2170questions covering four tasks and 23 graph properties. We evaluate 20 LMMs onGRAB finding it to be a challenging benchmark with the highest performingmodel attaining a score of just 21.7. Finally we conduct various ablations toinvestigate where the models succeed and struggle. We release GRAB to encourageprogress in this important growing domain.</p>
                <p>Last Updated: 2024-08-21 17:59:32 UTC</p>
                <button class="interpret-button" data-id="2408.11817v1">Interpret</button>
                <div id="interpretation-2408.11817v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>SynPlay: Importing Real-world Diversity for a Synthetic Human Dataset</h3>
                <p>Authors: Jinsub YimHyungtae LeeSungmin EumYi-Ting ShenYan ZhangHeesung KwonShuvra S. Bhattacharyya</p>
                <p><a href="http://arxiv.org/abs/2408.11814v1">Link to paper</a></p>
                <p>We introduce Synthetic Playground SynPlay a new synthetic human datasetthat aims to bring out the diversity of human appearance in the real world. Wefocus on two factors to achieve a level of diversity that has not yet been seenin previous works: i realistic human motions and poses and ii multiple cameraviewpoints towards human instances. We first use a game engine and itslibrary-provided elementary motions to create games where virtual players cantake less-constrained and natural movements while following the game rulesi.e. rule-guided motion design as opposed to detail-guided design. We thenaugment the elementary motions with real human motions captured with a motioncapture device. To render various human appearances in the games from multipleviewpoints we use seven virtual cameras encompassing the ground and aerialviews capturing abundant aerial-vs-ground and dynamic-vs-static attributes ofthe scene. Through extensive and carefully-designed experiments we show thatusing SynPlay in model training leads to enhanced accuracy over existingsynthetic datasets for human detection and segmentation. The benefit of SynPlaybecomes even greater for tasks in the data-scarce regime such as few-shot andcross-domain learning tasks. These results clearly demonstrate that SynPlay canbe used as an essential dataset with rich attributes of complex humanappearances and poses suitable for model pretraining. SynPlay datasetcomprising over 73k images and 6.5M human instances is available for downloadat https://synplaydataset.github.io/.</p>
                <p>Last Updated: 2024-08-21 17:58:49 UTC</p>
                <button class="interpret-button" data-id="2408.11814v1">Interpret</button>
                <div id="interpretation-2408.11814v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>SEA: Supervised Embedding Alignment for Token-Level Visual-Textual Integration in MLLMs</h3>
                <p>Authors: Yuanyang YinYaqi ZhaoYajie ZhangKe LinJiahao WangXin TaoPengfei WanDi ZhangBaoqun YinWentao Zhang</p>
                <p><a href="http://arxiv.org/abs/2408.11813v1">Link to paper</a></p>
                <p>Multimodal Large Language Models MLLMs have recently demonstratedremarkable perceptual and reasoning abilities typically comprising a VisionEncoder an Adapter and a Large Language Model LLM. The adapter serves asthe critical bridge between the visual and language components. Howevertraining adapters with image-level supervision often results in significantmisalignment undermining the LLMs capabilities and limiting the potential ofMultimodal LLMs. To address this we introduce Supervised Embedding AlignmentSEA a token-level alignment method that leverages vision-languagepre-trained models such as CLIP to align visual tokens with the LLMsembedding space through contrastive learning. This approach ensures a morecoherent integration of visual and language representations enhancing theperformance and interpretability of multimodal LLMs while preserving theirinherent capabilities. Extensive experiments show that SEA effectively improvesMLLMs particularly for smaller models without adding extra data or inferencecomputation. SEA also lays the groundwork for developing more general andadaptable solutions to enhance multimodal systems.</p>
                <p>Last Updated: 2024-08-21 17:58:02 UTC</p>
                <button class="interpret-button" data-id="2408.11813v1">Interpret</button>
                <div id="interpretation-2408.11813v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>EmbodiedSAM: Online Segment Any 3D Thing in Real Time</h3>
                <p>Authors: Xiuwei XuHuangxing ChenLinqing ZhaoZiwei WangJie ZhouJiwen Lu</p>
                <p><a href="http://arxiv.org/abs/2408.11811v1">Link to paper</a></p>
                <p>Embodied tasks require the agent to fully understand 3D scenes simultaneouslywith its exploration so an online real-time fine-grained andhighly-generalized 3D perception model is desperately needed. Sincehigh-quality 3D data is limited directly training such a model in 3D is almostinfeasible. Meanwhile vision foundation models VFM has revolutionized thefield of 2D computer vision with superior performance which makes the use ofVFM to assist embodied 3D perception a promising direction. However mostexisting VFM-assisted 3D perception methods are either offline or too slow thatcannot be applied in practical embodied tasks. In this paper we aim toleverage Segment Anything Model SAM for real-time 3D instance segmentation inan online setting. This is a challenging problem since future frames are notavailable in the input streaming RGB-D video and an instance may be observedin several frames so object matching between frames is required. To addressthese challenges we first propose a geometric-aware query lifting module torepresent the 2D masks generated by SAM by 3D-aware queries which is theniteratively refined by a dual-level query decoder. In this way the 2D masksare transferred to fine-grained shapes on 3D point clouds. Benefit from thequery representation for 3D masks we can compute the similarity matrix betweenthe 3D masks from different views by efficient matrix operation which enablesreal-time inference. Experiments on ScanNet ScanNet200 SceneNN and 3RScanshow our method achieves leading performance even compared with offlinemethods. Our method also demonstrates great generalization ability in severalzero-shot dataset transferring experiments and show great potential inopen-vocabulary and data-efficient setting. Code and demo are available athttps://xuxw98.github.io/ESAM/ with only one RTX 3090 GPU required fortraining and evaluation.</p>
                <p>Last Updated: 2024-08-21 17:57:06 UTC</p>
                <button class="interpret-button" data-id="2408.11811v1">Interpret</button>
                <div id="interpretation-2408.11811v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Pixel Is Not A Barrier: An Effective Evasion Attack for Pixel-Domain Diffusion Models</h3>
                <p>Authors: Chun-Yen ShihLi-Xuan PengJia-Wei LiaoErnie ChuCheng-Fu ChouJun-Cheng Chen</p>
                <p><a href="http://arxiv.org/abs/2408.11810v1">Link to paper</a></p>
                <p>Diffusion Models have emerged as powerful generative models for high-qualityimage synthesis with many subsequent image editing techniques based on them.However the ease of text-based image editing introduces significant riskssuch as malicious editing for scams or intellectual property infringement.Previous works have attempted to safeguard images from diffusion-based editingby adding imperceptible perturbations. These methods are costly andspecifically target prevalent Latent Diffusion Models LDMs whilePixel-domain Diffusion Models PDMs remain largely unexplored and robustagainst such attacks. Our work addresses this gap by proposing a novelattacking framework with a feature representation attack loss that exploitsvulnerabilities in denoising UNets and a latent optimization strategy toenhance the naturalness of protected images. Extensive experiments demonstratethe effectiveness of our approach in attacking dominant PDM-based editingmethods e.g. SDEdit while maintaining reasonable protection fidelity androbustness against common defense methods. Additionally our framework isextensible to LDMs achieving comparable performance to existing approaches.</p>
                <p>Last Updated: 2024-08-21 17:56:34 UTC</p>
                <button class="interpret-button" data-id="2408.11810v1">Interpret</button>
                <div id="interpretation-2408.11810v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>Efficient Exploration and Discriminative World Model Learning with an Object-Centric Abstraction</h3>
                <p>Authors: Anthony GX-ChenKenneth MarinoRob Fergus</p>
                <p><a href="http://arxiv.org/abs/2408.11816v1">Link to paper</a></p>
                <p>In the face of difficult exploration problems in reinforcement learning westudy whether giving an agent an object-centric mapping describing a set ofitems and their attributes allow for more efficient learning. We found thisproblem is best solved hierarchically by modelling items at a higher level ofstate abstraction to pixels and attribute change at a higher level of temporalabstraction to primitive actions. This abstraction simplifies the transitiondynamic by making specific future states easier to predict. We make use of thisto propose a fully model-based algorithm that learns a discriminative worldmodel plans to explore efficiently with only a count-based intrinsic rewardand can subsequently plan to reach any discovered abstract states.  We demonstrate the models ability to i efficiently solve single tasksii transfer zero-shot and few-shot across item types and environments andiii plan across long horizons. Across a suite of 2D crafting and MiniHackenvironments we empirically show our model significantly out-performsstate-of-the-art low-level methods without abstraction as well as performantmodel-free and model-based methods using the same abstraction. Finally we showhow to reinforce learn low level object-perturbing policies as well assupervise learn the object mapping itself.</p>
                <p>Last Updated: 2024-08-21 17:59:31 UTC</p>
                <button class="interpret-button" data-id="2408.11816v1">Interpret</button>
                <div id="interpretation-2408.11816v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Scaling Cross-Embodied Learning: One Policy for Manipulation, Navigation, Locomotion and Aviation</h3>
                <p>Authors: Ria DoshiHomer WalkeOier MeesSudeep DasariSergey Levine</p>
                <p><a href="http://arxiv.org/abs/2408.11812v1">Link to paper</a></p>
                <p>Modern machine learning systems rely on large datasets to attain broadgeneralization and this often poses a challenge in robot learning where eachrobotic platform and task might have only a small dataset. By training a singlepolicy across many different kinds of robots a robot learning method canleverage much broader and more diverse datasets which in turn can lead tobetter generalization and robustness. However training a single policy onmulti-robot data is challenging because robots can have widely varying sensorsactuators and control frequencies. We propose CrossFormer a scalable andflexible transformer-based policy that can consume data from any embodiment. Wetrain CrossFormer on the largest and most diverse dataset to date 900Ktrajectories across 20 different robot embodiments. We demonstrate that thesame network weights can control vastly different robots including single anddual arm manipulation systems wheeled robots quadcopters and quadrupeds.Unlike prior work our model does not require manual alignment of theobservation or action spaces. Extensive experiments in the real world show thatour method matches the performance of specialist policies tailored for eachembodiment while also significantly outperforming the prior state of the artin cross-embodiment learning.</p>
                <p>Last Updated: 2024-08-21 17:57:51 UTC</p>
                <button class="interpret-button" data-id="2408.11812v1">Interpret</button>
                <div id="interpretation-2408.11812v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>ACE: A Cross-Platform Visual-Exoskeletons System for Low-Cost Dexterous Teleoperation</h3>
                <p>Authors: Shiqi YangMinghuan LiuYuzhe QinRunyu DingJialong LiXuxin ChengRuihan YangSha YiXiaolong Wang</p>
                <p><a href="http://arxiv.org/abs/2408.11805v1">Link to paper</a></p>
                <p>Learning from demonstrations has shown to be an effective approach to roboticmanipulation especially with the recently collected large-scale robot datawith teleoperation systems. Building an efficient teleoperation system acrossdiverse robot platforms has become more crucial than ever. However there is anotable lack of cost-effective and user-friendly teleoperation systems fordifferent end-effectors e.g. anthropomorphic robot hands and grippers thatcan operate across multiple platforms. To address this issue we develop ACE across-platform visual-exoskeleton system for low-cost dexterous teleoperation.Our system utilizes a hand-facing camera to capture 3D hand poses and anexoskeleton mounted on a portable base enabling accurate real-time capture ofboth finger and wrist poses. Compared to previous systems which often requirehardware customization according to different robots our single system cangeneralize to humanoid hands arm-hands arm-gripper and quadruped-grippersystems with high-precision teleoperation. This enables imitation learning forcomplex manipulation tasks on diverse platforms.</p>
                <p>Last Updated: 2024-08-21 17:48:31 UTC</p>
                <button class="interpret-button" data-id="2408.11805v1">Interpret</button>
                <div id="interpretation-2408.11805v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Approaching Deep Learning through the Spectral Dynamics of Weights</h3>
                <p>Authors: David YunisKumar Kshitij PatelSamuel WheelerPedro SavareseGal VardiKaren LivescuMichael MaireMatthew R. Walter</p>
                <p><a href="http://arxiv.org/abs/2408.11804v1">Link to paper</a></p>
                <p>We propose an empirical approach centered on the spectral dynamics of weights-- the behavior of singular values and vectors during optimization -- to unifyand clarify several phenomena in deep learning. We identify a consistent biasin optimization across various experiments from small-scale grokking tolarge-scale tasks like image classification with ConvNets image generationwith UNets speech recognition with LSTMs and language modeling withTransformers. We also demonstrate that weight decay enhances this bias beyondits role as a norm regularizer even in practical systems. Moreover we showthat these spectral dynamics distinguish memorizing networks from generalizingones offering a novel perspective on this longstanding conundrum.Additionally we leverage spectral dynamics to explore the emergence ofwell-performing sparse subnetworks lottery tickets and the structure of theloss surface through linear mode connectivity. Our findings suggest thatspectral dynamics provide a coherent framework to better understand thebehavior of neural networks across diverse settings.</p>
                <p>Last Updated: 2024-08-21 17:48:01 UTC</p>
                <button class="interpret-button" data-id="2408.11804v1">Interpret</button>
                <div id="interpretation-2408.11804v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LLM Pruning and Distillation in Practice: The Minitron Approach</h3>
                <p>Authors: Sharath Turuvekere SreenivasSaurav MuralidharanRaviraj JoshiMarcin ChochowskiMostofa PatwaryMohammad ShoeybiBryan CatanzaroJan KautzPavlo Molchanov</p>
                <p><a href="http://arxiv.org/abs/2408.11796v1">Link to paper</a></p>
                <p>We present a comprehensive report on compressing the Llama 3.1 8B and MistralNeMo 12B models to 4B and 8B parameters respectively using pruning anddistillation. We explore two distinct pruning strategies: 1 depth pruning and2 joint hidden/attention/MLP width pruning and evaluate the results oncommon benchmarks from the LM Evaluation Harness. The models are then alignedwith NeMo Aligner and tested in instruct-tuned versions. This approach producesa compelling 4B model from Llama 3.1 8B and a state-of-the-artMistral-NeMo-Minitron-8B MN-Minitron-8B for brevity model from Mistral NeMo12B. We found that with no access to the original data it is beneficial toslightly fine-tune teacher models on the distillation dataset. We open-sourceour base model weights on Hugging Face with a permissive license.</p>
                <p>Last Updated: 2024-08-21 17:38:48 UTC</p>
                <button class="interpret-button" data-id="2408.11796v1">Interpret</button>
                <div id="interpretation-2408.11796v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Esports Training in StarCraft II: Stance Stability and Grip Strength</h3>
                <p>Authors: Andrzej BiałeckiMichał StaniszewskiRobert BiałeckiJan Gajewski</p>
                <p><a href="http://arxiv.org/abs/2408.11764v1">Link to paper</a></p>
                <p>Esports are a mostly sedentary activity. There is a growing need forinvestigation into how biomechanical and physical abilities can be optimizedfor esports through training. One such research avenue concerns the ability ofesports players to perform balance tasks due to the prolonged sedentary statesthat are required to reach the top echelon of performance.  Our aim for this work is to describe and compare physical abilities balancegrip strength and self-reported training habits of top Polish StarCraft2tournament players.  Esports players differed significantly from the reference group in theirability to balance on one leg. Additionally in a grip strength test theesports group fared worse than the reference group in all consecutive attempts.  Despite self-reported physical activity in the esports group player fitnessrequires further research. Training optimization could offset the issuesarising from sedentary activity and intensifying esports training so it couldtake less time overall.</p>
                <p>Last Updated: 2024-08-21 16:39:25 UTC</p>
                <button class="interpret-button" data-id="2408.11764v1">Interpret</button>
                <div id="interpretation-2408.11764v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Cultural Windows: Towards a Workflow for Immersive Journeys into Global Living Spaces</h3>
                <p>Authors: Hessam DjavaherpourPierre DragicevicYvonne Jansen</p>
                <p><a href="http://arxiv.org/abs/2408.11723v1">Link to paper</a></p>
                <p>Cultural Windows is a research initiative designed to enrich cross-culturalunderstanding through immersive extended reality XR experiences. This projectproposes a workflow for deploying AR and VR platforms allowing users toexplore living spaces from diverse cultures and socio-economic statuses. Theprocess involves 3D scanning of culturally significant objects creatingaccurate models of living spaces and integrating them into immersive systemsto facilitate engagement with global living designs. Targeted at individualscurious about how people live in different parts of the world the project aimsto expand cross-cultural understanding and design perspectives providinginsights into the effectiveness of immersive technologies in culturaleducation. By detailing its conceptual framework Cultural Windows aims toenhance comprehension and appreciation of global domestic aesthetics bycomparing participants perceptions with immersive realistic representationsof living spaces from different cultures. This can help bridge the gap betweenpreconceived notions and the actual appearance and feel of these spaces.</p>
                <p>Last Updated: 2024-08-21 15:52:10 UTC</p>
                <button class="interpret-button" data-id="2408.11723v1">Interpret</button>
                <div id="interpretation-2408.11723v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Improved Visual Saliency of Graph Clusters with Orderable Node-Link Layouts</h3>
                <p>Authors: Nora Al-NaamiNicolas MédocMatteo MagnaniMohammad Ghoniem</p>
                <p><a href="http://arxiv.org/abs/2408.11673v1">Link to paper</a></p>
                <p>Graphs are often used to model relationships between entities. Theidentification and visualization of clusters in graphs enable insight discoveryin many application areas such as life sciences and social sciences.Force-directed graph layouts promote the visual saliency of clusters as theybring adjacent nodes closer together and push non-adjacent nodes apart. At thesame time matrices can effectively show clusters when a suitable row/columnordering is applied but are less appealing to untrained users not providing anintuitive node-link metaphor. It is thus worth exploring layouts combining thestrengths of the node-link metaphor and node ordering. In this work we studythe impact of node ordering on the visual saliency of clusters in orderablenode-link diagrams namely radial diagrams arc diagrams and symmetric arcdiagrams. Through a crowdsourced controlled experiment we show that users cancount clusters consistently more accurately and to a large extent faster withorderable node-link diagrams than with three state-of-the art force-directedlayout algorithms i.e. Linlog Backbone and sfdp. The measuredadvantage is greater in case of low cluster separability and/or lowcompactness. A free copy of this paper and all supplemental materials areavailable at https://osf.io/kc3dg/.</p>
                <p>Last Updated: 2024-08-21 14:50:37 UTC</p>
                <button class="interpret-button" data-id="2408.11673v1">Interpret</button>
                <div id="interpretation-2408.11673v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The Problems with Proxies: Making Data Work Visible through Requester Practices</h3>
                <p>Authors: Annabel RothschildDing WangNiveditha Jayakumar VilvanathanLauren WilcoxCarl DiSalvoBetsy DiSalvo</p>
                <p><a href="http://arxiv.org/abs/2408.11667v1">Link to paper</a></p>
                <p>Fairness in AI and ML systems is increasingly linked to the proper treatmentand recognition of data workers involved in training dataset development. Yetthose who collect and annotate the data and thus have the most intimateknowledge of its development are often excluded from critical discussions.This exclusion prevents data annotators who are domain experts fromcontributing effectively to dataset contextualization. Our investigation intothe hiring and engagement practices of 52 data work requesters on platformslike Amazon Mechanical Turk reveals a gap: requesters frequently hold naive orunchallenged notions of worker identities and capabilities and rely on ad-hocqualification tasks that fail to respect the workers expertise. Thesepractices not only undermine the quality of data but also the ethical standardsof AI development. To rectify these issues we advocate for policy changes toenhance how data annotation tasks are designed and managed and to ensure dataworkers are treated with the respect they deserve.</p>
                <p>Last Updated: 2024-08-21 14:39:34 UTC</p>
                <button class="interpret-button" data-id="2408.11667v1">Interpret</button>
                <div id="interpretation-2408.11667v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Audio Description Customization</h3>
                <p>Authors: Rosiana NatalieRuei-Che ChangSmitha SheshadriAnhong GuoKotaro Hara</p>
                <p><a href="http://dx.doi.org/10.1145/3663548.3675617">Link to paper</a></p>
                <p>Blind and low-vision BLV people use audio descriptions ADs to accessvideos. However current ADs are unalterable by end users thus are incapableof supporting BLV individuals potentially diverse needs and preferences. Thisresearch investigates if customizing AD could improve how BLV individualsconsume videos. We conducted an interview study Study 1 with fifteen BLVparticipants which revealed desires for customizing properties like lengthemphasis speed voice format tone and language. At the same time concernslike interruptions and increased interaction load due to customization emerged.To examine AD customizations effectiveness and tradeoffs we designedCustomAD a prototype that enables BLV users to customize AD content andpresentation. An evaluation study Study 2 with twelve BLV participants showedusing CustomAD significantly enhanced BLV peoples video understandingimmersion and information navigation efficiency. Our work illustrates theimportance of AD customization and offers a design that enhances videoaccessibility for BLV individuals.</p>
                <p>Last Updated: 2024-08-21 08:04:22 UTC</p>
                <button class="interpret-button" data-id="2408.11406v1">Interpret</button>
                <div id="interpretation-2408.11406v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>Great Memory, Shallow Reasoning: Limits of $k$NN-LMs</h3>
                <p>Authors: Shangyi GengWenting ZhaoAlexander M Rush</p>
                <p><a href="http://arxiv.org/abs/2408.11815v1">Link to paper</a></p>
                <p>K-nearest neighbor language models kNN-LMs which integrate retrievalwith next-word prediction have demonstrated strong performance in languagemodeling as well as downstream NLP benchmarks. These results have ledresearchers to argue that models trained on poor quality or outdated data couldperform well by employing a kNN extension that has access to a higher-qualitydatastore. In this work we ask whether this improved ability to recallinformation really translates into downstream abilities. We extensivelyevaluate kNN-LMs on a diverse set of tasks ranging from sentimentclassification and commonsense reasoning to multi-hop reasoning. Results showthat kNN-LMs excel at memory-intensive tasks where utilizing the patterns inthe input is sufficient for determining the output but struggle with reasoningtasks that require integrating multiple pieces of information to derive newknowledge. We further demonstrate through oracle experiments and qualitativeanalysis that even with perfect retrieval kNN-LMs still fail to determinethe correct answers placing an upper bound on their reasoning performance.Code and datastores are released at https://github.com/GSYfate/knnlm-limits/.</p>
                <p>Last Updated: 2024-08-21 17:59:05 UTC</p>
                <button class="interpret-button" data-id="2408.11815v1">Interpret</button>
                <div id="interpretation-2408.11815v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain</h3>
                <p>Authors: Rounak MeyurHung PhanSridevi WagleJan StrubeMahantesh HalappanavarSameera HorawalavithanaAnurag AcharyaSai Munikoti</p>
                <p><a href="http://arxiv.org/abs/2408.11800v1">Link to paper</a></p>
                <p>In the rapidly evolving landscape of Natural Language Processing NLP andtext generation the emergence of Retrieval Augmented Generation RAG presentsa promising avenue for improving the quality and reliability of generated textby leveraging information retrieved from user specified database. Benchmarkingis essential to evaluate and compare the performance of the different RAGconfigurations in terms of retriever and generator providing insights intotheir effectiveness scalability and suitability for the specific domain andapplications. In this paper we present a comprehensive framework to generate adomain relevant RAG benchmark. Our framework is based on automaticquestion-answer generation with Human domain experts-AI Large Language ModelLLM teaming. As a case study we demonstrate the framework by introducingPermitQA a first-of-its-kind benchmark on the wind siting and permittingdomain which comprises of multiple scientific documents/reports related toenvironmental impact of wind energy projects. Our framework systematicallyevaluates RAG performance using diverse metrics and multiple question typeswith varying complexity level. We also demonstrate the performance of differentmodels on our benchmark.</p>
                <p>Last Updated: 2024-08-21 17:43:11 UTC</p>
                <button class="interpret-button" data-id="2408.11800v1">Interpret</button>
                <div id="interpretation-2408.11800v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Practical token pruning for foundation models in few-shot conversational virtual assistant systems</h3>
                <p>Authors: Haode QiCheng QianJian NiPratyush SinghReza FazeliGengyu WangZhongzheng ShuEric WayneJuergen Bross</p>
                <p><a href="http://arxiv.org/abs/2408.11799v1">Link to paper</a></p>
                <p>In an enterprise Virtual Assistant VA system intent classification is thecrucial component that determines how a user input is handled based on what theuser wants. The VA system is expected to be a cost-efficient SaaS service withlow training and inference time while achieving high accuracy even with a smallnumber of training samples. We pretrain a transformer-based sentence embeddingmodel with a contrastive learning objective and leverage the embedding of themodel as features when training intent classification models. Our approachachieves the state-of-the-art results for few-shot scenarios and performsbetter than other commercial solutions on popular intent classificationbenchmarks. However generating features via a transformer-based modelincreases the inference time especially for longer user inputs due to thequadratic runtime of the transformers attention mechanism. On top of modeldistillation we introduce a practical multi-task adaptation approach thatconfigures dynamic token pruning without the need for task-specific trainingfor intent classification. We demonstrate that this approach improves theinference speed of popular sentence transformer models without affecting modelperformance.</p>
                <p>Last Updated: 2024-08-21 17:42:17 UTC</p>
                <button class="interpret-button" data-id="2408.11799v1">Interpret</button>
                <div id="interpretation-2408.11799v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LLM Pruning and Distillation in Practice: The Minitron Approach</h3>
                <p>Authors: Sharath Turuvekere SreenivasSaurav MuralidharanRaviraj JoshiMarcin ChochowskiMostofa PatwaryMohammad ShoeybiBryan CatanzaroJan KautzPavlo Molchanov</p>
                <p><a href="http://arxiv.org/abs/2408.11796v1">Link to paper</a></p>
                <p>We present a comprehensive report on compressing the Llama 3.1 8B and MistralNeMo 12B models to 4B and 8B parameters respectively using pruning anddistillation. We explore two distinct pruning strategies: 1 depth pruning and2 joint hidden/attention/MLP width pruning and evaluate the results oncommon benchmarks from the LM Evaluation Harness. The models are then alignedwith NeMo Aligner and tested in instruct-tuned versions. This approach producesa compelling 4B model from Llama 3.1 8B and a state-of-the-artMistral-NeMo-Minitron-8B MN-Minitron-8B for brevity model from Mistral NeMo12B. We found that with no access to the original data it is beneficial toslightly fine-tune teacher models on the distillation dataset. We open-sourceour base model weights on Hugging Face with a permissive license.</p>
                <p>Last Updated: 2024-08-21 17:38:48 UTC</p>
                <button class="interpret-button" data-id="2408.11796v1">Interpret</button>
                <div id="interpretation-2408.11796v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>DreamFactory: Pioneering Multi-Scene Long Video Generation with a Multi-Agent Framework</h3>
                <p>Authors: Zhifei XieDaniel TangDingwei TanJacques KleinTegawend F. BissyandSaad Ezzini</p>
                <p><a href="http://arxiv.org/abs/2408.11788v1">Link to paper</a></p>
                <p>Current video generation models excel at creating short realistic clips butstruggle with longer multi-scene videos. We introduce textttDreamFactoryan LLM-based framework that tackles this challenge. textttDreamFactoryleverages multi-agent collaboration principles and a Key Frames IterationDesign Method to ensure consistency and style across long videos. It utilizesChain of Thought COT to address uncertainties inherent in large languagemodels. textttDreamFactory generates long stylistically coherent andcomplex videos. Evaluating these long-form videos presents a challenge. Wepropose novel metrics such as Cross-Scene Face Distance Score and Cross-SceneStyle Consistency Score. To further research in this area we contribute theMulti-Scene Videos Dataset containing over 150 human-rated videos.</p>
                <p>Last Updated: 2024-08-21 17:21:13 UTC</p>
                <button class="interpret-button" data-id="2408.11788v1">Interpret</button>
                <div id="interpretation-2408.11788v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Deviations from the Nash equilibrium and emergence of tacit collusion in a two-player optimal execution game with reinforcement learning</h3>
                <p>Authors: Fabrizio LilloAndrea Macrì</p>
                <p><a href="http://arxiv.org/abs/2408.11773v1">Link to paper</a></p>
                <p>The use of reinforcement learning algorithms in financial trading is becomingincreasingly prevalent. However the autonomous nature of these algorithms canlead to unexpected outcomes that deviate from traditional game-theoreticalpredictions and may even destabilize markets. In this study we examine ascenario in which two autonomous agents modeled with Double Deep Q-Learninglearn to liquidate the same asset optimally in the presence of market impactusing the Almgren-Chriss 2000 framework. Our results show that the strategieslearned by the agents deviate significantly from the Nash equilibrium of thecorresponding market impact game. Notably the learned strategies exhibit tacitcollusion closely aligning with the Pareto-optimal solution. We furtherexplore how different levels of market volatility influence the agentsperformance and the equilibria they discover including scenarios wherevolatility differs between the training and testing phases.</p>
                <p>Last Updated: 2024-08-21 16:54:53 UTC</p>
                <button class="interpret-button" data-id="2408.11773v1">Interpret</button>
                <div id="interpretation-2408.11773v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Scalable and non-iterative graphical model estimation</h3>
                <p>Authors: Kshitij KhareSyed RahmanBala RajaratnamJiayuan Zhou</p>
                <p><a href="http://arxiv.org/abs/2408.11718v1">Link to paper</a></p>
                <p>Graphical models have found widespread applications in many areas of modernstatistics and machine learning. Iterative Proportional Fitting IPF and itsvariants have become the default method for undirected graphical modelestimation and are thus ubiquitous in the field. As the IPF is an iterativeapproach it is not always readily scalable to modern high-dimensional dataregimes. In this paper we propose a novel and fast non-iterative method forpositive definite graphical model estimation in high dimensions one thatdirectly addresses the shortcomings of IPF and its variants. In addition theproposed method has a number of other attractive properties. First we showformally that as the dimension p grows the proportion of graphs for which theproposed method will outperform the state-of-the-art in terms of computationalcomplexity and performance tends to 1 affirming its efficacy in modernsettings. Second the proposed approach can be readily combined with scalablenon-iterative thresholding-based methods for high-dimensional sparsityselection. Third the proposed method has high-dimensional statisticalguarantees. Moreover our numerical experiments also show that the proposedmethod achieves scalability without compromising on statistical precision.Fourth unlike the IPF which depends on the Gaussian likelihood the proposedmethod is much more robust.</p>
                <p>Last Updated: 2024-08-21 15:46:00 UTC</p>
                <button class="interpret-button" data-id="2408.11718v1">Interpret</button>
                <div id="interpretation-2408.11718v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Plug-in estimation of Schrödinger bridges</h3>
                <p>Authors: Aram-Alexandre PooladianJonathan Niles-Weed</p>
                <p><a href="http://arxiv.org/abs/2408.11686v1">Link to paper</a></p>
                <p>We propose a procedure for estimating the Schrodinger bridge between twoprobability distributions. Unlike existing approaches our method does notrequire iteratively simulating forward and backward diffusions or trainingneural networks to fit unknown drifts. Instead we show that the potentialsobtained from solving the static entropic optimal transport problem between thesource and target samples can be modified to yield a natural plug-in estimatorof the time-dependent drift that defines the bridge between two measures. Underminimal assumptions we show that our proposal which we call theemphSinkhorn bridge provably estimates the Schrodinger bridge with a rateof convergence that depends on the intrinsic dimensionality of the targetmeasure. Our approach combines results from the areas of sampling andtheoretical and statistical entropic optimal transport.</p>
                <p>Last Updated: 2024-08-21 15:07:25 UTC</p>
                <button class="interpret-button" data-id="2408.11686v1">Interpret</button>
                <div id="interpretation-2408.11686v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>On Quasi-Localized Dual Pairs in Reproducing Kernel Hilbert Spaces</h3>
                <p>Authors: Helmut HarbrechtRüdiger KempfMichael Multerer</p>
                <p><a href="http://arxiv.org/abs/2408.11389v1">Link to paper</a></p>
                <p>In scattered data approximation the span of a finite number of translates ofa chosen radial basis function is used as approximation space and the basis oftranslates is used for representing the approximate. However this naturalchoice is by no means mandatory and different choices like for example theLagrange basis are possible and might offer additional features. In thisarticle we discuss different alternatives together with their canonical duals.We study a localized version of the Lagrange basis localized orthogonal basessuch as the Newton basis and multiresolution versions thereof constructed bymeans of samplets. We argue that the choice of orthogonal bases is particularlyuseful as they lead to symmetric preconditioners. All bases under considerationare compared numerically to illustrate their feasibility for scattered dataapproximation. We provide benchmark experiments in two spatial dimensions andconsider the reconstruction of an implicit surface as a relevant applicationfrom computer graphics.</p>
                <p>Last Updated: 2024-08-21 07:33:30 UTC</p>
                <button class="interpret-button" data-id="2408.11389v1">Interpret</button>
                <div id="interpretation-2408.11389v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Learning Flock: Enhancing Sets of Particles for Multi~Sub-State Particle Filtering with Neural Augmentation</h3>
                <p>Authors: Itai NuriNir Shlezinger</p>
                <p><a href="http://arxiv.org/abs/2408.11348v1">Link to paper</a></p>
                <p>A leading family of algorithms for state estimation in dynamic systems withmultiple sub-states is based on particle filters PFs. PFs often struggle whenoperating under complex or approximated modelling necessitating manyparticles with low latency requirements limiting the number of particles asis typically the case in multi target tracking MTT. In this work weintroduce a deep neural network DNN augmentation for PFs termed learningflock LF. LF learns to correct a particles-weights set which we coin flockbased on the relationships between all sub-particles in the set itself whiledisregarding the set acquisition procedure. Our proposed LF which can bereadily incorporated into different PFs flow is designed to facilitate rapidoperation by maintaining accuracy with a reduced number of particles. Weintroduce a dedicated training algorithm allowing both supervised andunsupervised training and yielding a module that supports a varying number ofsub-states and particles without necessitating re-training. We experimentallyshow the improvements in performance robustness and latency of LFaugmentation for radar multi-target tracking as well its ability to mitigatethe effect of a mismatched observation modelling. We also compare andillustrate the advantages of LF over a state-of-the-art DNN-aided PF anddemonstrate that LF enhances both classic PFs as well as DNN-based filters.</p>
                <p>Last Updated: 2024-08-21 05:28:12 UTC</p>
                <button class="interpret-button" data-id="2408.11348v1">Interpret</button>
                <div id="interpretation-2408.11348v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>Efficient Exploration and Discriminative World Model Learning with an Object-Centric Abstraction</h3>
                <p>Authors: Anthony GX-ChenKenneth MarinoRob Fergus</p>
                <p><a href="http://arxiv.org/abs/2408.11816v1">Link to paper</a></p>
                <p>In the face of difficult exploration problems in reinforcement learning westudy whether giving an agent an object-centric mapping describing a set ofitems and their attributes allow for more efficient learning. We found thisproblem is best solved hierarchically by modelling items at a higher level ofstate abstraction to pixels and attribute change at a higher level of temporalabstraction to primitive actions. This abstraction simplifies the transitiondynamic by making specific future states easier to predict. We make use of thisto propose a fully model-based algorithm that learns a discriminative worldmodel plans to explore efficiently with only a count-based intrinsic rewardand can subsequently plan to reach any discovered abstract states.  We demonstrate the models ability to i efficiently solve single tasksii transfer zero-shot and few-shot across item types and environments andiii plan across long horizons. Across a suite of 2D crafting and MiniHackenvironments we empirically show our model significantly out-performsstate-of-the-art low-level methods without abstraction as well as performantmodel-free and model-based methods using the same abstraction. Finally we showhow to reinforce learn low level object-perturbing policies as well assupervise learn the object mapping itself.</p>
                <p>Last Updated: 2024-08-21 17:59:31 UTC</p>
                <button class="interpret-button" data-id="2408.11816v1">Interpret</button>
                <div id="interpretation-2408.11816v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Great Memory, Shallow Reasoning: Limits of $k$NN-LMs</h3>
                <p>Authors: Shangyi GengWenting ZhaoAlexander M Rush</p>
                <p><a href="http://arxiv.org/abs/2408.11815v1">Link to paper</a></p>
                <p>K-nearest neighbor language models kNN-LMs which integrate retrievalwith next-word prediction have demonstrated strong performance in languagemodeling as well as downstream NLP benchmarks. These results have ledresearchers to argue that models trained on poor quality or outdated data couldperform well by employing a kNN extension that has access to a higher-qualitydatastore. In this work we ask whether this improved ability to recallinformation really translates into downstream abilities. We extensivelyevaluate kNN-LMs on a diverse set of tasks ranging from sentimentclassification and commonsense reasoning to multi-hop reasoning. Results showthat kNN-LMs excel at memory-intensive tasks where utilizing the patterns inthe input is sufficient for determining the output but struggle with reasoningtasks that require integrating multiple pieces of information to derive newknowledge. We further demonstrate through oracle experiments and qualitativeanalysis that even with perfect retrieval kNN-LMs still fail to determinethe correct answers placing an upper bound on their reasoning performance.Code and datastores are released at https://github.com/GSYfate/knnlm-limits/.</p>
                <p>Last Updated: 2024-08-21 17:59:05 UTC</p>
                <button class="interpret-button" data-id="2408.11815v1">Interpret</button>
                <div id="interpretation-2408.11815v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Approaching Deep Learning through the Spectral Dynamics of Weights</h3>
                <p>Authors: David YunisKumar Kshitij PatelSamuel WheelerPedro SavareseGal VardiKaren LivescuMichael MaireMatthew R. Walter</p>
                <p><a href="http://arxiv.org/abs/2408.11804v1">Link to paper</a></p>
                <p>We propose an empirical approach centered on the spectral dynamics of weights-- the behavior of singular values and vectors during optimization -- to unifyand clarify several phenomena in deep learning. We identify a consistent biasin optimization across various experiments from small-scale grokking tolarge-scale tasks like image classification with ConvNets image generationwith UNets speech recognition with LSTMs and language modeling withTransformers. We also demonstrate that weight decay enhances this bias beyondits role as a norm regularizer even in practical systems. Moreover we showthat these spectral dynamics distinguish memorizing networks from generalizingones offering a novel perspective on this longstanding conundrum.Additionally we leverage spectral dynamics to explore the emergence ofwell-performing sparse subnetworks lottery tickets and the structure of theloss surface through linear mode connectivity. Our findings suggest thatspectral dynamics provide a coherent framework to better understand thebehavior of neural networks across diverse settings.</p>
                <p>Last Updated: 2024-08-21 17:48:01 UTC</p>
                <button class="interpret-button" data-id="2408.11804v1">Interpret</button>
                <div id="interpretation-2408.11804v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LLM Pruning and Distillation in Practice: The Minitron Approach</h3>
                <p>Authors: Sharath Turuvekere SreenivasSaurav MuralidharanRaviraj JoshiMarcin ChochowskiMostofa PatwaryMohammad ShoeybiBryan CatanzaroJan KautzPavlo Molchanov</p>
                <p><a href="http://arxiv.org/abs/2408.11796v1">Link to paper</a></p>
                <p>We present a comprehensive report on compressing the Llama 3.1 8B and MistralNeMo 12B models to 4B and 8B parameters respectively using pruning anddistillation. We explore two distinct pruning strategies: 1 depth pruning and2 joint hidden/attention/MLP width pruning and evaluate the results oncommon benchmarks from the LM Evaluation Harness. The models are then alignedwith NeMo Aligner and tested in instruct-tuned versions. This approach producesa compelling 4B model from Llama 3.1 8B and a state-of-the-artMistral-NeMo-Minitron-8B MN-Minitron-8B for brevity model from Mistral NeMo12B. We found that with no access to the original data it is beneficial toslightly fine-tune teacher models on the distillation dataset. We open-sourceour base model weights on Hugging Face with a permissive license.</p>
                <p>Last Updated: 2024-08-21 17:38:48 UTC</p>
                <button class="interpret-button" data-id="2408.11796v1">Interpret</button>
                <div id="interpretation-2408.11796v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design</h3>
                <p>Authors: Nathaniel H. ParkTiffany J. CallahanJames L. HedrickTim ErdmannSara Capponi</p>
                <p><a href="http://arxiv.org/abs/2408.11793v1">Link to paper</a></p>
                <p>Molecular property prediction and generative design via deep learning modelshas been the subject of intense research given its potential to acceleratedevelopment of new high-performance materials. More recently these workflowshave been significantly augmented with the advent of large language modelsLLMs and systems of LLM-driven agents capable of utilizing pre-trained modelsto make predictions in the context of more complex research tasks. Whileeffective there is still room for substantial improvement within the agenticsystems on the retrieval of salient information for material design tasks.Moreover alternative uses of predictive deep learning models such asleveraging their latent representations to facilitate cross-modal retrievalaugmented generation within agentic systems to enable task-specific materialsdesign has remained unexplored. Herein we demonstrate that large pre-trainedchemistry foundation models can serve as a basis for enabling semanticchemistry information retrieval for both small-molecules complex polymericmaterials and reactions. Additionally we show the use of chemistry foundationmodels in conjunction with image models such as OpenCLIP facilitateunprecedented queries and information retrieval across multiplecharacterization data domains. Finally we demonstrate the integration of thesesystems within multi-agent systems to facilitate structure andtopological-based natural language queries and information retrieval forcomplex research tasks.</p>
                <p>Last Updated: 2024-08-21 17:25:45 UTC</p>
                <button class="interpret-button" data-id="2408.11793v1">Interpret</button>
                <div id="interpretation-2408.11793v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-08-22</p>
        </div>
    
        </div>
    </body>
    </html>
    