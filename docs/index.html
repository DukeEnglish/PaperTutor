
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Scalable Multi-Output Gaussian Processes with Stochastic Variational Inference</h3>
                <p>Authors: Xiaoyu JiangSokratia GeorgakaMagnus RattrayMauricio A. Alvarez</p>
                <p><a href="http://arxiv.org/abs/2407.02476v1">Link to paper</a></p>
                <p>The Multi-Output Gaussian Process is is a popular tool for modelling datafrom multiple sources. A typical choice to build a covariance function for aMOGP is the Linear Model of Coregionalization LMC which parametrically modelsthe covariance between outputs. The Latent Variable MOGP LV-MOGP generalisesthis idea by modelling the covariance between outputs using a kernel applied tolatent variables one per output leading to a flexible MOGP model that allowsefficient generalization to new outputs with few data points. Computationalcomplexity in LV-MOGP grows linearly with the number of outputs which makes itunsuitable for problems with a large number of outputs. In this paper wepropose a stochastic variational inference approach for the LV-MOGP that allowsmini-batches for both inputs and outputs making computational complexity pertraining iteration independent of the number of outputs.</p>
                <p>Last Updated: 2024-07-02 17:53:56 UTC</p>
                <button class="interpret-button" data-id="2407.02476v1">Interpret</button>
                <div id="interpretation-2407.02476v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Reliable Confidence Intervals for Information Retrieval Evaluation Using Generative A.I</h3>
                <p>Authors: Harrie OosterhuisRolf JagermanZhen QinXuanhui WangMichael Bendersky</p>
                <p><a href="http://dx.doi.org/10.1145/3637528.3671883">Link to paper</a></p>
                <p>The traditional evaluation of information retrieval IR systems is generallyvery costly as it requires manual relevance annotation from human experts.Recent advancements in generative artificial intelligence -- specifically largelanguage models LLMs -- can generate relevance annotations at an enormousscale with relatively small computational costs. Potentially this couldalleviate the costs traditionally associated with IR evaluation and make itapplicable to numerous low-resource applications. However generated relevanceannotations are not immune to systematic errors and as a result directlyusing them for evaluation produces unreliable results.  In this work we propose two methods based on prediction-powered inferenceand conformal risk control that utilize computer-generated relevanceannotations to place reliable confidence intervals CIs around IR evaluationmetrics. Our proposed methods require a small number of reliable annotationsfrom which the methods can statistically analyze the errors in the generatedannotations. Using this information we can place CIs around evaluation metricswith strong theoretical guarantees. Unlike existing approaches our conformalrisk control method is specifically designed for ranking metrics and can varyits CIs per query and document. Our experimental results show that our CIsaccurately capture both the variance and bias in evaluation based on LLMannotations better than the typical empirical bootstrapping estimates. We hopeour contributions bring reliable evaluation to the many IR applications wherethis was traditionally infeasible.</p>
                <p>Last Updated: 2024-07-02 17:44:00 UTC</p>
                <button class="interpret-button" data-id="2407.02464v1">Interpret</button>
                <div id="interpretation-2407.02464v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Statistical Advantages of Oblique Randomized Decision Trees and Forests</h3>
                <p>Authors: Eliza O'Reilly</p>
                <p><a href="http://arxiv.org/abs/2407.02458v1">Link to paper</a></p>
                <p>This work studies the statistical advantages of using features comprised ofgeneral linear combinations of covariates to partition the data in randomizeddecision tree and forest regression algorithms. Using random tessellationtheory in stochastic geometry we provide a theoretical analysis of a class ofefficiently generated random tree and forest estimators that allow for obliquesplits along such features. We call these estimators oblique Mondrian trees andforests as the trees are generated by first selecting a set of features fromlinear combinations of the covariates and then running a Mondrian process thathierarchically partitions the data along these features. Generalization errorbounds and convergence rates are obtained for the flexible dimension reductionmodel class of ridge functions also known as multi-index models where theoutput is assumed to depend on a low dimensional relevant feature subspace ofthe input domain. The results highlight how the risk of these estimatorsdepends on the choice of features and quantify how robust the risk is withrespect to error in the estimation of relevant features. The asymptoticanalysis also provides conditions on the selected features along which the datais split for these estimators to obtain minimax optimal rates of convergencewith respect to the dimension of the relevant feature subspace. Additionally alower bound on the risk of axis-aligned Mondrian trees where features arerestricted to the set of covariates is obtained proving that these estimatorsare suboptimal for these linear dimension reduction models in general nomatter how the distribution over the covariates used to divide the data at eachtree node is weighted.</p>
                <p>Last Updated: 2024-07-02 17:35:22 UTC</p>
                <button class="interpret-button" data-id="2407.02458v1">Interpret</button>
                <div id="interpretation-2407.02458v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Comparative Evaluation of Learning Models for Bionic Robots: Non-Linear Transfer Function Identifications</h3>
                <p>Authors: Po-Yu HsiehJune-Hao Hou</p>
                <p><a href="http://arxiv.org/abs/2407.02428v1">Link to paper</a></p>
                <p>The control and modeling of bionic robot dynamics have increasingly adoptedmodel-free control strategies using machine learning methods. Given thenon-linear elastic nature of bionic robotic systems learning-based methodsprovide reliable alternatives by utilizing numerical data to establish a directmapping from actuation inputs to robot trajectories without complex kinematicsmodels. However for developers the method of identifying an appropriatelearning model for their specific bionic robots and further constructing thetransfer function has not been thoroughly discussed. Thus this research trainsfour types of models including ensemble learning models regularization-basedmodels kernel-based models and neural network models suitable formulti-input multi-output MIMO data and non-linear transfer functionidentification in order to evaluate their 1 accuracy 2 computationcomplexity and 3 performance of capturing biological movements. Thisresearch encompasses data collection methods for control inputs and actionoutputs selection of machine learning models comparative analysis of trainingresults and transfer function identifications. The main objective is toprovide a comprehensive evaluation strategy and framework for the applicationof model-free control.</p>
                <p>Last Updated: 2024-07-02 17:00:23 UTC</p>
                <button class="interpret-button" data-id="2407.02428v1">Interpret</button>
                <div id="interpretation-2407.02428v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Quantum Curriculum Learning</h3>
                <p>Authors: Quoc Hoan TranYasuhiro EndoHirotaka Oshima</p>
                <p><a href="http://arxiv.org/abs/2407.02419v1">Link to paper</a></p>
                <p>Quantum machine learning QML requires significant quantum resources toachieve quantum advantage. Research should prioritize both the efficient designof quantum architectures and the development of learning strategies to optimizeresource usage. We propose a framework called quantum curriculum learningQ-CurL for quantum data where the curriculum introduces simpler tasks ordata to the learning model before progressing to more challenging ones. Wedefine the curriculum criteria based on the data density ratio between tasks todetermine the curriculum order. We also implement a dynamic learning scheduleto emphasize the significance of quantum data in optimizing the loss function.Empirical evidence shows that Q-CurL enhances the training convergence and thegeneralization for unitary learning tasks and improves the robustness ofquantum phase recognition tasks. Our framework provides a general learningstrategy bringing QML closer to realizing practical advantages.</p>
                <p>Last Updated: 2024-07-02 16:44:14 UTC</p>
                <button class="interpret-button" data-id="2407.02419v1">Interpret</button>
                <div id="interpretation-2407.02419v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Magic Insert: Style-Aware Drag-and-Drop</h3>
                <p>Authors: Nataniel RuizYuanzhen LiNeal WadhwaYael PritchMichael RubinsteinDavid E. JacobsShlomi Fruchter</p>
                <p><a href="http://arxiv.org/abs/2407.02489v1">Link to paper</a></p>
                <p>We present Magic Insert a method for dragging-and-dropping subjects from auser-provided image into a target image of a different style in a physicallyplausible manner while matching the style of the target image. This workformalizes the problem of style-aware drag-and-drop and presents a method fortackling it by addressing two sub-problems: style-aware personalization andrealistic object insertion in stylized images. For style-aware personalizationour method first fine-tunes a pretrained text-to-image diffusion model usingLoRA and learned text tokens on the subject image and then infuses it with aCLIP representation of the target style. For object insertion we useBootstrapped Domain Adaption to adapt a domain-specific photorealistic objectinsertion model to the domain of diverse artistic styles. Overall the methodsignificantly outperforms traditional approaches such as inpainting. Finallywe present a dataset SubjectPlop to facilitate evaluation and future progressin this area. Project page: https://magicinsert.github.io/</p>
                <p>Last Updated: 2024-07-02 17:59:50 UTC</p>
                <button class="interpret-button" data-id="2407.02489v1">Interpret</button>
                <div id="interpretation-2407.02489v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>What Should Be Considered to Support well-being with AI: Considerations Based on Responsible Research and Innovation</h3>
                <p>Authors: Yuri Nakao</p>
                <p><a href="http://arxiv.org/abs/2407.02381v2">Link to paper</a></p>
                <p>Achieving peoples well-being with AI systems requires that each user isguided to a healthier lifestyle in a way that is appropriate for her or him.Although well-being has diverse definitionscitecalvo2014positive leading ahealthy lifestyle is one of the most representative aspects of well-being. Ahealthy lifestyle often varies from individual to individual and cannot bedefined in a top-down manner. For example while moderate exercise is importantfor almost everyone how much exercise is needed and at what time of day variesfrom person to person. A habit that is easy for one person may be verydifficult for another. Habits that are too difficult do not lead to a mentallyhealthy lifestyle.</p>
                <p>Last Updated: 2024-07-03 13:59:38 UTC</p>
                <button class="interpret-button" data-id="2407.02381v2">Interpret</button>
                <div id="interpretation-2407.02381v2" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Talking to Machines: do you read me?</h3>
                <p>Authors: Lina M. Rojas-Barahona</p>
                <p><a href="http://arxiv.org/abs/2407.02354v1">Link to paper</a></p>
                <p>In this dissertation I would like to guide the reader to the research ondialogue but more precisely the research I have conducted during my careersince my PhD thesis. Starting from modular architectures with machinelearning/deep learning and reinforcement learning to end-to-end deep neuralnetworks. Besides my work as research associate I also present the work I havesupervised in the last years.  I review briefly the state of the art and highlight the open researchproblems on conversational agents. Afterwards I present my contribution toTask-Oriented Dialogues TOD both as research associate and as the industrialsupervisor of CIFRE theses. I discuss conversational QA. Particularly Ipresent the work of two PhD candidates Thibault Cordier and Sebastien Montellaas well as the work of the young researcher Quentin Brabant. Finally I presentthe scientific project where I discuss about Large Language Models LLMs forTask-Oriented Dialogue and Multimodal Task-Oriented Dialogue.</p>
                <p>Last Updated: 2024-07-02 15:19:46 UTC</p>
                <button class="interpret-button" data-id="2407.02354v1">Interpret</button>
                <div id="interpretation-2407.02354v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The Equality Maturity Model: an actionable tool to advance gender balance in leadership and participation roles</h3>
                <p>Authors: Paloma DíazPaula Alexandra SilvaKatja Tuma</p>
                <p><a href="http://arxiv.org/abs/2407.02305v1">Link to paper</a></p>
                <p>The underrepresentation of women in Computer Science and Engineering is apervasive issue impacting the enrolment and graduation rates of femalestudents as well as the presence of women in leadership positions in academiaand industry. The European Network For Gender Balance in Informatics EUGAINCOST action seeks to share data experiences best practices and lessons fromfailures and to provide actionable tools that may contribute to theadvancement of gender balance in the field. This paper summarises results fromthe Ph.D./Postdoc to Professor workgroup that were gathered in two booklets ofbest practices. Specifically we introduce the Equality Maturity Model EMM aconceptual tool aimed at supporting organisations in measuring how they aredoing concerning equality and identifying potential areas of improvement andthat was inspired by both booklets.</p>
                <p>Last Updated: 2024-07-02 14:41:07 UTC</p>
                <button class="interpret-button" data-id="2407.02305v1">Interpret</button>
                <div id="interpretation-2407.02305v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>IFTT-PIN: A Self-Calibrating PIN-Entry Method</h3>
                <p>Authors: Kathryn McConkeyTalha Enes AyranciMohamed KhamisJonathan Grizou</p>
                <p><a href="http://arxiv.org/abs/2407.02269v1">Link to paper</a></p>
                <p>Personalising an interface to the needs and preferences of a user oftenincurs additional interaction steps. In this paper we demonstrate a novelmethod that enables the personalising of an interface without the need forexplicit calibration procedures via a process we call self-calibration. Asecond-order effect of self-calibration is that an outside observer cannoteasily infer what a user is trying to achieve because they cannot interpret theusers actions. To explore this security angle we developed IFTT-PIN If ThisThen PIN as the first self-calibrating PIN-entry method. When using IFTT-PINusers are free to choose any button for any meaning without ever explicitlycommunicating their choice to the machine. IFTT-PIN infers both the users PINand their preferred button mapping at the same time. This paper presents theconcept implementation and interactive demonstrations of IFTT-PIN as well asan evaluation against shoulder surfing attacks. Our study N24 shows that byadding self-calibration to an existing PIN entry method IFTT-PIN statisticallysignificantly decreased PIN attack decoding rate by ca. 8.5 times p1.1e-9while only decreasing the PIN entry encoding rate by ca. 1.4 times p0.02leading to a positive security-usability trade-off. IFTT-PINs entry ratesignificantly improved 21 days after first exposure p3.6e-6 to the methodsuggesting self-calibrating interfaces are memorable despite using an initiallyundefined user interface. Self-calibration methods might lead to novelopportunities for interaction that are more inclusive and versatile apotentially interesting challenge for the community. A short introductory videois available at https://youtu.be/pP5sfniNRns.</p>
                <p>Last Updated: 2024-07-02 13:58:28 UTC</p>
                <button class="interpret-button" data-id="2407.02269v1">Interpret</button>
                <div id="interpretation-2407.02269v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>Magic Insert: Style-Aware Drag-and-Drop</h3>
                <p>Authors: Nataniel RuizYuanzhen LiNeal WadhwaYael PritchMichael RubinsteinDavid E. JacobsShlomi Fruchter</p>
                <p><a href="http://arxiv.org/abs/2407.02489v1">Link to paper</a></p>
                <p>We present Magic Insert a method for dragging-and-dropping subjects from auser-provided image into a target image of a different style in a physicallyplausible manner while matching the style of the target image. This workformalizes the problem of style-aware drag-and-drop and presents a method fortackling it by addressing two sub-problems: style-aware personalization andrealistic object insertion in stylized images. For style-aware personalizationour method first fine-tunes a pretrained text-to-image diffusion model usingLoRA and learned text tokens on the subject image and then infuses it with aCLIP representation of the target style. For object insertion we useBootstrapped Domain Adaption to adapt a domain-specific photorealistic objectinsertion model to the domain of diverse artistic styles. Overall the methodsignificantly outperforms traditional approaches such as inpainting. Finallywe present a dataset SubjectPlop to facilitate evaluation and future progressin this area. Project page: https://magicinsert.github.io/</p>
                <p>Last Updated: 2024-07-02 17:59:50 UTC</p>
                <button class="interpret-button" data-id="2407.02489v1">Interpret</button>
                <div id="interpretation-2407.02489v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Characterizing the Interpretability of Attention Maps in Digital Pathology</h3>
                <p>Authors: Tomé AlbuquerqueAnil YüceMarkus D. HerrmannAlvaro Gomariz</p>
                <p><a href="http://arxiv.org/abs/2407.02484v1">Link to paper</a></p>
                <p>Interpreting machine learning model decisions is crucial for high-riskapplications like healthcare. In digital pathology large whole slide imagesWSIs are decomposed into smaller tiles and tile-derived features areprocessed by attention-based multiple instance learning ABMIL models topredict WSI-level labels. These networks generate tile-specific attentionweights which can be visualized as attention maps for interpretability.However a standardized evaluation framework for these maps is lackingquestioning their reliability and ability to detect spurious correlations thatcan mislead models. We herein propose a framework to assess the ability ofattention networks to attend to relevant features in digital pathology bycreating artificial model confounders and using dedicated interpretabilitymetrics. Models are trained and evaluated on data with tile modificationscorrelated with WSI labels enabling the analysis of model sensitivity toartificial confounders and the accuracy of attention maps in highlighting them.Confounders are introduced either through synthetic tile modifications orthrough tile ablations based on their specific image-based features with thelatter being used to assess more clinically relevant scenarios. We also analyzethe impact of varying confounder quantities at both the tile and WSI levels.Our results show that ABMIL models perform as desired within our framework.While attention maps generally highlight relevant regions their robustness isaffected by the type and number of confounders. Our versatile framework has thepotential to be used in the evaluation of various methods and the explorationof image-based features driving model predictions which could aid in biomarkerdiscovery.</p>
                <p>Last Updated: 2024-07-02 17:58:58 UTC</p>
                <button class="interpret-button" data-id="2407.02484v1">Interpret</button>
                <div id="interpretation-2407.02484v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Boosting Consistency in Story Visualization with Rich-Contextual Conditional Diffusion Models</h3>
                <p>Authors: Fei ShenHu YeSibo LiuJun ZhangCong WangXiao HanWei Yang</p>
                <p><a href="http://arxiv.org/abs/2407.02482v1">Link to paper</a></p>
                <p>Recent research showcases the considerable potential of conditional diffusionmodels for generating consistent stories. However current methods whichpredominantly generate stories in an autoregressive and excessivelycaption-dependent manner often underrate the contextual consistency andrelevance of frames during sequential generation. To address this we propose anovel Rich-contextual Conditional Diffusion Models RCDMs a two-stageapproach designed to enhance story generations semantic consistency andtemporal consistency. Specifically in the first stage the frame-priortransformer diffusion model is presented to predict the frame semanticembedding of the unknown clip by aligning the semantic correlations between thecaptions and frames of the known clip. The second stage establishes a robustmodel with rich contextual conditions including reference images of the knownclip the predicted frame semantic embedding of the unknown clip and textembeddings of all captions. By jointly injecting these rich contextualconditions at the image and feature levels RCDMs can generate semantic andtemporal consistency stories. Moreover RCDMs can generate consistent storieswith a single forward inference compared to autoregressive models. Ourqualitative and quantitative results demonstrate that our proposed RCDMsoutperform in challenging scenarios. The code and model will be available athttps://github.com/muzishen/RCDMs.</p>
                <p>Last Updated: 2024-07-02 17:58:07 UTC</p>
                <button class="interpret-button" data-id="2407.02482v1">Interpret</button>
                <div id="interpretation-2407.02482v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Understanding Alignment in Multimodal LLMs: A Comprehensive Study</h3>
                <p>Authors: Elmira AmirlooJean-Philippe FauconnierChristoph RoesmannChristian KerlRinu BoneyYusu QianZirui WangAfshin DehghanYinfei YangZhe GanPeter Grasch</p>
                <p><a href="http://arxiv.org/abs/2407.02477v1">Link to paper</a></p>
                <p>Preference alignment has become a crucial component in enhancing theperformance of Large Language Models LLMs yet its impact in Multimodal LargeLanguage Models MLLMs remains comparatively underexplored. Similar tolanguage models MLLMs for image understanding tasks encounter challenges likehallucination. In MLLMs hallucination can occur not only by stating incorrectfacts but also by producing responses that are inconsistent with the imagecontent. A primary objective of alignment for MLLMs is to encourage thesemodels to align responses more closely with image information. Recentlymultiple works have introduced preference datasets for MLLMs and examineddifferent alignment methods including Direct Preference Optimization DPO andProximal Policy Optimization PPO. However due to variations in datasetsbase model types and alignment methods it remains unclear which specificelements contribute most significantly to the reported improvements in theseworks. In this paper we independently analyze each aspect of preferencealignment in MLLMs. We start by categorizing the alignment algorithms into twogroups offline such as DPO and online such as online-DPO and show thatcombining offline and online methods can improve the performance of the modelin certain scenarios. We review a variety of published multimodal preferencedatasets and discuss how the details of their construction impact modelperformance. Based on these insights we introduce a novel way of creatingmultimodal preference data called Bias-Driven Hallucination Sampling BDHSthat needs neither additional annotation nor external models and show that itcan achieve competitive performance to previously published alignment work formultimodal models across a range of benchmarks.</p>
                <p>Last Updated: 2024-07-02 17:55:03 UTC</p>
                <button class="interpret-button" data-id="2407.02477v1">Interpret</button>
                <div id="interpretation-2407.02477v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>SUPER: Seated Upper Body Pose Estimation using mmWave Radars</h3>
                <p>Authors: Bo ZhangZimeng ZhouBoyu JiangRong Zheng</p>
                <p><a href="http://dx.doi.org/10.1109/IoTDI61053.2024.00020">Link to paper</a></p>
                <p>In industrial countries adults spend a considerable amount of time sedentaryeach day at work driving and during activities of daily living. Characterizingthe seated upper body human poses using mmWave radars is an important yetunder-studied topic with many applications in human-machine interactiontransportation and road safety. In this work we devise SUPER a framework forseated upper body human pose estimation that utilizes dual-mmWave radars inclose proximity. A novel masking algorithm is proposed to coherently fuse datafrom the radars to generate intensity and Doppler point clouds withcomplementary information for high-motion but small radar cross section arease.g. upper extremities and low-motion but large RCS areas e.g. torso. Alightweight neural network extracts both global and local features of upperbody and output pose parameters for the Skinned Multi-Person Linear SMPLmodel. Extensive leave-one-subject-out experiments on various motion sequencesfrom multiple subjects show that SUPER outperforms a state-of-the-art baselinemethod by 30 -- 184. We also demonstrate its utility in a simple downstreamtask for hand-object interaction.</p>
                <p>Last Updated: 2024-07-02 17:32:34 UTC</p>
                <button class="interpret-button" data-id="2407.02455v1">Interpret</button>
                <div id="interpretation-2407.02455v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>Magic Insert: Style-Aware Drag-and-Drop</h3>
                <p>Authors: Nataniel RuizYuanzhen LiNeal WadhwaYael PritchMichael RubinsteinDavid E. JacobsShlomi Fruchter</p>
                <p><a href="http://arxiv.org/abs/2407.02489v1">Link to paper</a></p>
                <p>We present Magic Insert a method for dragging-and-dropping subjects from auser-provided image into a target image of a different style in a physicallyplausible manner while matching the style of the target image. This workformalizes the problem of style-aware drag-and-drop and presents a method fortackling it by addressing two sub-problems: style-aware personalization andrealistic object insertion in stylized images. For style-aware personalizationour method first fine-tunes a pretrained text-to-image diffusion model usingLoRA and learned text tokens on the subject image and then infuses it with aCLIP representation of the target style. For object insertion we useBootstrapped Domain Adaption to adapt a domain-specific photorealistic objectinsertion model to the domain of diverse artistic styles. Overall the methodsignificantly outperforms traditional approaches such as inpainting. Finallywe present a dataset SubjectPlop to facilitate evaluation and future progressin this area. Project page: https://magicinsert.github.io/</p>
                <p>Last Updated: 2024-07-02 17:59:50 UTC</p>
                <button class="interpret-button" data-id="2407.02489v1">Interpret</button>
                <div id="interpretation-2407.02489v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Neurocache: Efficient Vector Retrieval for Long-range Language Modeling</h3>
                <p>Authors: Ali SafayaDeniz Yuret</p>
                <p><a href="http://arxiv.org/abs/2407.02486v1">Link to paper</a></p>
                <p>This paper introduces Neurocache an approach to extend the effective contextsize of large language models LLMs using an external vector cache to storeits past states. Like recent vector retrieval approaches Neurocache uses anefficient k-nearest-neighbor kNN algorithm to retrieve relevant past statesand incorporate them into the attention process. Neurocache improves uponprevious methods by 1 storing compressed states which reduces cache size2 performing a single retrieval operation per token which increases inferencespeed and 3 extending the retrieval window to neighboring states whichimproves both language modeling and downstream task accuracy. Our experimentsshow the effectiveness of Neurocache both for models trained from scratch andfor pre-trained models such as Llama2-7B and Mistral-7B when enhanced with thecache mechanism. We also compare Neurocache with text retrieval methods andshow improvements in single-document question-answering and few-shot learningtasks. We made the source code available under:https://github.com/alisafaya/neurocache</p>
                <p>Last Updated: 2024-07-02 17:59:29 UTC</p>
                <button class="interpret-button" data-id="2407.02486v1">Interpret</button>
                <div id="interpretation-2407.02486v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs</h3>
                <p>Authors: Yue YuWei PingZihan LiuBoxin WangJiaxuan YouChao ZhangMohammad ShoeybiBryan Catanzaro</p>
                <p><a href="http://arxiv.org/abs/2407.02485v1">Link to paper</a></p>
                <p>Large language models LLMs typically utilize the top-k contexts from aretriever in retrieval-augmented generation RAG. In this work we propose anovel instruction fine-tuning framework RankRAG which instruction-tunes asingle LLM for the dual purpose of context ranking and answer generation inRAG. In particular the instruction-tuned LLMs work surprisingly well by addinga small fraction of ranking data into the training blend and outperformexisting expert ranking models including the same LLM exclusively fine-tunedon a large amount of ranking data. For generation we compare our model withmany strong baselines including GPT-4-0613 GPT-4-turbo-2024-0409 andChatQA-1.5 an open-sourced model with the state-of-the-art performance on RAGbenchmarks. Specifically our Llama3-RankRAG significantly outperformsLlama3-ChatQA-1.5 and GPT-4 models on nine knowledge-intensive benchmarks. Inaddition it also performs comparably to GPT-4 on five RAG benchmarks in thebiomedical domain without instruction fine-tuning on biomedical datademonstrating its superb capability for generalization to new domains.</p>
                <p>Last Updated: 2024-07-02 17:59:17 UTC</p>
                <button class="interpret-button" data-id="2407.02485v1">Interpret</button>
                <div id="interpretation-2407.02485v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>MMedAgent: Learning to Use Medical Tools with Multi-modal Agent</h3>
                <p>Authors: Binxu LiTiankai YanYuanting PanZhe XuJie LuoRuiyang JiShilong LiuHaoyu DongZihao LinYixin Wang</p>
                <p><a href="http://arxiv.org/abs/2407.02483v1">Link to paper</a></p>
                <p>Multi-Modal Large Language Models MLLMs despite being successful exhibitlimited generality and often fall short when compared to specialized models.Recently LLM-based agents have been developed to address these challenges byselecting appropriate specialized models as tools based on user inputs.However such advancements have not been extensively explored within themedical domain. To bridge this gap this paper introduces the first agentexplicitly designed for the medical field named textbfMulti-modaltextbfMedical textbfAgent MMedAgent. We curate an instruction-tuningdataset comprising six medical tools solving seven tasks enabling the agent tochoose the most suitable tools for a given task. Comprehensive experimentsdemonstrate that MMedAgent achieves superior performance across a variety ofmedical tasks compared to state-of-the-art open-source methods and even theclosed-source model GPT-4o. Furthermore MMedAgent exhibits efficiency inupdating and integrating new medical tools.</p>
                <p>Last Updated: 2024-07-02 17:58:23 UTC</p>
                <button class="interpret-button" data-id="2407.02483v1">Interpret</button>
                <div id="interpretation-2407.02483v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Free Energy in a Circumplex Model of Emotion</h3>
                <p>Authors: Candice PattisapuTim VerbelenRiddhi J. PitliyaAlex B. KieferMahault Albarracin</p>
                <p><a href="http://arxiv.org/abs/2407.02474v1">Link to paper</a></p>
                <p>Previous active inference accounts of emotion translate fluctuations in freeenergy to a sense of emotion mainly focusing on valence. However in affectivescience emotions are often represented as multi-dimensional. In this paper wepropose to adopt a Circumplex Model of emotion by mapping emotions into atwo-dimensional spectrum of valence and arousal. We show how one can derive avalence and arousal signal from an agents expected free energy relatingarousal to the entropy of posterior beliefs and valence to utility lessexpected utility. Under this formulation we simulate artificial agents engagedin a search task. We show that the manipulation of priors and object presenceresults in commonsense variability in emotional states.</p>
                <p>Last Updated: 2024-07-02 17:52:25 UTC</p>
                <button class="interpret-button" data-id="2407.02474v1">Interpret</button>
                <div id="interpretation-2407.02474v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention</h3>
                <p>Authors: Huiqiang JiangYucheng LiChengruidong ZhangQianhui WuXufang LuoSurin AhnZhenhua HanAmir H. AbdiDongsheng LiChin-Yew LinYuqing YangLili Qiu</p>
                <p><a href="http://arxiv.org/abs/2407.02490v1">Link to paper</a></p>
                <p>The computational challenges of Large Language Model LLM inference remain asignificant barrier to their widespread deployment especially as promptlengths continue to increase. Due to the quadratic complexity of the attentioncomputation it takes 30 minutes for an 8B LLM to process a prompt of 1M tokensi.e. the pre-filling stage on a single A100 GPU. Existing methods forspeeding up prefilling often fail to maintain acceptable accuracy or efficiencywhen applied to long-context LLMs. To address this gap we introduce MInferenceMilliontokens Inference a sparse calculation method designed to acceleratepre-filling of long-sequence processing. Specifically we identify three uniquepatterns in long-context attention matrices-the A-shape Vertical-Slash andBlock-Sparsethat can be leveraged for efficient sparse computation on GPUs. Wedetermine the optimal pattern for each attention head offline and dynamicallybuild sparse indices based on the assigned pattern during inference. With thepattern and sparse indices we perform efficient sparse attention calculationsvia our optimized GPU kernels to significantly reduce the latency in thepre-filling stage of long-context LLMs. Our proposed technique can be directlyapplied to existing LLMs without any modifications to the pre-training setup oradditional fine-tuning. By evaluating on a wide range of downstream tasksincluding InfiniteBench RULER PG-19 and Needle In A Haystack and modelsincluding LLaMA-3-1M GLM4-1M Yi-200K Phi-3-128K and Qwen2-128K wedemonstrate that MInference effectively reduces inference latency by up to 10xfor pre-filling on an A100 while maintaining accuracy. Our code is availableat https://aka.ms/MInference.</p>
                <p>Last Updated: 2024-07-02 17:59:56 UTC</p>
                <button class="interpret-button" data-id="2407.02490v1">Interpret</button>
                <div id="interpretation-2407.02490v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Neurocache: Efficient Vector Retrieval for Long-range Language Modeling</h3>
                <p>Authors: Ali SafayaDeniz Yuret</p>
                <p><a href="http://arxiv.org/abs/2407.02486v1">Link to paper</a></p>
                <p>This paper introduces Neurocache an approach to extend the effective contextsize of large language models LLMs using an external vector cache to storeits past states. Like recent vector retrieval approaches Neurocache uses anefficient k-nearest-neighbor kNN algorithm to retrieve relevant past statesand incorporate them into the attention process. Neurocache improves uponprevious methods by 1 storing compressed states which reduces cache size2 performing a single retrieval operation per token which increases inferencespeed and 3 extending the retrieval window to neighboring states whichimproves both language modeling and downstream task accuracy. Our experimentsshow the effectiveness of Neurocache both for models trained from scratch andfor pre-trained models such as Llama2-7B and Mistral-7B when enhanced with thecache mechanism. We also compare Neurocache with text retrieval methods andshow improvements in single-document question-answering and few-shot learningtasks. We made the source code available under:https://github.com/alisafaya/neurocache</p>
                <p>Last Updated: 2024-07-02 17:59:29 UTC</p>
                <button class="interpret-button" data-id="2407.02486v1">Interpret</button>
                <div id="interpretation-2407.02486v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs</h3>
                <p>Authors: Yue YuWei PingZihan LiuBoxin WangJiaxuan YouChao ZhangMohammad ShoeybiBryan Catanzaro</p>
                <p><a href="http://arxiv.org/abs/2407.02485v1">Link to paper</a></p>
                <p>Large language models LLMs typically utilize the top-k contexts from aretriever in retrieval-augmented generation RAG. In this work we propose anovel instruction fine-tuning framework RankRAG which instruction-tunes asingle LLM for the dual purpose of context ranking and answer generation inRAG. In particular the instruction-tuned LLMs work surprisingly well by addinga small fraction of ranking data into the training blend and outperformexisting expert ranking models including the same LLM exclusively fine-tunedon a large amount of ranking data. For generation we compare our model withmany strong baselines including GPT-4-0613 GPT-4-turbo-2024-0409 andChatQA-1.5 an open-sourced model with the state-of-the-art performance on RAGbenchmarks. Specifically our Llama3-RankRAG significantly outperformsLlama3-ChatQA-1.5 and GPT-4 models on nine knowledge-intensive benchmarks. Inaddition it also performs comparably to GPT-4 on five RAG benchmarks in thebiomedical domain without instruction fine-tuning on biomedical datademonstrating its superb capability for generalization to new domains.</p>
                <p>Last Updated: 2024-07-02 17:59:17 UTC</p>
                <button class="interpret-button" data-id="2407.02485v1">Interpret</button>
                <div id="interpretation-2407.02485v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>MMedAgent: Learning to Use Medical Tools with Multi-modal Agent</h3>
                <p>Authors: Binxu LiTiankai YanYuanting PanZhe XuJie LuoRuiyang JiShilong LiuHaoyu DongZihao LinYixin Wang</p>
                <p><a href="http://arxiv.org/abs/2407.02483v1">Link to paper</a></p>
                <p>Multi-Modal Large Language Models MLLMs despite being successful exhibitlimited generality and often fall short when compared to specialized models.Recently LLM-based agents have been developed to address these challenges byselecting appropriate specialized models as tools based on user inputs.However such advancements have not been extensively explored within themedical domain. To bridge this gap this paper introduces the first agentexplicitly designed for the medical field named textbfMulti-modaltextbfMedical textbfAgent MMedAgent. We curate an instruction-tuningdataset comprising six medical tools solving seven tasks enabling the agent tochoose the most suitable tools for a given task. Comprehensive experimentsdemonstrate that MMedAgent achieves superior performance across a variety ofmedical tasks compared to state-of-the-art open-source methods and even theclosed-source model GPT-4o. Furthermore MMedAgent exhibits efficiency inupdating and integrating new medical tools.</p>
                <p>Last Updated: 2024-07-02 17:58:23 UTC</p>
                <button class="interpret-button" data-id="2407.02483v1">Interpret</button>
                <div id="interpretation-2407.02483v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Understanding Alignment in Multimodal LLMs: A Comprehensive Study</h3>
                <p>Authors: Elmira AmirlooJean-Philippe FauconnierChristoph RoesmannChristian KerlRinu BoneyYusu QianZirui WangAfshin DehghanYinfei YangZhe GanPeter Grasch</p>
                <p><a href="http://arxiv.org/abs/2407.02477v1">Link to paper</a></p>
                <p>Preference alignment has become a crucial component in enhancing theperformance of Large Language Models LLMs yet its impact in Multimodal LargeLanguage Models MLLMs remains comparatively underexplored. Similar tolanguage models MLLMs for image understanding tasks encounter challenges likehallucination. In MLLMs hallucination can occur not only by stating incorrectfacts but also by producing responses that are inconsistent with the imagecontent. A primary objective of alignment for MLLMs is to encourage thesemodels to align responses more closely with image information. Recentlymultiple works have introduced preference datasets for MLLMs and examineddifferent alignment methods including Direct Preference Optimization DPO andProximal Policy Optimization PPO. However due to variations in datasetsbase model types and alignment methods it remains unclear which specificelements contribute most significantly to the reported improvements in theseworks. In this paper we independently analyze each aspect of preferencealignment in MLLMs. We start by categorizing the alignment algorithms into twogroups offline such as DPO and online such as online-DPO and show thatcombining offline and online methods can improve the performance of the modelin certain scenarios. We review a variety of published multimodal preferencedatasets and discuss how the details of their construction impact modelperformance. Based on these insights we introduce a novel way of creatingmultimodal preference data called Bias-Driven Hallucination Sampling BDHSthat needs neither additional annotation nor external models and show that itcan achieve competitive performance to previously published alignment work formultimodal models across a range of benchmarks.</p>
                <p>Last Updated: 2024-07-02 17:55:03 UTC</p>
                <button class="interpret-button" data-id="2407.02477v1">Interpret</button>
                <div id="interpretation-2407.02477v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention</h3>
                <p>Authors: Huiqiang JiangYucheng LiChengruidong ZhangQianhui WuXufang LuoSurin AhnZhenhua HanAmir H. AbdiDongsheng LiChin-Yew LinYuqing YangLili Qiu</p>
                <p><a href="http://arxiv.org/abs/2407.02490v1">Link to paper</a></p>
                <p>The computational challenges of Large Language Model LLM inference remain asignificant barrier to their widespread deployment especially as promptlengths continue to increase. Due to the quadratic complexity of the attentioncomputation it takes 30 minutes for an 8B LLM to process a prompt of 1M tokensi.e. the pre-filling stage on a single A100 GPU. Existing methods forspeeding up prefilling often fail to maintain acceptable accuracy or efficiencywhen applied to long-context LLMs. To address this gap we introduce MInferenceMilliontokens Inference a sparse calculation method designed to acceleratepre-filling of long-sequence processing. Specifically we identify three uniquepatterns in long-context attention matrices-the A-shape Vertical-Slash andBlock-Sparsethat can be leveraged for efficient sparse computation on GPUs. Wedetermine the optimal pattern for each attention head offline and dynamicallybuild sparse indices based on the assigned pattern during inference. With thepattern and sparse indices we perform efficient sparse attention calculationsvia our optimized GPU kernels to significantly reduce the latency in thepre-filling stage of long-context LLMs. Our proposed technique can be directlyapplied to existing LLMs without any modifications to the pre-training setup oradditional fine-tuning. By evaluating on a wide range of downstream tasksincluding InfiniteBench RULER PG-19 and Needle In A Haystack and modelsincluding LLaMA-3-1M GLM4-1M Yi-200K Phi-3-128K and Qwen2-128K wedemonstrate that MInference effectively reduces inference latency by up to 10xfor pre-filling on an A100 while maintaining accuracy. Our code is availableat https://aka.ms/MInference.</p>
                <p>Last Updated: 2024-07-02 17:59:56 UTC</p>
                <button class="interpret-button" data-id="2407.02490v1">Interpret</button>
                <div id="interpretation-2407.02490v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Magic Insert: Style-Aware Drag-and-Drop</h3>
                <p>Authors: Nataniel RuizYuanzhen LiNeal WadhwaYael PritchMichael RubinsteinDavid E. JacobsShlomi Fruchter</p>
                <p><a href="http://arxiv.org/abs/2407.02489v1">Link to paper</a></p>
                <p>We present Magic Insert a method for dragging-and-dropping subjects from auser-provided image into a target image of a different style in a physicallyplausible manner while matching the style of the target image. This workformalizes the problem of style-aware drag-and-drop and presents a method fortackling it by addressing two sub-problems: style-aware personalization andrealistic object insertion in stylized images. For style-aware personalizationour method first fine-tunes a pretrained text-to-image diffusion model usingLoRA and learned text tokens on the subject image and then infuses it with aCLIP representation of the target style. For object insertion we useBootstrapped Domain Adaption to adapt a domain-specific photorealistic objectinsertion model to the domain of diverse artistic styles. Overall the methodsignificantly outperforms traditional approaches such as inpainting. Finallywe present a dataset SubjectPlop to facilitate evaluation and future progressin this area. Project page: https://magicinsert.github.io/</p>
                <p>Last Updated: 2024-07-02 17:59:50 UTC</p>
                <button class="interpret-button" data-id="2407.02489v1">Interpret</button>
                <div id="interpretation-2407.02489v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Neurocache: Efficient Vector Retrieval for Long-range Language Modeling</h3>
                <p>Authors: Ali SafayaDeniz Yuret</p>
                <p><a href="http://arxiv.org/abs/2407.02486v1">Link to paper</a></p>
                <p>This paper introduces Neurocache an approach to extend the effective contextsize of large language models LLMs using an external vector cache to storeits past states. Like recent vector retrieval approaches Neurocache uses anefficient k-nearest-neighbor kNN algorithm to retrieve relevant past statesand incorporate them into the attention process. Neurocache improves uponprevious methods by 1 storing compressed states which reduces cache size2 performing a single retrieval operation per token which increases inferencespeed and 3 extending the retrieval window to neighboring states whichimproves both language modeling and downstream task accuracy. Our experimentsshow the effectiveness of Neurocache both for models trained from scratch andfor pre-trained models such as Llama2-7B and Mistral-7B when enhanced with thecache mechanism. We also compare Neurocache with text retrieval methods andshow improvements in single-document question-answering and few-shot learningtasks. We made the source code available under:https://github.com/alisafaya/neurocache</p>
                <p>Last Updated: 2024-07-02 17:59:29 UTC</p>
                <button class="interpret-button" data-id="2407.02486v1">Interpret</button>
                <div id="interpretation-2407.02486v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs</h3>
                <p>Authors: Yue YuWei PingZihan LiuBoxin WangJiaxuan YouChao ZhangMohammad ShoeybiBryan Catanzaro</p>
                <p><a href="http://arxiv.org/abs/2407.02485v1">Link to paper</a></p>
                <p>Large language models LLMs typically utilize the top-k contexts from aretriever in retrieval-augmented generation RAG. In this work we propose anovel instruction fine-tuning framework RankRAG which instruction-tunes asingle LLM for the dual purpose of context ranking and answer generation inRAG. In particular the instruction-tuned LLMs work surprisingly well by addinga small fraction of ranking data into the training blend and outperformexisting expert ranking models including the same LLM exclusively fine-tunedon a large amount of ranking data. For generation we compare our model withmany strong baselines including GPT-4-0613 GPT-4-turbo-2024-0409 andChatQA-1.5 an open-sourced model with the state-of-the-art performance on RAGbenchmarks. Specifically our Llama3-RankRAG significantly outperformsLlama3-ChatQA-1.5 and GPT-4 models on nine knowledge-intensive benchmarks. Inaddition it also performs comparably to GPT-4 on five RAG benchmarks in thebiomedical domain without instruction fine-tuning on biomedical datademonstrating its superb capability for generalization to new domains.</p>
                <p>Last Updated: 2024-07-02 17:59:17 UTC</p>
                <button class="interpret-button" data-id="2407.02485v1">Interpret</button>
                <div id="interpretation-2407.02485v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Scalable Multi-Output Gaussian Processes with Stochastic Variational Inference</h3>
                <p>Authors: Xiaoyu JiangSokratia GeorgakaMagnus RattrayMauricio A. Alvarez</p>
                <p><a href="http://arxiv.org/abs/2407.02476v1">Link to paper</a></p>
                <p>The Multi-Output Gaussian Process is is a popular tool for modelling datafrom multiple sources. A typical choice to build a covariance function for aMOGP is the Linear Model of Coregionalization LMC which parametrically modelsthe covariance between outputs. The Latent Variable MOGP LV-MOGP generalisesthis idea by modelling the covariance between outputs using a kernel applied tolatent variables one per output leading to a flexible MOGP model that allowsefficient generalization to new outputs with few data points. Computationalcomplexity in LV-MOGP grows linearly with the number of outputs which makes itunsuitable for problems with a large number of outputs. In this paper wepropose a stochastic variational inference approach for the LV-MOGP that allowsmini-batches for both inputs and outputs making computational complexity pertraining iteration independent of the number of outputs.</p>
                <p>Last Updated: 2024-07-02 17:53:56 UTC</p>
                <button class="interpret-button" data-id="2407.02476v1">Interpret</button>
                <div id="interpretation-2407.02476v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>Impact of the Network Size and Frequency of Information Receipt on Polarization in Social Networks</h3>
                <p>Authors: Sudhakar KrisharaoShaja Arul Selvamani</p>
                <p><a href="http://dx.doi.org/10.1155/2024/4742401">Link to paper</a></p>
                <p>Opinion Dynamics is an interdisciplinary area of research. Psychology andSociology have proposed models of how individuals form opinions and how socialinteractions influence this process. Socio-Physicists have interpreted patternsin opinion formation as arising from non-linearity in the underlying processshaping the models. Agent-based modeling has offered a platform to study theOpinion Dynamics of large groups. This paper recasts recent models in opinionformation into a proper dynamical system injecting the idea of clock time intoevolving opinions. The time interval between successive receipts of newinformation frequency of information receipts becomes a factor to study.Social media has shrunk time intervals between information receipts increasingtheir frequency. The recast models show that shorter intervals and largernetworks increase an individuals propensity for polarization defined as aninability to hold a neutral opinion. A Polarization number based onsociological parameters is proposed with critical values beyond whichindividuals are prone to polarization depending on psychological parameters.Reduced time intervals and larger interacting groups can push the Polarizationnumber to critical values contributing to polarization. The Extent ofPolarization is defined as the width of the region around neutral within whichan individual cannot hold an opinion. Results are reported for model parametersfound in the literature. The findings offer an opportunity to adjust modelparameters to align with empirical evidence aiding the study of OpinionDynamics in large social networks using Agent-Based Modeling.</p>
                <p>Last Updated: 2024-07-01 20:30:04 UTC</p>
                <button class="interpret-button" data-id="2407.01788v1">Interpret</button>
                <div id="interpretation-2407.01788v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Distributed Instruments for Planetary Surface Science: Scientific Opportunities and Technology Feasibility</h3>
                <p>Authors: Federico RossiRobert C. AndersonSaptarshi BandyopadhyayErik BrandonAshish GoelJoshua Vander HookMichael MischnaMichaela VillarrealMark Wronkiewicz</p>
                <p><a href="http://arxiv.org/abs/2407.01757v1">Link to paper</a></p>
                <p>In this paper we assess the scientific promise and technology feasibility ofdistributed instruments for planetary science. A distributed instrument is aninstrument designed to collect spatially and temporally correlated data frommultiple networked geographically distributed point sensors. Distributedinstruments are ubiquitous in Earth science where they are routinely employedfor weather and climate science seismic studies and resource prospecting anddetection of industrial emissions. However to date their adoption inplanetary surface science has been minimal. It is natural to ask whether thislack of adoption is driven by low potential to address high-priority questionsin planetary science immature technology or both. To address this questionwe survey high-priority planetary science questions that are uniquelywell-suited to distributed instruments. We identify four areas of researchwhere distributed instruments hold promise to unlock answers that are largelyinaccessible to monolithic sensors namely weather and climate studies ofMars localization of seismic events on rocky and icy bodies localization oftrace gas emissions primarily on Mars and magnetometry studies of internalcomposition. Next we survey enabling technologies for distributed sensors andassess their maturity. We identify sensor placement including descent andlanding on planetary surfaces power and instrument autonomy as three keyareas requiring further investment to enable future distributed instruments.Overall this work shows that distributed instruments hold great promise forplanetary science and paves the way for follow-on studies of futuredistributed instruments for Solar System in-situ science.</p>
                <p>Last Updated: 2024-07-01 19:41:41 UTC</p>
                <button class="interpret-button" data-id="2407.01757v1">Interpret</button>
                <div id="interpretation-2407.01757v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Online Learning of Temporal Dependencies for Sustainable Foraging Problem</h3>
                <p>Authors: John PayneAishwaryaprajnaPeter R. Lewis</p>
                <p><a href="http://arxiv.org/abs/2407.01501v1">Link to paper</a></p>
                <p>The sustainable foraging problem is a dynamic environment testbed forexploring the forms of agent cognition in dealing with social dilemmas in amulti-agent setting. The agents need to resist the temptation of individualrewards through foraging and choose the collective long-term goal ofsustainability. We investigate methods of online learning in Neuro-Evolutionand Deep Recurrent Q-Networks to enable agents to attempt the problem one-shotas is often required by wicked social problems. We further explore if learningtemporal dependencies with Long Short-Term Memory may be able to aid the agentsin developing sustainable foraging strategies in the long term. It was foundthat the integration of Long Short-Term Memory assisted agents in developingsustainable strategies for a single agent however failed to assist agents inmanaging the social dilemma that arises in the multi-agent scenario.</p>
                <p>Last Updated: 2024-07-01 17:47:31 UTC</p>
                <button class="interpret-button" data-id="2407.01501v1">Interpret</button>
                <div id="interpretation-2407.01501v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Optimizing Age of Information in Vehicular Edge Computing with Federated Graph Neural Network Multi-Agent Reinforcement Learning</h3>
                <p>Authors: Wenhua WangQiong WuPingyi FanNan ChengWen ChenJiangzhou WangKhaled B. Letaief</p>
                <p><a href="http://arxiv.org/abs/2407.02342v1">Link to paper</a></p>
                <p>With the rapid development of intelligent vehicles and Intelligent TransportSystems ITS the sensors such as cameras and LiDAR installed on intelligentvehicles provides higher capacity of executing computation-intensive anddelay-sensitive tasks thereby raising deployment costs. To address this issueVehicular Edge Computing VEC has been proposed to process data through RoadSide Units RSUs to support real-time applications. This paper focuses on theAge of Information AoI as a key metric for data freshness and explores taskoffloading issues for vehicles under RSU communication resource constraints. Weadopt a Multi-agent Deep Reinforcement Learning MADRL approach allowingvehicles to autonomously make optimal data offloading decisions. However MADRLposes risks of vehicle information leakage during communication learning andcentralized training. To mitigate this we employ a Federated Learning FLframework that shares model parameters instead of raw data to protect theprivacy of vehicle users. Building on this we propose an innovativedistributed federated learning framework combining Graph Neural Networks GNNnamed Federated Graph Neural Network Multi-Agent Reinforcement LearningFGNN-MADRL to optimize AoI across the system. For the first time roadscenarios are constructed as graph data structures and a GNN-based federatedlearning framework is proposed effectively combining distributed andcentralized federated aggregation. Furthermore we propose a new MADRLalgorithm that simplifies decision making and enhances offloading efficiencyfurther reducing the decision complexity. Simulation results demonstrate thesuperiority of our proposed approach to other methods through simulations.</p>
                <p>Last Updated: 2024-07-01 15:37:38 UTC</p>
                <button class="interpret-button" data-id="2407.02342v1">Interpret</button>
                <div id="interpretation-2407.02342v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Coordination Failure in Cooperative Offline MARL</h3>
                <p>Authors: Callum Rhys TilburyClaude FormanekLouise BeyersJonathan P. ShockArnu Pretorius</p>
                <p><a href="http://arxiv.org/abs/2407.01343v1">Link to paper</a></p>
                <p>Offline multi-agent reinforcement learning MARL leverages static datasetsof experience to learn optimal multi-agent control. However learning fromstatic data presents several unique challenges to overcome. In this paper wefocus on coordination failure and investigate the role of joint actions inmulti-agent policy gradients with offline data focusing on a common setting werefer to as the Best Response Under Data BRUD approach. By using two-playerpolynomial games as an analytical tool we demonstrate a simple yet overlookedfailure mode of BRUD-based algorithms which can lead to catastrophiccoordination failure in the offline setting. Building on these insights wepropose an approach to mitigate such failure by prioritising samples from thedataset based on joint-action similarity during policy learning and demonstrateits effectiveness in detailed experiments. More generally however we arguethat prioritised dataset sampling is a promising area for innovation in offlineMARL that can be combined with other effective approaches such as critic andpolicy regularisation. Importantly our work shows how insights drawn fromsimplified tractable games can lead to useful theoretically grounded insightsthat transfer to more complex contexts. A core dimension of offering is aninteractive notebook from which almost all of our results can be reproducedin a browser.</p>
                <p>Last Updated: 2024-07-01 14:51:29 UTC</p>
                <button class="interpret-button" data-id="2407.01343v1">Interpret</button>
                <div id="interpretation-2407.01343v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-07-04</p>
        </div>
    
        </div>
    </body>
    </html>
    