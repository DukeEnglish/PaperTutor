
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Stochastic Gradient Piecewise Deterministic Monte Carlo Samplers</h3>
                <p>Authors: Paul FearnheadSebastiano GrazziChris NemethGareth O. Roberts</p>
                <p><a href="http://arxiv.org/abs/2406.19051v1">Link to paper</a></p>
                <p>Recent work has suggested using Monte Carlo methods based on piecewisedeterministic Markov processes PDMPs to sample from target distributions ofinterest. PDMPs are non-reversible continuous-time processes endowed withmomentum and hence can mix better than standard reversible MCMC samplers.Furthermore they can incorporate exact sub-sampling schemes which only requireaccess to a single randomly selected data point at each iteration yetwithout introducing bias to the algorithms stationary distribution. Howeverthe range of models for which PDMPs can be used particularly withsub-sampling is limited. We propose approximate simulation of PDMPs withsub-sampling for scalable sampling from posterior distributions. Theapproximation takes the form of an Euler approximation to the true PDMPdynamics and involves using an estimate of the gradient of the log-posteriorbased on a data sub-sample. We thus call this class of algorithmsstochastic-gradient PDMPs. Importantly the trajectories of stochastic-gradientPDMPs are continuous and can leverage recent ideas for sampling from measureswith continuous and atomic components. We show these methods are easy toimplement present results on their approximation error and demonstratenumerically that this class of algorithms has similar efficiency to but ismore robust than stochastic gradient Langevin dynamics.</p>
                <p>Last Updated: 2024-06-27 09:59:28 UTC</p>
                <button class="interpret-button" data-id="2406.19051v1">Interpret</button>
                <div id="interpretation-2406.19051v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Accuracy on the wrong line: On the pitfalls of noisy data for out-of-distribution generalisation</h3>
                <p>Authors: Amartya SanyalYaxi HuYaodong YuYian MaYixin WangBernhard Sch√∂lkopf</p>
                <p><a href="http://arxiv.org/abs/2406.19049v1">Link to paper</a></p>
                <p>Accuracy-on-the-line is a widely observed phenomenon in machine learningwhere a models accuracy on in-distribution ID and out-of-distribution OODdata is positively correlated across different hyperparameters and dataconfigurations. But when does this useful relationship break down In thiswork we explore its robustness. The key observation is that noisy data and thepresence of nuisance features can be sufficient to shatter theAccuracy-on-the-line phenomenon. In these cases ID and OOD accuracy can becomenegatively correlated leading to Accuracy-on-the-wrong-line. This phenomenoncan also occur in the presence of spurious shortcut features which tend toovershadow the more complex signal core non-spurious features resulting ina large nuisance feature space. Moreover scaling to larger datasets does notmitigate this undesirable behavior and may even exacerbate it. We formallyprove a lower bound on Out-of-distribution OOD error in a linearclassification model characterizing the conditions on the noise and nuisancefeatures for a large OOD error. We finally demonstrate this phenomenon acrossboth synthetic and real datasets with noisy data and nuisance features.</p>
                <p>Last Updated: 2024-06-27 09:57:31 UTC</p>
                <button class="interpret-button" data-id="2406.19049v1">Interpret</button>
                <div id="interpretation-2406.19049v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Statistical Test for Data Analysis Pipeline by Selective Inference</h3>
                <p>Authors: Tomohiro ShiraishiTatsuya MatsukawaShuichi NishinoIchiro Takeuchi</p>
                <p><a href="http://arxiv.org/abs/2406.18902v1">Link to paper</a></p>
                <p>A data analysis pipeline is a structured sequence of processing steps thattransforms raw data into meaningful insights by effectively integrating variousanalysis algorithms. In this paper we propose a novel statistical testdesigned to assess the statistical significance of data analysis pipelines. Ourapproach allows for the systematic development of valid statistical testsapplicable to any data analysis pipeline configuration composed of a set ofdata analysis components. We have developed this framework by adaptingselective inference which has gained recent attention as a new statisticalinference technique for data-driven hypotheses. The proposed statistical testis theoretically designed to control the type I error at the desiredsignificance level in finite samples. As examples we consider a class ofpipelines composed of three missing value imputation algorithms three outlierdetection algorithms and three feature selection algorithms. We confirm thevalidity of our statistical test through experiments with both synthetic andreal data for this class of data analysis pipelines. Additionally we presentan implementation framework that facilitates testing across any configurationof data analysis pipelines in this class without extra implementation costs.</p>
                <p>Last Updated: 2024-06-27 05:30:08 UTC</p>
                <button class="interpret-button" data-id="2406.18902v1">Interpret</button>
                <div id="interpretation-2406.18902v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>From Biased Selective Labels to Pseudo-Labels: An Expectation-Maximization Framework for Learning from Biased Decisions</h3>
                <p>Authors: Trenton ChangJenna Wiens</p>
                <p><a href="http://arxiv.org/abs/2406.18865v1">Link to paper</a></p>
                <p>Selective labels occur when label observations are subject to adecision-making process e.g. diagnoses that depend on the administration oflaboratory tests. We study a clinically-inspired selective label problem calleddisparate censorship where labeling biases vary across subgroups and unlabeledindividuals are imputed as negative i.e. no diagnostic test  no illness.Machine learning models naively trained on such labels could amplify labelingbias. Inspired by causal models of selective labels we propose DisparateCensorship Expectation-Maximization DCEM an algorithm for learning in thepresence of disparate censorship. We theoretically analyze how DCEM mitigatesthe effects of disparate censorship on model performance. We validate DCEM onsynthetic data showing that it improves bias mitigation area between ROCcurves without sacrificing discriminative performance AUC compared tobaselines. We achieve similar results in a sepsis classification task usingclinical data.</p>
                <p>Last Updated: 2024-06-27 03:33:38 UTC</p>
                <button class="interpret-button" data-id="2406.18865v1">Interpret</button>
                <div id="interpretation-2406.18865v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Full Information Linked ICA: addressing missing data problem in multimodal fusion</h3>
                <p>Authors: Ruiyang LiF. DuBois BowmanSeonjoo Lee</p>
                <p><a href="http://arxiv.org/abs/2406.18829v1">Link to paper</a></p>
                <p>Recent advances in multimodal imaging acquisition techniques have allowed usto measure different aspects of brain structure and function. Multimodalfusion such as linked independent component analysis LICA is popularly usedto integrate complementary information. However it has suffered from missingdata commonly occurring in neuroimaging data. Therefore in this paper wepropose a Full Information LICA algorithm FI-LICA to handle the missing dataproblem during multimodal fusion under the LICA framework. Built upon completecases our method employs the principle of full information and utilizes allavailable information to recover the missing latent information. Our simulationexperiments showed the ideal performance of FI-LICA compared to currentpractices. Further we applied FI-LICA to multimodal data from the AlzheimersDisease Neuroimaging Initiative ADNI study showcasing better performance inclassifying current diagnosis and in predicting the AD transition ofparticipants with mild cognitive impairment MCI thereby highlighting thepractical utility of our proposed method.</p>
                <p>Last Updated: 2024-06-27 01:50:43 UTC</p>
                <button class="interpret-button" data-id="2406.18829v1">Interpret</button>
                <div id="interpretation-2406.18829v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models</h3>
                <p>Authors: Cathy Mengying FangValdemar DanryNathan WhitmoreAndria BaoAndrew HutchisonCayden PiercePattie Maes</p>
                <p><a href="http://arxiv.org/abs/2406.19283v1">Link to paper</a></p>
                <p>We present PhysioLLM an interactive system that leverages large languagemodels LLMs to provide personalized health understanding and exploration byintegrating physiological data from wearables with contextual information.Unlike commercial health apps for wearables our system offers a comprehensivestatistical analysis component that discovers correlations and trends in userdata allowing users to ask questions in natural language and receive generatedpersonalized insights and guides them to develop actionable goals. As a casestudy we focus on improving sleep quality given its measurability throughphysiological data and its importance to general well-being. Through a userstudy with 24 Fitbit watch users we demonstrate that PhysioLLM outperformsboth the Fitbit App alone and a generic LLM chatbot in facilitating a deeperpersonalized understanding of health data and supporting actionable stepstoward personal health goals.</p>
                <p>Last Updated: 2024-06-27 15:55:53 UTC</p>
                <button class="interpret-button" data-id="2406.19283v1">Interpret</button>
                <div id="interpretation-2406.19283v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Simulating Classroom Education with LLM-Empowered Agents</h3>
                <p>Authors: Zheyuan ZhangDaniel Zhang-LiJifan YuLinlu GongJinchang ZhouZhiyuan LiuLei HouJuanzi Li</p>
                <p><a href="http://arxiv.org/abs/2406.19226v1">Link to paper</a></p>
                <p>Large language models LLMs have been employed in various intelligenteducational tasks to assist teaching. While preliminary explorations havefocused on independent LLM-empowered agents for specific educational tasks thepotential for LLMs within a multi-agent collaborative framework to simulate aclassroom with real user participation remains unexplored. In this work wepropose SimClass a multi-agent classroom simulation framework involving userparticipation. We recognize representative class roles and introduce a novelclass control mechanism for automatic classroom teaching and conduct userexperiments in two real-world courses. Utilizing the Flanders InteractiveAnalysis System and Community of Inquiry theoretical frame works fromeducational analysis we demonstrate that LLMs can simulate traditionalclassroom interaction patterns effectively while enhancing users experience.We also observe emergent group behaviors among agents in SimClass where agentscollaborate to create enlivening interactions in classrooms to improve userlearning process. We hope this work pioneers the application of LLM-empoweredmulti-agent systems in virtual classroom teaching.</p>
                <p>Last Updated: 2024-06-27 14:51:07 UTC</p>
                <button class="interpret-button" data-id="2406.19226v1">Interpret</button>
                <div id="interpretation-2406.19226v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)</h3>
                <p>Authors: Daniel SonntagMichael BarzThiago Gouv√™a</p>
                <p><a href="http://arxiv.org/abs/2406.19054v1">Link to paper</a></p>
                <p>This DFKI technical report presents the anatomy of the No-IDLE prototypesystem funded by the German Federal Ministry of Education and Research thatprovides not only basic and fundamental research in interactive machinelearning but also reveals deeper insights into users behaviours needs andgoals. Machine learning and deep learning should become accessible to millionsof end users. No-IDLEs goals and scienfific challenges centre around thedesire to increase the reach of interactive deep learning solutions fornon-experts in machine learning. One of the key innovations described in thistechnical report is a methodology for interactive machine learning combinedwith multimodal interaction which will become central when we start interactingwith semi-intelligent machines in the upcoming area of neural networks andlarge language models.</p>
                <p>Last Updated: 2024-06-27 10:01:56 UTC</p>
                <button class="interpret-button" data-id="2406.19054v1">Interpret</button>
                <div id="interpretation-2406.19054v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>State-Based Automation for Time-Restricted Eating Adherence</h3>
                <p>Authors: Samuel E. ArmstrongAaron D. MullenJ. Matthew ThomasDorothy D. SearsJulie S. PendergastJeffrey TalbertCody Bumgardner</p>
                <p><a href="http://arxiv.org/abs/2406.18718v1">Link to paper</a></p>
                <p>Developing and enforcing study protocols is a foundational component ofmedical research. As study complexity for participant interactions increasestranslating study protocols to supporting application code becomes challenging.A collaboration exists between the University of Kentucky and Arizona StateUniversity to determine the efficacy of time-restricted eating in improvingmetabolic risk among postmenopausal women. This study utilizes a graph-basedapproach to monitor and support adherence to a designated schedule enablingthe validation and step-wise audit of participants statuses to derivedependable conclusions. A texting service driven by a participant graphautomatically manages interactions and collects data. Participant data is thenaccessible to the research study team via a website which enables viewingmanagement and exportation. This paper presents a system for automaticallymanaging participants in a time-restricted eating study that eliminatestime-consuming interactions with participants.</p>
                <p>Last Updated: 2024-06-26 19:37:36 UTC</p>
                <button class="interpret-button" data-id="2406.18718v1">Interpret</button>
                <div id="interpretation-2406.18718v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Simulating The U.S. Senate: An LLM-Driven Agent Approach to Modeling Legislative Behavior and Bipartisanship</h3>
                <p>Authors: Zachary R. BakerZarif L. Azher</p>
                <p><a href="http://arxiv.org/abs/2406.18702v1">Link to paper</a></p>
                <p>This study introduces a novel approach to simulating legislative processesusing LLM-driven virtual agents focusing on the U.S. Senate IntelligenceCommittee. We developed agents representing individual senators and placed themin simulated committee discussions. The agents demonstrated the ability toengage in realistic debate provide thoughtful reflections and find bipartisansolutions under certain conditions. Notably the simulation also showed promisein modeling shifts towards bipartisanship in response to externalperturbations. Our results indicate that this LLM-driven approach could becomea valuable tool for understanding and potentially improving legislativeprocesses supporting a broader pattern of findings highlighting how LLM-basedagents can usefully model real-world phenomena. Future works will focus onenhancing agent complexity expanding the simulation scope and exploringapplications in policy testing and negotiation.</p>
                <p>Last Updated: 2024-06-26 19:10:51 UTC</p>
                <button class="interpret-button" data-id="2406.18702v1">Interpret</button>
                <div id="interpretation-2406.18702v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>Dataset Size Recovery from LoRA Weights</h3>
                <p>Authors: Mohammad SalamaJonathan KahanaEliahu HorwitzYedid Hoshen</p>
                <p><a href="http://arxiv.org/abs/2406.19395v1">Link to paper</a></p>
                <p>Model inversion and membership inference attacks aim to reconstruct andverify the data which a model was trained on. However they are not guaranteedto find all training samples as they do not know the size of the training set.In this paper we introduce a new task: dataset size recovery that aims todetermine the number of samples used to train a model directly from itsweights. We then propose DSiRe a method for recovering the number of imagesused to fine-tune a model in the common case where fine-tuning uses LoRA. Wediscover that both the norm and the spectrum of the LoRA matrices are closelylinked to the fine-tuning dataset size we leverage this finding to propose asimple yet effective prediction algorithm. To evaluate dataset size recovery ofLoRA weights we develop and release a new benchmark LoRA-WiSE consisting ofover 25000 weight snapshots from more than 2000 diverse LoRA fine-tuned models.Our best classifier can predict the number of fine-tuning images with a meanabsolute error of 0.36 images establishing the feasibility of this attack.</p>
                <p>Last Updated: 2024-06-27 17:59:53 UTC</p>
                <button class="interpret-button" data-id="2406.19395v1">Interpret</button>
                <div id="interpretation-2406.19395v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>HUWSOD: Holistic Self-training for Unified Weakly Supervised Object Detection</h3>
                <p>Authors: Liujuan CaoJianghang LinZebo HongYunhang ShenShaohui LinChao ChenRongrong Ji</p>
                <p><a href="http://arxiv.org/abs/2406.19394v1">Link to paper</a></p>
                <p>Most WSOD methods rely on traditional object proposals to generate candidateregions and are confronted with unstable training which easily gets stuck in apoor local optimum. In this paper we introduce a unified high-capacity weaklysupervised object detection WSOD network called HUWSOD which utilizes acomprehensive self-training framework without needing external modules oradditional supervision. HUWSOD innovatively incorporates a self-supervisedproposal generator and an autoencoder proposal generator with a multi-rateresampling pyramid to replace traditional object proposals enabling end-to-endWSOD training and inference. Additionally we implement a holisticself-training scheme that refines detection scores and coordinates throughstep-wise entropy minimization and consistency-constraint regularizationensuring consistent predictions across stochastic augmentations of the sameimage. Extensive experiments on PASCAL VOC and MS COCO demonstrate that HUWSODcompetes with state-of-the-art WSOD methods eliminating the need for offlineproposals and additional data. The peak performance of HUWSOD approaches thatof fully-supervised Faster R-CNN. Our findings also indicate that randomlyinitialized boxes although significantly different from well-designed offlineobject proposals are effective for WSOD training.</p>
                <p>Last Updated: 2024-06-27 17:59:49 UTC</p>
                <button class="interpret-button" data-id="2406.19394v1">Interpret</button>
                <div id="interpretation-2406.19394v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Looking 3D: Anomaly Detection with 2D-3D Alignment</h3>
                <p>Authors: Ankan BhuniaChangjian LiHakan Bilen</p>
                <p><a href="http://arxiv.org/abs/2406.19393v1">Link to paper</a></p>
                <p>Automatic anomaly detection based on visual cues holds practical significancein various domains such as manufacturing and product quality assessment. Thispaper introduces a new conditional anomaly detection problem which involvesidentifying anomalies in a query image by comparing it to a reference shape. Toaddress this challenge we have created a large dataset BrokenChairs-180Kconsisting of around 180K images with diverse anomalies geometries andtextures paired with 8143 reference 3D shapes. To tackle this task we haveproposed a novel transformer-based approach that explicitly learns thecorrespondence between the query image and reference 3D shape via featurealignment and leverages a customized attention mechanism for anomaly detection.Our approach has been rigorously evaluated through comprehensive experimentsserving as a benchmark for future research in this domain.</p>
                <p>Last Updated: 2024-06-27 17:59:46 UTC</p>
                <button class="interpret-button" data-id="2406.19393v1">Interpret</button>
                <div id="interpretation-2406.19393v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos</h3>
                <p>Authors: Jr-Jen ChenYu-Chien LiaoHsi-Che LinYu-Chu YuYen-Chun ChenYu-Chiang Frank Wang</p>
                <p><a href="http://arxiv.org/abs/2406.19392v1">Link to paper</a></p>
                <p>We introduce ReXTime a benchmark designed to rigorously test AI modelsability to perform temporal reasoning within video events. SpecificallyReXTime focuses on reasoning across time i.e. human-like understanding whenthe question and its corresponding answer occur in different video segments.This form of reasoning requiring advanced understanding of cause-and-effectrelationships across video segments poses significant challenges to even thefrontier multimodal large language models. To facilitate this evaluation wedevelop an automated pipeline for generating temporal reasoning question-answerpairs significantly reducing the need for labor-intensive manual annotations.Our benchmark includes 921 carefully vetted validation samples and 2143 testsamples each manually curated for accuracy and relevance. Evaluation resultsshow that while frontier large language models outperform academic models theystill lag behind human performance by a significant 14.3 accuracy gap.Additionally our pipeline creates a training dataset of 9695 machinegenerated samples without manual effort which empirical studies suggest canenhance the across-time reasoning via fine-tuning.</p>
                <p>Last Updated: 2024-06-27 17:59:45 UTC</p>
                <button class="interpret-button" data-id="2406.19392v1">Interpret</button>
                <div id="interpretation-2406.19392v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Fibottention: Inceptive Visual Representation Learning with Diverse Attention Across Heads</h3>
                <p>Authors: Ali Khaleghi RahimianManish Kumar GovindSubhajit MaityDominick ReillyChristian K√ºmmerleSrijan DasAritra Dutta</p>
                <p><a href="http://arxiv.org/abs/2406.19391v1">Link to paper</a></p>
                <p>Visual perception tasks are predominantly solved by Vision Transformer ViTarchitectures which despite their effectiveness encounter a computationalbottleneck due to the quadratic complexity of computing self-attention. Thisinefficiency is largely due to the self-attention heads capturing redundanttoken interactions reflecting inherent redundancy within visual data. Manyworks have aimed to reduce the computational complexity of self-attention inViTs leading to the development of efficient and sparse transformerarchitectures. In this paper viewing through the efficiency lens we realizedthat introducing any sparse self-attention strategy in ViTs can keep thecomputational overhead low. However these strategies are sub-optimal as theyoften fail to capture fine-grained visual details. This observation leads us topropose a general efficient sparse architecture named Fibottention forapproximating self-attention with superlinear complexity that is built uponFibonacci sequences. The key strategies in Fibottention include: it excludesproximate tokens to reduce redundancy employs structured sparsity by design todecrease computational demands and incorporates inception-like diversityacross attention heads. This diversity ensures the capture of complementaryinformation through non-overlapping token interactions optimizing bothperformance and resource utilization in ViTs for visual representationlearning. We embed our Fibottention mechanism into multiple state-of-the-arttransformer architectures dedicated to visual tasks. Leveraging only 2-6 ofthe elements in the self-attention heads Fibottention in conjunction with ViTand its variants consistently achieves significant performance boosts comparedto standard ViTs in nine datasets across three domains unicodex2013 imageclassification video understanding and robot learning tasks.</p>
                <p>Last Updated: 2024-06-27 17:59:40 UTC</p>
                <button class="interpret-button" data-id="2406.19391v1">Interpret</button>
                <div id="interpretation-2406.19391v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>The Remarkable Robustness of LLMs: Stages of Inference?</h3>
                <p>Authors: Vedang LadWes GurneeMax Tegmark</p>
                <p><a href="http://arxiv.org/abs/2406.19384v1">Link to paper</a></p>
                <p>We demonstrate and investigate the remarkable robustness of Large LanguageModels by deleting and swapping adjacent layers. We find that deleting andswapping interventions retain 72-95 of the original models predictionaccuracy without fine-tuning whereas models with more layers exhibit morerobustness. Based on the results of the layer-wise intervention and furtherexperiments we hypothesize the existence of four universal stages of inferenceacross eight different models: detokenization feature engineering predictionensembling and residual sharpening. The first stage integrates localinformation lifting raw token representations into higher-level contextualrepresentations. Next is the iterative refinement of task and entity-specificfeatures. Then the second half of the model begins with a phase transitionwhere hidden representations align more with the vocabulary space due tospecialized model components. Finally the last layer sharpens the followingtoken distribution by eliminating obsolete features that add noise to theprediction.</p>
                <p>Last Updated: 2024-06-27 17:57:03 UTC</p>
                <button class="interpret-button" data-id="2406.19384v1">Interpret</button>
                <div id="interpretation-2406.19384v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space</h3>
                <p>Authors: Core Francisco ParkMaya OkawaAndrew LeeEkdeep Singh LubanaHidenori Tanaka</p>
                <p><a href="http://arxiv.org/abs/2406.19370v1">Link to paper</a></p>
                <p>Modern generative models demonstrate impressive capabilities likely stemmingfrom an ability to identify and manipulate abstract concepts underlying theirtraining data. However fundamental questions remain: what determines theconcepts a model learns the order in which it learns them and its ability tomanipulate those concepts To address these questions we propose analyzing amodels learning dynamics via a framework we call the concept space where eachaxis represents an independent concept underlying the data generating process.By characterizing learning dynamics in this space we identify how the speed atwhich a concept is learned and hence the order of concept learning iscontrolled by properties of the data we term concept signal. Further weobserve moments of sudden turns in the direction of a models learning dynamicsin concept space. Surprisingly these points precisely correspond to theemergence of hidden capabilities i.e. where latent interventions show themodel possesses the capability to manipulate a concept but these capabilitiescannot yet be elicited via naive input prompting. While our results focus onsynthetically defined toy datasets we hypothesize a general claim on emergenceof hidden capabilities may hold: generative models possess latent capabilitiesthat emerge suddenly and consistently during training though a model might notexhibit these capabilities under naive input prompting.</p>
                <p>Last Updated: 2024-06-27 17:50:05 UTC</p>
                <button class="interpret-button" data-id="2406.19370v1">Interpret</button>
                <div id="interpretation-2406.19370v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?</h3>
                <p>Authors: Peter HaseThomas HofweberXiang ZhouElias Stengel-EskinMohit Bansal</p>
                <p><a href="http://arxiv.org/abs/2406.19354v1">Link to paper</a></p>
                <p>The model editing problem concerns how language models should learn new factsabout the world over time. While empirical research on model editing has drawnwidespread attention the conceptual foundations of model editing remain shaky-- perhaps unsurprisingly since model editing is essentially belief revisiona storied problem in philosophy that has eluded succinct solutions for decades.Model editing nonetheless demands a solution since we need to be able tocontrol the knowledge within language models. With this goal in mind thispaper critiques the standard formulation of the model editing problem andproposes a formal testbed for model editing research. We first describe 12 openproblems with model editing based on challenges with 1 defining the problem2 developing benchmarks and 3 assuming LLMs have editable beliefs in thefirst place. Many of these challenges are extremely difficult to address e.g.determining far-reaching consequences of edits labeling probabilisticentailments between facts and updating beliefs of agent simulators. Next weintroduce a semi-synthetic dataset for model editing based on Wikidata wherewe can evaluate edits against labels given by an idealized Bayesian agent. Thisenables us to say exactly how belief revision in language models falls short ofa desirable epistemic standard. We encourage further research exploringsettings where such a gold standard can be compared against. Our code ispublicly available at: https://github.com/peterbhase/LLM-belief-revision</p>
                <p>Last Updated: 2024-06-27 17:33:03 UTC</p>
                <button class="interpret-button" data-id="2406.19354v1">Interpret</button>
                <div id="interpretation-2406.19354v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language</h3>
                <p>Authors: Lucky SusantoMusa Izzanardi WijanarkoPrasetia Anugrah PratamaTraci HongIka IdrisAlham Fikri AjiDerry Wijaya</p>
                <p><a href="http://arxiv.org/abs/2406.19349v1">Link to paper</a></p>
                <p>Hate speech poses a significant threat to social harmony. Over the past twoyears Indonesia has seen a ten-fold increase in the online hate speech ratiounderscoring the urgent need for effective detection mechanisms. Howeverprogress is hindered by the limited availability of labeled data for Indonesiantexts. The condition is even worse for marginalized minorities such as ShiaLGBTQ and other ethnic minorities because hate speech is underreported andless understood by detection tools. Furthermore the lack of accommodation forsubjectivity in current datasets compounds this issue. To address this weintroduce IndoToxic2024 a comprehensive Indonesian hate speech and toxicityclassification dataset. Comprising 43692 entries annotated by 19 diverseindividuals the dataset focuses on texts targeting vulnerable groups inIndonesia specifically during the hottest political event in the country: thepresidential election. We establish baselines for seven binary classificationtasks achieving a macro-F1 score of 0.78 with a BERT model IndoBERTweetfine-tuned for hate speech classification. Furthermore we demonstrate howincorporating demographic information can enhance the zero-shot performance ofthe large language model gpt-3.5-turbo. However we also caution that anoveremphasis on demographic information can negatively impact the fine-tunedmodel performance due to data fragmentation.</p>
                <p>Last Updated: 2024-06-27 17:26:38 UTC</p>
                <button class="interpret-button" data-id="2406.19349v1">Interpret</button>
                <div id="interpretation-2406.19349v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Efficient World Models with Context-Aware Tokenization</h3>
                <p>Authors: Vincent MicheliEloi AlonsoFran√ßois Fleuret</p>
                <p><a href="http://arxiv.org/abs/2406.19320v1">Link to paper</a></p>
                <p>Scaling up deep Reinforcement Learning RL methods presents a significantchallenge. Following developments in generative modelling model-based RLpositions itself as a strong contender. Recent advances in sequence modellinghave led to effective transformer-based world models albeit at the price ofheavy computations due to the long sequences of tokens required to accuratelysimulate environments. In this work we propose Delta-IRIS a new agent witha world model architecture composed of a discrete autoencoder that encodesstochastic deltas between time steps and an autoregressive transformer thatpredicts future deltas by summarizing the current state of the world withcontinuous tokens. In the Crafter benchmark Delta-IRIS sets a new state ofthe art at multiple frame budgets while being an order of magnitude faster totrain than previous attention-based approaches. We release our code and modelsat https://github.com/vmicheli/delta-iris.</p>
                <p>Last Updated: 2024-06-27 16:54:12 UTC</p>
                <button class="interpret-button" data-id="2406.19320v1">Interpret</button>
                <div id="interpretation-2406.19320v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>Taming Data and Transformers for Audio Generation</h3>
                <p>Authors: Moayed Haji-AliWilli MenapaceAliaksandr SiarohinGuha BalakrishnanSergey TulyakovVicente Ordonez</p>
                <p><a href="http://arxiv.org/abs/2406.19388v1">Link to paper</a></p>
                <p>Generating ambient sounds and effects is a challenging problem due to datascarcity and often insufficient caption quality making it difficult to employlarge-scale generative models for the task. In this work we tackle the problemby introducing two new models. First we propose AutoCap a high-quality andefficient automatic audio captioning model. We show that by leveraging metadataavailable with the audio modality we can substantially improve the quality ofcaptions. AutoCap reaches CIDEr score of 83.2 marking a 3.2 improvement fromthe best available captioning model at four times faster inference speed. Wethen use AutoCap to caption clips from existing datasets obtaining 761000audio clips with high-quality captions forming the largest availableaudio-text dataset. Second we propose GenAu a scalable transformer-basedaudio generation architecture that we scale up to 1.25B parameters and trainwith our new dataset. When compared to state-of-the-art audio generators GenAuobtains significant improvements of 15.7 in FAD score 22.7 in IS and 13.5in CLAP score indicating significantly improved quality of generated audiocompared to previous works. This shows that the quality of data is often asimportant as its quantity. Besides since AutoCap is fully automatic new audiosamples can be added to the training dataset unlocking the training of evenlarger generative models for audio synthesis.</p>
                <p>Last Updated: 2024-06-27 17:58:54 UTC</p>
                <button class="interpret-button" data-id="2406.19388v1">Interpret</button>
                <div id="interpretation-2406.19388v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The Remarkable Robustness of LLMs: Stages of Inference?</h3>
                <p>Authors: Vedang LadWes GurneeMax Tegmark</p>
                <p><a href="http://arxiv.org/abs/2406.19384v1">Link to paper</a></p>
                <p>We demonstrate and investigate the remarkable robustness of Large LanguageModels by deleting and swapping adjacent layers. We find that deleting andswapping interventions retain 72-95 of the original models predictionaccuracy without fine-tuning whereas models with more layers exhibit morerobustness. Based on the results of the layer-wise intervention and furtherexperiments we hypothesize the existence of four universal stages of inferenceacross eight different models: detokenization feature engineering predictionensembling and residual sharpening. The first stage integrates localinformation lifting raw token representations into higher-level contextualrepresentations. Next is the iterative refinement of task and entity-specificfeatures. Then the second half of the model begins with a phase transitionwhere hidden representations align more with the vocabulary space due tospecialized model components. Finally the last layer sharpens the followingtoken distribution by eliminating obsolete features that add noise to theprediction.</p>
                <p>Last Updated: 2024-06-27 17:57:03 UTC</p>
                <button class="interpret-button" data-id="2406.19384v1">Interpret</button>
                <div id="interpretation-2406.19384v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Suri: Multi-constraint Instruction Following for Long-form Text Generation</h3>
                <p>Authors: Chau Minh PhamSimeng SunMohit Iyyer</p>
                <p><a href="http://arxiv.org/abs/2406.19371v1">Link to paper</a></p>
                <p>Existing research on instruction following largely focuses on tasks withsimple instructions and short responses. In this work we exploremulti-constraint instruction following for generating long-form text. We createSuri a dataset with 20K human-written long-form texts paired withLLM-generated backtranslated instructions that contain multiple complexconstraints. Because of prohibitive challenges associated with collecting humanpreference judgments on long-form texts preference-tuning algorithms such asDPO are infeasible in our setting thus we propose Instructional ORPOI-ORPO an alignment method based on the ORPO algorithm. Instead of receivingnegative feedback from dispreferred responses I-ORPO obtains negative feedbackfrom synthetically corrupted instructions generated by an LLM. Using Suri weperform supervised and I-ORPO fine-tuning on Mistral-7b-Instruct-v0.2. Theresulting models Suri-SFT and Suri-I-ORPO generate significantly longer texts5K tokens than base models without significant quality deterioration. Ourhuman evaluation shows that while both SFT and I-ORPO models satisfy mostconstraints Suri-I-ORPO generations are generally preferred for their coherentand informative incorporation of the constraints. We release our code athttps://github.com/chtmp223/suri.</p>
                <p>Last Updated: 2024-06-27 17:50:35 UTC</p>
                <button class="interpret-button" data-id="2406.19371v1">Interpret</button>
                <div id="interpretation-2406.19371v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models</h3>
                <p>Authors: Xiliang ZhuShayna GardinerTere Rold√°nDavid Rossouw</p>
                <p><a href="http://arxiv.org/abs/2406.19358v1">Link to paper</a></p>
                <p>Sentiment analysis serves as a pivotal component in Natural LanguageProcessing NLP. Advancements in multilingual pre-trained models such as XLM-Rand mT5 have contributed to the increasing interest in cross-lingual sentimentanalysis. The recent emergence in Large Language Models LLM has significantlyadvanced general NLP tasks however the capability of such LLMs incross-lingual sentiment analysis has not been fully studied. This workundertakes an empirical analysis to compare the cross-lingual transfercapability of public Small Multilingual Language Models SMLM like XLM-Ragainst English-centric LLMs such as Llama-3 in the context of sentimentanalysis across English Spanish French and Chinese. Our findings reveal thatamong public models SMLMs exhibit superior zero-shot cross-lingual performancerelative to LLMs. However in few-shot cross-lingual settings public LLMsdemonstrate an enhanced adaptive potential. In addition we observe thatproprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability butare outpaced by public models in few-shot scenarios.</p>
                <p>Last Updated: 2024-06-27 17:38:45 UTC</p>
                <button class="interpret-button" data-id="2406.19358v1">Interpret</button>
                <div id="interpretation-2406.19358v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions</h3>
                <p>Authors: Nigel FernandezAlexander ScarlatosSimon WoodheadAndrew Lan</p>
                <p><a href="http://arxiv.org/abs/2406.19356v1">Link to paper</a></p>
                <p>High-quality distractors are crucial to both the assessment and pedagogicalvalue of multiple-choice questions MCQs where manually crafting ones thatanticipate knowledge deficiencies or misconceptions among real students isdifficult. Meanwhile automated distractor generation even with the help oflarge language models LLMs remains challenging for subjects like math. It iscrucial to not only identify plausible distractors but also understand theerror behind them. In this paper we introduce DiVERT Distractor Generationwith Variational Errors Represented as Text a novel variational approach thatlearns an interpretable representation of errors behind distractors in mathMCQs. Through experiments on a real-world math MCQ dataset with 1434 questionsused by hundreds of thousands of students we show that DiVERT despite using abase open-source LLM with 7B parameters outperforms state-of-the-artapproaches using GPT-4o on downstream distractor generation. We also conduct ahuman evaluation with math educators and find that DiVERT leads to error labelsthat are of comparable quality to human-authored ones.</p>
                <p>Last Updated: 2024-06-27 17:37:31 UTC</p>
                <button class="interpret-button" data-id="2406.19356v1">Interpret</button>
                <div id="interpretation-2406.19356v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>The Remarkable Robustness of LLMs: Stages of Inference?</h3>
                <p>Authors: Vedang LadWes GurneeMax Tegmark</p>
                <p><a href="http://arxiv.org/abs/2406.19384v1">Link to paper</a></p>
                <p>We demonstrate and investigate the remarkable robustness of Large LanguageModels by deleting and swapping adjacent layers. We find that deleting andswapping interventions retain 72-95 of the original models predictionaccuracy without fine-tuning whereas models with more layers exhibit morerobustness. Based on the results of the layer-wise intervention and furtherexperiments we hypothesize the existence of four universal stages of inferenceacross eight different models: detokenization feature engineering predictionensembling and residual sharpening. The first stage integrates localinformation lifting raw token representations into higher-level contextualrepresentations. Next is the iterative refinement of task and entity-specificfeatures. Then the second half of the model begins with a phase transitionwhere hidden representations align more with the vocabulary space due tospecialized model components. Finally the last layer sharpens the followingtoken distribution by eliminating obsolete features that add noise to theprediction.</p>
                <p>Last Updated: 2024-06-27 17:57:03 UTC</p>
                <button class="interpret-button" data-id="2406.19384v1">Interpret</button>
                <div id="interpretation-2406.19384v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>TabReD: A Benchmark of Tabular Machine Learning in-the-Wild</h3>
                <p>Authors: Ivan RubachevNikolay KartashevYury GorishniyArtem Babenko</p>
                <p><a href="http://arxiv.org/abs/2406.19380v1">Link to paper</a></p>
                <p>Benchmarks that closely reflect downstream application scenarios areessential for the streamlined adoption of new research in tabular machinelearning ML. In this work we examine existing tabular benchmarks and findtwo common characteristics of industry-grade tabular data that areunderrepresented in the datasets available to the academic community. Firsttabular data often changes over time in real-world deployment scenarios. Thisimpacts model performance and requires time-based train and test splits forcorrect model evaluation. Yet existing academic tabular datasets often lacktimestamp metadata to enable such evaluation. Second a considerable portion ofdatasets in production settings stem from extensive data acquisition andfeature engineering pipelines. For each specific dataset this can have adifferent impact on the absolute and relative number of predictiveuninformative and correlated features which in turn can affect modelselection. To fill the aforementioned gaps in academic benchmarks we introduceTabReD -- a collection of eight industry-grade tabular datasets covering a widerange of domains from finance to food delivery services. We assess a largenumber of tabular ML models in the feature-rich temporally-evolving datasetting facilitated by TabReD. We demonstrate that evaluation on time-baseddata splits leads to different methods ranking compared to evaluation onrandom splits more common in academic benchmarks. Furthermore on the TabReDdatasets MLP-like architectures and GBDT show the best results while moresophisticated DL models are yet to prove their effectiveness.</p>
                <p>Last Updated: 2024-06-27 17:55:31 UTC</p>
                <button class="interpret-button" data-id="2406.19380v1">Interpret</button>
                <div id="interpretation-2406.19380v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space</h3>
                <p>Authors: Core Francisco ParkMaya OkawaAndrew LeeEkdeep Singh LubanaHidenori Tanaka</p>
                <p><a href="http://arxiv.org/abs/2406.19370v1">Link to paper</a></p>
                <p>Modern generative models demonstrate impressive capabilities likely stemmingfrom an ability to identify and manipulate abstract concepts underlying theirtraining data. However fundamental questions remain: what determines theconcepts a model learns the order in which it learns them and its ability tomanipulate those concepts To address these questions we propose analyzing amodels learning dynamics via a framework we call the concept space where eachaxis represents an independent concept underlying the data generating process.By characterizing learning dynamics in this space we identify how the speed atwhich a concept is learned and hence the order of concept learning iscontrolled by properties of the data we term concept signal. Further weobserve moments of sudden turns in the direction of a models learning dynamicsin concept space. Surprisingly these points precisely correspond to theemergence of hidden capabilities i.e. where latent interventions show themodel possesses the capability to manipulate a concept but these capabilitiescannot yet be elicited via naive input prompting. While our results focus onsynthetically defined toy datasets we hypothesize a general claim on emergenceof hidden capabilities may hold: generative models possess latent capabilitiesthat emerge suddenly and consistently during training though a model might notexhibit these capabilities under naive input prompting.</p>
                <p>Last Updated: 2024-06-27 17:50:05 UTC</p>
                <button class="interpret-button" data-id="2406.19370v1">Interpret</button>
                <div id="interpretation-2406.19370v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions</h3>
                <p>Authors: Nigel FernandezAlexander ScarlatosSimon WoodheadAndrew Lan</p>
                <p><a href="http://arxiv.org/abs/2406.19356v1">Link to paper</a></p>
                <p>High-quality distractors are crucial to both the assessment and pedagogicalvalue of multiple-choice questions MCQs where manually crafting ones thatanticipate knowledge deficiencies or misconceptions among real students isdifficult. Meanwhile automated distractor generation even with the help oflarge language models LLMs remains challenging for subjects like math. It iscrucial to not only identify plausible distractors but also understand theerror behind them. In this paper we introduce DiVERT Distractor Generationwith Variational Errors Represented as Text a novel variational approach thatlearns an interpretable representation of errors behind distractors in mathMCQs. Through experiments on a real-world math MCQ dataset with 1434 questionsused by hundreds of thousands of students we show that DiVERT despite using abase open-source LLM with 7B parameters outperforms state-of-the-artapproaches using GPT-4o on downstream distractor generation. We also conduct ahuman evaluation with math educators and find that DiVERT leads to error labelsthat are of comparable quality to human-authored ones.</p>
                <p>Last Updated: 2024-06-27 17:37:31 UTC</p>
                <button class="interpret-button" data-id="2406.19356v1">Interpret</button>
                <div id="interpretation-2406.19356v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Subtractive Training for Music Stem Insertion using Latent Diffusion Models</h3>
                <p>Authors: Ivan Villa-RenteriaMason L. WangZachary ShahZhe LiSoohyun KimNeelesh RamachandranMert Pilanci</p>
                <p><a href="http://arxiv.org/abs/2406.19328v1">Link to paper</a></p>
                <p>We present Subtractive Training a simple and novel method for synthesizingindividual musical instrument stems given other instruments as context. Thismethod pairs a dataset of complete music mixes with 1 a variant of the datasetlacking a specific stem and 2 LLM-generated instructions describing how themissing stem should be reintroduced. We then fine-tune a pretrainedtext-to-audio diffusion model to generate the missing instrument stem guidedby both the existing stems and the text instruction. Our results demonstrateSubtractive Trainings efficacy in creating authentic drum stems thatseamlessly blend with the existing tracks. We also show that we can use thetext instruction to control the generation of the inserted stem in terms ofrhythm dynamics and genre allowing us to modify the style of a singleinstrument in a full song while keeping the remaining instruments the same.Lastly we extend this technique to MIDI formats successfully generatingcompatible bass drum and guitar parts for incomplete arrangements.</p>
                <p>Last Updated: 2024-06-27 16:59:14 UTC</p>
                <button class="interpret-button" data-id="2406.19328v1">Interpret</button>
                <div id="interpretation-2406.19328v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>Cooperative Target Capture using Voronoi Region Shaping</h3>
                <p>Authors: Gautam KumarAshwini Ratnoo</p>
                <p><a href="http://arxiv.org/abs/2406.19181v1">Link to paper</a></p>
                <p>This paper discusses a cooperative strategy for capturing a target usingmultiple pursuers in a planar scenario. Given an initial position distributionof pursuers the Voronoi Diagram is employed to characterize the targetsproximity region. The key idea is to dynamically shape that region using apolicy that directs its vertices towards its instantaneous centroid. Analysisof the resulting dynamics deduces the velocity control inputs for the pursuers.As the main result targets proximity region is shown to shrink exponentiallyirrespective of its speed and evasion policy. Simulation results demonstratethe characteristics of the proposed method.</p>
                <p>Last Updated: 2024-06-27 13:57:55 UTC</p>
                <button class="interpret-button" data-id="2406.19181v1">Interpret</button>
                <div id="interpretation-2406.19181v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Formation Under Communication Constraints: Control Performance Meets Channel Capacity</h3>
                <p>Authors: Yaru ChenYirui CongXiangyun ZhouLong ChengXiangke Wang</p>
                <p><a href="http://arxiv.org/abs/2406.18961v1">Link to paper</a></p>
                <p>In wireless communication-based formation control systems the controlperformance is significantly impacted by the channel capacity of eachcommunication link between agents. This relationship however remainsunder-investigated in the existing studies. To address this gap the formationcontrol problem of classical second-order multi-agent systems with boundedprocess noises was considered taking into account the channel capacity. Morespecifically the model of communication links between agents is firstestablished based on a new concept -- guaranteed communication region whichcharacterizes all possible locations for successful message decoding in thepresent of control-system uncertainty. Furthermore we rigorously prove thatthe guaranteed communication region does not unboundedly increase with thetransmission time which indicates an important trade-off between theguaranteed communication region and the data rate. The fundamental limits ofdata rate for any desired accuracy are also obtained. Finally the integrateddesign to achieve the desired formation accuracy is proposed where anestimation-based controller and transmit power control strategy are developed.</p>
                <p>Last Updated: 2024-06-27 07:45:01 UTC</p>
                <button class="interpret-button" data-id="2406.18961v1">Interpret</button>
                <div id="interpretation-2406.18961v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Differential error feedback for communication-efficient decentralized learning</h3>
                <p>Authors: Roula NassifStefan VlaskiMarco CarpentieroVincenzo MattaAli H. Sayed</p>
                <p><a href="http://arxiv.org/abs/2406.18418v1">Link to paper</a></p>
                <p>Communication-constrained algorithms for decentralized learning andoptimization rely on local updates coupled with the exchange of compressedsignals. In this context differential quantization is an effective techniqueto mitigate the negative impact of compression by leveraging correlationsbetween successive iterates. In addition the use of error feedback whichconsists of incorporating the compression error into subsequent steps is apowerful mechanism to compensate for the bias caused by the compression. Undererror feedback performance guarantees in the literature have so far focused onalgorithms employing a fusion center or a special class of contractivecompressors that cannot be implemented with a finite number of bits. In thiswork we propose a new decentralized communication-efficient learning approachthat blends differential quantization with error feedback. The approach isspecifically tailored for decentralized learning problems where agents haveindividual risk functions to minimize subject to subspace constraints thatrequire the minimizers across the network to lie in low-dimensional subspaces.This constrained formulation includes consensus or single-task optimization asspecial cases and allows for more general task relatedness models such asmultitask smoothness and coupled optimization. We show that under some generalconditions on the compression noise and for sufficiently small step-sizesmu the resulting communication-efficient strategy is stable both in termsof mean-square error and average bit rate: by reducing mu it is possible tokeep the estimation errors small on the order of mu without increasingindefinitely the bit rate as murightarrow 0. The results establish that inthe small step-size regime and with a finite number of bits it is possible toattain the performance achievable in the absence of compression.</p>
                <p>Last Updated: 2024-06-26 15:11:26 UTC</p>
                <button class="interpret-button" data-id="2406.18418v1">Interpret</button>
                <div id="interpretation-2406.18418v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Building multiscale models with PhysiBoSS, an agent-based modeling tool</h3>
                <p>Authors: Marco RusconeAndrea CheccoliRandy HeilandEmmanuel BarillotPaul MacklinLaurence CalzoneVincent No√´l</p>
                <p><a href="http://arxiv.org/abs/2406.18371v1">Link to paper</a></p>
                <p>Multiscale models provide a unique tool for studying complex processes thatstudy events occurring at different scales across space and time. In thecontext of biological systems such models can simulate mechanisms happening atthe intracellular level such as signaling and at the extracellular level wherecells communicate and coordinate with other cells. They aim to understand theimpact of genetic or environmental deregulation observed in complex diseasesdescribe the interplay between a pathological tissue and the immune system andsuggest strategies to revert the diseased phenotypes. The construction of thesemultiscale models remains a very complex task including the choice of thecomponents to consider the level of details of the processes to simulate orthe fitting of the parameters to the data. One additional difficulty is theexpert knowledge needed to program these models in languages such as C orPython which may discourage the participation of non-experts. Simplifying thisprocess through structured description formalisms -- coupled with a graphicalinterface -- is crucial in making modeling more accessible to the broaderscientific community as well as streamlining the process for advanced users.This article introduces three examples of multiscale models which rely on theframework PhysiBoSS an add-on of PhysiCell that includes intracellulardescriptions as continuous time Boolean models to the agent-based approach. Thearticle demonstrates how to easily construct such models relying on PhysiCellStudio the PhysiCell Graphical User Interface. A step-by-step tutorial isprovided as a Supplementary Material and all models are provided at:https://physiboss.github.io/tutorial/.</p>
                <p>Last Updated: 2024-06-26 14:14:57 UTC</p>
                <button class="interpret-button" data-id="2406.18371v1">Interpret</button>
                <div id="interpretation-2406.18371v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Emergence of social hierarchies in a society with two competitive classes</h3>
                <p>Authors: Marc Sadurn√≠Josep Perell√≥Miquel Montero</p>
                <p><a href="http://arxiv.org/abs/2406.18168v1">Link to paper</a></p>
                <p>Agent-based models describing social interactions among individuals can helpto better understand emerging macroscopic patterns in societies. One of thetopics which is worth tackling is the formation of different kinds ofhierarchies that emerge in social spaces such as cities. Here we propose aBonabeau-like model by adding a second class of agents. The fundamentalparticularity of our model is that only a pairwise interaction between agentsof the opposite class is allowed. Agent fitness can thus only change bycompetition among the two classes while the total fitness in the societyremains constant. The main result is that for a broad range of values of themodel parameters the fitness of the agents of each class show a decay in timeexcept for one or very few agents which capture almost all the fitness in thesociety. Numerical simulations also reveal a singular shift from egalitarian tohierarchical society for each class. This behaviour depends on the controlparameter eta playing the role of the inverse of the temperature of thesystem. Results are invariant with regard to the system size contingent solelyon the quantity of agents within each class. Finally a couple of scaling lawsare provided thus showing a data collapse from different model parameters andthey follow a shape which can be related to the presence of a phase transitionin the model.</p>
                <p>Last Updated: 2024-06-26 08:33:08 UTC</p>
                <button class="interpret-button" data-id="2406.18168v1">Interpret</button>
                <div id="interpretation-2406.18168v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-06-30</p>
        </div>
    
        </div>
    </body>
    </html>
    