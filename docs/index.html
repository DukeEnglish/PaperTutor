
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>How Far Are We From AGI</h3>
                <p>Authors: Tao FengChuanyang JinJingyu LiuKunlun ZhuHaoqin TuZirui ChengGuanyu LinJiaxuan You</p>
                <p><a href="http://arxiv.org/abs/2405.10313v1">Link to paper</a></p>
                <p>The evolution of artificial intelligence AI has profoundly impacted humansociety driving significant advancements in multiple sectors. Yet theescalating demands on AI have highlighted the limitations of AIs currentofferings catalyzing a movement towards Artificial General Intelligence AGI.AGI distinguished by its ability to execute diverse real-world tasks withefficiency and effectiveness comparable to human intelligence reflects aparamount milestone in AI evolution. While existing works have summarizedspecific recent advancements of AI they lack a comprehensive discussion ofAGIs definitions goals and developmental trajectories. Different fromexisting survey papers this paper delves into the pivotal questions of ourproximity to AGI and the strategies necessary for its realization throughextensive surveys discussions and original perspectives. We start byarticulating the requisite capability frameworks for AGI integrating theinternal interface and system dimensions. As the realization of AGI requiresmore advanced capabilities and adherence to stringent constraints we furtherdiscuss necessary AGI alignment technologies to harmonize these factors.Notably we emphasize the importance of approaching AGI responsibly by firstdefining the key levels of AGI progression followed by the evaluationframework that situates the status-quo and finally giving our roadmap of howto reach the pinnacle of AGI. Moreover to give tangible insights into theubiquitous impact of the integration of AI we outline existing challenges andpotential pathways toward AGI in multiple domains. In sum serving as apioneering exploration into the current state and future trajectory of AGIthis paper aims to foster a collective comprehension and catalyze broaderpublic discussions among researchers and practitioners on AGI.</p>
                <p>Last Updated: 2024-05-16 17:59:02 UTC</p>
                <button class="interpret-button" data-id="2405.10313v1">Interpret</button>
                <div id="interpretation-2405.10313v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning</h3>
                <p>Authors: Yuexiang ZhaiHao BaiZipeng LinJiayi PanShengbang TongYifei ZhouAlane SuhrSaining XieYann LeCunYi MaSergey Levine</p>
                <p><a href="http://arxiv.org/abs/2405.10292v1">Link to paper</a></p>
                <p>Large vision-language models VLMs fine-tuned on specialized visualinstruction-following data have exhibited impressive language reasoningcapabilities across various scenarios. However this fine-tuning paradigm maynot be able to efficiently learn optimal decision-making agents in multi-stepgoal-directed tasks from interactive environments. To address this challengewe propose an algorithmic framework that fine-tunes VLMs with reinforcementlearning RL. Specifically our framework provides a task description and thenprompts the VLM to generate chain-of-thought CoT reasoning enabling the VLMto efficiently explore intermediate reasoning steps that lead to the finaltext-based action. Next the open-ended text output is parsed into anexecutable action to interact with the environment to obtain goal-directed taskrewards. Finally our framework uses these task rewards to fine-tune the entireVLM with RL. Empirically we demonstrate that our proposed framework enhancesthe decision-making capabilities of VLM agents across various tasks enabling7b models to outperform commercial models such as GPT4-V or Gemini.Furthermore we find that CoT reasoning is a crucial component for performanceimprovement as removing the CoT reasoning results in a significant decrease inthe overall performance of our method.</p>
                <p>Last Updated: 2024-05-16 17:50:19 UTC</p>
                <button class="interpret-button" data-id="2405.10292v1">Interpret</button>
                <div id="interpretation-2405.10292v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Timeline-based Sentence Decomposition with In-Context Learning for Temporal Fact Extraction</h3>
                <p>Authors: Jianhao ChenHaoyuan OuyangJunyang RenWentao DingWei HuYuzhong Qu</p>
                <p><a href="http://arxiv.org/abs/2405.10288v1">Link to paper</a></p>
                <p>Facts extraction is pivotal for constructing knowledge graphs. Recently theincreasing demand for temporal facts in downstream tasks has led to theemergence of the task of temporal fact extraction. In this paper wespecifically address the extraction of temporal facts from natural languagetext. Previous studies fail to handle the challenge of establishingtime-to-fact correspondences in complex sentences. To overcome this hurdle wepropose a timeline-based sentence decomposition strategy using large languagemodels LLMs with in-context learning ensuring a fine-grained understandingof the timeline associated with various facts. In addition we evaluate theperformance of LLMs for direct temporal fact extraction and get unsatisfactoryresults. To this end we introduce TSDRE a method that incorporates thedecomposition capabilities of LLMs into the traditional fine-tuning of smallerpre-trained language models PLMs. To support the evaluation we constructComplexTRED a complex temporal fact extraction dataset. Our experiments showthat TSDRE achieves state-of-the-art results on both HyperRED-Temporal andComplexTRED datasets.</p>
                <p>Last Updated: 2024-05-16 17:48:21 UTC</p>
                <button class="interpret-button" data-id="2405.10288v1">Interpret</button>
                <div id="interpretation-2405.10288v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers</h3>
                <p>Authors: Tuo ZhangJinyue YuanSalman Avestimehr</p>
                <p><a href="http://arxiv.org/abs/2405.10276v1">Link to paper</a></p>
                <p>Numerous recent works aim to enhance the efficacy of Large Language ModelsLLMs through strategic prompting. In particular the Optimization byPROmpting OPRO approach provides state-of-the-art performance by leveragingLLMs as optimizers where the optimization task is to find instructions thatmaximize the task accuracy. In this paper we revisit OPRO for automatedprompting with relatively small-scale LLMs such as LLaMa-2 family and Mistral7B. Our investigation reveals that OPRO shows limited effectiveness insmall-scale LLMs with limited inference capabilities constraining optimizationability. We suggest future automatic prompting engineering to consider bothmodel capabilities and computational costs. Additionally for small-scale LLMswe recommend direct instructions that clearly outline objectives andmethodologies as robust prompt baselines ensuring efficient and effectiveprompt engineering in ongoing research.</p>
                <p>Last Updated: 2024-05-16 17:33:50 UTC</p>
                <button class="interpret-button" data-id="2405.10276v1">Interpret</button>
                <div id="interpretation-2405.10276v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Tale of Two Languages: Large-Vocabulary Continuous Sign Language Recognition from Spoken Language Supervision</h3>
                <p>Authors: Charles RaudeK R PrajwalLiliane MomeniHannah BullSamuel AlbanieAndrew ZissermanGÃ¼l Varol</p>
                <p><a href="http://arxiv.org/abs/2405.10266v1">Link to paper</a></p>
                <p>In this work our goals are two fold: large-vocabulary continuous signlanguage recognition CSLR and sign language retrieval. To this end weintroduce a multi-task Transformer model CSLR2 that is able to ingest asigning sequence and output in a joint embedding space between signed languageand spoken language text. To enable CSLR evaluation in the large-vocabularysetting we introduce new dataset annotations that have been manuallycollected. These provide continuous sign-level annotations for six hours oftest videos and will be made publicly available. We demonstrate that by acareful choice of loss functions training the model for both the CSLR andretrieval tasks is mutually beneficial in terms of performance -- retrievalimproves CSLR performance by providing context while CSLR improves retrievalwith more fine-grained supervision. We further show the benefits of leveragingweak and noisy supervision from large-vocabulary datasets such as BOBSL namelysign-level pseudo-labels and English subtitles. Our model significantlyoutperforms the previous state of the art on both tasks.</p>
                <p>Last Updated: 2024-05-16 17:19:06 UTC</p>
                <button class="interpret-button" data-id="2405.10266v1">Interpret</button>
                <div id="interpretation-2405.10266v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Stochastic Q-learning for Large Discrete Action Spaces</h3>
                <p>Authors: Fares FouratiVaneet AggarwalMohamed-Slim Alouini</p>
                <p><a href="http://arxiv.org/abs/2405.10310v1">Link to paper</a></p>
                <p>In complex environments with large discrete action spaces effectivedecision-making is critical in reinforcement learning RL. Despite thewidespread use of value-based RL approaches like Q-learning they come with acomputational burden necessitating the maximization of a value function overall actions in each iteration. This burden becomes particularly challengingwhen addressing large-scale problems and using deep neural networks as functionapproximators. In this paper we present stochastic value-based RL approacheswhich in each iteration as opposed to optimizing over the entire set of nactions only consider a variable stochastic set of a sublinear number ofactions possibly as small as mathcalOlogn. The presented stochasticvalue-based RL methods include among others Stochastic Q-learning StochDQNand StochDDQN all of which integrate this stochastic approach for bothvalue-function updates and action selection. The theoretical convergence ofStochastic Q-learning is established while an analysis of stochasticmaximization is provided. Moreover through empirical validation we illustratethat the various proposed approaches outperform the baseline methods acrossdiverse environments including different control problems achievingnear-optimal average returns in significantly reduced time.</p>
                <p>Last Updated: 2024-05-16 17:58:44 UTC</p>
                <button class="interpret-button" data-id="2405.10310v1">Interpret</button>
                <div id="interpretation-2405.10310v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Optimal Aggregation of Prediction Intervals under Unsupervised Domain Shift</h3>
                <p>Authors: Jiawei GeDebarghya MukherjeeJianqing Fan</p>
                <p><a href="http://arxiv.org/abs/2405.10302v1">Link to paper</a></p>
                <p>As machine learning models are increasingly deployed in dynamic environmentsit becomes paramount to assess and quantify uncertainties associated withdistribution shifts. A distribution shift occurs when the underlyingdata-generating process changes leading to a deviation in the modelsperformance. The prediction interval which captures the range of likelyoutcomes for a given prediction serves as a crucial tool for characterizinguncertainties induced by their underlying distribution. In this paper wepropose methodologies for aggregating prediction intervals to obtain one withminimal width and adequate coverage on the target domain under unsuperviseddomain shift under which we have labeled samples from a related source domainand unlabeled covariates from the target domain. Our analysis encompassesscenarios where the source and the target domain are related via i a boundeddensity ratio and ii a measure-preserving transformation. Our proposedmethodologies are computationally efficient and easy to implement. Beyondillustrating the performance of our method through a real-world dataset wealso delve into the theoretical details. This includes establishing rigoroustheoretical guarantees coupled with finite sample bounds regarding thecoverage and width of our prediction intervals. Our approach excels inpractical applications and is underpinned by a solid theoretical frameworkensuring its reliability and effectiveness across diverse contexts.</p>
                <p>Last Updated: 2024-05-16 17:55:42 UTC</p>
                <button class="interpret-button" data-id="2405.10302v1">Interpret</button>
                <div id="interpretation-2405.10302v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees</h3>
                <p>Authors: Yu GuiYing JinZhimei Ren</p>
                <p><a href="http://arxiv.org/abs/2405.10301v1">Link to paper</a></p>
                <p>Before deploying outputs from foundation models in high-stakes tasks it isimperative to ensure that they align with human values. For instance inradiology report generation reports generated by a vision-language model mustalign with human evaluations before their use in medical decision-making. Thispaper presents Conformal Alignment a general framework for identifying unitswhose outputs meet a user-specified alignment criterion. It is guaranteed thaton average a prescribed fraction of selected units indeed meet the alignmentcriterion regardless of the foundation model or the data distribution. Givenany pre-trained model and new units with model-generated outputs ConformalAlignment leverages a set of reference data with ground-truth alignment statusto train an alignment predictor. It then selects new units whose predictedalignment scores surpass a data-dependent threshold certifying theircorresponding outputs as trustworthy. Through applications to questionanswering and radiology report generation we demonstrate that our method isable to accurately identify units with trustworthy outputs via lightweighttraining over a moderate amount of reference data. En route we investigate theinformativeness of various features in alignment prediction and combine themwith standard models to construct the alignment predictor.</p>
                <p>Last Updated: 2024-05-16 17:55:24 UTC</p>
                <button class="interpret-button" data-id="2405.10301v1">Interpret</button>
                <div id="interpretation-2405.10301v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Subgradient Convergence Implies Subdifferential Convergence on Weakly Convex Functions: With Uniform Rates Guarantees</h3>
                <p>Authors: Feng Ruan</p>
                <p><a href="http://arxiv.org/abs/2405.10289v1">Link to paper</a></p>
                <p>In nonsmooth nonconvex stochastic optimization understanding the uniformconvergence of subdifferential mappings is crucial for analyzing stationarypoints of sample average approximations of risk as they approach the populationrisk. Yet characterizing this convergence remains a fundamental challenge.  This work introduces a novel perspective by connecting the uniformconvergence of subdifferential mappings to that of subgradient mappings asempirical risk converges to the population risk. We prove that for stochasticweakly-convex objectives and within any open set a uniform bound on theconvergence of subgradients -- chosen arbitrarily from the correspondingsubdifferential sets -- translates to a uniform bound on the convergence of thesubdifferential sets itself measured by the Hausdorff metric.  Using this technique we derive uniform convergence rates for subdifferentialsets of stochastic convex-composite objectives. Our results do not rely on keydistributional assumptions in the literature which require the population andfinite sample subdifferentials to be continuous in the Hausdorff metric yetstill provide tight convergence rates. These guarantees lead to new insightsinto the nonsmooth landscapes of such objectives within finite samples.</p>
                <p>Last Updated: 2024-05-16 17:49:46 UTC</p>
                <button class="interpret-button" data-id="2405.10289v1">Interpret</button>
                <div id="interpretation-2405.10289v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>On Partially Unitary Learning</h3>
                <p>Authors: Mikhail Gennadievich BelovVladislav Gennadievich Malyshkin</p>
                <p><a href="http://arxiv.org/abs/2405.10263v1">Link to paper</a></p>
                <p>The problem of an optimal mapping between Hilbert spaces IN ofleftpsirightrangle and OUT of leftphirightrangle based on a setof wavefunction measurements within a phase psi_l to phi_l l1dotsM is formulated as an optimization problem maximizing the total fidelitysum_l1M omegalleftlanglephi_lmathcalUpsi_lrangleright2 subject to probabilitypreservation constraints on mathcalU partial unitarity. Constructedoperator mathcalU can be considered as a IN to OUT quantum channel itis a partially unitary rectangular matrix of the dimension dimOUT timesdimIN transforming operators as AOUTmathcalU AINmathcalUdagger. An iteration algorithm finding the global maximum ofthis optimization problem is developed and its application to a number ofproblems is demonstrated. A software product implementing the algorithm isavailable from the authors.</p>
                <p>Last Updated: 2024-05-16 17:13:55 UTC</p>
                <button class="interpret-button" data-id="2405.10263v1">Interpret</button>
                <div id="interpretation-2405.10263v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>Toon3D: Seeing Cartoons from a New Perspective</h3>
                <p>Authors: Ethan WeberRiley PeterlinzRohan MathurFrederik WarburgAlexei A. EfrosAngjoo Kanazawa</p>
                <p><a href="http://arxiv.org/abs/2405.10320v1">Link to paper</a></p>
                <p>In this work we recover the underlying 3D structure of non-geometricallyconsistent scenes. We focus our analysis on hand-drawn images from cartoons andanime. Many cartoons are created by artists without a 3D rendering enginewhich means that any new image of a scene is hand-drawn. The hand-drawn imagesare usually faithful representations of the world but only in a qualitativesense since it is difficult for humans to draw multiple perspectives of anobject or scene 3D consistently. Nevertheless people can easily perceive 3Dscenes from inconsistent inputs In this work we correct for 2D drawinginconsistencies to recover a plausible 3D structure such that the newly warpeddrawings are consistent with each other. Our pipeline consists of auser-friendly annotation tool camera pose estimation and image deformation torecover a dense structure. Our method warps images to obey a perspective cameramodel enabling our aligned results to be plugged into novel-view synthesisreconstruction methods to experience cartoons from viewpoints never drawnbefore. Our project page is https://toon3d.studio/.</p>
                <p>Last Updated: 2024-05-16 17:59:51 UTC</p>
                <button class="interpret-button" data-id="2405.10320v1">Interpret</button>
                <div id="interpretation-2405.10320v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Text-to-Vector Generation with Neural Path Representation</h3>
                <p>Authors: Peiying ZhangNanxuan ZhaoJing Liao</p>
                <p><a href="http://arxiv.org/abs/2405.10317v1">Link to paper</a></p>
                <p>Vector graphics are widely used in digital art and highly favored bydesigners due to their scalability and layer-wise properties. However theprocess of creating and editing vector graphics requires creativity and designexpertise making it a time-consuming task. Recent advancements intext-to-vector T2V generation have aimed to make this process moreaccessible. However existing T2V methods directly optimize control points ofvector graphics paths often resulting in intersecting or jagged paths due tothe lack of geometry constraints. To overcome these limitations we propose anovel neural path representation by designing a dual-branch VariationalAutoencoder VAE that learns the path latent space from both sequence andimage modalities. By optimizing the combination of neural paths we canincorporate geometric constraints while preserving expressivity in generatedSVGs. Furthermore we introduce a two-stage path optimization method to improvethe visual and topological quality of generated SVGs. In the first stage apre-trained text-to-image diffusion model guides the initial generation ofcomplex vector graphics through the Variational Score Distillation VSDprocess. In the second stage we refine the graphics using a layer-wise imagevectorization strategy to achieve clearer elements and structure. Wedemonstrate the effectiveness of our method through extensive experiments andshowcase various applications. The project page ishttps://intchous.github.io/T2V-NPR.</p>
                <p>Last Updated: 2024-05-16 17:59:22 UTC</p>
                <button class="interpret-button" data-id="2405.10317v1">Interpret</button>
                <div id="interpretation-2405.10317v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Analogist: Out-of-the-box Visual In-Context Learning with Image Diffusion Model</h3>
                <p>Authors: Zheng GuShiyuan YangJing LiaoJing HuoYang Gao</p>
                <p><a href="http://arxiv.org/abs/2405.10316v1">Link to paper</a></p>
                <p>Visual In-Context Learning ICL has emerged as a promising research area dueto its capability to accomplish various tasks with limited example pairsthrough analogical reasoning. However training-based visual ICL haslimitations in its ability to generalize to unseen tasks and requires thecollection of a diverse task dataset. On the other hand existing methods inthe inference-based visual ICL category solely rely on textual prompts whichfail to capture fine-grained contextual information from given examples and canbe time-consuming when converting from images to text prompts. To address thesechallenges we propose Analogist a novel inference-based visual ICL approachthat exploits both visual and textual prompting techniques using atext-to-image diffusion model pretrained for image inpainting. For visualprompting we propose a self-attention cloning SAC method to guide thefine-grained structural-level analogy between image examples. For textualprompting we leverage GPT-4Vs visual reasoning capability to efficientlygenerate text prompts and introduce a cross-attention masking CAM operationto enhance the accuracy of semantic-level analogy guided by text prompts. Ourmethod is out-of-the-box and does not require fine-tuning or optimization. Itis also generic and flexible enabling a wide range of visual tasks to beperformed in an in-context manner. Extensive experiments demonstrate thesuperiority of our method over existing approaches both qualitatively andquantitatively.</p>
                <p>Last Updated: 2024-05-16 17:59:21 UTC</p>
                <button class="interpret-button" data-id="2405.10316v1">Interpret</button>
                <div id="interpretation-2405.10316v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>CAT3D: Create Anything in 3D with Multi-View Diffusion Models</h3>
                <p>Authors: Ruiqi GaoAleksander HolynskiPhilipp HenzlerArthur BrusseeRicardo Martin-BruallaPratul SrinivasanJonathan T. BarronBen Poole</p>
                <p><a href="http://arxiv.org/abs/2405.10314v1">Link to paper</a></p>
                <p>Advances in 3D reconstruction have enabled high-quality 3D capture butrequire a user to collect hundreds to thousands of images to create a 3D scene.We present CAT3D a method for creating anything in 3D by simulating thisreal-world capture process with a multi-view diffusion model. Given any numberof input images and a set of target novel viewpoints our model generateshighly consistent novel views of a scene. These generated views can be used asinput to robust 3D reconstruction techniques to produce 3D representations thatcan be rendered from any viewpoint in real-time. CAT3D can create entire 3Dscenes in as little as one minute and outperforms existing methods for singleimage and few-view 3D scene creation. See our project page for results andinteractive demos at https://cat3d.github.io .</p>
                <p>Last Updated: 2024-05-16 17:59:05 UTC</p>
                <button class="interpret-button" data-id="2405.10314v1">Interpret</button>
                <div id="interpretation-2405.10314v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>4D Panoptic Scene Graph Generation</h3>
                <p>Authors: Jingkang YangJun CenWenxuan PengShuai LiuFangzhou HongXiangtai LiKaiyang ZhouQifeng ChenZiwei Liu</p>
                <p><a href="http://arxiv.org/abs/2405.10305v1">Link to paper</a></p>
                <p>We are living in a three-dimensional space while moving forward through afourth dimension: time. To allow artificial intelligence to develop acomprehensive understanding of such a 4D environment we introduce 4D PanopticScene Graph PSG-4D a new representation that bridges the raw visual dataperceived in a dynamic 4D world and high-level visual understanding.Specifically PSG-4D abstracts rich 4D sensory data into nodes which represententities with precise location and status information and edges which capturethe temporal relations. To facilitate research in this new area we build arichly annotated PSG-4D dataset consisting of 3K RGB-D videos with a total of1M frames each of which is labeled with 4D panoptic segmentation masks as wellas fine-grained dynamic scene graphs. To solve PSG-4D we propose PSG4DFormera Transformer-based model that can predict panoptic segmentation masks trackmasks along the time axis and generate the corresponding scene graphs via arelation component. Extensive experiments on the new dataset show that ourmethod can serve as a strong baseline for future research on PSG-4D. In theend we provide a real-world application example to demonstrate how we canachieve dynamic scene understanding by integrating a large language model intoour PSG-4D system.</p>
                <p>Last Updated: 2024-05-16 17:56:55 UTC</p>
                <button class="interpret-button" data-id="2405.10305v1">Interpret</button>
                <div id="interpretation-2405.10305v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Societal Adaptation to Advanced AI</h3>
                <p>Authors: Jamie BernardiGabriel MukobiHilary GreavesLennart HeimMarkus Anderljung</p>
                <p><a href="http://arxiv.org/abs/2405.10295v1">Link to paper</a></p>
                <p>Existing strategies for managing risks from advanced AI systems often focuson affecting what AI systems are developed and how they diffuse. However thisapproach becomes less feasible as the number of developers of advanced AIgrows and impedes beneficial use-cases as well as harmful ones. In responsewe urge a complementary approach: increasing societal adaptation to advancedAI that is reducing the expected negative impacts from a given level ofdiffusion of a given AI capability. We introduce a conceptual framework whichhelps identify adaptive interventions that avoid defend against and remedypotentially harmful uses of AI systems illustrated with examples in electionmanipulation cyberterrorism and loss of control to AI decision-makers. Wediscuss a three-step cycle that society can implement to adapt to AI.Increasing societys ability to implement this cycle builds its resilience toadvanced AI. We conclude with concrete recommendations for governmentsindustry and third-parties.</p>
                <p>Last Updated: 2024-05-16 17:52:12 UTC</p>
                <button class="interpret-button" data-id="2405.10295v1">Interpret</button>
                <div id="interpretation-2405.10295v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers</h3>
                <p>Authors: Tuo ZhangJinyue YuanSalman Avestimehr</p>
                <p><a href="http://arxiv.org/abs/2405.10276v1">Link to paper</a></p>
                <p>Numerous recent works aim to enhance the efficacy of Large Language ModelsLLMs through strategic prompting. In particular the Optimization byPROmpting OPRO approach provides state-of-the-art performance by leveragingLLMs as optimizers where the optimization task is to find instructions thatmaximize the task accuracy. In this paper we revisit OPRO for automatedprompting with relatively small-scale LLMs such as LLaMa-2 family and Mistral7B. Our investigation reveals that OPRO shows limited effectiveness insmall-scale LLMs with limited inference capabilities constraining optimizationability. We suggest future automatic prompting engineering to consider bothmodel capabilities and computational costs. Additionally for small-scale LLMswe recommend direct instructions that clearly outline objectives andmethodologies as robust prompt baselines ensuring efficient and effectiveprompt engineering in ongoing research.</p>
                <p>Last Updated: 2024-05-16 17:33:50 UTC</p>
                <button class="interpret-button" data-id="2405.10276v1">Interpret</button>
                <div id="interpretation-2405.10276v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>IntelliExplain: Enhancing Interactive Code Generation through Natural Language Explanations for Non-Professional Programmers</h3>
                <p>Authors: Hao YanThomas D. LatozaZiyu Yao</p>
                <p><a href="http://arxiv.org/abs/2405.10250v1">Link to paper</a></p>
                <p>Large language models LLMs have exhibited a strong promise in automaticallygenerating executable code from natural language descriptions particularlywith interactive features that allow users to engage in the code-generationprocess by instructing the LLM with iterative feedback. However existinginteraction paradigms often assume that users have expert knowledge to debugsource code and are not optimized for non-professional programmers use. Thisraises challenges in making interactive code generation more accessible forindividuals with varying levels of programming expertise. To tackle thesechallenges we present IntelliExplain which offers a novel human-LLMinteraction paradigm to enhance non-professional programmers experience byenabling them to interact with source code via natural language explanations.Users interact with IntelliExplain by providing natural language correctivefeedback on errors they identify from the explanations. Feedback is used by thesystem to revise the code until the user is satisfied with explanations by thesystem of the code. Our user study demonstrates that users with IntelliExplainachieve a significantly higher success rate 11.6 and 25.3 better than withvanilla GPT-3.5 while also requiring 39.0 and 15.6 less time in Text-to-SQLand Python code generation tasks respectively.</p>
                <p>Last Updated: 2024-05-16 16:55:06 UTC</p>
                <button class="interpret-button" data-id="2405.10250v1">Interpret</button>
                <div id="interpretation-2405.10250v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Co-Matching: Towards Human-Machine Collaborative Legal Case Matching</h3>
                <p>Authors: Chen HuangXinwei YangYang DengWenqiang LeiJianCheng LvTat-Seng Chua</p>
                <p><a href="http://arxiv.org/abs/2405.10248v1">Link to paper</a></p>
                <p>Recent efforts have aimed to improve AI machines in legal case matching byintegrating legal domain knowledge. However successful legal case matchingrequires the tacit knowledge of legal practitioners which is difficult toverbalize and encode into machines. This emphasizes the crucial role ofinvolving legal practitioners in high-stakes legal case matching. To addressthis we propose a collaborative matching framework called Co-Matching whichencourages both the machine and the legal practitioner to participate in thematching process integrating tacit knowledge. Unlike existing methods thatrely solely on the machine Co-Matching allows both the legal practitioner andthe machine to determine key sentences and then combine them probabilistically.Co-Matching introduces a method called ProtoEM to estimate human decisionuncertainty facilitating the probabilistic combination. Experimental resultsdemonstrate that Co-Matching consistently outperforms existing legal casematching methods delivering significant performance improvements over human-and machine-based matching in isolation on average 5.51 and 8.71respectively. Further analysis shows that Co-Matching also ensures betterhuman-machine collaboration effectiveness. Our study represents a pioneeringeffort in human-machine collaboration for the matching task marking amilestone for future collaborative matching studies.</p>
                <p>Last Updated: 2024-05-16 16:50:31 UTC</p>
                <button class="interpret-button" data-id="2405.10248v1">Interpret</button>
                <div id="interpretation-2405.10248v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Design Trajectory Map of Human-AI Collaborative Reinforcement Learning Systems: Survey and Taxonomy</h3>
                <p>Authors: Zhaoxing Li</p>
                <p><a href="http://arxiv.org/abs/2405.10214v1">Link to paper</a></p>
                <p>Driven by the algorithmic advancements in reinforcement learning and theincreasing number of implementations of human-AI collaboration CollaborativeReinforcement Learning CRL has been receiving growing attention. Despite thisrecent upsurge this area is still rarely systematically studied. In thispaper we provide an extensive survey investigating CRL methods based on bothinteractive reinforcement learning algorithms and human-AI collaborativeframeworks that were proposed in the past decade. We elucidate and discuss viasynergistic analysis methods both the growth of the field and thestate-of-the-art we conceptualise the existing frameworks from theperspectives of design patterns collaborative levels parties andcapabilities and review interactive methods and algorithmic models.Specifically we create a new Human-AI CRL Design Trajectory Map as asystematic modelling tool for the selection of existing CRL frameworks as wellas a method of designing new CRL systems and finally of improving future CRLdesigns. Furthermore we elaborate generic Human-AI CRL challenges providingthe research community with a guide towards novel research directions. The aimof this paper is to empower researchers with a systematic framework for thedesign of efficient and natural human-AI collaborative methods making itpossible to work on maximised realisation of humans and AIs potentials.</p>
                <p>Last Updated: 2024-05-16 16:04:20 UTC</p>
                <button class="interpret-button" data-id="2405.10214v1">Interpret</button>
                <div id="interpretation-2405.10214v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>TRANSIC: Sim-to-Real Policy Transfer by Learning from Online Correction</h3>
                <p>Authors: Yunfan JiangChen WangRuohan ZhangJiajun WuLi Fei-Fei</p>
                <p><a href="http://arxiv.org/abs/2405.10315v1">Link to paper</a></p>
                <p>Learning in simulation and transferring the learned policy to the real worldhas the potential to enable generalist robots. The key challenge of thisapproach is to address simulation-to-reality sim-to-real gaps. Previousmethods often require domain-specific knowledge a priori. We argue that astraightforward way to obtain such knowledge is by asking humans to observe andassist robot policy execution in the real world. The robots can then learn fromhumans to close various sim-to-real gaps. We propose TRANSIC a data-drivenapproach to enable successful sim-to-real transfer based on a human-in-the-loopframework. TRANSIC allows humans to augment simulation policies to overcomevarious unmodeled sim-to-real gaps holistically through intervention and onlinecorrection. Residual policies can be learned from human corrections andintegrated with simulation policies for autonomous execution. We show that ourapproach can achieve successful sim-to-real transfer in complex andcontact-rich manipulation tasks such as furniture assembly. Through synergisticintegration of policies learned in simulation and from humans TRANSIC iseffective as a holistic approach to addressing various often coexistingsim-to-real gaps. It displays attractive properties such as scaling with humaneffort. Videos and code are available at https://transic-robot.github.io/</p>
                <p>Last Updated: 2024-05-16 17:59:07 UTC</p>
                <button class="interpret-button" data-id="2405.10315v1">Interpret</button>
                <div id="interpretation-2405.10315v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>How Far Are We From AGI</h3>
                <p>Authors: Tao FengChuanyang JinJingyu LiuKunlun ZhuHaoqin TuZirui ChengGuanyu LinJiaxuan You</p>
                <p><a href="http://arxiv.org/abs/2405.10313v1">Link to paper</a></p>
                <p>The evolution of artificial intelligence AI has profoundly impacted humansociety driving significant advancements in multiple sectors. Yet theescalating demands on AI have highlighted the limitations of AIs currentofferings catalyzing a movement towards Artificial General Intelligence AGI.AGI distinguished by its ability to execute diverse real-world tasks withefficiency and effectiveness comparable to human intelligence reflects aparamount milestone in AI evolution. While existing works have summarizedspecific recent advancements of AI they lack a comprehensive discussion ofAGIs definitions goals and developmental trajectories. Different fromexisting survey papers this paper delves into the pivotal questions of ourproximity to AGI and the strategies necessary for its realization throughextensive surveys discussions and original perspectives. We start byarticulating the requisite capability frameworks for AGI integrating theinternal interface and system dimensions. As the realization of AGI requiresmore advanced capabilities and adherence to stringent constraints we furtherdiscuss necessary AGI alignment technologies to harmonize these factors.Notably we emphasize the importance of approaching AGI responsibly by firstdefining the key levels of AGI progression followed by the evaluationframework that situates the status-quo and finally giving our roadmap of howto reach the pinnacle of AGI. Moreover to give tangible insights into theubiquitous impact of the integration of AI we outline existing challenges andpotential pathways toward AGI in multiple domains. In sum serving as apioneering exploration into the current state and future trajectory of AGIthis paper aims to foster a collective comprehension and catalyze broaderpublic discussions among researchers and practitioners on AGI.</p>
                <p>Last Updated: 2024-05-16 17:59:02 UTC</p>
                <button class="interpret-button" data-id="2405.10313v1">Interpret</button>
                <div id="interpretation-2405.10313v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Stochastic Q-learning for Large Discrete Action Spaces</h3>
                <p>Authors: Fares FouratiVaneet AggarwalMohamed-Slim Alouini</p>
                <p><a href="http://arxiv.org/abs/2405.10310v1">Link to paper</a></p>
                <p>In complex environments with large discrete action spaces effectivedecision-making is critical in reinforcement learning RL. Despite thewidespread use of value-based RL approaches like Q-learning they come with acomputational burden necessitating the maximization of a value function overall actions in each iteration. This burden becomes particularly challengingwhen addressing large-scale problems and using deep neural networks as functionapproximators. In this paper we present stochastic value-based RL approacheswhich in each iteration as opposed to optimizing over the entire set of nactions only consider a variable stochastic set of a sublinear number ofactions possibly as small as mathcalOlogn. The presented stochasticvalue-based RL methods include among others Stochastic Q-learning StochDQNand StochDDQN all of which integrate this stochastic approach for bothvalue-function updates and action selection. The theoretical convergence ofStochastic Q-learning is established while an analysis of stochasticmaximization is provided. Moreover through empirical validation we illustratethat the various proposed approaches outperform the baseline methods acrossdiverse environments including different control problems achievingnear-optimal average returns in significantly reduced time.</p>
                <p>Last Updated: 2024-05-16 17:58:44 UTC</p>
                <button class="interpret-button" data-id="2405.10310v1">Interpret</button>
                <div id="interpretation-2405.10310v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>4D Panoptic Scene Graph Generation</h3>
                <p>Authors: Jingkang YangJun CenWenxuan PengShuai LiuFangzhou HongXiangtai LiKaiyang ZhouQifeng ChenZiwei Liu</p>
                <p><a href="http://arxiv.org/abs/2405.10305v1">Link to paper</a></p>
                <p>We are living in a three-dimensional space while moving forward through afourth dimension: time. To allow artificial intelligence to develop acomprehensive understanding of such a 4D environment we introduce 4D PanopticScene Graph PSG-4D a new representation that bridges the raw visual dataperceived in a dynamic 4D world and high-level visual understanding.Specifically PSG-4D abstracts rich 4D sensory data into nodes which represententities with precise location and status information and edges which capturethe temporal relations. To facilitate research in this new area we build arichly annotated PSG-4D dataset consisting of 3K RGB-D videos with a total of1M frames each of which is labeled with 4D panoptic segmentation masks as wellas fine-grained dynamic scene graphs. To solve PSG-4D we propose PSG4DFormera Transformer-based model that can predict panoptic segmentation masks trackmasks along the time axis and generate the corresponding scene graphs via arelation component. Extensive experiments on the new dataset show that ourmethod can serve as a strong baseline for future research on PSG-4D. In theend we provide a real-world application example to demonstrate how we canachieve dynamic scene understanding by integrating a large language model intoour PSG-4D system.</p>
                <p>Last Updated: 2024-05-16 17:56:55 UTC</p>
                <button class="interpret-button" data-id="2405.10305v1">Interpret</button>
                <div id="interpretation-2405.10305v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees</h3>
                <p>Authors: Yu GuiYing JinZhimei Ren</p>
                <p><a href="http://arxiv.org/abs/2405.10301v1">Link to paper</a></p>
                <p>Before deploying outputs from foundation models in high-stakes tasks it isimperative to ensure that they align with human values. For instance inradiology report generation reports generated by a vision-language model mustalign with human evaluations before their use in medical decision-making. Thispaper presents Conformal Alignment a general framework for identifying unitswhose outputs meet a user-specified alignment criterion. It is guaranteed thaton average a prescribed fraction of selected units indeed meet the alignmentcriterion regardless of the foundation model or the data distribution. Givenany pre-trained model and new units with model-generated outputs ConformalAlignment leverages a set of reference data with ground-truth alignment statusto train an alignment predictor. It then selects new units whose predictedalignment scores surpass a data-dependent threshold certifying theircorresponding outputs as trustworthy. Through applications to questionanswering and radiology report generation we demonstrate that our method isable to accurately identify units with trustworthy outputs via lightweighttraining over a moderate amount of reference data. En route we investigate theinformativeness of various features in alignment prediction and combine themwith standard models to construct the alignment predictor.</p>
                <p>Last Updated: 2024-05-16 17:55:24 UTC</p>
                <button class="interpret-button" data-id="2405.10301v1">Interpret</button>
                <div id="interpretation-2405.10301v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>Fusion Intelligence: Confluence of Natural and Artificial Intelligence for Enhanced Problem-Solving Efficiency</h3>
                <p>Authors: Rohan Reddy KalavakondaJunjun HuanPeyman DehghanzadehArchit JaiswalSoumyajit MandalSwarup Bhunia</p>
                <p><a href="http://arxiv.org/abs/2405.09763v1">Link to paper</a></p>
                <p>This paper introduces Fusion Intelligence FI a bio-inspired intelligentsystem where the innate sensing intelligence and unique actuation abilitiesof biological organisms such as bees and ants are integrated with thecomputational power of Artificial Intelligence AI. This interdisciplinaryfield seeks to create systems that are not only smart but also adaptive andresponsive in ways that mimic the nature. As FI evolves it holds the promiseof revolutionizing the way we approach complex problems leveraging the best ofboth biological and digital worlds to create solutions that are more effectivesustainable and harmonious with the environment. We demonstrate FIs potentialto enhance agricultural IoT system performance through a simulated case studyon improving insect pollination efficacy entomophily.</p>
                <p>Last Updated: 2024-05-16 02:10:30 UTC</p>
                <button class="interpret-button" data-id="2405.09763v1">Interpret</button>
                <div id="interpretation-2405.09763v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>BonnBot-I Plus: A Bio-diversity Aware Precise Weed Management Robotic Platform</h3>
                <p>Authors: Alireza AhmadiMichael HalsteadClaus SmittChris McCool</p>
                <p><a href="http://arxiv.org/abs/2405.09118v1">Link to paper</a></p>
                <p>In this article we focus on the critical tasks of plant protection in arablefarms addressing a modern challenge in agriculture: integrating ecologicalconsiderations into the operational strategy of precision weeding robots likebbot. This article presents the recent advancements in weed managementalgorithms and the real-world performance of bbot at the University of BonnsKlein-Altendorf campus. We present a novel Rolling-view observation model forthe BonnBot-Is weed monitoring section which leads to an average absoluteweeding performance enhancement of 3.4. Furthermore for the first time weshow how precision weeding robots could consider bio-diversity-aware concernsin challenging weeding scenarios. We carried out comprehensive weedingexperiments in sugar-beet fields covering both weed-only and mixed crop-weedsituations and introduced a new dataset compatible with precision weeding. Ourreal-field experiments revealed that our weeding approach is capable ofhandling diverse weed distributions with a minimal loss of only 11.66attributable to intervention planning and 14.7 to vision system limitationshighlighting required improvements of the vision system.</p>
                <p>Last Updated: 2024-05-15 06:23:59 UTC</p>
                <button class="interpret-button" data-id="2405.09118v1">Interpret</button>
                <div id="interpretation-2405.09118v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Feature-based Federated Transfer Learning: Communication Efficiency, Robustness and Privacy</h3>
                <p>Authors: Feng WangM. Cenk GursoySenem Velipasalar</p>
                <p><a href="http://arxiv.org/abs/2405.09014v1">Link to paper</a></p>
                <p>In this paper we propose feature-based federated transfer learning as anovel approach to improve communication efficiency by reducing the uplinkpayload by multiple orders of magnitude compared to that of existing approachesin federated learning and federated transfer learning. Specifically in theproposed feature-based federated learning we design the extracted features andoutputs to be uploaded instead of parameter updates. For this distributedlearning model we determine the required payload and provide comparisons withthe existing schemes. Subsequently we analyze the robustness of feature-basedfederated transfer learning against packet loss data insufficiency andquantization. Finally we address privacy considerations by defining andanalyzing label privacy leakage and feature privacy leakage and investigatingmitigating approaches. For all aforementioned analyses we evaluate theperformance of the proposed learning scheme via experiments on an imageclassification task and a natural language processing task to demonstrate itseffectiveness.</p>
                <p>Last Updated: 2024-05-15 00:43:19 UTC</p>
                <button class="interpret-button" data-id="2405.09014v1">Interpret</button>
                <div id="interpretation-2405.09014v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Beyond Theorems: A Counterexample to Potential Markov Game Criteria</h3>
                <p>Authors: Fatemeh FardnoSeyed Majid Zahedi</p>
                <p><a href="http://arxiv.org/abs/2405.08206v1">Link to paper</a></p>
                <p>There are only limited classes of multi-player stochastic games in whichindependent learning is guaranteed to converge to a Nash equilibrium. Markovpotential games are a key example of such classes. Prior work has outlined setsof sufficient conditions for a stochastic game to qualify as a Markov potentialgame. However these conditions often impose strict limitations on the gamesstructure and tend to be challenging to verify. To address these limitationsMguni et al. 12 introduce a relaxed notion of Markov potential games andoffer an alternative set of necessary conditions for categorizing stochasticgames as potential games. Under these conditions the authors claim that adeterministic Nash equilibrium can be computed efficiently by solving a dualMarkov decision process. In this paper we offer evidence refuting this claimby presenting a counterexample.</p>
                <p>Last Updated: 2024-05-13 21:49:15 UTC</p>
                <button class="interpret-button" data-id="2405.08206v1">Interpret</button>
                <div id="interpretation-2405.08206v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Evaluating Supply Chain Resilience During Pandemic Using Agent-based Simulation</h3>
                <p>Authors: Teddy Lazebnik</p>
                <p><a href="http://arxiv.org/abs/2405.08830v1">Link to paper</a></p>
                <p>Recent pandemics have highlighted vulnerabilities in our global economicsystems especially supply chains. Possible future pandemic raises a dilemmafor businesses owners between short-term profitability and long-term supplychain resilience planning. In this study we propose a novel agent-basedsimulation model integrating extended Susceptible-Infected-Recovered SIRepidemiological model and supply and demand economic model to evaluate supplychain resilience strategies during pandemics. Using this model we explore arange of supply chain resilience strategies under pandemic scenarios using insilico experiments. We find that a balanced approach to supply chain resilienceperforms better in both pandemic and non-pandemic times compared to extremestrategies highlighting the importance of preparedness in the form of a bettersupply chain resilience. However our analysis shows that the exact supplychain resilience strategy is hard to obtain for each firm and is relativelysensitive to the exact profile of the pandemic and economic state at thebeginning of the pandemic. As such we used a machine learning model that usesthe agent-based simulation to estimate a near-optimal supply chain resiliencestrategy for a firm. The proposed model offers insights for policymakers andbusinesses to enhance supply chain resilience in the face of future pandemicscontributing to understanding the trade-offs between short-term gains andlong-term sustainability in supply chain management before and duringpandemics.</p>
                <p>Last Updated: 2024-05-13 18:32:28 UTC</p>
                <button class="interpret-button" data-id="2405.08830v1">Interpret</button>
                <div id="interpretation-2405.08830v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>TRANSIC: Sim-to-Real Policy Transfer by Learning from Online Correction</h3>
                <p>Authors: Yunfan JiangChen WangRuohan ZhangJiajun WuLi Fei-Fei</p>
                <p><a href="http://arxiv.org/abs/2405.10315v1">Link to paper</a></p>
                <p>Learning in simulation and transferring the learned policy to the real worldhas the potential to enable generalist robots. The key challenge of thisapproach is to address simulation-to-reality sim-to-real gaps. Previousmethods often require domain-specific knowledge a priori. We argue that astraightforward way to obtain such knowledge is by asking humans to observe andassist robot policy execution in the real world. The robots can then learn fromhumans to close various sim-to-real gaps. We propose TRANSIC a data-drivenapproach to enable successful sim-to-real transfer based on a human-in-the-loopframework. TRANSIC allows humans to augment simulation policies to overcomevarious unmodeled sim-to-real gaps holistically through intervention and onlinecorrection. Residual policies can be learned from human corrections andintegrated with simulation policies for autonomous execution. We show that ourapproach can achieve successful sim-to-real transfer in complex andcontact-rich manipulation tasks such as furniture assembly. Through synergisticintegration of policies learned in simulation and from humans TRANSIC iseffective as a holistic approach to addressing various often coexistingsim-to-real gaps. It displays attractive properties such as scaling with humaneffort. Videos and code are available at https://transic-robot.github.io/</p>
                <p>Last Updated: 2024-05-16 17:59:07 UTC</p>
                <button class="interpret-button" data-id="2405.10315v1">Interpret</button>
                <div id="interpretation-2405.10315v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>How Far Are We From AGI</h3>
                <p>Authors: Tao FengChuanyang JinJingyu LiuKunlun ZhuHaoqin TuZirui ChengGuanyu LinJiaxuan You</p>
                <p><a href="http://arxiv.org/abs/2405.10313v1">Link to paper</a></p>
                <p>The evolution of artificial intelligence AI has profoundly impacted humansociety driving significant advancements in multiple sectors. Yet theescalating demands on AI have highlighted the limitations of AIs currentofferings catalyzing a movement towards Artificial General Intelligence AGI.AGI distinguished by its ability to execute diverse real-world tasks withefficiency and effectiveness comparable to human intelligence reflects aparamount milestone in AI evolution. While existing works have summarizedspecific recent advancements of AI they lack a comprehensive discussion ofAGIs definitions goals and developmental trajectories. Different fromexisting survey papers this paper delves into the pivotal questions of ourproximity to AGI and the strategies necessary for its realization throughextensive surveys discussions and original perspectives. We start byarticulating the requisite capability frameworks for AGI integrating theinternal interface and system dimensions. As the realization of AGI requiresmore advanced capabilities and adherence to stringent constraints we furtherdiscuss necessary AGI alignment technologies to harmonize these factors.Notably we emphasize the importance of approaching AGI responsibly by firstdefining the key levels of AGI progression followed by the evaluationframework that situates the status-quo and finally giving our roadmap of howto reach the pinnacle of AGI. Moreover to give tangible insights into theubiquitous impact of the integration of AI we outline existing challenges andpotential pathways toward AGI in multiple domains. In sum serving as apioneering exploration into the current state and future trajectory of AGIthis paper aims to foster a collective comprehension and catalyze broaderpublic discussions among researchers and practitioners on AGI.</p>
                <p>Last Updated: 2024-05-16 17:59:02 UTC</p>
                <button class="interpret-button" data-id="2405.10313v1">Interpret</button>
                <div id="interpretation-2405.10313v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Stochastic Q-learning for Large Discrete Action Spaces</h3>
                <p>Authors: Fares FouratiVaneet AggarwalMohamed-Slim Alouini</p>
                <p><a href="http://arxiv.org/abs/2405.10310v1">Link to paper</a></p>
                <p>In complex environments with large discrete action spaces effectivedecision-making is critical in reinforcement learning RL. Despite thewidespread use of value-based RL approaches like Q-learning they come with acomputational burden necessitating the maximization of a value function overall actions in each iteration. This burden becomes particularly challengingwhen addressing large-scale problems and using deep neural networks as functionapproximators. In this paper we present stochastic value-based RL approacheswhich in each iteration as opposed to optimizing over the entire set of nactions only consider a variable stochastic set of a sublinear number ofactions possibly as small as mathcalOlogn. The presented stochasticvalue-based RL methods include among others Stochastic Q-learning StochDQNand StochDDQN all of which integrate this stochastic approach for bothvalue-function updates and action selection. The theoretical convergence ofStochastic Q-learning is established while an analysis of stochasticmaximization is provided. Moreover through empirical validation we illustratethat the various proposed approaches outperform the baseline methods acrossdiverse environments including different control problems achievingnear-optimal average returns in significantly reduced time.</p>
                <p>Last Updated: 2024-05-16 17:58:44 UTC</p>
                <button class="interpret-button" data-id="2405.10310v1">Interpret</button>
                <div id="interpretation-2405.10310v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Optimal Aggregation of Prediction Intervals under Unsupervised Domain Shift</h3>
                <p>Authors: Jiawei GeDebarghya MukherjeeJianqing Fan</p>
                <p><a href="http://arxiv.org/abs/2405.10302v1">Link to paper</a></p>
                <p>As machine learning models are increasingly deployed in dynamic environmentsit becomes paramount to assess and quantify uncertainties associated withdistribution shifts. A distribution shift occurs when the underlyingdata-generating process changes leading to a deviation in the modelsperformance. The prediction interval which captures the range of likelyoutcomes for a given prediction serves as a crucial tool for characterizinguncertainties induced by their underlying distribution. In this paper wepropose methodologies for aggregating prediction intervals to obtain one withminimal width and adequate coverage on the target domain under unsuperviseddomain shift under which we have labeled samples from a related source domainand unlabeled covariates from the target domain. Our analysis encompassesscenarios where the source and the target domain are related via i a boundeddensity ratio and ii a measure-preserving transformation. Our proposedmethodologies are computationally efficient and easy to implement. Beyondillustrating the performance of our method through a real-world dataset wealso delve into the theoretical details. This includes establishing rigoroustheoretical guarantees coupled with finite sample bounds regarding thecoverage and width of our prediction intervals. Our approach excels inpractical applications and is underpinned by a solid theoretical frameworkensuring its reliability and effectiveness across diverse contexts.</p>
                <p>Last Updated: 2024-05-16 17:55:42 UTC</p>
                <button class="interpret-button" data-id="2405.10302v1">Interpret</button>
                <div id="interpretation-2405.10302v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees</h3>
                <p>Authors: Yu GuiYing JinZhimei Ren</p>
                <p><a href="http://arxiv.org/abs/2405.10301v1">Link to paper</a></p>
                <p>Before deploying outputs from foundation models in high-stakes tasks it isimperative to ensure that they align with human values. For instance inradiology report generation reports generated by a vision-language model mustalign with human evaluations before their use in medical decision-making. Thispaper presents Conformal Alignment a general framework for identifying unitswhose outputs meet a user-specified alignment criterion. It is guaranteed thaton average a prescribed fraction of selected units indeed meet the alignmentcriterion regardless of the foundation model or the data distribution. Givenany pre-trained model and new units with model-generated outputs ConformalAlignment leverages a set of reference data with ground-truth alignment statusto train an alignment predictor. It then selects new units whose predictedalignment scores surpass a data-dependent threshold certifying theircorresponding outputs as trustworthy. Through applications to questionanswering and radiology report generation we demonstrate that our method isable to accurately identify units with trustworthy outputs via lightweighttraining over a moderate amount of reference data. En route we investigate theinformativeness of various features in alignment prediction and combine themwith standard models to construct the alignment predictor.</p>
                <p>Last Updated: 2024-05-16 17:55:24 UTC</p>
                <button class="interpret-button" data-id="2405.10301v1">Interpret</button>
                <div id="interpretation-2405.10301v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-05-17</p>
        </div>
    
        </div>
    </body>
    </html>
    