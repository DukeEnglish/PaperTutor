
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Practices and Challenges of Online Love-seeking Among Deaf or Hard of Hearing People: A Case Study in China</h3>
                <p>Authors: Beiyan CaoJingling ZhangChangyang HeYuru HuangMuzhi ZhouMingming Fan</p>
                <p><a href="http://arxiv.org/abs/2410.11810v2">Link to paper</a></p>
                <p>People who are deaf or hard of hearing DHH in China are increasinglyexploring online platforms to connect with potential partners. This researchexplores the online dating experiences of DHH communities in China an areathat has not been extensively researched. We interviewed sixteen participantswho have varying levels of hearing ability and love-seeking statuses tounderstand how they manage their identities and communicate with potentialpartners online. We find that DHH individuals made great efforts to navigatethe rich modality features to seek love online. Participants used bothalgorithm-based dating apps and community-based platforms like forums andWeChat to facilitate initial encounters through text-based functions thatminimized the need for auditory interaction thus fostering a more equitablestarting point. Community-based platforms were found to facilitate morein-depth communication and excelled in fostering trust and authenticityproviding a more secure environment for genuine relationships. Designrecommendations are proposed to enhance the accessibility and inclusiveness ofonline dating platforms for DHH individuals in China. This research sheds lighton the benefits and challenges of online dating for DHH individuals in Chinaand provides guidance for platform developers and researchers to enhance userexperience in this area.</p>
                <p>Last Updated: 2024-10-16 04:26:07 UTC</p>
                <button class="interpret-button" data-id="2410.11810v2">Interpret</button>
                <div id="interpretation-2410.11810v2" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Personas with Attitudes: Controlling LLMs for Diverse Data Annotation</h3>
                <p>Authors: Leon Fr√∂hlingGianluca DemartiniDennis Assenmacher</p>
                <p><a href="http://arxiv.org/abs/2410.11745v1">Link to paper</a></p>
                <p>We present a novel approach for enhancing diversity and control in dataannotation tasks by personalizing large language models LLMs. We investigatethe impact of injecting diverse persona descriptions into LLM prompts acrosstwo studies exploring whether personas increase annotation diversity andwhether the impacts of individual personas on the resulting annotations areconsistent and controllable. Our results show that persona-prompted LLMsproduce more diverse annotations than LLMs prompted without personas and thatthese effects are both controllable and repeatable making our approach asuitable tool for improving data annotation in subjective NLP tasks liketoxicity detection.</p>
                <p>Last Updated: 2024-10-15 16:22:49 UTC</p>
                <button class="interpret-button" data-id="2410.11745v1">Interpret</button>
                <div id="interpretation-2410.11745v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation</h3>
                <p>Authors: Anton AntonovAndrey MoskalenkoDenis ShepelevAlexander KrapukhinKonstantin SoshinAnton KonushinVlad Shakhuro</p>
                <p><a href="http://arxiv.org/abs/2410.11722v1">Link to paper</a></p>
                <p>The emergence of Segment Anything SAM sparked research interest in thefield of interactive segmentation especially in the context of image editingtasks and speeding up data annotation. Unlike common semantic segmentationinteractive segmentation methods allow users to directly influence their outputthrough prompts e.g. clicks. However click patterns in real-worldinteractive segmentation scenarios remain largely unexplored. Most methods relyon the assumption that users would click in the center of the largest erroneousarea. Nevertheless recent studies show that this is not always the case. Thusmethods may have poor performance in real-world deployment despite high metricsin a baseline benchmark. To accurately simulate real-user clicks we conducteda large crowdsourcing study of click patterns in an interactive segmentationscenario and collected 475K real-user clicks. Drawing on ideas from saliencytasks we develop a clickability model that enables sampling clicks whichclosely resemble actual user inputs. Using our model and dataset we proposeRClicks benchmark for a comprehensive comparison of existing interactivesegmentation methods on realistic clicks. Specifically we evaluate not onlythe average quality of methods but also the robustness w.r.t. click patterns.According to our benchmark in real-world usage interactive segmentation modelsmay perform worse than it has been reported in the baseline benchmark and mostof the methods are not robust. We believe that RClicks is a significant steptowards creating interactive segmentation methods that provide the best userexperience in real-world cases.</p>
                <p>Last Updated: 2024-10-15 15:55:00 UTC</p>
                <button class="interpret-button" data-id="2410.11722v1">Interpret</button>
                <div id="interpretation-2410.11722v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Human-LLM Collaborative Construction of a Cantonese Emotion Lexicon</h3>
                <p>Authors: Yusong ZhangDong DongChi-tim HungLeonard HeyerdahlTamara Giles-VernickEng-kiong Yeoh</p>
                <p><a href="http://arxiv.org/abs/2410.11526v1">Link to paper</a></p>
                <p>Large Language Models LLMs have demonstrated remarkable capabilities inlanguage understanding and generation. Advanced utilization of the knowledgeembedded in LLMs for automated annotation has consistently been explored. Thisstudy proposed to develop an emotion lexicon for Cantonese a low-resourcelanguage through collaborative efforts between LLM and human annotators. Byintegrating emotion labels provided by LLM and human annotators the studyleveraged existing linguistic resources including lexicons in other languagesand local forums to construct a Cantonese emotion lexicon enriched withcolloquial expressions. The consistency of the proposed emotion lexicon inemotion extraction was assessed through modification and utilization of threedistinct emotion text datasets. This study not only validates the efficacy ofthe constructed lexicon but also emphasizes that collaborative annotationbetween human and artificial intelligence can significantly enhance the qualityof emotion labels highlighting the potential of such partnerships infacilitating natural language processing tasks for low-resource languages.</p>
                <p>Last Updated: 2024-10-15 11:57:34 UTC</p>
                <button class="interpret-button" data-id="2410.11526v1">Interpret</button>
                <div id="interpretation-2410.11526v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>EmoBridge: Bridging the Communication Gap between Students with Disabilities and Peer Note-Takers Utilizing Emojis and Real-Time Sharing</h3>
                <p>Authors: Hyungwoo SongMinjeong ShinHyehyun ChuJiin HongJaechan LeeJinsu EunHajin Lim</p>
                <p><a href="http://arxiv.org/abs/2410.11432v1">Link to paper</a></p>
                <p>Students with disabilities SWDs often struggle with note-taking duringlectures. Therefore many higher education institutions have implemented peernote-taking programs PNTPs where peer note-takers PNTs assist SWDs intaking lecture notes. To better understand the experiences of SWDs and PNTs weconducted semi-structured interviews with eight SWDs and eight PNTs. We foundthat the interaction between SWDs and PNTs was predominantly unidirectionalhighlighting specific needs and challenges. In response we developedEmoBridge a collaborative note-taking platform that facilitates real-timecollaboration and communication between PNT-SWD pairs using emojis. Weevaluated EmoBridge through an in-the-wild study with seven PNT-SWD pairs. Theresults showed improved class participation for SWDs and a reduced sense ofsole responsibility for PNTs. Based on these insights we discuss designimplications for collaborative note-taking systems aimed at enhancing PNTPs andfostering more effective and inclusive educational experiences for SWDs.</p>
                <p>Last Updated: 2024-10-15 09:34:33 UTC</p>
                <button class="interpret-button" data-id="2410.11432v1">Interpret</button>
                <div id="interpretation-2410.11432v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks</h3>
                <p>Authors: Guibin ZhangYanwei YueXiangguo SunGuancheng WanMiao YuJunfeng FangKun WangDawei Cheng</p>
                <p><a href="http://arxiv.org/abs/2410.11782v1">Link to paper</a></p>
                <p>Recent advancements in large language model LLM-based agents havedemonstrated that collective intelligence can significantly surpass thecapabilities of individual agents primarily due to well-crafted inter-agentcommunication topologies. Despite the diverse and high-performing designsavailable practitioners often face confusion when selecting the most effectivepipeline for their specific task: textitWhich topology is the best choice formy task avoiding unnecessary communication token overhead while ensuringhigh-quality solution In response to this dilemma we introduce G-Designeran adaptive efficient and robust solution for multi-agent deployment whichdynamically designs task-aware customized communication topologies.Specifically G-Designer models the multi-agent system as a multi-agentnetwork leveraging a variational graph auto-encoder to encode both the nodesagents and a task-specific virtual node and decodes a task-adaptive andhigh-performing communication topology. Extensive experiments on six benchmarksshowcase that G-Designer is: textbf1 high-performing achieving superiorresults on MMLU with accuracy at 84.50 and on HumanEval with pass1 at89.90 textbf2 task-adaptive architecting communication protocolstailored to task difficulty reducing token consumption by up to 95.33 onHumanEval and textbf3 adversarially robust defending against agentadversarial attacks with merely 0.3 accuracy drop.</p>
                <p>Last Updated: 2024-10-15 17:01:21 UTC</p>
                <button class="interpret-button" data-id="2410.11782v1">Interpret</button>
                <div id="interpretation-2410.11782v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Improve Value Estimation of Q Function and Reshape Reward with Monte Carlo Tree Search</h3>
                <p>Authors: Jiamian Li</p>
                <p><a href="http://arxiv.org/abs/2410.11642v1">Link to paper</a></p>
                <p>Reinforcement learning has achieved remarkable success in perfect informationgames such as Go and Atari enabling agents to compete at the highest levelsagainst human players. However research in reinforcement learning forimperfect information games has been relatively limited due to the more complexgame structures and randomness. Traditional methods face challenges in trainingand improving performance in imperfect information games due to issues likeinaccurate Q value estimation and reward sparsity. In this paper we focus onUno an imperfect information game and aim to address these problems byreducing Q value overestimation and reshaping reward function. We propose anovel algorithm that utilizes Monte Carlo Tree Search to improve the valueestimation in Q function. Even though we choose Double Deep Q Learning as thefoundational framework in this paper our method can be generalized and used inany algorithm which needs Q value estimation such as the Actor-Critic.Additionally we employ Monte Carlo Tree Search to reshape the reward structurein the game environment. We compared our algorithm with several traditionalmethods applied to games such as Double Deep Q Learning Deep Monte Carlo andNeural Fictitious Self Play and the experiments demonstrate that our algorithmconsistently outperforms these approaches especially as the number of playersin Uno increases indicating a higher level of difficulty.</p>
                <p>Last Updated: 2024-10-15 14:31:54 UTC</p>
                <button class="interpret-button" data-id="2410.11642v1">Interpret</button>
                <div id="interpretation-2410.11642v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Agent-Based Modelling of Older Adult Needs for Autonomous Mobility-on-Demand: A Case Study in Winnipeg, Canada</h3>
                <p>Authors: Manon Pr√©dhumeauEd Manley</p>
                <p><a href="http://arxiv.org/abs/2410.11416v1">Link to paper</a></p>
                <p>As the populations continue to age across many nations ensuring accessibleand efficient transportation options for older adults has become anincreasingly important concern. Autonomous Mobility-on-Demand AMoD systemshave emerged as a potential solution to address the needs faced by older adultsin their daily mobility. However estimation of older adult mobility needs andhow they vary over space and time is crucial for effective planning andimplementation of such service and conventional four-step approaches lack thegranularity to fully account for these needs. To address this challenge wepropose an agent-based model of older adults mobility demand in WinnipegCanada. The model is built for 2022 using primarily open data and isimplemented in the Multi-Agent Transport Simulation MATSim toolkit. Aftercalibration to accurately reproduce observed travel behaviors a new AMoDservice is tested in simulation and its potential adoption among Winnipeg olderadults is explored. The model can help policy makers to estimate the needs ofthe elderly populations for door-to-door transportation and can guide thedesign of AMoD transport systems.</p>
                <p>Last Updated: 2024-10-15 09:03:58 UTC</p>
                <button class="interpret-button" data-id="2410.11416v1">Interpret</button>
                <div id="interpretation-2410.11416v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack</h3>
                <p>Authors: Naman GuptaShashank KirtaniaPriyanshu GuptaKrishna KariyaSumit GulwaniArun IyerSuresh ParthasarathyArjun RadhakrishnaSriram K. RajamaniGustavo Soares</p>
                <p><a href="http://arxiv.org/abs/2410.10584v1">Link to paper</a></p>
                <p>Large Language Models LLMs often generate incorrect or outdatedinformation especially in low-resource settings or when dealing with privatedata. To address this Retrieval-Augmented Generation RAG uses externalknowledge bases KBs but these can also suffer from inaccuracies. Weintroduce STACKFEED a novel Structured Textual Actor-Critic Knowledge baseediting with FEEDback approach that iteratively refines the KB based on expertfeedback using a multi-actor centralized critic reinforcement learningframework. Each document is assigned to an actor modeled as a ReACT agentwhich performs structured edits based on document-specific targetedinstructions from a centralized critic. Experimental results show thatSTACKFEED significantly improves KB quality and RAG system performanceenhancing accuracy by up to 8 over baselines.</p>
                <p>Last Updated: 2024-10-14 14:56:01 UTC</p>
                <button class="interpret-button" data-id="2410.10584v1">Interpret</button>
                <div id="interpretation-2410.10584v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Content Caching-Assisted Vehicular Edge Computing Using Multi-Agent Graph Attention Reinforcement Learning</h3>
                <p>Authors: Jinjin ShenYan LinYijin ZhangWeibin ZhangFeng ShuJun Li</p>
                <p><a href="http://arxiv.org/abs/2410.10071v1">Link to paper</a></p>
                <p>In order to avoid repeated task offloading and realize the reuse of populartask computing results we construct a novel content caching-assisted vehicularedge computing VEC framework. In the face of irregular network topology andunknown environmental dynamics we further propose a multi-agent graphattention reinforcement learning MGARL based edge caching scheme whichutilizes the graph attention convolution kernel to integrate the neighboringnodes features of each agent and further enhance the cooperation among agents.Our simulation results show that our proposed scheme is capable of improvingthe utilization of caching resources while reducing the long-term taskcomputing latency compared to the baselines.</p>
                <p>Last Updated: 2024-10-14 01:25:56 UTC</p>
                <button class="interpret-button" data-id="2410.10071v1">Interpret</button>
                <div id="interpretation-2410.10071v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions</h3>
                <p>Authors: Ayush JainNorio KosakaXinhu LiKyung-Min KimErdem Bƒ±yƒ±kJoseph J. Lim</p>
                <p><a href="http://arxiv.org/abs/2410.11833v1">Link to paper</a></p>
                <p>In reinforcement learning off-policy actor-critic approaches like DDPG andTD3 are based on the deterministic policy gradient. Herein the Q-function istrained from off-policy environment data and the actor policy is trained tomaximize the Q-function via gradient ascent. We observe that in complex taskslike dexterous manipulation and restricted locomotion the Q-value is a complexfunction of action having several local optima or discontinuities. This posesa challenge for gradient ascent to traverse and makes the actor prone to getstuck at local optima. To address this we introduce a new actor architecturethat combines two simple insights: i use multiple actors and evaluate theQ-value maximizing action and ii learn surrogates to the Q-function that aresimpler to optimize with gradient-based methods. We evaluate tasks such asrestricted locomotion dexterous manipulation and large discrete-action spacerecommender systems and show that our actor finds optimal actions morefrequently and outperforms alternate actor architectures.</p>
                <p>Last Updated: 2024-10-15 17:58:03 UTC</p>
                <button class="interpret-button" data-id="2410.11833v1">Interpret</button>
                <div id="interpretation-2410.11833v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Bayesian Experimental Design via Contrastive Diffusions</h3>
                <p>Authors: Jacopo IolloChristophe Heinkel√©Pierre AlliezFlorence Forbes</p>
                <p><a href="http://arxiv.org/abs/2410.11826v1">Link to paper</a></p>
                <p>Bayesian Optimal Experimental Design BOED is a powerful tool to reduce thecost of running a sequence of experiments. When based on the ExpectedInformation Gain EIG design optimization corresponds to the maximization ofsome intractable expected it contrast between prior and posteriordistributions. Scaling this maximization to high dimensional and complexsettings has been an issue due to BOED inherent computational complexity. Inthis work we introduce an it expected posterior distribution withcost-effective sampling properties and provide a tractable access to the EIGcontrast maximization via a new EIG gradient expression. Diffusion-basedsamplers are used to compute the dynamics of the expected posterior and ideasfrom bi-level optimization are leveraged to derive an efficient jointsampling-optimization loop without resorting to lower bound approximations ofthe EIG. The resulting efficiency gain allows to extend BOED to the well-testedgenerative capabilities of diffusion models. By incorporating generative modelsinto the BOED framework we expand its scope and its use in scenarios that werepreviously impractical. Numerical experiments and comparison withstate-of-the-art methods show the potential of the approach.</p>
                <p>Last Updated: 2024-10-15 17:53:07 UTC</p>
                <button class="interpret-button" data-id="2410.11826v1">Interpret</button>
                <div id="interpretation-2410.11826v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Solving The Dynamic Volatility Fitting Problem: A Deep Reinforcement Learning Approach</h3>
                <p>Authors: Emmanuel GnabeyeuOmar KarkarImad Idboufous</p>
                <p><a href="http://arxiv.org/abs/2410.11789v1">Link to paper</a></p>
                <p>The volatility fitting is one of the core problems in the equity derivativesbusiness. Through a set of deterministic rules the degrees of freedom in theimplied volatility surface encoding parametrization density diffusion aredefined. Whilst very effective this approach widespread in the industry is notnatively tailored to learn from shifts in market regimes and discoverunsuspected optimal behaviors. In this paper we change the classical paradigmand apply the latest advances in Deep Reinforcement LearningDRL to solve thefitting problem. In particular we show that variants of Deep DeterministicPolicy Gradient DDPG and Soft Actor Critic SAC can achieve at least as goodas standard fitting algorithms. Furthermore we explain why the reinforcementlearning framework is appropriate to handle complex objective functions and isnatively adapted for online learning.</p>
                <p>Last Updated: 2024-10-15 17:10:54 UTC</p>
                <button class="interpret-button" data-id="2410.11789v1">Interpret</button>
                <div id="interpretation-2410.11789v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>On the Training Convergence of Transformers for In-Context Classification</h3>
                <p>Authors: Wei ShenRuida ZhouJing YangCong Shen</p>
                <p><a href="http://arxiv.org/abs/2410.11778v1">Link to paper</a></p>
                <p>While transformers have demonstrated impressive capacities for in-contextlearning ICL in practice theoretical understanding of the underlyingmechanism enabling transformers to perform ICL is still in its infant stage.This work aims to theoretically study the training dynamics of transformers forin-context classification tasks. We demonstrate that for in-contextclassification of Gaussian mixtures under certain assumptions a single-layertransformer trained via gradient descent converges to a globally optimal modelat a linear rate. We further quantify the impact of the training and testingprompt lengths on the ICL inference error of the trained transformer. We showthat when the lengths of training and testing prompts are sufficiently largethe prediction of the trained transformer approaches the Bayes-optimalclassifier. Experimental results corroborate the theoretical findings.</p>
                <p>Last Updated: 2024-10-15 16:57:14 UTC</p>
                <button class="interpret-button" data-id="2410.11778v1">Interpret</button>
                <div id="interpretation-2410.11778v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>l_inf-approximation of localized distributions</h3>
                <p>Authors: Tiangang CuiShuigen LiuXin Tong</p>
                <p><a href="http://arxiv.org/abs/2410.11771v1">Link to paper</a></p>
                <p>Distributions in spatial model often exhibit localized features. Intuitivelythis locality implies a low intrinsic dimensionality which can be exploitedfor efficient approximation and computation of complex distributions. Howeverexisting approximation theory mainly considers the joint distributions whichdoes not guarantee that the marginal errors are small. In this work weestablish a dimension independent error bound for the marginals of approximatedistributions. This ell_infty-approximation error is obtained using Steinsmethod and we propose a delta-locality condition that quantifies the degreeof localization in a distribution. We also show how delta-locality can bederived from different conditions that characterize the distributionslocality. Our ell_infty bound motivates the localization of existingapproximation methods to respect the locality. As examples we show how to uselocalized likelihood-informed subspace method and localized score matchingwhich not only avoid dimension dependence in the approximation error but alsosignificantly reduce the computational cost due to the local and parallelimplementation based on the localized structure.</p>
                <p>Last Updated: 2024-10-15 16:47:05 UTC</p>
                <button class="interpret-button" data-id="2410.11771v1">Interpret</button>
                <div id="interpretation-2410.11771v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>MoH: Multi-Head Attention as Mixture-of-Head Attention</h3>
                <p>Authors: Peng JinBo ZhuLi YuanShuicheng Yan</p>
                <p><a href="http://arxiv.org/abs/2410.11842v1">Link to paper</a></p>
                <p>In this work we upgrade the multi-head attention mechanism the core of theTransformer model to improve efficiency while maintaining or surpassing theprevious accuracy level. We show that multi-head attention can be expressed inthe summation form. Drawing on the insight that not all attention heads holdequal significance we propose Mixture-of-Head attention MoH a newarchitecture that treats attention heads as experts in the Mixture-of-ExpertsMoE mechanism. MoH has two significant advantages: First MoH enables eachtoken to select the appropriate attention heads enhancing inference efficiencywithout compromising accuracy or increasing the number of parameters. SecondMoH replaces the standard summation in multi-head attention with a weightedsummation introducing flexibility to the attention mechanism and unlockingextra performance potential. Extensive experiments on ViT DiT and LLMsdemonstrate that MoH outperforms multi-head attention by using only 50-90 ofthe attention heads. Moreover we demonstrate that pre-trained multi-headattention models such as LLaMA3-8B can be further continue-tuned into our MoHmodels. Notably MoH-LLaMA3-8B achieves an average accuracy of 64.0 across 14benchmarks outperforming LLaMA3-8B by 2.4 by utilizing only 75 of theattention heads. We believe the proposed MoH is a promising alternative tomulti-head attention and provides a strong foundation for developing advancedand efficient attention-based models.</p>
                <p>Last Updated: 2024-10-15 17:59:44 UTC</p>
                <button class="interpret-button" data-id="2410.11842v1">Interpret</button>
                <div id="interpretation-2410.11842v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>High-Resolution Frame Interpolation with Patch-based Cascaded Diffusion</h3>
                <p>Authors: Junhwa HurCharles HerrmannSaurabh SaxenaJanne KontkanenWei-Sheng LaiYichang ShihMichael RubinsteinDavid J. FleetDeqing Sun</p>
                <p><a href="http://arxiv.org/abs/2410.11838v1">Link to paper</a></p>
                <p>Despite the recent progress existing frame interpolation methods stillstruggle with processing extremely high resolution input and handlingchallenging cases such as repetitive textures thin objects and large motion.To address these issues we introduce a patch-based cascaded pixel diffusionmodel for frame interpolation HiFI that excels in these scenarios whileachieving competitive performance on standard benchmarks. Cascades whichgenerate a series of images from low- to high-resolution can helpsignificantly with large or complex motion that require both global context fora coarse solution and detailed context for high resolution output. Howevercontrary to prior work on cascaded diffusion models which perform diffusion onincreasingly large resolutions we use a single model that always performsdiffusion at the same resolution and upsamples by processing patches of theinputs and the prior solution. We show that this technique drastically reducesmemory usage at inference time and also allows us to use a single model at testtime solving both frame interpolation and spatial up-sampling saving trainingcost. We show that HiFI helps significantly with high resolution and complexrepeated textures that require global context. HiFI demonstrates comparable orbeyond state-of-the-art performance on multiple benchmarks Vimeo XiphX-Test SEPE-8K. On our newly introduced dataset that focuses on particularlychallenging cases HiFI also significantly outperforms other baselines on thesecases. Please visit our project page for video results:https://hifi-diffusion.github.io</p>
                <p>Last Updated: 2024-10-15 17:59:04 UTC</p>
                <button class="interpret-button" data-id="2410.11838v1">Interpret</button>
                <div id="interpretation-2410.11838v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>On the Effectiveness of Dataset Alignment for Fake Image Detection</h3>
                <p>Authors: Anirudh Sundara RajanUtkarsh OjhaJedidiah SchloesserYong Jae Lee</p>
                <p><a href="http://arxiv.org/abs/2410.11835v1">Link to paper</a></p>
                <p>As latent diffusion models LDMs democratize image generation capabilitiesthere is a growing need to detect fake images. A good detector should focus onthe generative models fingerprints while ignoring image properties such assemantic content resolution file format etc. Fake image detectors areusually built in a data driven way where a model is trained to separate realfrom fake images. Existing works primarily investigate network architecturechoices and training recipes. In this work we argue that in addition to thesealgorithmic choices we also require a well aligned dataset of real/fake imagesto train a robust detector. For the family of LDMs we propose a very simpleway to achieve this: we reconstruct all the real images using the LDMsautoencoder without any denoising operation. We then train a model to separatethese real images from their reconstructions. The fakes created this way areextremely similar to the real ones in almost every aspect e.g. size aspectratio semantic content which forces the model to look for the LDM decodersartifacts. We empirically show that this way of creating aligned real/fakedatasets which also sidesteps the computationally expensive denoising processhelps in building a detector that focuses less on spurious correlationssomething that a very popular existing method is susceptible to. Finally todemonstrate just how effective the alignment in a dataset can be we build adetector using images that are not natural objects and present promisingresults. Overall our work identifies the subtle but significant issues thatarise when training a fake image detector and proposes a simple and inexpensivesolution to address these problems.</p>
                <p>Last Updated: 2024-10-15 17:58:07 UTC</p>
                <button class="interpret-button" data-id="2410.11835v1">Interpret</button>
                <div id="interpretation-2410.11835v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos</h3>
                <p>Authors: Nikita KaraevIurii MakarovJianyuan WangNatalia NeverovaAndrea VedaldiChristian Rupprecht</p>
                <p><a href="http://arxiv.org/abs/2410.11831v1">Link to paper</a></p>
                <p>Most state-of-the-art point trackers are trained on synthetic data due to thedifficulty of annotating real videos for this task. However this can result insuboptimal performance due to the statistical gap between synthetic and realvideos. In order to understand these issues better we introduce CoTracker3comprising a new tracking model and a new semi-supervised training recipe. Thisallows real videos without annotations to be used during training by generatingpseudo-labels using off-the-shelf teachers. The new model eliminates orsimplifies components from previous trackers resulting in a simpler and oftensmaller architecture. This training scheme is much simpler than prior work andachieves better results using 1000 times less data. We further study thescaling behaviour to understand the impact of using more real unsupervised datain point tracking. The model is available in online and offline variants andreliably tracks visible and occluded points.</p>
                <p>Last Updated: 2024-10-15 17:56:32 UTC</p>
                <button class="interpret-button" data-id="2410.11831v1">Interpret</button>
                <div id="interpretation-2410.11831v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>MMFuser: Multimodal Multi-Layer Feature Fuser for Fine-Grained Vision-Language Understanding</h3>
                <p>Authors: Yue CaoYangzhou LiuZhe ChenGuangchen ShiWenhai WangDanhuai ZhaoTong Lu</p>
                <p><a href="http://arxiv.org/abs/2410.11829v1">Link to paper</a></p>
                <p>Despite significant advancements in Multimodal Large Language Models MLLMsfor understanding complex human intentions through cross-modal interactionscapturing intricate image details remains challenging. Previous methodsintegrating multiple vision encoders to enhance visual detail introduceredundancy and computational overhead. We observe that most MLLMs utilize onlythe last-layer feature map of the vision encoder for visual representationneglecting the rich fine-grained information in shallow feature maps. Toaddress this issue we propose modelname a simple yet effective multi-layerfeature fuser that efficiently integrates deep and shallow features from VisionTransformers ViTs. Specifically it leverages semantically aligned deepfeatures as queries to dynamically extract missing details from shallowfeatures thus preserving semantic alignment while enriching the representationwith fine-grained information. Applied to the LLaVA-1.5 modelmodelnameachieves significant improvements in visual representation andbenchmark performance providing a more flexible and lightweight solutioncompared to multi-encoder ensemble methods. The code and model have beenreleased at https://github.com/yuecao0119/MMFuser.</p>
                <p>Last Updated: 2024-10-15 17:55:22 UTC</p>
                <button class="interpret-button" data-id="2410.11829v1">Interpret</button>
                <div id="interpretation-2410.11829v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>MoH: Multi-Head Attention as Mixture-of-Head Attention</h3>
                <p>Authors: Peng JinBo ZhuLi YuanShuicheng Yan</p>
                <p><a href="http://arxiv.org/abs/2410.11842v1">Link to paper</a></p>
                <p>In this work we upgrade the multi-head attention mechanism the core of theTransformer model to improve efficiency while maintaining or surpassing theprevious accuracy level. We show that multi-head attention can be expressed inthe summation form. Drawing on the insight that not all attention heads holdequal significance we propose Mixture-of-Head attention MoH a newarchitecture that treats attention heads as experts in the Mixture-of-ExpertsMoE mechanism. MoH has two significant advantages: First MoH enables eachtoken to select the appropriate attention heads enhancing inference efficiencywithout compromising accuracy or increasing the number of parameters. SecondMoH replaces the standard summation in multi-head attention with a weightedsummation introducing flexibility to the attention mechanism and unlockingextra performance potential. Extensive experiments on ViT DiT and LLMsdemonstrate that MoH outperforms multi-head attention by using only 50-90 ofthe attention heads. Moreover we demonstrate that pre-trained multi-headattention models such as LLaMA3-8B can be further continue-tuned into our MoHmodels. Notably MoH-LLaMA3-8B achieves an average accuracy of 64.0 across 14benchmarks outperforming LLaMA3-8B by 2.4 by utilizing only 75 of theattention heads. We believe the proposed MoH is a promising alternative tomulti-head attention and provides a strong foundation for developing advancedand efficient attention-based models.</p>
                <p>Last Updated: 2024-10-15 17:59:44 UTC</p>
                <button class="interpret-button" data-id="2410.11842v1">Interpret</button>
                <div id="interpretation-2410.11842v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable Recommendation</h3>
                <p>Authors: Fei TangYongliang ShenHang ZhangZeqi TanWenqi ZhangGuiyang HouKaitao SongWeiming LuYueting Zhuang</p>
                <p><a href="http://arxiv.org/abs/2410.11841v1">Link to paper</a></p>
                <p>Large language model-based explainable recommendation LLM-based ER systemsshow promise in generating human-like explanations for recommendations.However they face challenges in modeling user-item collaborative preferencespersonalizing explanations and handling sparse user-item interactions. Toaddress these issues we propose GaVaMoE a novel Gaussian-Variational GatedMixture of Experts framework for explainable recommendation. GaVaMoE introducestwo key components: 1 a rating reconstruction module that employs VariationalAutoencoder VAE with a Gaussian Mixture Model GMM to capture complexuser-item collaborative preferences serving as a pre-trained multi-gatingmechanism and 2 a set of fine-grained expert models coupled with themulti-gating mechanism for generating highly personalized explanations. The VAEcomponent models latent factors in user-item interactions while the GMMclusters users with similar behaviors. Each cluster corresponds to a gate inthe multi-gating mechanism routing user-item pairs to appropriate expertmodels. This architecture enables GaVaMoE to generate tailored explanations forspecific user types and preferences mitigating data sparsity by leveraginguser similarities. Extensive experiments on three real-world datasetsdemonstrate that GaVaMoE significantly outperforms existing methods inexplanation quality personalization and consistency. Notably GaVaMoEexhibits robust performance in scenarios with sparse user-item interactionsmaintaining high-quality explanations even for users with limited historicaldata.</p>
                <p>Last Updated: 2024-10-15 17:59:30 UTC</p>
                <button class="interpret-button" data-id="2410.11841v1">Interpret</button>
                <div id="interpretation-2410.11841v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Hitchhiker's Guide to Scaling Law Estimation</h3>
                <p>Authors: Leshem ChoshenYang ZhangJacob Andreas</p>
                <p><a href="http://arxiv.org/abs/2410.11840v1">Link to paper</a></p>
                <p>Scaling laws predict the loss of a target machine learning model byextrapolating from easier-to-train models with fewer parameters or smallertraining sets. This provides an efficient way for practitioners and researchersalike to compare pretraining decisions involving optimizers datasets andmodel architectures. Despite the widespread use of scaling laws to model thedynamics of language model training there has been little work onunderstanding how to best estimate and interpret them. We collect and releasea large-scale dataset containing losses and downstream evaluations for 485previously published pretrained models. We use these to estimate more than 1000scaling laws then derive a set of best practices for estimating scaling lawsin new model families. We find that fitting scaling laws to intermediatecheckpoints of training runs and not just their final losses substantiallyimproves accuracy and that -- all else equal -- estimates of performance aregenerally most accurate when derived from other models of similar sizes.However because there is a significant degree of variability across modelseeds training multiple small models is sometimes more useful than training asingle large one. Moreover while different model families differ scalingbehavior they are often similar enough that a target models behavior can bepredicted from a single model with the same architecture along with scalingparameter estimates derived from other model families.</p>
                <p>Last Updated: 2024-10-15 17:59:10 UTC</p>
                <button class="interpret-button" data-id="2410.11840v1">Interpret</button>
                <div id="interpretation-2410.11840v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions</h3>
                <p>Authors: Ayush JainNorio KosakaXinhu LiKyung-Min KimErdem Bƒ±yƒ±kJoseph J. Lim</p>
                <p><a href="http://arxiv.org/abs/2410.11833v1">Link to paper</a></p>
                <p>In reinforcement learning off-policy actor-critic approaches like DDPG andTD3 are based on the deterministic policy gradient. Herein the Q-function istrained from off-policy environment data and the actor policy is trained tomaximize the Q-function via gradient ascent. We observe that in complex taskslike dexterous manipulation and restricted locomotion the Q-value is a complexfunction of action having several local optima or discontinuities. This posesa challenge for gradient ascent to traverse and makes the actor prone to getstuck at local optima. To address this we introduce a new actor architecturethat combines two simple insights: i use multiple actors and evaluate theQ-value maximizing action and ii learn surrogates to the Q-function that aresimpler to optimize with gradient-based methods. We evaluate tasks such asrestricted locomotion dexterous manipulation and large discrete-action spacerecommender systems and show that our actor finds optimal actions morefrequently and outperforms alternate actor architectures.</p>
                <p>Last Updated: 2024-10-15 17:58:03 UTC</p>
                <button class="interpret-button" data-id="2410.11833v1">Interpret</button>
                <div id="interpretation-2410.11833v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Learning Smooth Humanoid Locomotion through Lipschitz-Constrained Policies</h3>
                <p>Authors: Zixuan ChenXialin HeYen-Jen WangQiayuan LiaoYanjie ZeZhongyu LiS. Shankar SastryJiajun WuKoushil SreenathSaurabh GuptaXue Bin Peng</p>
                <p><a href="http://arxiv.org/abs/2410.11825v2">Link to paper</a></p>
                <p>Reinforcement learning combined with sim-to-real transfer offers a generalframework for developing locomotion controllers for legged robots. Tofacilitate successful deployment in the real world smoothing techniques suchas low-pass filters and smoothness rewards are often employed to developpolicies with smooth behaviors. However because these techniques arenon-differentiable and usually require tedious tuning of a large set ofhyperparameters they tend to require extensive manual tuning for each roboticplatform. To address this challenge and establish a general technique forenforcing smooth behaviors we propose a simple and effective method thatimposes a Lipschitz constraint on a learned policy which we refer to asLipschitz-Constrained Policies LCP. We show that the Lipschitz constraint canbe implemented in the form of a gradient penalty which provides adifferentiable objective that can be easily incorporated with automaticdifferentiation frameworks. We demonstrate that LCP effectively replaces theneed for smoothing rewards or low-pass filters and can be easily integratedinto training frameworks for many distinct humanoid robots. We extensivelyevaluate LCP in both simulation and real-world humanoid robots producingsmooth and robust locomotion controllers. All simulation and deployment codealong with complete checkpoints is available on our project page:https://lipschitz-constrained-policy.github.io.</p>
                <p>Last Updated: 2024-10-16 15:21:16 UTC</p>
                <button class="interpret-button" data-id="2410.11825v2">Interpret</button>
                <div id="interpretation-2410.11825v2" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>A Hitchhiker's Guide to Scaling Law Estimation</h3>
                <p>Authors: Leshem ChoshenYang ZhangJacob Andreas</p>
                <p><a href="http://arxiv.org/abs/2410.11840v1">Link to paper</a></p>
                <p>Scaling laws predict the loss of a target machine learning model byextrapolating from easier-to-train models with fewer parameters or smallertraining sets. This provides an efficient way for practitioners and researchersalike to compare pretraining decisions involving optimizers datasets andmodel architectures. Despite the widespread use of scaling laws to model thedynamics of language model training there has been little work onunderstanding how to best estimate and interpret them. We collect and releasea large-scale dataset containing losses and downstream evaluations for 485previously published pretrained models. We use these to estimate more than 1000scaling laws then derive a set of best practices for estimating scaling lawsin new model families. We find that fitting scaling laws to intermediatecheckpoints of training runs and not just their final losses substantiallyimproves accuracy and that -- all else equal -- estimates of performance aregenerally most accurate when derived from other models of similar sizes.However because there is a significant degree of variability across modelseeds training multiple small models is sometimes more useful than training asingle large one. Moreover while different model families differ scalingbehavior they are often similar enough that a target models behavior can bepredicted from a single model with the same architecture along with scalingparameter estimates derived from other model families.</p>
                <p>Last Updated: 2024-10-15 17:59:10 UTC</p>
                <button class="interpret-button" data-id="2410.11840v1">Interpret</button>
                <div id="interpretation-2410.11840v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>NesTools: A Dataset for Evaluating Nested Tool Learning Abilities of Large Language Models</h3>
                <p>Authors: Han HanTong ZhuXiang ZhangMengsong WuHao XiongWenliang Chen</p>
                <p><a href="http://arxiv.org/abs/2410.11805v1">Link to paper</a></p>
                <p>Large language models LLMs combined with tool learning have gainedimpressive results in real-world applications. During tool learning LLMs maycall multiple tools in nested orders where the latter tool call may take theformer response as its input parameters. However current research on thenested tool learning capabilities is still under-explored since the existingbenchmarks lack of relevant data instances. To address this problem weintroduce NesTools to bridge the current gap in comprehensive nested toollearning evaluations. NesTools comprises a novel automatic data generationmethod to construct large-scale nested tool calls with different nestingstructures. With manual review and refinement the dataset is in high qualityand closely aligned with real-world scenarios. Therefore NesTools can serve asa new benchmark to evaluate the nested tool learning abilities of LLMs. Weconduct extensive experiments on 22 LLMs and provide in-depth analyses withNesTools which shows that current LLMs still suffer from the complex nestedtool learning task.</p>
                <p>Last Updated: 2024-10-15 17:33:43 UTC</p>
                <button class="interpret-button" data-id="2410.11805v1">Interpret</button>
                <div id="interpretation-2410.11805v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability</h3>
                <p>Authors: Tsz Ting ChungLeyang CuiLemao LiuXinting HuangShuming ShiDit-Yan Yeung</p>
                <p><a href="http://arxiv.org/abs/2410.11786v1">Link to paper</a></p>
                <p>Large Language Models LLMs have demonstrated impressive capabilities in awide range of natural language processing tasks when leveraging in-contextlearning. To mitigate the additional computational and financial costsassociated with in-context learning several prompt compression methods havebeen proposed to compress the in-context learning prompts. Despite theirsuccess these methods face challenges with transferability due tomodel-specific compression or rely on external training data such as GPT-4.In this paper we investigate the ability of LLMs to develop a unifiedcompression method that discretizes uninformative tokens utilizing aself-supervised pre-training technique. By introducing a small number ofparameters during the continual pre-training the proposed Selection-p producesa probability for each input token indicating whether to preserve or discardit. Experiments show Selection-p achieves state-of-the-art performance acrossnumerous classification tasks achieving compression rates of up to 10 timeswhile experiencing only a marginal 0.8 decrease in performance. Moreover itexhibits superior transferability to different models compared to prior work.Additionally we further analyze how Selection-p helps maintain performance onin-context learning with long contexts.</p>
                <p>Last Updated: 2024-10-15 17:05:25 UTC</p>
                <button class="interpret-button" data-id="2410.11786v1">Interpret</button>
                <div id="interpretation-2410.11786v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation</h3>
                <p>Authors: Chenxi WangXiang ChenNingyu ZhangBozhong TianHaoming XuShumin DengHuajun Chen</p>
                <p><a href="http://arxiv.org/abs/2410.11779v1">Link to paper</a></p>
                <p>Multimodal Large Language Models MLLMs frequently exhibit hallucinationphenomena but the underlying reasons remain poorly understood. In this paperwe present an empirical analysis and find that although MLLMs incorrectlygenerate the objects in the final output they are actually able to recognizevisual objects in the preceding layers. We speculate that this may be due tothe strong knowledge priors of the language model suppressing the visualinformation leading to hallucinations. Motivated by this we propose a noveldynamic correction decoding method for MLLMs DeCo which adaptively selectsthe appropriate preceding layers and proportionally integrates knowledge intothe final layer to adjust the output logits. Note that DeCo is model agnosticand can be seamlessly incorporated with various classic decoding strategies andapplied to different MLLMs. We evaluate DeCo on widely-used benchmarksdemonstrating that it can reduce hallucination rates by a large margin comparedto baselines highlighting its potential to mitigate hallucinations. Code isavailable at https://github.com/zjunlp/DeCo.</p>
                <p>Last Updated: 2024-10-15 16:57:44 UTC</p>
                <button class="interpret-button" data-id="2410.11779v1">Interpret</button>
                <div id="interpretation-2410.11779v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models</h3>
                <p>Authors: Kai YaoPenlei GaoLichun LiYuan ZhaoXiaofeng WangWei WangJianke Zhu</p>
                <p><a href="http://arxiv.org/abs/2410.11772v1">Link to paper</a></p>
                <p>Parameter-Efficient Fine-Tuning PEFT methods have gained significantpopularity for adapting pre-trained Large Language Models LLMs to downstreamtasks primarily due to their potential to significantly reduce memory andcomputational overheads. However a common limitation in most PEFT approachesis their application of a uniform architectural design across all layers. Thisuniformity involves identical trainable modules and ignores the varyingimportance of each layer leading to sub-optimal fine-tuning results. Toovercome the above limitation and obtain better performance we develop a novelapproach Importance-aware Sparse Tuning IST to fully utilize the inherentsparsity and select the most important subset of full layers with effectivelayer-wise importance scoring. The proposed IST is a versatile andplug-and-play technique compatible with various PEFT methods that operate on aper-layer basis. By leveraging the estimated importance scores IST dynamicallyupdates these selected layers in PEFT modules leading to reduced memorydemands. We further provide theoretical proof of convergence and empiricalevidence of superior performance to demonstrate the advantages of IST overuniform updating strategies. Extensive experiments on a range of LLMs PEFTsand downstream tasks substantiate the effectiveness of our proposed methodshowcasing ISTs capacity to enhance existing layer-based PEFT methods. Ourcode is available at https://github.com/Kaiseem/IST.</p>
                <p>Last Updated: 2024-10-15 16:53:26 UTC</p>
                <button class="interpret-button" data-id="2410.11772v1">Interpret</button>
                <div id="interpretation-2410.11772v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>MoH: Multi-Head Attention as Mixture-of-Head Attention</h3>
                <p>Authors: Peng JinBo ZhuLi YuanShuicheng Yan</p>
                <p><a href="http://arxiv.org/abs/2410.11842v1">Link to paper</a></p>
                <p>In this work we upgrade the multi-head attention mechanism the core of theTransformer model to improve efficiency while maintaining or surpassing theprevious accuracy level. We show that multi-head attention can be expressed inthe summation form. Drawing on the insight that not all attention heads holdequal significance we propose Mixture-of-Head attention MoH a newarchitecture that treats attention heads as experts in the Mixture-of-ExpertsMoE mechanism. MoH has two significant advantages: First MoH enables eachtoken to select the appropriate attention heads enhancing inference efficiencywithout compromising accuracy or increasing the number of parameters. SecondMoH replaces the standard summation in multi-head attention with a weightedsummation introducing flexibility to the attention mechanism and unlockingextra performance potential. Extensive experiments on ViT DiT and LLMsdemonstrate that MoH outperforms multi-head attention by using only 50-90 ofthe attention heads. Moreover we demonstrate that pre-trained multi-headattention models such as LLaMA3-8B can be further continue-tuned into our MoHmodels. Notably MoH-LLaMA3-8B achieves an average accuracy of 64.0 across 14benchmarks outperforming LLaMA3-8B by 2.4 by utilizing only 75 of theattention heads. We believe the proposed MoH is a promising alternative tomulti-head attention and provides a strong foundation for developing advancedand efficient attention-based models.</p>
                <p>Last Updated: 2024-10-15 17:59:44 UTC</p>
                <button class="interpret-button" data-id="2410.11842v1">Interpret</button>
                <div id="interpretation-2410.11842v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Hitchhiker's Guide to Scaling Law Estimation</h3>
                <p>Authors: Leshem ChoshenYang ZhangJacob Andreas</p>
                <p><a href="http://arxiv.org/abs/2410.11840v1">Link to paper</a></p>
                <p>Scaling laws predict the loss of a target machine learning model byextrapolating from easier-to-train models with fewer parameters or smallertraining sets. This provides an efficient way for practitioners and researchersalike to compare pretraining decisions involving optimizers datasets andmodel architectures. Despite the widespread use of scaling laws to model thedynamics of language model training there has been little work onunderstanding how to best estimate and interpret them. We collect and releasea large-scale dataset containing losses and downstream evaluations for 485previously published pretrained models. We use these to estimate more than 1000scaling laws then derive a set of best practices for estimating scaling lawsin new model families. We find that fitting scaling laws to intermediatecheckpoints of training runs and not just their final losses substantiallyimproves accuracy and that -- all else equal -- estimates of performance aregenerally most accurate when derived from other models of similar sizes.However because there is a significant degree of variability across modelseeds training multiple small models is sometimes more useful than training asingle large one. Moreover while different model families differ scalingbehavior they are often similar enough that a target models behavior can bepredicted from a single model with the same architecture along with scalingparameter estimates derived from other model families.</p>
                <p>Last Updated: 2024-10-15 17:59:10 UTC</p>
                <button class="interpret-button" data-id="2410.11840v1">Interpret</button>
                <div id="interpretation-2410.11840v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions</h3>
                <p>Authors: Ayush JainNorio KosakaXinhu LiKyung-Min KimErdem Bƒ±yƒ±kJoseph J. Lim</p>
                <p><a href="http://arxiv.org/abs/2410.11833v1">Link to paper</a></p>
                <p>In reinforcement learning off-policy actor-critic approaches like DDPG andTD3 are based on the deterministic policy gradient. Herein the Q-function istrained from off-policy environment data and the actor policy is trained tomaximize the Q-function via gradient ascent. We observe that in complex taskslike dexterous manipulation and restricted locomotion the Q-value is a complexfunction of action having several local optima or discontinuities. This posesa challenge for gradient ascent to traverse and makes the actor prone to getstuck at local optima. To address this we introduce a new actor architecturethat combines two simple insights: i use multiple actors and evaluate theQ-value maximizing action and ii learn surrogates to the Q-function that aresimpler to optimize with gradient-based methods. We evaluate tasks such asrestricted locomotion dexterous manipulation and large discrete-action spacerecommender systems and show that our actor finds optimal actions morefrequently and outperforms alternate actor architectures.</p>
                <p>Last Updated: 2024-10-15 17:58:03 UTC</p>
                <button class="interpret-button" data-id="2410.11833v1">Interpret</button>
                <div id="interpretation-2410.11833v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Bayesian Experimental Design via Contrastive Diffusions</h3>
                <p>Authors: Jacopo IolloChristophe Heinkel√©Pierre AlliezFlorence Forbes</p>
                <p><a href="http://arxiv.org/abs/2410.11826v1">Link to paper</a></p>
                <p>Bayesian Optimal Experimental Design BOED is a powerful tool to reduce thecost of running a sequence of experiments. When based on the ExpectedInformation Gain EIG design optimization corresponds to the maximization ofsome intractable expected it contrast between prior and posteriordistributions. Scaling this maximization to high dimensional and complexsettings has been an issue due to BOED inherent computational complexity. Inthis work we introduce an it expected posterior distribution withcost-effective sampling properties and provide a tractable access to the EIGcontrast maximization via a new EIG gradient expression. Diffusion-basedsamplers are used to compute the dynamics of the expected posterior and ideasfrom bi-level optimization are leveraged to derive an efficient jointsampling-optimization loop without resorting to lower bound approximations ofthe EIG. The resulting efficiency gain allows to extend BOED to the well-testedgenerative capabilities of diffusion models. By incorporating generative modelsinto the BOED framework we expand its scope and its use in scenarios that werepreviously impractical. Numerical experiments and comparison withstate-of-the-art methods show the potential of the approach.</p>
                <p>Last Updated: 2024-10-15 17:53:07 UTC</p>
                <button class="interpret-button" data-id="2410.11826v1">Interpret</button>
                <div id="interpretation-2410.11826v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Adaptive Data Optimization: Dynamic Sample Selection with Scaling Laws</h3>
                <p>Authors: Yiding JiangAllan ZhouZhili FengSadhika MalladiJ. Zico Kolter</p>
                <p><a href="http://arxiv.org/abs/2410.11820v1">Link to paper</a></p>
                <p>The composition of pretraining data is a key determinant of foundationmodels performance but there is no standard guideline for allocating alimited computational budget across different data sources. Most currentapproaches either rely on extensive experiments with smaller models or dynamicdata adjustments that also require proxy models both of which significantlyincrease the workflow complexity and computational overhead. In this paper weintroduce Adaptive Data Optimization ADO an algorithm that optimizes datadistributions in an online fashion concurrent with model training. Unlikeexisting techniques ADO does not require external knowledge proxy models ormodifications to the model update. Instead ADO uses per-domain scaling laws toestimate the learning potential of each domain during training and adjusts thedata mixture accordingly making it more scalable and easier to integrate.Experiments demonstrate that ADO can achieve comparable or better performancethan prior methods while maintaining computational efficiency across differentcomputation scales offering a practical solution for dynamically adjustingdata distribution without sacrificing flexibility or increasing costs. Beyondits practical benefits ADO also provides a new perspective on data collectionstrategies via scaling laws.</p>
                <p>Last Updated: 2024-10-15 17:47:44 UTC</p>
                <button class="interpret-button" data-id="2410.11820v1">Interpret</button>
                <div id="interpretation-2410.11820v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-10-17</p>
        </div>
    
        </div>
    </body>
    </html>
    