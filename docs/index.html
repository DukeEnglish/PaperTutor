
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>Nash Equilibrium and Learning Dynamics in Three-Player Matching $m$-Action Games</h3>
                <p>Authors: Yuma FujimotoKaito AriuKenshi Abe</p>
                <p><a href="http://arxiv.org/abs/2402.10825v1">Link to paper</a></p>
                <p>Learning in games discusses the processes where multiple players learn theiroptimal strategies through the repetition of game plays. The dynamics oflearning between two players in zero-sum games such as matching pennies wheretheir benefits are competitive have already been well analyzed. However it isstill unexplored and challenging to analyze the dynamics of learning amongthree players. In this study we formulate a minimalistic game where threeplayers compete to match their actions with one another. Although interactionamong three players diversifies and complicates the Nash equilibria we fullyanalyze the equilibria. We also discuss the dynamics of learning based on somefamous algorithms categorized into Follow the Regularized Leader. From boththeoretical and experimental aspects we characterize the dynamics bycategorizing three-player interactions into three forces to synchronize theiractions switch their actions rotationally and seek competition.</p>
                <p>Last Updated: 2024-02-16 16:54:07 UTC</p>
                <button class="interpret-button" data-id="2402.10825v1">Interpret</button>
                <div id="interpretation-2402.10825v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Modelling crypto markets by multi-agent reinforcement learning</h3>
                <p>Authors: Johann LussangeStefano VrizziStefano PalminteriBoris Gutkin</p>
                <p><a href="http://arxiv.org/abs/2402.10803v1">Link to paper</a></p>
                <p>Building on a previous foundation work Lussange et al. 2020 this studyintroduces a multi-agent reinforcement learning MARL model simulating cryptomarkets which is calibrated to the Binances daily closing prices of 153cryptocurrencies that were continuously traded between 2018 and 2022. Unlikeprevious agent-based models ABM or multi-agent systems MAS which relied onzero-intelligence agents or single autonomous agent methodologies our approachrelies on endowing agents with reinforcement learning RL techniques in orderto model crypto markets. This integration is designed to emulate with abottom-up approach to complexity inference both individual and collectiveagents ensuring robustness in the recent volatile conditions of such marketsand during the COVID-19 era. A key feature of our model also lies in the factthat its autonomous agents perform asset price valuation based on two sourcesof information: the market prices themselves and the approximation of thecrypto assets fundamental values beyond what those market prices are. Our MAScalibration against real market data allows for an accurate emulation of cryptomarkets microstructure and probing key market behaviors in both the bearishand bullish regimes of that particular time period.</p>
                <p>Last Updated: 2024-02-16 16:28:58 UTC</p>
                <button class="interpret-button" data-id="2402.10803v1">Interpret</button>
                <div id="interpretation-2402.10803v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Network Formation and Dynamics Among Multi-LLMs</h3>
                <p>Authors: Marios PapachristouYuan Yuan</p>
                <p><a href="http://arxiv.org/abs/2402.10659v1">Link to paper</a></p>
                <p>Social networks influence behaviors preferences and relationships and playa crucial role in the dissemination of information and norms within humansocieties. As large language models LLMs increasingly integrate into socialand professional environments understanding their behavior within the contextof social networks and interactions becomes essential. Our study analyzes thebehaviors of standard network structures and real-world networks to determinewhether the dynamics of multiple LLMs align with human social dynamics. Weexplore various social network principles including micro-level concepts suchas preferential attachment triadic closure and homophily as well asmacro-level concepts like community structure and the small-world phenomenon.Our findings suggest that LLMs demonstrate all these principles when they areprovided with network structures and asked about their preferences regardingnetwork formation. Furthermore we investigate LLMs decision-making based onreal-world networks to compare the strengths of these principles. Our resultsreveal that triadic closure and homophily have a stronger influence thanpreferential attachment and that LLMs substantially exceed random guessing inthe task of network formation predictions. Overall our study contributes tothe development of socially aware LLMs by shedding light on LLMs networkformation behaviors and exploring their impacts on social dynamics and norms.</p>
                <p>Last Updated: 2024-02-16 13:10:14 UTC</p>
                <button class="interpret-button" data-id="2402.10659v1">Interpret</button>
                <div id="interpretation-2402.10659v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>OptiMUS: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models</h3>
                <p>Authors: Ali AhmadiTeshniziWenzhi GaoMadeleine Udell</p>
                <p><a href="http://arxiv.org/abs/2402.10172v1">Link to paper</a></p>
                <p>Optimization problems are pervasive in sectors from manufacturing anddistribution to healthcare. However most such problems are still solvedheuristically by hand rather than optimally by state-of-the-art solvers becausethe expertise required to formulate and solve these problems limits thewidespread adoption of optimization tools and techniques. This paper introducesOptiMUS a Large Language Model LLM-based agent designed to formulate andsolve mixed integer linear programming problems from their natural languagedescriptions. OptiMUS can develop mathematical models write and debug solvercode evaluate the generated solutions and improve its model and code based onthese evaluations. OptiMUS utilizes a modular structure to process problemsallowing it to handle problems with long descriptions and complex data withoutlong prompts. Experiments demonstrate that OptiMUS outperforms existingstate-of-the-art methods on easy datasets by more than 20 and on harddatasets including a new dataset NLP4LP released with this paper thatfeatures long and complex problems by more than 30.</p>
                <p>Last Updated: 2024-02-15 18:19:18 UTC</p>
                <button class="interpret-button" data-id="2402.10172v1">Interpret</button>
                <div id="interpretation-2402.10172v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Identifying and modelling cognitive biases in mobility choices</h3>
                <p>Authors: Chloe ConradCarole Adam</p>
                <p><a href="http://arxiv.org/abs/2402.09921v1">Link to paper</a></p>
                <p>This report presents results from an M1 internship dedicated to agent-basedmodelling and simulation of daily mobility choices. This simulation is intendedto be realistic enough to serve as a basis for a serious game about themobility transition. In order to ensure this level of realism we conducted asurvey to measure if real mobility choices are made rationally or how biasedthey are. Results analysed here show that various biases could play a role indecisions. We then propose an implementation in a GAMA agent-based simulation.</p>
                <p>Last Updated: 2024-02-15 12:58:27 UTC</p>
                <button class="interpret-button" data-id="2402.09921v1">Interpret</button>
                <div id="interpretation-2402.09921v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>RLVF: Learning from Verbal Feedback without Overgeneralization</h3>
                <p>Authors: Moritz StephanAlexander KhazatskyEric MitchellAnnie S ChenSheryl HsuArchit SharmaChelsea Finn</p>
                <p><a href="http://arxiv.org/abs/2402.10893v1">Link to paper</a></p>
                <p>The diversity of contexts in which large language models LLMs are deployedrequires the ability to modify or customize default model behaviors toincorporate nuanced requirements and preferences. A convenient interface tospecify such model adjustments is high-level verbal feedback such as Dontuse emojis when drafting emails to my boss. However while writing high-levelfeedback is far simpler than collecting annotations for reinforcement learningfrom human feedback RLHF we find that simply prompting a model with suchfeedback leads to overgeneralization of the feedback to contexts where it isnot relevant. We study the problem of incorporating verbal feedback withoutsuch overgeneralization inspiring a new method Contextualized Critiques withConstrained Preference Optimization C3PO. C3PO uses a piece of high-levelfeedback to generate a small synthetic preference dataset specifying how thefeedback should and should not be applied. It then fine-tunes the model inaccordance with the synthetic preference data while minimizing the divergencefrom the original model for prompts where the feedback does not apply. Ourexperimental results indicate that our approach effectively applies verbalfeedback to relevant scenarios while preserving existing behaviors for othercontexts. For both human- and GPT-4-generated high-level feedback C3POeffectively adheres to the given feedback comparably to in-context baselineswhile reducing overgeneralization by 30.</p>
                <p>Last Updated: 2024-02-16 18:50:24 UTC</p>
                <button class="interpret-button" data-id="2402.10893v1">Interpret</button>
                <div id="interpretation-2402.10893v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Instruction Diversity Drives Generalization To Unseen Tasks</h3>
                <p>Authors: Dylan ZhangJustin WangFrancois Charton</p>
                <p><a href="http://arxiv.org/abs/2402.10891v1">Link to paper</a></p>
                <p>Instruction tuning -- fine-tuning a large language model LLM on pairs ofinstructions and desired outcomes -- is an approach that enables pre-trainedlanguage models to perform real-world tasks and follow human instructions. Itspractical success depends on the model learning a broader set of instructionsthan those it was trained on. Yet the factors that determine modelgeneralization to such emphunseen tasks are not well understood. Tounderstand the driving factors of generalization In this paper we experimentwith string rewrites a symbolic task that serves as a building block forTuring complete Markov algorithms while allowing experimental control ofinputs and instructions. We investigate the trade-off between the number ofinstructions the model is trained on and the number of training samplesprovided for each instruction and observe that the diversity of the instructionset determines generalization. Generalization emerges once a diverse enough setof tasks is provided even though very few examples are provided for each task.Instruction diversity also ensures robustness with respect to non-uniformdistributions of instructions in the training set.</p>
                <p>Last Updated: 2024-02-16 18:47:21 UTC</p>
                <button class="interpret-button" data-id="2402.10891v1">Interpret</button>
                <div id="interpretation-2402.10891v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>When is Tree Search Useful for LLM Planning? It Depends on the Discriminator</h3>
                <p>Authors: Ziru ChenMichael WhiteRaymond MooneyAli PayaniYu SuHuan Sun</p>
                <p><a href="http://arxiv.org/abs/2402.10890v1">Link to paper</a></p>
                <p>In this paper we examine how large language models LLMs solve multi-stepproblems under a language agent framework with three components: a generator adiscriminator and a planning method. We investigate the practical utility oftwo advanced planning methods iterative correction and tree search. We presenta comprehensive analysis of how discrimination accuracy affects the overallperformance of agents when using these two methods or a simpler methodre-ranking. Experiments on two tasks text-to-SQL parsing and mathematicalreasoning show that: 1 advanced planning methods demand discriminators withat least 90 accuracy to achieve significant improvements over re-ranking 2current LLMs discrimination abilities have not met the needs of advancedplanning methods to achieve such improvements 3 with LLM-baseddiscriminators advanced planning methods may not adequately balance accuracyand efficiency. For example compared to the other two methods tree search isat least 10--20 times slower but leads to negligible performance gains whichhinders its real-world applications. Code and data will be released athttps://github.com/OSU-NLP-Group/llm-planning-eval.</p>
                <p>Last Updated: 2024-02-16 18:45:58 UTC</p>
                <button class="interpret-button" data-id="2402.10890v1">Interpret</button>
                <div id="interpretation-2402.10890v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Explainability for Machine Learning Models: From Data Adaptability to User Perception</h3>
                <p>Authors: julien Delaunay</p>
                <p><a href="http://arxiv.org/abs/2402.10888v1">Link to paper</a></p>
                <p>This thesis explores the generation of local explanations for alreadydeployed machine learning models aiming to identify optimal conditions forproducing meaningful explanations considering both data and user requirements.The primary goal is to develop methods for generating explanations for anymodel while ensuring that these explanations remain faithful to the underlyingmodel and comprehensible to the users.  The thesis is divided into two parts. The first enhances a widely usedrule-based explanation method. It then introduces a novel approach forevaluating the suitability of linear explanations to approximate a model.Additionally it conducts a comparative experiment between two families ofcounterfactual explanation methods to analyze the advantages of one over theother. The second part focuses on user experiments to assess the impact ofthree explanation methods and two distinct representations. These experimentsmeasure how users perceive their interaction with the model in terms ofunderstanding and trust depending on the explanations and representations.This research contributes to a better explanation generation with potentialimplications for enhancing the transparency trustworthiness and usability ofdeployed AI systems.</p>
                <p>Last Updated: 2024-02-16 18:44:37 UTC</p>
                <button class="interpret-button" data-id="2402.10888v1">Interpret</button>
                <div id="interpretation-2402.10888v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>3D Diffuser Actor: Policy Diffusion with 3D Scene Representations</h3>
                <p>Authors: Tsung-Wei KeNikolaos GkanatsiosKaterina Fragkiadaki</p>
                <p><a href="http://arxiv.org/abs/2402.10885v1">Link to paper</a></p>
                <p>We marry diffusion policies and 3D scene representations for robotmanipulation. Diffusion policies learn the action distribution conditioned onthe robot and environment state using conditional diffusion models. They haverecently shown to outperform both deterministic and alternativestate-conditioned action distribution learning methods. 3D robot policies use3D scene feature representations aggregated from a single or multiple cameraviews using sensed depth. They have shown to generalize better than their 2Dcounterparts across camera viewpoints. We unify these two lines of work andpresent 3D Diffuser Actor a neural policy architecture that given a languageinstruction builds a 3D representation of the visual scene and conditions onit to iteratively denoise 3D rotations and translations for the robotsend-effector. At each denoising iteration our model represents end-effectorpose estimates as 3D scene tokens and predicts the 3D translation and rotationerror for each of them by featurizing them using 3D relative attention toother 3D visual and language tokens. 3D Diffuser Actor sets a newstate-of-the-art on RLBench with an absolute performance gain of 16.3 over thecurrent SOTA on a multi-view setup and an absolute gain of 13.1 on asingle-view setup. On the CALVIN benchmark it outperforms the current SOTA inthe setting of zero-shot unseen scene generalization by being able tosuccessfully run 0.2 more tasks a 7 relative increase. It also works in thereal world from a handful of demonstrations. We ablate our modelsarchitectural design choices such as 3D scene featurization and 3D relativeattentions and show they all help generalization. Our results suggest that 3Dscene representations and powerful generative modeling are keys to efficientrobot learning from demonstrations.</p>
                <p>Last Updated: 2024-02-16 18:43:02 UTC</p>
                <button class="interpret-button" data-id="2402.10885v1">Interpret</button>
                <div id="interpretation-2402.10885v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>The Price of Adaptivity in Stochastic Convex Optimization</h3>
                <p>Authors: Yair CarmonOliver Hinder</p>
                <p><a href="http://arxiv.org/abs/2402.10898v1">Link to paper</a></p>
                <p>We prove impossibility results for adaptivity in non-smooth stochastic convexoptimization. Given a set of problem parameters we wish to adapt to we definea price of adaptivity PoA that roughly speaking measures themultiplicative increase in suboptimality due to uncertainty in theseparameters. When the initial distance to the optimum is unknown but a gradientnorm bound is known we show that the PoA is at least logarithmic for expectedsuboptimality and double-logarithmic for median suboptimality. When there isuncertainty in both distance and gradient norm we show that the PoA must bepolynomial in the level of uncertainty. Our lower bounds nearly match existingupper bounds and establish that there is no parameter-free lunch.</p>
                <p>Last Updated: 2024-02-16 18:56:41 UTC</p>
                <button class="interpret-button" data-id="2402.10898v1">Interpret</button>
                <div id="interpretation-2402.10898v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Trading off Consistency and Dimensionality of Convex Surrogates for the Mode</h3>
                <p>Authors: Enrique NueveBo WaggonerDhamma KimparaJessie Finocchiaro</p>
                <p><a href="http://arxiv.org/abs/2402.10818v1">Link to paper</a></p>
                <p>In multiclass classification over n outcomes the outcomes must be embeddedinto the reals with dimension at least n-1 in order to design a consistentsurrogate loss that leads to the correct classification regardless of thedata distribution. For large n such as in information retrieval andstructured prediction tasks optimizing a surrogate in n-1 dimensions isoften intractable. We investigate ways to trade off surrogate loss dimensionthe number of problem instances and restricting the region of consistency inthe simplex for multiclass classification. Following past work we examine anintuitive embedding procedure that maps outcomes into the vertices of convexpolytopes in a low-dimensional surrogate space. We show that full-dimensionalsubsets of the simplex exist around each point mass distribution for whichconsistency holds but also with less than n-1 dimensions there existdistributions for which a phenomenon called hallucination occurs which is whenthe optimal report under the surrogate loss is an outcome with zeroprobability. Looking towards application we derive a result to check ifconsistency holds under a given polytope embedding and low-noise assumptionproviding insight into when to use a particular embedding. We provide examplesof embedding n  2d outcomes into the d-dimensional unit cube and n d outcomes into the d-dimensional permutahedron under low-noiseassumptions. Finally we demonstrate that with multiple problem instances wecan learn the mode with fracn2 dimensions over the whole simplex.</p>
                <p>Last Updated: 2024-02-16 16:42:09 UTC</p>
                <button class="interpret-button" data-id="2402.10818v1">Interpret</button>
                <div id="interpretation-2402.10818v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Double Duality: Variational Primal-Dual Policy Optimization for Constrained Reinforcement Learning</h3>
                <p>Authors: Zihao LiBoyi LiuZhuoran YangZhaoran WangMengdi Wang</p>
                <p><a href="http://arxiv.org/abs/2402.10810v1">Link to paper</a></p>
                <p>We study the Constrained Convex Markov Decision Process MDP where the goalis to minimize a convex functional of the visitation measure subject to aconvex constraint. Designing algorithms for a constrained convex MDP facesseveral challenges including 1 handling the large state space 2 managingthe exploration/exploitation tradeoff and 3 solving the constrainedoptimization where the objective and the constraint are both nonlinearfunctions of the visitation measure. In this work we present a model-basedalgorithm Variational Primal-Dual Policy Optimization VPDPO in whichLagrangian and Fenchel duality are implemented to reformulate the originalconstrained problem into an unconstrained primal-dual optimization. Moreoverthe primal variables are updated by model-based value iteration following theprinciple of Optimism in the Face of Uncertainty OFU while the dualvariables are updated by gradient ascent. Moreover by embedding the visitationmeasure into a finite-dimensional space we can handle large state spaces byincorporating function approximation. Two notable examples are 1 KernelizedNonlinear Regulators and 2 Low-rank MDPs. We prove that with an optimisticplanning oracle our algorithm achieves sublinear regret and constraintviolation in both cases and can attain the globally optimal policy of theoriginal constrained problem.</p>
                <p>Last Updated: 2024-02-16 16:35:18 UTC</p>
                <button class="interpret-button" data-id="2402.10810v1">Interpret</button>
                <div id="interpretation-2402.10810v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>BlackJAX: Composable Bayesian inference in JAX</h3>
                <p>Authors: Alberto CabezasAdrien CorenflosJunpeng LaoRémi Louf</p>
                <p><a href="http://arxiv.org/abs/2402.10797v1">Link to paper</a></p>
                <p>BlackJAX is a library implementing sampling and variational inferencealgorithms commonly used in Bayesian computation. It is designed for ease ofuse speed and modularity by taking a functional approach to the algorithmsimplementation. BlackJAX is written in Python using JAX to compile and runNumpPy-like samplers and variational methods on CPUs GPUs and TPUs. Thelibrary integrates well with probabilistic programming languages by workingdirectly with the un-normalized target log density function. BlackJAX isintended as a collection of low-level composable implementations of basicstatistical atoms that can be combined to perform well-defined Bayesianinference but also provides high-level routines for ease of use. It isdesigned for users who need cutting-edge methods researchers who want tocreate complex sampling methods and people who want to learn how these work.</p>
                <p>Last Updated: 2024-02-16 16:21:02 UTC</p>
                <button class="interpret-button" data-id="2402.10797v1">Interpret</button>
                <div id="interpretation-2402.10797v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants</h3>
                <p>Authors: Peter RichtárikElnur GasanovKonstantin Burlachenko</p>
                <p><a href="http://arxiv.org/abs/2402.10774v1">Link to paper</a></p>
                <p>Error Feedback EF is a highly popular and immensely effective mechanism forfixing convergence issues which arise in distributed training methods such asdistributed GD or SGD when these are enhanced with greedy communicationcompression techniques such as TopK. While EF was proposed almost a decade agoSeide et al. 2014 and despite concentrated effort by the community toadvance the theoretical understanding of this mechanism there is still a lotto explore. In this work we study a modern form of error feedback called EF21Richtarik et al. 2021 which offers the currently best-known theoreticalguarantees under the weakest assumptions and also works well in practice. Inparticular while the theoretical communication complexity of EF21 depends onthe quadratic mean of certain smoothness parameters we improve this dependenceto their arithmetic mean which is always smaller and can be substantiallysmaller especially in heterogeneous data regimes. We take the reader on ajourney of our discovery process. Starting with the idea of applying EF21 to anequivalent reformulation of the underlying problem which unfortunatelyrequires often impractical machine cloning we continue to the discovery of anew weighted version of EF21 which can fortunately be executed without anycloning and finally circle back to an improved analysis of the original EF21method. While this development applies to the simplest form of EF21 ourapproach naturally extends to more elaborate variants involving stochasticgradients and partial participation. Further our technique improves thebest-known theory of EF21 in the rare features regime Richtarik et al. 2023.Finally we validate our theoretical findings with suitable experiments.</p>
                <p>Last Updated: 2024-02-16 15:55:59 UTC</p>
                <button class="interpret-button" data-id="2402.10774v1">Interpret</button>
                <div id="interpretation-2402.10774v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>Proving membership in LLM pretraining data via data watermarks</h3>
                <p>Authors: Johnny Tian-Zheng WeiRyan Yixiang WangRobin Jia</p>
                <p><a href="http://arxiv.org/abs/2402.10892v1">Link to paper</a></p>
                <p>Detecting whether copyright holders works were used in LLM pretraining ispoised to be an important problem. This work proposes using data watermarks toenable principled detection with only black-box model access provided that therightholder contributed multiple training documents and watermarked them beforepublic release. By applying a randomly sampled data watermark detection can beframed as hypothesis testing which provides guarantees on the false detectionrate. We study two watermarks: one that inserts random sequences and anotherthat randomly substitutes characters with Unicode lookalikes. We first show howthree aspects of watermark design -- watermark length number of duplicationsand interference -- affect the power of the hypothesis test. Next we study howa watermarks detection strength changes under model and dataset scaling: whileincreasing the dataset size decreases the strength of the watermark watermarksremain strong if the model size also increases. Finally we view SHA hashes asnatural watermarks and show that we can robustly detect hashes fromBLOOM-176Bs training data as long as they occurred at least 90 times.Together our results point towards a promising future for data watermarks inreal world use.</p>
                <p>Last Updated: 2024-02-16 18:49:27 UTC</p>
                <button class="interpret-button" data-id="2402.10892v1">Interpret</button>
                <div id="interpretation-2402.10892v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Instruction Diversity Drives Generalization To Unseen Tasks</h3>
                <p>Authors: Dylan ZhangJustin WangFrancois Charton</p>
                <p><a href="http://arxiv.org/abs/2402.10891v1">Link to paper</a></p>
                <p>Instruction tuning -- fine-tuning a large language model LLM on pairs ofinstructions and desired outcomes -- is an approach that enables pre-trainedlanguage models to perform real-world tasks and follow human instructions. Itspractical success depends on the model learning a broader set of instructionsthan those it was trained on. Yet the factors that determine modelgeneralization to such emphunseen tasks are not well understood. Tounderstand the driving factors of generalization In this paper we experimentwith string rewrites a symbolic task that serves as a building block forTuring complete Markov algorithms while allowing experimental control ofinputs and instructions. We investigate the trade-off between the number ofinstructions the model is trained on and the number of training samplesprovided for each instruction and observe that the diversity of the instructionset determines generalization. Generalization emerges once a diverse enough setof tasks is provided even though very few examples are provided for each task.Instruction diversity also ensures robustness with respect to non-uniformdistributions of instructions in the training set.</p>
                <p>Last Updated: 2024-02-16 18:47:21 UTC</p>
                <button class="interpret-button" data-id="2402.10891v1">Interpret</button>
                <div id="interpretation-2402.10891v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>When is Tree Search Useful for LLM Planning? It Depends on the Discriminator</h3>
                <p>Authors: Ziru ChenMichael WhiteRaymond MooneyAli PayaniYu SuHuan Sun</p>
                <p><a href="http://arxiv.org/abs/2402.10890v1">Link to paper</a></p>
                <p>In this paper we examine how large language models LLMs solve multi-stepproblems under a language agent framework with three components: a generator adiscriminator and a planning method. We investigate the practical utility oftwo advanced planning methods iterative correction and tree search. We presenta comprehensive analysis of how discrimination accuracy affects the overallperformance of agents when using these two methods or a simpler methodre-ranking. Experiments on two tasks text-to-SQL parsing and mathematicalreasoning show that: 1 advanced planning methods demand discriminators withat least 90 accuracy to achieve significant improvements over re-ranking 2current LLMs discrimination abilities have not met the needs of advancedplanning methods to achieve such improvements 3 with LLM-baseddiscriminators advanced planning methods may not adequately balance accuracyand efficiency. For example compared to the other two methods tree search isat least 10--20 times slower but leads to negligible performance gains whichhinders its real-world applications. Code and data will be released athttps://github.com/OSU-NLP-Group/llm-planning-eval.</p>
                <p>Last Updated: 2024-02-16 18:45:58 UTC</p>
                <button class="interpret-button" data-id="2402.10890v1">Interpret</button>
                <div id="interpretation-2402.10890v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Reviewer2: Optimizing Review Generation Through Prompt Generation</h3>
                <p>Authors: Zhaolin GaoKianté BrantleyThorsten Joachims</p>
                <p><a href="http://arxiv.org/abs/2402.10886v1">Link to paper</a></p>
                <p>Recent developments in LLMs offer new opportunities for assisting authors inimproving their work. In this paper we envision a use case where authors canreceive LLM-generated reviews that uncover weak points in the current draft.While initial methods for automated review generation already exist thesemethods tend to produce reviews that lack detail and they do not cover therange of opinions that human reviewers produce. To address this shortcoming wepropose an efficient two-stage review generation framework called Reviewer2.Unlike prior work this approach explicitly models the distribution of possibleaspects that the review may address. We show that this leads to more detailedreviews that better cover the range of aspects that human reviewers identify inthe draft. As part of the research we generate a large-scale review dataset of27k papers and 99k reviews that we annotate with aspect prompts which we makeavailable as a resource for future research.</p>
                <p>Last Updated: 2024-02-16 18:43:10 UTC</p>
                <button class="interpret-button" data-id="2402.10886v1">Interpret</button>
                <div id="interpretation-2402.10886v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Multi-modal preference alignment remedies regression of visual instruction tuning on language model</h3>
                <p>Authors: Shengzhi LiRongyu LinShichao Pei</p>
                <p><a href="http://arxiv.org/abs/2402.10884v1">Link to paper</a></p>
                <p>In production multi-modal large language models MLLMs are expected tosupport multi-turn queries of interchanging image and text modalities. Howeverthe current MLLMs trained with visual-question-answering VQA datasets couldsuffer from degradation as VQA datasets lack the diversity and complexity ofthe original text instruction datasets which the underlying language model hadbeen trained with. To address this challenging degradation we first collect alightweight 6k entries VQA preference dataset where answers were annotated byGemini for 5 quality metrics in a granular fashion and investigate standardSupervised Fine-tuning rejection sampling Direct Preference OptimizationDPO and SteerLM. Our findings indicate that the with DPO we are able tosurpass instruction-following capabilities of the language model achieving a6.73 score on MT-Bench compared to Vicunas 6.57 and LLaVAs 5.99 despitesmall data scale. This enhancement in textual instruction proficiencycorrelates with boosted visual instruction performance 4.9 on MM-Vet 6on LLaVA-Bench with minimal alignment tax on visual knowledge benchmarkscompared to previous RLHF approach. In conclusion we propose adistillation-based multi-modal alignment model with fine-grained annotations ona small dataset that reconciles the textual and visual performance of MLLMsrestoring and boosting language capability after visual instruction tuning.</p>
                <p>Last Updated: 2024-02-16 18:42:08 UTC</p>
                <button class="interpret-button" data-id="2402.10884v1">Interpret</button>
                <div id="interpretation-2402.10884v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Explainability for Machine Learning Models: From Data Adaptability to User Perception</h3>
                <p>Authors: julien Delaunay</p>
                <p><a href="http://arxiv.org/abs/2402.10888v1">Link to paper</a></p>
                <p>This thesis explores the generation of local explanations for alreadydeployed machine learning models aiming to identify optimal conditions forproducing meaningful explanations considering both data and user requirements.The primary goal is to develop methods for generating explanations for anymodel while ensuring that these explanations remain faithful to the underlyingmodel and comprehensible to the users.  The thesis is divided into two parts. The first enhances a widely usedrule-based explanation method. It then introduces a novel approach forevaluating the suitability of linear explanations to approximate a model.Additionally it conducts a comparative experiment between two families ofcounterfactual explanation methods to analyze the advantages of one over theother. The second part focuses on user experiments to assess the impact ofthree explanation methods and two distinct representations. These experimentsmeasure how users perceive their interaction with the model in terms ofunderstanding and trust depending on the explanations and representations.This research contributes to a better explanation generation with potentialimplications for enhancing the transparency trustworthiness and usability ofdeployed AI systems.</p>
                <p>Last Updated: 2024-02-16 18:44:37 UTC</p>
                <button class="interpret-button" data-id="2402.10888v1">Interpret</button>
                <div id="interpretation-2402.10888v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Insights into mobile health application market via a content analysis of marketplace data with machine learning</h3>
                <p>Authors: Gokhan AydinGokhan Silahtaroglu</p>
                <p><a href="http://dx.doi.org/10.1371/journal.pone.0244302">Link to paper</a></p>
                <p>Background Despite the benefits offered by an abundance of healthapplications promoted on app marketplaces e.g. Google Play Store the wideadoption of mobile health and e-health apps is yet to come. Objective Thisstudy aims to investigate the current landscape of smartphone apps that focuson improving and sustaining health and wellbeing. Understanding the categoriesthat popular apps focus on and the relevant features provided to users whichlead to higher user scores and downloads will offer insights to enable higheradoption in the general populace. This study on 1000 mobile healthapplications aims to shed light on the reasons why particular apps are likedand adopted while many are not. Methods User-generated data i.e. reviewscores and company-generated data i.e. app descriptions were collected fromapp marketplaces and manually coded and categorized by two researchers. Foranalysis Artificial Neural Networks Random Forest and Naive BayesArtificial Intelligence algorithms were used. Results The analysis led tofeatures that attracted more download behavior and higher user scores. Thefindings suggest that apps that mention a privacy policy or provide videos indescription lead to higher user scores whereas free apps with in-app purchasepossibilities social networking and sharing features and feedback mechanismslead to higher number of downloads. Moreover differences in user scores andthe total number of downloads are detected in distinct subcategories of mobilehealth apps. Conclusion This study contributes to the current knowledge ofm-health application use by reviewing mobile health applications using contentanalysis and machine learning algorithms. The content analysis adds significantvalue by providing classification keywords and factors that influence downloadbehavior and user scores in a m-health context.</p>
                <p>Last Updated: 2024-02-16 16:12:13 UTC</p>
                <button class="interpret-button" data-id="2402.10789v1">Interpret</button>
                <div id="interpretation-2402.10789v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Noisy Beat is Worth 16 Words: a Tiny Transformer for Low-Power Arrhythmia Classification on Microcontrollers</h3>
                <p>Authors: Paola BusiaMatteo Antonio ScrugliVictor Jean-Baptiste JungLuca BeniniPaolo Meloni</p>
                <p><a href="http://arxiv.org/abs/2402.10748v1">Link to paper</a></p>
                <p>Wearable systems for the long-term monitoring of cardiovascular diseases arebecoming widespread and valuable assets in diagnosis and therapy. A promisingapproach for real-time analysis of the electrocardiographic ECG signal andthe detection of heart conditions such as arrhythmia is represented by thetransformer machine learning model. Transformers are powerful models for theclassification of time series although efficient implementation in thewearable domain raises significant design challenges to combine adequateaccuracy and a suitable complexity. In this work we present a tiny transformermodel for the analysis of the ECG signal requiring only 6k parameters andreaching 98.97 accuracy in the recognition of the 5 most common arrhythmiaclasses from the MIT-BIH Arrhythmia database assessed considering 8-bitinteger inference as required for efficient execution on low-powermicrocontroller-based devices. We explored an augmentation-based trainingapproach for improving the robustness against electrode motion artifacts noiseresulting in a worst-case post-deployment performance assessment of 98.36accuracy. Suitability for wearable monitoring solutions is finally demonstratedthrough efficient deployment on the parallel ultra-low-power GAP9 processorwhere inference execution requires 4.28ms and 0.09mJ.</p>
                <p>Last Updated: 2024-02-16 15:14:16 UTC</p>
                <button class="interpret-button" data-id="2402.10748v1">Interpret</button>
                <div id="interpretation-2402.10748v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Generative AI and Attentive User Interfaces: Five Strategies to Enhance Take-Over Quality in Automated Driving</h3>
                <p>Authors: Patrick Ebel</p>
                <p><a href="http://arxiv.org/abs/2402.10664v1">Link to paper</a></p>
                <p>As the automotive world moves toward higher levels of driving automationLevel 3 automated driving represents a critical juncture. In Level 3 drivingvehicles can drive alone under limited conditions but drivers are expected tobe ready to take over when the system requests. Assisting the driver tomaintain an appropriate level of Situation Awareness SA in such contextsbecomes a critical task. This position paper explores the potential ofAttentive User Interfaces AUIs powered by generative Artificial IntelligenceAI to address this need. Rather than relying on overt notifications we arguethat AUIs based on novel AI technologies such as large language models ordiffusion models can be used to improve SA in an unconscious and subtle waywithout negative effects on drivers overall workload. Accordingly we propose 5strategies how generative AI s can be used to improve the quality of takeoversand ultimately road safety.</p>
                <p>Last Updated: 2024-02-16 13:13:57 UTC</p>
                <button class="interpret-button" data-id="2402.10664v1">Interpret</button>
                <div id="interpretation-2402.10664v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Properties and Challenges of LLM-Generated Explanations</h3>
                <p>Authors: Jenny KunzMarco Kuhlmann</p>
                <p><a href="http://arxiv.org/abs/2402.10532v1">Link to paper</a></p>
                <p>The self-rationalising capabilities of large language models LLMs have beenexplored in restricted settings using task/specific data sets. Howevercurrent LLMs do not only rely on specifically annotated data nonethelessthey frequently explain their outputs. The properties of the generatedexplanations are influenced by the pre-training corpus and by the target dataused for instruction fine-tuning. As the pre-training corpus includes a largeamount of human-written explanations in the wild we hypothesise that LLMsadopt common properties of human explanations. By analysing the outputs for amulti-domain instruction fine-tuning data set we find that generatedexplanations show selectivity and contain illustrative elements but lessfrequently are subjective or misleading. We discuss reasons and consequences ofthe properties presence or absence. In particular we outline positive andnegative implications depending on the goals and user groups of theself-rationalising system.</p>
                <p>Last Updated: 2024-02-16 09:37:54 UTC</p>
                <button class="interpret-button" data-id="2402.10532v1">Interpret</button>
                <div id="interpretation-2402.10532v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>The Price of Adaptivity in Stochastic Convex Optimization</h3>
                <p>Authors: Yair CarmonOliver Hinder</p>
                <p><a href="http://arxiv.org/abs/2402.10898v1">Link to paper</a></p>
                <p>We prove impossibility results for adaptivity in non-smooth stochastic convexoptimization. Given a set of problem parameters we wish to adapt to we definea price of adaptivity PoA that roughly speaking measures themultiplicative increase in suboptimality due to uncertainty in theseparameters. When the initial distance to the optimum is unknown but a gradientnorm bound is known we show that the PoA is at least logarithmic for expectedsuboptimality and double-logarithmic for median suboptimality. When there isuncertainty in both distance and gradient norm we show that the PoA must bepolynomial in the level of uncertainty. Our lower bounds nearly match existingupper bounds and establish that there is no parameter-free lunch.</p>
                <p>Last Updated: 2024-02-16 18:56:41 UTC</p>
                <button class="interpret-button" data-id="2402.10898v1">Interpret</button>
                <div id="interpretation-2402.10898v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Fusion of Diffusion Weighted MRI and Clinical Data for Predicting Functional Outcome after Acute Ischemic Stroke with Deep Contrastive Learning</h3>
                <p>Authors: Chia-Ling TsaiHui-Yun SuShen-Feng SungWei-Yang LinYing-Ying SuTzu-Hsien YangMan-Lin Mai</p>
                <p><a href="http://arxiv.org/abs/2402.10894v1">Link to paper</a></p>
                <p>Stroke is a common disabling neurological condition that affects aboutone-quarter of the adult population over age 25 more than half of patientsstill have poor outcomes such as permanent functional dependence or evendeath after the onset of acute stroke. The aim of this study is to investigatethe efficacy of diffusion-weighted MRI modalities combining with structuredhealth profile on predicting the functional outcome to facilitate earlyintervention. A deep fusion learning network is proposed with two-stagetraining: the first stage focuses on cross-modality representation learning andthe second stage on classification. Supervised contrastive learning isexploited to learn discriminative features that separate the two classes ofpatients from embeddings of individual modalities and from the fused multimodalembedding. The network takes as the input DWI and ADC images and structuredhealth profile data. The outcome is the prediction of the patient needinglong-term care at 3 months after the onset of stroke. Trained and evaluatedwith a dataset of 3297 patients our proposed fusion model achieves 0.87 0.80and 80.45 for AUC F1-score and accuracy respectively outperforming existingmodels that consolidate both imaging and structured data in the medical domain.If trained with comprehensive clinical variables including NIHSS andcomorbidities the gain from images on making accurate prediction is notconsidered substantial but significant. However diffusion-weighted MRI canreplace NIHSS to achieve comparable level of accuracy combining with otherreadily available clinical variables for better generalization.</p>
                <p>Last Updated: 2024-02-16 18:51:42 UTC</p>
                <button class="interpret-button" data-id="2402.10894v1">Interpret</button>
                <div id="interpretation-2402.10894v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>RLVF: Learning from Verbal Feedback without Overgeneralization</h3>
                <p>Authors: Moritz StephanAlexander KhazatskyEric MitchellAnnie S ChenSheryl HsuArchit SharmaChelsea Finn</p>
                <p><a href="http://arxiv.org/abs/2402.10893v1">Link to paper</a></p>
                <p>The diversity of contexts in which large language models LLMs are deployedrequires the ability to modify or customize default model behaviors toincorporate nuanced requirements and preferences. A convenient interface tospecify such model adjustments is high-level verbal feedback such as Dontuse emojis when drafting emails to my boss. However while writing high-levelfeedback is far simpler than collecting annotations for reinforcement learningfrom human feedback RLHF we find that simply prompting a model with suchfeedback leads to overgeneralization of the feedback to contexts where it isnot relevant. We study the problem of incorporating verbal feedback withoutsuch overgeneralization inspiring a new method Contextualized Critiques withConstrained Preference Optimization C3PO. C3PO uses a piece of high-levelfeedback to generate a small synthetic preference dataset specifying how thefeedback should and should not be applied. It then fine-tunes the model inaccordance with the synthetic preference data while minimizing the divergencefrom the original model for prompts where the feedback does not apply. Ourexperimental results indicate that our approach effectively applies verbalfeedback to relevant scenarios while preserving existing behaviors for othercontexts. For both human- and GPT-4-generated high-level feedback C3POeffectively adheres to the given feedback comparably to in-context baselineswhile reducing overgeneralization by 30.</p>
                <p>Last Updated: 2024-02-16 18:50:24 UTC</p>
                <button class="interpret-button" data-id="2402.10893v1">Interpret</button>
                <div id="interpretation-2402.10893v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Proving membership in LLM pretraining data via data watermarks</h3>
                <p>Authors: Johnny Tian-Zheng WeiRyan Yixiang WangRobin Jia</p>
                <p><a href="http://arxiv.org/abs/2402.10892v1">Link to paper</a></p>
                <p>Detecting whether copyright holders works were used in LLM pretraining ispoised to be an important problem. This work proposes using data watermarks toenable principled detection with only black-box model access provided that therightholder contributed multiple training documents and watermarked them beforepublic release. By applying a randomly sampled data watermark detection can beframed as hypothesis testing which provides guarantees on the false detectionrate. We study two watermarks: one that inserts random sequences and anotherthat randomly substitutes characters with Unicode lookalikes. We first show howthree aspects of watermark design -- watermark length number of duplicationsand interference -- affect the power of the hypothesis test. Next we study howa watermarks detection strength changes under model and dataset scaling: whileincreasing the dataset size decreases the strength of the watermark watermarksremain strong if the model size also increases. Finally we view SHA hashes asnatural watermarks and show that we can robustly detect hashes fromBLOOM-176Bs training data as long as they occurred at least 90 times.Together our results point towards a promising future for data watermarks inreal world use.</p>
                <p>Last Updated: 2024-02-16 18:49:27 UTC</p>
                <button class="interpret-button" data-id="2402.10892v1">Interpret</button>
                <div id="interpretation-2402.10892v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Instruction Diversity Drives Generalization To Unseen Tasks</h3>
                <p>Authors: Dylan ZhangJustin WangFrancois Charton</p>
                <p><a href="http://arxiv.org/abs/2402.10891v1">Link to paper</a></p>
                <p>Instruction tuning -- fine-tuning a large language model LLM on pairs ofinstructions and desired outcomes -- is an approach that enables pre-trainedlanguage models to perform real-world tasks and follow human instructions. Itspractical success depends on the model learning a broader set of instructionsthan those it was trained on. Yet the factors that determine modelgeneralization to such emphunseen tasks are not well understood. Tounderstand the driving factors of generalization In this paper we experimentwith string rewrites a symbolic task that serves as a building block forTuring complete Markov algorithms while allowing experimental control ofinputs and instructions. We investigate the trade-off between the number ofinstructions the model is trained on and the number of training samplesprovided for each instruction and observe that the diversity of the instructionset determines generalization. Generalization emerges once a diverse enough setof tasks is provided even though very few examples are provided for each task.Instruction diversity also ensures robustness with respect to non-uniformdistributions of instructions in the training set.</p>
                <p>Last Updated: 2024-02-16 18:47:21 UTC</p>
                <button class="interpret-button" data-id="2402.10891v1">Interpret</button>
                <div id="interpretation-2402.10891v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>PaLM2-VAdapter: Progressively Aligned Language Model Makes a Strong Vision-language Adapter</h3>
                <p>Authors: Junfei XiaoZheng XuAlan YuilleShen YanBoyu Wang</p>
                <p><a href="http://arxiv.org/abs/2402.10896v1">Link to paper</a></p>
                <p>This paper demonstrates that a progressively aligned language model caneffectively bridge frozen vision encoders and large language models LLMs.While the fundamental architecture and pre-training methods of vision encodersand LLMs have been extensively studied the architecture and training strategyof vision-language adapters vary significantly across recent works. Ourresearch undertakes a thorough exploration of the state-of-the-art perceiverresampler architecture and builds a strong baseline. However we observe thatthe vision-language alignment with perceiver resampler exhibits slowconvergence and limited scalability with a lack of direct supervision. Toaddress this issue we propose PaLM2-VAdapter employing a progressivelyaligned language model as the vision-language adapter. Compared to the strongbaseline with perceiver resampler our method empirically shows fasterconvergence higher performance and stronger scalability. Extensiveexperiments across various Visual Question Answering VQA and captioning taskson both images and videos demonstrate that our model exhibits state-of-the-artvisual understanding and multi-modal reasoning capabilities. Notably ourmethod achieves these advancements with 3070 fewer parameters than thestate-of-the-art large vision-language models marking a significant efficiencyimprovement.</p>
                <p>Last Updated: 2024-02-16 18:54:47 UTC</p>
                <button class="interpret-button" data-id="2402.10896v1">Interpret</button>
                <div id="interpretation-2402.10896v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Fusion of Diffusion Weighted MRI and Clinical Data for Predicting Functional Outcome after Acute Ischemic Stroke with Deep Contrastive Learning</h3>
                <p>Authors: Chia-Ling TsaiHui-Yun SuShen-Feng SungWei-Yang LinYing-Ying SuTzu-Hsien YangMan-Lin Mai</p>
                <p><a href="http://arxiv.org/abs/2402.10894v1">Link to paper</a></p>
                <p>Stroke is a common disabling neurological condition that affects aboutone-quarter of the adult population over age 25 more than half of patientsstill have poor outcomes such as permanent functional dependence or evendeath after the onset of acute stroke. The aim of this study is to investigatethe efficacy of diffusion-weighted MRI modalities combining with structuredhealth profile on predicting the functional outcome to facilitate earlyintervention. A deep fusion learning network is proposed with two-stagetraining: the first stage focuses on cross-modality representation learning andthe second stage on classification. Supervised contrastive learning isexploited to learn discriminative features that separate the two classes ofpatients from embeddings of individual modalities and from the fused multimodalembedding. The network takes as the input DWI and ADC images and structuredhealth profile data. The outcome is the prediction of the patient needinglong-term care at 3 months after the onset of stroke. Trained and evaluatedwith a dataset of 3297 patients our proposed fusion model achieves 0.87 0.80and 80.45 for AUC F1-score and accuracy respectively outperforming existingmodels that consolidate both imaging and structured data in the medical domain.If trained with comprehensive clinical variables including NIHSS andcomorbidities the gain from images on making accurate prediction is notconsidered substantial but significant. However diffusion-weighted MRI canreplace NIHSS to achieve comparable level of accuracy combining with otherreadily available clinical variables for better generalization.</p>
                <p>Last Updated: 2024-02-16 18:51:42 UTC</p>
                <button class="interpret-button" data-id="2402.10894v1">Interpret</button>
                <div id="interpretation-2402.10894v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Weak-Mamba-UNet: Visual Mamba Makes CNN and ViT Work Better for Scribble-based Medical Image Segmentation</h3>
                <p>Authors: Ziyang WangChao Ma</p>
                <p><a href="http://arxiv.org/abs/2402.10887v1">Link to paper</a></p>
                <p>Medical image segmentation is increasingly reliant on deep learningtechniques yet the promising performance often come with high annotationcosts. This paper introduces Weak-Mamba-UNet an innovative weakly-supervisedlearning WSL framework that leverages the capabilities of ConvolutionalNeural Network CNN Vision Transformer ViT and the cutting-edge VisualMamba VMamba architecture for medical image segmentation especially whendealing with scribble-based annotations. The proposed WSL strategy incorporatesthree distinct architecture but same symmetrical encoder-decoder networks: aCNN-based UNet for detailed local feature extraction a Swin Transformer-basedSwinUNet for comprehensive global context understanding and a VMamba-basedMamba-UNet for efficient long-range dependency modeling. The key concept ofthis framework is a collaborative and cross-supervisory mechanism that employspseudo labels to facilitate iterative learning and refinement across thenetworks. The effectiveness of Weak-Mamba-UNet is validated on a publiclyavailable MRI cardiac segmentation dataset with processed scribble annotationswhere it surpasses the performance of a similar WSL framework utilizing onlyUNet or SwinUNet. This highlights its potential in scenarios with sparse orimprecise annotations. The source code is made publicly accessible.</p>
                <p>Last Updated: 2024-02-16 18:43:39 UTC</p>
                <button class="interpret-button" data-id="2402.10887v1">Interpret</button>
                <div id="interpretation-2402.10887v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>3D Diffuser Actor: Policy Diffusion with 3D Scene Representations</h3>
                <p>Authors: Tsung-Wei KeNikolaos GkanatsiosKaterina Fragkiadaki</p>
                <p><a href="http://arxiv.org/abs/2402.10885v1">Link to paper</a></p>
                <p>We marry diffusion policies and 3D scene representations for robotmanipulation. Diffusion policies learn the action distribution conditioned onthe robot and environment state using conditional diffusion models. They haverecently shown to outperform both deterministic and alternativestate-conditioned action distribution learning methods. 3D robot policies use3D scene feature representations aggregated from a single or multiple cameraviews using sensed depth. They have shown to generalize better than their 2Dcounterparts across camera viewpoints. We unify these two lines of work andpresent 3D Diffuser Actor a neural policy architecture that given a languageinstruction builds a 3D representation of the visual scene and conditions onit to iteratively denoise 3D rotations and translations for the robotsend-effector. At each denoising iteration our model represents end-effectorpose estimates as 3D scene tokens and predicts the 3D translation and rotationerror for each of them by featurizing them using 3D relative attention toother 3D visual and language tokens. 3D Diffuser Actor sets a newstate-of-the-art on RLBench with an absolute performance gain of 16.3 over thecurrent SOTA on a multi-view setup and an absolute gain of 13.1 on asingle-view setup. On the CALVIN benchmark it outperforms the current SOTA inthe setting of zero-shot unseen scene generalization by being able tosuccessfully run 0.2 more tasks a 7 relative increase. It also works in thereal world from a handful of demonstrations. We ablate our modelsarchitectural design choices such as 3D scene featurization and 3D relativeattentions and show they all help generalization. Our results suggest that 3Dscene representations and powerful generative modeling are keys to efficientrobot learning from demonstrations.</p>
                <p>Last Updated: 2024-02-16 18:43:02 UTC</p>
                <button class="interpret-button" data-id="2402.10885v1">Interpret</button>
                <div id="interpretation-2402.10885v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Multi-modal preference alignment remedies regression of visual instruction tuning on language model</h3>
                <p>Authors: Shengzhi LiRongyu LinShichao Pei</p>
                <p><a href="http://arxiv.org/abs/2402.10884v1">Link to paper</a></p>
                <p>In production multi-modal large language models MLLMs are expected tosupport multi-turn queries of interchanging image and text modalities. Howeverthe current MLLMs trained with visual-question-answering VQA datasets couldsuffer from degradation as VQA datasets lack the diversity and complexity ofthe original text instruction datasets which the underlying language model hadbeen trained with. To address this challenging degradation we first collect alightweight 6k entries VQA preference dataset where answers were annotated byGemini for 5 quality metrics in a granular fashion and investigate standardSupervised Fine-tuning rejection sampling Direct Preference OptimizationDPO and SteerLM. Our findings indicate that the with DPO we are able tosurpass instruction-following capabilities of the language model achieving a6.73 score on MT-Bench compared to Vicunas 6.57 and LLaVAs 5.99 despitesmall data scale. This enhancement in textual instruction proficiencycorrelates with boosted visual instruction performance 4.9 on MM-Vet 6on LLaVA-Bench with minimal alignment tax on visual knowledge benchmarkscompared to previous RLHF approach. In conclusion we propose adistillation-based multi-modal alignment model with fine-grained annotations ona small dataset that reconciles the textual and visual performance of MLLMsrestoring and boosting language capability after visual instruction tuning.</p>
                <p>Last Updated: 2024-02-16 18:42:08 UTC</p>
                <button class="interpret-button" data-id="2402.10884v1">Interpret</button>
                <div id="interpretation-2402.10884v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-02-20</p>
        </div>
    
        </div>
    </body>
    </html>
    