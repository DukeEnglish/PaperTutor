
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>On the Pros and Cons of Active Learning for Moral Preference Elicitation</h3>
                <p>Authors: Vijay KeswaniVincent ConitzerHoda HeidariJana Schaich BorgWalter Sinnott-Armstrong</p>
                <p><a href="http://arxiv.org/abs/2407.18889v1">Link to paper</a></p>
                <p>Computational preference elicitation methods are tools used to learn peoplespreferences quantitatively in a given context. Recent works on preferenceelicitation advocate for active learning as an efficient method to iterativelyconstruct queries framed as comparisons between context-specific cases thatare likely to be most informative about an agents underlying preferences. Inthis work we argue that the use of active learning for moral preferenceelicitation relies on certain assumptions about the underlying moralpreferences which can be violated in practice. Specifically we highlight thefollowing common assumptions a preferences are stable over time and notsensitive to the sequence of presented queries b the appropriate hypothesisclass is chosen to model moral preferences and c noise in the agentsresponses is limited. While these assumptions can be appropriate for preferenceelicitation in certain domains prior research on moral psychology suggeststhey may not be valid for moral judgments. Through a synthetic simulation ofpreferences that violate the above assumptions we observe that active learningcan have similar or worse performance than a basic random query selectionmethod in certain settings. Yet simulation results also demonstrate thatactive learning can still be viable if the degree of instability or noise isrelatively small and when the agents preferences can be approximatelyrepresented with the hypothesis class used for learning. Our study highlightsthe nuances associated with effective moral preference elicitation in practiceand advocates for the cautious use of active learning as a methodology to learnmoral preferences.</p>
                <p>Last Updated: 2024-07-26 17:40:52 UTC</p>
                <button class="interpret-button" data-id="2407.18889v1">Interpret</button>
                <div id="interpretation-2407.18889v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Engaging with Children's Artwork in Mixed Visual-Ability Families</h3>
                <p>Authors: Arnavi Chheda-KotharyJacob O. WobbrockJon E. Froehlich</p>
                <p><a href="http://arxiv.org/abs/2407.18874v1">Link to paper</a></p>
                <p>We present two studies exploring how blind or low-vision BLV family membersengage with their sighted childrens artwork strategies to supportunderstanding and interpretation and the potential role of technology such asAI therein. Our first study involved 14 BLV individuals and the secondincluded five groups of BLV individuals with their children. Throughsemi-structured interviews with AI descriptions of childrens artwork andmulti-sensory design probes we found that BLV family members value artworkengagement as a bonding opportunity preferring the childs storytelling andinterpretation over other nonvisual representations. Additionally despite someinaccuracies BLV family members felt that AI-generated descriptions couldfacilitate dialogue with their children and aid self-guided art discovery. Weclose with specific design considerations for supporting artwork engagement inmixed visual-ability families including enabling artwork access throughvarious methods supporting childrens corrections of AI output anddistinctions in context vs. content and interpretation vs. description ofchildrens artwork.</p>
                <p>Last Updated: 2024-07-26 17:08:53 UTC</p>
                <button class="interpret-button" data-id="2407.18874v1">Interpret</button>
                <div id="interpretation-2407.18874v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Design Frictions on Social Media: Balancing Reduced Mindless Scrolling and User Satisfaction</h3>
                <p>Authors: Nicolas RuizGrabriela Molina LeónHendrik Heuer</p>
                <p><a href="http://arxiv.org/abs/2407.18803v1">Link to paper</a></p>
                <p>Design features of social media platforms such as infinite scroll increaseusers likelihood of experiencing normative dissociation -- a mental state ofabsorption that diminishes self-awareness and disrupts memory. This paperinvestigates how adding design frictions into the interface of a social mediaplatform reduce mindless scrolling and user satisfaction. We conducted a studywith 30 participants and compared their memory recognition of posts in twoscenarios: one where participants had to react to each post to access furthercontent and another using an infinite scroll design. Participants who used thedesign frictions interface exhibited significantly better content recallalthough a majority of participants found the interface frustrating. We discussdesign recommendations and scenarios where adding design frictions to socialmedia platforms can be beneficial.</p>
                <p>Last Updated: 2024-07-26 15:07:01 UTC</p>
                <button class="interpret-button" data-id="2407.18803v1">Interpret</button>
                <div id="interpretation-2407.18803v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>TAGIFY: LLM-powered Tagging Interface for Improved Data Findability on OGD portals</h3>
                <p>Authors: Kevin KliimaskAnastasija Nikiforova</p>
                <p><a href="http://arxiv.org/abs/2407.18764v1">Link to paper</a></p>
                <p>Efforts directed towards promoting Open Government Data OGD have gainedsignificant traction across various governmental tiers since the mid-2000s. Asmore datasets are published on OGD portals finding specific data becomesharder leading to information overload. Complete and accurate documentation ofdatasets including association of proper tags with datasets is key toimproving dataset findability and accessibility. Analysis conducted on theEstonian Open Data Portal revealed that 11 datasets have no associated tagswhile 26 had only one tag assigned to them which underscores challenges indata findability and accessibility within the portal which according to therecent Open Data Maturity Report is considered trend-setter. The aim of thisstudy is to propose an automated solution to tagging datasets to improve datafindability on OGD portals. This paper presents Tagify - a prototype of tagginginterface that employs large language models LLM such as GPT-3.5-turbo andGPT-4 to automate dataset tagging generating tags for datasets in English andEstonian thereby augmenting metadata preparation by data publishers andimproving data findability on OGD portals by data users. The developed solutionwas evaluated by users and their feedback was collected to define an agenda forfuture prototype improvements.</p>
                <p>Last Updated: 2024-07-26 14:22:30 UTC</p>
                <button class="interpret-button" data-id="2407.18764v1">Interpret</button>
                <div id="interpretation-2407.18764v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Who Let the Guards Out: Visual Support for Patrolling Games</h3>
                <p>Authors: Matěj LangAdam ŠtěpánekRóbert ZvaraVojtěch ŘehákBarbora Kozlíková</p>
                <p><a href="http://arxiv.org/abs/2407.18705v1">Link to paper</a></p>
                <p>Effective security patrol management is critical for ensuring safety indiverse environments such as art galleries airports and factories. Thebehavior of patrols in these situations can be modeled by patrolling games.They simulate the behavior of the patrol and adversary in the building whichis modeled as a graph of interconnected nodes representing rooms. The designersof algorithms solving the game face the problem of analyzing complex graphlayouts with temporal dependencies. Therefore appropriate visual support iscrucial for them to work effectively. In this paper we present a novel toolthat helps the designers of patrolling games explore the outcomes of theproposed algorithms and approaches evaluate their success rate and proposemodifications that can improve their solutions. Our tool offers an intuitiveand interactive interface featuring a detailed exploration of patrol routesand probabilities of taking them simulation of patrols and other requestedfeatures. In close collaboration with experts in designing patrolling games weconducted three case studies demonstrating the usage and usefulness of ourtool. The prototype of the tool along with exemplary datasets is available athttps://gitlab.fi.muni.cz/formela/strategy-vizualizer.</p>
                <p>Last Updated: 2024-07-26 12:41:34 UTC</p>
                <button class="interpret-button" data-id="2407.18705v1">Interpret</button>
                <div id="interpretation-2407.18705v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>SOAP-RL: Sequential Option Advantage Propagation for Reinforcement Learning in POMDP Environments</h3>
                <p>Authors: Shu IshidaJoão F. Henriques</p>
                <p><a href="http://arxiv.org/abs/2407.18913v1">Link to paper</a></p>
                <p>This work compares ways of extending Reinforcement Learning algorithms toPartially Observed Markov Decision Processes POMDPs with options. One view ofoptions is as temporally extended action which can be realized as a memorythat allows the agent to retain historical information beyond the policyscontext window. While option assignment could be handled using heuristics andhand-crafted objectives learning temporally consistent options and associatedsub-policies without explicit supervision is a challenge. Two algorithms PPOEMand SOAP are proposed and studied in depth to address this problem. PPOEMapplies the forward-backward algorithm for Hidden Markov Models to optimizethe expected returns for an option-augmented policy. However this learningapproach is unstable during on-policy rollouts. It is also unsuited forlearning causal policies without the knowledge of future trajectories sinceoption assignments are optimized for offline sequences where the entire episodeis available. As an alternative approach SOAP evaluates the policy gradientfor an optimal option assignment. It extends the concept of the generalizedadvantage estimation GAE to propagate option advantages through time whichis an analytical equivalent to performing temporal back-propagation of optionpolicy gradients. This option policy is only conditional on the history of theagent not future actions. Evaluated against competing baselines SOAPexhibited the most robust performance correctly discovering options for POMDPcorridor environments as well as on standard benchmarks including Atari andMuJoCo outperforming PPOEM as well as LSTM and Option-Critic baselines. Theopen-sourced code is available at https://github.com/shuishida/SoapRL.</p>
                <p>Last Updated: 2024-07-26 17:59:55 UTC</p>
                <button class="interpret-button" data-id="2407.18913v1">Interpret</button>
                <div id="interpretation-2407.18913v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Do We Really Need Graph Convolution During Training? Light Post-Training Graph-ODE for Efficient Recommendation</h3>
                <p>Authors: Weizhi ZhangLiangwei YangZihe SongHenry Peng ZouKe XuHenry Peng ZouLiancheng FangPhilip S. Yu</p>
                <p><a href="http://arxiv.org/abs/2407.18910v1">Link to paper</a></p>
                <p>The efficiency and scalability of graph convolution networks GCNs intraining recommender systems RecSys have been persistent concerns hinderingtheir deployment in real-world applications. This paper presents a criticalexamination of the necessity of graph convolutions during the training phaseand introduces an innovative alternative: the Light Post-Training GraphOrdinary-Differential-Equation LightGODE. Our investigation reveals that thebenefits of GCNs are more pronounced during testing rather than training.Motivated by this LightGODE utilizes a novel post-training graph convolutionmethod that bypasses the computation-intensive message passing of GCNs andemploys a non-parametric continuous graph ordinary-differential-equation ODEto dynamically model node representations. This approach drastically reducestraining time while achieving fine-grained post-training graph convolution toavoid the distortion of the original training embedding space termed theembedding discrepancy issue. We validate our model across several real-worlddatasets of different scales demonstrating that LightGODE not only outperformsGCN-based models in terms of efficiency and effectiveness but alsosignificantly mitigates the embedding discrepancy commonly associated withdeeper graph convolution layers. Our LightGODE challenges the prevailingparadigms in RecSys training and suggests re-evaluating the role of graphconvolutions potentially guiding future developments of efficient large-scalegraph-based RecSys.</p>
                <p>Last Updated: 2024-07-26 17:59:32 UTC</p>
                <button class="interpret-button" data-id="2407.18910v1">Interpret</button>
                <div id="interpretation-2407.18910v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Hybrid summary statistics: neural weak lensing inference beyond the power spectrum</h3>
                <p>Authors: T. Lucas MakinenTom CharnockNatalia PorqueresAxel LapelAlan HeavensBenjamin D. Wandelt</p>
                <p><a href="http://arxiv.org/abs/2407.18909v1">Link to paper</a></p>
                <p>In inference problems we often have domain knowledge which allows us todefine summary statistics that capture most of the information content in adataset. In this paper we present a hybrid approach where such physics-basedsummaries are augmented by a set of compressed neural summary statistics thatare optimised to extract the extra information that is not captured by thepredefined summaries. The resulting statistics are very powerful inputs tosimulation-based or implicit inference of model parameters. We apply thisgeneralisation of Information Maximising Neural Networks IMNNs to parameterconstraints from tomographic weak gravitational lensing convergence maps tofind summary statistics that are explicitly optimised to complement angularpower spectrum estimates. We study several dark matter simulation resolutionsin low- and high-noise regimes. We show that i the information-updateformalism extracts at least 3times and up to 8times as much informationas the angular power spectrum in all noise regimes ii the network summariesare highly complementary to existing 2-point summaries and iii our formalismallows for networks with smaller physically-informed architectures to matchmuch larger regression networks with far fewer simulations needed to obtainasymptotically optimal inference.</p>
                <p>Last Updated: 2024-07-26 17:59:26 UTC</p>
                <button class="interpret-button" data-id="2407.18909v1">Interpret</button>
                <div id="interpretation-2407.18909v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Wolf: Captioning Everything with a World Summarization Framework</h3>
                <p>Authors: Boyi LiLigeng ZhuRan TianShuhan TanYuxiao ChenYao LuYin CuiSushant VeerMax EhrlichJonah PhilionXinshuo WengFuzhao XueAndrew TaoMing-Yu LiuSanja FidlerBoris IvanovicTrevor DarrellJitendra MalikSong HanMarco Pavone</p>
                <p><a href="http://arxiv.org/abs/2407.18908v1">Link to paper</a></p>
                <p>We propose Wolf a WOrLd summarization Framework for accurate videocaptioning. Wolf is an automated captioning framework that adopts amixture-of-experts approach leveraging complementary strengths of VisionLanguage Models VLMs. By utilizing both image and video models our frameworkcaptures different levels of information and summarizes them efficiently. Ourapproach can be applied to enhance video understanding auto-labeling andcaptioning. To evaluate caption quality we introduce CapScore an LLM-basedmetric to assess the similarity and quality of generated captions compared tothe ground truth captions. We further build four human-annotated datasets inthree domains: autonomous driving general scenes and robotics to facilitatecomprehensive comparisons. We show that Wolf achieves superior captioningperformance compared to state-of-the-art approaches from the research communityVILA1.5 CogAgent and commercial solutions Gemini-Pro-1.5 GPT-4V. Forinstance in comparison with GPT-4V Wolf improves CapScore both quality-wiseby 55.6 and similarity-wise by 77.4 on challenging driving videos. Finallywe establish a benchmark for video captioning and introduce a leaderboardaiming to accelerate advancements in video understanding captioning and dataalignment. Leaderboard: https://wolfv0.github.io/leaderboard.html.</p>
                <p>Last Updated: 2024-07-26 17:59:09 UTC</p>
                <button class="interpret-button" data-id="2407.18908v1">Interpret</button>
                <div id="interpretation-2407.18908v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Scalable Quantum Non-local Neural Network for Image Classification</h3>
                <p>Authors: Sparsh GuptaDebanjan KonarVaneet Aggarwal</p>
                <p><a href="http://arxiv.org/abs/2407.18906v1">Link to paper</a></p>
                <p>Non-local operations play a crucial role in computer vision enabling thecapture of long-range dependencies through weighted sums of features across theinput surpassing the constraints of traditional convolution operations thatfocus solely on local neighborhoods. Non-local operations typically requirecomputing pairwise relationships between all elements in a set leading toquadratic complexity in terms of time and memory. Due to the high computationaland memory demands scaling non-local neural networks to large-scale problemscan be challenging. This article introduces a hybrid quantum-classical scalablenon-local neural network referred to as Quantum Non-Local Neural NetworkQNL-Net to enhance pattern recognition. The proposed QNL-Net relies oninherent quantum parallelism to allow the simultaneous processing of a largenumber of input features enabling more efficient computations inquantum-enhanced feature space and involving pairwise relationships throughquantum entanglement. We benchmark our proposed QNL-Net with other quantumcounterparts to binary classification with datasets MNIST and CIFAR-10. Thesimulation findings showcase our QNL-Net achieves cutting-edge accuracy levelsin binary image classification among quantum classifiers while utilizing fewerqubits.</p>
                <p>Last Updated: 2024-07-26 17:58:57 UTC</p>
                <button class="interpret-button" data-id="2407.18906v1">Interpret</button>
                <div id="interpretation-2407.18906v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>Wolf: Captioning Everything with a World Summarization Framework</h3>
                <p>Authors: Boyi LiLigeng ZhuRan TianShuhan TanYuxiao ChenYao LuYin CuiSushant VeerMax EhrlichJonah PhilionXinshuo WengFuzhao XueAndrew TaoMing-Yu LiuSanja FidlerBoris IvanovicTrevor DarrellJitendra MalikSong HanMarco Pavone</p>
                <p><a href="http://arxiv.org/abs/2407.18908v1">Link to paper</a></p>
                <p>We propose Wolf a WOrLd summarization Framework for accurate videocaptioning. Wolf is an automated captioning framework that adopts amixture-of-experts approach leveraging complementary strengths of VisionLanguage Models VLMs. By utilizing both image and video models our frameworkcaptures different levels of information and summarizes them efficiently. Ourapproach can be applied to enhance video understanding auto-labeling andcaptioning. To evaluate caption quality we introduce CapScore an LLM-basedmetric to assess the similarity and quality of generated captions compared tothe ground truth captions. We further build four human-annotated datasets inthree domains: autonomous driving general scenes and robotics to facilitatecomprehensive comparisons. We show that Wolf achieves superior captioningperformance compared to state-of-the-art approaches from the research communityVILA1.5 CogAgent and commercial solutions Gemini-Pro-1.5 GPT-4V. Forinstance in comparison with GPT-4V Wolf improves CapScore both quality-wiseby 55.6 and similarity-wise by 77.4 on challenging driving videos. Finallywe establish a benchmark for video captioning and introduce a leaderboardaiming to accelerate advancements in video understanding captioning and dataalignment. Leaderboard: https://wolfv0.github.io/leaderboard.html.</p>
                <p>Last Updated: 2024-07-26 17:59:09 UTC</p>
                <button class="interpret-button" data-id="2407.18908v1">Interpret</button>
                <div id="interpretation-2407.18908v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents</h3>
                <p>Authors: Harsh TrivediTushar KhotMareike HartmannRuskin MankuVinty DongEdward LiShashank GuptaAshish SabharwalNiranjan Balasubramanian</p>
                <p><a href="http://arxiv.org/abs/2407.18901v1">Link to paper</a></p>
                <p>Autonomous agents that address day-to-day digital tasks e.g. orderinggroceries for a household must not only operate multiple apps e.g. notesmessaging shopping app via APIs but also generate rich code with complexcontrol flow in an iterative manner based on their interaction with theenvironment. However existing benchmarks for tool use are inadequate as theyonly cover tasks that require a simple sequence of API calls.  To remedy this gap we built textbfAppWorld Engine a high-qualityexecution environment 60K lines of code of 9 day-to-day apps operable via 457APIs and populated with realistic digital activities simulating the lives of100 fictitious users. We then created textbfAppWorld Benchmark 40K linesof code a suite of 750 natural diverse and challenging autonomous agenttasks requiring rich and interactive code generation. It supports robustprogrammatic evaluation with state-based unit tests allowing for differentways of completing a task while also checking for unexpected changes i.e.collateral damage. The state-of-the-art LLM GPT-4o solves only 49 of ournormal tasks and 30 of challenge tasks while other models solve at least16 fewer. This highlights the benchmarks difficulty and AppWorlds potentialto push the frontiers of interactive coding agents. The project website isavailable at https://appworld.dev/.</p>
                <p>Last Updated: 2024-07-26 17:55:45 UTC</p>
                <button class="interpret-button" data-id="2407.18901v1">Interpret</button>
                <div id="interpretation-2407.18901v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Embedding And Clustering Your Data Can Improve Contrastive Pretraining</h3>
                <p>Authors: Luke Merrick</p>
                <p><a href="http://arxiv.org/abs/2407.18887v1">Link to paper</a></p>
                <p>Recent studies of large-scale contrastive pretraining in the text embeddingdomain show that using single-source minibatches rather than mixed-sourceminibatches can substantially improve overall model accuracy. In this work weexplore extending training data stratification beyond source granularity byleveraging a pretrained text embedding model and the classic k-means clusteringalgorithm to further split training data apart by the semantic clusters withineach source. Experimentally we observe a notable increase in NDCG10 whenpretraining a BERT-based text embedding model on query-passage pairs from theMSMARCO passage retrieval dataset. Additionally we conceptually connect ourclustering approach to both the Topic Aware Sampling TAS aspect of the TAS-Bmethodology and the nearest-neighbor-based hard-negative mining aspect of theANCE methodology and discuss how this unified view motivates future lines ofresearch on the organization of contrastive pretraining data.</p>
                <p>Last Updated: 2024-07-26 17:36:40 UTC</p>
                <button class="interpret-button" data-id="2407.18887v1">Interpret</button>
                <div id="interpretation-2407.18887v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Granularity is crucial when applying differential privacy to text: An investigation for neural machine translation</h3>
                <p>Authors: Doan Nam Long VuTimour IgamberdievIvan Habernal</p>
                <p><a href="http://arxiv.org/abs/2407.18789v1">Link to paper</a></p>
                <p>Applying differential privacy DP by means of the DP-SGD algorithm toprotect individual data points during training is becoming increasingly popularin NLP. However the choice of granularity at which DP is applied is oftenneglected. For example neural machine translation NMT typically operates onthe sentence-level granularity. From the perspective of DP this setup assumesthat each sentence belongs to a single person and any two sentences in thetraining dataset are independent. This assumption is however violated in manyreal-world NMT datasets e.g. those including dialogues. For proper applicationof DP we thus must shift from sentences to entire documents. In this paper weinvestigate NMT at both the sentence and document levels analyzing theprivacy/utility trade-off for both scenarios and evaluating the risks of notusing the appropriate privacy granularity in terms of leaking personallyidentifiable information PII. Our findings indicate that the document-levelNMT system is more resistant to membership inference attacks emphasizing thesignificance of using the appropriate granularity when working with DP.</p>
                <p>Last Updated: 2024-07-26 14:52:37 UTC</p>
                <button class="interpret-button" data-id="2407.18789v1">Interpret</button>
                <div id="interpretation-2407.18789v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs</h3>
                <p>Authors: Aleix SantCarlos EscolanoAudrey MashFrancesca De Luca FornaciariMaite Melero</p>
                <p><a href="http://arxiv.org/abs/2407.18786v1">Link to paper</a></p>
                <p>This paper studies gender bias in machine translation through the lens ofLarge Language Models LLMs. Four widely-used test sets are employed tobenchmark various base LLMs comparing their translation quality and genderbias against state-of-the-art Neural Machine Translation NMT models forEnglish to Catalan En rightarrow Ca and English to Spanish Enrightarrow Es translation directions. Our findings reveal pervasive genderbias across all models with base LLMs exhibiting a higher degree of biascompared to NMT models. To combat this bias we explore prompting engineeringtechniques applied to an instruction-tuned LLM. We identify a prompt structurethat significantly reduces gender bias by up to 12 on the WinoMT evaluationdataset compared to more straightforward prompts. These results significantlyreduce the gender bias accuracy gap between LLMs and traditional NMT systems.</p>
                <p>Last Updated: 2024-07-26 14:47:31 UTC</p>
                <button class="interpret-button" data-id="2407.18786v1">Interpret</button>
                <div id="interpretation-2407.18786v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Hybrid summary statistics: neural weak lensing inference beyond the power spectrum</h3>
                <p>Authors: T. Lucas MakinenTom CharnockNatalia PorqueresAxel LapelAlan HeavensBenjamin D. Wandelt</p>
                <p><a href="http://arxiv.org/abs/2407.18909v1">Link to paper</a></p>
                <p>In inference problems we often have domain knowledge which allows us todefine summary statistics that capture most of the information content in adataset. In this paper we present a hybrid approach where such physics-basedsummaries are augmented by a set of compressed neural summary statistics thatare optimised to extract the extra information that is not captured by thepredefined summaries. The resulting statistics are very powerful inputs tosimulation-based or implicit inference of model parameters. We apply thisgeneralisation of Information Maximising Neural Networks IMNNs to parameterconstraints from tomographic weak gravitational lensing convergence maps tofind summary statistics that are explicitly optimised to complement angularpower spectrum estimates. We study several dark matter simulation resolutionsin low- and high-noise regimes. We show that i the information-updateformalism extracts at least 3times and up to 8times as much informationas the angular power spectrum in all noise regimes ii the network summariesare highly complementary to existing 2-point summaries and iii our formalismallows for networks with smaller physically-informed architectures to matchmuch larger regression networks with far fewer simulations needed to obtainasymptotically optimal inference.</p>
                <p>Last Updated: 2024-07-26 17:59:26 UTC</p>
                <button class="interpret-button" data-id="2407.18909v1">Interpret</button>
                <div id="interpretation-2407.18909v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Learning Chaotic Systems and Long-Term Predictions with Neural Jump ODEs</h3>
                <p>Authors: Florian KrachJosef Teichmann</p>
                <p><a href="http://arxiv.org/abs/2407.18808v1">Link to paper</a></p>
                <p>The Path-dependent Neural Jump ODE PD-NJ-ODE is a model for onlineprediction of generic possibly non-Markovian stochastic processes withirregular in time and potentially incomplete with respect to coordinatesobservations. It is a model for which convergence to the L2-optimalpredictor which is given by the conditional expectation is establishedtheoretically. Thereby the training of the model is solely based on a datasetof realizations of the underlying stochastic process without the need ofknowledge of the law of the process. In the case where the underlying processis deterministic the conditional expectation coincides with the processitself. Therefore this framework can equivalently be used to learn thedynamics of ODE or PDE systems solely from realizations of the dynamical systemwith different initial conditions. We showcase the potential of our method byapplying it to the chaotic system of a double pendulum. When training thestandard PD-NJ-ODE method we see that the prediction starts to diverge fromthe true path after about half of the evaluation time. In this work we enhancethe model with two novel ideas which independently of each other improve theperformance of our modelling setup. The resulting dynamics match the truedynamics of the chaotic system very closely. The same enhancements can be usedto provably enable the PD-NJ-ODE to learn long-term predictions for generalstochastic datasets where the standard model fails. This is verified inseveral experiments.</p>
                <p>Last Updated: 2024-07-26 15:18:29 UTC</p>
                <button class="interpret-button" data-id="2407.18808v1">Interpret</button>
                <div id="interpretation-2407.18808v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Log-Concave Coupling for Sampling Neural Net Posteriors</h3>
                <p>Authors: Curtis McDonaldAndrew R Barron</p>
                <p><a href="http://arxiv.org/abs/2407.18802v1">Link to paper</a></p>
                <p>In this work we present a sampling algorithm for single hidden layer neuralnetworks. This algorithm is built upon a recursive series of Bayesianposteriors using a method we call Greedy Bayes. Sampling of the Bayesianposterior for neuron weight vectors w of dimension d is challenging becauseof its multimodality. Our algorithm to tackle this problem is based on acoupling of the posterior density for w with an auxiliary random variablexi.  The resulting reverse conditional wxi of neuron weights given auxiliaryrandom variable is shown to be log concave. In the construction of theposterior distributions we provide some freedom in the choice of the prior. Inparticular for Gaussian priors on w with suitably small variance theresulting marginal density of the auxiliary variable xi is proven to bestrictly log concave for all dimensions d. For a uniform prior on the unitell_1 ball evidence is given that the density of xi is again strictlylog concave for sufficiently large d.  The score of the marginal density of the auxiliary random variable xi isdetermined by an expectation over wxi and thus can be computed by variousrapidly mixing Markov Chain Monte Carlo methods. Moreover the computation ofthe score of xi permits methods of sampling xi by a stochastic diffusionLangevin dynamics with drift function built from this score. With suchdynamics information-theoretic methods pioneered by Bakry and Emery show thataccurate sampling of xi is obtained rapidly when its density is indeedstrictly log-concave. After which one more draw from wxi produces neuronweights w whose marginal distribution is from the desired posterior.</p>
                <p>Last Updated: 2024-07-26 15:05:41 UTC</p>
                <button class="interpret-button" data-id="2407.18802v1">Interpret</button>
                <div id="interpretation-2407.18802v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Score matching through the roof: linear, nonlinear, and latent variables causal discovery</h3>
                <p>Authors: Francesco MontagnaPhilipp M. FallerPatrick BloebaumElke KirschbaumFrancesco Locatello</p>
                <p><a href="http://arxiv.org/abs/2407.18755v1">Link to paper</a></p>
                <p>Causal discovery from observational data holds great promise but existingmethods rely on strong assumptions about the underlying causal structure oftenrequiring full observability of all relevant variables. We tackle thesechallenges by leveraging the score function nabla log pX of observedvariables for causal discovery and propose the following contributions. Firstwe generalize the existing results of identifiability with the score toadditive noise models with minimal requirements on the causal mechanisms.Second we establish conditions for inferring causal relations from the scoreeven in the presence of hidden variables this result is two-faced: wedemonstrate the scores potential as an alternative to conditional independencetests to infer the equivalence class of causal graphs with hidden variablesand we provide the necessary conditions for identifying direct causes in latentvariable models. Building on these insights we propose a flexible algorithmfor causal discovery across linear nonlinear and latent variable modelswhich we empirically validate.</p>
                <p>Last Updated: 2024-07-26 14:09:06 UTC</p>
                <button class="interpret-button" data-id="2407.18755v1">Interpret</button>
                <div id="interpretation-2407.18755v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Finite Neural Networks as Mixtures of Gaussian Processes: From Provable Error Bounds to Prior Selection</h3>
                <p>Authors: Steven AdamsPatanèMorteza LahijanianLuca Laurenti</p>
                <p><a href="http://arxiv.org/abs/2407.18707v1">Link to paper</a></p>
                <p>Infinitely wide or deep neural networks NNs with independent andidentically distributed i.i.d. parameters have been shown to be equivalent toGaussian processes. Because of the favorable properties of Gaussian processesthis equivalence is commonly employed to analyze neural networks and has led tovarious breakthroughs over the years. However neural networks and Gaussianprocesses are equivalent only in the limit in the finite case there arecurrently no methods available to approximate a trained neural network with aGaussian model with bounds on the approximation error. In this work we presentan algorithmic framework to approximate a neural network of finite width anddepth and with not necessarily i.i.d. parameters with a mixture of Gaussianprocesses with error bounds on the approximation error. In particular weconsider the Wasserstein distance to quantify the closeness betweenprobabilistic models and by relying on tools from optimal transport andGaussian processes we iteratively approximate the output distribution of eachlayer of the neural network as a mixture of Gaussian processes. Crucially forany NN and epsilon 0 our approach is able to return a mixture of Gaussianprocesses that is epsilon-close to the NN at a finite set of input points.Furthermore we rely on the differentiability of the resulting error bound toshow how our approach can be employed to tune the parameters of a NN to mimicthe functional behavior of a given Gaussian process e.g. for prior selectionin the context of Bayesian inference. We empirically investigate theeffectiveness of our results on both regression and classification problemswith various neural network architectures. Our experiments highlight how ourresults can represent an important step towards understanding neural networkpredictions and formally quantifying their uncertainty.</p>
                <p>Last Updated: 2024-07-26 12:45:53 UTC</p>
                <button class="interpret-button" data-id="2407.18707v1">Interpret</button>
                <div id="interpretation-2407.18707v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>SOAP-RL: Sequential Option Advantage Propagation for Reinforcement Learning in POMDP Environments</h3>
                <p>Authors: Shu IshidaJoão F. Henriques</p>
                <p><a href="http://arxiv.org/abs/2407.18913v1">Link to paper</a></p>
                <p>This work compares ways of extending Reinforcement Learning algorithms toPartially Observed Markov Decision Processes POMDPs with options. One view ofoptions is as temporally extended action which can be realized as a memorythat allows the agent to retain historical information beyond the policyscontext window. While option assignment could be handled using heuristics andhand-crafted objectives learning temporally consistent options and associatedsub-policies without explicit supervision is a challenge. Two algorithms PPOEMand SOAP are proposed and studied in depth to address this problem. PPOEMapplies the forward-backward algorithm for Hidden Markov Models to optimizethe expected returns for an option-augmented policy. However this learningapproach is unstable during on-policy rollouts. It is also unsuited forlearning causal policies without the knowledge of future trajectories sinceoption assignments are optimized for offline sequences where the entire episodeis available. As an alternative approach SOAP evaluates the policy gradientfor an optimal option assignment. It extends the concept of the generalizedadvantage estimation GAE to propagate option advantages through time whichis an analytical equivalent to performing temporal back-propagation of optionpolicy gradients. This option policy is only conditional on the history of theagent not future actions. Evaluated against competing baselines SOAPexhibited the most robust performance correctly discovering options for POMDPcorridor environments as well as on standard benchmarks including Atari andMuJoCo outperforming PPOEM as well as LSTM and Option-Critic baselines. Theopen-sourced code is available at https://github.com/shuishida/SoapRL.</p>
                <p>Last Updated: 2024-07-26 17:59:55 UTC</p>
                <button class="interpret-button" data-id="2407.18913v1">Interpret</button>
                <div id="interpretation-2407.18913v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Scalable Quantum Non-local Neural Network for Image Classification</h3>
                <p>Authors: Sparsh GuptaDebanjan KonarVaneet Aggarwal</p>
                <p><a href="http://arxiv.org/abs/2407.18906v1">Link to paper</a></p>
                <p>Non-local operations play a crucial role in computer vision enabling thecapture of long-range dependencies through weighted sums of features across theinput surpassing the constraints of traditional convolution operations thatfocus solely on local neighborhoods. Non-local operations typically requirecomputing pairwise relationships between all elements in a set leading toquadratic complexity in terms of time and memory. Due to the high computationaland memory demands scaling non-local neural networks to large-scale problemscan be challenging. This article introduces a hybrid quantum-classical scalablenon-local neural network referred to as Quantum Non-Local Neural NetworkQNL-Net to enhance pattern recognition. The proposed QNL-Net relies oninherent quantum parallelism to allow the simultaneous processing of a largenumber of input features enabling more efficient computations inquantum-enhanced feature space and involving pairwise relationships throughquantum entanglement. We benchmark our proposed QNL-Net with other quantumcounterparts to binary classification with datasets MNIST and CIFAR-10. Thesimulation findings showcase our QNL-Net achieves cutting-edge accuracy levelsin binary image classification among quantum classifiers while utilizing fewerqubits.</p>
                <p>Last Updated: 2024-07-26 17:58:57 UTC</p>
                <button class="interpret-button" data-id="2407.18906v1">Interpret</button>
                <div id="interpretation-2407.18906v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Lessons from Learning to Spin "Pens"</h3>
                <p>Authors: Jun WangYing YuanHaichuan CheHaozhi QiYi MaJitendra MalikXiaolong Wang</p>
                <p><a href="http://arxiv.org/abs/2407.18902v1">Link to paper</a></p>
                <p>In-hand manipulation of pen-like objects is an important skill in our dailylives as many tools such as hammers and screwdrivers are similarly shaped.However current learning-based methods struggle with this task due to a lackof high-quality demonstrations and the significant gap between simulation andthe real world. In this work we push the boundaries of learning-based in-handmanipulation systems by demonstrating the capability to spin pen-like objects.We first use reinforcement learning to train an oracle policy with privilegedinformation and generate a high-fidelity trajectory dataset in simulation. Thisserves two purposes: 1 pre-training a sensorimotor policy in simulation 2conducting open-loop trajectory replay in the real world. We then fine-tune thesensorimotor policy using these real-world trajectories to adapt it to the realworld dynamics. With less than 50 trajectories our policy learns to rotatemore than ten pen-like objects with different physical properties for multiplerevolutions. We present a comprehensive analysis of our design choices andshare the lessons learned during development.</p>
                <p>Last Updated: 2024-07-26 17:56:01 UTC</p>
                <button class="interpret-button" data-id="2407.18902v1">Interpret</button>
                <div id="interpretation-2407.18902v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents</h3>
                <p>Authors: Harsh TrivediTushar KhotMareike HartmannRuskin MankuVinty DongEdward LiShashank GuptaAshish SabharwalNiranjan Balasubramanian</p>
                <p><a href="http://arxiv.org/abs/2407.18901v1">Link to paper</a></p>
                <p>Autonomous agents that address day-to-day digital tasks e.g. orderinggroceries for a household must not only operate multiple apps e.g. notesmessaging shopping app via APIs but also generate rich code with complexcontrol flow in an iterative manner based on their interaction with theenvironment. However existing benchmarks for tool use are inadequate as theyonly cover tasks that require a simple sequence of API calls.  To remedy this gap we built textbfAppWorld Engine a high-qualityexecution environment 60K lines of code of 9 day-to-day apps operable via 457APIs and populated with realistic digital activities simulating the lives of100 fictitious users. We then created textbfAppWorld Benchmark 40K linesof code a suite of 750 natural diverse and challenging autonomous agenttasks requiring rich and interactive code generation. It supports robustprogrammatic evaluation with state-based unit tests allowing for differentways of completing a task while also checking for unexpected changes i.e.collateral damage. The state-of-the-art LLM GPT-4o solves only 49 of ournormal tasks and 30 of challenge tasks while other models solve at least16 fewer. This highlights the benchmarks difficulty and AppWorlds potentialto push the frontiers of interactive coding agents. The project website isavailable at https://appworld.dev/.</p>
                <p>Last Updated: 2024-07-26 17:55:45 UTC</p>
                <button class="interpret-button" data-id="2407.18901v1">Interpret</button>
                <div id="interpretation-2407.18901v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Learn from the Learnt: Source-Free Active Domain Adaptation via Contrastive Sampling and Visual Persistence</h3>
                <p>Authors: Mengyao LyuTianxiang HaoXinhao XuHui ChenZijia LinJungong HanGuiguang Ding</p>
                <p><a href="http://arxiv.org/abs/2407.18899v1">Link to paper</a></p>
                <p>Domain Adaptation DA facilitates knowledge transfer from a source domain toa related target domain. This paper investigates a practical DA paradigmnamely Source data-Free Active Domain Adaptation SFADA where source databecomes inaccessible during adaptation and a minimum amount of annotationbudget is available in the target domain. Without referencing the source datanew challenges emerge in identifying the most informative target samples forlabeling establishing cross-domain alignment during adaptation and ensuringcontinuous performance improvements through the iterative query-and-adaptationprocess. In response we present learn from the learnt LFTL a novel paradigmfor SFADA to leverage the learnt knowledge from the source pretrained model andactively iterated models without extra overhead. We propose Contrastive ActiveSampling to learn from the hypotheses of the preceding model thereby queryingtarget samples that are both informative to the current model and persistentlychallenging throughout active learning. During adaptation we learn fromfeatures of actively selected anchors obtained from previous intermediatemodels so that the Visual Persistence-guided Adaptation can facilitate featuredistribution alignment and active sample exploitation. Extensive experiments onthree widely-used benchmarks show that our LFTL achieves state-of-the-artperformance superior computational efficiency and continuous improvements asthe annotation budget increases. Our code is available athttps://github.com/lyumengyao/lftl.</p>
                <p>Last Updated: 2024-07-26 17:51:58 UTC</p>
                <button class="interpret-button" data-id="2407.18899v1">Interpret</button>
                <div id="interpretation-2407.18899v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>Mechanism Design for Locating Facilities with Capacities with Insufficient Resources</h3>
                <p>Authors: Gennaro AuricchioHarry J. CloughJie Zhang</p>
                <p><a href="http://arxiv.org/abs/2407.18547v1">Link to paper</a></p>
                <p>This paper explores the Mechanism Design aspects of the m-CapacitatedFacility Location Problem where the total facility capacity is less than thenumber of agents. Following the framework outlined by Aziz et al. the SocialWelfare of the facility location is determined through aFirst-Come-First-Served FCFS game in which agents compete once the facilitypositions are established. When the number of facilities is m  1 the NashEquilibrium NE of the FCFS game is not unique making the utility of theagents and the concept of truthfulness unclear. To tackle these issues weconsider absolutely truthful mechanisms i.e. mechanisms that prevent agentsfrom misreporting regardless of the strategies used during the FCFS game. Wecombine this stricter truthfulness requirement with the notion of EquilibriumStable ES mechanisms which are mechanisms whose Social Welfare does notdepend on the NE of the FCFS game. We demonstrate that the class of percentilemechanisms is absolutely truthful and identify the conditions under which theyare ES. We also show that the approximation ratio of each ES percentilemechanism is bounded and determine its value. Notably when all the facilitieshave the same capacity and the number of agents is sufficiently large it ispossible to achieve an approximation ratio smaller than 1frac12m-1.Finally we extend our study to encompass higher-dimensional problems. Withinthis framework we demonstrate that the class of ES percentile mechanisms iseven more restricted and characterize the mechanisms that are both ES andabsolutely truthful. We further support our findings by empirically evaluatingthe performance of the mechanisms when the agents are the samples of adistribution.</p>
                <p>Last Updated: 2024-07-26 06:55:26 UTC</p>
                <button class="interpret-button" data-id="2407.18547v1">Interpret</button>
                <div id="interpretation-2407.18547v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Socially efficient mechanism on the minimum budget</h3>
                <p>Authors: Hirota KinoshitaTakayuki OsogamiKohei Miyaguchi</p>
                <p><a href="http://arxiv.org/abs/2407.18515v1">Link to paper</a></p>
                <p>In social decision-making among strategic agents a universal focus lies onthe balance between social and individual interests. Socially efficientmechanisms are thus desirably designed to not only maximize the social welfarebut also incentivize the agents for their own profit. Under a generalized modelthat includes applications such as double auctions and trading networks thisstudy establishes a socially efficient SE dominant-strategy incentivecompatible DSIC and individually rational IR mechanism with the minimumtotal budget expensed to the agents. The present method exploits discrete andknown type domains to reduce a set of constraints into the shortest pathproblem in a weighted graph. In addition to theoretical derivation wesubstantiate the optimality of the proposed mechanism through numericalexperiments where it certifies strictly lower budget thanVickery-Clarke-Groves VCG mechanisms for a wide class of instances.</p>
                <p>Last Updated: 2024-07-26 05:00:19 UTC</p>
                <button class="interpret-button" data-id="2407.18515v1">Interpret</button>
                <div id="interpretation-2407.18515v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Strategic Cost Selection in Participatory Budgeting</h3>
                <p>Authors: Piotr FaliszewskiŁukasz JaneczkoAndrzej KaczmarczykGrzegorz LisowskiPiotr SkowronStanisław Szufa</p>
                <p><a href="http://arxiv.org/abs/2407.18092v1">Link to paper</a></p>
                <p>We study strategic behavior of project proposers in the context ofapproval-based participatory budgeting PB. In our model we assume that thevotes are fixed and known and the proposers want to set as high project pricesas possible provided that their projects get selected and the prices are notbelow the minimum costs of their delivery. We study the existence of pure Nashequilibria NE in such games focusing on the AV/Cost Phragmen and Methodof Equal Shares rules. Furthermore we report an experimental study ofstrategic cost selection on real-life PB election data.</p>
                <p>Last Updated: 2024-07-25 15:00:12 UTC</p>
                <button class="interpret-button" data-id="2407.18092v1">Interpret</button>
                <div id="interpretation-2407.18092v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Principal-Agent Reinforcement Learning</h3>
                <p>Authors: Dima IvanovPaul DüttingInbal Talgam-CohenTonghan WangDavid C. Parkes</p>
                <p><a href="http://arxiv.org/abs/2407.18074v1">Link to paper</a></p>
                <p>Contracts are the economic framework which allows a principal to delegate atask to an agent -- despite misaligned interests and even without directlyobserving the agents actions. In many modern reinforcement learning settingsself-interested agents learn to perform a multi-stage task delegated to them bya principal. We explore the significant potential of utilizing contracts toincentivize the agents. We model the delegated task as an MDP and study astochastic game between the principal and agent where the principal learns whatcontracts to use and the agent learns an MDP policy in response. We present alearning-based algorithm for optimizing the principals contracts whichprovably converges to the subgame-perfect equilibrium of the principal-agentgame. A deep RL implementation allows us to apply our method to very large MDPswith unknown transition dynamics. We extend our approach to multiple agentsand demonstrate its relevance to resolving a canonical sequential socialdilemma with minimal intervention to agent rewards.</p>
                <p>Last Updated: 2024-07-25 14:28:58 UTC</p>
                <button class="interpret-button" data-id="2407.18074v1">Interpret</button>
                <div id="interpretation-2407.18074v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Stochastic Games with Minimally Bounded Action Costs</h3>
                <p>Authors: David Mguni</p>
                <p><a href="http://arxiv.org/abs/2407.18010v1">Link to paper</a></p>
                <p>In many multi-player interactions players incur strictly positive costs eachtime they execute actions e.g. menu costs or transaction costs in financialsystems. Since acting at each available opportunity would accumulateprohibitively large costs the resulting decision problem is one in whichplayers must make strategic decisions about when to execute actions in additionto their choice of action. This paper analyses a discrete-time stochastic gameSG in which players face minimally bounded positive costs for each action andinfluence the system using impulse controls. We prove SGs of two-sided impulsecontrol have a unique value and characterise the saddle point equilibrium inwhich the players execute actions at strategically chosen times in accordancewith Markovian strategies. We prove the game respects a dynamic programmingprinciple and that the Markov perfect equilibrium can be computed as a limitpoint of a sequence of Bellman operations. We then introduce a new Q-learningvariant which we show converges almost surely to the value of the game enablingsolutions to be extracted in unknown settings. Lastly we extend our results tosettings with budgetory constraints.</p>
                <p>Last Updated: 2024-07-25 13:04:49 UTC</p>
                <button class="interpret-button" data-id="2407.18010v1">Interpret</button>
                <div id="interpretation-2407.18010v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>Floating No More: Object-Ground Reconstruction from a Single Image</h3>
                <p>Authors: Yunze ManYichen ShengJianming ZhangLiang-Yan GuiYu-Xiong Wang</p>
                <p><a href="http://arxiv.org/abs/2407.18914v1">Link to paper</a></p>
                <p>Recent advancements in 3D object reconstruction from single images haveprimarily focused on improving the accuracy of object shapes. Yet thesetechniques often fail to accurately capture the inter-relation between theobject ground and camera. As a result the reconstructed objects often appearfloating or tilted when placed on flat surfaces. This limitation significantlyaffects 3D-aware image editing applications like shadow rendering and objectpose manipulation. To address this issue we introduce ORG ObjectReconstruction with Ground a novel task aimed at reconstructing 3D objectgeometry in conjunction with the ground surface. Our method uses two compactpixel-level representations to depict the relationship between camera objectand ground. Experiments show that the proposed ORG model can effectivelyreconstruct object-ground geometry on unseen data significantly enhancing thequality of shadow generation and pose manipulation compared to conventionalsingle-image 3D reconstruction techniques.</p>
                <p>Last Updated: 2024-07-26 17:59:56 UTC</p>
                <button class="interpret-button" data-id="2407.18914v1">Interpret</button>
                <div id="interpretation-2407.18914v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>HRP: Human Affordances for Robotic Pre-Training</h3>
                <p>Authors: Mohan Kumar SriramaSudeep DasariShikhar BahlAbhinav Gupta</p>
                <p><a href="http://arxiv.org/abs/2407.18911v1">Link to paper</a></p>
                <p>In order to generalize to various tasks in the wild robotic agents willneed a suitable representation i.e. vision network that enables the robot topredict optimal actions given high dimensional vision inputs. However learningsuch a representation requires an extreme amount of diverse training datawhich is prohibitively expensive to collect on a real robot. How can weovercome this problem Instead of collecting more robot data this paperproposes using internet-scale human videos to extract affordances both atthe environment and agent level and distill them into a pre-trainedrepresentation. We present a simple framework for pre-training representationson hand object and contact affordance labels that highlight relevantobjects in images and how to interact with them. These affordances areautomatically extracted from human video data with the help of off-the-shelfcomputer vision modules and used to fine-tune existing representations. Ourapproach can efficiently fine-tune any existing representation and resultsin models with stronger downstream robotic performance across the board. Weexperimentally demonstrate using 3000 robot trials that this affordancepre-training scheme boosts performance by a minimum of 15 on 5 real-worldtasks which consider three diverse robot morphologies including a dexteroushand. Unlike prior works in the space these representations improveperformance across 3 different camera views. Quantitatively we find that ourapproach leads to higher levels of generalization in out-of-distributionsettings. For code weights and data check: https://hrp-robot.github.io</p>
                <p>Last Updated: 2024-07-26 17:59:52 UTC</p>
                <button class="interpret-button" data-id="2407.18911v1">Interpret</button>
                <div id="interpretation-2407.18911v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Wolf: Captioning Everything with a World Summarization Framework</h3>
                <p>Authors: Boyi LiLigeng ZhuRan TianShuhan TanYuxiao ChenYao LuYin CuiSushant VeerMax EhrlichJonah PhilionXinshuo WengFuzhao XueAndrew TaoMing-Yu LiuSanja FidlerBoris IvanovicTrevor DarrellJitendra MalikSong HanMarco Pavone</p>
                <p><a href="http://arxiv.org/abs/2407.18908v1">Link to paper</a></p>
                <p>We propose Wolf a WOrLd summarization Framework for accurate videocaptioning. Wolf is an automated captioning framework that adopts amixture-of-experts approach leveraging complementary strengths of VisionLanguage Models VLMs. By utilizing both image and video models our frameworkcaptures different levels of information and summarizes them efficiently. Ourapproach can be applied to enhance video understanding auto-labeling andcaptioning. To evaluate caption quality we introduce CapScore an LLM-basedmetric to assess the similarity and quality of generated captions compared tothe ground truth captions. We further build four human-annotated datasets inthree domains: autonomous driving general scenes and robotics to facilitatecomprehensive comparisons. We show that Wolf achieves superior captioningperformance compared to state-of-the-art approaches from the research communityVILA1.5 CogAgent and commercial solutions Gemini-Pro-1.5 GPT-4V. Forinstance in comparison with GPT-4V Wolf improves CapScore both quality-wiseby 55.6 and similarity-wise by 77.4 on challenging driving videos. Finallywe establish a benchmark for video captioning and introduce a leaderboardaiming to accelerate advancements in video understanding captioning and dataalignment. Leaderboard: https://wolfv0.github.io/leaderboard.html.</p>
                <p>Last Updated: 2024-07-26 17:59:09 UTC</p>
                <button class="interpret-button" data-id="2407.18908v1">Interpret</button>
                <div id="interpretation-2407.18908v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>SHIC: Shape-Image Correspondences with no Keypoint Supervision</h3>
                <p>Authors: Aleksandar ShtedritskiChristian RupprechtAndrea Vedaldi</p>
                <p><a href="http://arxiv.org/abs/2407.18907v1">Link to paper</a></p>
                <p>Canonical surface mapping generalizes keypoint detection by assigning eachpixel of an object to a corresponding point in a 3D template. Popularised byDensePose for the analysis of humans authors have since attempted to apply theconcept to more categories but with limited success due to the high cost ofmanual supervision. In this work we introduce SHIC a method to learncanonical maps without manual supervision which achieves better results thansupervised methods for most categories. Our idea is to leverage foundationcomputer vision models such as DINO and Stable Diffusion that are open-endedand thus possess excellent priors over natural categories. SHIC reduces theproblem of estimating image-to-template correspondences to predictingimage-to-image correspondences using features from the foundation models. Thereduction works by matching images of the object to non-photorealistic rendersof the template which emulates the process of collecting manual annotationsfor this task. These correspondences are then used to supervise high-qualitycanonical maps for any object of interest. We also show that image generatorscan further improve the realism of the template views which provide anadditional source of supervision for the model.</p>
                <p>Last Updated: 2024-07-26 17:58:59 UTC</p>
                <button class="interpret-button" data-id="2407.18907v1">Interpret</button>
                <div id="interpretation-2407.18907v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Scalable Quantum Non-local Neural Network for Image Classification</h3>
                <p>Authors: Sparsh GuptaDebanjan KonarVaneet Aggarwal</p>
                <p><a href="http://arxiv.org/abs/2407.18906v1">Link to paper</a></p>
                <p>Non-local operations play a crucial role in computer vision enabling thecapture of long-range dependencies through weighted sums of features across theinput surpassing the constraints of traditional convolution operations thatfocus solely on local neighborhoods. Non-local operations typically requirecomputing pairwise relationships between all elements in a set leading toquadratic complexity in terms of time and memory. Due to the high computationaland memory demands scaling non-local neural networks to large-scale problemscan be challenging. This article introduces a hybrid quantum-classical scalablenon-local neural network referred to as Quantum Non-Local Neural NetworkQNL-Net to enhance pattern recognition. The proposed QNL-Net relies oninherent quantum parallelism to allow the simultaneous processing of a largenumber of input features enabling more efficient computations inquantum-enhanced feature space and involving pairwise relationships throughquantum entanglement. We benchmark our proposed QNL-Net with other quantumcounterparts to binary classification with datasets MNIST and CIFAR-10. Thesimulation findings showcase our QNL-Net achieves cutting-edge accuracy levelsin binary image classification among quantum classifiers while utilizing fewerqubits.</p>
                <p>Last Updated: 2024-07-26 17:58:57 UTC</p>
                <button class="interpret-button" data-id="2407.18906v1">Interpret</button>
                <div id="interpretation-2407.18906v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-07-29</p>
        </div>
    
        </div>
    </body>
    </html>
    