
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>SpaceByte: Towards Deleting Tokenization from Large Language Modeling</h3>
                <p>Authors: Kevin Slagle</p>
                <p><a href="http://arxiv.org/abs/2404.14408v1">Link to paper</a></p>
                <p>Tokenization is widely used in large language models because it significantlyimproves performance. However tokenization imposes several disadvantages suchas performance biases increased adversarial vulnerability decreasedcharacter-level modeling performance and increased modeling complexity. Toaddress these disadvantages without sacrificing performance we proposeSpaceByte a novel byte-level decoder architecture that closes the performancegap between byte-level and subword autoregressive language modeling. SpaceByteconsists of a byte-level Transformer model but with extra larger transformerblocks inserted in the middle of the layers. We find that performance issignificantly improved by applying these larger blocks only after certainbytes such as space characters which typically denote word boundaries. Ourexperiments show that for a fixed training and inference compute budgetSpaceByte outperforms other byte-level architectures and roughly matches theperformance of tokenized Transformer architectures.</p>
                <p>Last Updated: 2024-04-22 17:59:29 UTC</p>
                <button class="interpret-button" data-id="2404.14408v1">Interpret</button>
                <div id="interpretation-2404.14408v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>PARAMANU-GANITA: Language Model with Mathematical Capabilities</h3>
                <p>Authors: Mitodru NiyogiArnab Bhattacharya</p>
                <p><a href="http://arxiv.org/abs/2404.14395v1">Link to paper</a></p>
                <p>In this paper we present Paramanu-Ganita a 208 million parameter novel AutoRegressive AR decoder based language model on mathematics. The model ispretrained from scratch at context size of 4096 on our curated mixedmathematical corpus. We evaluate our model on both perplexity metric and GSM8kmathematical benchmark. Paramanu-Ganita despite being 35 times smaller than 7BLLMs outperformed generalist LLMs such as LLaMa-1 7B by 28.4 points LLaMa-27B by 27.6 points Falcon 7B by 32.6 points PaLM 8B by 35.3 points andmath specialised LLMs such as Minerva 8B by 23.2 points and LLEMMA-7B by 3.0points in GSM8k test accuracy metric respectively. Paramanu-Ganita alsooutperformed giant LLMs like PaLM 62B by 6.4 points Falcon 40B by 19.8points LLaMa-1 33B by 3.8 points and Vicuna 13B by 11.8 points respectively.The large significant margin improvement in performance of our math model overthe existing LLMs signifies that reasoning capabilities of language model arejust not restricted to LLMs with humongous number of parameters.Paramanu-Ganita took 146 hours of A100 training whereas math specialised LLMLLEMMA 7B was trained for 23000 A100 hours of training equivalent. Thus ourapproach of pretraining powerful domain specialised language models fromscratch for domain adaptation is much more cost-effective than performingcontinual training of LLMs for domain adaptation. Hence we conclude that forstrong mathematical reasoning abilities of language model we do not need giantLLMs and immense computing power to our end. In the end we want to point outthat we have only trained Paramanu-Ganita only on a part of our entiremathematical corpus and yet to explore the full potential of our model.</p>
                <p>Last Updated: 2024-04-22 17:55:56 UTC</p>
                <button class="interpret-button" data-id="2404.14395v1">Interpret</button>
                <div id="interpretation-2404.14395v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Multimodal Automated Interpretability Agent</h3>
                <p>Authors: Tamar Rott ShahamSarah SchwettmannFranklin WangAchyuta RajaramEvan HernandezJacob AndreasAntonio Torralba</p>
                <p><a href="http://arxiv.org/abs/2404.14394v1">Link to paper</a></p>
                <p>This paper describes MAIA a Multimodal Automated Interpretability Agent.MAIA is a system that uses neural models to automate neural model understandingtasks like feature interpretation and failure mode discovery. It equips apre-trained vision-language model with a set of tools that support iterativeexperimentation on subcomponents of other models to explain their behavior.These include tools commonly used by human interpretability researchers: forsynthesizing and editing inputs computing maximally activating exemplars fromreal-world datasets and summarizing and describing experimental results.Interpretability experiments proposed by MAIA compose these tools to describeand explain system behavior. We evaluate applications of MAIA to computervision models. We first characterize MAIAs ability to describe neuron-levelfeatures in learned representations of images. Across several trained modelsand a novel dataset of synthetic vision neurons with paired ground-truthdescriptions MAIA produces descriptions comparable to those generated byexpert human experimenters. We then show that MAIA can aid in two additionalinterpretability tasks: reducing sensitivity to spurious features andautomatically identifying inputs likely to be mis-classified.</p>
                <p>Last Updated: 2024-04-22 17:55:11 UTC</p>
                <button class="interpret-button" data-id="2404.14394v1">Interpret</button>
                <div id="interpretation-2404.14394v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Survey on Self-Evolution of Large Language Models</h3>
                <p>Authors: Zhengwei TaoTing-En LinXiancai ChenHangyu LiYuchuan WuYongbin LiZhi JinFei HuangDacheng TaoJingren Zhou</p>
                <p><a href="http://arxiv.org/abs/2404.14387v1">Link to paper</a></p>
                <p>Large language models LLMs have significantly advanced in various fieldsand intelligent agent applications. However current LLMs that learn from humanor external model supervision are costly and may face performance ceilings astask complexity and diversity increase. To address this issue self-evolutionapproaches that enable LLM to autonomously acquire refine and learn fromexperiences generated by the model itself are rapidly growing. This newtraining paradigm inspired by the human experiential learning process offersthe potential to scale LLMs towards superintelligence. In this work we presenta comprehensive survey of self-evolution approaches in LLMs. We first propose aconceptual framework for self-evolution and outline the evolving process asiterative cycles composed of four phases: experience acquisition experiencerefinement updating and evaluation. Second we categorize the evolutionobjectives of LLMs and LLM-based agents then we summarize the literature andprovide taxonomy and insights for each module. Lastly we pinpoint existingchallenges and propose future directions to improve self-evolution frameworksequipping researchers with critical insights to fast-track the development ofself-evolving LLMs.</p>
                <p>Last Updated: 2024-04-22 17:43:23 UTC</p>
                <button class="interpret-button" data-id="2404.14387v1">Interpret</button>
                <div id="interpretation-2404.14387v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph</h3>
                <p>Authors: Xiaochen Kev GaoFeng YaoKewen ZhaoBeilei HeAnimesh KumarVish KrishnanJingbo Shang</p>
                <p><a href="http://arxiv.org/abs/2404.14372v1">Link to paper</a></p>
                <p>Model scaling is becoming the default choice for many language tasks due tothe success of large language models LLMs. However it can fall short inspecific scenarios where simple customized methods excel. In this paper wedelve into the patent approval pre-diction task and unveil that simpledomain-specific graph methods outperform enlarging the model using theintrinsic dependencies within the patent data. Specifically we first extendthe embedding-based state-of-the-art SOTA by scaling up its backbone modelwith various sizes of open-source LLMs then explore prompt-based methods toharness proprietary LLMs potential but find the best results close to randomguessing underlining the ineffectiveness of model scaling-up. Hence wepropose a novel Fine-grained cLAim depeNdency FLAN Graph through meticulouspatent data analyses capturing the inherent dependencies across segments ofthe patent text. As it is model-agnostic we apply cost-effective graph modelsto our FLAN Graph to obtain representations for approval prediction. Extensiveexperiments and detailed analyses prove that incorporating FLAN Graph viavarious graph models consistently outperforms all LLM baselines significantly.We hope that our observations and analyses in this paper can bring moreattention to this challenging task and prompt further research into thelimitations of LLMs. Our source code and dataset can be obtained fromhttp://github.com/ShangDataLab/FLAN-Graph.</p>
                <p>Last Updated: 2024-04-22 17:22:31 UTC</p>
                <button class="interpret-button" data-id="2404.14372v1">Interpret</button>
                <div id="interpretation-2404.14372v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Preserving linear invariants in ensemble filtering methods</h3>
                <p>Authors: Mathieu Le ProvostJan GlaubitzYoussef Marzouk</p>
                <p><a href="http://arxiv.org/abs/2404.14328v1">Link to paper</a></p>
                <p>Formulating dynamical models for physical phenomena is essential forunderstanding the interplay between the different mechanisms and predicting theevolution of physical states. However a dynamical model alone is ofteninsufficient to address these fundamental tasks as it suffers from modelerrors and uncertainties. One common remedy is to rely on data assimilationwhere the state estimate is updated with observations of the true system.Ensemble filters sequentially assimilate observations by updating a set ofsamples over time. They operate in two steps: a forecast step that propagateseach sample through the dynamical model and an analysis step that updates thesamples with incoming observations. For accurate and robust predictions ofdynamical systems discrete solutions must preserve their critical invariants.While modern numerical solvers satisfy these invariants existinginvariant-preserving analysis steps are limited to Gaussian settings and areoften not compatible with classical regularization techniques of ensemblefilters e.g. inflation and covariance tapering. The present work focuses onpreserving linear invariants such as mass stoichiometric balance of chemicalspecies and electrical charges. Using tools from measure transport theorySpantini et al. 2022 SIAM Review we introduce a generic class of nonlinearensemble filters that automatically preserve desired linear invariants innon-Gaussian filtering problems. By specializing this framework to the Gaussiansetting we recover a constrained formulation of the Kalman filter. Then weshow how to combine existing regularization techniques for the ensemble Kalmanfilter Evensen 1994 J. Geophys. Res. with the preservation of the linearinvariants. Finally we assess the benefits of preserving linear invariants forthe ensemble Kalman filter and nonlinear ensemble filters.</p>
                <p>Last Updated: 2024-04-22 16:39:32 UTC</p>
                <button class="interpret-button" data-id="2404.14328v1">Interpret</button>
                <div id="interpretation-2404.14328v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Bayesian Approach for Prioritising Driving Behaviour Investigations in Telematic Auto Insurance Policies</h3>
                <p>Authors: Mark McLeodBernardo Perez-OrozcoNika LeeDavide Zilli</p>
                <p><a href="http://arxiv.org/abs/2404.14276v1">Link to paper</a></p>
                <p>Automotive insurers increasingly have access to telematic information viablack-box recorders installed in the insured vehicle and wish to identifyundesirable behaviour which may signify increased risk or uninsured activities.However identification of such behaviour with machine learning is non-trivialand results are far from perfect requiring human investigation to verifysuspected cases. An appropriately formed priority score generated by automatedanalysis of GPS data allows underwriters to make more efficient use of theirtime improving detection of the behaviour under investigation.  An example of such behaviour is the use of a privately insured vehicle forcommercial purposes such as delivering meals and parcels. We first make use oftrip GPS and accelerometer data augmented by geospatial information to trainan imperfect classifier for delivery driving on a per-trip basis. We make useof a mixture of Beta-Binomial distributions to model the propensity of apolicyholder to undertake trips which result in a positive classification asbeing drawn from either a rare high-scoring or common low-scoring group andlearn the parameters of this model using MCMC. This model provides us with aposterior probability that any policyholder will be a regular generator ofautomated alerts given any number of trips and alerts. This posteriorprobability is converted to a priority score which was used to select the mostvaluable candidates for manual investigation.  Testing over a 1-year period ranked policyholders by likelihood of commercialdriving activity on a weekly basis. The top 0.9 have been reviewed at leastonce by the underwriters at the time of writing and of those 99.4 have beenconfirmed as correctly identified showing the approach has achieved asignificant improvement in efficiency of human resource allocation compared tomanual searching.</p>
                <p>Last Updated: 2024-04-22 15:26:24 UTC</p>
                <button class="interpret-button" data-id="2404.14276v1">Interpret</button>
                <div id="interpretation-2404.14276v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Rotting Infinitely Many-armed Bandits beyond the Worst-case Rotting: An Adaptive Approach</h3>
                <p>Authors: Jung-hun KimMilan VojnovicSe-Young Yun</p>
                <p><a href="http://arxiv.org/abs/2404.14202v1">Link to paper</a></p>
                <p>In this study we consider the infinitely many armed bandit problems inrotting environments where the mean reward of an arm may decrease with eachpull while otherwise it remains unchanged. We explore two scenarios capturingproblem-dependent characteristics regarding the decay of rewards: one in whichthe cumulative amount of rotting is bounded by V_T referred to as theslow-rotting scenario and the other in which the number of rotting instancesis bounded by S_T referred to as the abrupt-rotting scenario. To address thechallenge posed by rotting rewards we introduce an algorithm that utilizes UCBwith an adaptive sliding window designed to manage the bias and variancetrade-off arising due to rotting rewards. Our proposed algorithm achieves tightregret bounds for both slow and abrupt rotting scenarios. Lastly wedemonstrate the performance of our algorithms using synthetic datasets.</p>
                <p>Last Updated: 2024-04-22 14:11:54 UTC</p>
                <button class="interpret-button" data-id="2404.14202v1">Interpret</button>
                <div id="interpretation-2404.14202v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Prediction of flow and elastic stresses in a viscoelastic turbulent channel flow using convolutional neural networks</h3>
                <p>Authors: Arivazhagan G. BalasubramanianRicardo VinuesaOuti Tammisola</p>
                <p><a href="http://arxiv.org/abs/2404.14121v1">Link to paper</a></p>
                <p>Neural-network models have been employed to predict the instantaneous flowclose to the wall in a viscoelastic turbulent channel flow. The numericalsimulation data at the wall is utilized to predict the instantaneous velocityfluctuations and polymeric-stress fluctuations at three different wall-normalpositions. Apart from predicting the velocity fluctuations well in ahibernating flow the neural-network models are also shown to predict thepolymeric shear stress and the trace of the polymeric stresses at a givenwall-normal location with reasonably good accuracy. These non-intrusive sensingmodels can be integrated in an experimental setting to construct thepolymeric-stress field in turbulent flows which otherwise may not be directlyquantifiable in experimental measurements.</p>
                <p>Last Updated: 2024-04-22 12:19:00 UTC</p>
                <button class="interpret-button" data-id="2404.14121v1">Interpret</button>
                <div id="interpretation-2404.14121v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Noise contrastive estimation with soft targets for conditional models</h3>
                <p>Authors: Johannes HuggerVirginie Uhlmann</p>
                <p><a href="http://arxiv.org/abs/2404.14076v1">Link to paper</a></p>
                <p>Soft targets combined with the cross-entropy loss have shown to improvegeneralization performance of deep neural networks on supervised classificationtasks. The standard cross-entropy loss however assumes data to be categoricallydistributed which may often not be the case in practice. In contrast InfoNCEdoes not rely on such an explicit assumption but instead implicitly estimatesthe true conditional through negative sampling. Unfortunately it cannot becombined with soft targets in its standard formulation hindering its use incombination with sophisticated training strategies. In this paper we addressthis limitation by proposing a principled loss function that is compatible withprobabilistic targets. Our new soft target InfoNCE loss is conceptually simpleefficient to compute and can be derived within the framework of noisecontrastive estimation. Using a toy example we demonstrate shortcomings of thecategorical distribution assumption of cross-entropy and discuss implicationsof sampling from soft distributions. We observe that soft target InfoNCEperforms on par with strong soft target cross-entropy baselines and outperformshard target NLL and InfoNCE losses on popular benchmarks including ImageNet.Finally we provide a simple implementation of our loss geared towardssupervised classification and fully compatible with deep classification modeltrained with cross-entropy.</p>
                <p>Last Updated: 2024-04-22 10:45:59 UTC</p>
                <button class="interpret-button" data-id="2404.14076v1">Interpret</button>
                <div id="interpretation-2404.14076v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>SpaceByte: Towards Deleting Tokenization from Large Language Modeling</h3>
                <p>Authors: Kevin Slagle</p>
                <p><a href="http://arxiv.org/abs/2404.14408v1">Link to paper</a></p>
                <p>Tokenization is widely used in large language models because it significantlyimproves performance. However tokenization imposes several disadvantages suchas performance biases increased adversarial vulnerability decreasedcharacter-level modeling performance and increased modeling complexity. Toaddress these disadvantages without sacrificing performance we proposeSpaceByte a novel byte-level decoder architecture that closes the performancegap between byte-level and subword autoregressive language modeling. SpaceByteconsists of a byte-level Transformer model but with extra larger transformerblocks inserted in the middle of the layers. We find that performance issignificantly improved by applying these larger blocks only after certainbytes such as space characters which typically denote word boundaries. Ourexperiments show that for a fixed training and inference compute budgetSpaceByte outperforms other byte-level architectures and roughly matches theperformance of tokenized Transformer architectures.</p>
                <p>Last Updated: 2024-04-22 17:59:29 UTC</p>
                <button class="interpret-button" data-id="2404.14408v1">Interpret</button>
                <div id="interpretation-2404.14408v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?</h3>
                <p>Authors: Adrian de WynterIshaan WattsNektar Ege AltıntoprakTua WongsangaroonsriMinghui ZhangNoura FarraLena BaurSamantha ClaudetPavel GajdusekCan GörenQilong GuAnna KaminskaTomasz KaminskiRuby KuoAkiko KyubaJongho LeeKartik MathurPetter MerokIvana MilovanovićNani PaananenVesa-Matti PaananenAnna PavlenkoBruno Pereira VidalLuciano StrikaYueh TsaoDavide TurcatoOleksandr VakhnoJudit VelcsovAnna VickersStéphanie VisserHerdyan WidarmantoAndrey ZaikinSi-Qing Chen</p>
                <p><a href="http://arxiv.org/abs/2404.14397v1">Link to paper</a></p>
                <p>Large language models LLMs and small language models SLMs are beingadopted at remarkable speed although their safety still remains a seriousconcern. With the advent of multilingual S/LLMs the question now becomes amatter of scale: can we expand multilingual safety evaluations of these modelswith the same velocity at which they are deployed To this end we introduceRTP-LX a human-transcreated and human-annotated corpus of toxic prompts andoutputs in 28 languages. RTP-LX follows participatory design practices and aportion of the corpus is especially designed to detect culturally-specifictoxic language. We evaluate seven S/LLMs on their ability to detect toxiccontent in a culturally-sensitive multilingual scenario. We find thatalthough they typically score acceptably in terms of accuracy they have lowagreement with human judges when judging holistically the toxicity of a promptand have difficulty discerning harm in context-dependent scenariosparticularly with subtle-yet-harmful content e.g. microagressions bias. Werelease of this dataset to contribute to further reduce harmful uses of thesemodels and improve their safe deployment.</p>
                <p>Last Updated: 2024-04-22 17:56:26 UTC</p>
                <button class="interpret-button" data-id="2404.14397v1">Interpret</button>
                <div id="interpretation-2404.14397v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>PARAMANU-GANITA: Language Model with Mathematical Capabilities</h3>
                <p>Authors: Mitodru NiyogiArnab Bhattacharya</p>
                <p><a href="http://arxiv.org/abs/2404.14395v1">Link to paper</a></p>
                <p>In this paper we present Paramanu-Ganita a 208 million parameter novel AutoRegressive AR decoder based language model on mathematics. The model ispretrained from scratch at context size of 4096 on our curated mixedmathematical corpus. We evaluate our model on both perplexity metric and GSM8kmathematical benchmark. Paramanu-Ganita despite being 35 times smaller than 7BLLMs outperformed generalist LLMs such as LLaMa-1 7B by 28.4 points LLaMa-27B by 27.6 points Falcon 7B by 32.6 points PaLM 8B by 35.3 points andmath specialised LLMs such as Minerva 8B by 23.2 points and LLEMMA-7B by 3.0points in GSM8k test accuracy metric respectively. Paramanu-Ganita alsooutperformed giant LLMs like PaLM 62B by 6.4 points Falcon 40B by 19.8points LLaMa-1 33B by 3.8 points and Vicuna 13B by 11.8 points respectively.The large significant margin improvement in performance of our math model overthe existing LLMs signifies that reasoning capabilities of language model arejust not restricted to LLMs with humongous number of parameters.Paramanu-Ganita took 146 hours of A100 training whereas math specialised LLMLLEMMA 7B was trained for 23000 A100 hours of training equivalent. Thus ourapproach of pretraining powerful domain specialised language models fromscratch for domain adaptation is much more cost-effective than performingcontinual training of LLMs for domain adaptation. Hence we conclude that forstrong mathematical reasoning abilities of language model we do not need giantLLMs and immense computing power to our end. In the end we want to point outthat we have only trained Paramanu-Ganita only on a part of our entiremathematical corpus and yet to explore the full potential of our model.</p>
                <p>Last Updated: 2024-04-22 17:55:56 UTC</p>
                <button class="interpret-button" data-id="2404.14395v1">Interpret</button>
                <div id="interpretation-2404.14395v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Multimodal Automated Interpretability Agent</h3>
                <p>Authors: Tamar Rott ShahamSarah SchwettmannFranklin WangAchyuta RajaramEvan HernandezJacob AndreasAntonio Torralba</p>
                <p><a href="http://arxiv.org/abs/2404.14394v1">Link to paper</a></p>
                <p>This paper describes MAIA a Multimodal Automated Interpretability Agent.MAIA is a system that uses neural models to automate neural model understandingtasks like feature interpretation and failure mode discovery. It equips apre-trained vision-language model with a set of tools that support iterativeexperimentation on subcomponents of other models to explain their behavior.These include tools commonly used by human interpretability researchers: forsynthesizing and editing inputs computing maximally activating exemplars fromreal-world datasets and summarizing and describing experimental results.Interpretability experiments proposed by MAIA compose these tools to describeand explain system behavior. We evaluate applications of MAIA to computervision models. We first characterize MAIAs ability to describe neuron-levelfeatures in learned representations of images. Across several trained modelsand a novel dataset of synthetic vision neurons with paired ground-truthdescriptions MAIA produces descriptions comparable to those generated byexpert human experimenters. We then show that MAIA can aid in two additionalinterpretability tasks: reducing sensitivity to spurious features andautomatically identifying inputs likely to be mis-classified.</p>
                <p>Last Updated: 2024-04-22 17:55:11 UTC</p>
                <button class="interpret-button" data-id="2404.14394v1">Interpret</button>
                <div id="interpretation-2404.14394v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Survey on Self-Evolution of Large Language Models</h3>
                <p>Authors: Zhengwei TaoTing-En LinXiancai ChenHangyu LiYuchuan WuYongbin LiZhi JinFei HuangDacheng TaoJingren Zhou</p>
                <p><a href="http://arxiv.org/abs/2404.14387v1">Link to paper</a></p>
                <p>Large language models LLMs have significantly advanced in various fieldsand intelligent agent applications. However current LLMs that learn from humanor external model supervision are costly and may face performance ceilings astask complexity and diversity increase. To address this issue self-evolutionapproaches that enable LLM to autonomously acquire refine and learn fromexperiences generated by the model itself are rapidly growing. This newtraining paradigm inspired by the human experiential learning process offersthe potential to scale LLMs towards superintelligence. In this work we presenta comprehensive survey of self-evolution approaches in LLMs. We first propose aconceptual framework for self-evolution and outline the evolving process asiterative cycles composed of four phases: experience acquisition experiencerefinement updating and evaluation. Second we categorize the evolutionobjectives of LLMs and LLM-based agents then we summarize the literature andprovide taxonomy and insights for each module. Lastly we pinpoint existingchallenges and propose future directions to improve self-evolution frameworksequipping researchers with critical insights to fast-track the development ofself-evolving LLMs.</p>
                <p>Last Updated: 2024-04-22 17:43:23 UTC</p>
                <button class="interpret-button" data-id="2404.14387v1">Interpret</button>
                <div id="interpretation-2404.14387v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>AutoAD III: The Prequel -- Back to the Pixels</h3>
                <p>Authors: Tengda HanMax BainArsha NagraniGül VarolWeidi XieAndrew Zisserman</p>
                <p><a href="http://arxiv.org/abs/2404.14412v1">Link to paper</a></p>
                <p>Generating Audio Description AD for movies is a challenging task thatrequires fine-grained visual understanding and an awareness of the charactersand their names. Currently visual language models for AD generation arelimited by a lack of suitable training data and also their evaluation ishampered by using performance measures not specialized to the AD domain. Inthis paper we make three contributions: i We propose two approaches forconstructing AD datasets with aligned video data and build training andevaluation datasets using these. These datasets will be publicly released iiWe develop a Q-former-based architecture which ingests raw video and generatesAD using frozen pre-trained visual encoders and large language models andiii We provide new evaluation metrics to benchmark AD quality that arewell-matched to human performance. Taken together we improve the state of theart on AD generation.</p>
                <p>Last Updated: 2024-04-22 17:59:57 UTC</p>
                <button class="interpret-button" data-id="2404.14412v1">Interpret</button>
                <div id="interpretation-2404.14412v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Guess The Unseen: Dynamic 3D Scene Reconstruction from Partial 2D Glimpses</h3>
                <p>Authors: Inhee LeeByungjun KimHanbyul Joo</p>
                <p><a href="http://arxiv.org/abs/2404.14410v1">Link to paper</a></p>
                <p>In this paper we present a method to reconstruct the world and multipledynamic humans in 3D from a monocular video input. As a key idea we representboth the world and multiple humans via the recently emerging 3D GaussianSplatting 3D-GS representation enabling to conveniently and efficientlycompose and render them together. In particular we address the scenarios withseverely limited and sparse observations in 3D human reconstruction a commonchallenge encountered in the real world. To tackle this challenge we introducea novel approach to optimize the 3D-GS representation in a canonical space byfusing the sparse cues in the common space where we leverage a pre-trained 2Ddiffusion model to synthesize unseen views while keeping the consistency withthe observed 2D appearances. We demonstrate our method can reconstructhigh-quality animatable 3D humans in various challenging examples in thepresence of occlusion image crops few-shot and extremely sparseobservations. After reconstruction our method is capable of not only renderingthe scene in any novel views at arbitrary time instances but also editing the3D scene by removing individual humans or applying different motions for eachhuman. Through various experiments we demonstrate the quality and efficiencyof our methods over alternative existing approaches.</p>
                <p>Last Updated: 2024-04-22 17:59:50 UTC</p>
                <button class="interpret-button" data-id="2404.14410v1">Interpret</button>
                <div id="interpretation-2404.14410v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>CrossScore: Towards Multi-View Image Evaluation and Scoring</h3>
                <p>Authors: Zirui WangWenjing BianOmkar ParkhiYuheng RenVictor Adrian Prisacariu</p>
                <p><a href="http://arxiv.org/abs/2404.14409v1">Link to paper</a></p>
                <p>We introduce a novel cross-reference image quality assessment method thateffectively fills the gap in the image assessment landscape complementing thearray of established evaluation schemes -- ranging from full-reference metricslike SSIM no-reference metrics such as NIQE to general-reference metricsincluding FID and Multi-modal-reference metrics e.g. CLIPScore. Utilising aneural network with the cross-attention mechanism and a unique data collectionpipeline from NVS optimisation our method enables accurate image qualityassessment without requiring ground truth references. By comparing a queryimage against multiple views of the same scene our method addresses thelimitations of existing metrics in novel view synthesis NVS and similar taskswhere direct reference images are unavailable. Experimental results show thatour method is closely correlated to the full-reference metric SSIM while notrequiring ground truth references.</p>
                <p>Last Updated: 2024-04-22 17:59:36 UTC</p>
                <button class="interpret-button" data-id="2404.14409v1">Interpret</button>
                <div id="interpretation-2404.14409v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Hyp-OC: Hyperbolic One Class Classification for Face Anti-Spoofing</h3>
                <p>Authors: Kartik NarayanVishal M. Patel</p>
                <p><a href="http://arxiv.org/abs/2404.14406v1">Link to paper</a></p>
                <p>Face recognition technology has become an integral part of modern securitysystems and user authentication processes. However these systems arevulnerable to spoofing attacks and can easily be circumvented. Most priorresearch in face anti-spoofing FAS approaches it as a two-classclassification task where models are trained on real samples and known spoofattacks and tested for detection performance on unknown spoof attacks. Howeverin practice FAS should be treated as a one-class classification task wherewhile training one cannot assume any knowledge regarding the spoof samples apriori. In this paper we reformulate the face anti-spoofing task from aone-class perspective and propose a novel hyperbolic one-class classificationframework. To train our network we use a pseudo-negative class sampled fromthe Gaussian distribution with a weighted running mean and propose two novelloss functions: 1 Hyp-PC: Hyperbolic Pairwise Confusion loss and 2 Hyp-CE:Hyperbolic Cross Entropy loss which operate in the hyperbolic space.Additionally we employ Euclidean feature clipping and gradient clipping tostabilize the training in the hyperbolic space. To the best of our knowledgethis is the first work extending hyperbolic embeddings for face anti-spoofingin a one-class manner. With extensive experiments on five benchmark datasets:Rose-Youtu MSU-MFSD CASIA-MFSD Idiap Replay-Attack and OULU-NPU wedemonstrate that our method significantly outperforms the state-of-the-artachieving better spoof detection performance.</p>
                <p>Last Updated: 2024-04-22 17:59:18 UTC</p>
                <button class="interpret-button" data-id="2404.14406v1">Interpret</button>
                <div id="interpretation-2404.14406v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>GeoDiffuser: Geometry-Based Image Editing with Diffusion Models</h3>
                <p>Authors: Rahul SajnaniJeroen VanbaarJie MinKapil KatyalSrinath Sridhar</p>
                <p><a href="http://arxiv.org/abs/2404.14403v1">Link to paper</a></p>
                <p>The success of image generative models has enabled us to build methods thatcan edit images based on text or other user input. However these methods arebespoke imprecise require additional information or are limited to only 2Dimage edits. We present GeoDiffuser a zero-shot optimization-based method thatunifies common 2D and 3D image-based object editing capabilities into a singlemethod. Our key insight is to view image editing operations as geometrictransformations. We show that these transformations can be directlyincorporated into the attention layers in diffusion models to implicitlyperform editing operations. Our training-free optimization method uses anobjective function that seeks to preserve object style but generate plausibleimages for instance with accurate lighting and shadows. It also inpaintsdisoccluded parts of the image where the object was originally located. Given anatural image and user input we segment the foreground object using SAM andestimate a corresponding transform which is used by our optimization approachfor editing. GeoDiffuser can perform common 2D and 3D edits like objecttranslation 3D rotation and removal. We present quantitative resultsincluding a perceptual study that shows how our approach is better thanexisting methods. Visit https://ivl.cs.brown.edu/research/geodiffuser.html formore information.</p>
                <p>Last Updated: 2024-04-22 17:58:36 UTC</p>
                <button class="interpret-button" data-id="2404.14403v1">Interpret</button>
                <div id="interpretation-2404.14403v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>SpaceByte: Towards Deleting Tokenization from Large Language Modeling</h3>
                <p>Authors: Kevin Slagle</p>
                <p><a href="http://arxiv.org/abs/2404.14408v1">Link to paper</a></p>
                <p>Tokenization is widely used in large language models because it significantlyimproves performance. However tokenization imposes several disadvantages suchas performance biases increased adversarial vulnerability decreasedcharacter-level modeling performance and increased modeling complexity. Toaddress these disadvantages without sacrificing performance we proposeSpaceByte a novel byte-level decoder architecture that closes the performancegap between byte-level and subword autoregressive language modeling. SpaceByteconsists of a byte-level Transformer model but with extra larger transformerblocks inserted in the middle of the layers. We find that performance issignificantly improved by applying these larger blocks only after certainbytes such as space characters which typically denote word boundaries. Ourexperiments show that for a fixed training and inference compute budgetSpaceByte outperforms other byte-level architectures and roughly matches theperformance of tokenized Transformer architectures.</p>
                <p>Last Updated: 2024-04-22 17:59:29 UTC</p>
                <button class="interpret-button" data-id="2404.14408v1">Interpret</button>
                <div id="interpretation-2404.14408v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A mean curvature flow arising in adversarial training</h3>
                <p>Authors: Leon BungertTim LauxKerrek Stinson</p>
                <p><a href="http://arxiv.org/abs/2404.14402v1">Link to paper</a></p>
                <p>We connect adversarial training for binary classification to a geometricevolution equation for the decision boundary. Relying on a perspective thatrecasts adversarial training as a regularization problem we introduce amodified training scheme that constitutes a minimizing movements scheme for anonlocal perimeter functional. We prove that the scheme is monotone andconsistent as the adversarial budget vanishes and the perimeter localizes andas a consequence we rigorously show that the scheme approximates a weightedmean curvature flow. This highlights that the efficacy of adversarial trainingmay be due to locally minimizing the length of the decision boundary. In ouranalysis we introduce a variety of tools for working with the subdifferentialof a supremal-type nonlocal total variation and its regularity properties.</p>
                <p>Last Updated: 2024-04-22 17:58:36 UTC</p>
                <button class="interpret-button" data-id="2404.14402v1">Interpret</button>
                <div id="interpretation-2404.14402v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?</h3>
                <p>Authors: Adrian de WynterIshaan WattsNektar Ege AltıntoprakTua WongsangaroonsriMinghui ZhangNoura FarraLena BaurSamantha ClaudetPavel GajdusekCan GörenQilong GuAnna KaminskaTomasz KaminskiRuby KuoAkiko KyubaJongho LeeKartik MathurPetter MerokIvana MilovanovićNani PaananenVesa-Matti PaananenAnna PavlenkoBruno Pereira VidalLuciano StrikaYueh TsaoDavide TurcatoOleksandr VakhnoJudit VelcsovAnna VickersStéphanie VisserHerdyan WidarmantoAndrey ZaikinSi-Qing Chen</p>
                <p><a href="http://arxiv.org/abs/2404.14397v1">Link to paper</a></p>
                <p>Large language models LLMs and small language models SLMs are beingadopted at remarkable speed although their safety still remains a seriousconcern. With the advent of multilingual S/LLMs the question now becomes amatter of scale: can we expand multilingual safety evaluations of these modelswith the same velocity at which they are deployed To this end we introduceRTP-LX a human-transcreated and human-annotated corpus of toxic prompts andoutputs in 28 languages. RTP-LX follows participatory design practices and aportion of the corpus is especially designed to detect culturally-specifictoxic language. We evaluate seven S/LLMs on their ability to detect toxiccontent in a culturally-sensitive multilingual scenario. We find thatalthough they typically score acceptably in terms of accuracy they have lowagreement with human judges when judging holistically the toxicity of a promptand have difficulty discerning harm in context-dependent scenariosparticularly with subtle-yet-harmful content e.g. microagressions bias. Werelease of this dataset to contribute to further reduce harmful uses of thesemodels and improve their safe deployment.</p>
                <p>Last Updated: 2024-04-22 17:56:26 UTC</p>
                <button class="interpret-button" data-id="2404.14397v1">Interpret</button>
                <div id="interpretation-2404.14397v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>PARAMANU-GANITA: Language Model with Mathematical Capabilities</h3>
                <p>Authors: Mitodru NiyogiArnab Bhattacharya</p>
                <p><a href="http://arxiv.org/abs/2404.14395v1">Link to paper</a></p>
                <p>In this paper we present Paramanu-Ganita a 208 million parameter novel AutoRegressive AR decoder based language model on mathematics. The model ispretrained from scratch at context size of 4096 on our curated mixedmathematical corpus. We evaluate our model on both perplexity metric and GSM8kmathematical benchmark. Paramanu-Ganita despite being 35 times smaller than 7BLLMs outperformed generalist LLMs such as LLaMa-1 7B by 28.4 points LLaMa-27B by 27.6 points Falcon 7B by 32.6 points PaLM 8B by 35.3 points andmath specialised LLMs such as Minerva 8B by 23.2 points and LLEMMA-7B by 3.0points in GSM8k test accuracy metric respectively. Paramanu-Ganita alsooutperformed giant LLMs like PaLM 62B by 6.4 points Falcon 40B by 19.8points LLaMa-1 33B by 3.8 points and Vicuna 13B by 11.8 points respectively.The large significant margin improvement in performance of our math model overthe existing LLMs signifies that reasoning capabilities of language model arejust not restricted to LLMs with humongous number of parameters.Paramanu-Ganita took 146 hours of A100 training whereas math specialised LLMLLEMMA 7B was trained for 23000 A100 hours of training equivalent. Thus ourapproach of pretraining powerful domain specialised language models fromscratch for domain adaptation is much more cost-effective than performingcontinual training of LLMs for domain adaptation. Hence we conclude that forstrong mathematical reasoning abilities of language model we do not need giantLLMs and immense computing power to our end. In the end we want to point outthat we have only trained Paramanu-Ganita only on a part of our entiremathematical corpus and yet to explore the full potential of our model.</p>
                <p>Last Updated: 2024-04-22 17:55:56 UTC</p>
                <button class="interpret-button" data-id="2404.14395v1">Interpret</button>
                <div id="interpretation-2404.14395v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Poisoning Attacks on Federated Learning-based Wireless Traffic Prediction</h3>
                <p>Authors: Zifan ZhangMinghong FangJiayuan HuangYuchen Liu</p>
                <p><a href="http://arxiv.org/abs/2404.14389v1">Link to paper</a></p>
                <p>Federated Learning FL offers a distributed framework to train a globalcontrol model across multiple base stations without compromising the privacy oftheir local network data. This makes it ideal for applications like wirelesstraffic prediction WTP which plays a crucial role in optimizing networkresources enabling proactive traffic flow management and enhancing thereliability of downstream communication-aided applications such as IoTdevices autonomous vehicles and industrial automation systems. Despite itspromise the security aspects of FL-based distributed wireless systemsparticularly in regression-based WTP problems remain inadequatelyinvestigated. In this paper we introduce a novel fake traffic injection FTIattack designed to undermine the FL-based WTP system by injecting fabricatedtraffic distributions with minimal knowledge. We further propose a defensemechanism termed global-local inconsistency detection GLID whichstrategically removes abnormal model parameters that deviate beyond a specificpercentile range estimated through statistical methods in each dimension.Extensive experimental evaluations performed on real-world wireless trafficdatasets demonstrate that both our attack and defense strategies significantlyoutperform existing baselines.</p>
                <p>Last Updated: 2024-04-22 17:50:27 UTC</p>
                <button class="interpret-button" data-id="2404.14389v1">Interpret</button>
                <div id="interpretation-2404.14389v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>STROOBnet Optimization via GPU-Accelerated Proximal Recurrence Strategies</h3>
                <p>Authors: Ted Edward HolmbergMahdi AbdelguerfiElias Ioup</p>
                <p><a href="http://dx.doi.org/10.1109/BigData59044.2023.10386774">Link to paper</a></p>
                <p>Spatiotemporal networks observational capabilities are crucial for accuratedata gathering and informed decisions across multiple sectors. This studyfocuses on the Spatiotemporal Ranged Observer-Observable Bipartite NetworkSTROOBnet linking observational nodes e.g. surveillance cameras to eventswithin defined geographical regions enabling efficient monitoring. Using datafrom Real-Time Crime Camera RTCC systems and Calls for Service CFS in NewOrleans where RTCC combats rising crime amidst reduced police presence weaddress the networks initial observational imbalances. Aiming for uniformobservational efficacy we propose the Proximal Recurrence approach. Itoutperformed traditional clustering methods like k-means and DBSCAN by offeringholistic event frequency and spatial consideration enhancing observationalcoverage.</p>
                <p>Last Updated: 2024-04-22 17:46:29 UTC</p>
                <button class="interpret-button" data-id="2404.14388v1">Interpret</button>
                <div id="interpretation-2404.14388v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Stochastic Geo-spatiotemporal Bipartite Network to Optimize GCOOS Sensor Placement Strategies</h3>
                <p>Authors: Ted Edward HolmbergElias IoupMahdi Abdelguerfi</p>
                <p><a href="http://dx.doi.org/10.1109/BigData55660.2022.10020928">Link to paper</a></p>
                <p>This paper proposes two new measures applicable in a spatial bipartitenetwork model: coverage and coverage robustness. The bipartite network mustconsist of observer nodes observable nodes and edges that connect observernodes to observable nodes. The coverage and coverage robustness scores evaluatethe effectiveness of the observer node placements. This measure is beneficialfor stochastic data as it may be coupled with Monte Carlo simulations toidentify optimal placements for new observer nodes. In this paper we constructa Geo-SpatioTemporal Bipartite Network GSTBN within the stochastic anddynamical environment of the Gulf of Mexico. This GSTBN consists of GCOOSsensor nodes and HYCOM Region of Interest RoI event nodes. The goal is toidentify optimal placements to expand GCOOS to improve the forecasting outcomesby the HYCOM ocean prediction model.</p>
                <p>Last Updated: 2024-04-22 17:12:06 UTC</p>
                <button class="interpret-button" data-id="2404.14357v1">Interpret</button>
                <div id="interpretation-2404.14357v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Liquid-Graph Time-Constant Network for Multi-Agent Systems Control</h3>
                <p>Authors: Antonio MarinoClaudio PacchierottiPaolo Robuffo Giordano</p>
                <p><a href="http://arxiv.org/abs/2404.13982v1">Link to paper</a></p>
                <p>In this paper we propose the Liquid-Graph Time-constant LGTC network acontinuous graph neural networkGNN model for control of multi-agent systemsbased on therecent Liquid Time Constant LTC network. We analyse itsstabilityleveraging contraction analysis and propose a closed-form model that preservesthe model contraction rate and doesnot require solving an ODE at eachiteration. Compared todiscrete models like Graph Gated Neural NetworksGGNNsthe higher expressivity of the proposed model guaranteesremarkableperformance while reducing the large amountof communicated variables normallyrequired by GNNs. Weevaluate our model on a distributed multi-agent controlcasestudy flocking taking into account variable communicationrange andscalability under non-instantaneous communication</p>
                <p>Last Updated: 2024-04-22 08:44:07 UTC</p>
                <button class="interpret-button" data-id="2404.13982v1">Interpret</button>
                <div id="interpretation-2404.13982v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A survey of air combat behavior modeling using machine learning</h3>
                <p>Authors: Patrick Ribu GortonAndreas StrandKarsten Brathen</p>
                <p><a href="http://arxiv.org/abs/2404.13954v1">Link to paper</a></p>
                <p>With the recent advances in machine learning creating agents that behaverealistically in simulated air combat has become a growing field of interest.This survey explores the application of machine learning techniques formodeling air combat behavior motivated by the potential to enhancesimulation-based pilot training. Current simulated entities tend to lackrealistic behavior and traditional behavior modeling is labor-intensive andprone to loss of essential domain knowledge between development steps.Advancements in reinforcement learning and imitation learning algorithms havedemonstrated that agents may learn complex behavior from data which could befaster and more scalable than manual methods. Yet making adaptive agentscapable of performing tactical maneuvers and operating weapons and sensorsstill poses a significant challenge. The survey examines applications behaviormodel types prevalent machine learning methods and the technical and humanchallenges in developing adaptive and realistically behaving agents. Anotherchallenge is the transfer of agents from learning environments to militarysimulation systems and the consequent demand for standardization. Four primaryrecommendations are presented regarding increased emphasis onbeyond-visual-range scenarios multi-agent machine learning and cooperationutilization of hierarchical behavior models and initiatives forstandardization and research collaboration. These recommendations aim toaddress current issues and guide the development of more comprehensiveadaptable and realistic machine learning-based behavior models for air combatapplications.</p>
                <p>Last Updated: 2024-04-22 07:54:56 UTC</p>
                <button class="interpret-button" data-id="2404.13954v1">Interpret</button>
                <div id="interpretation-2404.13954v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Rate Analysis of Coupled Distributed Stochastic Approximation for Misspecified Optimization</h3>
                <p>Authors: Yaqun YangJinlong Lei</p>
                <p><a href="http://arxiv.org/abs/2404.13669v1">Link to paper</a></p>
                <p>We consider an n agents distributed optimization problem with imperfectinformation characterized in a parametric sense where the unknown parametercan be solved by a distinct distributed parameter learning problem. Though eachagent only has access to its local parameter learning and computationalproblem they mean to collaboratively minimize the average of their local costfunctions. To address the special optimization problem we propose a coupleddistributed stochastic approximation algorithm in which every agent updatesthe current beliefs of its unknown parameter and decision variable bystochastic approximation method and then averages the beliefs and decisionvariables of its neighbors over network in consensus protocol. Our interestlies in the convergence analysis of this algorithm. We quantitativelycharacterize the factors that affect the algorithm performance and prove thatthe mean-squared error of the decision variable is bounded bymathcalOfrac1nkmathcalOleftfrac1sqrtn1-rho_wrightfrac1k1.5mathcalObigfrac11-rho_w2bigfrac1k2 where k is the iteration count and 1-rho_w is thespectral gap of the network weighted adjacency matrix. It reveals that thenetwork connectivity characterized by 1-rho_w only influences the highorder of convergence rate while the domain rate still acts the same as thecentralized algorithm. In addition we analyze that the transient iterationneeded for reaching its dominant rate mathcalOfrac1nk ismathcalOfracn1-rho_w2. Numerical experiments are carried out todemonstrate the theoretical results by taking different CPUs as agents whichis more applicable to real-world distributed scenarios.</p>
                <p>Last Updated: 2024-04-21 14:18:49 UTC</p>
                <button class="interpret-button" data-id="2404.13669v1">Interpret</button>
                <div id="interpretation-2404.13669v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Penn & Slavery Project's Augmented Reality Tour: Augmenting a Campus to Reveal a Hidden History</h3>
                <p>Authors: VanJessica GladneyBreanna MooreKathleen Brown</p>
                <p><a href="http://arxiv.org/abs/2404.14379v1">Link to paper</a></p>
                <p>In 2006 and 2016 the University of Pennsylvania denied any ties to slavery.In 2017 a group of undergraduate researchers led by Professor Kathleen Browninvestigated this claim. Initial research focused on 18th century faculty andtrustees who owned slaves revealed deep connections between the universityshistory and the institution of slavery. These findings and discussions amongstthe researchers shaped the Penn and Slavery Projects goal of redefiningcomplicity beyond ownership. Breanna Moores contributions in PSPs secondsemester expanded the projects focus to include generational wealth gaps. In2018 VanJessica Gladney served as the PSPs Public History Fellow and spreadthe project outreach in the greater Philadelphia area. That year the PSP teambegan to design an augmented reality app as a Digital Interruption and anattempt to display the truth about Penns history on its campus. UnfortunatelyPSP faced delays due to COVID 19. Despite setbacks the project persistedengaging with activists and the wider community to confront historicalinjustices and modern inequalities.</p>
                <p>Last Updated: 2024-04-22 17:32:52 UTC</p>
                <button class="interpret-button" data-id="2404.14379v1">Interpret</button>
                <div id="interpretation-2404.14379v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>"I Upload...All Types of Different Things to Say, the World of Blindness Is More Than What They Think It Is": A Study of Blind TikTokers' Identity Work from a Flourishing Perspective</h3>
                <p>Authors: Yao LyuJie CaiBryan DosonoDavis YadavJohn M. Carroll</p>
                <p><a href="http://arxiv.org/abs/2404.14305v1">Link to paper</a></p>
                <p>Identity work in Human-Computer Interaction HCI has focused on themarginalized group to explore designs to support their asset what they have.However little has been explored specifically on the identity work of peoplewith disabilities specifically visual impairments. In this study weinterviewed 45 BlindTokers blind users on TikTok from various backgrounds tounderstand their identity work from a positive design perspective. We foundthat BlindTokers leverage the affordance of the platform to create positivecontent share their identities and build the community with the desire toflourish. We proposed flourishing labor to present the work conducted byBlindTokers for their communitys flourishing with implications to support theflourishing labor. This work contributes to understanding blind usersexperience in short video platforms and highlights that flourishing is not justan activity for any single Blind user but also a job that needs allstakeholders including all user groups and the TikTok platform serious andcommitted contribution.</p>
                <p>Last Updated: 2024-04-22 16:03:44 UTC</p>
                <button class="interpret-button" data-id="2404.14305v1">Interpret</button>
                <div id="interpretation-2404.14305v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Shifting Focus with HCEye: Exploring the Dynamics of Visual Highlighting and Cognitive Load on User Attention and Saliency Prediction</h3>
                <p>Authors: Anwesha DasZekun WuIza ŠkrjanecAnna Maria Feit</p>
                <p><a href="http://dx.doi.org/10.1145/3655610">Link to paper</a></p>
                <p>Visual highlighting can guide user attention in complex interfaces. Howeverits effectiveness under limited attentional capacities is underexplored. Thispaper examines the joint impact of visual highlighting permanent and dynamicand dual-task-induced cognitive load on gaze behaviour. Our analysis usingeye-movement data from 27 participants viewing 150 unique webpages reveals thatwhile participants ability to attend to UI elements decreases with increasingcognitive load dynamic adaptations i.e. highlighting remainattention-grabbing. The presence of these factors significantly alters whatpeople attend to and thus what is salient. Accordingly we show thatstate-of-the-art saliency models increase their performance when accounting fordifferent cognitive loads. Our empirical insights along with our openlyavailable dataset enhance our understanding of attentional processes in UIsunder varying cognitive and perceptual loads and open the door for new modelsthat can predict user attention while multitasking.</p>
                <p>Last Updated: 2024-04-22 14:45:30 UTC</p>
                <button class="interpret-button" data-id="2404.14232v1">Interpret</button>
                <div id="interpretation-2404.14232v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Resistance Against Manipulative AI: key factors and possible actions</h3>
                <p>Authors: Piotr WilczyńskiWiktoria Mieleszczenko-KowszewiczPrzemysław Biecek</p>
                <p><a href="http://arxiv.org/abs/2404.14230v1">Link to paper</a></p>
                <p>If AI is the new electricity what should we do to keep ourselves fromgetting electrocuted In this work we explore factors related to the potentialof large language models LLMs to manipulate human decisions. We describe theresults of two experiments designed to determine what characteristics of humansare associated with their susceptibility to LLM manipulation and whatcharacteristics of LLMs are associated with their manipulativeness potential.We explore human factors by conducting user studies in which participantsanswer general knowledge questions using LLM-generated hints whereas LLMfactors by provoking language models to create manipulative statements. Thenwe analyze their obedience the persuasion strategies used and the choice ofvocabulary. Based on these experiments we discuss two actions that can protectus from LLM manipulation. In the long term we put AI literacy at theforefront arguing that educating society would minimize the risk ofmanipulation and its consequences. We also propose an ad hoc solution aclassifier that detects manipulation of LLMs - a Manipulation Fuse.</p>
                <p>Last Updated: 2024-04-22 14:41:39 UTC</p>
                <button class="interpret-button" data-id="2404.14230v1">Interpret</button>
                <div id="interpretation-2404.14230v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>An Artificial Neuron for Enhanced Problem Solving in Large Language Models</h3>
                <p>Authors: Sumedh Rasal</p>
                <p><a href="http://arxiv.org/abs/2404.14222v1">Link to paper</a></p>
                <p>Recent advancements in artificial intelligence have propelled thecapabilities of Large Language Models yet their ability to mimic nuanced humanreasoning remains limited. This paper introduces a novel conceptual enhancementto LLMs termed the Artificial Neuron designed to significantly bolstercognitive processing by integrating external memory systems. This enhancementmimics neurobiological processes facilitating advanced reasoning and learningthrough a dynamic feedback loop mechanism. We propose a unique frameworkwherein each LLM interaction specifically in solving complex math word problemsand common sense reasoning tasks is recorded and analyzed. Incorrect responsesare refined using a higher capacity LLM or human in the loop corrections andboth the query and the enhanced response are stored in a vector databasestructured much like neuronal synaptic connections. This Artificial Neuron thusserves as an external memory aid allowing the LLM to reference pastinteractions and apply learned reasoning strategies to new problems. Ourexperimental setup involves training with the GSM8K dataset for initial modelresponse generation followed by systematic refinements through feedback loops.Subsequent testing demonstrated a significant improvement in accuracy andefficiency underscoring the potential of external memory systems to advanceLLMs beyond current limitations. This approach not only enhances the LLMsproblem solving precision but also reduces computational redundancy paving theway for more sophisticated applications of artificial intelligence in cognitivetasks. This paper details the methodology implementation and implications ofthe Artificial Neuron model offering a transformative perspective on enhancingmachine intelligence.</p>
                <p>Last Updated: 2024-04-22 14:33:16 UTC</p>
                <button class="interpret-button" data-id="2404.14222v1">Interpret</button>
                <div id="interpretation-2404.14222v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-04-23</p>
        </div>
    
        </div>
    </body>
    </html>
    