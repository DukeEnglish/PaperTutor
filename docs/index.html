
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>Design and Realization of a Benchmarking Testbed for Evaluating Autonomous Platooning Algorithms</h3>
                <p>Authors: Michael ShahamRisha RanjanEngin KirdaTaskin Padir</p>
                <p><a href="http://arxiv.org/abs/2402.09233v1">Link to paper</a></p>
                <p>Autonomous vehicle platoons present near- and long-term opportunities toenhance operational efficiencies and save lives. The past 30 years have seenrapid development in the autonomous driving space enabling new technologiesthat will alleviate the strain placed on human drivers and reduce vehicleemissions. This paper introduces a testbed for evaluating and benchmarkingplatooning algorithms on 1/10th scale vehicles with onboard sensors. Todemonstrate the testbeds utility we evaluate three algorithms linearfeedback and two variations of distributed model predictive control andcompare their results on a typical platooning scenario where the lead vehicletracks a reference trajectory that changes speed multiple times. We validateour algorithms in simulation to analyze the performance as the platoon sizeincreases and find that the distributed model predictive control algorithmsoutperform linear feedback on hardware and in simulation.</p>
                <p>Last Updated: 2024-02-14 15:22:24 UTC</p>
                <button class="interpret-button" data-id="2402.09233v1">Interpret</button>
                <div id="interpretation-2402.09233v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Time preference, wealth and utility inequality: A microeconomic interaction and dynamic macroeconomic model connection approach</h3>
                <p>Authors: Takeshi Kato</p>
                <p><a href="http://arxiv.org/abs/2402.08905v1">Link to paper</a></p>
                <p>Based on interactions between individuals and others and references to socialnorms this study reveals the impact of heterogeneity in time preference onwealth distribution and inequality. We present a novel approach that connectsthe interactions between microeconomic agents that generate heterogeneity tothe dynamic equations for capital and consumption in macroeconomic models.Using this approach we estimate the impact of changes in the discount rate dueto microeconomic interactions on capital consumption and utility and thedegree of inequality. The results show that intercomparisons with othersregarding consumption significantly affect capital i.e. wealth inequality.Furthermore the impact on utility is never small and social norms can reducethis impact. Our supporting evidence shows that the quantitative results ofinequality calculations correspond to survey data from cohort andcross-cultural studies. This studys micro-macro connection approach can bedeployed to connect microeconomic interactions such as exchange interest anddebt redistribution mutual aid and time preference to dynamic macroeconomicmodels.</p>
                <p>Last Updated: 2024-02-14 02:41:36 UTC</p>
                <button class="interpret-button" data-id="2402.08905v1">Interpret</button>
                <div id="interpretation-2402.08905v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Auto-Encoding Bayesian Inverse Games</h3>
                <p>Authors: Xinjie LiuLasse PetersJavier Alonso-MoraUfuk TopcuDavid Fridovich-Keil</p>
                <p><a href="http://arxiv.org/abs/2402.08902v1">Link to paper</a></p>
                <p>When multiple agents interact in a common environment each agents actionsimpact others future decisions and noncooperative dynamic games naturallycapture this coupling. In interactive motion planning however agentstypically do not have access to a complete model of the game e.g. due tounknown objectives of other players. Therefore we consider the inverse gameproblem in which some properties of the game are unknown a priori and must beinferred from observations. Existing maximum likelihood estimation MLEapproaches to solve inverse games provide only point estimates of unknownparameters without quantifying uncertainty and perform poorly when manyparameter values explain the observed behavior. To address these limitationswe take a Bayesian perspective and construct posterior distributions of gameparameters. To render inference tractable we employ a variational autoencoderVAE with an embedded differentiable game solver. This structured VAE can betrained from an unlabeled dataset of observed interactions naturally handlescontinuous multi-modal distributions and supports efficient sampling from theinferred posteriors without computing game solutions at runtime. Extensiveevaluations in simulated driving scenarios demonstrate that the proposedapproach successfully learns the prior and posterior objective distributionsprovides more accurate objective estimates than MLE baselines and facilitatessafer and more efficient game-theoretic motion planning.</p>
                <p>Last Updated: 2024-02-14 02:17:37 UTC</p>
                <button class="interpret-button" data-id="2402.08902v1">Interpret</button>
                <div id="interpretation-2402.08902v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Strategic Contract Negotiation in Financial Networks</h3>
                <p>Authors: Akhil JalanDeepayan Chakrabarti</p>
                <p><a href="http://arxiv.org/abs/2402.08779v1">Link to paper</a></p>
                <p>How can firms optimally negotiate bilateral contracts with each other in afinancial network Every firm seeks to maximize the utility it gains from itsportfolio of contracts. We focus on mean-variance utilities where each firmhas its own beliefs about the expected returns of the contracts and thecovariances between them Markowitz J. Finance 711 1952. Instead ofrevealing these beliefs a firm may adopt a different negotiating positionseeking better contract terms. We formulate a contract negotiation process bywhich such strategic behavior leads to a network of contracts. In ourformulation any subset of firms can be strategic. The negotiating positions ofthese firms can form Nash equilibria where each firms position is optimalgiven the others positions.  We give a polynomial-time algorithm to find the Nash equilibria if theyexist and certify their nonexistence otherwise. We explore the implications ofsuch equilibria on several model networks. These illustrate that firmsutilities can be sensitive to their negotiating position. We then propose tradedeadlines as a mechanism to reduce the need for strategic behavior. At thedeadline each firm can unilaterally cancel some or all of its contracts for apenalty. In our model networks we show that trade deadlines can reduce theloss of utility from being honest. We empirically verify our insights usingdata on international trade between 46 large economies.</p>
                <p>Last Updated: 2024-02-13 20:23:19 UTC</p>
                <button class="interpret-button" data-id="2402.08779v1">Interpret</button>
                <div id="interpretation-2402.08779v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Optimal Task Assignment and Path Planning using Conflict-Based Search with Precedence and Temporal Constraints</h3>
                <p>Authors: Yu Quan ChongJiaoyang LiKatia Sycara</p>
                <p><a href="http://arxiv.org/abs/2402.08772v1">Link to paper</a></p>
                <p>The Multi-Agent Path Finding MAPF problem entails finding collision-freepaths for a set of agents guiding them from their start to goal locations.However MAPF does not account for several practical task-related constraints.For example agents may need to perform actions at goal locations with specificexecution times adhering to predetermined orders and timeframes. Moreovergoal assignments may not be predefined for agents and the optimizationobjective may lack an explicit definition. To incorporate task assignment pathplanning and a user-defined objective into a coherent framework this paperexamines the Task Assignment and Path Finding with Precedence and TemporalConstraints TAPF-PTC problem. We augment Conflict-Based Search CBS tosimultaneously generate task assignments and collision-free paths that adhereto precedence and temporal constraints maximizing an objective quantified bythe return from a user-defined reward function in reinforcement learning RL.Experimentally we demonstrate that our algorithm CBS-TA-PTC can solve highlychallenging bomb-defusing tasks with precedence and temporal constraintsefficiently relative to MARL and adapted Target Assignment and Path FindingTAPF methods.</p>
                <p>Last Updated: 2024-02-13 20:07:58 UTC</p>
                <button class="interpret-button" data-id="2402.08772v1">Interpret</button>
                <div id="interpretation-2402.08772v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability</h3>
                <p>Authors: Siwei YangBingchen ZhaoCihang Xie</p>
                <p><a href="http://arxiv.org/abs/2402.09404v1">Link to paper</a></p>
                <p>This paper introduces AQA-Bench a novel benchmark to assess the sequentialreasoning capabilities of large language models LLMs in algorithmic contextssuch as depth-first search DFS. The key feature of our evaluation benchmarklies in its interactive evaluation protocol -- for example in DFS theavailability of each nodes connected edge is contingent upon the modelstraversal to that node thereby necessitating the LLMs ability to effectivelyremember visited nodes and strategize subsequent moves. We comprehensivelybuild AQA-Bench with three different algorithms namely binary searchdepth-first search and breadth-first search and to evaluate the sequentialreasoning ability of 12 different LLMs. Our investigations reveal severalinteresting findings: 1 Closed-source models like GPT-4 and Gemini generallyshow strong sequential reasoning ability significantly outperformingopen-source LLMs. 2 Naively providing interactive examples may inadvertentlyhurt few-shot performance. 3 A very limited number of predecessor stepsfollowing the optimal policy can substantially boost small models performance.4 The scaling correlation between performance and model size is not alwayssignificant sometimes even showcasing an inverse trend. We hope our study cancatalyze future work on advancing the understanding and enhancement of LLMscapabilities in sequential reasoning. The code is available athttps://github.com/UCSC-VLAA/AQA-Bench.</p>
                <p>Last Updated: 2024-02-14 18:59:33 UTC</p>
                <button class="interpret-button" data-id="2402.09404v1">Interpret</button>
                <div id="interpretation-2402.09404v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Reinforcement Learning from Human Feedback with Active Queries</h3>
                <p>Authors: Kaixuan JiJiafan HeQuanquan Gu</p>
                <p><a href="http://arxiv.org/abs/2402.09401v1">Link to paper</a></p>
                <p>Aligning large language models LLM with human preference plays a key rolein building modern generative models and can be achieved by reinforcementlearning from human feedback RLHF. Despite their superior performancecurrent RLHF approaches often require a large amount of human-labelledpreference data which is expensive to collect. In this paper inspired by thesuccess of active learning we address this problem by proposingquery-efficient RLHF methods. We first formalize the alignment problem as acontextual dueling bandit problem and design an active-query-based proximalpolicy optimization APPO algorithm with an tildeOd2/Delta regretbound and an tildeOd2/Delta2 query complexity where d is thedimension of feature space and Delta is the sub-optimality gap over all thecontexts. We then propose ADPO a practical version of our algorithm based ondirect preference optimization DPO and apply it to fine-tuning LLMs. Ourexperiments show that ADPO while only making about half of queries for humanpreference matches the performance of the state-of-the-art DPO method.</p>
                <p>Last Updated: 2024-02-14 18:58:40 UTC</p>
                <button class="interpret-button" data-id="2402.09401v1">Interpret</button>
                <div id="interpretation-2402.09401v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference</h3>
                <p>Authors: Harry DongXinyu YangZhenyu ZhangZhangyang WangYuejie ChiBeidi Chen</p>
                <p><a href="http://arxiv.org/abs/2402.09398v1">Link to paper</a></p>
                <p>Many computational factors limit broader deployment of large language models.In this paper we focus on a memory bottleneck imposed by the key-value KVcache a computational shortcut that requires storing previous KV pairs duringdecoding. While existing KV cache methods approach this problem by pruning orevicting large swaths of relatively less important KV pairs to dramaticallyreduce the memory footprint of the cache they can have limited success intasks that require recollecting a majority of previous tokens. To alleviatethis issue we propose LESS a simple integration of a nearly free constantsized cache with eviction-based cache methods such that all tokens can bequeried at later decoding steps. Its ability to retain information throughouttime shows merit on a variety of tasks where we demonstrate LESS can helpreduce the performance gap from caching everything sometimes even matching itall while being efficient.</p>
                <p>Last Updated: 2024-02-14 18:54:56 UTC</p>
                <button class="interpret-button" data-id="2402.09398v1">Interpret</button>
                <div id="interpretation-2402.09398v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LL-GABR: Energy Efficient Live Video Streaming Using Reinforcement Learning</h3>
                <p>Authors: Adithya RamanBekir TurkkanTevfik Kosar</p>
                <p><a href="http://arxiv.org/abs/2402.09392v1">Link to paper</a></p>
                <p>Over the recent years research and development in adaptive bitrate ABRalgorithms for live video streaming have been successful in improving usersquality of experience QoE by reducing latency to near real-time levels whiledelivering higher bitrate videos with minimal rebuffering time. However theQoE models used by these ABR algorithms do not take into account that a largeportion of live video streaming clients use mobile devices where a higherbitrate does not necessarily translate into higher perceived quality. Ignoringperceived quality results in playing videos at higher bitrates without asignificant increase in perceptual video quality and becomes a burden forbattery-constrained mobile devices due to higher energy consumption. In thispaper we propose LL-GABR a deep reinforcement learning approach that modelsthe QoE using perceived video quality instead of bitrate and uses energyconsumption along with other metrics like latency rebuffering events andsmoothness. LL-GABR makes no assumptions about the underlying videoenvironment or network settings and can operate flexibly on different videotitles each having a different bitrate encoding ladder without additionalre-training unlike existing learning-based ABRs. Trace-driven experimentalresults show that LL-GABR outperforms the state-of-the-art approaches by up to44 in terms of perceptual QoE and a 73 increase in energy efficiency as aresult of reducing net energy consumption by 11.</p>
                <p>Last Updated: 2024-02-14 18:43:19 UTC</p>
                <button class="interpret-button" data-id="2402.09392v1">Interpret</button>
                <div id="interpretation-2402.09392v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset</h3>
                <p>Authors: Botao YuFrazier N. BakerZiqi ChenXia NingHuan Sun</p>
                <p><a href="http://arxiv.org/abs/2402.09391v1">Link to paper</a></p>
                <p>Chemistry plays a crucial role in many domains such as drug discovery andmaterial science. While large language models LLMs such as GPT-4 exhibitremarkable capabilities on natural language processing tasks existing workshows their performance on chemistry tasks is discouragingly low. In thispaper however we demonstrate that our developed LLMs can achieve very strongresults on a comprehensive set of chemistry tasks outperforming the mostadvanced GPT-4 across all the tasks by a substantial margin and approaching theSoTA task-specific models. The key to our success is a large-scalecomprehensive high-quality dataset for instruction tuning named SMolInstruct.It contains 14 meticulously selected chemistry tasks and over three millionhigh-quality samples laying a solid foundation for training and evaluatingLLMs for chemistry. Based on SMolInstruct we fine-tune a set of open-sourceLLMs among which we find that Mistral serves as the best base model forchemistry tasks. We further conduct analysis on the impact of trainableparameters providing insights for future research.</p>
                <p>Last Updated: 2024-02-14 18:42:25 UTC</p>
                <button class="interpret-button" data-id="2402.09391v1">Interpret</button>
                <div id="interpretation-2402.09391v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>Reinforcement Learning from Human Feedback with Active Queries</h3>
                <p>Authors: Kaixuan JiJiafan HeQuanquan Gu</p>
                <p><a href="http://arxiv.org/abs/2402.09401v1">Link to paper</a></p>
                <p>Aligning large language models LLM with human preference plays a key rolein building modern generative models and can be achieved by reinforcementlearning from human feedback RLHF. Despite their superior performancecurrent RLHF approaches often require a large amount of human-labelledpreference data which is expensive to collect. In this paper inspired by thesuccess of active learning we address this problem by proposingquery-efficient RLHF methods. We first formalize the alignment problem as acontextual dueling bandit problem and design an active-query-based proximalpolicy optimization APPO algorithm with an tildeOd2/Delta regretbound and an tildeOd2/Delta2 query complexity where d is thedimension of feature space and Delta is the sub-optimality gap over all thecontexts. We then propose ADPO a practical version of our algorithm based ondirect preference optimization DPO and apply it to fine-tuning LLMs. Ourexperiments show that ADPO while only making about half of queries for humanpreference matches the performance of the state-of-the-art DPO method.</p>
                <p>Last Updated: 2024-02-14 18:58:40 UTC</p>
                <button class="interpret-button" data-id="2402.09401v1">Interpret</button>
                <div id="interpretation-2402.09401v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Loss Shaping Constraints for Long-Term Time Series Forecasting</h3>
                <p>Authors: Ignacio HounieJavier Porras-ValenzuelaAlejandro Ribeiro</p>
                <p><a href="http://arxiv.org/abs/2402.09373v1">Link to paper</a></p>
                <p>Several applications in time series forecasting require predicting multiplesteps ahead. Despite the vast amount of literature in the topic both classicaland recent deep learning based approaches have mostly focused on minimisingperformance averaged over the predicted window. We observe that this can leadto disparate distributions of errors across forecasting steps especially forrecent transformer architectures trained on popular forecasting benchmarks.That is optimising performance on average can lead to undesirably large errorsat specific time-steps. In this work we present a Constrained Learningapproach for long-term time series forecasting that aims to find the best modelin terms of average performance that respects a user-defined upper bound on theloss at each time-step. We call our approach loss shaping constraints becauseit imposes constraints on the loss at each time step and leverage recentduality results to show that despite its non-convexity the resulting problemhas a bounded duality gap. We propose a practical Primal-Dual algorithm totackle it and demonstrate that the proposed approach exhibits competitiveaverage performance in time series forecasting benchmarks while shaping thedistribution of errors across the predicted window.</p>
                <p>Last Updated: 2024-02-14 18:20:44 UTC</p>
                <button class="interpret-button" data-id="2402.09373v1">Interpret</button>
                <div id="interpretation-2402.09373v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Connecting Algorithmic Fairness to Quality Dimensions in Machine Learning in Official Statistics and Survey Production</h3>
                <p>Authors: Patrick Oliver SchenkChristoph Kern</p>
                <p><a href="http://arxiv.org/abs/2402.09328v1">Link to paper</a></p>
                <p>National Statistical Organizations NSOs increasingly draw on MachineLearning ML to improve the timeliness and cost-effectiveness of theirproducts. When introducing ML solutions NSOs must ensure that high standardswith respect to robustness reproducibility and accuracy are upheld ascodified e.g. in the Quality Framework for Statistical Algorithms QF4SAYung et al. 2022. At the same time a growing body of research focuses onfairness as a pre-condition of a safe deployment of ML to prevent disparatesocial impacts in practice. However fairness has not yet been explicitlydiscussed as a quality aspect in the context of the application of ML at NSOs.We employ Yung et al. 2022s QF4SA quality framework and present a mapping ofits quality dimensions to algorithmic fairness. We thereby extend the QF4SAframework in several ways: we argue for fairness as its own quality dimensionwe investigate the interaction of fairness with other dimensions and weexplicitly address data both on its own and its interaction with appliedmethodology. In parallel with empirical illustrations we show how our mappingcan contribute to methodology in the domains of official statisticsalgorithmic fairness and trustworthy machine learning.</p>
                <p>Last Updated: 2024-02-14 17:18:03 UTC</p>
                <button class="interpret-button" data-id="2402.09328v1">Interpret</button>
                <div id="interpretation-2402.09328v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Learning Interpretable Concepts: Unifying Causal Representation Learning and Foundation Models</h3>
                <p>Authors: Goutham RajendranSimon BuchholzBryon AragamBernhard SchölkopfPradeep Ravikumar</p>
                <p><a href="http://arxiv.org/abs/2402.09236v1">Link to paper</a></p>
                <p>To build intelligent machine learning systems there are two broadapproaches. One approach is to build inherently interpretable models asendeavored by the growing field of causal representation learning. The otherapproach is to build highly-performant foundation models and then investefforts into understanding how they work. In this work we relate these twoapproaches and study how to learn human-interpretable concepts from data.Weaving together ideas from both fields we formally define a notion ofconcepts and show that they can be provably recovered from diverse data.Experiments on synthetic data and large language models show the utility of ourunified approach.</p>
                <p>Last Updated: 2024-02-14 15:23:59 UTC</p>
                <button class="interpret-button" data-id="2402.09236v1">Interpret</button>
                <div id="interpretation-2402.09236v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Directional Convergence Near Small Initializations and Saddles in Two-Homogeneous Neural Networks</h3>
                <p>Authors: Akshay KumarJarvis Haupt</p>
                <p><a href="http://arxiv.org/abs/2402.09226v1">Link to paper</a></p>
                <p>This paper examines gradient flow dynamics of two-homogeneous neural networksfor small initializations where all weights are initialized near the origin.For both square and logistic losses it is shown that for sufficiently smallinitializations the gradient flow dynamics spend sufficient time in theneighborhood of the origin to allow the weights of the neural network toapproximately converge in direction to the Karush-Kuhn-Tucker KKT points of aneural correlation function that quantifies the correlation between the outputof the neural network and corresponding labels in the training data set. Forsquare loss it has been observed that neural networks undergo saddle-to-saddledynamics when initialized close to the origin. Motivated by this this paperalso shows a similar directional convergence among weights of small magnitudein the neighborhood of certain saddle points.</p>
                <p>Last Updated: 2024-02-14 15:10:37 UTC</p>
                <button class="interpret-button" data-id="2402.09226v1">Interpret</button>
                <div id="interpretation-2402.09226v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability</h3>
                <p>Authors: Siwei YangBingchen ZhaoCihang Xie</p>
                <p><a href="http://arxiv.org/abs/2402.09404v1">Link to paper</a></p>
                <p>This paper introduces AQA-Bench a novel benchmark to assess the sequentialreasoning capabilities of large language models LLMs in algorithmic contextssuch as depth-first search DFS. The key feature of our evaluation benchmarklies in its interactive evaluation protocol -- for example in DFS theavailability of each nodes connected edge is contingent upon the modelstraversal to that node thereby necessitating the LLMs ability to effectivelyremember visited nodes and strategize subsequent moves. We comprehensivelybuild AQA-Bench with three different algorithms namely binary searchdepth-first search and breadth-first search and to evaluate the sequentialreasoning ability of 12 different LLMs. Our investigations reveal severalinteresting findings: 1 Closed-source models like GPT-4 and Gemini generallyshow strong sequential reasoning ability significantly outperformingopen-source LLMs. 2 Naively providing interactive examples may inadvertentlyhurt few-shot performance. 3 A very limited number of predecessor stepsfollowing the optimal policy can substantially boost small models performance.4 The scaling correlation between performance and model size is not alwayssignificant sometimes even showcasing an inverse trend. We hope our study cancatalyze future work on advancing the understanding and enhancement of LLMscapabilities in sequential reasoning. The code is available athttps://github.com/UCSC-VLAA/AQA-Bench.</p>
                <p>Last Updated: 2024-02-14 18:59:33 UTC</p>
                <button class="interpret-button" data-id="2402.09404v1">Interpret</button>
                <div id="interpretation-2402.09404v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Reinforcement Learning from Human Feedback with Active Queries</h3>
                <p>Authors: Kaixuan JiJiafan HeQuanquan Gu</p>
                <p><a href="http://arxiv.org/abs/2402.09401v1">Link to paper</a></p>
                <p>Aligning large language models LLM with human preference plays a key rolein building modern generative models and can be achieved by reinforcementlearning from human feedback RLHF. Despite their superior performancecurrent RLHF approaches often require a large amount of human-labelledpreference data which is expensive to collect. In this paper inspired by thesuccess of active learning we address this problem by proposingquery-efficient RLHF methods. We first formalize the alignment problem as acontextual dueling bandit problem and design an active-query-based proximalpolicy optimization APPO algorithm with an tildeOd2/Delta regretbound and an tildeOd2/Delta2 query complexity where d is thedimension of feature space and Delta is the sub-optimality gap over all thecontexts. We then propose ADPO a practical version of our algorithm based ondirect preference optimization DPO and apply it to fine-tuning LLMs. Ourexperiments show that ADPO while only making about half of queries for humanpreference matches the performance of the state-of-the-art DPO method.</p>
                <p>Last Updated: 2024-02-14 18:58:40 UTC</p>
                <button class="interpret-button" data-id="2402.09401v1">Interpret</button>
                <div id="interpretation-2402.09401v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Long-form evaluation of model editing</h3>
                <p>Authors: Domenic RosatiRobie GonzalesJinkun ChenXuemin YuMelis ErkanYahya KayaniSatya Deepika ChavatapalliFrank RudziczHassan Sajjad</p>
                <p><a href="http://arxiv.org/abs/2402.09394v1">Link to paper</a></p>
                <p>Evaluations of model editing currently only use the next few tokencompletions after a prompt. As a result the impact of these methods on longernatural language generation is largely unknown. We introduce long-formevaluation of model editing textbftextitLEME a novel evaluationprotocol that measures the efficacy and impact of model editing in long-formgenerative settings. Our protocol consists of a machine-rated survey and aclassifier which correlates well with human ratings. Importantly we find thatour protocol has very little relationship with previous short-form metricsdespite being designed to extend efficacy generalization locality andportability into a long-form setting indicating that our method introduces anovel set of dimensions for understanding model editing methods. Using thisprotocol we benchmark a number of model editing techniques and present severalfindings including that while some methods ROME and MEMIT perform well inmaking consistent edits within a limited scope they suffer much more fromfactual drift than other methods. Finally we present a qualitative analysisthat illustrates common failure modes in long-form generative settingsincluding internal consistency lexical cohesion and locality issues.</p>
                <p>Last Updated: 2024-02-14 18:45:14 UTC</p>
                <button class="interpret-button" data-id="2402.09394v1">Interpret</button>
                <div id="interpretation-2402.09394v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset</h3>
                <p>Authors: Botao YuFrazier N. BakerZiqi ChenXia NingHuan Sun</p>
                <p><a href="http://arxiv.org/abs/2402.09391v1">Link to paper</a></p>
                <p>Chemistry plays a crucial role in many domains such as drug discovery andmaterial science. While large language models LLMs such as GPT-4 exhibitremarkable capabilities on natural language processing tasks existing workshows their performance on chemistry tasks is discouragingly low. In thispaper however we demonstrate that our developed LLMs can achieve very strongresults on a comprehensive set of chemistry tasks outperforming the mostadvanced GPT-4 across all the tasks by a substantial margin and approaching theSoTA task-specific models. The key to our success is a large-scalecomprehensive high-quality dataset for instruction tuning named SMolInstruct.It contains 14 meticulously selected chemistry tasks and over three millionhigh-quality samples laying a solid foundation for training and evaluatingLLMs for chemistry. Based on SMolInstruct we fine-tune a set of open-sourceLLMs among which we find that Mistral serves as the best base model forchemistry tasks. We further conduct analysis on the impact of trainableparameters providing insights for future research.</p>
                <p>Last Updated: 2024-02-14 18:42:25 UTC</p>
                <button class="interpret-button" data-id="2402.09391v1">Interpret</button>
                <div id="interpretation-2402.09391v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation</h3>
                <p>Authors: Yihao FangStephen W. ThomasXiaodan Zhu</p>
                <p><a href="http://arxiv.org/abs/2402.09390v1">Link to paper</a></p>
                <p>With the widespread adoption of large language models LLMs in numerousapplications the challenge of factuality and the propensity for hallucinationsraises significant concerns. To address this issue particularly inretrieval-augmented in-context learning we introduce the hierarchical graph ofthoughts HGOT a structured multi-layered graph approach designed to enhancethe retrieval of pertinent passages during in-context learning. The frameworkutilizes the emergent planning capabilities of LLMs employing thedivide-and-conquer strategy to break down complex queries into manageablesub-queries. It refines self-consistency majority voting for answer selectionwhich incorporates the recently proposed citation recall and precision metricsto assess the quality of thoughts linking an answers credibilityintrinsically to the thoughts quality. This methodology introduces a weightedsystem in majority voting prioritizing answers based on the citation qualityof their thoughts. Additionally we propose a scoring mechanism for evaluatingretrieved passages considering factors such as citation frequency and qualityself-consistency confidence and the retrieval modules ranking. Experimentsreveal that HGOT outperforms other retrieval-augmented in-context learningmethods including Demonstrate-Search-Predict DSP ReAct Self-Ask andRetrieve-then-Read on different datasets by as much as 7 demonstrating itsefficacy in enhancing the factuality of LLMs.</p>
                <p>Last Updated: 2024-02-14 18:41:19 UTC</p>
                <button class="interpret-button" data-id="2402.09390v1">Interpret</button>
                <div id="interpretation-2402.09390v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Persuasion, Delegation, and Private Information in Algorithm-Assisted Decisions</h3>
                <p>Authors: Ruqing Xu</p>
                <p><a href="http://arxiv.org/abs/2402.09384v1">Link to paper</a></p>
                <p>A principal designs an algorithm that generates a publicly observableprediction of a binary state. She must decide whether to act directly based onthe prediction or to delegate the decision to an agent with private informationbut potential misalignment. We study the optimal design of the predictionalgorithm and the delegation rule in such environments. Three key findingsemerge: 1 Delegation is optimal if and only if the principal would make thesame binary decision as the agent had she observed the agents information. 2Providing the most informative algorithm may be suboptimal even if theprincipal can act on the algorithms prediction. Instead the optimal algorithmmay provide more information about one state and restrict information about theother. 3 Common restrictions on algorithms such as keeping ahuman-in-the-loop or requiring maximal prediction accuracy strictly worsendecision quality in the absence of perfectly aligned agents and state-revealingsignals. These findings predict the underperformance of human-machinecollaborations if no measures are taken to mitigate common preferencemisalignment between algorithms and human decision-makers.</p>
                <p>Last Updated: 2024-02-14 18:32:30 UTC</p>
                <button class="interpret-button" data-id="2402.09384v1">Interpret</button>
                <div id="interpretation-2402.09384v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>UR2M: Uncertainty and Resource-Aware Event Detection on Microcontrollers</h3>
                <p>Authors: Hong JiaYoung D. KwonDong MaNhat PhamLorena QendroTam VuCecilia Mascolo</p>
                <p><a href="http://arxiv.org/abs/2402.09264v1">Link to paper</a></p>
                <p>Traditional machine learning techniques are prone to generating inaccuratepredictions when confronted with shifts in the distribution of data between thetraining and testing phases. This vulnerability can lead to severeconsequences especially in applications such as mobile healthcare. Uncertaintyestimation has the potential to mitigate this issue by assessing thereliability of a models output. However existing uncertainty estimationtechniques often require substantial computational resources and memory makingthem impractical for implementation on microcontrollers MCUs. This limitationhinders the feasibility of many important on-device wearable event detectionWED applications such as heart attack detection.  In this paper we present UR2M a novel Uncertainty and Resource-aware eventdetection framework for MCUs. Specifically we i develop an uncertainty-awareWED based on evidential theory for accurate event detection and reliableuncertainty estimation ii introduce a cascade ML framework to achieveefficient model inference via early exits by sharing shallower model layersamong different event models iii optimize the deployment of the model andMCU library for system efficiency. We conducted extensive experiments andcompared UR2M to traditional uncertainty baselines using three wearabledatasets. Our results demonstrate that UR2M achieves up to 864 fasterinference speed 857 energy-saving for uncertainty estimation 55 memorysaving on two popular MCUs and a 22 improvement in uncertainty quantificationperformance.  UR2M can be deployed on a wide range of MCUs significantly expandingreal-time and reliable WED applications.</p>
                <p>Last Updated: 2024-02-14 15:51:28 UTC</p>
                <button class="interpret-button" data-id="2402.09264v1">Interpret</button>
                <div id="interpretation-2402.09264v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Evaluating the Experience of LGBTQ+ People Using Large Language Model Based Chatbots for Mental Health Support</h3>
                <p>Authors: Zilin MaYiyang MeiYinru LongZhaoyuan SuKrzysztof Z. Gajos</p>
                <p><a href="http://dx.doi.org/10.1145/3613904.3642482">Link to paper</a></p>
                <p>LGBTQ individuals are increasingly turning to chatbots powered by largelanguage models LLMs to meet their mental health needs. However littleresearch has explored whether these chatbots can adequately and safely providetailored support for this demographic. We interviewed 18 LGBTQ and 13non-LGBTQ participants about their experiences with LLM-based chatbots formental health needs. LGBTQ participants relied on these chatbots for mentalhealth support likely due to an absence of support in real life. Notablywhile LLMs offer prompt support they frequently fall short in grasping thenuances of LGBTQ-specific challenges. Although fine-tuning LLMs to addressLGBTQ needs can be a step in the right direction it isnt the panacea. Thedeeper issue is entrenched in societal discrimination. Consequently we call onfuture researchers and designers to look beyond mere technical refinements andadvocate for holistic strategies that confront and counteract the societalbiases burdening the LGBTQ community.</p>
                <p>Last Updated: 2024-02-14 15:48:07 UTC</p>
                <button class="interpret-button" data-id="2402.09260v1">Interpret</button>
                <div id="interpretation-2402.09260v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Scaling the Authoring of AutoTutors with Large Language Models</h3>
                <p>Authors: Sankalan Pal ChowdhuryVilém ZouharMrinmaya Sachan</p>
                <p><a href="http://arxiv.org/abs/2402.09216v1">Link to paper</a></p>
                <p>Large Language Models LLMs have found several use cases in educationranging from automatic question generation to essay evaluation. In this paperwe explore the potential of using Large Language Models LLMs to authorIntelligent Tutoring Systems. A common pitfall of LLMs is their straying fromdesired pedagogical strategies such as leaking the answer to the student andin general providing no guarantees. We posit that while LLMs with certainguardrails can take the place of subject experts the overall pedagogicaldesign still needs to be handcrafted for the best learning results. Based onthis principle we create a sample end-to-end tutoring system named MWPTutorwhich uses LLMs to fill in the state space of a pre-defined finite statetransducer. This approach retains the structure and the pedagogy of traditionaltutoring systems that has been developed over the years by learning scientistsbut brings in additional flexibility of LLM-based approaches. Through a humanevaluation study on two datasets based on math word problems we show that ourhybrid approach achieves a better overall tutoring score than an instructedbut otherwise free-form GPT-4. MWPTutor is completely modular and opens up thescope for the community to improve its performance by improving individualmodules or using different teaching strategies that it can follow</p>
                <p>Last Updated: 2024-02-14 14:53:56 UTC</p>
                <button class="interpret-button" data-id="2402.09216v1">Interpret</button>
                <div id="interpretation-2402.09216v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents</h3>
                <p>Authors: Cheng QianBingxiang HeZhong ZhuangJia DengYujia QinXin CongZhong ZhangJie ZhouYankai LinZhiyuan LiuMaosong Sun</p>
                <p><a href="http://arxiv.org/abs/2402.09205v2">Link to paper</a></p>
                <p>Current language model-driven agents often lack mechanisms for effective userparticipation which is crucial given the vagueness commonly found in userinstructions. Although adept at devising strategies and performing tasks theseagents struggle with seeking clarification and grasping precise userintentions. To bridge this gap we introduce Intention-in-Interaction IN3 anovel benchmark designed to inspect users implicit intentions through explicitqueries. Next we propose the incorporation of model experts as the upstream inagent designs to enhance user-agent interaction. Employing IN3 we empiricallytrain Mistral-Interact a powerful model that proactively assesses taskvagueness inquires user intentions and refines them into actionable goalsbefore starting downstream agent task execution. Integrating it into the XAgentframework we comprehensively evaluate the enhanced agent system regarding userinstruction understanding and execution revealing that our approach notablyexcels at identifying vague user tasks recovering and summarizing criticalmissing information setting precise and necessary agent execution goals andminimizing redundant tool usage thus boosting overall efficiency. All the dataand codes are released.</p>
                <p>Last Updated: 2024-02-15 09:59:52 UTC</p>
                <button class="interpret-button" data-id="2402.09205v2">Interpret</button>
                <div id="interpretation-2402.09205v2" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability</h3>
                <p>Authors: Siwei YangBingchen ZhaoCihang Xie</p>
                <p><a href="http://arxiv.org/abs/2402.09404v1">Link to paper</a></p>
                <p>This paper introduces AQA-Bench a novel benchmark to assess the sequentialreasoning capabilities of large language models LLMs in algorithmic contextssuch as depth-first search DFS. The key feature of our evaluation benchmarklies in its interactive evaluation protocol -- for example in DFS theavailability of each nodes connected edge is contingent upon the modelstraversal to that node thereby necessitating the LLMs ability to effectivelyremember visited nodes and strategize subsequent moves. We comprehensivelybuild AQA-Bench with three different algorithms namely binary searchdepth-first search and breadth-first search and to evaluate the sequentialreasoning ability of 12 different LLMs. Our investigations reveal severalinteresting findings: 1 Closed-source models like GPT-4 and Gemini generallyshow strong sequential reasoning ability significantly outperformingopen-source LLMs. 2 Naively providing interactive examples may inadvertentlyhurt few-shot performance. 3 A very limited number of predecessor stepsfollowing the optimal policy can substantially boost small models performance.4 The scaling correlation between performance and model size is not alwayssignificant sometimes even showcasing an inverse trend. We hope our study cancatalyze future work on advancing the understanding and enhancement of LLMscapabilities in sequential reasoning. The code is available athttps://github.com/UCSC-VLAA/AQA-Bench.</p>
                <p>Last Updated: 2024-02-14 18:59:33 UTC</p>
                <button class="interpret-button" data-id="2402.09404v1">Interpret</button>
                <div id="interpretation-2402.09404v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Reinforcement Learning from Human Feedback with Active Queries</h3>
                <p>Authors: Kaixuan JiJiafan HeQuanquan Gu</p>
                <p><a href="http://arxiv.org/abs/2402.09401v1">Link to paper</a></p>
                <p>Aligning large language models LLM with human preference plays a key rolein building modern generative models and can be achieved by reinforcementlearning from human feedback RLHF. Despite their superior performancecurrent RLHF approaches often require a large amount of human-labelledpreference data which is expensive to collect. In this paper inspired by thesuccess of active learning we address this problem by proposingquery-efficient RLHF methods. We first formalize the alignment problem as acontextual dueling bandit problem and design an active-query-based proximalpolicy optimization APPO algorithm with an tildeOd2/Delta regretbound and an tildeOd2/Delta2 query complexity where d is thedimension of feature space and Delta is the sub-optimality gap over all thecontexts. We then propose ADPO a practical version of our algorithm based ondirect preference optimization DPO and apply it to fine-tuning LLMs. Ourexperiments show that ADPO while only making about half of queries for humanpreference matches the performance of the state-of-the-art DPO method.</p>
                <p>Last Updated: 2024-02-14 18:58:40 UTC</p>
                <button class="interpret-button" data-id="2402.09401v1">Interpret</button>
                <div id="interpretation-2402.09401v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference</h3>
                <p>Authors: Harry DongXinyu YangZhenyu ZhangZhangyang WangYuejie ChiBeidi Chen</p>
                <p><a href="http://arxiv.org/abs/2402.09398v1">Link to paper</a></p>
                <p>Many computational factors limit broader deployment of large language models.In this paper we focus on a memory bottleneck imposed by the key-value KVcache a computational shortcut that requires storing previous KV pairs duringdecoding. While existing KV cache methods approach this problem by pruning orevicting large swaths of relatively less important KV pairs to dramaticallyreduce the memory footprint of the cache they can have limited success intasks that require recollecting a majority of previous tokens. To alleviatethis issue we propose LESS a simple integration of a nearly free constantsized cache with eviction-based cache methods such that all tokens can bequeried at later decoding steps. Its ability to retain information throughouttime shows merit on a variety of tasks where we demonstrate LESS can helpreduce the performance gap from caching everything sometimes even matching itall while being efficient.</p>
                <p>Last Updated: 2024-02-14 18:54:56 UTC</p>
                <button class="interpret-button" data-id="2402.09398v1">Interpret</button>
                <div id="interpretation-2402.09398v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Active Disruption Avoidance and Trajectory Design for Tokamak Ramp-downs with Neural Differential Equations and Reinforcement Learning</h3>
                <p>Authors: Allen M. WangOswin SoCharles DawsonDarren T. GarnierCristina ReaChuchu Fan</p>
                <p><a href="http://arxiv.org/abs/2402.09387v1">Link to paper</a></p>
                <p>The tokamak offers a promising path to fusion energy but plasma disruptionspose a major economic risk motivating considerable advances in disruptionavoidance. This work develops a reinforcement learning approach to this problemby training a policy to safely ramp-down the plasma current while avoidinglimits on a number of quantities correlated with disruptions. The policytraining environment is a hybrid physics and machine learning model trained onsimulations of the SPARC primary reference discharge PRD ramp-down anupcoming burning plasma scenario which we use as a testbed. To address physicsuncertainty and model inaccuracies the simulation environment is massivelyparallelized on GPU with randomized physics parameters during policy training.The trained policy is then successfully transferred to a higher fidelitysimulator where it successfully ramps down the plasma while avoidinguser-specified disruptive limits. We also address the crucial issue of safetycriticality by demonstrating that a constraint-conditioned policy can be usedas a trajectory design assistant to design a library of feed-forwardtrajectories to handle different physics conditions and user settings. As alibrary of trajectories is more interpretable and verifiable offline we arguesuch an approach is a promising path for leveraging the capabilities ofreinforcement learning in the safety-critical context of burning plasmatokamaks. Finally we demonstrate how the training environment can be a usefulplatform for other feed-forward optimization approaches by using anevolutionary algorithm to perform optimization of feed-forward trajectoriesthat are robust to physics uncertainty</p>
                <p>Last Updated: 2024-02-14 18:37:40 UTC</p>
                <button class="interpret-button" data-id="2402.09387v1">Interpret</button>
                <div id="interpretation-2402.09387v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>GraSSRep: Graph-Based Self-Supervised Learning for Repeat Detection in Metagenomic Assembly</h3>
                <p>Authors: Ali AzizpourAdvait BalajiTodd J. TreangenSantiago Segarra</p>
                <p><a href="http://arxiv.org/abs/2402.09381v1">Link to paper</a></p>
                <p>Repetitive DNA repeats poses significant challenges for accurate andefficient genome assembly and sequence alignment. This is particularly true formetagenomic data where genome dynamics such as horizontal gene transfer geneduplication and gene loss/gain complicate accurate genome assembly frommetagenomic communities. Detecting repeats is a crucial first step inovercoming these challenges. To address this issue we propose GraSSRep anovel approach that leverages the assembly graphs structure through graphneural networks GNNs within a self-supervised learning framework to classifyDNA sequences into repetitive and non-repetitive categories. Specifically weframe this problem as a node classification task within a metagenomic assemblygraph. In a self-supervised fashion we rely on a high-precision butlow-recall heuristic to generate pseudo-labels for a small proportion of thenodes. We then use those pseudo-labels to train a GNN embedding and a randomforest classifier to propagate the labels to the remaining nodes. In this wayGraSSRep combines sequencing features with pre-defined and learned graphfeatures to achieve state-of-the-art performance in repeat detection. Weevaluate our method using simulated and synthetic metagenomic datasets. Theresults on the simulated data highlight our GraSSReps robustness to repeatattributes demonstrating its effectiveness in handling the complexity ofrepeated sequences. Additionally our experiments with synthetic metagenomicdatasets reveal that incorporating the graph structure and the GNN enhances ourdetection performance. Finally in comparative analyses GraSSRep outperformsexisting repeat detection tools with respect to precision and recall.</p>
                <p>Last Updated: 2024-02-14 18:26:58 UTC</p>
                <button class="interpret-button" data-id="2402.09381v1">Interpret</button>
                <div id="interpretation-2402.09381v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>Deep Rib Fracture Instance Segmentation and Classification from CT on the RibFrac Challenge</h3>
                <p>Authors: Jiancheng YangRui ShiLiang JinXiaoyang HuangKaiming KuangDonglai WeiShixuan GuJianying LiuPengfei LiuZhizhong ChaiYongjie XiaoHao ChenLiming XuBang DuXiangyi YanHao TangAdam AlessioGregory HolsteJiapeng ZhangXiaoming WangJianye HeLixuan CheHanspeter PfisterMing LiBingbing Ni</p>
                <p><a href="http://arxiv.org/abs/2402.09372v1">Link to paper</a></p>
                <p>Rib fractures are a common and potentially severe injury that can bechallenging and labor-intensive to detect in CT scans. While there have beenefforts to address this field the lack of large-scale annotated datasets andevaluation benchmarks has hindered the development and validation of deeplearning algorithms. To address this issue the RibFrac Challenge wasintroduced providing a benchmark dataset of over 5000 rib fractures from 660CT scans with voxel-level instance mask annotations and diagnosis labels forfour clinical categories buckle nondisplaced displaced or segmental. Thechallenge includes two tracks: a detection instance segmentation trackevaluated by an FROC-style metric and a classification track evaluated by anF1-style metric. During the MICCAI 2020 challenge period 243 results wereevaluated and seven teams were invited to participate in the challengesummary. The analysis revealed that several top rib fracture detectionsolutions achieved performance comparable or even better than human experts.Nevertheless the current rib fracture classification solutions are hardlyclinically applicable which can be an interesting area in the future. As anactive benchmark and research resource the data and online evaluation of theRibFrac Challenge are available at the challenge website. As an independentcontribution we have also extended our previous internal baseline byincorporating recent advancements in large-scale pretrained networks andpoint-based rib segmentation techniques. The resulting FracNet demonstratescompetitive performance in rib fracture detection which lays a foundation forfurther research and development in AI-assisted rib fracture detection anddiagnosis.</p>
                <p>Last Updated: 2024-02-14 18:18:33 UTC</p>
                <button class="interpret-button" data-id="2402.09372v1">Interpret</button>
                <div id="interpretation-2402.09372v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Magic-Me: Identity-Specific Video Customized Diffusion</h3>
                <p>Authors: Ze MaDaquan ZhouChun-Hsiao YehXue-She WangXiuyu LiHuanrui YangZhen DongKurt KeutzerJiashi Feng</p>
                <p><a href="http://arxiv.org/abs/2402.09368v1">Link to paper</a></p>
                <p>Creating content for a specific identity ID has shown significant interestin the field of generative models. In the field of text-to-image generationT2I subject-driven content generation has achieved great progress with theID in the images controllable. However extending it to video generation is notwell explored. In this work we propose a simple yet effective subject identitycontrollable video generation framework termed Video Custom Diffusion VCD.With a specified subject ID defined by a few images VCD reinforces theidentity information extraction and injects frame-wise correlation at theinitialization stage for stable video outputs with identity preserved to alarge extent. To achieve this we propose three novel components that areessential for high-quality ID preservation: 1 an ID module trained with thecropped identity by prompt-to-segmentation to disentangle the ID informationand the background noise for more accurate ID token learning 2 atext-to-video T2V VCD module with 3D Gaussian Noise Prior for betterinter-frame consistency and 3 video-to-video V2V Face VCD and Tiled VCDmodules to deblur the face and upscale the video for higher resolution.  Despite its simplicity we conducted extensive experiments to verify that VCDis able to generate stable and high-quality videos with better ID over theselected strong baselines. Besides due to the transferability of the IDmodule VCD is also working well with finetuned text-to-image models availablepublically further improving its usability. The codes are available athttps://github.com/Zhen-Dong/Magic-Me.</p>
                <p>Last Updated: 2024-02-14 18:13:51 UTC</p>
                <button class="interpret-button" data-id="2402.09368v1">Interpret</button>
                <div id="interpretation-2402.09368v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Prediction of Activated Sludge Settling Characteristics from Microscopy Images with Deep Convolutional Neural Networks and Transfer Learning</h3>
                <p>Authors: Sina BorzooeiLeonardo ScabiniGisele MirandaSaba DaneshgarLukas DeblieckPiet De LangheOdemir BrunoBernard De BaetsIngmar NopensElena Torfs</p>
                <p><a href="http://arxiv.org/abs/2402.09367v1">Link to paper</a></p>
                <p>Microbial communities play a key role in biological wastewater treatmentprocesses. Activated sludge settling characteristics for example are affectedby microbial community composition varying by changes in operating conditionsand influent characteristics of wastewater treatment plants WWTPs. Timelyassessment and prediction of changes in microbial composition leading tosettling problems such as filamentous bulking FB can prevent operationalchallenges reductions in treatment efficiency and adverse environmentalimpacts. This study presents an innovative computer vision-based approach toassess activated sludge-settling characteristics based on the morphologicalproperties of flocs and filaments in microscopy images. Implementing thetransfer learning of deep convolutional neural network CNN models thisapproach aims to overcome the limitations of existing quantitative imageanalysis techniques. The offline microscopy image dataset was collected overtwo years with weekly sampling at a full-scale industrial WWTP in Belgium.Multiple data augmentation techniques were employed to enhance thegeneralizability of the CNN models. Various CNN architectures includingInception v3 ResNet18 ResNet152 ConvNeXt-nano and ConvNeXt-S were testedto evaluate their performance in predicting sludge settling characteristics.The sludge volume index was used as the final prediction variable but themethod can easily be adjusted to predict any other settling metric of choice.The results showed that the suggested CNN-based approach provides lesslabour-intensive objective and consistent assessments while transferlearning notably minimises the training phase resulting in a generalizablesystem that can be employed in real-time applications.</p>
                <p>Last Updated: 2024-02-14 18:13:37 UTC</p>
                <button class="interpret-button" data-id="2402.09367v1">Interpret</button>
                <div id="interpretation-2402.09367v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Pruning Sparse Tensor Neural Networks Enables Deep Learning for 3D Ultrasound Localization Microscopy</h3>
                <p>Authors: Brice RaubyPaul XingJonathan PoréeMaxime GasseJean Provost</p>
                <p><a href="http://arxiv.org/abs/2402.09359v1">Link to paper</a></p>
                <p>Ultrasound Localization Microscopy ULM is a non-invasive technique thatallows for the imaging of micro-vessels in vivo at depth and with a resolutionon the order of ten microns. ULM is based on the sub-resolution localization ofindividual microbubbles injected in the bloodstream. Mapping the wholeangioarchitecture requires the accumulation of microbubbles trajectories fromthousands of frames typically acquired over a few minutes. ULM acquisitiontimes can be reduced by increasing the microbubble concentration but requiresmore advanced algorithms to detect them individually. Several deep learningapproaches have been proposed for this task but they remain limited to 2Dimaging in part due to the associated large memory requirements. Herein wepropose to use sparse tensor neural networks to reduce memory usage in 2D andto improve the scaling of the memory requirement for the extension of deeplearning architecture to 3D. We study several approaches to efficiently convertultrasound data into a sparse format and study the impact of the associatedloss of information. When applied in 2D the sparse formulation reduces thememory requirements by a factor 2 at the cost of a small reduction ofperformance when compared against dense networks. In 3D the proposed approachreduces memory requirements by two order of magnitude while largelyoutperforming conventional ULM in high concentration settings. We show thatSparse Tensor Neural Networks in 3D ULM allow for the same benefits as densedeep learning based method in 2D ULM i.e. the use of higher concentration insilico and reduced acquisition time.</p>
                <p>Last Updated: 2024-02-14 18:03:58 UTC</p>
                <button class="interpret-button" data-id="2402.09359v1">Interpret</button>
                <div id="interpretation-2402.09359v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>DoRA: Weight-Decomposed Low-Rank Adaptation</h3>
                <p>Authors: Shih-Yang LiuChien-Yi WangHongxu YinPavlo MolchanovYu-Chiang Frank WangKwang-Ting ChengMin-Hung Chen</p>
                <p><a href="http://arxiv.org/abs/2402.09353v1">Link to paper</a></p>
                <p>Among the widely used parameter-efficient finetuning PEFT methods LoRA andits variants have gained considerable popularity because of avoiding additionalinference costs. However there still often exists an accuracy gap betweenthese methods and full fine-tuning FT. In this work we first introduce anovel weight decomposition analysis to investigate the inherent differencesbetween FT and LoRA. Aiming to resemble the learning capacity of FT from thefindings we propose Weight-Decomposed LowRank Adaptation DoRA. DoRAdecomposes the pre-trained weight into two components magnitude and directionfor fine-tuning specifically employing LoRA for directional updates toefficiently minimize the number of trainable parameters. By employing DoRA weenhance both the learning capacity and training stability of LoRA whileavoiding any additional inference overhead. DoRA consistently outperforms LoRAon fine-tuning LLaMA LLaVA and VL-BART on various downstream tasks such ascommonsense reasoning visual instruction tuning and image/video-textunderstanding.</p>
                <p>Last Updated: 2024-02-14 17:59:34 UTC</p>
                <button class="interpret-button" data-id="2402.09353v1">Interpret</button>
                <div id="interpretation-2402.09353v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-02-16</p>
        </div>
    
        </div>
    </body>
    </html>
    