
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.MA">cs.MA</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>From Mobilisation to Radicalisation: Probing the Persistence and Radicalisation of Social Movements Using an Agent-Based Model</h3>
                <p>Authors: Emma F. ThomasMengbin YeSimon D. AngusTony J. MathewWinnifred LouisLiam WalshSilas ElleryMorgana Lizzio-WilsonCraig McGarty</p>
                <p><a href="http://arxiv.org/abs/2408.12795v1">Link to paper</a></p>
                <p>We are living in an age of protest. Although we have an excellentunderstanding of the factors that predict participation in protest weunderstand little about the conditions that foster a sustained versustransient movement. How do interactions between supporters and authoritiescombine to influence whether and how people engage i.e. using conventional orradical tactics This paper introduces a novel theoretically-founded andempirically-informed agent-based model DIMESim to address these questions. Wemodel the complex interactions between the psychological attributes of theprotester agents the authority to whom the protests are targeted and theenvironment that allows protesters to coordinate with each other -- over timeand at a population scale. Where an authority is responsive and failure iscontested a modest sized conventional movement endured. Where authoritiesrepeatedly and incontrovertibly fail the movement the population disengagedfrom action but evidenced an ongoing commitment to radicalism latentradicalism.</p>
                <p>Last Updated: 2024-08-23 02:18:07 UTC</p>
                <button class="interpret-button" data-id="2408.12795v1">Interpret</button>
                <div id="interpretation-2408.12795v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>MEDCO: Medical Education Copilots Based on A Multi-Agent Framework</h3>
                <p>Authors: Hao WeiJianing QiuHaibao YuWu Yuan</p>
                <p><a href="http://arxiv.org/abs/2408.12496v1">Link to paper</a></p>
                <p>Large language models LLMs have had a significant impact on diverseresearch domains including medicine and healthcare. However the potential ofLLMs as copilots in medical education remains underexplored. CurrentAI-assisted educational tools are limited by their solitary learning approachand inability to simulate the multi-disciplinary and interactive nature ofactual medical training. To address these limitations we propose MEDCOMedical EDucation COpilots a novel multi-agent-based copilot systemspecially developed to emulate real-world medical training environments. MEDCOincorporates three primary agents: an agentic patient an expert doctor and aradiologist facilitating a multi-modal and interactive learning environment.Our framework emphasizes the learning of proficient question-asking skillsmulti-disciplinary collaboration and peer discussions between students. Ourexperiments show that simulated virtual students who underwent training withMEDCO not only achieved substantial performance enhancements comparable tothose of advanced models but also demonstrated human-like learning behaviorsand improvements coupled with an increase in the number of learning samples.This work contributes to medical education by introducing a copilot thatimplements an interactive and collaborative learning approach. It also providesvaluable insights into the effectiveness of AI-integrated training paradigms.</p>
                <p>Last Updated: 2024-08-22 15:41:58 UTC</p>
                <button class="interpret-button" data-id="2408.12496v1">Interpret</button>
                <div id="interpretation-2408.12496v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards</h3>
                <p>Authors: Shresth VermaNiclas BoehmerLingkai KongMilind Tambe</p>
                <p><a href="http://arxiv.org/abs/2408.12112v1">Link to paper</a></p>
                <p>LLMs are increasingly used to design reward functions based on humanpreferences in Reinforcement Learning RL. We focus on LLM-designed rewardsfor Restless Multi-Armed Bandits a framework for allocating limited resourcesamong agents. In applications such as public health this approach empowersgrassroots health workers to tailor automated allocation decisions to communityneeds. In the presence of multiple agents altering the reward function basedon human preferences can impact subpopulations very differently leading tocomplex tradeoffs and a multi-objective resource allocation problem. We are thefirst to present a principled method termed Social Choice Language Model fordealing with these tradeoffs for LLM-designed rewards for multiagent plannersin general and restless bandits in particular. The novel part of our model is atransparent and configurable selection component called an adjudicatorexternal to the LLM that controls complex tradeoffs via a user-selected socialwelfare function. Our experiments demonstrate that our model reliably selectsmore effective aligned and balanced reward functions compared to purelyLLM-based approaches.</p>
                <p>Last Updated: 2024-08-22 03:54:08 UTC</p>
                <button class="interpret-button" data-id="2408.12112v1">Interpret</button>
                <div id="interpretation-2408.12112v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Empirical Equilibria in Agent-based Economic systems with Learning agents</h3>
                <p>Authors: Kshama DwarakanathSvitlana VyetrenkoTucker Balch</p>
                <p><a href="http://arxiv.org/abs/2408.12038v1">Link to paper</a></p>
                <p>We present an agent-based simulator for economic systems with heterogeneoushouseholds firms central bank and government agents. These agents interactto define production consumption and monetary flow. Each agent type hasdistinct objectives such as households seeking utility from consumption andthe central bank targeting inflation and production. We define this multi-agenteconomic system using an OpenAI Gym-style environment enabling agents tooptimize their objectives through reinforcement learning. Standard multi-agentreinforcement learning MARL schemes like independent learning enable agentsto learn concurrently but do not address whether the resulting strategies areat equilibrium. This study integrates the Policy Space Response Oracle PSROalgorithm which has shown superior performance over independent MARL in gameswith homogeneous agents with economic agent-based modeling. We use PSRO todevelop agent policies approximating Nash equilibria of the empirical economicgame thereby linking to economic equilibria. Our results demonstrate that PSROstrategies achieve lower regret values than independent MARL strategies in oureconomic system with four agent types. This work aims to bridge artificialintelligence economics and empirical game theory towards future research.</p>
                <p>Last Updated: 2024-08-21 23:47:46 UTC</p>
                <button class="interpret-button" data-id="2408.12038v1">Interpret</button>
                <div id="interpretation-2408.12038v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>VIRIS: Simulating indoor airborne transmission combining architectural design and people movement</h3>
                <p>Authors: Yidan XueWassim JabiThomas E. WoolleyKaterina Kaouri</p>
                <p><a href="http://arxiv.org/abs/2408.11772v1">Link to paper</a></p>
                <p>A Viral Infection Risk Indoor Simulator VIRIS has been developed to quicklyassess and compare mitigations for airborne disease spread. This agent-basedsimulator combines people movement in an indoor space viral transmissionmodelling and detailed architectural design and it is powered by topologicpyan open-source Python library. VIRIS generates very fast predictions of theviral concentration and the spatiotemporal infection risk for individuals asthey move through a given space. The simulator is validated with data from acourtroom superspreader event. A sensitivity study for unknown parameter valuesis also performed. We compare several non-pharmaceutical interventions NPIsissued in UK government guidance for two indoor settings: a care home and asupermarket. Additionally we have developed the user-friendly VIRIS web appthat allows quick exploration of diverse scenarios of interest andvisualisation allowing policymakers architects and space managers to easilydesign or assess infection risk in an indoor space.</p>
                <p>Last Updated: 2024-08-21 16:54:22 UTC</p>
                <button class="interpret-button" data-id="2408.11772v1">Interpret</button>
                <div id="interpretation-2408.11772v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>MME-RealWorld: Could Your Multimodal LLM Challenge High-Resolution Real-World Scenarios that are Difficult for Humans?</h3>
                <p>Authors: Yi-Fan ZhangHuanyu ZhangHaochen TianChaoyou FuShuangqing ZhangJunfei WuFeng LiKun WangQingsong WenZhang ZhangLiang WangRong JinTieniu Tan</p>
                <p><a href="http://arxiv.org/abs/2408.13257v1">Link to paper</a></p>
                <p>Comprehensive evaluation of Multimodal Large Language Models MLLMs hasrecently garnered widespread attention in the research community. However weobserve that existing benchmarks present several common barriers that make itdifficult to measure the significant challenges that models face in the realworld including: 1 small data scale leads to a large performance variance 2reliance on model-based annotations results in restricted data quality 3insufficient task difficulty especially caused by the limited imageresolution. To tackle these issues we introduce MME-RealWorld. Specificallywe collect more than 300K images from public datasets and the Internetfiltering 13366 high-quality images for annotation. This involves theefforts of professional 25 annotators and 7 experts in MLLMs contributingto 29429 question-answer pairs that cover 43 subtasks across 5real-world scenarios extremely challenging even for humans. As far as we knowMME-RealWorld is the largest manually annotated benchmark to date featuringthe highest resolution and a targeted focus on real-world applications. Wefurther conduct a thorough evaluation involving 28 prominent MLLMs such asGPT-4o Gemini 1.5 Pro and Claude 3.5 Sonnet. Our results show that even themost advanced models struggle with our benchmarks where none of them reach60 accuracy. The challenges of perceiving high-resolution images andunderstanding complex real-world scenarios remain urgent issues to beaddressed. The data and evaluation code are released athttps://mme-realworld.github.io/ .</p>
                <p>Last Updated: 2024-08-23 17:59:51 UTC</p>
                <button class="interpret-button" data-id="2408.13257v1">Interpret</button>
                <div id="interpretation-2408.13257v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>How Diffusion Models Learn to Factorize and Compose</h3>
                <p>Authors: Qiyao LiangZiming LiuMitchell OstrowIla Fiete</p>
                <p><a href="http://arxiv.org/abs/2408.13256v1">Link to paper</a></p>
                <p>Diffusion models are capable of generating photo-realistic images thatcombine elements which likely do not appear together in the training setdemonstrating the ability to compositionally generalize. Nonetheless theprecise mechanism of compositionality and how it is acquired through trainingremains elusive. Inspired by cognitive neuroscientific approaches we considera highly reduced setting to examine whether and when diffusion models learnsemantically meaningful and factorized representations of composable features.We performed extensive controlled experiments on conditional DenoisingDiffusion Probabilistic Models DDPMs trained to generate various forms of 2DGaussian data. We found that the models learn factorized but not fullycontinuous manifold representations for encoding continuous features ofvariation underlying the data. With such representations models demonstratesuperior feature compositionality but limited ability to interpolate overunseen values of a given feature. Our experimental results further demonstratethat diffusion models can attain compositionality with few compositionalexamples suggesting a more efficient way to train DDPMs. Finally we connectmanifold formation in diffusion models to percolation theory in physicsoffering insight into the sudden onset of factorized representation learning.Our thorough toy experiments thus contribute a deeper understanding of howdiffusion models capture compositional structure in data.</p>
                <p>Last Updated: 2024-08-23 17:59:03 UTC</p>
                <button class="interpret-button" data-id="2408.13256v1">Interpret</button>
                <div id="interpretation-2408.13256v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Ensemble Modeling of Multiple Physical Indicators to Dynamically Phenotype Autism Spectrum Disorder</h3>
                <p>Authors: Marie HuynhAaron KlineSaimourya SurabhiKaitlyn DunlapOnur Cezmi MutluMohammadmahdi HonarmandParnian AzizianPeter WashingtonDennis P. Wall</p>
                <p><a href="http://arxiv.org/abs/2408.13255v1">Link to paper</a></p>
                <p>Early detection of autism a neurodevelopmental disorder marked by socialcommunication challenges is crucial for timely intervention. Recentadvancements have utilized naturalistic home videos captured via the mobileapplication GuessWhat. Through interactive games played between children andtheir guardians GuessWhat has amassed over 3000 structured videos from 382children both diagnosed with and without Autism Spectrum Disorder ASD. Thiscollection provides a robust dataset for training computer vision models todetect ASD-related phenotypic markers including variations in emotionalexpression eye contact and head movements. We have developed a protocol tocurate high-quality videos from this dataset forming a comprehensive trainingset. Utilizing this set we trained individual LSTM-based models using eyegaze head positions and facial landmarks as input features achieving testAUCs of 86 67 and 78 respectively. To boost diagnostic accuracy weapplied late fusion techniques to create ensemble models improving the overallAUC to 90. This approach also yielded more equitable results across differentgenders and age groups. Our methodology offers a significant step forward inthe early detection of ASD by potentially reducing the reliance on subjectiveassessments and making early identification more accessibly and equitable.</p>
                <p>Last Updated: 2024-08-23 17:55:58 UTC</p>
                <button class="interpret-button" data-id="2408.13255v1">Interpret</button>
                <div id="interpretation-2408.13255v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LayerPano3D: Layered 3D Panorama for Hyper-Immersive Scene Generation</h3>
                <p>Authors: Shuai YangJing TanMengchen ZhangTong WuYixuan LiGordon WetzsteinZiwei LiuDahua Lin</p>
                <p><a href="http://arxiv.org/abs/2408.13252v1">Link to paper</a></p>
                <p>3D immersive scene generation is a challenging yet critical task in computervision and graphics. A desired virtual 3D scene should 1 exhibitomnidirectional view consistency and 2 allow for free exploration in complexscene hierarchies. Existing methods either rely on successive scene expansionvia inpainting or employ panorama representation to represent large FOV sceneenvironments. However the generated scene suffers from semantic drift duringexpansion and is unable to handle occlusion among scene hierarchies. To tacklethese challenges we introduce LayerPano3D a novel framework for full-viewexplorable panoramic 3D scene generation from a single text prompt. Our keyinsight is to decompose a reference 2D panorama into multiple layers atdifferent depth levels where each layer reveals the unseen space from thereference views via diffusion prior. LayerPano3D comprises multiple dedicateddesigns: 1 we introduce a novel text-guided anchor view synthesis pipeline forhigh-quality consistent panorama generation. 2 We pioneer the Layered 3DPanorama as underlying representation to manage complex scene hierarchies andlift it into 3D Gaussians to splat detailed 360-degree omnidirectional sceneswith unconstrained viewing paths. Extensive experiments demonstrate that ourframework generates state-of-the-art 3D panoramic scene in both full viewconsistency and immersive exploratory experience. We believe that LayerPano3Dholds promise for advancing 3D panoramic scene creation with numerousapplications.</p>
                <p>Last Updated: 2024-08-23 17:50:23 UTC</p>
                <button class="interpret-button" data-id="2408.13252v1">Interpret</button>
                <div id="interpretation-2408.13252v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Re-evaluation of Face Anti-spoofing Algorithm in Post COVID-19 Era Using Mask Based Occlusion Attack</h3>
                <p>Authors: Vaibhav SundharamAbhijit SarkarA. Lynn Abbott</p>
                <p><a href="http://arxiv.org/abs/2408.13251v1">Link to paper</a></p>
                <p>Face anti-spoofing algorithms play a pivotal role in the robust deployment offace recognition systems against presentation attacks. Conventionally fullfacial images are required by such systems to correctly authenticateindividuals but the widespread requirement of masks due to the currentCOVID-19 pandemic has introduced new challenges for these biometricauthentication systems. Hence in this work we investigate the performance ofpresentation attack detection PAD algorithms under synthetic facialocclusions using masks and glasses. We have used five variants of masks tocover the lower part of the face with varying coverage areas low-coveragemedium-coverage high-coverage round coverage and 3D cues. We have also useddifferent variants of glasses that cover the upper part of the face. Wesystematically tested the performance of four PAD algorithms under theseocclusion attacks using a benchmark dataset. We have specifically looked atfour different baseline PAD algorithms that focus on texture image qualityframe difference/motion and abstract features through a convolutional neuralnetwork CNN. Additionally we have introduced a new hybrid model that uses CNNand local binary pattern textures. Our experiment shows that adding theocclusions significantly degrades the performance of all of the PAD algorithms.Our results show the vulnerability of face anti-spoofing algorithms withocclusions which could be in the usage of such algorithms in the post-pandemicera.</p>
                <p>Last Updated: 2024-08-23 17:48:22 UTC</p>
                <button class="interpret-button" data-id="2408.13251v1">Interpret</button>
                <div id="interpretation-2408.13251v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>How Diffusion Models Learn to Factorize and Compose</h3>
                <p>Authors: Qiyao LiangZiming LiuMitchell OstrowIla Fiete</p>
                <p><a href="http://arxiv.org/abs/2408.13256v1">Link to paper</a></p>
                <p>Diffusion models are capable of generating photo-realistic images thatcombine elements which likely do not appear together in the training setdemonstrating the ability to compositionally generalize. Nonetheless theprecise mechanism of compositionality and how it is acquired through trainingremains elusive. Inspired by cognitive neuroscientific approaches we considera highly reduced setting to examine whether and when diffusion models learnsemantically meaningful and factorized representations of composable features.We performed extensive controlled experiments on conditional DenoisingDiffusion Probabilistic Models DDPMs trained to generate various forms of 2DGaussian data. We found that the models learn factorized but not fullycontinuous manifold representations for encoding continuous features ofvariation underlying the data. With such representations models demonstratesuperior feature compositionality but limited ability to interpolate overunseen values of a given feature. Our experimental results further demonstratethat diffusion models can attain compositionality with few compositionalexamples suggesting a more efficient way to train DDPMs. Finally we connectmanifold formation in diffusion models to percolation theory in physicsoffering insight into the sudden onset of factorized representation learning.Our thorough toy experiments thus contribute a deeper understanding of howdiffusion models capture compositional structure in data.</p>
                <p>Last Updated: 2024-08-23 17:59:03 UTC</p>
                <button class="interpret-button" data-id="2408.13256v1">Interpret</button>
                <div id="interpretation-2408.13256v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Foundational Model for Electron Micrograph Analysis: Instruction-Tuning Small-Scale Language-and-Vision Assistant for Enterprise Adoption</h3>
                <p>Authors: Sakhinana Sagar SrinivasChidaksh RavuruGeethan SannidhiVenkataramana Runkana</p>
                <p><a href="http://arxiv.org/abs/2408.13248v1">Link to paper</a></p>
                <p>Semiconductor imaging and analysis are critical yet understudied in deeplearning limiting our ability for precise control and optimization insemiconductor manufacturing. We introduce a small-scale multimodal frameworkfor analyzing semiconductor electron microscopy images MAEMI throughvision-language instruction tuning. We generate a customizedinstruction-following dataset using large multimodal models on microscopicimage analysis. We perform knowledge transfer from larger to smaller modelsthrough knowledge distillation resulting in improved accuracy of smallermodels on visual question answering VQA tasks. This approach eliminates theneed for expensive human expert-annotated datasets for microscopic imageanalysis tasks. Enterprises can further finetune MAEMI on their intellectualdata enhancing privacy and performance on low-cost consumer hardware. Ourexperiments show that MAEMI outperforms traditional methods adapts to datadistribution shifts and supports high-throughput screening.</p>
                <p>Last Updated: 2024-08-23 17:42:11 UTC</p>
                <button class="interpret-button" data-id="2408.13248v1">Interpret</button>
                <div id="interpretation-2408.13248v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Data Exposure from LLM Apps: An In-depth Investigation of OpenAI's GPTs</h3>
                <p>Authors: Evin JaffYuhao WuNing ZhangUmar Iqbal</p>
                <p><a href="http://arxiv.org/abs/2408.13247v1">Link to paper</a></p>
                <p>LLM app ecosystems are quickly maturing and supporting a wide range of usecases which requires them to collect excessive user data. Given that the LLMapps are developed by third-parties and that anecdotal evidence suggests LLMplatforms currently do not strictly enforce their policies user data sharedwith arbitrary third-parties poses a significant privacy risk. In this paper weaim to bring transparency in data practices of LLM apps. As a case study westudy OpenAIs GPT app ecosystem. We develop an LLM-based framework to conductthe static analysis of natural language-based source code of GPTs and theirActions external services to characterize their data collection practices.Our findings indicate that Actions collect expansive data about usersincluding sensitive information prohibited by OpenAI such as passwords. Wefind that some Actions including related to advertising and analytics areembedded in multiple GPTs which allow them to track user activities acrossGPTs. Additionally co-occurrence of Actions exposes as much as 9.5x more datato them than it is exposed to individual Actions. Lastly we develop anLLM-based privacy policy analysis framework to automatically check theconsistency of data collection by Actions with disclosures in their privacypolicies. Our measurements indicate that the disclosures for most of thecollected data types are omitted in privacy policies with only 5.8 of Actionsclearly disclosing their data collection practices.</p>
                <p>Last Updated: 2024-08-23 17:42:06 UTC</p>
                <button class="interpret-button" data-id="2408.13247v1">Interpret</button>
                <div id="interpretation-2408.13247v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Improving Equivariant Model Training via Constraint Relaxation</h3>
                <p>Authors: Stefanos PertigkiozoglouEvangelos ChatzipantazisShubhendu TrivediKostas Daniilidis</p>
                <p><a href="http://arxiv.org/abs/2408.13242v1">Link to paper</a></p>
                <p>Equivariant neural networks have been widely used in a variety ofapplications due to their ability to generalize well in tasks where theunderlying data symmetries are known. Despite their successes such networkscan be difficult to optimize and require careful hyperparameter tuning to trainsuccessfully. In this work we propose a novel framework for improving theoptimization of such models by relaxing the hard equivariance constraint duringtraining: We relax the equivariance constraint of the networks intermediatelayers by introducing an additional non-equivariance term that we progressivelyconstrain until we arrive at an equivariant solution. By controlling themagnitude of the activation of the additional relaxation term we allow themodel to optimize over a larger hypothesis space containing approximateequivariant networks and converge back to an equivariant solution at the end oftraining. We provide experimental results on different state-of-the-art networkarchitectures demonstrating how this training framework can result inequivariant models with improved generalization performance.</p>
                <p>Last Updated: 2024-08-23 17:35:08 UTC</p>
                <button class="interpret-button" data-id="2408.13242v1">Interpret</button>
                <div id="interpretation-2408.13242v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>JacNet: Learning Functions with Structured Jacobians</h3>
                <p>Authors: Jonathan LorraineSafwan Hossain</p>
                <p><a href="http://arxiv.org/abs/2408.13237v1">Link to paper</a></p>
                <p>Neural networks are trained to learn an approximate mapping from an inputdomain to a target domain. Incorporating prior knowledge about true mappings iscritical to learning a useful approximation. With current architectures it ischallenging to enforce structure on the derivatives of the input-outputmapping. We propose to use a neural network to directly learn the Jacobian ofthe input-output function which allows easy control of the derivative. Wefocus on structuring the derivative to allow invertibility and also demonstratethat other useful priors such as k-Lipschitz can be enforced. Using thisapproach we can learn approximations to simple functions that are guaranteedto be invertible and easily compute the inverse. We also show similar resultsfor 1-Lipschitz functions.</p>
                <p>Last Updated: 2024-08-23 17:21:44 UTC</p>
                <button class="interpret-button" data-id="2408.13237v1">Interpret</button>
                <div id="interpretation-2408.13237v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>Demonstration of Wheeler: A Three-Wheeled Input Device for Usable, Efficient, and Versatile Non-Visual Interaction</h3>
                <p>Authors: Md Touhidul IslamNoushad SojibImran KabirAshiqur Rahman AmitMohammad Ruhul AminSyed Masum Billah</p>
                <p><a href="http://dx.doi.org/10.1145/3672539.3686749">Link to paper</a></p>
                <p>Navigating multi-level menus with complex hierarchies remains a big challengefor blind and low-vision users who predominantly use screen readers tointeract with computers. To that end we demonstrate Wheeler a three-wheeledinput device with two side buttons that can speed up complex multi-levelhierarchy navigation in common applications. When in operation the threewheels of Wheeler are each mapped to a different level in the applicationhierarchy. Each level can be independently traversed using its designatedwheel allowing users to navigate through multiple levels efficiently.Wheelers three wheels can also be repurposed for other tasks such as 2D cursormanipulation. In this demonstration we describe the different operation modesand usage of Wheeler.</p>
                <p>Last Updated: 2024-08-23 15:44:06 UTC</p>
                <button class="interpret-button" data-id="2408.13173v1">Interpret</button>
                <div id="interpretation-2408.13173v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Wheeler: A Three-Wheeled Input Device for Usable, Efficient, and Versatile Non-Visual Interaction</h3>
                <p>Authors: Md Touhidul IslamNoushad SojibImran KabirAshiqur Rahman AmitMohammad Ruhul AminSyed Masum Billah</p>
                <p><a href="http://dx.doi.org/10.1145/3654777.3676396">Link to paper</a></p>
                <p>Blind users rely on keyboards and assistive technologies like screen readersto interact with user interface UI elements. In modern applications withcomplex UI hierarchies navigating to different UI elements poses a significantaccessibility challenge. Users must listen to screen reader audio descriptionsand press relevant keyboard keys one at a time. This paper introduces Wheelera novel three-wheeled mouse-shaped stationary input device to address thisissue. Informed by participatory sessions Wheeler enables blind users tonavigate up to three hierarchical levels in an app independently using threewheels instead of navigating just one level at a time using a keyboard. Thethree wheels also offer versatility allowing users to repurpose them for othertasks such as 2D cursor manipulation. A study with 12 blind users indicates asignificant reduction 40 in navigation time compared to using a keyboard.Further a diary study with our blind co-author highlights Wheelers additionalbenefits such as accessing UI elements with partial metadata and facilitatingmixed-ability collaboration.</p>
                <p>Last Updated: 2024-08-23 15:39:21 UTC</p>
                <button class="interpret-button" data-id="2408.13166v1">Interpret</button>
                <div id="interpretation-2408.13166v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Avatar Visual Similarity for Social HCI: Increasing Self-Awareness</h3>
                <p>Authors: Bernhard HilpertClaudio Alves da SilvaLeon ChristidisChirag BhuvaneshwaraPatrick GebhardFabrizio NunnariDimitra Tsovaltzi</p>
                <p><a href="http://arxiv.org/abs/2408.13084v1">Link to paper</a></p>
                <p>Self-awareness is a critical factor in social human-human interaction andhence in social HCI interaction. Increasing self-awareness through mirrors orvideo recordings is common in face-to-face trainings since it influencesantecedents of self-awareness like explicit identification and implicitaffective identification affinity. However increasing self-awareness hasbeen scarcely examined in virtual trainings with virtual avatars which allowfor adjusting the similarity e.g. to avoid negative effects ofself-consciousness. Automatic visual similarity in avatars is an open issuerelated to high costs. It is important to understand which features need to bemanipulated and which degree of similarity is necessary for self-awareness toleverage the added value of using avatars for self-awareness. This articleexamines the relationship between avatar visual similarity and increasingself-awareness in virtual training environments. We define visual similaritybased on perceptually important facial features for human-human identificationand develop a theory-based methodology to systematically manipulate visualsimilarity of virtual avatars and support self-awareness. Three personalizedversions of virtual avatars with varying degrees of visual similarity toparticipants were created weak medium and strong facial featuresmanipulation. In a within-subject study N33 we tested effects of degree ofsimilarity on perceived similarity explicit identification and implicitaffective identification affinity. Results show significant differencesbetween the weak similarity manipulation and both the strong manipulation andthe random avatar for all three antecedents of self-awareness. An increasingdegree of avatar visual similarity influences antecedents of self-awareness invirtual environments.</p>
                <p>Last Updated: 2024-08-23 14:11:35 UTC</p>
                <button class="interpret-button" data-id="2408.13084v1">Interpret</button>
                <div id="interpretation-2408.13084v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>VCEMO: Multi-Modal Emotion Recognition for Chinese Voiceprints</h3>
                <p>Authors: Jinghua TangLiyun ZhangYu LuDian DingLanqing YangYiChao ChenMinjie BianXiaoshan LiGuangtao Xue</p>
                <p><a href="http://arxiv.org/abs/2408.13019v1">Link to paper</a></p>
                <p>Emotion recognition can enhance humanized machine responses to user commandswhile voiceprint-based perception systems can be easily integrated intocommonly used devices like smartphones and stereos. Despite having the largestnumber of speakers there is a noticeable absence of high-quality corpusdatasets for emotion recognition using Chinese voiceprints. Hence this paperintroduces the VCEMO dataset to address this deficiency. The proposed datasetis constructed from everyday conversations and comprises over 100 users and7747 textual samples. Furthermore this paper proposes a multimodal-basedmodel as a benchmark which effectively fuses speech text and externalknowledge using a co-attention structure. The system employs contrastivelearning-based regulation for the uneven distribution of the dataset and thediversity of emotional expressions. The experiments demonstrate the significantimprovement of the proposed model over SOTA on the VCEMO and IEMOCAP datasets.Code and dataset will be released for research.</p>
                <p>Last Updated: 2024-08-23 12:14:18 UTC</p>
                <button class="interpret-button" data-id="2408.13019v1">Interpret</button>
                <div id="interpretation-2408.13019v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>A Survey on Drowsiness Detection -- Modern Applications and Methods</h3>
                <p>Authors: Biying FuFadi BoutrosChin-Teng LinNaser Damer</p>
                <p><a href="http://arxiv.org/abs/2408.12990v1">Link to paper</a></p>
                <p>Drowsiness detection holds paramount importance in ensuring safety inworkplaces or behind the wheel enhancing productivity and healthcare acrossdiverse domains. Therefore accurate and real-time drowsiness detection plays acritical role in preventing accidents enhancing safety and ultimately savinglives across various sectors and scenarios. This comprehensive review exploresthe significance of drowsiness detection in various areas of applicationtranscending the conventional focus solely on driver drowsiness detection. Wedelve into the current methodologies challenges and technologicaladvancements in drowsiness detection schemes considering diverse contexts suchas public transportation healthcare workplace safety and beyond. Byexamining the multifaceted implications of drowsiness this work contributes toa holistic understanding of its impact and the crucial role of accurate andreal-time detection techniques in enhancing safety and performance. Weidentified weaknesses in current algorithms and limitations in existingresearch such as accurate and real-time detection stable data transmissionand building bias-free systems. Our survey frames existing works and leads topractical recommendations like mitigating the bias issue by using syntheticdata overcoming the hardware limitations with model compression andleveraging fusion to boost model performance. This is a pioneering work tosurvey the topic of drowsiness detection in such an entirely and not onlyfocusing on one single aspect. We consider the topic of drowsiness detection asa dynamic and evolving field presenting numerous opportunities for furtherexploration.</p>
                <p>Last Updated: 2024-08-23 11:15:21 UTC</p>
                <button class="interpret-button" data-id="2408.12990v1">Interpret</button>
                <div id="interpretation-2408.12990v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>Domain-specific long text classification from sparse relevant information</h3>
                <p>Authors: Célia D'CruzJean-Marc BerederFrédéric PreciosoMichel Riveill</p>
                <p><a href="http://arxiv.org/abs/2408.13253v1">Link to paper</a></p>
                <p>Large Language Models have undoubtedly revolutionized the Natural LanguageProcessing field the current trend being to promote one-model-for-all taskssentiment analysis translation etc.. However the statistical mechanisms atwork in the larger language models struggle to exploit the relevant informationwhen it is very sparse when it is a weak signal. This is the case forexample for the classification of long domain-specific documents when therelevance relies on a single relevant word or on very few relevant words fromtechnical jargon. In the medical domain it is essential to determine whether agiven report contains critical information about a patients condition. Thiscritical information is often based on one or few specific isolated terms. Inthis paper we propose a hierarchical model which exploits a short list ofpotential target terms to retrieve candidate sentences and represent them intothe contextualized embedding of the target terms they contain. A pooling ofthe terms embeddings entails the document representation to be classified.We evaluate our model on one public medical document benchmark in English andon one private French medical dataset. We show that our narrower hierarchicalmodel is better than larger language models for retrieving relevant longdocuments in a domain-specific context.</p>
                <p>Last Updated: 2024-08-23 17:54:19 UTC</p>
                <button class="interpret-button" data-id="2408.13253v1">Interpret</button>
                <div id="interpretation-2408.13253v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Data Exposure from LLM Apps: An In-depth Investigation of OpenAI's GPTs</h3>
                <p>Authors: Evin JaffYuhao WuNing ZhangUmar Iqbal</p>
                <p><a href="http://arxiv.org/abs/2408.13247v1">Link to paper</a></p>
                <p>LLM app ecosystems are quickly maturing and supporting a wide range of usecases which requires them to collect excessive user data. Given that the LLMapps are developed by third-parties and that anecdotal evidence suggests LLMplatforms currently do not strictly enforce their policies user data sharedwith arbitrary third-parties poses a significant privacy risk. In this paper weaim to bring transparency in data practices of LLM apps. As a case study westudy OpenAIs GPT app ecosystem. We develop an LLM-based framework to conductthe static analysis of natural language-based source code of GPTs and theirActions external services to characterize their data collection practices.Our findings indicate that Actions collect expansive data about usersincluding sensitive information prohibited by OpenAI such as passwords. Wefind that some Actions including related to advertising and analytics areembedded in multiple GPTs which allow them to track user activities acrossGPTs. Additionally co-occurrence of Actions exposes as much as 9.5x more datato them than it is exposed to individual Actions. Lastly we develop anLLM-based privacy policy analysis framework to automatically check theconsistency of data collection by Actions with disclosures in their privacypolicies. Our measurements indicate that the disclosures for most of thecollected data types are omitted in privacy policies with only 5.8 of Actionsclearly disclosing their data collection practices.</p>
                <p>Last Updated: 2024-08-23 17:42:06 UTC</p>
                <button class="interpret-button" data-id="2408.13247v1">Interpret</button>
                <div id="interpretation-2408.13247v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Which Prosodic Features Matter Most for Pragmatics?</h3>
                <p>Authors: Nigel G. WardDivette MarcoOlac Fuentes</p>
                <p><a href="http://arxiv.org/abs/2408.13240v1">Link to paper</a></p>
                <p>We investigate which prosodic features matter most in conveying prosodicfunctions. We use the problem of predicting human perceptions of pragmaticsimilarity among utterance pairs to evaluate the utility of prosodic featuresof different types. We find for example that duration-related features aremore important than pitch-related features and that utterance-initial featuresare more important than utterance-final features. Further failure analysisindicates that modeling using pitch features only often fails to handleimportant pragmatic functions and suggests that several generally-neglectedacoustic and prosodic features are pragmatically significant includingnasality and vibrato. These findings can guide future basic research inprosody and suggest how to improve speech synthesis evaluation among otherapplications.</p>
                <p>Last Updated: 2024-08-23 17:29:05 UTC</p>
                <button class="interpret-button" data-id="2408.13240v1">Interpret</button>
                <div id="interpretation-2408.13240v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Multi-Layer Transformers Gradient Can be Approximated in Almost Linear Time</h3>
                <p>Authors: Yingyu LiangZhizhou ShaZhenmei ShiZhao SongYufa Zhou</p>
                <p><a href="http://arxiv.org/abs/2408.13233v1">Link to paper</a></p>
                <p>The quadratic computational complexity in the self-attention mechanism ofpopular transformer architectures poses significant challenges for training andinference particularly in terms of efficiency and memory requirements. Towardsaddressing these challenges this paper introduces a novel fast computationmethod for gradient calculation in multi-layer transformer models. Our approachenables the computation of gradients for the entire multi-layer transformermodel in almost linear time n1o1 where n is the input sequencelength. This breakthrough significantly reduces the computational bottleneckassociated with the traditional quadratic time complexity. Our theory holds forany loss function and maintains a bounded approximation error across the entiremodel. Furthermore our analysis can hold when the multi-layer transformermodel contains many practical sub-modules such as residual connection casualmask and multi-head attention. By improving the efficiency of gradientcomputation in large language models we hope that our work will facilitate themore effective training and deployment of long-context language models based onour theoretical results.</p>
                <p>Last Updated: 2024-08-23 17:16:43 UTC</p>
                <button class="interpret-button" data-id="2408.13233v1">Interpret</button>
                <div id="interpretation-2408.13233v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Enhancing Few-Shot Transfer Learning with Optimized Multi-Task Prompt Tuning through Modular Prompt Composition</h3>
                <p>Authors: Ahmad PouraminiHesham Faili</p>
                <p><a href="http://arxiv.org/abs/2408.13227v1">Link to paper</a></p>
                <p>In recent years multi-task prompt tuning has garnered considerable attentionfor its inherent modularity and potential to enhance parameter-efficienttransfer learning across diverse tasks. This paper aims to analyze and improvethe performance of multiple tasks by facilitating the transfer of knowledgebetween their corresponding prompts in a multi-task setting. Our proposedapproach decomposes the prompt for each target task into a combination ofshared prompts source prompts and a task-specific prompt private prompt.During training the source prompts undergo fine-tuning and are integrated withthe private prompt to drive the target prompt for each task. We present andcompare multiple methods for combining source prompts to construct the targetprompt analyzing the roles of both source and private prompts within eachmethod. We investigate their contributions to task performance and offerflexible adjustable configurations based on these insights to optimizeperformance. Our empirical findings clearly showcase improvements in accuracyand robustness compared to the conventional practice of prompt tuning andrelated works. Notably our results substantially outperform other methods inthe field in few-shot settings demonstrating superior performance in varioustasks across GLUE benchmark among other tasks. This achievement is attainedwith a significantly reduced amount of training data making our method apromising one for few-shot settings.</p>
                <p>Last Updated: 2024-08-23 17:01:51 UTC</p>
                <button class="interpret-button" data-id="2408.13227v1">Interpret</button>
                <div id="interpretation-2408.13227v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>JacNet: Learning Functions with Structured Jacobians</h3>
                <p>Authors: Jonathan LorraineSafwan Hossain</p>
                <p><a href="http://arxiv.org/abs/2408.13237v1">Link to paper</a></p>
                <p>Neural networks are trained to learn an approximate mapping from an inputdomain to a target domain. Incorporating prior knowledge about true mappings iscritical to learning a useful approximation. With current architectures it ischallenging to enforce structure on the derivatives of the input-outputmapping. We propose to use a neural network to directly learn the Jacobian ofthe input-output function which allows easy control of the derivative. Wefocus on structuring the derivative to allow invertibility and also demonstratethat other useful priors such as k-Lipschitz can be enforced. Using thisapproach we can learn approximations to simple functions that are guaranteedto be invertible and easily compute the inverse. We also show similar resultsfor 1-Lipschitz functions.</p>
                <p>Last Updated: 2024-08-23 17:21:44 UTC</p>
                <button class="interpret-button" data-id="2408.13237v1">Interpret</button>
                <div id="interpretation-2408.13237v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Double Descent: Understanding Linear Model Estimation of Nonidentifiable Parameters and a Model for Overfitting</h3>
                <p>Authors: Ronald Christensen</p>
                <p><a href="http://arxiv.org/abs/2408.13235v1">Link to paper</a></p>
                <p>We consider ordinary least squares estimation and variations on least squaresestimation such as penalized regularized least squares and spectral shrinkageestimates for problems with p  n and associated problems with prediction ofnew observations. After the introduction of Section 1 Section 2 examines anumber of commonly used estimators for p  n. Section 3 introduces predictionwith p  n. Section 4 introduces notational changes to facilitate discussion ofoverfitting and Section 5 illustrates the phenomenon of double descent. Weconclude with some final comments.</p>
                <p>Last Updated: 2024-08-23 17:19:17 UTC</p>
                <button class="interpret-button" data-id="2408.13235v1">Interpret</button>
                <div id="interpretation-2408.13235v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>On the design of scalable, high-precision spherical-radial Fourier features</h3>
                <p>Authors: Ayoub BelhadjiQianyu Julie ZhuYoussef Marzouk</p>
                <p><a href="http://arxiv.org/abs/2408.13231v1">Link to paper</a></p>
                <p>Approximation using Fourier features is a popular technique for scalingkernel methods to large-scale problems with myriad applications in machinelearning and statistics. This method replaces the integral representation of ashift-invariant kernel with a sum using a quadrature rule. The design of thelatter is meant to reduce the number of features required for high-precisionapproximation. Specifically for the squared exponential kernel one mustdesign a quadrature rule that approximates the Gaussian measure onmathbbRd. Previous efforts in this line of research have faceddifficulties in higher dimensions. We introduce a new family of quadraturerules that accurately approximate the Gaussian measure in higher dimensions byexploiting its isotropy. These rules are constructed as a tensor product of aradial quadrature rule and a spherical quadrature rule. Compared to previouswork our approach leverages a thorough analysis of the approximation errorwhich suggests natural choices for both the radial and spherical components. Wedemonstrate that this family of Fourier features yields improved approximationbounds.</p>
                <p>Last Updated: 2024-08-23 17:11:25 UTC</p>
                <button class="interpret-button" data-id="2408.13231v1">Interpret</button>
                <div id="interpretation-2408.13231v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Amortized Bayesian Multilevel Models</h3>
                <p>Authors: Daniel HabermannMarvin SchmittLars KühmichelAndreas BullingStefan T. RadevPaul-Christian Bürkner</p>
                <p><a href="http://arxiv.org/abs/2408.13230v1">Link to paper</a></p>
                <p>Multilevel models MLMs are a central building block of the Bayesianworkflow. They enable joint interpretable modeling of data across hierarchicallevels and provide a fully probabilistic quantification of uncertainty. Despitetheir well-recognized advantages MLMs pose significant computationalchallenges often rendering their estimation and evaluation intractable withinreasonable time constraints. Recent advances in simulation-based inferenceoffer promising solutions for addressing complex probabilistic models usingdeep generative networks. However the utility and reliability of deep learningmethods for estimating Bayesian MLMs remains largely unexplored especiallywhen compared with gold-standard samplers. To this end we explore a family ofneural network architectures that leverage the probabilistic factorization ofmultilevel models to facilitate efficient neural network training andsubsequent near-instant posterior inference on unseen data sets. We test ourmethod on several real-world case studies and provide comprehensive comparisonsto Stan as a gold-standard method where possible. Finally we provide anopen-source implementation of our methods to stimulate further research in thenascent field of amortized Bayesian inference.</p>
                <p>Last Updated: 2024-08-23 17:11:04 UTC</p>
                <button class="interpret-button" data-id="2408.13230v1">Interpret</button>
                <div id="interpretation-2408.13230v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>An Overview on Machine Learning Methods for Partial Differential Equations: from Physics Informed Neural Networks to Deep Operator Learning</h3>
                <p>Authors: Lukas GononArnulf JentzenBenno KuckuckSiyu LiangAdrian RiekertPhilippe von Wurstemberger</p>
                <p><a href="http://arxiv.org/abs/2408.13222v1">Link to paper</a></p>
                <p>The approximation of solutions of partial differential equations PDEs withnumerical algorithms is a central topic in applied mathematics. For manydecades various types of methods for this purpose have been developed andextensively studied. One class of methods which has received a lot of attentionin recent years are machine learning-based methods which typically involve thetraining of artificial neural networks ANNs by means of stochastic gradientdescent type optimization methods. While approximation methods for PDEs usingANNs have first been proposed in the 1990s they have only gained widepopularity in the last decade with the rise of deep learning. This article aimsto provide an introduction to some of these methods and the mathematical theoryon which they are based. We discuss methods such as physics-informed neuralnetworks PINNs and deep BSDE methods and consider several operator learningapproaches.</p>
                <p>Last Updated: 2024-08-23 16:57:34 UTC</p>
                <button class="interpret-button" data-id="2408.13222v1">Interpret</button>
                <div id="interpretation-2408.13222v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>How Diffusion Models Learn to Factorize and Compose</h3>
                <p>Authors: Qiyao LiangZiming LiuMitchell OstrowIla Fiete</p>
                <p><a href="http://arxiv.org/abs/2408.13256v1">Link to paper</a></p>
                <p>Diffusion models are capable of generating photo-realistic images thatcombine elements which likely do not appear together in the training setdemonstrating the ability to compositionally generalize. Nonetheless theprecise mechanism of compositionality and how it is acquired through trainingremains elusive. Inspired by cognitive neuroscientific approaches we considera highly reduced setting to examine whether and when diffusion models learnsemantically meaningful and factorized representations of composable features.We performed extensive controlled experiments on conditional DenoisingDiffusion Probabilistic Models DDPMs trained to generate various forms of 2DGaussian data. We found that the models learn factorized but not fullycontinuous manifold representations for encoding continuous features ofvariation underlying the data. With such representations models demonstratesuperior feature compositionality but limited ability to interpolate overunseen values of a given feature. Our experimental results further demonstratethat diffusion models can attain compositionality with few compositionalexamples suggesting a more efficient way to train DDPMs. Finally we connectmanifold formation in diffusion models to percolation theory in physicsoffering insight into the sudden onset of factorized representation learning.Our thorough toy experiments thus contribute a deeper understanding of howdiffusion models capture compositional structure in data.</p>
                <p>Last Updated: 2024-08-23 17:59:03 UTC</p>
                <button class="interpret-button" data-id="2408.13256v1">Interpret</button>
                <div id="interpretation-2408.13256v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Ensemble Modeling of Multiple Physical Indicators to Dynamically Phenotype Autism Spectrum Disorder</h3>
                <p>Authors: Marie HuynhAaron KlineSaimourya SurabhiKaitlyn DunlapOnur Cezmi MutluMohammadmahdi HonarmandParnian AzizianPeter WashingtonDennis P. Wall</p>
                <p><a href="http://arxiv.org/abs/2408.13255v1">Link to paper</a></p>
                <p>Early detection of autism a neurodevelopmental disorder marked by socialcommunication challenges is crucial for timely intervention. Recentadvancements have utilized naturalistic home videos captured via the mobileapplication GuessWhat. Through interactive games played between children andtheir guardians GuessWhat has amassed over 3000 structured videos from 382children both diagnosed with and without Autism Spectrum Disorder ASD. Thiscollection provides a robust dataset for training computer vision models todetect ASD-related phenotypic markers including variations in emotionalexpression eye contact and head movements. We have developed a protocol tocurate high-quality videos from this dataset forming a comprehensive trainingset. Utilizing this set we trained individual LSTM-based models using eyegaze head positions and facial landmarks as input features achieving testAUCs of 86 67 and 78 respectively. To boost diagnostic accuracy weapplied late fusion techniques to create ensemble models improving the overallAUC to 90. This approach also yielded more equitable results across differentgenders and age groups. Our methodology offers a significant step forward inthe early detection of ASD by potentially reducing the reliance on subjectiveassessments and making early identification more accessibly and equitable.</p>
                <p>Last Updated: 2024-08-23 17:55:58 UTC</p>
                <button class="interpret-button" data-id="2408.13255v1">Interpret</button>
                <div id="interpretation-2408.13255v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Foundational Model for Electron Micrograph Analysis: Instruction-Tuning Small-Scale Language-and-Vision Assistant for Enterprise Adoption</h3>
                <p>Authors: Sakhinana Sagar SrinivasChidaksh RavuruGeethan SannidhiVenkataramana Runkana</p>
                <p><a href="http://arxiv.org/abs/2408.13248v1">Link to paper</a></p>
                <p>Semiconductor imaging and analysis are critical yet understudied in deeplearning limiting our ability for precise control and optimization insemiconductor manufacturing. We introduce a small-scale multimodal frameworkfor analyzing semiconductor electron microscopy images MAEMI throughvision-language instruction tuning. We generate a customizedinstruction-following dataset using large multimodal models on microscopicimage analysis. We perform knowledge transfer from larger to smaller modelsthrough knowledge distillation resulting in improved accuracy of smallermodels on visual question answering VQA tasks. This approach eliminates theneed for expensive human expert-annotated datasets for microscopic imageanalysis tasks. Enterprises can further finetune MAEMI on their intellectualdata enhancing privacy and performance on low-cost consumer hardware. Ourexperiments show that MAEMI outperforms traditional methods adapts to datadistribution shifts and supports high-throughput screening.</p>
                <p>Last Updated: 2024-08-23 17:42:11 UTC</p>
                <button class="interpret-button" data-id="2408.13248v1">Interpret</button>
                <div id="interpretation-2408.13248v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Data Exposure from LLM Apps: An In-depth Investigation of OpenAI's GPTs</h3>
                <p>Authors: Evin JaffYuhao WuNing ZhangUmar Iqbal</p>
                <p><a href="http://arxiv.org/abs/2408.13247v1">Link to paper</a></p>
                <p>LLM app ecosystems are quickly maturing and supporting a wide range of usecases which requires them to collect excessive user data. Given that the LLMapps are developed by third-parties and that anecdotal evidence suggests LLMplatforms currently do not strictly enforce their policies user data sharedwith arbitrary third-parties poses a significant privacy risk. In this paper weaim to bring transparency in data practices of LLM apps. As a case study westudy OpenAIs GPT app ecosystem. We develop an LLM-based framework to conductthe static analysis of natural language-based source code of GPTs and theirActions external services to characterize their data collection practices.Our findings indicate that Actions collect expansive data about usersincluding sensitive information prohibited by OpenAI such as passwords. Wefind that some Actions including related to advertising and analytics areembedded in multiple GPTs which allow them to track user activities acrossGPTs. Additionally co-occurrence of Actions exposes as much as 9.5x more datato them than it is exposed to individual Actions. Lastly we develop anLLM-based privacy policy analysis framework to automatically check theconsistency of data collection by Actions with disclosures in their privacypolicies. Our measurements indicate that the disclosures for most of thecollected data types are omitted in privacy policies with only 5.8 of Actionsclearly disclosing their data collection practices.</p>
                <p>Last Updated: 2024-08-23 17:42:06 UTC</p>
                <button class="interpret-button" data-id="2408.13247v1">Interpret</button>
                <div id="interpretation-2408.13247v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>JacNet: Learning Functions with Structured Jacobians</h3>
                <p>Authors: Jonathan LorraineSafwan Hossain</p>
                <p><a href="http://arxiv.org/abs/2408.13237v1">Link to paper</a></p>
                <p>Neural networks are trained to learn an approximate mapping from an inputdomain to a target domain. Incorporating prior knowledge about true mappings iscritical to learning a useful approximation. With current architectures it ischallenging to enforce structure on the derivatives of the input-outputmapping. We propose to use a neural network to directly learn the Jacobian ofthe input-output function which allows easy control of the derivative. Wefocus on structuring the derivative to allow invertibility and also demonstratethat other useful priors such as k-Lipschitz can be enforced. Using thisapproach we can learn approximations to simple functions that are guaranteedto be invertible and easily compute the inverse. We also show similar resultsfor 1-Lipschitz functions.</p>
                <p>Last Updated: 2024-08-23 17:21:44 UTC</p>
                <button class="interpret-button" data-id="2408.13237v1">Interpret</button>
                <div id="interpretation-2408.13237v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-08-26</p>
        </div>
    
        </div>
    </body>
    </html>
    