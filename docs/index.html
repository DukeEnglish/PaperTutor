
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Research Papers</title>
        <link rel="stylesheet" href="style.css">
        <script src="script.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    </head>
    <body>
        <div id="sidebar">
            <h3>Papers by Category:</h3>
            <ul id="categories">
    
                <li><a href="#cs.CL">cs.CL</a></li>
            
                <li><a href="#cs.HC">cs.HC</a></li>
            
                <li><a href="#stat.ML">stat.ML</a></li>
            
                <li><a href="#cs.AI">cs.AI</a></li>
            
                <li><a href="#cs.LG">cs.LG</a></li>
            
                <li><a href="#cs.CV">cs.CV</a></li>
            
                <li><a href="#cs.MA">cs.MA</a></li>
            
            </ul>
            <li>
                    <a href="https://github.com/DukeEnglish/papertutor" target="_blank" rel="noopener noreferrer">
                        <span class="fab fa-github"></span> GitHub
                    </a>
            </li>
        </div>
        <div id="content">
    
    <section id="cs.CL">
        <h2>cs.CL</h2>
        <ul>
    
            <li>
                <h3>LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning</h3>
                <p>Authors: Rui PanXiang LiuShizhe DiaoRenjie PiJipeng ZhangChi HanTong Zhang</p>
                <p><a href="http://arxiv.org/abs/2403.17919v1">Link to paper</a></p>
                <p>The machine learning community has witnessed impressive advancements sincethe first appearance of large language models LLMs yet their huge memoryconsumption has become a major roadblock to large-scale training. ParameterEfficient Fine-Tuning techniques such as Low-Rank Adaptation LoRA have beenproposed to alleviate this problem but their performance still fails to matchfull parameter training in most large-scale fine-tuning settings. Attempting tocomplement this deficiency we investigate layerwise properties of LoRA onfine-tuning tasks and observe an uncommon skewness of weight norms acrossdifferent layers. Utilizing this key observation a surprisingly simpletraining strategy is discovered which outperforms both LoRA and full parametertraining in a wide range of settings with memory costs as low as LoRA. We nameit Layerwise Importance Sampled AdamW LISA a promising alternative for LoRAwhich applies the idea of importance sampling to different layers in LLMs andrandomly freeze most middle layers during optimization. Experimental resultsshow that with similar or less GPU memory consumption LISA surpasses LoRA oreven full parameter tuning in downstream fine-tuning tasks where LISAconsistently outperforms LoRA by over 11-37 in terms of MT-Benchscores. On large models specifically LLaMA-2-70B LISA achieves on-par orbetter performance than LoRA on MT-Bench GSM8K and PubMedQA demonstratingits effectiveness across different domains.</p>
                <p>Last Updated: 2024-03-26 17:55:02 UTC</p>
                <button class="interpret-button" data-id="2403.17919v1">Interpret</button>
                <div id="interpretation-2403.17919v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The Unreasonable Ineffectiveness of the Deeper Layers</h3>
                <p>Authors: Andrey GromovKushal TirumalaHassan ShapourianPaolo GloriosoDaniel A. Roberts</p>
                <p><a href="http://arxiv.org/abs/2403.17887v1">Link to paper</a></p>
                <p>We empirically study a simple layer-pruning strategy for popular families ofopen-weight pretrained LLMs finding minimal degradation of performance ondifferent question-answering benchmarks until after a large fraction up tohalf of the layers are removed. To prune these models we identify the optimalblock of layers to prune by considering similarity across layers then toheal the damage we perform a small amount of finetuning. In particular weuse parameter-efficient finetuning PEFT methods specifically quantizationand Low Rank Adapters QLoRA such that each of our experiments can beperformed on a single A100 GPU. From a practical perspective these resultssuggest that layer pruning methods can complement other PEFT strategies tofurther reduce computational resources of finetuning on the one hand and canimprove the memory and latency of inference on the other hand. From ascientific perspective the robustness of these LLMs to the deletion of layersimplies either that current pretraining methods are not properly leveraging theparameters in the deeper layers of the network or that the shallow layers playa critical role in storing knowledge.</p>
                <p>Last Updated: 2024-03-26 17:20:04 UTC</p>
                <button class="interpret-button" data-id="2403.17887v1">Interpret</button>
                <div id="interpretation-2403.17887v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Exploring LLMs as a Source of Targeted Synthetic Textual Data to Minimize High Confidence Misclassifications</h3>
                <p>Authors: Philip LippmannMatthijs SpaanJie Yang</p>
                <p><a href="http://arxiv.org/abs/2403.17860v1">Link to paper</a></p>
                <p>Natural Language Processing NLP models optimized for predictive performanceoften make high confidence errors and suffer from vulnerability to adversarialand out-of-distribution data. Existing work has mainly focused on mitigation ofsuch errors using either humans or an automated approach. In this study weexplore the usage of large language models LLMs for data augmentation as apotential solution to the issue of NLP models making wrong predictions withhigh confidence during classification tasks. We compare the effectiveness ofsynthetic data generated by LLMs with that of human data obtained via the sameprocedure. For mitigation humans or LLMs provide natural languagecharacterizations of high confidence misclassifications to generate syntheticdata which are then used to extend the training set. We conduct an extensiveevaluation of our approach on three classification tasks and demonstrate itseffectiveness in reducing the number of high confidence misclassificationspresent in the model all while maintaining the same level of accuracy.Moreover we find that the cost gap between humans and LLMs surpasses an orderof magnitude as LLMs attain human-like performance while being more scalable.</p>
                <p>Last Updated: 2024-03-26 16:49:25 UTC</p>
                <button class="interpret-button" data-id="2403.17860v1">Interpret</button>
                <div id="interpretation-2403.17860v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on Historical American Newspaper Pages</h3>
                <p>Authors: Bhawna PiryaniJamshid MozafariAdam Jatowt</p>
                <p><a href="http://arxiv.org/abs/2403.17859v1">Link to paper</a></p>
                <p>Question answering QA and Machine Reading Comprehension MRC tasks havesignificantly advanced in recent years due to the rapid development of deeplearning techniques and more recently large language models. At the sametime many benchmark datasets have become available for QA and MRC tasks.However most existing large-scale benchmark datasets have been createdpredominantly using synchronous document collections like Wikipedia or the Web.Archival document collections such as historical newspapers contain valuableinformation from the past that is still not widely used to train large languagemodels. To further contribute to advancing QA and MRC tasks and to overcome thelimitation of previous datasets we introduce ChroniclingAmericaQA alarge-scale dataset with 485K question-answer pairs created based on thehistorical newspaper collection Chronicling America. Our dataset is constructedfrom a subset of the Chronicling America newspaper collection spanning 120years. One of the significant challenges for utilizing digitized historicalnewspaper collections is the low quality of OCR text. Therefore to enablerealistic testing of QA models our dataset can be used in three differentways: answering questions from raw and noisy content answering questions fromcleaner corrected version of the content as well as answering questions fromscanned images of newspaper pages. This and the fact that ChroniclingAmericaQAspans the longest time period among available QA datasets make it quite aunique and useful resource.</p>
                <p>Last Updated: 2024-03-26 16:48:13 UTC</p>
                <button class="interpret-button" data-id="2403.17859v1">Interpret</button>
                <div id="interpretation-2403.17859v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Verbing Weirds Language (Models): Evaluation of English Zero-Derivation in Five LLMs</h3>
                <p>Authors: David R. MortensenValentina IzrailevitchYunze XiaoHinrich Sch√ºtzeLeonie Weissweiler</p>
                <p><a href="http://arxiv.org/abs/2403.17856v1">Link to paper</a></p>
                <p>Lexical-syntactic flexibility in the form of conversion or zero-derivationis a hallmark of English morphology. In conversion a word with one part ofspeech is placed in a non-prototypical context where it is coerced to behaveas if it had a different part of speech. However while this process affects alarge part of the English lexicon little work has been done to establish thedegree to which language models capture this type of generalization. This paperreports the first study on the behavior of large language models with referenceto conversion. We design a task for testing lexical-syntactic flexibility --the degree to which models can generalize over words in a construction with anon-prototypical part of speech. This task is situated within a naturallanguage inference paradigm. We test the abilities of five language models --two proprietary models GPT-3.5 and GPT-4 three open-source models Mistral7B Falcon 40B and Llama 2 70B. We find that GPT-4 performs best on the taskfollowed by GPT-3.5 but that the open source language models are also able toperform it and that the 7B parameter Mistral displays as little differencebetween its baseline performance on the natural language inference task and thenon-prototypical syntactic category task as the massive GPT-4.</p>
                <p>Last Updated: 2024-03-26 16:45:27 UTC</p>
                <button class="interpret-button" data-id="2403.17856v1">Interpret</button>
                <div id="interpretation-2403.17856v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.HC">
        <h2>cs.HC</h2>
        <ul>
    
            <li>
                <h3>A Sociotechnical Framework For Addressing Stigma and Designing Personalized Digital Health Products</h3>
                <p>Authors: Danielly de PaulaDaniel JuehlingFalk Uebernickel</p>
                <p><a href="http://arxiv.org/abs/2403.17843v1">Link to paper</a></p>
                <p>Stigma a recognized global barrier to effective disease management impactssocial interactions resource access and psychological well-being. In thisstudy we developed a patient-centered framework for deriving designrequirements and interventions for health conditions subject to social stigma.This study introduces a patient-centered framework grounded in sociotechnicalsystems theory to create tailored interventions and design requirements forhealth conditions influenced by social stigma. We tested this framework througha mixed-method study on chronic pelvic pain patients. Our approach led to theidentification of ten design requirements that encompass behavioral andpsychological support and strategies for day-to-day living. The findings reveala preference among CPP patients for priming and social support interventions.This study underscores the value of a systems-based perspective in healthcareadvocating for a nuanced patient-centered approach that addresses the complexnature of health conditions affected by social stigma. It contributes to theongoing discourse on integrating STS theory into healthcare frameworkshighlighting the need for targeted strategies to combat the complexities ofstigma in patient care.</p>
                <p>Last Updated: 2024-03-26 16:30:36 UTC</p>
                <button class="interpret-button" data-id="2403.17843v1">Interpret</button>
                <div id="interpretation-2403.17843v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Towards Inclusive Video Commenting: Introducing Signmaku for the Deaf and Hard-of-Hearing</h3>
                <p>Authors: Si ChenHaocong ChengJason SituDesir√©e KirstSuzy SuSaumya MalhotraLawrence AngraveQi WangYun Huang</p>
                <p><a href="http://arxiv.org/abs/2403.17807v1">Link to paper</a></p>
                <p>Previous research underscored the potential of danmaku--a text-basedcommenting feature on videos--in engaging hearing audiences. Yet for many Deafand hard-of-hearing DHH individuals American Sign Language ASL takesprecedence over English. To improve inclusivity we introduce Signmaku a newcommenting mechanism that uses ASL serving as a sign language counterpart todanmaku. Through a need-finding study N12 and a within-subject experimentN20 we evaluated three design styles: real human faces cartoon-likefigures and robotic representations. The results showed that cartoon-likesignmaku not only entertained but also encouraged participants to create andshare ASL comments with fewer privacy concerns compared to the other designs.Conversely the robotic representations faced challenges in accuratelydepicting hand movements and facial expressions resulting in higher cognitivedemands on users. Signmaku featuring real human faces elicited the lowestcognitive load and was the most comprehensible among all three types. Ourfindings offered novel design implications for leveraging generative AI tocreate signmaku comments enriching co-learning experiences for DHHindividuals.</p>
                <p>Last Updated: 2024-03-26 15:45:07 UTC</p>
                <button class="interpret-button" data-id="2403.17807v1">Interpret</button>
                <div id="interpretation-2403.17807v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>SciCapenter: Supporting Caption Composition for Scientific Figures with Machine-Generated Captions and Ratings</h3>
                <p>Authors: Ting-Yao HsuChieh-Yang HuangShih-Hong HuangRyan RossiSungchul KimTong YuC. Lee GilesTing-Hao K. Huang</p>
                <p><a href="http://dx.doi.org/10.1145/3613905.3650738">Link to paper</a></p>
                <p>Crafting effective captions for figures is important. Readers heavily dependon these captions to grasp the figures message. However despite awell-developed set of AI technologies for figures and captions these haverarely been tested for usefulness in aiding caption writing. This paperintroduces SciCapenter an interactive system that puts together cutting-edgeAI technologies for scientific figure captions to aid caption composition.SciCapenter generates a variety of captions for each figure in a scholarlyarticle providing scores and a comprehensive checklist to assess captionquality across multiple critical aspects such as helpfulness OCR mention keytakeaways and visual properties reference. Users can directly edit captions inSciCapenter resubmit for revised evaluations and iteratively refine them. Auser study with Ph.D. students indicates that SciCapenter significantly lowersthe cognitive load of caption writing. Participants feedback further offersvaluable design insights for future systems aiming to enhance caption writing.</p>
                <p>Last Updated: 2024-03-26 15:16:14 UTC</p>
                <button class="interpret-button" data-id="2403.17784v1">Interpret</button>
                <div id="interpretation-2403.17784v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Exploring the Boundaries of Ambient Awareness in Twitter</h3>
                <p>Authors: Pablo Sanchez-MartinSonja UtzIsabel Valera</p>
                <p><a href="http://arxiv.org/abs/2403.17776v1">Link to paper</a></p>
                <p>Ambient awareness refers to the ability of social media users to obtainknowledge about who knows what i.e. users expertise in their network bysimply being exposed to other users content e.g tweets on Twitter. Previouswork based on user surveys reveals that individuals self-report ambientawareness only for parts of their networks. However it is unclear whether itis their limited cognitive capacity or the limited exposure to diagnostictweets i.e. online content that prevents people from developing ambientawareness for their complete network. In this work we focus on in-wall ambientawareness IWAA in Twitter and conduct a two-step data-driven analysis thatallows us to explore to which extent IWAA is likely or even possible. Firstwe rely on reactions e.g. likes as strong evidence of users being aware ofexperts in Twitter. Unfortunately such strong evidence can be only measuredfor active users which represent the minority in the network. Thus to studythe boundaries of IWAA to a larger extent in the second part of our analysiswe instead focus on the passive exposure to content generated by other users --which we refer to as in-wall visibility. This analysis shows that in line withcitetlevordashka2016ambient only for a subset of users IWAA is plausiblewhile for the majority it is unlikely if even possible to develop IWAA. Wehope that our methodology paves the way for the emergence of data-drivenapproaches for the study of ambient awareness.</p>
                <p>Last Updated: 2024-03-26 15:09:33 UTC</p>
                <button class="interpret-button" data-id="2403.17776v1">Interpret</button>
                <div id="interpretation-2403.17776v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>FastPerson: Enhancing Video Learning through Effective Video Summarization that Preserves Linguistic and Visual Contexts</h3>
                <p>Authors: Kazuki KawamuraJun Rekimoto</p>
                <p><a href="http://dx.doi.org/10.1145/3652920.3652922">Link to paper</a></p>
                <p>Quickly understanding lengthy lecture videos is essential for learners withlimited time and interest in various topics to improve their learningefficiency. To this end video summarization has been actively researched toenable users to view only important scenes from a video. However these studiesfocus on either the visual or audio information of a video and extractimportant segments in the video. Therefore there is a risk of missingimportant information when both the teachers speech and visual information onthe blackboard or slides are important such as in a lecture video. To tacklethis issue we propose FastPerson a video summarization approach thatconsiders both the visual and auditory information in lecture videos.FastPerson creates summary videos by utilizing audio transcriptions along withon-screen images and text minimizing the risk of overlooking crucialinformation for learners. Further it provides a feature that allows learnersto switch between the summary and original videos for each chapter of thevideo enabling them to adjust the pace of learning based on their interestsand level of understanding. We conducted an evaluation with 40 participants toassess the effectiveness of our method and confirmed that it reduced viewingtime by 53 at the same level of comprehension as that when using traditionalvideo playback methods.</p>
                <p>Last Updated: 2024-03-26 14:16:56 UTC</p>
                <button class="interpret-button" data-id="2403.17727v1">Interpret</button>
                <div id="interpretation-2403.17727v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="stat.ML">
        <h2>stat.ML</h2>
        <ul>
    
            <li>
                <h3>The Unreasonable Ineffectiveness of the Deeper Layers</h3>
                <p>Authors: Andrey GromovKushal TirumalaHassan ShapourianPaolo GloriosoDaniel A. Roberts</p>
                <p><a href="http://arxiv.org/abs/2403.17887v1">Link to paper</a></p>
                <p>We empirically study a simple layer-pruning strategy for popular families ofopen-weight pretrained LLMs finding minimal degradation of performance ondifferent question-answering benchmarks until after a large fraction up tohalf of the layers are removed. To prune these models we identify the optimalblock of layers to prune by considering similarity across layers then toheal the damage we perform a small amount of finetuning. In particular weuse parameter-efficient finetuning PEFT methods specifically quantizationand Low Rank Adapters QLoRA such that each of our experiments can beperformed on a single A100 GPU. From a practical perspective these resultssuggest that layer pruning methods can complement other PEFT strategies tofurther reduce computational resources of finetuning on the one hand and canimprove the memory and latency of inference on the other hand. From ascientific perspective the robustness of these LLMs to the deletion of layersimplies either that current pretraining methods are not properly leveraging theparameters in the deeper layers of the network or that the shallow layers playa critical role in storing knowledge.</p>
                <p>Last Updated: 2024-03-26 17:20:04 UTC</p>
                <button class="interpret-button" data-id="2403.17887v1">Interpret</button>
                <div id="interpretation-2403.17887v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Counterfactual Fairness through Transforming Data Orthogonal to Bias</h3>
                <p>Authors: Shuyi ChenShixiang Zhu</p>
                <p><a href="http://arxiv.org/abs/2403.17852v1">Link to paper</a></p>
                <p>Machine learning models have shown exceptional prowess in solving complexissues across various domains. Nonetheless these models can sometimes exhibitbiased decision-making leading to disparities in treatment across differentgroups. Despite the extensive research on fairness the nuanced effects ofmultivariate and continuous sensitive variables on decision-making outcomesremain insufficiently studied. We introduce a novel data pre-processingalgorithm Orthogonal to Bias OB designed to remove the influence of a groupof continuous sensitive variables thereby facilitating counterfactual fairnessin machine learning applications. Our approach is grounded in the assumption ofa jointly normal distribution within a structural causal model SCM provingthat counterfactual fairness can be achieved by ensuring the data isuncorrelated with sensitive variables. The OB algorithm is model-agnosticcatering to a wide array of machine learning models and tasks and includes asparse variant to enhance numerical stability through regularization. Throughempirical evaluation on simulated and real-world datasets - including the adultincome and the COMPAS recidivism datasets - our methodology demonstrates itscapacity to enable fairer outcomes without compromising accuracy.</p>
                <p>Last Updated: 2024-03-26 16:40:08 UTC</p>
                <button class="interpret-button" data-id="2403.17852v1">Interpret</button>
                <div id="interpretation-2403.17852v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Towards Multilevel Modelling of Train Passing Events on the Staffordshire Bridge</h3>
                <p>Authors: Lawrence A. BullChiho JeonMark GirolamiAndrew DuncanJennifer SchoolingMiguel Bravo Haro</p>
                <p><a href="http://dx.doi.org/10.12783/shm2023/37066">Link to paper</a></p>
                <p>We suggest a multilevel model to represent aggregate train-passing eventsfrom the Staffordshire bridge monitoring system. We formulate a combined modelfrom simple units representing strain envelopes of each train passing fortwo types of commuter train. The measurements are treated as a longitudinaldataset and represented with a low-rank approximation hierarchical Gaussianprocess. For each unit in the combined model we encode domain expertise asboundary condition constraints and work towards a general representation of thestrain response. Looking forward this should allow for the simulation of traintypes that were previously unobserved in the training data. For example trainswith more passengers or freights with a heavier payload. The strain eventsimulations are valuable since they can inform further experiments includingFEM calibration fatigue analysis or design to test the bridge inhypothesised scenarios.</p>
                <p>Last Updated: 2024-03-26 15:55:54 UTC</p>
                <button class="interpret-button" data-id="2403.17820v1">Interpret</button>
                <div id="interpretation-2403.17820v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Asymptotic Bayes risk of semi-supervised learning with uncertain labeling</h3>
                <p>Authors: Victor LegerRomain Couillet</p>
                <p><a href="http://arxiv.org/abs/2403.17767v1">Link to paper</a></p>
                <p>This article considers a semi-supervised classification setting on a Gaussianmixture model where the data is not labeled strictly as usual but insteadwith uncertain labels. Our main aim is to compute the Bayes risk for thismodel. We compare the behavior of the Bayes risk and the best known algorithmfor this model. This comparison eventually gives new insights over thealgorithm.</p>
                <p>Last Updated: 2024-03-26 14:54:35 UTC</p>
                <button class="interpret-button" data-id="2403.17767v1">Interpret</button>
                <div id="interpretation-2403.17767v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>On the Benefits of Over-parameterization for Out-of-Distribution Generalization</h3>
                <p>Authors: Yifan HaoYong LinDifan ZouTong Zhang</p>
                <p><a href="http://arxiv.org/abs/2403.17592v1">Link to paper</a></p>
                <p>In recent years machine learning models have achieved success based on theindependently and identically distributed assumption. However this assumptioncan be easily violated in real-world applications leading to theOut-of-Distribution OOD problem. Understanding how modern over-parameterizedDNNs behave under non-trivial natural distributional shifts is essential ascurrent theoretical understanding is insufficient. Existing theoretical worksoften provide meaningless results for over-parameterized models in OODscenarios or even contradict empirical findings. To this end we areinvestigating the performance of the over-parameterized model in terms of OODgeneralization under the general benign overfitting conditions. Our analysisfocuses on a random feature model and examines non-trivial naturaldistributional shifts where the benign overfitting estimators demonstrate aconstant excess OOD loss despite achieving zero excess in-distribution IDloss. We demonstrate that in this scenario further increasing the modelsparameterization can significantly reduce the OOD loss. Intuitively thevariance term of ID loss remains low due to orthogonality of long-tailfeatures meaning overfitting noise during training generally doesnt raisetesting loss. However in OOD cases distributional shift increases thevariance term. Thankfully the inherent shift is unrelated to individual xmaintaining the orthogonality of long-tail features. Expanding the hiddendimension can additionally improve this orthogonality by mapping the featuresinto higher-dimensional spaces thereby reducing the variance term. We furthershow that model ensembles also improve OOD loss akin to increasing modelcapacity. These insights explain the empirical phenomenon of enhanced OODgeneralization through model ensembles supported by consistent simulationswith theoretical results.</p>
                <p>Last Updated: 2024-03-26 11:01:53 UTC</p>
                <button class="interpret-button" data-id="2403.17592v1">Interpret</button>
                <div id="interpretation-2403.17592v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.AI">
        <h2>cs.AI</h2>
        <ul>
    
            <li>
                <h3>SLEDGE: Synthesizing Simulation Environments for Driving Agents with Generative Models</h3>
                <p>Authors: Kashyap ChittaDaniel DaunerAndreas Geiger</p>
                <p><a href="http://arxiv.org/abs/2403.17933v1">Link to paper</a></p>
                <p>SLEDGE is the first generative simulator for vehicle motion planning trainedon real-world driving logs. Its core component is a learned model that is ableto generate agent bounding boxes and lane graphs. The models outputs serve asan initial state for traffic simulation. The unique properties of the entitiesto be generated for SLEDGE such as their connectivity and variable count perscene render the naive application of most modern generative models to thistask non-trivial. Therefore together with a systematic study of existing lanegraph representations we introduce a novel raster-to-vector autoencoderRVAE. It encodes agents and the lane graph into distinct channels in arasterized latent map. This facilitates both lane-conditioned agent generationand combined generation of lanes and agents with a Diffusion Transformer. Usinggenerated entities in SLEDGE enables greater control over the simulation e.g.upsampling turns or increasing traffic density. Further SLEDGE can support500m long routes a capability not found in existing data-driven simulatorslike nuPlan. It presents new challenges for planning algorithms evidenced byfailure rates of over 40 for PDM the winner of the 2023 nuPlan challengewhen tested on hard routes and dense traffic generated by our model. Comparedto nuPlan SLEDGE requires 500times less storage to set up 4GB making ita more accessible option and helping with democratizing future research in thisfield.</p>
                <p>Last Updated: 2024-03-26 17:58:29 UTC</p>
                <button class="interpret-button" data-id="2403.17933v1">Interpret</button>
                <div id="interpretation-2403.17933v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution</h3>
                <p>Authors: Wei TaoYucheng ZhouWenqiang ZhangYu Cheng</p>
                <p><a href="http://arxiv.org/abs/2403.17927v1">Link to paper</a></p>
                <p>In software evolution resolving the emergent issues within GitHubrepositories is a complex challenge that involves not only the incorporation ofnew code but also the maintenance of existing functionalities. Large LanguageModels LLMs have shown promise in code generation and understanding but facedifficulties in code change particularly at the repository level. To overcomethese challenges we empirically study the reason why LLMs mostly fail toresolve GitHub issues and analyze some impact factors. Motivated by theempirical findings we propose a novel LLM-based Multi-Agent framework forGitHub Issue reSolution MAGIS consisting of four kinds of agents customizedfor the software evolution: Manager Repository Custodian Developer andQuality Assurance Engineer agents. This framework leverages the collaborationof various agents in the planning and coding process to unlock the potential ofLLMs to resolve GitHub issues. In experiments we employ the SWE-benchbenchmark to compare MAGIS with popular LLMs including GPT-3.5 GPT-4 andClaude-2. MAGIS can resolve 13.94 GitHub issues which significantlyoutperforms the baselines. Specifically MAGIS achieves an eight-fold increasein resolved ratio over the direct application of GPT-4 the based LLM of ourmethod. We also analyze the factors for improving GitHub issue resolutionrates such as line location task allocation etc.</p>
                <p>Last Updated: 2024-03-26 17:57:57 UTC</p>
                <button class="interpret-button" data-id="2403.17927v1">Interpret</button>
                <div id="interpretation-2403.17927v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>AID: Attention Interpolation of Text-to-Image Diffusion</h3>
                <p>Authors: Qiyuan HeJinghao WangZiwei LiuAngela Yao</p>
                <p><a href="http://arxiv.org/abs/2403.17924v1">Link to paper</a></p>
                <p>Conditional diffusion models can create unseen images in various settingsaiding image interpolation. Interpolation in latent spaces is well-studied butinterpolation with specific conditions like text or poses is less understood.Simple approaches such as linear interpolation in the space of conditionsoften result in images that lack consistency smoothness and fidelity. To thatend we introduce a novel training-free technique named Attention Interpolationvia Diffusion AID. Our key contributions include 1 proposing an inner/outerinterpolated attention layer 2 fusing the interpolated attention withself-attention to boost fidelity and 3 applying beta distribution toselection to increase smoothness. We also present a variant Prompt-guidedAttention Interpolation via Diffusion PAID that considers interpolation as acondition-dependent generative process. This method enables the creation of newimages with greater consistency smoothness and efficiency and offers controlover the exact path of interpolation. Our approach demonstrates effectivenessfor conceptual and spatial interpolation. Code and demo are available athttps://github.com/QY-H00/attention-interpolation-diffusion.</p>
                <p>Last Updated: 2024-03-26 17:57:05 UTC</p>
                <button class="interpret-button" data-id="2403.17924v1">Interpret</button>
                <div id="interpretation-2403.17924v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning</h3>
                <p>Authors: Rui PanXiang LiuShizhe DiaoRenjie PiJipeng ZhangChi HanTong Zhang</p>
                <p><a href="http://arxiv.org/abs/2403.17919v1">Link to paper</a></p>
                <p>The machine learning community has witnessed impressive advancements sincethe first appearance of large language models LLMs yet their huge memoryconsumption has become a major roadblock to large-scale training. ParameterEfficient Fine-Tuning techniques such as Low-Rank Adaptation LoRA have beenproposed to alleviate this problem but their performance still fails to matchfull parameter training in most large-scale fine-tuning settings. Attempting tocomplement this deficiency we investigate layerwise properties of LoRA onfine-tuning tasks and observe an uncommon skewness of weight norms acrossdifferent layers. Utilizing this key observation a surprisingly simpletraining strategy is discovered which outperforms both LoRA and full parametertraining in a wide range of settings with memory costs as low as LoRA. We nameit Layerwise Importance Sampled AdamW LISA a promising alternative for LoRAwhich applies the idea of importance sampling to different layers in LLMs andrandomly freeze most middle layers during optimization. Experimental resultsshow that with similar or less GPU memory consumption LISA surpasses LoRA oreven full parameter tuning in downstream fine-tuning tasks where LISAconsistently outperforms LoRA by over 11-37 in terms of MT-Benchscores. On large models specifically LLaMA-2-70B LISA achieves on-par orbetter performance than LoRA on MT-Bench GSM8K and PubMedQA demonstratingits effectiveness across different domains.</p>
                <p>Last Updated: 2024-03-26 17:55:02 UTC</p>
                <button class="interpret-button" data-id="2403.17919v1">Interpret</button>
                <div id="interpretation-2403.17919v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>AgentStudio: A Toolkit for Building General Virtual Agents</h3>
                <p>Authors: Longtao ZhengZhiyuan HuangZhenghai XueXinrun WangBo AnShuicheng Yan</p>
                <p><a href="http://arxiv.org/abs/2403.17918v1">Link to paper</a></p>
                <p>Creating autonomous virtual agents capable of using arbitrary software on anydigital device remains a major challenge for artificial intelligence. Two keyobstacles hinder progress: insufficient infrastructure for building virtualagents in real-world environments and the need for in-the-wild evaluation offundamental agent abilities. To address this we introduce AgentStudio anonline realistic and multimodal toolkit that covers the entire lifecycle ofagent development. This includes environment setups data collection agentevaluation and visualization. The observation and action spaces are highlygeneric supporting both function calling and human-computer interfaces. Thisversatility is further enhanced by AgentStudios graphical user interfaceswhich allow efficient development of datasets and benchmarks in real-worldsettings. To illustrate we introduce a visual grounding dataset and areal-world benchmark suite both created with our graphical interfaces.Furthermore we present several actionable insights derived from AgentStudioe.g. general visual grounding open-ended tool creation learning from videosetc. We have open-sourced the environments datasets benchmarks andinterfaces to promote research towards developing general virtual agents forthe future.</p>
                <p>Last Updated: 2024-03-26 17:54:15 UTC</p>
                <button class="interpret-button" data-id="2403.17918v1">Interpret</button>
                <div id="interpretation-2403.17918v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.LG">
        <h2>cs.LG</h2>
        <ul>
    
            <li>
                <h3>SLEDGE: Synthesizing Simulation Environments for Driving Agents with Generative Models</h3>
                <p>Authors: Kashyap ChittaDaniel DaunerAndreas Geiger</p>
                <p><a href="http://arxiv.org/abs/2403.17933v1">Link to paper</a></p>
                <p>SLEDGE is the first generative simulator for vehicle motion planning trainedon real-world driving logs. Its core component is a learned model that is ableto generate agent bounding boxes and lane graphs. The models outputs serve asan initial state for traffic simulation. The unique properties of the entitiesto be generated for SLEDGE such as their connectivity and variable count perscene render the naive application of most modern generative models to thistask non-trivial. Therefore together with a systematic study of existing lanegraph representations we introduce a novel raster-to-vector autoencoderRVAE. It encodes agents and the lane graph into distinct channels in arasterized latent map. This facilitates both lane-conditioned agent generationand combined generation of lanes and agents with a Diffusion Transformer. Usinggenerated entities in SLEDGE enables greater control over the simulation e.g.upsampling turns or increasing traffic density. Further SLEDGE can support500m long routes a capability not found in existing data-driven simulatorslike nuPlan. It presents new challenges for planning algorithms evidenced byfailure rates of over 40 for PDM the winner of the 2023 nuPlan challengewhen tested on hard routes and dense traffic generated by our model. Comparedto nuPlan SLEDGE requires 500times less storage to set up 4GB making ita more accessible option and helping with democratizing future research in thisfield.</p>
                <p>Last Updated: 2024-03-26 17:58:29 UTC</p>
                <button class="interpret-button" data-id="2403.17933v1">Interpret</button>
                <div id="interpretation-2403.17933v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>The Need for Speed: Pruning Transformers with One Recipe</h3>
                <p>Authors: Samir KhakiKonstantinos N. Plataniotis</p>
                <p><a href="http://arxiv.org/abs/2403.17921v1">Link to paper</a></p>
                <p>We introduce the textbfOne-shot textbfPruning textbfTechniquefor textbfInterchangeable textbfNetworks textbfOPTIN frameworkas a tool to increase the efficiency of pre-trained transformer architecturestextitwithout requiring re-training. Recent works have explored improvingtransformer efficiency however often incur computationally expensivere-training procedures or depend on architecture-specific characteristics thusimpeding practical wide-scale adoption. To address these shortcomings theOPTIN framework leverages intermediate feature distillation capturing thelong-range dependencies of model parameters coined textittrajectory toproduce state-of-the-art results on natural language image classificationtransfer learning and semantic segmentation tasks textitwithoutre-training. Given a FLOP constraint the OPTIN framework will compress thenetwork while maintaining competitive accuracy performance and improvedthroughput. Particularly we show a leq 2 accuracy degradation from NLPbaselines and a 0.5 improvement from state-of-the-art methods on imageclassification at competitive FLOPs reductions. We further demonstrate thegeneralization of tasks and architecture with comparative performance usingMask2Former for semantic segmentation and cnn-style networks. OPTIN presentsone of the first one-shot efficient frameworks for compressing transformerarchitectures that generalizes well across different class domains inparticular: natural language and image-related tasks withouttextitre-training.</p>
                <p>Last Updated: 2024-03-26 17:55:58 UTC</p>
                <button class="interpret-button" data-id="2403.17921v1">Interpret</button>
                <div id="interpretation-2403.17921v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning</h3>
                <p>Authors: Rui PanXiang LiuShizhe DiaoRenjie PiJipeng ZhangChi HanTong Zhang</p>
                <p><a href="http://arxiv.org/abs/2403.17919v1">Link to paper</a></p>
                <p>The machine learning community has witnessed impressive advancements sincethe first appearance of large language models LLMs yet their huge memoryconsumption has become a major roadblock to large-scale training. ParameterEfficient Fine-Tuning techniques such as Low-Rank Adaptation LoRA have beenproposed to alleviate this problem but their performance still fails to matchfull parameter training in most large-scale fine-tuning settings. Attempting tocomplement this deficiency we investigate layerwise properties of LoRA onfine-tuning tasks and observe an uncommon skewness of weight norms acrossdifferent layers. Utilizing this key observation a surprisingly simpletraining strategy is discovered which outperforms both LoRA and full parametertraining in a wide range of settings with memory costs as low as LoRA. We nameit Layerwise Importance Sampled AdamW LISA a promising alternative for LoRAwhich applies the idea of importance sampling to different layers in LLMs andrandomly freeze most middle layers during optimization. Experimental resultsshow that with similar or less GPU memory consumption LISA surpasses LoRA oreven full parameter tuning in downstream fine-tuning tasks where LISAconsistently outperforms LoRA by over 11-37 in terms of MT-Benchscores. On large models specifically LLaMA-2-70B LISA achieves on-par orbetter performance than LoRA on MT-Bench GSM8K and PubMedQA demonstratingits effectiveness across different domains.</p>
                <p>Last Updated: 2024-03-26 17:55:02 UTC</p>
                <button class="interpret-button" data-id="2403.17919v1">Interpret</button>
                <div id="interpretation-2403.17919v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>CMP: Cooperative Motion Prediction with Multi-Agent Communication</h3>
                <p>Authors: Zhuoyuan WuYuping WangHengbo MaZhaowei LiHang QiuJiachen Li</p>
                <p><a href="http://arxiv.org/abs/2403.17916v1">Link to paper</a></p>
                <p>The confluence of the advancement of Autonomous Vehicles AVs and thematurity of Vehicle-to-Everything V2X communication has enabled thecapability of cooperative connected and automated vehicles CAVs. Building ontop of cooperative perception this paper explores the feasibility andeffectiveness of cooperative motion prediction. Our method CMP takes LiDARsignals as input to enhance tracking and prediction capabilities. Unlikeprevious work that focuses separately on either cooperative perception ormotion prediction our framework to the best of our knowledge is the first toaddress the unified problem where CAVs share information in both perception andprediction modules. Incorporated into our design is the unique capability totolerate realistic V2X bandwidth limitations and transmission delays whiledealing with bulky perception representations. We also propose a predictionaggregation module which unifies the predictions obtained by different CAVsand generates the final prediction. Through extensive experiments and ablationstudies we demonstrate the effectiveness of our method in cooperativeperception tracking and motion prediction tasks. In particular CMP reducesthe average prediction error by 17.2 with fewer missing detections comparedwith the no cooperation setting. Our work marks a significant step forward inthe cooperative capabilities of CAVs showcasing enhanced performance incomplex scenarios.</p>
                <p>Last Updated: 2024-03-26 17:53:27 UTC</p>
                <button class="interpret-button" data-id="2403.17916v1">Interpret</button>
                <div id="interpretation-2403.17916v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Scalable Non-Cartesian Magnetic Resonance Imaging with R2D2</h3>
                <p>Authors: Chen YiweiTang ChaoAghabiglou AmirChu Chung SanWiaux Yves</p>
                <p><a href="http://arxiv.org/abs/2403.17905v1">Link to paper</a></p>
                <p>We propose a new approach for non-Cartesian magnetic resonance imagereconstruction. While unrolled architectures provide robustness viadata-consistency layers embedding measurement operators in Deep Neural NetworkDNN can become impractical at large scale. Alternative Plug-and-Play PnPapproaches where the denoising DNNs are blind to the measurement setting arenot affected by this limitation and have also proven effective but theirhighly iterative nature also affects scalability. To address this scalabilitychallenge we leverage the Residual-to-Residual DNN series for high-Dynamicrange imaging R2D2 approach recently introduced in astronomical imaging.R2D2s reconstruction is formed as a series of residual images iterativelyestimated as outputs of DNNs taking the previous iterations image estimate andassociated data residual as inputs. The method can be interpreted as a learnedversion of the Matching Pursuit algorithm. We demonstrate R2D2 in simulationconsidering radial k-space sampling acquisition sequences. Our preliminaryresults suggest that R2D2 achieves: i suboptimal performance compared to itsunrolled incarnation R2D2-Net which is however non-scalable due to thenecessary embedding of NUFFT-based data-consistency layers ii superiorreconstruction quality to a scalable version of R2D2-Net embedding an FFT-basedapproximation for data consistency iii superior reconstruction quality toPnP while only requiring few iterations.</p>
                <p>Last Updated: 2024-03-26 17:45:06 UTC</p>
                <button class="interpret-button" data-id="2403.17905v1">Interpret</button>
                <div id="interpretation-2403.17905v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.CV">
        <h2>cs.CV</h2>
        <ul>
    
            <li>
                <h3>Efficient Video Object Segmentation via Modulated Cross-Attention Memory</h3>
                <p>Authors: Abdelrahman ShakerSyed Talal WasimMartin DanelljanSalman KhanMing-Hsuan YangFahad Shahbaz Khan</p>
                <p><a href="http://arxiv.org/abs/2403.17937v1">Link to paper</a></p>
                <p>Recently transformer-based approaches have shown promising results forsemi-supervised video object segmentation. However these approaches typicallystruggle on long videos due to increased GPU memory demands as they frequentlyexpand the memory bank every few frames. We propose a transformer-basedapproach named MAVOS that introduces an optimized and dynamic long-termmodulated cross-attention MCA memory to model temporal smoothness withoutrequiring frequent memory expansion. The proposed MCA effectively encodes bothlocal and global features at various levels of granularity while efficientlymaintaining consistent speed regardless of the video length. Extensiveexperiments on multiple benchmarks LVOS Long-Time Video and DAVIS 2017demonstrate the effectiveness of our proposed contributions leading toreal-time inference and markedly reduced memory demands without any degradationin segmentation accuracy on long videos. Compared to the best existingtransformer-based approach our MAVOS increases the speed by 7.6x whilesignificantly reducing the GPU memory by 87 with comparable segmentationperformance on short and long video datasets. Notably on the LVOS dataset ourMAVOS achieves a JF score of 63.3 while operating at 37 frames per secondFPS on a single V100 GPU. Our code and models will be publicly available at:https://github.com/Amshaker/MAVOS.</p>
                <p>Last Updated: 2024-03-26 17:59:58 UTC</p>
                <button class="interpret-button" data-id="2403.17937v1">Interpret</button>
                <div id="interpretation-2403.17937v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>ConvoFusion: Multi-Modal Conversational Diffusion for Co-Speech Gesture Synthesis</h3>
                <p>Authors: Muhammad Hamza MughalRishabh DabralIkhsanul HabibieLucia DonatelliMarc HabermannChristian Theobalt</p>
                <p><a href="http://arxiv.org/abs/2403.17936v1">Link to paper</a></p>
                <p>Gestures play a key role in human communication. Recent methods for co-speechgesture generation while managing to generate beat-aligned motions strugglegenerating gestures that are semantically aligned with the utterance. Comparedto beat gestures that align naturally to the audio signal semanticallycoherent gestures require modeling the complex interactions between thelanguage and human motion and can be controlled by focusing on certain words.Therefore we present ConvoFusion a diffusion-based approach for multi-modalgesture synthesis which can not only generate gestures based on multi-modalspeech inputs but can also facilitate controllability in gesture synthesis.Our method proposes two guidance objectives that allow the users to modulatethe impact of different conditioning modalities e.g. audio vs text as well asto choose certain words to be emphasized during gesturing. Our method isversatile in that it can be trained either for generating monologue gestures oreven the conversational gestures. To further advance the research onmulti-party interactive gestures the DnD Group Gesture dataset is releasedwhich contains 6 hours of gesture data showing 5 people interacting with oneanother. We compare our method with several recent works and demonstrateeffectiveness of our method on a variety of tasks. We urge the reader to watchour supplementary video at our website.</p>
                <p>Last Updated: 2024-03-26 17:59:52 UTC</p>
                <button class="interpret-button" data-id="2403.17936v1">Interpret</button>
                <div id="interpretation-2403.17936v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>OmniVid: A Generative Framework for Universal Video Understanding</h3>
                <p>Authors: Junke WangDongdong ChenChong LuoBo HeLu YuanZuxuan WuYu-Gang Jiang</p>
                <p><a href="http://arxiv.org/abs/2403.17935v1">Link to paper</a></p>
                <p>The core of video understanding tasks such as recognition captioning andtracking is to automatically detect objects or actions in a video and analyzetheir temporal evolution. Despite sharing a common goal different tasks oftenrely on distinct model architectures and annotation formats. In contrastnatural language processing benefits from a unified output space i.e. textsequences which simplifies the training of powerful foundational languagemodels such as GPT-3 with extensive training corpora. Inspired by this weseek to unify the output space of video understanding tasks by using languagesas labels and additionally introducing time and box tokens. In this way avariety of video tasks could be formulated as video-grounded token generation.This enables us to address various types of video tasks includingclassification such as action recognition captioning covering clipcaptioning video question answering and dense video captioning andlocalization tasks such as visual object tracking within a fully sharedencoder-decoder architecture following a generative framework. Throughcomprehensive experiments we demonstrate such a simple and straightforwardidea is quite effective and can achieve state-of-the-art or competitive resultson seven video benchmarks providing a novel perspective for more universalvideo understanding. Code is available at https://github.com/wangjk666/OmniVid.</p>
                <p>Last Updated: 2024-03-26 17:59:24 UTC</p>
                <button class="interpret-button" data-id="2403.17935v1">Interpret</button>
                <div id="interpretation-2403.17935v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>AiOS: All-in-One-Stage Expressive Human Pose and Shape Estimation</h3>
                <p>Authors: Qingping SunYanjun WangAiling ZengWanqi YinChen WeiWenjia WangHaiyi MeiChi Sing LeungZiwei LiuLei YangZhongang Cai</p>
                <p><a href="http://arxiv.org/abs/2403.17934v1">Link to paper</a></p>
                <p>Expressive human pose and shape estimation a.k.a. 3D whole-body meshrecovery involves the human body hand and expression estimation. Mostexisting methods have tackled this task in a two-stage manner first detectingthe human body part with an off-the-shelf detection model and inferring thedifferent human body parts individually. Despite the impressive resultsachieved these methods suffer from 1 loss of valuable contextual informationvia cropping 2 introducing distractions and 3 lacking inter-associationamong different persons and body parts inevitably causing performancedegradation especially for crowded scenes. To address these issues weintroduce a novel all-in-one-stage framework AiOS for multiple expressivehuman pose and shape recovery without an additional human detection step.Specifically our method is built upon DETR which treats multi-personwhole-body mesh recovery task as a progressive set prediction problem withvarious sequential detection. We devise the decoder tokens and extend them toour task. Specifically we first employ a human token to probe a human locationin the image and encode global features for each instance which provides acoarse location for the later transformer block. Then we introduce ajoint-related token to probe the human joint in the image and encoder afine-grained local feature which collaborates with the global feature toregress the whole-body mesh. This straightforward but effective modeloutperforms previous state-of-the-art methods by a 9 reduction in NMVE onAGORA a 30 reduction in PVE on EHF a 10 reduction in PVE on ARCTIC and a3 reduction in PVE on EgoBody.</p>
                <p>Last Updated: 2024-03-26 17:59:23 UTC</p>
                <button class="interpret-button" data-id="2403.17934v1">Interpret</button>
                <div id="interpretation-2403.17934v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>SLEDGE: Synthesizing Simulation Environments for Driving Agents with Generative Models</h3>
                <p>Authors: Kashyap ChittaDaniel DaunerAndreas Geiger</p>
                <p><a href="http://arxiv.org/abs/2403.17933v1">Link to paper</a></p>
                <p>SLEDGE is the first generative simulator for vehicle motion planning trainedon real-world driving logs. Its core component is a learned model that is ableto generate agent bounding boxes and lane graphs. The models outputs serve asan initial state for traffic simulation. The unique properties of the entitiesto be generated for SLEDGE such as their connectivity and variable count perscene render the naive application of most modern generative models to thistask non-trivial. Therefore together with a systematic study of existing lanegraph representations we introduce a novel raster-to-vector autoencoderRVAE. It encodes agents and the lane graph into distinct channels in arasterized latent map. This facilitates both lane-conditioned agent generationand combined generation of lanes and agents with a Diffusion Transformer. Usinggenerated entities in SLEDGE enables greater control over the simulation e.g.upsampling turns or increasing traffic density. Further SLEDGE can support500m long routes a capability not found in existing data-driven simulatorslike nuPlan. It presents new challenges for planning algorithms evidenced byfailure rates of over 40 for PDM the winner of the 2023 nuPlan challengewhen tested on hard routes and dense traffic generated by our model. Comparedto nuPlan SLEDGE requires 500times less storage to set up 4GB making ita more accessible option and helping with democratizing future research in thisfield.</p>
                <p>Last Updated: 2024-03-26 17:58:29 UTC</p>
                <button class="interpret-button" data-id="2403.17933v1">Interpret</button>
                <div id="interpretation-2403.17933v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
    <section id="cs.MA">
        <h2>cs.MA</h2>
        <ul>
    
            <li>
                <h3>CMP: Cooperative Motion Prediction with Multi-Agent Communication</h3>
                <p>Authors: Zhuoyuan WuYuping WangHengbo MaZhaowei LiHang QiuJiachen Li</p>
                <p><a href="http://arxiv.org/abs/2403.17916v1">Link to paper</a></p>
                <p>The confluence of the advancement of Autonomous Vehicles AVs and thematurity of Vehicle-to-Everything V2X communication has enabled thecapability of cooperative connected and automated vehicles CAVs. Building ontop of cooperative perception this paper explores the feasibility andeffectiveness of cooperative motion prediction. Our method CMP takes LiDARsignals as input to enhance tracking and prediction capabilities. Unlikeprevious work that focuses separately on either cooperative perception ormotion prediction our framework to the best of our knowledge is the first toaddress the unified problem where CAVs share information in both perception andprediction modules. Incorporated into our design is the unique capability totolerate realistic V2X bandwidth limitations and transmission delays whiledealing with bulky perception representations. We also propose a predictionaggregation module which unifies the predictions obtained by different CAVsand generates the final prediction. Through extensive experiments and ablationstudies we demonstrate the effectiveness of our method in cooperativeperception tracking and motion prediction tasks. In particular CMP reducesthe average prediction error by 17.2 with fewer missing detections comparedwith the no cooperation setting. Our work marks a significant step forward inthe cooperative capabilities of CAVs showcasing enhanced performance incomplex scenarios.</p>
                <p>Last Updated: 2024-03-26 17:53:27 UTC</p>
                <button class="interpret-button" data-id="2403.17916v1">Interpret</button>
                <div id="interpretation-2403.17916v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Scenario-Based Curriculum Generation for Multi-Agent Autonomous Driving</h3>
                <p>Authors: Axel BrunnbauerLuigi BerducciPeter PrillerDejan NickovicRadu Grosu</p>
                <p><a href="http://arxiv.org/abs/2403.17805v1">Link to paper</a></p>
                <p>The automated generation of diverse and complex training scenarios has beenan important ingredient in many complex learning tasks. Especially inreal-world application domains such as autonomous driving auto-curriculumgeneration is considered vital for obtaining robust and general policies.However crafting traffic scenarios with multiple heterogeneous agents istypically considered as a tedious and time-consuming task especially in morecomplex simulation environments. In our work we introduce MATS-Gym aMulti-Agent Traffic Scenario framework to train agents in CARLA ahigh-fidelity driving simulator. MATS-Gym is a multi-agent training frameworkfor autonomous driving that uses partial scenario specifications to generatetraffic scenarios with variable numbers of agents. This paper unifies variousexisting approaches to traffic scenario description into a single trainingframework and demonstrates how it can be integrated with techniques fromunsupervised environment design to automate the generation of adaptiveauto-curricula. The code is available athttps://github.com/AutonomousDrivingExaminer/mats-gym.</p>
                <p>Last Updated: 2024-03-26 15:42:04 UTC</p>
                <button class="interpret-button" data-id="2403.17805v1">Interpret</button>
                <div id="interpretation-2403.17805v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Prioritize Team Actions: Multi-Agent Temporal Logic Task Planning with Ordering Constraints</h3>
                <p>Authors: Bowen YeJianing ZhaoShaoyuan LiXiang Yin</p>
                <p><a href="http://arxiv.org/abs/2403.17704v1">Link to paper</a></p>
                <p>In this paper we investigate the problem of linear temporal logic LTL pathplanning for multi-agent systems introducing the new concept of emphorderingconstraints. Specifically we consider a generic objective function that isdefined for the path of each individual agent. The primary objective is to finda global plan for the team of agents ensuring they collectively meet thespecified LTL requirements. Simultaneously we aim to maintain a pre-determinedorder in the values of the objective function for each agent which we refer toas the ordering constraints. This new requirement stems from scenarios likesecurity-aware planning where relative orders outweigh absolute values inimportance. We present an efficient algorithm to solve this problem supportedby proofs of correctness that demonstrate the optimality of our solution.Additionally we provide a case study in security-aware path planning toillustrate the practicality and effectiveness of our proposed approach.</p>
                <p>Last Updated: 2024-03-26 13:49:48 UTC</p>
                <button class="interpret-button" data-id="2403.17704v1">Interpret</button>
                <div id="interpretation-2403.17704v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Depending on yourself when you should: Mentoring LLM with RL agents to become the master in cybersecurity games</h3>
                <p>Authors: Yikuan YanYaolun ZhangKeman Huang</p>
                <p><a href="http://arxiv.org/abs/2403.17674v1">Link to paper</a></p>
                <p>Integrating LLM and reinforcement learning RL agent effectively to achievecomplementary performance is critical in high stake tasks like cybersecurityoperations. In this study we introduce SecurityBot a LLM agent mentored bypre-trained RL agents to support cybersecurity operations. In particularlythe LLM agent is supported with a profile module to generated behaviorguidelines a memory module to accumulate local experiences a reflectionmodule to re-evaluate choices and an action module to reduce action space.Additionally it adopts the collaboration mechanism to take suggestions frompre-trained RL agents including a cursor for dynamic suggestion taken anaggregator for multiple mentors suggestions ranking and a caller for proactivesuggestion asking. Building on the CybORG experiment framework our experiencesshow that SecurityBot demonstrates significant performance improvement comparedwith LLM or RL standalone achieving the complementary performance in thecybersecurity games.</p>
                <p>Last Updated: 2024-03-26 13:02:46 UTC</p>
                <button class="interpret-button" data-id="2403.17674v1">Interpret</button>
                <div id="interpretation-2403.17674v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
            <li>
                <h3>Prediction-sharing During Training and Inference</h3>
                <p>Authors: Yotam GafniRonen GradwohlMoshe Tennenholtz</p>
                <p><a href="http://arxiv.org/abs/2403.17515v1">Link to paper</a></p>
                <p>Two firms are engaged in a competitive prediction task. Each firm has twosources of data -- labeled historical data and unlabeled inference-time data --and uses the former to derive a prediction model and the latter to makepredictions on new instances. We study data-sharing contracts between thefirms. The novelty of our study is to introduce and highlight the differencesbetween contracts that share prediction models only contracts to shareinference-time predictions only and contracts to share both. Our analysisproceeds on three levels. First we develop a general Bayesian framework thatfacilitates our study. Second we narrow our focus to two natural settingswithin this framework: i a setting in which the accuracy of each firmsprediction model is common knowledge but the correlation between therespective models is unknown and ii a setting in which two hypotheses existregarding the optimal predictor and one of the firms has a structuraladvantage in deducing it. Within these two settings we study optimal contractchoice. More specifically we find the individually rational and Pareto-optimalcontracts for some notable cases and describe specific settings where each ofthe different sharing contracts emerge as optimal. Finally in the third levelof our analysis we demonstrate the applicability of our concepts in a syntheticsimulation using real loan data.</p>
                <p>Last Updated: 2024-03-26 09:18:50 UTC</p>
                <button class="interpret-button" data-id="2403.17515v1">Interpret</button>
                <div id="interpretation-2403.17515v1" class="interpretation" style="display:none;">
                    <p>Interpretation: <br></p>
                </div>
            </li>
        
        </ul>
    </section>
    
        <div id="last-updated">
            <p>Updated Time: 2024-03-27</p>
        </div>
    
        </div>
    </body>
    </html>
    