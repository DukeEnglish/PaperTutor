# cs.CL 

| Item |Content|
| --- |---|
|idx| 2407.21792v1 |
|title| Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress? |
|authors| Richard RenSteven BasartAdam KhojaAlice GattiLong PhanXuwang YinMantas MazeikaAlexander PanGabriel MukobiRyan H. KimStephen FitzDan Hendrycks
|links| http://arxiv.org/abs/2407.21792v1 |
|updated| 2024-07-31 17:59:24 UTC |
|summary| As artificial intelligence systems grow more powerful there has beenincreasing interest in AI safety research to address emerging and futurerisks. However the field of AI safety remains poorly defined andinconsistently measured leading to confusion about how researchers cancontribute. This lack of clarity is compounded by the unclear relationshipbetween AI safety benchmarks and upstream general capabilities e.g. generalknowledge and reasoning. To address these issues we conduct a comprehensivemeta-analysis of AI safety benchmarks empirically analyzing their correlationwith general capabilities across dozens of models and providing a survey ofexisting directions in AI safety. Our findings reveal that many safetybenchmarks highly correlate with upstream model capabilities potentiallyenabling safetywashing -- where capability improvements are misrepresented assafety advancements. Based on these findings we propose an empiricalfoundation for developing more meaningful safety metrics and define AI safetyin a machine learning research context as a set of clearly delineated researchgoals that are empirically separable from generic capabilities advancements. Indoing so we aim to provide a more rigorous framework for AI safety researchadvancing the science of safety evaluations and clarifying the path towardsmeasurable progress. |


| Item |Content|
| --- |---|
|idx| 2407.21788v1 |
|title| Vision-Language Model Based Handwriting Verification |
|authors| Mihir ChauhanAbhishek SatbhaiMohammad Abuzar HashemiMir Basheer AliBina RamamurthyMingchen GaoSiwei LyuSargur Srihari
|links| http://arxiv.org/abs/2407.21788v1 |
|updated| 2024-07-31 17:57:32 UTC |
|summary| Handwriting Verification is a critical in document forensics. Deep learningbased approaches often face skepticism from forensic document examiners due totheir lack of explainability and reliance on extensive training data andhandcrafted features. This paper explores using Vision Language Models VLMssuch as OpenAIs GPT-4o and Googles PaliGemma to address these challenges. Byleveraging their Visual Question Answering capabilities and 0-shotChain-of-Thought CoT reasoning our goal is to provide clearhuman-understandable explanations for model decisions. Our experiments on theCEDAR handwriting dataset demonstrate that VLMs offer enhancedinterpretability reduce the need for large training datasets and adapt betterto diverse handwriting styles. However results show that the CNN-basedResNet-18 architecture outperforms the 0-shot CoT prompt engineering approachwith GPT-4o Accuracy: 70 and supervised fine-tuned PaliGemma Accuracy:71 achieving an accuracy of 84 on the CEDAR AND dataset. These findingshighlight the potential of VLMs in generating human-interpretable decisionswhile underscoring the need for further advancements to match the performanceof specialized deep learning models. |


| Item |Content|
| --- |---|
|idx| 2407.21783v1 |
|title| The Llama 3 Herd of Models |
|authors| Abhimanyu DubeyAbhinav JauhriAbhinav PandeyAbhishek KadianAhmad Al-DahleAiesha LetmanAkhil MathurAlan ScheltenAmy YangAngela FanAnirudh GoyalAnthony HartshornAobo YangArchi MitraArchie SravankumarArtem KorenevArthur HinsvarkArun RaoAston ZhangAurelien RodriguezAusten GregersonAva SpataruBaptiste RoziereBethany BironBinh TangBobbie ChernCharlotte CaucheteuxChaya NayakChloe BiChris MarraChris McConnellChristian KellerChristophe TouretChunyang WuCorinne WongCristian Canton FerrerCyrus NikolaidisDamien AllonsiusDaniel SongDanielle PintzDanny LivshitsDavid EsiobuDhruv ChoudharyDhruv MahajanDiego Garcia-OlanoDiego PerinoDieuwke HupkesEgor LakomkinEhab AlBadawyElina LobanovaEmily DinanEric Michael SmithFilip RadenovicFrank ZhangGabriel SynnaeveGabrielle LeeGeorgia Lewis AndersonGraeme NailGregoire MialonGuan PangGuillem CucurellHailey NguyenHannah KorevaarHu XuHugo TouvronIliyan ZarovImanol Arrieta IbarraIsabel KloumannIshan MisraIvan EvtimovJade CopetJaewon LeeJan GeffertJana VranesJason ParkJay MahadeokarJeet ShahJelmer van der LindeJennifer BillockJenny HongJenya LeeJeremy FuJianfeng ChiJianyu HuangJiawen LiuJie WangJiecao YuJoanna BittonJoe SpisakJongsoo ParkJoseph RoccaJoshua JohnstunJoshua SaxeJunteng JiaKalyan Vasuden AlwalaKartikeya UpasaniKate PlawiakKe LiKenneth HeafieldKevin StoneKhalid El-AriniKrithika IyerKshitiz MalikKuenley ChiuKunal BhallaLauren Rantala-YearyLaurens van der MaatenLawrence ChenLiang TanLiz JenkinsLouis MartinLovish MadaanLubo MaloLukas BlecherLukas LandzaatLuke de OliveiraMadeline MuzziMahesh PasupuletiMannat SinghManohar PaluriMarcin KardasMathew OldhamMathieu RitaMaya PavlovaMelanie KambadurMike LewisMin SiMitesh Kumar SinghMona HassanNaman GoyalNarjes TorabiNikolay BashlykovNikolay BogoychevNiladri ChatterjiOlivier DuchenneOnur ÇelebiPatrick AlrassyPengchuan ZhangPengwei LiPetar VasicPeter WengPrajjwal BhargavaPratik DubalPraveen KrishnanPunit Singh KouraPuxin XuQing HeQingxiao DongRagavan SrinivasanRaj GanapathyRamon CaldererRicardo Silveira CabralRobert StojnicRoberta RaileanuRohit GirdharRohit PatelRomain SauvestreRonnie PolidoroRoshan SumbalyRoss TaylorRuan SilvaRui HouRui WangSaghar HosseiniSahana ChennabasappaSanjay SinghSean BellSeohyun Sonia KimSergey EdunovShaoliang NieSharan NarangSharath RaparthySheng ShenShengye WanShruti BhosaleShun ZhangSimon VandenhendeSoumya BatraSpencer WhitmanSten SootlaStephane CollotSuchin GururanganSydney BorodinskyTamar HermanTara FowlerTarek SheashaThomas GeorgiouThomas ScialomTobias SpeckbacherTodor MihaylovTong XiaoUjjwal KarnVedanuj GoswamiVibhor GuptaVignesh RamanathanViktor KerkezVincent GonguetVirginie DoVish VogetiVladan PetrovicWeiwei ChuWenhan XiongWenyin FuWhitney MeersXavier MartinetXiaodong WangXiaoqing Ellen TanXinfeng XieXuchao JiaXuewei WangYaelle GoldschlagYashesh GaurYasmine BabaeiYi WenYiwen SongYuchen ZhangYue LiYuning MaoZacharie Delpierre CoudertZheng YanZhengxing ChenZoe PapakiposAaditya SinghAaron GrattafioriAbha JainAdam KelseyAdam ShajnfeldAdithya GangidiAdolfo VictoriaAhuva GoldstandAjay MenonAjay SharmaAlex BoesenbergAlex VaughanAlexei BaevskiAllie FeinsteinAmanda KalletAmit SanganiAnam YunusAndrei LupuAndres AlvaradoAndrew CaplesAndrew GuAndrew HoAndrew PoultonAndrew RyanAnkit RamchandaniAnnie FrancoAparajita SarafArkabandhu ChowdhuryAshley GabrielAshwin BharambeAssaf EisenmanAzadeh YazdanBeau JamesBen MaurerBenjamin LeonhardiBernie HuangBeth LoydBeto De PaolaBhargavi ParanjapeBing LiuBo WuBoyu NiBraden HancockBram WastiBrandon SpenceBrani StojkovicBrian GamidoBritt MontalvoCarl ParkerCarly BurtonCatalina MejiaChanghan WangChangkyu KimChao ZhouChester HuChing-Hsiang ChuChris CaiChris TindalChristoph FeichtenhoferDamon CivinDana BeatyDaniel KreymerDaniel LiDanny WyattDavid AdkinsDavid XuDavide TestuggineDelia DavidDevi ParikhDiana LiskovichDidem FossDingkang WangDuc LeDustin HollandEdward DowlingEissa JamilElaine MontgomeryEleonora PresaniEmily HahnEmily WoodErik BrinkmanEsteban ArcauteEvan DunbarEvan SmothersFei SunFelix KreukFeng TianFirat OzgenelFrancesco CaggioniFrancisco GuzmánFrank KanayetFrank SeideGabriela Medina FlorezGabriella SchwarzGada BadeerGeorgia SweeGil HalpernGovind ThattaiGrant HermanGrigory SizovGuangyiZhangGuna LakshminarayananHamid ShojanazeriHan ZouHannah WangHanwen ZhaHaroun HabeebHarrison RudolphHelen SukHenry AspegrenHunter GoldmanIgor MolybogIgor TufanovIrina-Elena VelicheItai GatJake WeissmanJames GeboskiJames KohliJaphet AsherJean-Baptiste GayaJeff MarcusJeff TangJennifer ChanJenny ZhenJeremy ReizensteinJeremy TeboulJessica ZhongJian JinJingyi YangJoe CummingsJon CarvillJon ShepardJonathan McPhieJonathan TorresJosh GinsburgJunjie WangKai WuKam Hou UKaran SaxenaKarthik PrasadKartikay KhandelwalKatayoun ZandKathy MatosichKaushik VeeraraghavanKelly MichelenaKeqian LiKun HuangKunal ChawlaKushal LakhotiaKyle HuangLailin ChenLakshya GargLavender ALeandro SilvaLee BellLei ZhangLiangpeng GuoLicheng YuLiron MoshkovichLuca WehrstedtMadian KhabsaManav AvalaniManish BhattMaria TsimpoukelliMartynas MankusMatan HassonMatthew LennieMatthias ResoMaxim GroshevMaxim NaumovMaya LathiMeghan KeneallyMichael L. SeltzerMichal ValkoMichelle RestrepoMihir PatelMik VyatskovMikayel SamvelyanMike ClarkMike MaceyMike WangMiquel Jubert HermosoMo MetanatMohammad RastegariMunish BansalNandhini SanthanamNatascha ParksNatasha WhiteNavyata BawaNayan SinghalNick EgeboNicolas UsunierNikolay Pavlovich LaptevNing DongNing ZhangNorman ChengOleg ChernoguzOlivia HartOmkar SalpekarOzlem KalinliParkin KentParth ParekhPaul SaabPavan BalajiPedro RittnerPhilip BontragerPierre RouxPiotr DollarPolina ZvyaginaPrashant RatanchandaniPritish YuvrajQian LiangRachad AlaoRachel RodriguezRafi AyubRaghotham MurthyRaghu NayaniRahul MitraRaymond LiRebekkah HoganRobin BatteyRocky WangRohan MaheswariRuss HowesRuty RinottSai Jayesh BonduSamyak DattaSara ChughSara HuntSargun DhillonSasha SidorovSatadru PanSaurabh VermaSeiji YamamotoSharadh RamaswamyShaun LindsayShaun LindsaySheng FengShenghao LinShengxin Cindy ZhaShiva ShankarShuqiang ZhangShuqiang ZhangSinong WangSneha AgarwalSoji SajuyigbeSoumith ChintalaStephanie MaxStephen ChenSteve KehoeSteve SatterfieldSudarshan GovindaprasadSumit GuptaSungmin ChoSunny VirkSuraj SubramanianSy ChoudhurySydney GoldmanTal RemezTamar GlaserTamara BestThilo KohlerThomas RobinsonTianhe LiTianjun ZhangTim MatthewsTimothy ChouTzook ShakedVarun VontimittaVictoria AjayiVictoria MontanezVijai MohanVinay Satish KumarVishal ManglaVlad IonescuVlad PoenaruVlad Tiberiu MihailescuVladimir IvanovWei LiWenchen WangWenwen JiangWes BouazizWill ConstableXiaocheng TangXiaofang WangXiaojian WuXiaolan WangXide XiaXilun WuXinbo GaoYanjun ChenYe HuYe JiaYe QiYenda LiYilin ZhangYing ZhangYossi AdiYoungjin NamYuWangYuchen HaoYundi QianYuzi HeZach RaitZachary DeVitoZef RosnbrickZhaoduo WenZhenyu YangZhiwei Zhao
|links| http://arxiv.org/abs/2407.21783v1 |
|updated| 2024-07-31 17:54:27 UTC |
|summary| Modern artificial intelligence AI systems are powered by foundation models.This paper presents a new set of foundation models called Llama 3. It is aherd of language models that natively support multilinguality codingreasoning and tool usage. Our largest model is a dense Transformer with 405Bparameters and a context window of up to 128K tokens. This paper presents anextensive empirical evaluation of Llama 3. We find that Llama 3 deliverscomparable quality to leading language models such as GPT-4 on a plethora oftasks. We publicly release Llama 3 including pre-trained and post-trainedversions of the 405B parameter language model and our Llama Guard 3 model forinput and output safety. The paper also presents the results of experiments inwhich we integrate image video and speech capabilities into Llama 3 via acompositional approach. We observe this approach performs competitively withthe state-of-the-art on image video and speech recognition tasks. Theresulting models are not yet being broadly released as they are still underdevelopment. |


| Item |Content|
| --- |---|
|idx| 2407.21772v1 |
|title| ShieldGemma: Generative AI Content Moderation Based on Gemma |
|authors| Wenjun ZengYuchi LiuRyan MullinsLudovic PeranJoe FernandezHamza HarkousKarthik NarasimhanDrew ProudPiyush KumarBhaktipriya RadharapuOlivia SturmanOscar Wahltinez
|links| http://arxiv.org/abs/2407.21772v1 |
|updated| 2024-07-31 17:48:14 UTC |
|summary| We present ShieldGemma a comprehensive suite of LLM-based safety contentmoderation models built upon Gemma2. These models provide robuststate-of-the-art predictions of safety risks across key harm types sexuallyexplicit dangerous content harassment hate speech in both user input andLLM-generated output. By evaluating on both public and internal benchmarks wedemonstrate superior performance compared to existing models such as LlamaGuard 10.8 AU-PRC on public benchmarks and WildCard 4.3.Additionally we present a novel LLM-based data curation pipeline adaptable toa variety of safety-related tasks and beyond. We have shown stronggeneralization performance for model trained mainly on synthetic data. Byreleasing ShieldGemma we provide a valuable resource to the researchcommunity advancing LLM safety and enabling the creation of more effectivecontent moderation solutions for developers. |


| Item |Content|
| --- |---|
|idx| 2407.21712v1 |
|title| Adaptive Retrieval-Augmented Generation for Conversational Systems |
|authors| Xi WangProcheta SenRuizhe LiEmine Yilmaz
|links| http://arxiv.org/abs/2407.21712v1 |
|updated| 2024-07-31 16:04:03 UTC |
|summary| Despite the success of integrating large language models into the developmentof conversational systems many studies have shown the effectiveness ofretrieving and augmenting external knowledge for informative responses. Hencemany existing studies commonly assume the always need for Retrieval AugmentedGeneration RAG in a conversational system without explicit control. Thisraises a research question about such a necessity. In this study we propose toinvestigate the need for each turn of system response to be augmented withexternal knowledge. In particular by leveraging human judgements on the binarychoice of adaptive augmentation we develop RAGate a gating model whichmodels conversation context and relevant inputs to predict if a conversationalsystem requires RAG for improved responses. We conduct extensive experiments ondevising and applying RAGate to conversational models and well-rounded analysesof different conversational scenarios. Our experimental results and analysisindicate the effective application of RAGate in RAG-based conversationalsystems in identifying system responses for appropriate RAG with high-qualityresponses and a high generation confidence. This study also identifies thecorrelation between the generations confidence level and the relevance of theaugmented knowledge. |


# cs.AI 

| Item |Content|
| --- |---|
|idx| 2407.21794v1 |
|title| Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey |
|authors| Atsuyuki MiyaiJingkang YangJingyang ZhangYifei MingYueqian LinQing YuGo IrieShafiq JotyYixuan LiHai LiZiwei LiuToshihiko YamasakiKiyoharu Aizawa
|links| http://arxiv.org/abs/2407.21794v1 |
|updated| 2024-07-31 17:59:58 UTC |
|summary| Detecting out-of-distribution OOD samples is crucial for ensuring thesafety of machine learning systems and has shaped the field of OOD detection.Meanwhile several other problems are closely related to OOD detectionincluding anomaly detection AD novelty detection ND open set recognitionOSR and outlier detection OD. To unify these problems a generalized OODdetection framework was proposed taxonomically categorizing these fiveproblems. However Vision Language Models VLMs such as CLIP havesignificantly changed the paradigm and blurred the boundaries between thesefields again confusing researchers. In this survey we first present ageneralized OOD detection v2 encapsulating the evolution of AD ND OSR OODdetection and OD in the VLM era. Our framework reveals that with some fieldinactivity and integration the demanding challenges have become OOD detectionand AD. In addition we also highlight the significant shift in the definitionproblem settings and benchmarks we thus feature a comprehensive review of themethodology for OOD detection including the discussion over other relatedtasks to clarify their relationship to OOD detection. Finally we explore theadvancements in the emerging Large Vision Language Model LVLM era such asGPT-4V. We conclude this survey with open challenges and future directions. |


| Item |Content|
| --- |---|
|idx| 2407.21792v1 |
|title| Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress? |
|authors| Richard RenSteven BasartAdam KhojaAlice GattiLong PhanXuwang YinMantas MazeikaAlexander PanGabriel MukobiRyan H. KimStephen FitzDan Hendrycks
|links| http://arxiv.org/abs/2407.21792v1 |
|updated| 2024-07-31 17:59:24 UTC |
|summary| As artificial intelligence systems grow more powerful there has beenincreasing interest in AI safety research to address emerging and futurerisks. However the field of AI safety remains poorly defined andinconsistently measured leading to confusion about how researchers cancontribute. This lack of clarity is compounded by the unclear relationshipbetween AI safety benchmarks and upstream general capabilities e.g. generalknowledge and reasoning. To address these issues we conduct a comprehensivemeta-analysis of AI safety benchmarks empirically analyzing their correlationwith general capabilities across dozens of models and providing a survey ofexisting directions in AI safety. Our findings reveal that many safetybenchmarks highly correlate with upstream model capabilities potentiallyenabling safetywashing -- where capability improvements are misrepresented assafety advancements. Based on these findings we propose an empiricalfoundation for developing more meaningful safety metrics and define AI safetyin a machine learning research context as a set of clearly delineated researchgoals that are empirically separable from generic capabilities advancements. Indoing so we aim to provide a more rigorous framework for AI safety researchadvancing the science of safety evaluations and clarifying the path towardsmeasurable progress. |


| Item |Content|
| --- |---|
|idx| 2407.21788v1 |
|title| Vision-Language Model Based Handwriting Verification |
|authors| Mihir ChauhanAbhishek SatbhaiMohammad Abuzar HashemiMir Basheer AliBina RamamurthyMingchen GaoSiwei LyuSargur Srihari
|links| http://arxiv.org/abs/2407.21788v1 |
|updated| 2024-07-31 17:57:32 UTC |
|summary| Handwriting Verification is a critical in document forensics. Deep learningbased approaches often face skepticism from forensic document examiners due totheir lack of explainability and reliance on extensive training data andhandcrafted features. This paper explores using Vision Language Models VLMssuch as OpenAIs GPT-4o and Googles PaliGemma to address these challenges. Byleveraging their Visual Question Answering capabilities and 0-shotChain-of-Thought CoT reasoning our goal is to provide clearhuman-understandable explanations for model decisions. Our experiments on theCEDAR handwriting dataset demonstrate that VLMs offer enhancedinterpretability reduce the need for large training datasets and adapt betterto diverse handwriting styles. However results show that the CNN-basedResNet-18 architecture outperforms the 0-shot CoT prompt engineering approachwith GPT-4o Accuracy: 70 and supervised fine-tuned PaliGemma Accuracy:71 achieving an accuracy of 84 on the CEDAR AND dataset. These findingshighlight the potential of VLMs in generating human-interpretable decisionswhile underscoring the need for further advancements to match the performanceof specialized deep learning models. |


| Item |Content|
| --- |---|
|idx| 2407.21787v1 |
|title| Large Language Monkeys: Scaling Inference Compute with Repeated Sampling |
|authors| Bradley BrownJordan JuravskyRyan EhrlichRonald ClarkQuoc V. LeChristopher RéAzalia Mirhoseini
|links| http://arxiv.org/abs/2407.21787v1 |
|updated| 2024-07-31 17:57:25 UTC |
|summary| Scaling the amount of compute used to train language models has dramaticallyimproved their capabilities. However when it comes to inference we oftenlimit the amount of compute to only one attempt per problem. Here we exploreinference compute as another axis for scaling by increasing the number ofgenerated samples. Across multiple tasks and models we observe that coverage -the fraction of problems solved by any attempt - scales with the number ofsamples over four orders of magnitude. In domains like coding and formalproofs where all answers can be automatically verified these increases incoverage directly translate into improved performance. When we apply repeatedsampling to SWE-bench Lite the fraction of issues solved withDeepSeek-V2-Coder-Instruct increases from 15.9 with one sample to 56 with 250samples outperforming the single-attempt state-of-the-art of 43 which usesmore capable frontier models. Moreover using current API pricing amplifyingthe cheaper DeepSeek model with five samples is more cost-effective and solvesmore issues than paying a premium for one sample from GPT-4o or Claude 3.5Sonnet. Interestingly the relationship between coverage and the number ofsamples is often log-linear and can be modelled with an exponentiated powerlaw suggesting the existence of inference-time scaling laws. Finally we findthat identifying correct samples out of many generations remains an importantdirection for future research in domains without automatic verifiers. Whensolving math word problems from GSM8K and MATH coverage with Llama-3 modelsgrows to over 95 with 10000 samples. However common methods to pick correctsolutions from a sample collection such as majority voting or reward modelsplateau beyond several hundred samples and fail to fully scale with the samplebudget. |


| Item |Content|
| --- |---|
|idx| 2407.21783v1 |
|title| The Llama 3 Herd of Models |
|authors| Abhimanyu DubeyAbhinav JauhriAbhinav PandeyAbhishek KadianAhmad Al-DahleAiesha LetmanAkhil MathurAlan ScheltenAmy YangAngela FanAnirudh GoyalAnthony HartshornAobo YangArchi MitraArchie SravankumarArtem KorenevArthur HinsvarkArun RaoAston ZhangAurelien RodriguezAusten GregersonAva SpataruBaptiste RoziereBethany BironBinh TangBobbie ChernCharlotte CaucheteuxChaya NayakChloe BiChris MarraChris McConnellChristian KellerChristophe TouretChunyang WuCorinne WongCristian Canton FerrerCyrus NikolaidisDamien AllonsiusDaniel SongDanielle PintzDanny LivshitsDavid EsiobuDhruv ChoudharyDhruv MahajanDiego Garcia-OlanoDiego PerinoDieuwke HupkesEgor LakomkinEhab AlBadawyElina LobanovaEmily DinanEric Michael SmithFilip RadenovicFrank ZhangGabriel SynnaeveGabrielle LeeGeorgia Lewis AndersonGraeme NailGregoire MialonGuan PangGuillem CucurellHailey NguyenHannah KorevaarHu XuHugo TouvronIliyan ZarovImanol Arrieta IbarraIsabel KloumannIshan MisraIvan EvtimovJade CopetJaewon LeeJan GeffertJana VranesJason ParkJay MahadeokarJeet ShahJelmer van der LindeJennifer BillockJenny HongJenya LeeJeremy FuJianfeng ChiJianyu HuangJiawen LiuJie WangJiecao YuJoanna BittonJoe SpisakJongsoo ParkJoseph RoccaJoshua JohnstunJoshua SaxeJunteng JiaKalyan Vasuden AlwalaKartikeya UpasaniKate PlawiakKe LiKenneth HeafieldKevin StoneKhalid El-AriniKrithika IyerKshitiz MalikKuenley ChiuKunal BhallaLauren Rantala-YearyLaurens van der MaatenLawrence ChenLiang TanLiz JenkinsLouis MartinLovish MadaanLubo MaloLukas BlecherLukas LandzaatLuke de OliveiraMadeline MuzziMahesh PasupuletiMannat SinghManohar PaluriMarcin KardasMathew OldhamMathieu RitaMaya PavlovaMelanie KambadurMike LewisMin SiMitesh Kumar SinghMona HassanNaman GoyalNarjes TorabiNikolay BashlykovNikolay BogoychevNiladri ChatterjiOlivier DuchenneOnur ÇelebiPatrick AlrassyPengchuan ZhangPengwei LiPetar VasicPeter WengPrajjwal BhargavaPratik DubalPraveen KrishnanPunit Singh KouraPuxin XuQing HeQingxiao DongRagavan SrinivasanRaj GanapathyRamon CaldererRicardo Silveira CabralRobert StojnicRoberta RaileanuRohit GirdharRohit PatelRomain SauvestreRonnie PolidoroRoshan SumbalyRoss TaylorRuan SilvaRui HouRui WangSaghar HosseiniSahana ChennabasappaSanjay SinghSean BellSeohyun Sonia KimSergey EdunovShaoliang NieSharan NarangSharath RaparthySheng ShenShengye WanShruti BhosaleShun ZhangSimon VandenhendeSoumya BatraSpencer WhitmanSten SootlaStephane CollotSuchin GururanganSydney BorodinskyTamar HermanTara FowlerTarek SheashaThomas GeorgiouThomas ScialomTobias SpeckbacherTodor MihaylovTong XiaoUjjwal KarnVedanuj GoswamiVibhor GuptaVignesh RamanathanViktor KerkezVincent GonguetVirginie DoVish VogetiVladan PetrovicWeiwei ChuWenhan XiongWenyin FuWhitney MeersXavier MartinetXiaodong WangXiaoqing Ellen TanXinfeng XieXuchao JiaXuewei WangYaelle GoldschlagYashesh GaurYasmine BabaeiYi WenYiwen SongYuchen ZhangYue LiYuning MaoZacharie Delpierre CoudertZheng YanZhengxing ChenZoe PapakiposAaditya SinghAaron GrattafioriAbha JainAdam KelseyAdam ShajnfeldAdithya GangidiAdolfo VictoriaAhuva GoldstandAjay MenonAjay SharmaAlex BoesenbergAlex VaughanAlexei BaevskiAllie FeinsteinAmanda KalletAmit SanganiAnam YunusAndrei LupuAndres AlvaradoAndrew CaplesAndrew GuAndrew HoAndrew PoultonAndrew RyanAnkit RamchandaniAnnie FrancoAparajita SarafArkabandhu ChowdhuryAshley GabrielAshwin BharambeAssaf EisenmanAzadeh YazdanBeau JamesBen MaurerBenjamin LeonhardiBernie HuangBeth LoydBeto De PaolaBhargavi ParanjapeBing LiuBo WuBoyu NiBraden HancockBram WastiBrandon SpenceBrani StojkovicBrian GamidoBritt MontalvoCarl ParkerCarly BurtonCatalina MejiaChanghan WangChangkyu KimChao ZhouChester HuChing-Hsiang ChuChris CaiChris TindalChristoph FeichtenhoferDamon CivinDana BeatyDaniel KreymerDaniel LiDanny WyattDavid AdkinsDavid XuDavide TestuggineDelia DavidDevi ParikhDiana LiskovichDidem FossDingkang WangDuc LeDustin HollandEdward DowlingEissa JamilElaine MontgomeryEleonora PresaniEmily HahnEmily WoodErik BrinkmanEsteban ArcauteEvan DunbarEvan SmothersFei SunFelix KreukFeng TianFirat OzgenelFrancesco CaggioniFrancisco GuzmánFrank KanayetFrank SeideGabriela Medina FlorezGabriella SchwarzGada BadeerGeorgia SweeGil HalpernGovind ThattaiGrant HermanGrigory SizovGuangyiZhangGuna LakshminarayananHamid ShojanazeriHan ZouHannah WangHanwen ZhaHaroun HabeebHarrison RudolphHelen SukHenry AspegrenHunter GoldmanIgor MolybogIgor TufanovIrina-Elena VelicheItai GatJake WeissmanJames GeboskiJames KohliJaphet AsherJean-Baptiste GayaJeff MarcusJeff TangJennifer ChanJenny ZhenJeremy ReizensteinJeremy TeboulJessica ZhongJian JinJingyi YangJoe CummingsJon CarvillJon ShepardJonathan McPhieJonathan TorresJosh GinsburgJunjie WangKai WuKam Hou UKaran SaxenaKarthik PrasadKartikay KhandelwalKatayoun ZandKathy MatosichKaushik VeeraraghavanKelly MichelenaKeqian LiKun HuangKunal ChawlaKushal LakhotiaKyle HuangLailin ChenLakshya GargLavender ALeandro SilvaLee BellLei ZhangLiangpeng GuoLicheng YuLiron MoshkovichLuca WehrstedtMadian KhabsaManav AvalaniManish BhattMaria TsimpoukelliMartynas MankusMatan HassonMatthew LennieMatthias ResoMaxim GroshevMaxim NaumovMaya LathiMeghan KeneallyMichael L. SeltzerMichal ValkoMichelle RestrepoMihir PatelMik VyatskovMikayel SamvelyanMike ClarkMike MaceyMike WangMiquel Jubert HermosoMo MetanatMohammad RastegariMunish BansalNandhini SanthanamNatascha ParksNatasha WhiteNavyata BawaNayan SinghalNick EgeboNicolas UsunierNikolay Pavlovich LaptevNing DongNing ZhangNorman ChengOleg ChernoguzOlivia HartOmkar SalpekarOzlem KalinliParkin KentParth ParekhPaul SaabPavan BalajiPedro RittnerPhilip BontragerPierre RouxPiotr DollarPolina ZvyaginaPrashant RatanchandaniPritish YuvrajQian LiangRachad AlaoRachel RodriguezRafi AyubRaghotham MurthyRaghu NayaniRahul MitraRaymond LiRebekkah HoganRobin BatteyRocky WangRohan MaheswariRuss HowesRuty RinottSai Jayesh BonduSamyak DattaSara ChughSara HuntSargun DhillonSasha SidorovSatadru PanSaurabh VermaSeiji YamamotoSharadh RamaswamyShaun LindsayShaun LindsaySheng FengShenghao LinShengxin Cindy ZhaShiva ShankarShuqiang ZhangShuqiang ZhangSinong WangSneha AgarwalSoji SajuyigbeSoumith ChintalaStephanie MaxStephen ChenSteve KehoeSteve SatterfieldSudarshan GovindaprasadSumit GuptaSungmin ChoSunny VirkSuraj SubramanianSy ChoudhurySydney GoldmanTal RemezTamar GlaserTamara BestThilo KohlerThomas RobinsonTianhe LiTianjun ZhangTim MatthewsTimothy ChouTzook ShakedVarun VontimittaVictoria AjayiVictoria MontanezVijai MohanVinay Satish KumarVishal ManglaVlad IonescuVlad PoenaruVlad Tiberiu MihailescuVladimir IvanovWei LiWenchen WangWenwen JiangWes BouazizWill ConstableXiaocheng TangXiaofang WangXiaojian WuXiaolan WangXide XiaXilun WuXinbo GaoYanjun ChenYe HuYe JiaYe QiYenda LiYilin ZhangYing ZhangYossi AdiYoungjin NamYuWangYuchen HaoYundi QianYuzi HeZach RaitZachary DeVitoZef RosnbrickZhaoduo WenZhenyu YangZhiwei Zhao
|links| http://arxiv.org/abs/2407.21783v1 |
|updated| 2024-07-31 17:54:27 UTC |
|summary| Modern artificial intelligence AI systems are powered by foundation models.This paper presents a new set of foundation models called Llama 3. It is aherd of language models that natively support multilinguality codingreasoning and tool usage. Our largest model is a dense Transformer with 405Bparameters and a context window of up to 128K tokens. This paper presents anextensive empirical evaluation of Llama 3. We find that Llama 3 deliverscomparable quality to leading language models such as GPT-4 on a plethora oftasks. We publicly release Llama 3 including pre-trained and post-trainedversions of the 405B parameter language model and our Llama Guard 3 model forinput and output safety. The paper also presents the results of experiments inwhich we integrate image video and speech capabilities into Llama 3 via acompositional approach. We observe this approach performs competitively withthe state-of-the-art on image video and speech recognition tasks. Theresulting models are not yet being broadly released as they are still underdevelopment. |


# cs.LG 

| Item |Content|
| --- |---|
|idx| 2407.21794v1 |
|title| Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey |
|authors| Atsuyuki MiyaiJingkang YangJingyang ZhangYifei MingYueqian LinQing YuGo IrieShafiq JotyYixuan LiHai LiZiwei LiuToshihiko YamasakiKiyoharu Aizawa
|links| http://arxiv.org/abs/2407.21794v1 |
|updated| 2024-07-31 17:59:58 UTC |
|summary| Detecting out-of-distribution OOD samples is crucial for ensuring thesafety of machine learning systems and has shaped the field of OOD detection.Meanwhile several other problems are closely related to OOD detectionincluding anomaly detection AD novelty detection ND open set recognitionOSR and outlier detection OD. To unify these problems a generalized OODdetection framework was proposed taxonomically categorizing these fiveproblems. However Vision Language Models VLMs such as CLIP havesignificantly changed the paradigm and blurred the boundaries between thesefields again confusing researchers. In this survey we first present ageneralized OOD detection v2 encapsulating the evolution of AD ND OSR OODdetection and OD in the VLM era. Our framework reveals that with some fieldinactivity and integration the demanding challenges have become OOD detectionand AD. In addition we also highlight the significant shift in the definitionproblem settings and benchmarks we thus feature a comprehensive review of themethodology for OOD detection including the discussion over other relatedtasks to clarify their relationship to OOD detection. Finally we explore theadvancements in the emerging Large Vision Language Model LVLM era such asGPT-4V. We conclude this survey with open challenges and future directions. |


| Item |Content|
| --- |---|
|idx| 2407.21792v1 |
|title| Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress? |
|authors| Richard RenSteven BasartAdam KhojaAlice GattiLong PhanXuwang YinMantas MazeikaAlexander PanGabriel MukobiRyan H. KimStephen FitzDan Hendrycks
|links| http://arxiv.org/abs/2407.21792v1 |
|updated| 2024-07-31 17:59:24 UTC |
|summary| As artificial intelligence systems grow more powerful there has beenincreasing interest in AI safety research to address emerging and futurerisks. However the field of AI safety remains poorly defined andinconsistently measured leading to confusion about how researchers cancontribute. This lack of clarity is compounded by the unclear relationshipbetween AI safety benchmarks and upstream general capabilities e.g. generalknowledge and reasoning. To address these issues we conduct a comprehensivemeta-analysis of AI safety benchmarks empirically analyzing their correlationwith general capabilities across dozens of models and providing a survey ofexisting directions in AI safety. Our findings reveal that many safetybenchmarks highly correlate with upstream model capabilities potentiallyenabling safetywashing -- where capability improvements are misrepresented assafety advancements. Based on these findings we propose an empiricalfoundation for developing more meaningful safety metrics and define AI safetyin a machine learning research context as a set of clearly delineated researchgoals that are empirically separable from generic capabilities advancements. Indoing so we aim to provide a more rigorous framework for AI safety researchadvancing the science of safety evaluations and clarifying the path towardsmeasurable progress. |


| Item |Content|
| --- |---|
|idx| 2407.21791v1 |
|title| Deep Learning for Options Trading: An End-To-End Approach |
|authors| Wee Ling TanStephen RobertsStefan Zohren
|links| http://arxiv.org/abs/2407.21791v1 |
|updated| 2024-07-31 17:59:09 UTC |
|summary| We introduce a novel approach to options trading strategies using a highlyscalable and data-driven machine learning algorithm. In contrast to traditionalapproaches that often require specifications of underlying market dynamics orassumptions on an option pricing model our models depart fundamentally fromthe need for these prerequisites directly learning non-trivial mappings frommarket data to optimal trading signals. Backtesting on more than a decade ofoption contracts for equities listed on the SP 100 we demonstrate that deeplearning models trained according to our end-to-end approach exhibitsignificant improvements in risk-adjusted performance over existing rules-basedtrading strategies. We find that incorporating turnover regularization into themodels leads to further performance enhancements at prohibitively high levelsof transaction costs. |


| Item |Content|
| --- |---|
|idx| 2407.21788v1 |
|title| Vision-Language Model Based Handwriting Verification |
|authors| Mihir ChauhanAbhishek SatbhaiMohammad Abuzar HashemiMir Basheer AliBina RamamurthyMingchen GaoSiwei LyuSargur Srihari
|links| http://arxiv.org/abs/2407.21788v1 |
|updated| 2024-07-31 17:57:32 UTC |
|summary| Handwriting Verification is a critical in document forensics. Deep learningbased approaches often face skepticism from forensic document examiners due totheir lack of explainability and reliance on extensive training data andhandcrafted features. This paper explores using Vision Language Models VLMssuch as OpenAIs GPT-4o and Googles PaliGemma to address these challenges. Byleveraging their Visual Question Answering capabilities and 0-shotChain-of-Thought CoT reasoning our goal is to provide clearhuman-understandable explanations for model decisions. Our experiments on theCEDAR handwriting dataset demonstrate that VLMs offer enhancedinterpretability reduce the need for large training datasets and adapt betterto diverse handwriting styles. However results show that the CNN-basedResNet-18 architecture outperforms the 0-shot CoT prompt engineering approachwith GPT-4o Accuracy: 70 and supervised fine-tuned PaliGemma Accuracy:71 achieving an accuracy of 84 on the CEDAR AND dataset. These findingshighlight the potential of VLMs in generating human-interpretable decisionswhile underscoring the need for further advancements to match the performanceof specialized deep learning models. |


| Item |Content|
| --- |---|
|idx| 2407.21787v1 |
|title| Large Language Monkeys: Scaling Inference Compute with Repeated Sampling |
|authors| Bradley BrownJordan JuravskyRyan EhrlichRonald ClarkQuoc V. LeChristopher RéAzalia Mirhoseini
|links| http://arxiv.org/abs/2407.21787v1 |
|updated| 2024-07-31 17:57:25 UTC |
|summary| Scaling the amount of compute used to train language models has dramaticallyimproved their capabilities. However when it comes to inference we oftenlimit the amount of compute to only one attempt per problem. Here we exploreinference compute as another axis for scaling by increasing the number ofgenerated samples. Across multiple tasks and models we observe that coverage -the fraction of problems solved by any attempt - scales with the number ofsamples over four orders of magnitude. In domains like coding and formalproofs where all answers can be automatically verified these increases incoverage directly translate into improved performance. When we apply repeatedsampling to SWE-bench Lite the fraction of issues solved withDeepSeek-V2-Coder-Instruct increases from 15.9 with one sample to 56 with 250samples outperforming the single-attempt state-of-the-art of 43 which usesmore capable frontier models. Moreover using current API pricing amplifyingthe cheaper DeepSeek model with five samples is more cost-effective and solvesmore issues than paying a premium for one sample from GPT-4o or Claude 3.5Sonnet. Interestingly the relationship between coverage and the number ofsamples is often log-linear and can be modelled with an exponentiated powerlaw suggesting the existence of inference-time scaling laws. Finally we findthat identifying correct samples out of many generations remains an importantdirection for future research in domains without automatic verifiers. Whensolving math word problems from GSM8K and MATH coverage with Llama-3 modelsgrows to over 95 with 10000 samples. However common methods to pick correctsolutions from a sample collection such as majority voting or reward modelsplateau beyond several hundred samples and fail to fully scale with the samplebudget. |


# cs.CV 

| Item |Content|
| --- |---|
|idx| 2407.21794v1 |
|title| Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey |
|authors| Atsuyuki MiyaiJingkang YangJingyang ZhangYifei MingYueqian LinQing YuGo IrieShafiq JotyYixuan LiHai LiZiwei LiuToshihiko YamasakiKiyoharu Aizawa
|links| http://arxiv.org/abs/2407.21794v1 |
|updated| 2024-07-31 17:59:58 UTC |
|summary| Detecting out-of-distribution OOD samples is crucial for ensuring thesafety of machine learning systems and has shaped the field of OOD detection.Meanwhile several other problems are closely related to OOD detectionincluding anomaly detection AD novelty detection ND open set recognitionOSR and outlier detection OD. To unify these problems a generalized OODdetection framework was proposed taxonomically categorizing these fiveproblems. However Vision Language Models VLMs such as CLIP havesignificantly changed the paradigm and blurred the boundaries between thesefields again confusing researchers. In this survey we first present ageneralized OOD detection v2 encapsulating the evolution of AD ND OSR OODdetection and OD in the VLM era. Our framework reveals that with some fieldinactivity and integration the demanding challenges have become OOD detectionand AD. In addition we also highlight the significant shift in the definitionproblem settings and benchmarks we thus feature a comprehensive review of themethodology for OOD detection including the discussion over other relatedtasks to clarify their relationship to OOD detection. Finally we explore theadvancements in the emerging Large Vision Language Model LVLM era such asGPT-4V. We conclude this survey with open challenges and future directions. |


| Item |Content|
| --- |---|
|idx| 2407.21788v1 |
|title| Vision-Language Model Based Handwriting Verification |
|authors| Mihir ChauhanAbhishek SatbhaiMohammad Abuzar HashemiMir Basheer AliBina RamamurthyMingchen GaoSiwei LyuSargur Srihari
|links| http://arxiv.org/abs/2407.21788v1 |
|updated| 2024-07-31 17:57:32 UTC |
|summary| Handwriting Verification is a critical in document forensics. Deep learningbased approaches often face skepticism from forensic document examiners due totheir lack of explainability and reliance on extensive training data andhandcrafted features. This paper explores using Vision Language Models VLMssuch as OpenAIs GPT-4o and Googles PaliGemma to address these challenges. Byleveraging their Visual Question Answering capabilities and 0-shotChain-of-Thought CoT reasoning our goal is to provide clearhuman-understandable explanations for model decisions. Our experiments on theCEDAR handwriting dataset demonstrate that VLMs offer enhancedinterpretability reduce the need for large training datasets and adapt betterto diverse handwriting styles. However results show that the CNN-basedResNet-18 architecture outperforms the 0-shot CoT prompt engineering approachwith GPT-4o Accuracy: 70 and supervised fine-tuned PaliGemma Accuracy:71 achieving an accuracy of 84 on the CEDAR AND dataset. These findingshighlight the potential of VLMs in generating human-interpretable decisionswhile underscoring the need for further advancements to match the performanceof specialized deep learning models. |


| Item |Content|
| --- |---|
|idx| 2407.21783v1 |
|title| The Llama 3 Herd of Models |
|authors| Abhimanyu DubeyAbhinav JauhriAbhinav PandeyAbhishek KadianAhmad Al-DahleAiesha LetmanAkhil MathurAlan ScheltenAmy YangAngela FanAnirudh GoyalAnthony HartshornAobo YangArchi MitraArchie SravankumarArtem KorenevArthur HinsvarkArun RaoAston ZhangAurelien RodriguezAusten GregersonAva SpataruBaptiste RoziereBethany BironBinh TangBobbie ChernCharlotte CaucheteuxChaya NayakChloe BiChris MarraChris McConnellChristian KellerChristophe TouretChunyang WuCorinne WongCristian Canton FerrerCyrus NikolaidisDamien AllonsiusDaniel SongDanielle PintzDanny LivshitsDavid EsiobuDhruv ChoudharyDhruv MahajanDiego Garcia-OlanoDiego PerinoDieuwke HupkesEgor LakomkinEhab AlBadawyElina LobanovaEmily DinanEric Michael SmithFilip RadenovicFrank ZhangGabriel SynnaeveGabrielle LeeGeorgia Lewis AndersonGraeme NailGregoire MialonGuan PangGuillem CucurellHailey NguyenHannah KorevaarHu XuHugo TouvronIliyan ZarovImanol Arrieta IbarraIsabel KloumannIshan MisraIvan EvtimovJade CopetJaewon LeeJan GeffertJana VranesJason ParkJay MahadeokarJeet ShahJelmer van der LindeJennifer BillockJenny HongJenya LeeJeremy FuJianfeng ChiJianyu HuangJiawen LiuJie WangJiecao YuJoanna BittonJoe SpisakJongsoo ParkJoseph RoccaJoshua JohnstunJoshua SaxeJunteng JiaKalyan Vasuden AlwalaKartikeya UpasaniKate PlawiakKe LiKenneth HeafieldKevin StoneKhalid El-AriniKrithika IyerKshitiz MalikKuenley ChiuKunal BhallaLauren Rantala-YearyLaurens van der MaatenLawrence ChenLiang TanLiz JenkinsLouis MartinLovish MadaanLubo MaloLukas BlecherLukas LandzaatLuke de OliveiraMadeline MuzziMahesh PasupuletiMannat SinghManohar PaluriMarcin KardasMathew OldhamMathieu RitaMaya PavlovaMelanie KambadurMike LewisMin SiMitesh Kumar SinghMona HassanNaman GoyalNarjes TorabiNikolay BashlykovNikolay BogoychevNiladri ChatterjiOlivier DuchenneOnur ÇelebiPatrick AlrassyPengchuan ZhangPengwei LiPetar VasicPeter WengPrajjwal BhargavaPratik DubalPraveen KrishnanPunit Singh KouraPuxin XuQing HeQingxiao DongRagavan SrinivasanRaj GanapathyRamon CaldererRicardo Silveira CabralRobert StojnicRoberta RaileanuRohit GirdharRohit PatelRomain SauvestreRonnie PolidoroRoshan SumbalyRoss TaylorRuan SilvaRui HouRui WangSaghar HosseiniSahana ChennabasappaSanjay SinghSean BellSeohyun Sonia KimSergey EdunovShaoliang NieSharan NarangSharath RaparthySheng ShenShengye WanShruti BhosaleShun ZhangSimon VandenhendeSoumya BatraSpencer WhitmanSten SootlaStephane CollotSuchin GururanganSydney BorodinskyTamar HermanTara FowlerTarek SheashaThomas GeorgiouThomas ScialomTobias SpeckbacherTodor MihaylovTong XiaoUjjwal KarnVedanuj GoswamiVibhor GuptaVignesh RamanathanViktor KerkezVincent GonguetVirginie DoVish VogetiVladan PetrovicWeiwei ChuWenhan XiongWenyin FuWhitney MeersXavier MartinetXiaodong WangXiaoqing Ellen TanXinfeng XieXuchao JiaXuewei WangYaelle GoldschlagYashesh GaurYasmine BabaeiYi WenYiwen SongYuchen ZhangYue LiYuning MaoZacharie Delpierre CoudertZheng YanZhengxing ChenZoe PapakiposAaditya SinghAaron GrattafioriAbha JainAdam KelseyAdam ShajnfeldAdithya GangidiAdolfo VictoriaAhuva GoldstandAjay MenonAjay SharmaAlex BoesenbergAlex VaughanAlexei BaevskiAllie FeinsteinAmanda KalletAmit SanganiAnam YunusAndrei LupuAndres AlvaradoAndrew CaplesAndrew GuAndrew HoAndrew PoultonAndrew RyanAnkit RamchandaniAnnie FrancoAparajita SarafArkabandhu ChowdhuryAshley GabrielAshwin BharambeAssaf EisenmanAzadeh YazdanBeau JamesBen MaurerBenjamin LeonhardiBernie HuangBeth LoydBeto De PaolaBhargavi ParanjapeBing LiuBo WuBoyu NiBraden HancockBram WastiBrandon SpenceBrani StojkovicBrian GamidoBritt MontalvoCarl ParkerCarly BurtonCatalina MejiaChanghan WangChangkyu KimChao ZhouChester HuChing-Hsiang ChuChris CaiChris TindalChristoph FeichtenhoferDamon CivinDana BeatyDaniel KreymerDaniel LiDanny WyattDavid AdkinsDavid XuDavide TestuggineDelia DavidDevi ParikhDiana LiskovichDidem FossDingkang WangDuc LeDustin HollandEdward DowlingEissa JamilElaine MontgomeryEleonora PresaniEmily HahnEmily WoodErik BrinkmanEsteban ArcauteEvan DunbarEvan SmothersFei SunFelix KreukFeng TianFirat OzgenelFrancesco CaggioniFrancisco GuzmánFrank KanayetFrank SeideGabriela Medina FlorezGabriella SchwarzGada BadeerGeorgia SweeGil HalpernGovind ThattaiGrant HermanGrigory SizovGuangyiZhangGuna LakshminarayananHamid ShojanazeriHan ZouHannah WangHanwen ZhaHaroun HabeebHarrison RudolphHelen SukHenry AspegrenHunter GoldmanIgor MolybogIgor TufanovIrina-Elena VelicheItai GatJake WeissmanJames GeboskiJames KohliJaphet AsherJean-Baptiste GayaJeff MarcusJeff TangJennifer ChanJenny ZhenJeremy ReizensteinJeremy TeboulJessica ZhongJian JinJingyi YangJoe CummingsJon CarvillJon ShepardJonathan McPhieJonathan TorresJosh GinsburgJunjie WangKai WuKam Hou UKaran SaxenaKarthik PrasadKartikay KhandelwalKatayoun ZandKathy MatosichKaushik VeeraraghavanKelly MichelenaKeqian LiKun HuangKunal ChawlaKushal LakhotiaKyle HuangLailin ChenLakshya GargLavender ALeandro SilvaLee BellLei ZhangLiangpeng GuoLicheng YuLiron MoshkovichLuca WehrstedtMadian KhabsaManav AvalaniManish BhattMaria TsimpoukelliMartynas MankusMatan HassonMatthew LennieMatthias ResoMaxim GroshevMaxim NaumovMaya LathiMeghan KeneallyMichael L. SeltzerMichal ValkoMichelle RestrepoMihir PatelMik VyatskovMikayel SamvelyanMike ClarkMike MaceyMike WangMiquel Jubert HermosoMo MetanatMohammad RastegariMunish BansalNandhini SanthanamNatascha ParksNatasha WhiteNavyata BawaNayan SinghalNick EgeboNicolas UsunierNikolay Pavlovich LaptevNing DongNing ZhangNorman ChengOleg ChernoguzOlivia HartOmkar SalpekarOzlem KalinliParkin KentParth ParekhPaul SaabPavan BalajiPedro RittnerPhilip BontragerPierre RouxPiotr DollarPolina ZvyaginaPrashant RatanchandaniPritish YuvrajQian LiangRachad AlaoRachel RodriguezRafi AyubRaghotham MurthyRaghu NayaniRahul MitraRaymond LiRebekkah HoganRobin BatteyRocky WangRohan MaheswariRuss HowesRuty RinottSai Jayesh BonduSamyak DattaSara ChughSara HuntSargun DhillonSasha SidorovSatadru PanSaurabh VermaSeiji YamamotoSharadh RamaswamyShaun LindsayShaun LindsaySheng FengShenghao LinShengxin Cindy ZhaShiva ShankarShuqiang ZhangShuqiang ZhangSinong WangSneha AgarwalSoji SajuyigbeSoumith ChintalaStephanie MaxStephen ChenSteve KehoeSteve SatterfieldSudarshan GovindaprasadSumit GuptaSungmin ChoSunny VirkSuraj SubramanianSy ChoudhurySydney GoldmanTal RemezTamar GlaserTamara BestThilo KohlerThomas RobinsonTianhe LiTianjun ZhangTim MatthewsTimothy ChouTzook ShakedVarun VontimittaVictoria AjayiVictoria MontanezVijai MohanVinay Satish KumarVishal ManglaVlad IonescuVlad PoenaruVlad Tiberiu MihailescuVladimir IvanovWei LiWenchen WangWenwen JiangWes BouazizWill ConstableXiaocheng TangXiaofang WangXiaojian WuXiaolan WangXide XiaXilun WuXinbo GaoYanjun ChenYe HuYe JiaYe QiYenda LiYilin ZhangYing ZhangYossi AdiYoungjin NamYuWangYuchen HaoYundi QianYuzi HeZach RaitZachary DeVitoZef RosnbrickZhaoduo WenZhenyu YangZhiwei Zhao
|links| http://arxiv.org/abs/2407.21783v1 |
|updated| 2024-07-31 17:54:27 UTC |
|summary| Modern artificial intelligence AI systems are powered by foundation models.This paper presents a new set of foundation models called Llama 3. It is aherd of language models that natively support multilinguality codingreasoning and tool usage. Our largest model is a dense Transformer with 405Bparameters and a context window of up to 128K tokens. This paper presents anextensive empirical evaluation of Llama 3. We find that Llama 3 deliverscomparable quality to leading language models such as GPT-4 on a plethora oftasks. We publicly release Llama 3 including pre-trained and post-trainedversions of the 405B parameter language model and our Llama Guard 3 model forinput and output safety. The paper also presents the results of experiments inwhich we integrate image video and speech capabilities into Llama 3 via acompositional approach. We observe this approach performs competitively withthe state-of-the-art on image video and speech recognition tasks. Theresulting models are not yet being broadly released as they are still underdevelopment. |


| Item |Content|
| --- |---|
|idx| 2407.21773v1 |
|title| RainMamba: Enhanced Locality Learning with State Space Models for Video Deraining |
|authors| Hongtao WuYijun YangHuihui XuWeiming WangJinni ZhouLei Zhu
|links| http://dx.doi.org/10.1145/3664647.3680916 |
|updated| 2024-07-31 17:48:22 UTC |
|summary| The outdoor vision systems are frequently contaminated by rain streaks andraindrops which significantly degenerate the performance of visual tasks andmultimedia applications. The nature of videos exhibits redundant temporal cuesfor rain removal with higher stability. Traditional video deraining methodsheavily rely on optical flow estimation and kernel-based manners which have alimited receptive field. Yet transformer architectures while enablinglong-term dependencies bring about a significant increase in computationalcomplexity. Recently the linear-complexity operator of the state space modelsSSMs has contrarily facilitated efficient long-term temporal modeling whichis crucial for rain streaks and raindrops removal in videos. Unexpectedly itsuni-dimensional sequential process on videos destroys the local correlationsacross the spatio-temporal dimension by distancing adjacent pixels. To addressthis we present an improved SSMs-based video deraining network RainMambawith a novel Hilbert scanning mechanism to better capture sequence-level localinformation. We also introduce a difference-guided dynamic contrastive localitylearning strategy to enhance the patch-level self-similarity learning abilityof the proposed network. Extensive experiments on four synthesized videoderaining datasets and real-world rainy videos demonstrate the superiority ofour network in the removal of rain streaks and raindrops. |


| Item |Content|
| --- |---|
|idx| 2407.21771v1 |
|title| Paying More Attention to Image: A Training-Free Method for Alleviating Hallucination in LVLMs |
|authors| Shi LiuKecheng ZhengWei Chen
|links| http://arxiv.org/abs/2407.21771v1 |
|updated| 2024-07-31 17:46:57 UTC |
|summary| Existing Large Vision-Language Models LVLMs primarily align image featuresof vision encoder with Large Language Models LLMs to leverage their superiortext generation capabilities. However the scale disparity between visionencoder and language model may led to LLMs assuming a predominant role inmulti-modal comprehension. This imbalance in LVLMs may result in the instancesof hallucinatory. Concretely LVLMs may generate consistent descriptions withor without visual input indicating that certain outputs are influenced solelyby context text. We refer to this phenomenon as text inertia. To counteractthis issue we introduce a training-free algorithm to find an equilibrium pointbetween image comprehension and language inference. Specifically we adaptivelyinvolve adjusting and amplifying the attention weights assigned to imagetokens thereby granting greater prominence to visual elements. Meanwhile wesubtract the logits of multi-modal inputs from ones of pure text input whichcan help LVLMs be not biased towards LLMs. By enhancing images tokens andreducing the stubborn output of LLM we can let LVLM pay more attention toimages towards alleviating text inertia and reducing the hallucination inLVLMs. Our extensive experiments shows that this method substantially reducesthe frequency of hallucinatory outputs in various LVLMs in terms of differentmetrics. Project page is available at https://lalbj.github.io/projects/PAI/. |


# stat.ML 

| Item |Content|
| --- |---|
|idx| 2407.21622v1 |
|title| Extended Fiducial Inference: Toward an Automated Process of Statistical Inference |
|authors| Faming LiangSehwan KimYan Sun
|links| http://arxiv.org/abs/2407.21622v1 |
|updated| 2024-07-31 14:15:42 UTC |
|summary| While fiducial inference was widely considered a big blunder by R.A. Fisherthe goal he initially set --inferring the uncertainty of model parameters onthe basis of observations -- has been continually pursued by manystatisticians. To this end we develop a new statistical inference methodcalled extended Fiducial inference EFI. The new method achieves the goal offiducial inference by leveraging advanced statistical computing techniqueswhile remaining scalable for big data. EFI involves jointly imputing randomerrors realized in observations using stochastic gradient Markov chain MonteCarlo and estimating the inverse function using a sparse deep neural networkDNN. The consistency of the sparse DNN estimator ensures that the uncertaintyembedded in observations is properly propagated to model parameters through theestimated inverse function thereby validating downstream statisticalinference. Compared to frequentist and Bayesian methods EFI offers significantadvantages in parameter estimation and hypothesis testing. Specifically EFIprovides higher fidelity in parameter estimation especially when outliers arepresent in the observations and eliminates the need for theoretical referencedistributions in hypothesis testing thereby automating the statisticalinference process. EFI also provides an innovative framework forsemi-supervised learning. |


| Item |Content|
| --- |---|
|idx| 2407.21435v1 |
|title| Transient anisotropic kernel for probabilistic learning on manifolds |
|authors| Christian SoizeRoger Ghanem
|links| http://arxiv.org/abs/2407.21435v1 |
|updated| 2024-07-31 08:38:39 UTC |
|summary| PLoM Probabilistic Learning on Manifolds is a method introduced in 2016 forhandling small training datasets by projecting an Ito equation from astochastic dissipative Hamiltonian dynamical system acting as the MCMCgenerator for which the KDE-estimated probability measure with the trainingdataset is the invariant measure. PLoM performs a projection on a reduced-ordervector basis related to the training dataset using the diffusion maps DMAPSbasis constructed with a time-independent isotropic kernel. In this paper wepropose a new ISDE projection vector basis built from a transient anisotropickernel providing an alternative to the DMAPS basis to improve statisticalsurrogates for stochastic manifolds with heterogeneous data. The constructionensures that for times near the initial time the DMAPS basis coincides withthe transient basis. For larger times the differences between the two basesare characterized by the angle of their spanned vector subspaces. The optimalinstant yielding the optimal transient basis is determined using an estimationof mutual information from Information Theory which is normalized by theentropy estimation to account for the effects of the number of realizationsused in the estimations. Consequently this new vector basis better representsstatistical dependencies in the learned probability measure for any dimension.Three applications with varying levels of statistical complexity and dataheterogeneity validate the proposed theory showing that the transientanisotropic kernel improves the learned probability measure. |


| Item |Content|
| --- |---|
|idx| 2407.21424v1 |
|title| Cost-Effective Hallucination Detection for LLMs |
|authors| Simon ValentinJinmiao FuGianluca DetommasoShaoyuan XuGiovanni ZappellaBryan Wang
|links| http://arxiv.org/abs/2407.21424v1 |
|updated| 2024-07-31 08:19:06 UTC |
|summary| Large language models LLMs can be prone to hallucinations - generatingunreliable outputs that are unfaithful to their inputs external facts orinternally inconsistent. In this work we address several challenges forpost-hoc hallucination detection in production settings. Our pipeline forhallucination detection entails: first producing a confidence scorerepresenting the likelihood that a generated answer is a hallucination secondcalibrating the score conditional on attributes of the inputs and candidateresponse finally performing detection by thresholding the calibrated score.We benchmark a variety of state-of-the-art scoring methods on differentdatasets encompassing question answering fact checking and summarizationtasks. We employ diverse LLMs to ensure a comprehensive assessment ofperformance. We show that calibrating individual scoring methods is criticalfor ensuring risk-aware downstream decision making. Based on findings that noindividual score performs best in all situations we propose a multi-scoringframework which combines different scores and achieves top performance acrossall datasets. We further introduce cost-effective multi-scoring which canmatch or even outperform more expensive detection methods while significantlyreducing computational overhead. |


| Item |Content|
| --- |---|
|idx| 2407.21420v1 |
|title| Whitney extension theorems on symmetric spaces, an example |
|authors| Birgit SpehPeter Vang Uttenthal
|links| http://arxiv.org/abs/2407.21420v1 |
|updated| 2024-07-31 08:09:04 UTC |
|summary| H. Whitney introduced in 1934 the problem of extending a function on a set ofpoints in mathbbRn to an analytic function on the ambient space. In thisarticle we prove Whitney type extension theorems for data on some homogeneousspaces. We use harmonic analysis on the homogeneous spaces and representationtheory of compact as well as noncompact reductive groups. |


| Item |Content|
| --- |---|
|idx| 2407.21372v1 |
|title| Two Completely Parameter-Free Alternating Gradient Projection Algorithms for Nonconvex-(strongly) Concave Minimax Problems |
|authors| Junnan YangHuiling ZhangZi Xu
|links| http://arxiv.org/abs/2407.21372v1 |
|updated| 2024-07-31 06:54:24 UTC |
|summary| Due to their importance in various emerging applications efficientalgorithms for solving minimax problems have recently received increasingattention. However many existing algorithms require prior knowledge of theproblem parameters in order to achieve optimal iteration complexity. In thispaper we propose a completely parameter-free alternating gradient projectionPF-AGP algorithm to solve the smooth nonconvex-strongly concave minimaxproblems using a backtracking strategy which does not require prior knowledgeof parameters such as the Lipschtiz constant L or the strongly concaveconstant mu. The PF-AGP algorithm utilizes a parameter-free gradientprojection step to alternately update the outer and inner variables in eachiteration. We show that the total number of gradient calls of the PF-AGPalgorithm to obtain an varepsilon-stationary point for nonconvex-stronglyconcave minimax problems is upper bounded by mathcalOleftLkappa3varepsilon-2 right where kappa is the condition numberwhile the total number of gradient calls to obtain an varepsilon-stationarypoint for nonconvex-concave minimax problems is upper bounded bymathcalOleft L4varepsilon-4 right. As far as we know this is thefirst completely parameter-free algorithm for solving nonconvex-stronglyconcave minimax problems and it is also the completely parameter-freealgorithm which achieves the best iteration complexity in single loop methodfor solving nonconvex-concave minimax problems. Numerical results validate theefficiency of the proposed PF-AGP algorithm. |


# cs.HC 

| Item |Content|
| --- |---|
|idx| 2407.21767v1 |
|title| Does empirical evidence from healthy aging studies predict a practical difference between visualizations for different age groups? |
|authors| S. ShaoY. LiA. I. MesoN. Holliman
|links| http://arxiv.org/abs/2407.21767v1 |
|updated| 2024-07-31 17:44:16 UTC |
|summary| When communicating critical information to decision-makers one of the majorchallenges in visualization is whether the communication is affected bydifferent perceptual or cognitive abilities one major influencing factor isage. We review both visualization and psychophysics literature to understandwhere quantitative evidence exists on age differences in visual perception.Using contrast sensitivity data from the literature we show how the differencesbetween visualizations for different age groups can be predicted using a newmodel of visible frequency range with age. The model assumed that at thresholdvalues some visual data will not be visible to older people spatial frequency 2 and contrast 0.01. We apply this result to a practical visualization andshow an example that at higher levels of contrast the visual signal should beperceivable by all viewers over 20. Universally usable visualization should usea contrast of 0.02 or higher and be designed to avoid spatial frequenciesgreater than eight cycles per degree to accommodate all ages. There remainsmuch research to do on to translate psychophysics results to practicalquantitative guidelines for visualization producers. |


| Item |Content|
| --- |---|
|idx| 2407.21665v1 |
|title| A State-of-the-Art Review of Computational Models for Analyzing Longitudinal Wearable Sensor Data in Healthcare |
|authors| Paula Lago
|links| http://arxiv.org/abs/2407.21665v1 |
|updated| 2024-07-31 15:08:15 UTC |
|summary| Wearable devices are increasingly used as tools for biomedical research asthe continuous stream of behavioral and physiological data they collect canprovide insights about our health in everyday contexts. Long-term trackingdefined in the timescale of months of year can provide insights of patternsand changes as indicators of health changes. These insights can make medicineand healthcare more predictive preventive personalized and participativeThe 4Ps. However the challenges in modeling understanding and processinglongitudinal data are a significant barrier to their adoption in researchstudies and clinical settings. In this paper we review and discuss threemodels used to make sense of longitudinal data: routines rhythms and stabilitymetrics. We present the challenges associated with the processing and analysisof longitudinal wearable sensor data with a special focus on how to handle thedifferent temporal dynamics at various granularities. We then discuss currentlimitations and identify directions for future work. This review is essentialto the advancement of computational modeling and analysis of longitudinalsensor data for pervasive healthcare. |


| Item |Content|
| --- |---|
|idx| 2407.21615v1 |
|title| Between the AI and Me: Analysing Listeners' Perspectives on AI- and Human-Composed Progressive Metal Music |
|authors| Pedro SarmentoJackson LothMathieu Barthet
|links| http://arxiv.org/abs/2407.21615v1 |
|updated| 2024-07-31 14:03:45 UTC |
|summary| Generative AI models have recently blossomed significantly impactingartistic and musical traditions. Research investigating how humans interactwith and deem these models is therefore crucial. Through a listening andreflection study we explore participants perspectives on AI- vshuman-generated progressive metal in symbolic format using rock music as acontrol group. AI-generated examples were produced by ProgGP aTransformer-based model. We propose a mixed methods approach to assess theeffects of generation type human vs. AI genre progressive metal vs. rockand curation process random vs. cherry-picked. This combines quantitativefeedback on genre congruence preference creativity consistency playabilityhumanness and repeatability and qualitative feedback to provide insights intolisteners experiences. A total of 32 progressive metal fans completed thestudy. Our findings validate the use of fine-tuning to achieve genre-specificspecialization in AI music generation as listeners could distinguish betweenAI-generated rock and progressive metal. Despite some AI-generated excerptsreceiving similar ratings to human music listeners exhibited a preference forhuman compositions. Thematic analysis identified key features for genre and AIvs. human distinctions. Finally we consider the ethical implications of ourwork in promoting musical data diversity within MIR research by focusing on anunder-explored genre. |


| Item |Content|
| --- |---|
|idx| 2407.21593v1 |
|title| LLM-for-X: Application-agnostic Integration of Large Language Models to Support Personal Writing Workflows |
|authors| Lukas TeufelbergerXintong LiuZhipeng LiMax MoebusChristian Holz
|links| http://arxiv.org/abs/2407.21593v1 |
|updated| 2024-07-31 13:29:22 UTC |
|summary| To enhance productivity and to streamline workflows there is a growing trendto embed large language model LLM functionality into applications frombrowser-based web apps to native apps that run on personal computers. Here weintroduce LLM-for-X a system-wide shortcut layer that seamlessly augments anyapplication with LLM services through a lightweight popup dialog. Our nativelayer seamlessly connects front-end applications to popular LLM backends suchas ChatGPT and Gemini using their uniform chat front-ends as the programminginterface or their custom API calls. We demonstrate the benefits of LLM-for-Xacross a wide variety of applications including Microsoft Office VSCode andAdobe Acrobat as well as popular web apps such as Overleaf. In our evaluationwe compared LLM-for-X with ChatGPTs web interface in a series of tasksshowing that our approach can provide users with quick efficient andeasy-to-use LLM assistance without context switching to support writing andreading tasks that is agnostic of the specific application. |


| Item |Content|
| --- |---|
|idx| 2407.21592v1 |
|title| Does the Source of a Warning Matter? Examining the Effectiveness of Veracity Warning Labels Across Warners |
|authors| Benjamin D. Horne
|links| http://arxiv.org/abs/2407.21592v1 |
|updated| 2024-07-31 13:27:26 UTC |
|summary| In this study we conducted an online between-subjects experiment N 2049 to better understand the impact of warning label sources on informationtrust and sharing intentions. Across four warners the social media platformother social media users Artificial Intelligence AI and fact checkers wefound that all significantly decreased trust in false information relative tocontrol but warnings from AI were modestly more effective. All warnerssignificantly decreased the sharing intentions of false information exceptwarnings from other social media users. AI was again the most effective. Theseresults were moderated by prior trust in media and the information itself. Mostnoteworthy we found that warning labels from AI were significantly moreeffective than all other warning labels for participants who reported a lowtrust in news organizations while warnings from AI were no more effective thanany other warning label for participants who reported a high trust in newsorganizations. |


# cs.MA 

| Item |Content|
| --- |---|
|idx| 2407.21307v1 |
|title| Modeling Urban Transport Choices: Incorporating Sociocultural Aspects |
|authors| Kathleen Salazar-SernaLorena CadavidCarlos J. Franco
|links| http://arxiv.org/abs/2407.21307v1 |
|updated| 2024-07-31 03:19:56 UTC |
|summary| This paper introduces an agent-based simulation model aimed at understandingurban commuters mode choices and evaluating the impacts of transport policiesto promote sustainable mobility. Crafted for developing countries whereutilitarian travel heavily relies on motorcycles the model integratessociocultural factors that influence transport behavior. Multinomial models andinferential statistics applied to survey data from Cali Colombia inform themodel revealing significant influences of sociodemographic factors and travelattributes on mode choice. Findings highlight the importance of cost timesafety comfort and personal security with disparities across socioeconomicgroups. Policy simulations demonstrate positive responses to interventions likefree public transportation increased bus frequency and enhanced security yetwith modest shifts in mode choice. Multifaceted policy approaches are deemedmore effective addressing diverse user preferences. Outputs can be extended tocities with similar sociocultural characteristics and transport dynamics. Themethodology applied in this work can be replicated for other territories. |


| Item |Content|
| --- |---|
|idx| 2407.21294v1 |
|title| Decentralized and Uncoordinated Learning of Stable Matchings: A Game-Theoretic Approach |
|authors| S. Rasoul EtesamiR. Srikant
|links| http://arxiv.org/abs/2407.21294v1 |
|updated| 2024-07-31 02:36:14 UTC |
|summary| We consider the problem of learning stable matchings in a fully decentralizedand uncoordinated manner. In this problem there are n men and n womeneach having preference over the other side. It is assumed that women know theirpreferences over men but men are not aware of their preferences over womenand they only learn them if they propose and successfully get matched to women.A matching is called stable if no man and woman prefer each other over theircurrent matches. When all the preferences are known a priori the celebratedDeferred-Acceptance algorithm proposed by Gale and Shapley provides adecentralized and uncoordinated algorithm to obtain a stable matching. Howeverwhen the preferences are unknown developing such an algorithm faces majorchallenges due to a lack of coordination. We achieve this goal by making aconnection between stable matchings and learning Nash equilibria NE innoncooperative games. First we provide a complete information game formulationfor the stable matching problem with known preferences such that its set ofpure NE coincides with the set of stable matchings while its mixed NE can berounded in a decentralized manner to a stable matching. Relying on such agame-theoretic formulation we show that for hierarchical markets adopting theexponential weight EXP learning algorithm for the stable matching gameachieves logarithmic regret with polynomial dependence on the number ofplayers thus answering a question posed in previous literature. Moreover weshow that the same EXP learning algorithm converges locally and exponentiallyfast to a stable matching in general matching markets. We complement thisresult by introducing another decentralized and uncoordinated learningalgorithm that globally converges to a stable matching with arbitrarily highprobability leveraging the weak acyclicity property of the stable matchinggame. |


| Item |Content|
| --- |---|
|idx| 2407.20770v1 |
|title| Non-Bayesian Social Learning with Multiview Observations |
|authors| Dongyan SuiWeichen CaoStefan VlaskiChun GuanSiyang Leng
|links| http://arxiv.org/abs/2407.20770v1 |
|updated| 2024-07-30 12:16:02 UTC |
|summary| Non-Bayesian social learning enables multiple agents to conduct networkedsignal and information processing through observing environmental signals andinformation aggregating. Traditional non-Bayesian social learning models onlyconsider single signals limiting their applications in scenarios wheremultiple viewpoints of information are available. In this work we exploit inthe information aggregation step the independently learned results fromobservations taken from multiple viewpoints and propose a novel non-Bayesiansocial learning model for scenarios with multiview observations. We prove theconvergence of the model under traditional assumptions and provide convergenceconditions for the algorithm in the presence of misleading signals. Throughtheoretical analyses and numerical experiments we validate the strongreliability and robustness of the proposed algorithm showcasing its potentialfor real-world applications. |


| Item |Content|
| --- |---|
|idx| 2407.20739v1 |
|title| Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization |
|authors| Michael KölleKarola SchneiderSabrina EggerFelix ToppThomy PhanPhilipp AltmannJonas NüßleinClaudia Linnhoff-Popien
|links| http://arxiv.org/abs/2407.20739v1 |
|updated| 2024-07-30 11:16:25 UTC |
|summary| In recent years Multi-Agent Reinforcement Learning MARL has foundapplication in numerous areas of science and industry such as autonomousdriving telecommunications and global health. Nevertheless MARL suffersfrom for instance an exponential growth of dimensions. Inherent properties ofquantum mechanics help to overcome these limitations e.g. by significantlyreducing the number of trainable parameters. Previous studies have developed anapproach that uses gradient-free quantum Reinforcement Learning andevolutionary optimization for variational quantum circuits VQCs to reduce thetrainable parameters and avoid barren plateaus as well as vanishing gradients.This leads to a significantly better performance of VQCs compared to classicalneural networks with a similar number of trainable parameters and a reductionin the number of parameters by more than 97  compared to similarly goodneural networks. We extend an approach of Kolle et al. by proposing aGate-Based a Layer-Based and a Prototype-Based concept to mutate andrecombine VQCs. Our results show the best performance for mutation-onlystrategies and the Gate-Based approach. In particular we observe asignificantly better score higher total and own collected coins as well as asuperior own coin rate for the best agent when evaluated in the Coin Gameenvironment. |


| Item |Content|
| --- |---|
|idx| 2407.20441v1 |
|title| Finite-Time Analysis of Asynchronous Multi-Agent TD Learning |
|authors| Nicolò Dal FabbroArman AdibiAritra MitraGeorge J. Pappas
|links| http://arxiv.org/abs/2407.20441v1 |
|updated| 2024-07-29 22:36:07 UTC |
|summary| Recent research endeavours have theoretically shown the beneficial effect ofcooperation in multi-agent reinforcement learning MARL. In a settinginvolving N agents this beneficial effect usually comes in the form of anN-fold linear convergence speedup i.e. a reduction - proportional to N -in the number of iterations required to reach a certain convergence precision.In this paper we show for the first time that this speedup property also holdsfor a MARL framework subject to asynchronous delays in the local agentsupdates. In particular we consider a policy evaluation problem in whichmultiple agents cooperate to evaluate a common policy by communicating with acentral aggregator. In this setting we study the finite-time convergence oftextttAsyncMATD an asynchronous multi-agent temporal difference TDlearning algorithm in which agents local TD update directions are subject toasynchronous bounded delays. Our main contribution is providing a finite-timeanalysis of textttAsyncMATD for which we establish a linear convergencespeedup while highlighting the effect of time-varying asynchronous delays onthe resulting convergence rate. |


