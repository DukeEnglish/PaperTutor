# cs.CL 

| Item |Content|
| --- |---|
|idx| 2405.03689v1 |
|title| Pose Priors from Language Models |
|authors| Sanjay SubramanianEvonne NgLea MüllerDan KleinShiry GinosarTrevor Darrell
|links| http://arxiv.org/abs/2405.03689v1 |
|updated| 2024-05-06 17:59:36 UTC |
|summary| We present a zero-shot pose optimization method that enforces accuratephysical contact constraints when estimating the 3D pose of humans. Our centralinsight is that since language is often used to describe physical interactionlarge pretrained text-based models can act as priors on pose estimation.  We can thus leverage this insight to improve pose estimation by convertingnatural language descriptors generated by a large multimodal model LMM intotractable losses to constrain the 3D pose optimization. Despite its simplicityour method produces surprisingly compelling pose reconstructions of people inclose contact correctly capturing the semantics of the social and physicalinteractions. We demonstrate that our method rivals more complexstate-of-the-art approaches that require expensive human annotation of contactpoints and training specialized models. Moreover unlike previous approachesour method provides a unified framework for resolving self-contact andperson-to-person contact. |


| Item |Content|
| --- |---|
|idx| 2405.03688v1 |
|title| Large Language Models Reveal Information Operation Goals, Tactics, and Narrative Frames |
|authors| Keith BurghardtKai ChenKristina Lerman
|links| http://arxiv.org/abs/2405.03688v1 |
|updated| 2024-05-06 17:59:07 UTC |
|summary| Adversarial information operations can destabilize societies by underminingfair elections manipulating public opinions on policies and promoting scams.Despite their widespread occurrence and potential impacts our understanding ofinfluence campaigns is limited by manual analysis of messages and subjectiveinterpretation of their observable behavior. In this paper we explore whetherthese limitations can be mitigated with large language models LLMs usingGPT-3.5 as a case-study for coordinated campaign annotation. We first useGPT-3.5 to scrutinize 126 identified information operations spanning over adecade. We utilize a number of metrics to quantify the close if imperfectagreement between LLM and ground truth descriptions. We next extractcoordinated campaigns from two large multilingual datasets from X formerlyTwitter that respectively discuss the 2022 French election and 2023 BalikaranPhilippine-U.S. military exercise in 2023. For each coordinated campaign weuse GPT-3.5 to analyze posts related to a specific concern and extract goalstactics and narrative frames both before and after critical events such asthe date of an election. While the GPT-3.5 sometimes disagrees with subjectiveinterpretation its ability to summarize and interpret demonstrates LLMspotential to extract higher-order indicators from text to provide a morecomplete picture of the information campaigns compared to previous methods. |


| Item |Content|
| --- |---|
|idx| 2405.03685v1 |
|title| Language-Image Models with 3D Understanding |
|authors| Jang Hyun ChoBoris IvanovicYulong CaoEdward SchmerlingYue WangXinshuo WengBoyi LiYurong YouPhilipp KrähenbühlYan WangMarco Pavone
|links| http://arxiv.org/abs/2405.03685v1 |
|updated| 2024-05-06 17:57:27 UTC |
|summary| Multi-modal large language models MLLMs have shown incredible capabilitiesin a variety of 2D vision and language tasks. We extend MLLMs perceptualcapabilities to ground and reason about images in 3-dimensional space. To thatend we first develop a large-scale pre-training dataset for 2D and 3D calledLV3D by combining multiple existing 2D and 3D recognition datasets under acommon task formulation: as multi-turn question-answering. Next we introduce anew MLLM named Cube-LLM and pre-train it on LV3D. We show that pure datascaling makes a strong 3D perception capability without 3D specificarchitectural design or training objective. Cube-LLM exhibits intriguingproperties similar to LLMs: 1 Cube-LLM can apply chain-of-thought promptingto improve 3D understanding from 2D context information. 2 Cube-LLM canfollow complex and diverse instructions and adapt to versatile input and outputformats. 3 Cube-LLM can be visually prompted such as 2D box or a set ofcandidate 3D boxes from specialists. Our experiments on outdoor benchmarksdemonstrate that Cube-LLM significantly outperforms existing baselines by 21.3points of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7points on the DriveLM dataset for complex reasoning about driving scenariosrespectively. Cube-LLM also shows competitive results in general MLLMbenchmarks such as refCOCO for 2D grounding with 87.0 average score as wellas visual question answering benchmarks such as VQAv2 GQA SQA POPE etc. forcomplex reasoning. Our project is available athttps://janghyuncho.github.io/Cube-LLM. |


| Item |Content|
| --- |---|
|idx| 2405.03677v1 |
|title| Towards A Human-in-the-Loop LLM Approach to Collaborative Discourse Analysis |
|authors| Clayton CohnCaitlin SnyderJustin MontenegroGautam Biswas
|links| http://arxiv.org/abs/2405.03677v1 |
|updated| 2024-05-06 17:53:33 UTC |
|summary| LLMs have demonstrated proficiency in contextualizing their outputs usinghuman input often matching or beating human-level performance on a variety oftasks. However LLMs have not yet been used to characterize synergisticlearning in students collaborative discourse. In this exploratory work wetake a first step towards adopting a human-in-the-loop prompt engineeringapproach with GPT-4-Turbo to summarize and categorize students synergisticlearning during collaborative discourse. Our preliminary findings suggestGPT-4-Turbo may be able to characterize students synergistic learning in amanner comparable to humans and that our approach warrants furtherinvestigation. |


| Item |Content|
| --- |---|
|idx| 2405.03595v1 |
|title| GREEN: Generative Radiology Report Evaluation and Error Notation |
|authors| Sophie OstmeierJustin XuZhihong ChenMaya VarmaLouis BlankemeierChristian BluethgenArne Edward MichalsonMichael MoseleyCurtis LanglotzAkshay S ChaudhariJean-Benoit Delbrouck
|links| http://arxiv.org/abs/2405.03595v1 |
|updated| 2024-05-06 16:04:03 UTC |
|summary| Evaluating radiology reports is a challenging problem as factual correctnessis extremely important due to the need for accurate medical communication aboutmedical images. Existing automatic evaluation metrics either suffer fromfailing to consider factual correctness e.g. BLEU and ROUGE or are limitedin their interpretability e.g. F1CheXpert and F1RadGraph. In this paper weintroduce GREEN Generative Radiology Report Evaluation and Error Notation aradiology report generation metric that leverages the natural languageunderstanding of language models to identify and explain clinically significanterrors in candidate reports both quantitatively and qualitatively. Compared tocurrent metrics GREEN offers: 1 a score aligned with expert preferences 2human interpretable explanations of clinically significant errors enablingfeedback loops with end-users and 3 a lightweight open-source method thatreaches the performance of commercial counterparts. We validate our GREENmetric by comparing it to GPT-4 as well as to error counts of 6 experts andpreferences of 2 experts. Our method demonstrates not only higher correlationwith expert error counts but simultaneously higher alignment with expertpreferences when compared to previous approaches. |


# cs.AI 

| Item |Content|
| --- |---|
|idx| 2405.03685v1 |
|title| Language-Image Models with 3D Understanding |
|authors| Jang Hyun ChoBoris IvanovicYulong CaoEdward SchmerlingYue WangXinshuo WengBoyi LiYurong YouPhilipp KrähenbühlYan WangMarco Pavone
|links| http://arxiv.org/abs/2405.03685v1 |
|updated| 2024-05-06 17:57:27 UTC |
|summary| Multi-modal large language models MLLMs have shown incredible capabilitiesin a variety of 2D vision and language tasks. We extend MLLMs perceptualcapabilities to ground and reason about images in 3-dimensional space. To thatend we first develop a large-scale pre-training dataset for 2D and 3D calledLV3D by combining multiple existing 2D and 3D recognition datasets under acommon task formulation: as multi-turn question-answering. Next we introduce anew MLLM named Cube-LLM and pre-train it on LV3D. We show that pure datascaling makes a strong 3D perception capability without 3D specificarchitectural design or training objective. Cube-LLM exhibits intriguingproperties similar to LLMs: 1 Cube-LLM can apply chain-of-thought promptingto improve 3D understanding from 2D context information. 2 Cube-LLM canfollow complex and diverse instructions and adapt to versatile input and outputformats. 3 Cube-LLM can be visually prompted such as 2D box or a set ofcandidate 3D boxes from specialists. Our experiments on outdoor benchmarksdemonstrate that Cube-LLM significantly outperforms existing baselines by 21.3points of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7points on the DriveLM dataset for complex reasoning about driving scenariosrespectively. Cube-LLM also shows competitive results in general MLLMbenchmarks such as refCOCO for 2D grounding with 87.0 average score as wellas visual question answering benchmarks such as VQAv2 GQA SQA POPE etc. forcomplex reasoning. Our project is available athttps://janghyuncho.github.io/Cube-LLM. |


| Item |Content|
| --- |---|
|idx| 2405.03673v1 |
|title| MemoryMamba: Memory-Augmented State Space Model for Defect Recognition |
|authors| Qianning WangHe HuYucheng Zhou
|links| http://arxiv.org/abs/2405.03673v1 |
|updated| 2024-05-06 17:49:31 UTC |
|summary| As automation advances in manufacturing the demand for precise andsophisticated defect detection technologies grows. Existing vision models fordefect recognition methods are insufficient for handling the complexities andvariations of defects in contemporary manufacturing settings. These modelsespecially struggle in scenarios involving limited or imbalanced defect data.In this work we introduce MemoryMamba a novel memory-augmented state spacemodel SSM designed to overcome the limitations of existing defectrecognition models. MemoryMamba integrates the state space model with thememory augmentation mechanism enabling the system to maintain and retrieveessential defect-specific information in training. Its architecture is designedto capture dependencies and intricate defect characteristics which are crucialfor effective defect detection. In the experiments MemoryMamba was evaluatedacross four industrial datasets with diverse defect types and complexities. Themodel consistently outperformed other methods demonstrating its capability toadapt to various defect recognition scenarios. |


| Item |Content|
| --- |---|
|idx| 2405.03671v1 |
|title| Prompting Task Trees using Gemini: Methodologies and Insights |
|authors| Pallavi Tandra
|links| http://arxiv.org/abs/2405.03671v1 |
|updated| 2024-05-06 17:48:10 UTC |
|summary| Robots are the future of every technology where every advanced technologyeventually will be used to make robots which are more efficient. The majorchallenge today is to train the robots exactly and empathetically usingknowledge representation. This paper gives you insights of how we can useunstructured knowledge representation and convert them to meaningful structuredrepresentation with the help of prompt engineering which can be eventually usedin the robots to make help them understand how human brain can make wonderswith the minimal data or objects can providing to them. |


| Item |Content|
| --- |---|
|idx| 2405.03666v1 |
|title| ScrewMimic: Bimanual Imitation from Human Videos with Screw Space Projection |
|authors| Arpit BahetyPriyanka MandikalBen AbbatematteoRoberto Martín-Martín
|links| http://arxiv.org/abs/2405.03666v1 |
|updated| 2024-05-06 17:43:34 UTC |
|summary| Bimanual manipulation is a longstanding challenge in robotics due to thelarge number of degrees of freedom and the strict spatial and temporalsynchronization required to generate meaningful behavior. Humans learn bimanualmanipulation skills by watching other humans and by refining their abilitiesthrough play. In this work we aim to enable robots to learn bimanualmanipulation behaviors from human video demonstrations and fine-tune themthrough interaction. Inspired by seminal work in psychology and biomechanicswe propose modeling the interaction between two hands as a serial kinematiclinkage -- as a screw motion in particular that we use to define a new actionspace for bimanual manipulation: screw actions. We introduce ScrewMimic aframework that leverages this novel action representation to facilitatelearning from human demonstration and self-supervised policy fine-tuning. Ourexperiments demonstrate that ScrewMimic is able to learn several complexbimanual behaviors from a single human video demonstration and that itoutperforms baselines that interpret demonstrations and fine-tune directly inthe original space of motion of both arms. For more information and videoresults https://robin-lab.cs.utexas.edu/ScrewMimic/ |


| Item |Content|
| --- |---|
|idx| 2405.03654v1 |
|title| Can LLMs Deeply Detect Complex Malicious Queries? A Framework for Jailbreaking via Obfuscating Intent |
|authors| Shang ShangXinqiang ZhaoZhongjiang YaoYepeng YaoLiya SuZijing FanXiaodan ZhangZhengwei Jiang
|links| http://arxiv.org/abs/2405.03654v1 |
|updated| 2024-05-06 17:26:34 UTC |
|summary| To demonstrate and address the underlying maliciousness we propose atheoretical hypothesis and analytical approach and introduce a new black-boxjailbreak attack methodology named IntentObfuscator exploiting this identifiedflaw by obfuscating the true intentions behind user prompts.This approachcompels LLMs to inadvertently generate restricted content bypassing theirbuilt-in content security measures. We detail two implementations under thisframework: Obscure Intention and Create Ambiguity which manipulate querycomplexity and ambiguity to evade malicious intent detection effectively. Weempirically validate the effectiveness of the IntentObfuscator method acrossseveral models including ChatGPT-3.5 ChatGPT-4 Qwen and Baichuan achievingan average jailbreak success rate of 69.21. Notably our tests onChatGPT-3.5 which claims 100 million weekly active users achieved aremarkable success rate of 83.65. We also extend our validation to diversetypes of sensitive content like graphic violence racism sexism politicalsensitivity cybersecurity threats and criminal skills further proving thesubstantial impact of our findings on enhancing Red Team strategies againstLLM content security frameworks. |


# cs.LG 

| Item |Content|
| --- |---|
|idx| 2405.03688v1 |
|title| Large Language Models Reveal Information Operation Goals, Tactics, and Narrative Frames |
|authors| Keith BurghardtKai ChenKristina Lerman
|links| http://arxiv.org/abs/2405.03688v1 |
|updated| 2024-05-06 17:59:07 UTC |
|summary| Adversarial information operations can destabilize societies by underminingfair elections manipulating public opinions on policies and promoting scams.Despite their widespread occurrence and potential impacts our understanding ofinfluence campaigns is limited by manual analysis of messages and subjectiveinterpretation of their observable behavior. In this paper we explore whetherthese limitations can be mitigated with large language models LLMs usingGPT-3.5 as a case-study for coordinated campaign annotation. We first useGPT-3.5 to scrutinize 126 identified information operations spanning over adecade. We utilize a number of metrics to quantify the close if imperfectagreement between LLM and ground truth descriptions. We next extractcoordinated campaigns from two large multilingual datasets from X formerlyTwitter that respectively discuss the 2022 French election and 2023 BalikaranPhilippine-U.S. military exercise in 2023. For each coordinated campaign weuse GPT-3.5 to analyze posts related to a specific concern and extract goalstactics and narrative frames both before and after critical events such asthe date of an election. While the GPT-3.5 sometimes disagrees with subjectiveinterpretation its ability to summarize and interpret demonstrates LLMspotential to extract higher-order indicators from text to provide a morecomplete picture of the information campaigns compared to previous methods. |


| Item |Content|
| --- |---|
|idx| 2405.03685v1 |
|title| Language-Image Models with 3D Understanding |
|authors| Jang Hyun ChoBoris IvanovicYulong CaoEdward SchmerlingYue WangXinshuo WengBoyi LiYurong YouPhilipp KrähenbühlYan WangMarco Pavone
|links| http://arxiv.org/abs/2405.03685v1 |
|updated| 2024-05-06 17:57:27 UTC |
|summary| Multi-modal large language models MLLMs have shown incredible capabilitiesin a variety of 2D vision and language tasks. We extend MLLMs perceptualcapabilities to ground and reason about images in 3-dimensional space. To thatend we first develop a large-scale pre-training dataset for 2D and 3D calledLV3D by combining multiple existing 2D and 3D recognition datasets under acommon task formulation: as multi-turn question-answering. Next we introduce anew MLLM named Cube-LLM and pre-train it on LV3D. We show that pure datascaling makes a strong 3D perception capability without 3D specificarchitectural design or training objective. Cube-LLM exhibits intriguingproperties similar to LLMs: 1 Cube-LLM can apply chain-of-thought promptingto improve 3D understanding from 2D context information. 2 Cube-LLM canfollow complex and diverse instructions and adapt to versatile input and outputformats. 3 Cube-LLM can be visually prompted such as 2D box or a set ofcandidate 3D boxes from specialists. Our experiments on outdoor benchmarksdemonstrate that Cube-LLM significantly outperforms existing baselines by 21.3points of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7points on the DriveLM dataset for complex reasoning about driving scenariosrespectively. Cube-LLM also shows competitive results in general MLLMbenchmarks such as refCOCO for 2D grounding with 87.0 average score as wellas visual question answering benchmarks such as VQAv2 GQA SQA POPE etc. forcomplex reasoning. Our project is available athttps://janghyuncho.github.io/Cube-LLM. |


| Item |Content|
| --- |---|
|idx| 2405.03676v1 |
|title| Why is SAM Robust to Label Noise? |
|authors| Christina BaekZico KolterAditi Raghunathan
|links| http://arxiv.org/abs/2405.03676v1 |
|updated| 2024-05-06 17:52:04 UTC |
|summary| Sharpness-Aware Minimization SAM is most known for achieving state-ofthe-art performances on natural image and language tasks. However its mostpronounced improvements of tens of percent is rather in the presence of labelnoise. Understanding SAMs label noise robustness requires a departure fromcharacterizing the robustness of minimas lying in flatter regions of the losslandscape. In particular the peak performance under label noise occurs withearly stopping far before the loss converges. We decompose SAMs robustnessinto two effects: one induced by changes to the logit term and the otherinduced by changes to the network Jacobian. The first can be observed in linearlogistic regression where SAM provably up-weights the gradient contributionfrom clean examples. Although this explicit up-weighting is also observable inneural networks when we intervene and modify SAM to remove this effectsurprisingly we see no visible degradation in performance. We infer that SAMseffect in deeper networks is instead explained entirely by the effect SAM hason the network Jacobian. We theoretically derive the implicit regularizationinduced by this Jacobian effect in two layer linear networks. Motivated by ouranalysis we see that cheaper alternatives to SAM that explicitly induce theseregularization effects largely recover the benefits in deep networks trained onreal-world datasets. |


| Item |Content|
| --- |---|
|idx| 2405.03672v1 |
|title| Cutting through buggy adversarial example defenses: fixing 1 line of code breaks Sabre |
|authors| Nicholas Carlini
|links| http://arxiv.org/abs/2405.03672v1 |
|updated| 2024-05-06 17:48:24 UTC |
|summary| Sabre is a defense to adversarial examples that was accepted at IEEE SP2024. We first reveal significant flaws in the evaluation that point to clearsigns of gradient masking. We then show the cause of this gradient masking: abug in the original evaluation code. By fixing a single line of code in theoriginal repository we reduce Sabres robust accuracy to 0. In response tothis the authors modify the defense and introduce a new defense component notdescribed in the original paper. But this fix contains a second bug modifyingone more line of code reduces robust accuracy to below baseline levels. |


| Item |Content|
| --- |---|
|idx| 2405.03667v1 |
|title| Fault Detection and Monitoring using an Information-Driven Strategy: Method, Theory, and Application |
|authors| Camilo RamírezJorge F. SilvaFerhat TamssaouetTomás RojasMarcos E. Orchard
|links| http://arxiv.org/abs/2405.03667v1 |
|updated| 2024-05-06 17:43:39 UTC |
|summary| The ability to detect when a system undergoes an incipient fault is ofparamount importance in preventing a critical failure. In this work we proposean information-driven fault detection method based on a novel concept driftdetector. The method is tailored to identifying drifts in input-outputrelationships of additive noise models i.e. model drifts and is based on adistribution-free mutual information MI estimator. Our scheme does notrequire prior faulty examples and can be applied distribution-free over a largeclass of system models. Our core contributions are twofold. First wedemonstrate the connection between fault detection model drift detection andtesting independence between two random variables. Second we prove severaltheoretical properties of the proposed MI-based fault detection scheme: istrong consistency ii exponentially fast detection of the non-faulty caseand iii control of both significance levels and power of the test. Toconclude we validate our theory with synthetic data and the benchmark datasetN-CMAPSS of aircraft turbofan engines. These empirical results support theusefulness of our methodology in many practical and realistic settings and thetheoretical results show performance guarantees that other methods cannotoffer. |


# cs.CV 

| Item |Content|
| --- |---|
|idx| 2405.03690v1 |
|title| Complex Video Reasoning and Robustness Evaluation Suite for Video-LMMs |
|authors| Muhammad Uzair KhattakMuhammad Ferjad NaeemJameel HassanMuzammal NaseerFederico TombariFahad Shahbaz KhanSalman Khan
|links| http://arxiv.org/abs/2405.03690v1 |
|updated| 2024-05-06 17:59:45 UTC |
|summary| Recent advancements in Large Language Models LLMs have led to thedevelopment of Video Large Multi-modal Models Video-LMMs that can handle awide range of video understanding tasks. These models have the potential to bedeployed in real-world applications such as robotics AI assistants medicalimaging and autonomous vehicles. The widespread adoption of Video-LMMs in ourdaily lives underscores the importance of ensuring and evaluating their robustperformance in mirroring human-like reasoning and interaction capabilities incomplex real-world contexts. However existing benchmarks for Video-LMMsprimarily focus on general video comprehension abilities and neglect assessingtheir reasoning capabilities over complex videos in the real-world context androbustness of these models through the lens of user prompts as text queries. Inthis paper we present the Complex Video Reasoning and Robustness EvaluationSuite CVRR-ES a novel benchmark that comprehensively assesses theperformance of Video-LMMs across 11 diverse real-world video dimensions. Weevaluate 9 recent models including both open-source and closed-sourcevariants and find that most of the Video-LMMs especially open-source onesstruggle with robustness and reasoning when dealing with complex videos. Basedon our analysis we develop a training-free Dual-Step Contextual PromptingDSCP technique to enhance the performance of existing Video-LMMs. Ourfindings provide valuable insights for building the next generation ofhuman-centric AI systems with advanced robustness and reasoning capabilities.Our dataset and code are publicly available at:https://mbzuai-oryx.github.io/CVRR-Evaluation-Suite/. |


| Item |Content|
| --- |---|
|idx| 2405.03689v1 |
|title| Pose Priors from Language Models |
|authors| Sanjay SubramanianEvonne NgLea MüllerDan KleinShiry GinosarTrevor Darrell
|links| http://arxiv.org/abs/2405.03689v1 |
|updated| 2024-05-06 17:59:36 UTC |
|summary| We present a zero-shot pose optimization method that enforces accuratephysical contact constraints when estimating the 3D pose of humans. Our centralinsight is that since language is often used to describe physical interactionlarge pretrained text-based models can act as priors on pose estimation.  We can thus leverage this insight to improve pose estimation by convertingnatural language descriptors generated by a large multimodal model LMM intotractable losses to constrain the 3D pose optimization. Despite its simplicityour method produces surprisingly compelling pose reconstructions of people inclose contact correctly capturing the semantics of the social and physicalinteractions. We demonstrate that our method rivals more complexstate-of-the-art approaches that require expensive human annotation of contactpoints and training specialized models. Moreover unlike previous approachesour method provides a unified framework for resolving self-contact andperson-to-person contact. |


| Item |Content|
| --- |---|
|idx| 2405.03685v1 |
|title| Language-Image Models with 3D Understanding |
|authors| Jang Hyun ChoBoris IvanovicYulong CaoEdward SchmerlingYue WangXinshuo WengBoyi LiYurong YouPhilipp KrähenbühlYan WangMarco Pavone
|links| http://arxiv.org/abs/2405.03685v1 |
|updated| 2024-05-06 17:57:27 UTC |
|summary| Multi-modal large language models MLLMs have shown incredible capabilitiesin a variety of 2D vision and language tasks. We extend MLLMs perceptualcapabilities to ground and reason about images in 3-dimensional space. To thatend we first develop a large-scale pre-training dataset for 2D and 3D calledLV3D by combining multiple existing 2D and 3D recognition datasets under acommon task formulation: as multi-turn question-answering. Next we introduce anew MLLM named Cube-LLM and pre-train it on LV3D. We show that pure datascaling makes a strong 3D perception capability without 3D specificarchitectural design or training objective. Cube-LLM exhibits intriguingproperties similar to LLMs: 1 Cube-LLM can apply chain-of-thought promptingto improve 3D understanding from 2D context information. 2 Cube-LLM canfollow complex and diverse instructions and adapt to versatile input and outputformats. 3 Cube-LLM can be visually prompted such as 2D box or a set ofcandidate 3D boxes from specialists. Our experiments on outdoor benchmarksdemonstrate that Cube-LLM significantly outperforms existing baselines by 21.3points of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7points on the DriveLM dataset for complex reasoning about driving scenariosrespectively. Cube-LLM also shows competitive results in general MLLMbenchmarks such as refCOCO for 2D grounding with 87.0 average score as wellas visual question answering benchmarks such as VQAv2 GQA SQA POPE etc. forcomplex reasoning. Our project is available athttps://janghyuncho.github.io/Cube-LLM. |


| Item |Content|
| --- |---|
|idx| 2405.03682v1 |
|title| An Empty Room is All We Want: Automatic Defurnishing of Indoor Panoramas |
|authors| Mira SlavchevaDave GausebeckKevin ChenDavid BuchhoferAzwad SabikChen MaSachal DhillonOlaf BrandtAlan Dolhasz
|links| http://arxiv.org/abs/2405.03682v1 |
|updated| 2024-05-06 17:57:03 UTC |
|summary| We propose a pipeline that leverages Stable Diffusion to improve inpaintingresults in the context of defurnishing -- the removal of furniture items fromindoor panorama images. Specifically we illustrate how increased contextdomain-specific model fine-tuning and improved image blending can producehigh-fidelity inpaints that are geometrically plausible without needing to relyon room layout estimation. We demonstrate qualitative and quantitativeimprovements over other furniture removal techniques. |


| Item |Content|
| --- |---|
|idx| 2405.03673v1 |
|title| MemoryMamba: Memory-Augmented State Space Model for Defect Recognition |
|authors| Qianning WangHe HuYucheng Zhou
|links| http://arxiv.org/abs/2405.03673v1 |
|updated| 2024-05-06 17:49:31 UTC |
|summary| As automation advances in manufacturing the demand for precise andsophisticated defect detection technologies grows. Existing vision models fordefect recognition methods are insufficient for handling the complexities andvariations of defects in contemporary manufacturing settings. These modelsespecially struggle in scenarios involving limited or imbalanced defect data.In this work we introduce MemoryMamba a novel memory-augmented state spacemodel SSM designed to overcome the limitations of existing defectrecognition models. MemoryMamba integrates the state space model with thememory augmentation mechanism enabling the system to maintain and retrieveessential defect-specific information in training. Its architecture is designedto capture dependencies and intricate defect characteristics which are crucialfor effective defect detection. In the experiments MemoryMamba was evaluatedacross four industrial datasets with diverse defect types and complexities. Themodel consistently outperformed other methods demonstrating its capability toadapt to various defect recognition scenarios. |


# stat.ML 

| Item |Content|
| --- |---|
|idx| 2405.03664v1 |
|title| A New Robust Partial $p$-Wasserstein-Based Metric for Comparing Distributions |
|authors| Sharath RaghvendraPouyan ShirzadianKaiyi Zhang
|links| http://arxiv.org/abs/2405.03664v1 |
|updated| 2024-05-06 17:41:13 UTC |
|summary| The 2-Wasserstein distance is sensitive to minor geometric differencesbetween distributions making it a very powerful dissimilarity metric. Howeverdue to this sensitivity a small outlier mass can also cause a significantincrease in the 2-Wasserstein distance between two similar distributions.Similarly sampling discrepancy can cause the empirical 2-Wassersteindistance on n samples in mathbbR2 to converge to the true distance at arate of n-1/4 which is significantly slower than the rate of n-1/2for 1-Wasserstein distance.  We introduce a new family of distances parameterized by k ge 0 calledk-RPW that is based on computing the partial 2-Wasserstein distance. Weshow that 1 k-RPW satisfies the metric properties 2 k-RPW is robust tosmall outlier mass while retaining the sensitivity of 2-Wasserstein distanceto minor geometric differences and 3 when k is a constant k-RPWdistance between empirical distributions on n samples in mathbbR2converges to the true distance at a rate of n-1/3 which is faster thanthe convergence rate of n-1/4 for the 2-Wasserstein distance.  Using the partial p-Wasserstein distance we extend our distance to any pin 1infty. By setting parameters k or p appropriately we can reduceour distance to the total variation p-Wasserstein and the Levy-Prokhorovdistances. Experiments show that our distance function achieves higher accuracyin comparison to the 1-Wasserstein 2-Wasserstein and TV distances forimage retrieval tasks on noisy real-world data sets. |


| Item |Content|
| --- |---|
|idx| 2405.03624v1 |
|title| $ε$-Policy Gradient for Online Pricing |
|authors| Lukasz SzpruchTanut TreetanthiploetYufei Zhang
|links| http://arxiv.org/abs/2405.03624v1 |
|updated| 2024-05-06 16:41:52 UTC |
|summary| Combining model-based and model-free reinforcement learning approaches thispaper proposes and analyzes an epsilon-policy gradient algorithm for theonline pricing learning task. The algorithm extends epsilon-greedy algorithmby replacing greedy exploitation with gradient descent step and facilitateslearning via model inference. We optimize the regret of the proposed algorithmby quantifying the exploration cost in terms of the exploration probabilityepsilon and the exploitation cost in terms of the gradient descentoptimization and gradient estimation errors. The algorithm achieves an expectedregret of order mathcalOsqrtT up to a logarithmic factor over Ttrials. |


| Item |Content|
| --- |---|
|idx| 2405.03549v1 |
|title| Bridging discrete and continuous state spaces: Exploring the Ehrenfest process in time-continuous diffusion models |
|authors| Ludwig WinklerLorenz RichterManfred Opper
|links| http://arxiv.org/abs/2405.03549v1 |
|updated| 2024-05-06 15:12:51 UTC |
|summary| Generative modeling via stochastic processes has led to remarkable empiricalresults as well as to recent advances in their theoretical understanding. Inprinciple both space and time of the processes can be discrete or continuous.In this work we study time-continuous Markov jump processes on discrete statespaces and investigate their correspondence to state-continuous diffusionprocesses given by SDEs. In particular we revisit the textitEhrenfestprocess which converges to an Ornstein-Uhlenbeck process in the infinitestate space limit. Likewise we can show that the time-reversal of theEhrenfest process converges to the time-reversed Ornstein-Uhlenbeck process.This observation bridges discrete and continuous state spaces and allows tocarry over methods from one to the respective other setting. Additionally wesuggest an algorithm for training the time-reversal of Markov jump processeswhich relies on conditional expectations and can thus be directly related todenoising score matching. We demonstrate our methods in multiple convincingnumerical experiments. |


| Item |Content|
| --- |---|
|idx| 2405.03468v1 |
|title| Hierarchic Flows to Estimate and Sample High-dimensional Probabilities |
|authors| Etienne LempereurStéphane Mallat
|links| http://arxiv.org/abs/2405.03468v1 |
|updated| 2024-05-06 13:44:51 UTC |
|summary| Finding low-dimensional interpretable models of complex physical fields suchas turbulence remains an open question 80 years after the pioneer work ofKolmogorov. Estimating high-dimensional probability distributions from datasamples suffers from an optimization and an approximation curse ofdimensionality. It may be avoided by following a hierarchic probability flowfrom coarse to fine scales. This inverse renormalization group is defined byconditional probabilities across scales renormalized in a wavelet basis. For avarphi4 scalar potential sampling these hierarchic models avoids thecritical slowing down at the phase transition. An outstanding issue is to alsoapproximate non-Gaussian fields having long-range interactions in space andacross scales. We introduce low-dimensional models with robust multiscaleapproximations of high order polynomial energies. They are calculated with asecond wavelet transform which defines interactions over two hierarchies ofscales. We estimate and sample these wavelet scattering models to generate 2Dvorticity fields of turbulence and images of dark matter densities. |


| Item |Content|
| --- |---|
|idx| 2405.03449v1 |
|title| Byzantine-Robust Gossip: Insights from a Dual Approach |
|authors| Renaud GaucherHadrien HendrikxAymeric Dieuleveut
|links| http://arxiv.org/abs/2405.03449v1 |
|updated| 2024-05-06 13:22:54 UTC |
|summary| Distributed approaches have many computational benefits but they arevulnerable to attacks from a subset of devices transmitting incorrectinformation. This paper investigates Byzantine-resilient algorithms in adecentralized setting where devices communicate directly with one another. Weleverage the so-called dual approach to design a general robust decentralizedoptimization method. We provide both global and local clipping rules in thespecial case of average consensus with tight convergence guarantees. Theseclipping rules are practical and yield results that finely characterize theimpact of Byzantine nodes highlighting for instance a qualitative differencein convergence between global and local clipping thresholds. Lastly wedemonstrate that they can serve as a basis for designing efficient attacks. |


# cs.HC 

| Item |Content|
| --- |---|
|idx| 2405.03674v1 |
|title| Anti-Heroes: An Ethics-focused Method for Responsible Designer Intentions |
|authors| Shikha MehtaShruthi Sai ChivukulaColin M. GrayRitika Gairola
|links| http://arxiv.org/abs/2405.03674v1 |
|updated| 2024-05-06 17:49:32 UTC |
|summary| HCI and design researchers have designed adopted and customized a range ofethics-focused methods to inscribe values and support ethical decision makingin a design process. In this work-in-progress we add to this body ofresources constructing a method that surfaces the designers intentions in anaction-focused way encouraging consideration of both manipulative andvalue-centered roles. Anti-Heroes is a card deck that allows a designer toplayfully take on pairs of manipulative Anti-Hero and value-centered Heroroles during design ideation/conceptualization evaluation and ethicaldialogue. The card deck includes twelve cards with Anti-Hero and Hero facesalong with three action cards that include reflective questions for differentplay modes. Alongside the creation of the Anti-Hero card deck we describe theevaluation and iteration of the card deck through playtesting sessions withfour groups of three design students. We propose implications of Anti-Heros fortechnology and design education and practice. |


| Item |Content|
| --- |---|
|idx| 2405.03585v1 |
|title| The Sociotechnical Stack: Opportunities for Social Computing Research in Non-consensual Intimate Media |
|authors| Li QiweiAllison McDonaldOliver L. HaimsonSarita SchoenebeckEric Gilbert
|links| http://arxiv.org/abs/2405.03585v1 |
|updated| 2024-05-06 15:58:03 UTC |
|summary| Non-consensual intimate media NCIM involves sharing intimate contentwithout the depicted persons consent including revenge porn and sexuallyexplicit deepfakes. While NCIM has received attention in legal psychologicaland communication fields over the past decade it is not sufficiently addressedin computing scholarship. This paper addresses this gap by linking NCIM harmsto the specific technological components that facilitate them. We introduce thesociotechnical stack a conceptual framework designed to map the technicalstack to its corresponding social impacts. The sociotechnical stack allows usto analyze sociotechnical problems like NCIM and points toward opportunitiesfor computing research. We propose a research roadmap for computing and socialcomputing communities to deter NCIM perpetration and support victim-survivorsthrough building and rebuilding technologies. |


| Item |Content|
| --- |---|
|idx| 2405.03506v1 |
|title| Spin-Wave Voices: Sonification of Nanoscale Spin Waves as an Engagement and Research Tool |
|authors| Santa PileOleg LesotaSilvan David PeterChristina HumerMartin Gasser
|links| http://arxiv.org/abs/2405.03506v1 |
|updated| 2024-05-06 14:20:42 UTC |
|summary| Magnonics is an emerging research field that addresses the use of spin wavesmagnons purely magnetic waves for information transport and processing.Spin waves are a potential replacement for electric current in moderncomputational devices that would make them more compact and energy efficient.The field is yet little known even among physicists. Additionally with thedevelopment of new measuring techniques and computational physics the obtainedmagnetic data becomes more complex in some cases including 3D vector fieldsand time-resolution. This work presents an approach to the audio-visualrepresentation of the spin waves and discusses its use as a tool for sciencecommunication exhibits and possible data analysis tool. The work also detailsan instance of such an exhibit presented at the annual international digitalart exhibition Ars Electronica Festival in 2022. |


| Item |Content|
| --- |---|
|idx| 2405.03442v1 |
|title| Behavioral analysis in immersive learning environments: A systematic literature review and research agenda |
|authors| Yu LiuKang YueYue Liu
|links| http://arxiv.org/abs/2405.03442v1 |
|updated| 2024-05-06 13:14:28 UTC |
|summary| The rapid growth of immersive technologies in educational areas has increasedresearch interest in analyzing the specific behavioral patterns of learners inimmersive learning environments. Considering the fact that research on thetechnical affordances of immersive technologies and the pedagogical affordancesof behavioral analysis remains fragmented this study first contributes bydeveloping a conceptual framework that amalgamates learning requirementsspecification evaluation and iteration into an integrated model to identifylearning benefits and potential hurdles of behavioral analysis in immersivelearning environments. Then a systematic review was conducted underpinning theproposed conceptual framework to retrieve valuable empirical evidence from the40 eligible articles during the last decade. The review findings suggest that1 there is an essential need to sufficiently prepare the salient pedagogicalrequirements to define the specific learning stage envisage intended cognitiveobjectives and specify an appropriate set of learning activities whendeveloping comprehensive plans on behavioral analysis in immersive learningenvironments. 2 Researchers could customize the unique immersive experimentalimplementation by considering factors from four dimensions: learner pedagogycontext and representation. 3 The behavioral patterns constructed inimmersive learning environments vary by considering the influence of behavioralanalysis techniques research themes and immersive technical features. 4 Theuse of behavioral analysis in immersive learning environments faces severalchallenges from technical implementation and data processing perspectives.This study also articulates critical research agenda that could drive futureinvestigation on behavioral analysis in immersive learning environments. |


| Item |Content|
| --- |---|
|idx| 2405.03363v1 |
|title| Telextiles: End-to-end Remote Transmission of Fabric Tactile Sensation |
|authors| Takekazu KitagishiYuichi HiroiYuna WatanabeYuta ItohJun Rekimoto
|links| http://dx.doi.org/10.1145/3586183.3606764 |
|updated| 2024-05-06 11:13:50 UTC |
|summary| The tactile sensation of textiles is critical in determining the comfort ofclothing. For remote use such as online shopping users cannot physicallytouch the textile of clothes making it difficult to evaluate its tactilesensation. Tactile sensing and actuation devices are required to transmit thetactile sensation of textiles. The sensing device needs to recognize differentgarments even with hand-held sensors. In addition the existing actuationdevice can only present a limited number of known patterns and cannot transmitunknown tactile sensations of textiles. To address these issues we proposeTelextiles an interface that can remotely transmit tactile sensations oftextiles by creating a latent space that reflects the proximity of textilesthrough contrastive self-supervised learning. We confirm that textiles withsimilar tactile features are located close to each other in the latent spacethrough a two-dimensional plot. We then compress the latent features for knowntextile samples into the 1D distance and apply the 16 textile samples to therollers in the order of the distance. The roller is rotated to select thetextile with the closest feature if an unknown textile is detected. |


# cs.MA 

| Item |Content|
| --- |---|
|idx| 2405.03250v1 |
|title| A survey to measure cognitive biases influencing mobility choices |
|authors| Carole Adam
|links| http://arxiv.org/abs/2405.03250v1 |
|updated| 2024-05-06 08:12:13 UTC |
|summary| In this paper we describe a survey about the perceptions of 4 mobility modescar bus bicycle walking and the preferences of users for 6 modal choicefactors. This survey has gathered 650 answers in 2023 that are published asopen data. In this study we analyse these results to highlight the influenceof 3 cognitive biases on mobility decisions: halo bias choice-supportive biasand reactance. These cognitive biases are proposed as plausible explanations ofthe observed behaviour where the population tends to stick to individual carsdespite urban policies aiming at favouring soft mobility. This model can serveas the basis for a simulator of mobility decisions in a virtual town and thegathered data can be used to initialise this population with realisticattributes. Work is ongoing to design a simulation-based serious game where theplayer takes the role of an urban manager faced with planning choices to maketheir city more sustainable. |


| Item |Content|
| --- |---|
|idx| 2405.03132v1 |
|title| A Multi-Agent Rollout Approach for Highway Bottleneck Decongenston in Mixed Autonomy |
|authors| Lu LiuMaonan WangMan-On PunXi Xiong
|links| http://arxiv.org/abs/2405.03132v1 |
|updated| 2024-05-06 03:06:04 UTC |
|summary| The integration of autonomous vehicles AVs into the existing transportationinfrastructure offers a promising solution to alleviate congestion and enhancemobility. This research explores a novel approach to traffic optimization byemploying a multi-agent rollout approach within a mixed autonomy environment.The study concentrates on coordinating the speed of human-driven vehicles bylongitudinally controlling AVs aiming to dynamically optimize traffic flow andalleviate congestion at highway bottlenecks in real-time. We model the problemas a decentralized partially observable Markov decision process Dec-POMDP andpropose an improved multi-agent rollout algorithm. By employing agent-by-agentpolicy iterations our approach implicitly considers cooperation among multipleagents and seamlessly adapts to complex scenarios where the number of agentsdynamically varies. Validated in a real-world network with varying AVpenetration rates and traffic flow the simulations demonstrate that themulti-agent rollout algorithm significantly enhances performance reducingaverage travel time on bottleneck segments by 9.42 with a 10 AV penetrationrate. |


| Item |Content|
| --- |---|
|idx| 2405.03076v1 |
|title| Traffic Performance GPT (TP-GPT): Real-Time Data Informed Intelligent ChatBot for Transportation Surveillance and Management |
|authors| Bingzhang WangZhiyuCaiMuhammad Monjurul KarimChenxi LiuYinhai Wang
|links| http://arxiv.org/abs/2405.03076v1 |
|updated| 2024-05-05 22:54:51 UTC |
|summary| The digitization of traffic sensing infrastructure has significantlyaccumulated an extensive traffic data warehouse which presents unprecedentedchallenges for transportation analytics. The complexities associated withquerying large-scale multi-table databases require specialized programmingexpertise and labor-intensive development. Additionally traditional analysismethods have focused mainly on numerical data often neglecting the semanticaspects that could enhance interpretability and understanding. Furthermorereal-time traffic data access is typically limited due to privacy concerns. Tobridge this gap the integration of Large Language Models LLMs into thedomain of traffic management presents a transformative approach to addressingthe complexities and challenges inherent in modern transportation systems. Thispaper proposes an intelligent online chatbot TP-GPT for efficient customizedtransportation surveillance and management empowered by a large real-timetraffic database. The innovative framework leverages contextual and generativeintelligence of language models to generate accurate SQL queries and naturallanguage interpretations by employing transportation-specialized promptsChain-of-Thought prompting few-shot learning multi-agent collaborationstrategy and chat memory. Experimental study demonstrates that our approachoutperforms state-of-the-art baselines such as GPT-4 and PaLM 2 on achallenging traffic-analysis benchmark TransQuery. TP-GPT would aid researchersand practitioners in real-time transportation surveillance and management in aprivacy-preserving equitable and customizable manner. |


| Item |Content|
| --- |---|
|idx| 2405.02980v1 |
|title| Self-Organized Construction by Minimal Surprise |
|authors| Tanja Katharina KaiserHeiko Hamann
|links| http://dx.doi.org/10.1109/FAS-W.2019.00057 |
|updated| 2024-05-05 15:59:22 UTC |
|summary| For the robots to achieve a desired behavior we can program them directlytrain them or give them an innate driver that makes the robots themselvesdesire the targeted behavior. With the minimal surprise approach we implant inour robots the desire to make their world predictable. Here we apply minimalsurprise to collective construction. Simulated robots push blocks in a 2D torusgrid world. In two variants of our experiment we either allow for emergentbehaviors or predefine the expected environment of the robots. In either waywe evolve robot behaviors that move blocks to structure their environment andmake it more predictable. The resulting controllers can be applied incollective construction by robots. |


| Item |Content|
| --- |---|
|idx| 2405.02849v1 |
|title| Modelling Opaque Bilateral Market Dynamics in Financial Trading: Insights from a Multi-Agent Simulation Study |
|authors| Alicia VidlerToby Walsh
|links| http://arxiv.org/abs/2405.02849v1 |
|updated| 2024-05-05 08:42:20 UTC |
|summary| Exploring complex adaptive financial trading environments through multi-agentbased simulation methods presents an innovative approach within the realm ofquantitative finance. Despite the dominance of multi-agent reinforcementlearning approaches in financial markets with observable data there exists aset of systematically significant financial markets that pose challenges due totheir partial or obscured data availability. We therefore devise amulti-agent simulation approach employing small-scale meta-heuristic methods.This approach aims to represent the opaque bilateral market for Australiangovernment bond trading capturing the bilateral nature of bank-to-banktrading also referred to as over-the-counter OTC trading and commonlyoccurring between market makers. The uniqueness of the bilateral marketcharacterized by negotiated transactions and a limited number of agents yieldsvaluable insights for agent-based modelling and quantitative finance. Theinherent rigidity of this market structure which is at odds with the globalproliferation of multilateral platforms and the decentralization of financeunderscores the unique insights offered by our agent-based model. We explorethe implications of market rigidity on market structure and consider theelement of stability in market design. This extends the ongoing discourse oncomplex financial trading environments providing an enhanced understanding oftheir dynamics and implications. |


