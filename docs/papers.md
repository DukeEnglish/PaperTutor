# cs.CL 

| Item |Content|
| --- |---|
|idx| 2410.18976v1 |
|title| CAMEL-Bench: A Comprehensive Arabic LMM Benchmark |
|authors| Sara GhabouraAhmed HeaklOmkar ThawakarAli AlharthiInes RiahiAbduljalil SaifJorma LaaksonenFahad S. KhanSalman KhanRao M. Anwer
|links| http://arxiv.org/abs/2410.18976v1 |
|updated| 2024-10-24 17:59:38 UTC |
|summary| Recent years have witnessed a significant interest in developing largemultimodal models LMMs capable of performing various visual reasoning andunderstanding tasks. This has led to the introduction of multiple LMMbenchmarks to evaluate LMMs on different tasks. However most existing LMMevaluation benchmarks are predominantly English-centric. In this work wedevelop a comprehensive LMM evaluation benchmark for the Arabic language torepresent a large population of over 400 million speakers. The proposedbenchmark named CAMEL-Bench comprises eight diverse domains and 38sub-domains including multi-image understanding complex visual perceptionhandwritten document understanding video understanding medical imaging plantdiseases and remote sensing-based land use understanding to evaluate broadscenario generalizability. Our CAMEL-Bench comprises around 29036 questionsthat are filtered from a larger pool of samples where the quality is manuallyverified by native speakers to ensure reliable model assessment. We conductevaluations of both closed-source including GPT-4 series and open-sourceLMMs. Our analysis reveals the need for substantial improvement especiallyamong the best open-source models with even the closed-source GPT-4o achievingan overall score of 62. Our benchmark and evaluation scripts are open-sourced. |


| Item |Content|
| --- |---|
|idx| 2410.18975v1 |
|title| Unbounded: A Generative Infinite Game of Character Life Simulation |
|authors| Jialu LiYuanzhen LiNeal WadhwaYael PritchDavid E. JacobsMichael RubinsteinMohit BansalNataniel Ruiz
|links| http://arxiv.org/abs/2410.18975v1 |
|updated| 2024-10-24 17:59:31 UTC |
|summary| We introduce the concept of a generative infinite game a video game thattranscends the traditional boundaries of finite hard-coded systems by usinggenerative models. Inspired by James P. Carses distinction between finite andinfinite games we leverage recent advances in generative AI to createUnbounded: a game of character life simulation that is fully encapsulated ingenerative models. Specifically Unbounded draws inspiration from sandbox lifesimulations and allows you to interact with your autonomous virtual characterin a virtual world by feeding playing with and guiding it - with open-endedmechanics generated by an LLM some of which can be emergent. In order todevelop Unbounded we propose technical innovations in both the LLM and visualgeneration domains. Specifically we present: 1 a specialized distilledlarge language model LLM that dynamically generates game mechanicsnarratives and character interactions in real-time and 2 a new dynamicregional image prompt Adapter IP-Adapter for vision models that ensuresconsistent yet flexible visual generation of a character across multipleenvironments. We evaluate our system through both qualitative and quantitativeanalysis showing significant improvements in character life simulation userinstruction following narrative coherence and visual consistency for bothcharacters and the environments compared to traditional related approaches. |


| Item |Content|
| --- |---|
|idx| 2410.18967v1 |
|title| Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms |
|authors| Zhangheng LiKeen YouHaotian ZhangDi FengHarsh AgrawalXiujun LiMohana Prasad Sathya MoorthyJeff NicholsYinfei YangZhe Gan
|links| http://arxiv.org/abs/2410.18967v1 |
|updated| 2024-10-24 17:58:31 UTC |
|summary| Building a generalist model for user interface UI understanding ischallenging due to various foundational issues such as platform diversityresolution variation and data limitation. In this paper we introduceFerret-UI 2 a multimodal large language model MLLM designed for universal UIunderstanding across a wide range of platforms including iPhone AndroidiPad Webpage and AppleTV. Building on the foundation of Ferret-UI Ferret-UI2 introduces three key innovations: support for multiple platform typeshigh-resolution perception through adaptive scaling and advanced task trainingdata generation powered by GPT-4o with set-of-mark visual prompting. Theseadvancements enable Ferret-UI 2 to perform complex user-centered interactionsmaking it highly versatile and adaptable for the expanding diversity ofplatform ecosystems. Extensive empirical experiments on referring groundinguser-centric advanced tasks comprising 9 subtasks times 5 platforms GUIDEnext-action prediction dataset and GUI-World multi-platform benchmarkdemonstrate that Ferret-UI 2 significantly outperforms Ferret-UI and alsoshows strong cross-platform transfer capabilities. |


| Item |Content|
| --- |---|
|idx| 2410.18966v1 |
|title| Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions |
|authors| Yujuan FuOzlem UzunerMeliha YetisgenFei Xia
|links| http://arxiv.org/abs/2410.18966v1 |
|updated| 2024-10-24 17:58:22 UTC |
|summary| Large language models LLMs have demonstrated great performance acrossvarious benchmarks showing potential as general-purpose task solvers. Howeveras LLMs are typically trained on vast amounts of data a significant concern intheir evaluation is data contamination where overlap between training data andevaluation datasets inflates performance assessments. While multiple approacheshave been developed to identify data contamination these approaches rely onspecific assumptions that may not hold universally across different settings.To bridge this gap we systematically review 47 papers on data contaminationdetection categorize the underlying assumptions and assess whether they havebeen rigorously validated. We identify and analyze eight categories ofassumptions and test three of them as case studies. Our analysis reveals thatwhen classifying instances used for pretraining LLMs detection approachesbased on these three assumptions perform close to random guessing suggestingthat current LLMs learn data distributions rather than memorizing individualinstances. Overall this work underscores the importance of approaches clearlystating their underlying assumptions and testing their validity across variousscenarios. |


| Item |Content|
| --- |---|
|idx| 2410.18963v1 |
|title| OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning |
|authors| Xiaoqiang WangBang Liu
|links| http://arxiv.org/abs/2410.18963v1 |
|updated| 2024-10-24 17:58:08 UTC |
|summary| Large language models LLMs and large multimodal models LMMs have showngreat potential in automating complex tasks like web browsing and gaming.However their ability to generalize across diverse applications remainslimited hindering broader utility. To address this challenge we presentOSCAR: Operating System Control via state-Aware reasoning and Re-planning.OSCAR is a generalist agent designed to autonomously navigate and interact withvarious desktop and mobile applications through standardized controls such asmouse and keyboard inputs while processing screen images to fulfill usercommands. OSCAR translates human instructions into executable Python codeenabling precise control over graphical user interfaces GUIs. To enhancestability and adaptability OSCAR operates as a state machine equipped witherror-handling mechanisms and dynamic task re-planning allowing it toefficiently adjust to real-time feedback and exceptions. We demonstrate OSCARseffectiveness through extensive experiments on diverse benchmarks acrossdesktop and mobile platforms where it transforms complex workflows into simplenatural language commands significantly boosting user productivity. Our codewill be open-source upon publication. |


# cs.AI 

| Item |Content|
| --- |---|
|idx| 2410.18979v1 |
|title| PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary Views |
|authors| Xin FeiWenzhao ZhengYueqi DuanWei ZhanMasayoshi TomizukaKurt KeutzerJiwen Lu
|links| http://arxiv.org/abs/2410.18979v1 |
|updated| 2024-10-24 17:59:58 UTC |
|summary| We propose PixelGaussian an efficient feed-forward framework for learninggeneralizable 3D Gaussian reconstruction from arbitrary views. Most existingmethods rely on uniform pixel-wise Gaussian representations which learn afixed number of 3D Gaussians for each view and cannot generalize well to moreinput views. Differently our PixelGaussian dynamically adapts both theGaussian distribution and quantity based on geometric complexity leading tomore efficient representations and significant improvements in reconstructionquality. Specifically we introduce a Cascade Gaussian Adapter to adjustGaussian distribution according to local geometry complexity identified by akeypoint scorer. CGA leverages deformable attention in context-awarehypernetworks to guide Gaussian pruning and splitting ensuring accuraterepresentation in complex regions while reducing redundancy. Furthermore wedesign a transformer-based Iterative Gaussian Refiner module that refinesGaussian representations through direct image-Gaussian interactions. OurPixelGaussian can effectively reduce Gaussian redundancy as input viewsincrease. We conduct extensive experiments on the large-scale ACID andRealEstate10K datasets where our method achieves state-of-the-art performancewith good generalization to various numbers of views. Code:https://github.com/Barrybarry-Smith/PixelGaussian. |


| Item |Content|
| --- |---|
|idx| 2410.18976v1 |
|title| CAMEL-Bench: A Comprehensive Arabic LMM Benchmark |
|authors| Sara GhabouraAhmed HeaklOmkar ThawakarAli AlharthiInes RiahiAbduljalil SaifJorma LaaksonenFahad S. KhanSalman KhanRao M. Anwer
|links| http://arxiv.org/abs/2410.18976v1 |
|updated| 2024-10-24 17:59:38 UTC |
|summary| Recent years have witnessed a significant interest in developing largemultimodal models LMMs capable of performing various visual reasoning andunderstanding tasks. This has led to the introduction of multiple LMMbenchmarks to evaluate LMMs on different tasks. However most existing LMMevaluation benchmarks are predominantly English-centric. In this work wedevelop a comprehensive LMM evaluation benchmark for the Arabic language torepresent a large population of over 400 million speakers. The proposedbenchmark named CAMEL-Bench comprises eight diverse domains and 38sub-domains including multi-image understanding complex visual perceptionhandwritten document understanding video understanding medical imaging plantdiseases and remote sensing-based land use understanding to evaluate broadscenario generalizability. Our CAMEL-Bench comprises around 29036 questionsthat are filtered from a larger pool of samples where the quality is manuallyverified by native speakers to ensure reliable model assessment. We conductevaluations of both closed-source including GPT-4 series and open-sourceLMMs. Our analysis reveals the need for substantial improvement especiallyamong the best open-source models with even the closed-source GPT-4o achievingan overall score of 62. Our benchmark and evaluation scripts are open-sourced. |


| Item |Content|
| --- |---|
|idx| 2410.18975v1 |
|title| Unbounded: A Generative Infinite Game of Character Life Simulation |
|authors| Jialu LiYuanzhen LiNeal WadhwaYael PritchDavid E. JacobsMichael RubinsteinMohit BansalNataniel Ruiz
|links| http://arxiv.org/abs/2410.18975v1 |
|updated| 2024-10-24 17:59:31 UTC |
|summary| We introduce the concept of a generative infinite game a video game thattranscends the traditional boundaries of finite hard-coded systems by usinggenerative models. Inspired by James P. Carses distinction between finite andinfinite games we leverage recent advances in generative AI to createUnbounded: a game of character life simulation that is fully encapsulated ingenerative models. Specifically Unbounded draws inspiration from sandbox lifesimulations and allows you to interact with your autonomous virtual characterin a virtual world by feeding playing with and guiding it - with open-endedmechanics generated by an LLM some of which can be emergent. In order todevelop Unbounded we propose technical innovations in both the LLM and visualgeneration domains. Specifically we present: 1 a specialized distilledlarge language model LLM that dynamically generates game mechanicsnarratives and character interactions in real-time and 2 a new dynamicregional image prompt Adapter IP-Adapter for vision models that ensuresconsistent yet flexible visual generation of a character across multipleenvironments. We evaluate our system through both qualitative and quantitativeanalysis showing significant improvements in character life simulation userinstruction following narrative coherence and visual consistency for bothcharacters and the environments compared to traditional related approaches. |


| Item |Content|
| --- |---|
|idx| 2410.18974v1 |
|title| 3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation |
|authors| Hansheng ChenBokui ShenYulin LiuRuoxi ShiLinqi ZhouConnor Z. LinJiayuan GuHao SuGordon WetzsteinLeonidas Guibas
|links| http://arxiv.org/abs/2410.18974v1 |
|updated| 2024-10-24 17:59:30 UTC |
|summary| Multi-view image diffusion models have significantly advanced open-domain 3Dobject generation. However most existing models rely on 2D networkarchitectures that lack inherent 3D biases resulting in compromised geometricconsistency. To address this challenge we introduce 3D-Adapter a plug-inmodule designed to infuse 3D geometry awareness into pretrained image diffusionmodels. Central to our approach is the idea of 3D feedback augmentation: foreach denoising step in the sampling loop 3D-Adapter decodes intermediatemulti-view features into a coherent 3D representation then re-encodes therendered RGBD views to augment the pretrained base model through featureaddition. We study two variants of 3D-Adapter: a fast feed-forward versionbased on Gaussian splatting and a versatile training-free version utilizingneural fields and meshes. Our extensive experiments demonstrate that 3D-Adapternot only greatly enhances the geometry quality of text-to-multi-view modelssuch as Instant3D and Zero123 but also enables high-quality 3D generationusing the plain text-to-image Stable Diffusion. Furthermore we showcase thebroad application potential of 3D-Adapter by presenting high quality results intext-to-3D image-to-3D text-to-texture and text-to-avatar tasks. |


| Item |Content|
| --- |---|
|idx| 2410.18972v1 |
|title| Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques |
|authors| David Ortiz-PerezManuel Benavent-LledoJose Garcia-RodriguezDavid TomásM. Flores Vizcaya-Moreno
|links| http://arxiv.org/abs/2410.18972v1 |
|updated| 2024-10-24 17:59:21 UTC |
|summary| Cognitive decline is a natural part of aging often resulting in reducedcognitive abilities. In some cases however this decline is more pronouncedtypically due to disorders such as Alzheimers disease. Early detection ofanomalous cognitive decline is crucial as it can facilitate timelyprofessional intervention. While medical data can help in this detection itoften involves invasive procedures. An alternative approach is to employnon-intrusive techniques such as speech or handwriting analysis which do notnecessarily affect daily activities. This survey reviews the most relevantmethodologies that use deep learning techniques to automate the cognitivedecline estimation task including audio text and visual processing. Wediscuss the key features and advantages of each modality and methodologyincluding state-of-the-art approaches like Transformer architecture andfoundation models. In addition we present works that integrate differentmodalities to develop multimodal models. We also highlight the most significantdatasets and the quantitative results from studies using these resources. Fromthis review several conclusions emerge. In most cases the textual modalityachieves the best results and is the most relevant for detecting cognitivedecline. Moreover combining various approaches from individual modalities intoa multimodal model consistently enhances performance across nearly allscenarios. |


# cs.LG 

| Item |Content|
| --- |---|
|idx| 2410.18979v1 |
|title| PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary Views |
|authors| Xin FeiWenzhao ZhengYueqi DuanWei ZhanMasayoshi TomizukaKurt KeutzerJiwen Lu
|links| http://arxiv.org/abs/2410.18979v1 |
|updated| 2024-10-24 17:59:58 UTC |
|summary| We propose PixelGaussian an efficient feed-forward framework for learninggeneralizable 3D Gaussian reconstruction from arbitrary views. Most existingmethods rely on uniform pixel-wise Gaussian representations which learn afixed number of 3D Gaussians for each view and cannot generalize well to moreinput views. Differently our PixelGaussian dynamically adapts both theGaussian distribution and quantity based on geometric complexity leading tomore efficient representations and significant improvements in reconstructionquality. Specifically we introduce a Cascade Gaussian Adapter to adjustGaussian distribution according to local geometry complexity identified by akeypoint scorer. CGA leverages deformable attention in context-awarehypernetworks to guide Gaussian pruning and splitting ensuring accuraterepresentation in complex regions while reducing redundancy. Furthermore wedesign a transformer-based Iterative Gaussian Refiner module that refinesGaussian representations through direct image-Gaussian interactions. OurPixelGaussian can effectively reduce Gaussian redundancy as input viewsincrease. We conduct extensive experiments on the large-scale ACID andRealEstate10K datasets where our method achieves state-of-the-art performancewith good generalization to various numbers of views. Code:https://github.com/Barrybarry-Smith/PixelGaussian. |


| Item |Content|
| --- |---|
|idx| 2410.18976v1 |
|title| CAMEL-Bench: A Comprehensive Arabic LMM Benchmark |
|authors| Sara GhabouraAhmed HeaklOmkar ThawakarAli AlharthiInes RiahiAbduljalil SaifJorma LaaksonenFahad S. KhanSalman KhanRao M. Anwer
|links| http://arxiv.org/abs/2410.18976v1 |
|updated| 2024-10-24 17:59:38 UTC |
|summary| Recent years have witnessed a significant interest in developing largemultimodal models LMMs capable of performing various visual reasoning andunderstanding tasks. This has led to the introduction of multiple LMMbenchmarks to evaluate LMMs on different tasks. However most existing LMMevaluation benchmarks are predominantly English-centric. In this work wedevelop a comprehensive LMM evaluation benchmark for the Arabic language torepresent a large population of over 400 million speakers. The proposedbenchmark named CAMEL-Bench comprises eight diverse domains and 38sub-domains including multi-image understanding complex visual perceptionhandwritten document understanding video understanding medical imaging plantdiseases and remote sensing-based land use understanding to evaluate broadscenario generalizability. Our CAMEL-Bench comprises around 29036 questionsthat are filtered from a larger pool of samples where the quality is manuallyverified by native speakers to ensure reliable model assessment. We conductevaluations of both closed-source including GPT-4 series and open-sourceLMMs. Our analysis reveals the need for substantial improvement especiallyamong the best open-source models with even the closed-source GPT-4o achievingan overall score of 62. Our benchmark and evaluation scripts are open-sourced. |


| Item |Content|
| --- |---|
|idx| 2410.18975v1 |
|title| Unbounded: A Generative Infinite Game of Character Life Simulation |
|authors| Jialu LiYuanzhen LiNeal WadhwaYael PritchDavid E. JacobsMichael RubinsteinMohit BansalNataniel Ruiz
|links| http://arxiv.org/abs/2410.18975v1 |
|updated| 2024-10-24 17:59:31 UTC |
|summary| We introduce the concept of a generative infinite game a video game thattranscends the traditional boundaries of finite hard-coded systems by usinggenerative models. Inspired by James P. Carses distinction between finite andinfinite games we leverage recent advances in generative AI to createUnbounded: a game of character life simulation that is fully encapsulated ingenerative models. Specifically Unbounded draws inspiration from sandbox lifesimulations and allows you to interact with your autonomous virtual characterin a virtual world by feeding playing with and guiding it - with open-endedmechanics generated by an LLM some of which can be emergent. In order todevelop Unbounded we propose technical innovations in both the LLM and visualgeneration domains. Specifically we present: 1 a specialized distilledlarge language model LLM that dynamically generates game mechanicsnarratives and character interactions in real-time and 2 a new dynamicregional image prompt Adapter IP-Adapter for vision models that ensuresconsistent yet flexible visual generation of a character across multipleenvironments. We evaluate our system through both qualitative and quantitativeanalysis showing significant improvements in character life simulation userinstruction following narrative coherence and visual consistency for bothcharacters and the environments compared to traditional related approaches. |


| Item |Content|
| --- |---|
|idx| 2410.18973v1 |
|title| Tuning-free coreset Markov chain Monte Carlo |
|authors| Naitong ChenJonathan H. HugginsTrevor Campbell
|links| http://arxiv.org/abs/2410.18973v1 |
|updated| 2024-10-24 17:59:23 UTC |
|summary| A Bayesian coreset is a small weighted subset of a data set that replacesthe full data during inference to reduce computational cost. Thestate-of-the-art coreset construction algorithm Coreset Markov chain MonteCarlo Coreset MCMC uses draws from an adaptive Markov chain targeting thecoreset posterior to train the coreset weights via stochastic gradientoptimization. However the quality of the constructed coreset and thus thequality of its posterior approximation is sensitive to the stochasticoptimization learning rate. In this work we propose a learning-rate-freestochastic gradient optimization procedure Hot-start Distance over GradientHot DoG for training coreset weights in Coreset MCMC without user tuningeffort. Empirical results demonstrate that Hot DoG provides higher qualityposterior approximations than other learning-rate-free stochastic gradientmethods and performs competitively to optimally-tuned ADAM. |


| Item |Content|
| --- |---|
|idx| 2410.18972v1 |
|title| Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques |
|authors| David Ortiz-PerezManuel Benavent-LledoJose Garcia-RodriguezDavid TomásM. Flores Vizcaya-Moreno
|links| http://arxiv.org/abs/2410.18972v1 |
|updated| 2024-10-24 17:59:21 UTC |
|summary| Cognitive decline is a natural part of aging often resulting in reducedcognitive abilities. In some cases however this decline is more pronouncedtypically due to disorders such as Alzheimers disease. Early detection ofanomalous cognitive decline is crucial as it can facilitate timelyprofessional intervention. While medical data can help in this detection itoften involves invasive procedures. An alternative approach is to employnon-intrusive techniques such as speech or handwriting analysis which do notnecessarily affect daily activities. This survey reviews the most relevantmethodologies that use deep learning techniques to automate the cognitivedecline estimation task including audio text and visual processing. Wediscuss the key features and advantages of each modality and methodologyincluding state-of-the-art approaches like Transformer architecture andfoundation models. In addition we present works that integrate differentmodalities to develop multimodal models. We also highlight the most significantdatasets and the quantitative results from studies using these resources. Fromthis review several conclusions emerge. In most cases the textual modalityachieves the best results and is the most relevant for detecting cognitivedecline. Moreover combining various approaches from individual modalities intoa multimodal model consistently enhances performance across nearly allscenarios. |


# cs.CV 

| Item |Content|
| --- |---|
|idx| 2410.18979v1 |
|title| PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary Views |
|authors| Xin FeiWenzhao ZhengYueqi DuanWei ZhanMasayoshi TomizukaKurt KeutzerJiwen Lu
|links| http://arxiv.org/abs/2410.18979v1 |
|updated| 2024-10-24 17:59:58 UTC |
|summary| We propose PixelGaussian an efficient feed-forward framework for learninggeneralizable 3D Gaussian reconstruction from arbitrary views. Most existingmethods rely on uniform pixel-wise Gaussian representations which learn afixed number of 3D Gaussians for each view and cannot generalize well to moreinput views. Differently our PixelGaussian dynamically adapts both theGaussian distribution and quantity based on geometric complexity leading tomore efficient representations and significant improvements in reconstructionquality. Specifically we introduce a Cascade Gaussian Adapter to adjustGaussian distribution according to local geometry complexity identified by akeypoint scorer. CGA leverages deformable attention in context-awarehypernetworks to guide Gaussian pruning and splitting ensuring accuraterepresentation in complex regions while reducing redundancy. Furthermore wedesign a transformer-based Iterative Gaussian Refiner module that refinesGaussian representations through direct image-Gaussian interactions. OurPixelGaussian can effectively reduce Gaussian redundancy as input viewsincrease. We conduct extensive experiments on the large-scale ACID andRealEstate10K datasets where our method achieves state-of-the-art performancewith good generalization to various numbers of views. Code:https://github.com/Barrybarry-Smith/PixelGaussian. |


| Item |Content|
| --- |---|
|idx| 2410.18978v1 |
|title| Framer: Interactive Frame Interpolation |
|authors| Wen WangQiuyu WangKecheng ZhengHao OuyangZhekai ChenBiao GongHao ChenYujun ShenChunhua Shen
|links| http://arxiv.org/abs/2410.18978v1 |
|updated| 2024-10-24 17:59:51 UTC |
|summary| We propose Framer for interactive frame interpolation which targetsproducing smoothly transitioning frames between two images as per usercreativity. Concretely besides taking the start and end frames as inputs ourapproach supports customizing the transition process by tailoring thetrajectory of some selected keypoints. Such a design enjoys two clear benefits.First incorporating human interaction mitigates the issue arising fromnumerous possibilities of transforming one image to another and in turnenables finer control of local motions. Second as the most basic form ofinteraction keypoints help establish the correspondence across framesenhancing the model to handle challenging cases e.g. objects on the start andend frames are of different shapes and styles. It is noteworthy that oursystem also offers an autopilot mode where we introduce a module to estimatethe keypoints and refine the trajectory automatically to simplify the usage inpractice. Extensive experimental results demonstrate the appealing performanceof Framer on various applications such as image morphing time-lapse videogeneration cartoon interpolation etc. The code the model and the interfacewill be released to facilitate further research. |


| Item |Content|
| --- |---|
|idx| 2410.18977v1 |
|title| MotionCLR: Motion Generation and Training-free Editing via Understanding Attention Mechanisms |
|authors| Ling-Hao ChenWenxun DaiXuan JuShunlin LuLei Zhang
|links| http://arxiv.org/abs/2410.18977v1 |
|updated| 2024-10-24 17:59:45 UTC |
|summary| This research delves into the problem of interactive editing of human motiongeneration. Previous motion diffusion models lack explicit modeling of theword-level text-motion correspondence and good explainability hencerestricting their fine-grained editing ability. To address this issue wepropose an attention-based motion diffusion model namely MotionCLR with CLeaRmodeling of attention mechanisms. Technically MotionCLR models the in-modalityand cross-modality interactions with self-attention and cross-attentionrespectively. More specifically the self-attention mechanism aims to measurethe sequential similarity between frames and impacts the order of motionfeatures. By contrast the cross-attention mechanism works to find thefine-grained word-sequence correspondence and activate the correspondingtimesteps in the motion sequence. Based on these key properties we develop aversatile set of simple yet effective motion editing methods via manipulatingattention maps such as motion de-emphasizing in-place motion replacementand example-based motion generation etc. For further verification of theexplainability of the attention mechanism we additionally explore thepotential of action-counting and grounded motion generation ability viaattention maps. Our experimental results show that our method enjoys goodgeneration and editing ability with good explainability. |


| Item |Content|
| --- |---|
|idx| 2410.18976v1 |
|title| CAMEL-Bench: A Comprehensive Arabic LMM Benchmark |
|authors| Sara GhabouraAhmed HeaklOmkar ThawakarAli AlharthiInes RiahiAbduljalil SaifJorma LaaksonenFahad S. KhanSalman KhanRao M. Anwer
|links| http://arxiv.org/abs/2410.18976v1 |
|updated| 2024-10-24 17:59:38 UTC |
|summary| Recent years have witnessed a significant interest in developing largemultimodal models LMMs capable of performing various visual reasoning andunderstanding tasks. This has led to the introduction of multiple LMMbenchmarks to evaluate LMMs on different tasks. However most existing LMMevaluation benchmarks are predominantly English-centric. In this work wedevelop a comprehensive LMM evaluation benchmark for the Arabic language torepresent a large population of over 400 million speakers. The proposedbenchmark named CAMEL-Bench comprises eight diverse domains and 38sub-domains including multi-image understanding complex visual perceptionhandwritten document understanding video understanding medical imaging plantdiseases and remote sensing-based land use understanding to evaluate broadscenario generalizability. Our CAMEL-Bench comprises around 29036 questionsthat are filtered from a larger pool of samples where the quality is manuallyverified by native speakers to ensure reliable model assessment. We conductevaluations of both closed-source including GPT-4 series and open-sourceLMMs. Our analysis reveals the need for substantial improvement especiallyamong the best open-source models with even the closed-source GPT-4o achievingan overall score of 62. Our benchmark and evaluation scripts are open-sourced. |


| Item |Content|
| --- |---|
|idx| 2410.18975v1 |
|title| Unbounded: A Generative Infinite Game of Character Life Simulation |
|authors| Jialu LiYuanzhen LiNeal WadhwaYael PritchDavid E. JacobsMichael RubinsteinMohit BansalNataniel Ruiz
|links| http://arxiv.org/abs/2410.18975v1 |
|updated| 2024-10-24 17:59:31 UTC |
|summary| We introduce the concept of a generative infinite game a video game thattranscends the traditional boundaries of finite hard-coded systems by usinggenerative models. Inspired by James P. Carses distinction between finite andinfinite games we leverage recent advances in generative AI to createUnbounded: a game of character life simulation that is fully encapsulated ingenerative models. Specifically Unbounded draws inspiration from sandbox lifesimulations and allows you to interact with your autonomous virtual characterin a virtual world by feeding playing with and guiding it - with open-endedmechanics generated by an LLM some of which can be emergent. In order todevelop Unbounded we propose technical innovations in both the LLM and visualgeneration domains. Specifically we present: 1 a specialized distilledlarge language model LLM that dynamically generates game mechanicsnarratives and character interactions in real-time and 2 a new dynamicregional image prompt Adapter IP-Adapter for vision models that ensuresconsistent yet flexible visual generation of a character across multipleenvironments. We evaluate our system through both qualitative and quantitativeanalysis showing significant improvements in character life simulation userinstruction following narrative coherence and visual consistency for bothcharacters and the environments compared to traditional related approaches. |


# stat.ML 

| Item |Content|
| --- |---|
|idx| 2410.18959v1 |
|title| Context is Key: A Benchmark for Forecasting with Essential Textual Information |
|authors| Andrew Robert WilliamsArjun AshokÉtienne MarcotteValentina ZantedeschiJithendaraa SubramanianRoland RiachiJames RequeimaAlexandre LacosteIrina RishNicolas ChapadosAlexandre Drouin
|links| http://arxiv.org/abs/2410.18959v1 |
|updated| 2024-10-24 17:56:08 UTC |
|summary| Forecasting is a critical task in decision making across various domains.While numerical data provides a foundation it often lacks crucial contextnecessary for accurate predictions. Human forecasters frequently rely onadditional information such as background knowledge or constraints which canbe efficiently communicated through natural language. However the ability ofexisting forecasting models to effectively integrate this textual informationremains an open question. To address this we introduce Context is Key CiKa time series forecasting benchmark that pairs numerical data with diversetypes of carefully crafted textual context requiring models to integrate bothmodalities. We evaluate a range of approaches including statistical modelstime series foundation models and LLM-based forecasters and propose a simpleyet effective LLM prompting method that outperforms all other tested methods onour benchmark. Our experiments highlight the importance of incorporatingcontextual information demonstrate surprising performance when using LLM-basedforecasting models and also reveal some of their critical shortcomings. Bypresenting this benchmark we aim to advance multimodal forecasting promotingmodels that are both accurate and accessible to decision-makers with variedtechnical expertise. The benchmark can be visualized athttps://servicenow.github.io/context-is-key-forecasting/v0/ . |


| Item |Content|
| --- |---|
|idx| 2410.18938v1 |
|title| A Random Matrix Theory Perspective on the Spectrum of Learned Features and Asymptotic Generalization Capabilities |
|authors| Yatin DandiLuca PesceHugo CuiFlorent KrzakalaYue M. LuBruno Loureiro
|links| http://arxiv.org/abs/2410.18938v1 |
|updated| 2024-10-24 17:24:34 UTC |
|summary| A key property of neural networks is their capacity of adapting to dataduring training. Yet our current mathematical understanding of featurelearning and its relationship to generalization remain limited. In this workwe provide a random matrix analysis of how fully-connected two-layer neuralnetworks adapt to the target function after a single but aggressive gradientdescent step. We rigorously establish the equivalence between the updatedfeatures and an isotropic spiked random feature model in the limit of largebatch size. For the latter model we derive a deterministic equivalentdescription of the feature empirical covariance matrix in terms of certainlow-dimensional operators. This allows us to sharply characterize the impact oftraining in the asymptotic feature spectrum and in particular provides atheoretical grounding for how the tails of the feature spectrum modify withtraining. The deterministic equivalent further yields the exact asymptoticgeneralization error shedding light on the mechanisms behind its improvementin the presence of feature learning. Our result goes beyond standard randommatrix ensembles and therefore we believe it is of independent technicalinterest. Different from previous work our result holds in the challengingmaximal learning rate regime is fully rigorous and allows for finitelysupported second layer initialization which turns out to be crucial forstudying the functional expressivity of the learned features. This provides asharp description of the impact of feature learning in the generalization oftwo-layer neural networks beyond the random features and lazy trainingregimes. |


| Item |Content|
| --- |---|
|idx| 2410.18929v1 |
|title| AutoStep: Locally adaptive involutive MCMC |
|authors| Tiange LiuNikola SurjanovicMiguel Biron-LattesAlexandre Bouchard-CôtéTrevor Campbell
|links| http://arxiv.org/abs/2410.18929v1 |
|updated| 2024-10-24 17:17:11 UTC |
|summary| Many common Markov chain Monte Carlo MCMC kernels can be formulated using adeterministic involutive proposal with a step size parameter. Selecting anappropriate step size is often a challenging task in practice and for complexmultiscale targets there may not be one choice of step size that works wellglobally. In this work we address this problem with a novel class ofinvolutive MCMC methods -- AutoStep MCMC -- that selects an appropriate stepsize at each iteration adapted to the local geometry of the targetdistribution. We prove that AutoStep MCMC is pi-invariant and has otherdesirable properties under mild assumptions on the target distribution piand involutive proposal. Empirical results examine the effect of various stepsize selection design choices and show that AutoStep MCMC is competitive withstate-of-the-art methods in terms of effective sample size per unit cost on arange of challenging target distributions. |


| Item |Content|
| --- |---|
|idx| 2410.18918v1 |
|title| MissNODAG: Differentiable Cyclic Causal Graph Learning from Incomplete Data |
|authors| Muralikrishnna G. SethuramanRazieh NabiFaramarz Fekri
|links| http://arxiv.org/abs/2410.18918v1 |
|updated| 2024-10-24 17:09:10 UTC |
|summary| Causal discovery in real-world systems such as biological networks is oftencomplicated by feedback loops and incomplete data. Standard algorithms whichassume acyclic structures or fully observed data struggle with thesechallenges. To address this gap we propose MissNODAG a differentiableframework for learning both the underlying cyclic causal graph and themissingness mechanism from partially observed data including data missing notat random. Our framework integrates an additive noise model with anexpectation-maximization procedure alternating between imputing missing valuesand optimizing the observed data likelihood to uncover both the cyclicstructures and the missingness mechanism. We demonstrate the effectiveness ofMissNODAG through synthetic experiments and an application to real-world geneperturbation data. |


| Item |Content|
| --- |---|
|idx| 2410.18844v1 |
|title| Learning to Explore with Lagrangians for Bandits under Unknown Linear Constraints |
|authors| Udvas DasDebabrota Basu
|links| http://arxiv.org/abs/2410.18844v1 |
|updated| 2024-10-24 15:26:14 UTC |
|summary| Pure exploration in bandits models multiple real-world problems such astuning hyper-parameters or conducting user studies where different safetyresource and fairness constraints on the decision space naturally appear. Westudy these problems as pure exploration in multi-armed bandits with unknownlinear constraints where the aim is to identify an rtextit-good feasiblepolicy. First we propose a Lagrangian relaxation of the sample complexitylower bound for pure exploration under constraints. We show how this lowerbound evolves with the sequential estimation of constraints. Second weleverage the Lagrangian lower bound and the properties of convex optimisationto propose two computationally efficient extensions of Track-and-Stop andGamified Explorer namely LATS and LAGEX. To this end we propose aconstraint-adaptive stopping rule and while tracking the lower bound usepessimistic estimate of the feasible set at each step. We show that thesealgorithms achieve asymptotically optimal sample complexity upper bounds up toconstraint-dependent constants. Finally we conduct numerical experiments withdifferent reward distributions and constraints that validate efficientperformance of LAGEX and LATS with respect to baselines. |


# cs.HC 

| Item |Content|
| --- |---|
|idx| 2410.18924v1 |
|title| Swarm manipulation: An efficient and accurate technique for multi-object manipulation in virtual reality |
|authors| Xiang LiJin-Du WangJohn J. DudleyPer Ola Kristensson
|links| http://arxiv.org/abs/2410.18924v1 |
|updated| 2024-10-24 17:12:51 UTC |
|summary| The theory of swarm control shows promise for controlling multiple objectshowever scalability is hindered by cost constraints such as hardware andinfrastructure. Virtual Reality VR can overcome these limitations butresearch on swarm interaction in VR is limited. This paper introduces a novelSwarm Manipulation interaction technique and compares it with two baselinetechniques: Virtual Hand and Controller ray-casting. We evaluated thesetechniques in a user study N  12 in three tasks selection rotation andresizing across five conditions. Our results indicate that Swarm Manipulationyielded superior performance with significantly faster speeds in mostconditions across the three tasks. It notably reduced resizing size deviationsbut introduced a trade-off between speed and accuracy in the rotation task.Additionally we conducted a follow-up user study N  6 using SwarmManipulation in two complex VR scenarios and obtained insights throughsemi-structured interviews shedding light on optimized swarm controlmechanisms and perceptual changes induced by this interaction paradigm. Theseresults demonstrate the potential of the Swarm Manipulation technique toenhance the usability and user experience in VR compared to conventionalmanipulation techniques. In future studies we aim to understand and improveswarm interaction via internal swarm particle cooperation. |


| Item |Content|
| --- |---|
|idx| 2410.18876v1 |
|title| Guiding Empowerment Model: Liberating Neurodiversity in Online Higher Education |
|authors| Hannah BeauxPegah KarimiOtilia PopRob Clark
|links| http://arxiv.org/abs/2410.18876v1 |
|updated| 2024-10-24 16:05:38 UTC |
|summary| In this innovative practice full paper we address the equity gap forneurodivergent and situationally limited learners by identifying the spectrumof dynamic factors that impact learning and function. Educators have shown agrowing interest in identifying learners cognitive abilities and learningpreferences to measure their impact on academic achievement. Often institutionsemploy one-size-fits-all approaches leaving the burden on disabled students toself-advocate or tolerate inadequate support. Emerging frameworks guideneurodivergent learners through instructional approaches such as onlineeducation. However these frameworks fail to address holistic environmentalneeds or recommend technology interventions particularly for those withundisclosed learning or developmental disabilities and situational limitations.In this article we integrate a neurodivergent perspective through secondaryresearch of around 100 articles to introduce a Guiding Empowerment Modelinvolving key cognitive and situational factors that contextualize day-to-dayexperiences affecting learner ability. We synthesize three sample studentprofiles that highlight user problems in functioning. We use this model toevaluate sample learning platform features and other supportive technologysolutions. The proposed approach augments frameworks such as Universal Designfor Learning to consider factors including various sensory processingdifferences social connection challenges and environmental limitations. Wesuggest that by applying the mode through technology-enabled features such ascustomizable task management guided varied content access and guidedmulti-modal collaboration major learning barriers of neurodivergent andsituationally limited learners will be removed to activate the successfulpursuit of their academic goals. |


| Item |Content|
| --- |---|
|idx| 2410.18875v1 |
|title| Exploring the Universe with SNAD: Anomaly Detection in Astronomy |
|authors| Alina A. VolnovaPatrick D. AleoAnastasia LavrukhinaEtienne RusseilTimofey SemenikhinEmmanuel GanglerEmille E. O. IshidaMatwey V. KornilovVladimir KorolevKonstantin MalanchevMaria V. PruzhinskayaSreevarsha Sreejith
|links| http://dx.doi.org/10.1007/978-3-031-67826-4_15 |
|updated| 2024-10-24 16:05:11 UTC |
|summary| SNAD is an international project with a primary focus on detectingastronomical anomalies within large-scale surveys using active learning andother machine learning algorithms. The work carried out by SNAD not onlycontributes to the discovery and classification of various astronomicalphenomena but also enhances our understanding and implementation of machinelearning techniques within the field of astrophysics. This paper provides areview of the SNAD project and summarizes the advancements and achievementsmade by the team over several years. |


| Item |Content|
| --- |---|
|idx| 2410.18851v1 |
|title| Intention Is All You Need |
|authors| Advait Sarkar
|links| http://arxiv.org/abs/2410.18851v1 |
|updated| 2024-10-24 15:33:34 UTC |
|summary| Among the many narratives of the transformative power of Generative AI is onethat sees in the world a latent nation of programmers who need to wield nothingbut intentions and natural language to render their ideas in software. In thispaper this outlook is problematised in two ways. First it is observed thatgenerative AI is not a neutral vehicle of intention. Multiple recent studiespaint a picture of the mechanised convergence phenomenon namely thatgenerative AI has a homogenising effect on intention. Second it is observedthat the formation of intention itself is immensely challenging. Constraintsmateriality and resistance can offer paths to design metaphors for intentionaltools. Finally existentialist approaches to intention are discussed andpossible implications for programming are proposed in the form of aspeculative illustrative set of intentional programming practices. |


| Item |Content|
| --- |---|
|idx| 2410.18845v1 |
|title| Expanding AI Awareness Through Everyday Interactions with AI: A Reflective Journal Study |
|authors| Ashish HingleAditya Johri
|links| http://arxiv.org/abs/2410.18845v1 |
|updated| 2024-10-24 15:26:34 UTC |
|summary| As the application of AI continues to expand students in technology programsare poised to be both producers and users of the technologies. They are alsopositioned to engage with AI applications within and outside the classroom.While focusing on the curriculum when examining students AI knowledge iscommon extending this connection to students everyday interactions with AIprovides a more complete picture of their learning. In this paper we explorestudents awareness and engagement with AI in the context of school and theirdaily lives. Over six weeks 22 undergraduate students participated in areflective journal study and submitted a weekly journal entry about theirinteractions with AI. The participants were recruited from a technology andsociety course that focuses on the implications of technology on peoplecommunities and processes. In their weekly journal entries participantsreflected on interactions with AI on campus coursework advertises campusevents or seminars and beyond social media news or conversations withfriends and family. The journal prompts were designed to help them thinkthrough what they had read watched or been told and reflect on thedevelopment of their own perspectives knowledge and literacy on the topic.Overall students described nine categories of interactions: coursework newsand current events using software and applications university events socialmedia related to their work personal discussions with friends and familyinteracting with content and gaming. Students reported that completing thediaries allowed them time for reflection and made them more aware of thepresence of AI in their daily lives and of its potential benefits anddrawbacks. This research contributes to the ongoing work on AI awareness andliteracy by bringing in perspectives from beyond a formal educational context. |


# cs.MA 

| Item |Content|
| --- |---|
|idx| 2410.18871v1 |
|title| Learning Collusion in Episodic, Inventory-Constrained Markets |
|authors| Paul FriedrichBarna PásztorGiorgia Ramponi
|links| http://arxiv.org/abs/2410.18871v1 |
|updated| 2024-10-24 15:58:14 UTC |
|summary| Pricing algorithms have demonstrated the capability to learn tacit collusionthat is largely unaddressed by current regulations. Their increasing use inmarkets including oligopolistic industries with a history of collusion callsfor closer examination by competition authorities. In this paper we extend thestudy of tacit collusion in learning algorithms from basic pricing games tomore complex markets characterized by perishable goods with fixed supply andsell-by dates such as airline tickets perishables and hotel rooms. Weformalize collusion within this framework and introduce a metric based on pricelevels under both the competitive Nash equilibrium and collusivemonopolistic optimum. Since no analytical expressions for these price levelsexist we propose an efficient computational approach to derive them. Throughexperiments we demonstrate that deep reinforcement learning agents can learnto collude in this more complex domain. Additionally we analyze the underlyingmechanisms and structures of the collusive strategies these agents adopt. |


| Item |Content|
| --- |---|
|idx| 2410.18631v1 |
|title| Leveraging Graph Neural Networks and Multi-Agent Reinforcement Learning for Inventory Control in Supply Chains |
|authors| Niki KotechaAntonio del Rio Chanona
|links| http://arxiv.org/abs/2410.18631v1 |
|updated| 2024-10-24 10:43:04 UTC |
|summary| Inventory control in modern supply chains has attracted significant attentiondue to the increasing number of disruptive shocks and the challenges posed bycomplex dynamics uncertainties and limited collaboration. Traditionalmethods which often rely on static parameters struggle to adapt to changingenvironments. This paper proposes a Multi-Agent Reinforcement Learning MARLframework with Graph Neural Networks GNNs for state representation to addressthese limitations.  Our approach redefines the action space by parameterizing heuristic inventorycontrol policies making it adaptive as the parameters dynamically adjust basedon system conditions. By leveraging the inherent graph structure of supplychains our framework enables agents to learn the systems topology and weemploy a centralized learning decentralized execution scheme that allowsagents to learn collaboratively while overcoming information-sharingconstraints. Additionally we incorporate global mean pooling andregularization techniques to enhance performance.  We test the capabilities of our proposed approach on four different supplychain configurations and conduct a sensitivity analysis. This work paves theway for utilizing MARL-GNN frameworks to improve inventory management incomplex decentralized supply chain environments. |


| Item |Content|
| --- |---|
|idx| 2410.18202v1 |
|title| PyTSC: A Unified Platform for Multi-Agent Reinforcement Learning in Traffic Signal Control |
|authors| Rohit BokadeXiaoning Jin
|links| http://arxiv.org/abs/2410.18202v1 |
|updated| 2024-10-23 18:10:38 UTC |
|summary| Multi-Agent Reinforcement Learning MARL presents a promising approach foraddressing the complexity of Traffic Signal Control TSC in urbanenvironments. However existing platforms for MARL-based TSC research facechallenges such as slow simulation speeds and convoluted difficult-to-maintaincodebases. To address these limitations we introduce PyTSC a robust andflexible simulation environment that facilitates the training and evaluation ofMARL algorithms for TSC. PyTSC integrates multiple simulators such as SUMO andCityFlow and offers a streamlined API empowering researchers to explore abroad spectrum of MARL approaches efficiently. PyTSC acceleratesexperimentation and provides new opportunities for advancing intelligenttraffic management systems in real-world applications. |


| Item |Content|
| --- |---|
|idx| 2410.18032v1 |
|title| GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration |
|authors| Xin LiQizhi ChuYubin ChenYang LiuYaoqi LiuZekai YuWeize ChenChen QianChuan ShiCheng Yang
|links| http://arxiv.org/abs/2410.18032v1 |
|updated| 2024-10-23 17:02:59 UTC |
|summary| Graphs are widely used for modeling relational data in real-world scenariossuch as social networks and urban computing. Existing LLM-based graph analysisapproaches either integrate graph neural networks GNNs for specific machinelearning tasks limiting their transferability or rely solely on LLMsinternal reasoning ability resulting in suboptimal performance. To addressthese limitations we take advantage of recent advances in LLM-based agentswhich have shown capabilities of utilizing external knowledge or tools forproblem solving. By simulating human problem-solving strategies such as analogyand collaboration we propose a multi-agent system based on LLMs namedGraphTeam for graph analysis. GraphTeam consists of five LLM-based agents fromthree modules and the agents with different specialities can collaborate witheach other to address complex problems. Specifically 1 input-outputnormalization module: the question agent extracts and refines four keyarguments from the original question facilitating the problem understandingand the answer agent organizes the results to meet the output requirement 2external knowledge retrieval module: we first build a knowledge base consistingof relevant documentation and experience information and then the search agentretrieves the most relevant entries for each question. 3 problem-solvingmodule: given the retrieved information from search agent the coding agentuses established algorithms via programming to generate solutions and in casethe coding agent does not work the reasoning agent will directly compute theresults without programming. Extensive experiments on six graph analysisbenchmarks demonstrate that GraphTeam achieves state-of-the-art performancewith an average 25.85 improvement over the best baseline in terms of accuracy.The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam. |


| Item |Content|
| --- |---|
|idx| 2410.17898v1 |
|title| Scalable Offline Reinforcement Learning for Mean Field Games |
|authors| Axel BrunnbauerJulian LemmelZahra BabaieeSophie NeubauerRadu Grosu
|links| http://arxiv.org/abs/2410.17898v1 |
|updated| 2024-10-23 14:16:34 UTC |
|summary| Reinforcement learning algorithms for mean-field games offer a scalableframework for optimizing policies in large populations of interacting agents.Existing methods often depend on online interactions or access to systemdynamics limiting their practicality in real-world scenarios where suchinteractions are infeasible or difficult to model. In this paper we presentOffline Munchausen Mirror Descent Off-MMD a novel mean-field RL algorithmthat approximates equilibrium policies in mean-field games using purely offlinedata. By leveraging iterative mirror descent and importance samplingtechniques Off-MMD estimates the mean-field distribution from static datasetswithout relying on simulation or environment dynamics. Additionally weincorporate techniques from offline reinforcement learning to address commonissues like Q-value overestimation ensuring robust policy learning even withlimited data coverage. Our algorithm scales to complex environments anddemonstrates strong performance on benchmark tasks like crowd exploration ornavigation highlighting its applicability to real-world multi-agent systemswhere online experimentation is infeasible. We empirically demonstrate therobustness of Off-MMD to low-quality datasets and conduct experiments toinvestigate its sensitivity to hyperparameter choices. |


