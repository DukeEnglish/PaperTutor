# cs.CL 

| Item |Content|
| --- |---|
|idx| 2409.17146v1 |
|title| Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models |
|authors| Matt DeitkeChristopher ClarkSangho LeeRohun TripathiYue YangJae Sung ParkMohammadreza SalehiNiklas MuennighoffKyle LoLuca SoldainiJiasen LuTaira AndersonErin BransomKiana EhsaniHuong NgoYenSung ChenAjay PatelMark YatskarChris Callison-BurchAndrew HeadRose HendrixFavyen BastaniEli VanderBiltNathan LambertYvonne ChouArnavi ChhedaJenna SparksSam SkjonsbergMichael SchmitzAaron SarnatByron BischoffPete WalshChris NewellPiper WoltersTanmay GuptaKuo-Hao ZengJon BorchardtDirk GroeneveldJen DumasCrystal NamSophie LebrechtCaitlin WittlifCarissa SchoenickOscar MichelRanjay KrishnaLuca WeihsNoah A. SmithHannaneh HajishirziRoss GirshickAli FarhadiAniruddha Kembhavi
|links| http://arxiv.org/abs/2409.17146v1 |
|updated| 2024-09-25 17:59:51 UTC |
|summary| Todays most advanced multimodal models remain proprietary. The strongestopen-weight models rely heavily on synthetic data from proprietary VLMs toachieve good performance effectively distilling these closed models into openones. As a result the community is still missing foundational knowledge abouthow to build performant VLMs from scratch. We present Molmo a new family ofVLMs that are state-of-the-art in their class of openness. Our key innovationis a novel highly detailed image caption dataset collected entirely from humanannotators using speech-based descriptions. To enable a wide array of userinteractions we also introduce a diverse dataset mixture for fine-tuning thatincludes in-the-wild QA and innovative 2D pointing data. The success of ourapproach relies on careful choices for the model architecture details awell-tuned training pipeline and most critically the quality of our newlycollected datasets all of which will be released. The best-in-class 72B modelwithin the Molmo family not only outperforms others in the class of open weightand data models but also compares favorably against proprietary systems likeGPT-4o Claude 3.5 and Gemini 1.5 on both academic benchmarks and humanevaluation.  We will be releasing all of our model weights captioning and fine-tuningdata and source code in the near future. Select model weights inference codeand demo are available at https://molmo.allenai.org. |


| Item |Content|
| --- |---|
|idx| 2409.17141v1 |
|title| FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression |
|authors| Fazal MittuYihuan BuAkshat GuptaAshok DevireddyAlp Eren OzdarendeliAnant SinghGopala Anumanchipalli
|links| http://arxiv.org/abs/2409.17141v1 |
|updated| 2024-09-25 17:58:35 UTC |
|summary| While the language modeling objective has been shown to be deeply connectedwith compression it is surprising that modern LLMs are not employed inpractical text compression systems. In this paper we provide an in-depthanalysis of neural network and transformer-based compression techniques toanswer this question. We compare traditional text compression systems withneural network and LLM-based text compression methods. Although LLM-basedsystems significantly outperform conventional compression methods they arehighly impractical. Specifically LLMZip a recent text compression systemusing Llama3-8B requires 9.5 days to compress just 10 MB of text although withhuge improvements in compression ratios. To overcome this we present FineZip -a novel LLM-based text compression system that combines ideas of onlinememorization and dynamic context to reduce the compression time immensely.FineZip can compress the above corpus in approximately 4 hours compared to 9.5days a 54 times improvement over LLMZip and comparable performance. FineZipoutperforms traditional algorithmic compression methods with a large marginimproving compression ratios by approximately 50. With this work we take thefirst step towards making lossless text compression with LLMs a reality. WhileFineZip presents a significant step in that direction LLMs are still not aviable solution for large-scale text compression. We hope our work paves theway for future research and innovation to solve this problem. |


| Item |Content|
| --- |---|
|idx| 2409.17130v1 |
|title| Assessing the Level of Toxicity Against Distinct Groups in Bangla Social Media Comments: A Comprehensive Investigation |
|authors| Mukaffi Bin MoinPronay DebnathUsafa Akther RifaRijeet Bin Anis
|links| http://arxiv.org/abs/2409.17130v1 |
|updated| 2024-09-25 17:48:59 UTC |
|summary| Social media platforms have a vital role in the modern world serving asconduits for communication the exchange of ideas and the establishment ofnetworks. However the misuse of these platforms through toxic comments whichcan range from offensive remarks to hate speech is a concerning issue. Thisstudy focuses on identifying toxic comments in the Bengali language targetingthree specific groups: transgender people indigenous people and migrantpeople from multiple social media sources. The study delves into the intricateprocess of identifying and categorizing toxic language while considering thevarying degrees of toxicity: high medium and low. The methodology involvescreating a dataset manual annotation and employing pre-trained transformermodels like Bangla-BERT bangla-bert-base distil-BERT andBert-base-multilingual-cased for classification. Diverse assessment metricssuch as accuracy recall precision and F1-score are employed to evaluate themodels effectiveness. The experimental findings reveal that Bangla-BERTsurpasses alternative models achieving an F1-score of 0.8903. This researchexposes the complexity of toxicity in Bangla social media dialogues revealingits differing impacts on diverse demographic groups. |


| Item |Content|
| --- |---|
|idx| 2409.17120v1 |
|title| Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Handy Appetizer |
|authors| Benji PengXuanhe PanYizhu WenZiqian BiKeyu ChenMing LiMing LiuQian NiuJunyu LiuJinlang WangSen ZhangJiawei XuPohsun Feng
|links| http://arxiv.org/abs/2409.17120v1 |
|updated| 2024-09-25 17:31:45 UTC |
|summary| This book explores the role of Artificial Intelligence AI Machine LearningML and Deep Learning DL in driving the progress of big data analytics andmanagement. The book focuses on simplifying the complex mathematical conceptsbehind deep learning offering intuitive visualizations and practical casestudies to help readers understand how neural networks and technologies likeConvolutional Neural Networks CNNs work. It introduces several classic modelsand technologies such as Transformers GPT ResNet BERT and YOLOhighlighting their applications in fields like natural language processingimage recognition and autonomous driving. The book also emphasizes theimportance of pre-trained models and how they can enhance model performance andaccuracy with instructions on how to apply these models in various real-worldscenarios. Additionally it provides an overview of key big data managementtechnologies like SQL and NoSQL databases as well as distributed computingframeworks such as Apache Hadoop and Spark explaining their importance inmanaging and processing vast amounts of data. Ultimately the book underscoresthe value of mastering deep learning and big data management skills as criticaltools for the future workforce making it an essential resource for bothbeginners and experienced professionals. |


| Item |Content|
| --- |---|
|idx| 2409.17115v1 |
|title| Programming Every Example: Lifting Pre-training Data Quality like Experts at Scale |
|authors| Fan ZhouZengzhi WangQian LiuJunlong LiPengfei Liu
|links| http://arxiv.org/abs/2409.17115v1 |
|updated| 2024-09-25 17:28:13 UTC |
|summary| Large language model pre-training has traditionally relied on human expertsto craft heuristics for improving the corpora quality resulting in numerousrules developed to date. However these rules lack the flexibility to addressthe unique characteristics of individual example effectively. Meanwhileapplying tailored rules to every example is impractical for human experts. Inthis paper we demonstrate that even small language models with as few as 0.3Bparameters can exhibit substantial data refining capabilities comparable tothose of human experts. We introduce Programming Every Example ProX a novelframework that treats data refinement as a programming task enabling models torefine corpora by generating and executing fine-grained operations such asstring normalization for each individual example at scale. Experimentalresults show that models pre-trained on ProX-curated data outperform eitheroriginal data or data filtered by other selection methods by more than 2across various downstream benchmarks. Its effectiveness spans various modelsizes and pre-training corpora including C4 RedPajama-V2 and FineWeb.Furthermore ProX exhibits significant potential in domain-specific continualpre-training: without domain specific design models trained on OpenWebMathrefined by ProX outperform human-crafted rule-based methods improving averageaccuracy by 7.6 over Mistral-7B with 14.6 for Llama-2-7B and 20.3 forCodeLlama-7B all within 10B tokens to be comparable to models like Llemma-7Btrained on 200B tokens. Further analysis highlights that ProX significantlysaves training FLOPs offering a promising path for efficient LLMpre-training.We are open-sourcing ProX with 100B corpus models and sharingall training and implementation details for reproducible research and futureinnovation. Code: https://github.com/GAIR-NLP/ProX |


# cs.AI 

| Item |Content|
| --- |---|
|idx| 2409.17144v1 |
|title| Differential Privacy Regularization: Protecting Training Data Through Loss Function Regularization |
|authors| Francisco Aguilera-Mart√≠nezFernando Berzal
|links| http://arxiv.org/abs/2409.17144v1 |
|updated| 2024-09-25 17:59:32 UTC |
|summary| Training machine learning models based on neural networks requires largedatasets which may contain sensitive information. The models however shouldnot expose private information from these datasets. Differentially private SGDDP-SGD requires the modification of the standard stochastic gradient descentSGD algorithm for training new models. In this short paper a novelregularization strategy is proposed to achieve the same goal in a moreefficient manner. |


| Item |Content|
| --- |---|
|idx| 2409.17143v1 |
|title| Attention Prompting on Image for Large Vision-Language Models |
|authors| Runpeng YuWeihao YuXinchao Wang
|links| http://arxiv.org/abs/2409.17143v1 |
|updated| 2024-09-25 17:59:13 UTC |
|summary| Compared with Large Language Models LLMs Large Vision-Language ModelsLVLMs can also accept images as input thus showcasing more interestingemergent capabilities and demonstrating impressive performance on variousvision-language tasks. Motivated by text prompting in LLMs visual promptinghas been explored to enhance LVLMs capabilities of perceiving visualinformation. However previous visual prompting techniques solely processvisual inputs without considering text queries limiting the models ability tofollow text instructions to complete tasks. To fill this gap in this work wepropose a new prompting technique named Attention Prompting on Image whichjust simply overlays a text-query-guided attention heatmap on the originalinput image and effectively enhances LVLM on various tasks. Specifically wegenerate an attention heatmap for the input image dependent on the text querywith an auxiliary model like CLIP. Then the heatmap simply multiplies the pixelvalues of the original image to obtain the actual input image for the LVLM.Extensive experiments on various vison-language benchmarks verify theeffectiveness of our technique. For example Attention Prompting on Imageimproves LLaVA-1.5 by 3.8 and 2.9 on MM-Vet and LLaVA-Wild benchmarksrespectively. |


| Item |Content|
| --- |---|
|idx| 2409.17141v1 |
|title| FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression |
|authors| Fazal MittuYihuan BuAkshat GuptaAshok DevireddyAlp Eren OzdarendeliAnant SinghGopala Anumanchipalli
|links| http://arxiv.org/abs/2409.17141v1 |
|updated| 2024-09-25 17:58:35 UTC |
|summary| While the language modeling objective has been shown to be deeply connectedwith compression it is surprising that modern LLMs are not employed inpractical text compression systems. In this paper we provide an in-depthanalysis of neural network and transformer-based compression techniques toanswer this question. We compare traditional text compression systems withneural network and LLM-based text compression methods. Although LLM-basedsystems significantly outperform conventional compression methods they arehighly impractical. Specifically LLMZip a recent text compression systemusing Llama3-8B requires 9.5 days to compress just 10 MB of text although withhuge improvements in compression ratios. To overcome this we present FineZip -a novel LLM-based text compression system that combines ideas of onlinememorization and dynamic context to reduce the compression time immensely.FineZip can compress the above corpus in approximately 4 hours compared to 9.5days a 54 times improvement over LLMZip and comparable performance. FineZipoutperforms traditional algorithmic compression methods with a large marginimproving compression ratios by approximately 50. With this work we take thefirst step towards making lossless text compression with LLMs a reality. WhileFineZip presents a significant step in that direction LLMs are still not aviable solution for large-scale text compression. We hope our work paves theway for future research and innovation to solve this problem. |


| Item |Content|
| --- |---|
|idx| 2409.17140v1 |
|title| Turn Every Application into an Agent: Towards Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents |
|authors| Junting LuZhiyang ZhangFangkai YangJue ZhangLu WangChao DuQingwei LinSaravan RajmohanDongmei ZhangQi Zhang
|links| http://arxiv.org/abs/2409.17140v1 |
|updated| 2024-09-25 17:58:08 UTC |
|summary| Multimodal large language models MLLMs have enabled LLM-based agents todirectly interact with application user interfaces UIs enhancing agentsperformance in complex tasks. However these agents often suffer from highlatency and low reliability due to the extensive sequential UI interactions. Toaddress this issue we propose AXIS a novel LLM-based agents frameworkprioritize actions through application programming interfaces APIs over UIactions. This framework also facilitates the creation and expansion of APIsthrough automated exploration of applications. Our experiments on Office Worddemonstrate that AXIS reduces task completion time by 65-70 and cognitiveworkload by 38-53 while maintaining accuracy of 97-98 compare to humans.Our work contributes to a new human-agent-computer interaction HACI frameworkand a fresh UI design principle for application providers in the era of LLMs.It also explores the possibility of turning every applications into agentspaving the way towards an agent-centric operating system Agent OS. |


| Item |Content|
| --- |---|
|idx| 2409.17126v1 |
|title| Blox-Net: Generative Design-for-Robot-Assembly Using VLM Supervision, Physics Simulation, and a Robot with Reset |
|authors| Andrew GoldbergKavish KondapTianshuang QiuZehan MaLetian FuJustin KerrHuang HuangKaiyuan ChenKuan FangKen Goldberg
|links| http://arxiv.org/abs/2409.17126v1 |
|updated| 2024-09-25 17:42:20 UTC |
|summary| Generative AI systems have shown impressive capabilities in creating textcode and images. Inspired by the rich history of research in industrialDesign for Assembly we introduce a novel problem: GenerativeDesign-for-Robot-Assembly GDfRA. The task is to generate an assembly based ona natural language prompt e.g. giraffe and an image of availablephysical components such as 3D-printed blocks. The output is an assembly aspatial arrangement of these components and instructions for a robot to buildthis assembly. The output must 1 resemble the requested object and 2 bereliably assembled by a 6 DoF robot arm with a suction gripper. We then presentBlox-Net a GDfRA system that combines generative vision language models withwell-established methods in computer vision simulation perturbation analysismotion planning and physical robot experimentation to solve a class of GDfRAproblems with minimal human supervision. Blox-Net achieved a Top-1 accuracy of63.5 in the recognizability of its designed assemblies eg resemblinggiraffe as judged by a VLM. These designs after automated perturbationredesign were reliably assembled by a robot achieving near-perfect successacross 10 consecutive assembly iterations with human intervention only duringreset prior to assembly. Surprisingly this entire design process from textualword giraffe to reliable physical assembly is performed with zero humanintervention. |


# cs.LG 

| Item |Content|
| --- |---|
|idx| 2409.17146v1 |
|title| Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models |
|authors| Matt DeitkeChristopher ClarkSangho LeeRohun TripathiYue YangJae Sung ParkMohammadreza SalehiNiklas MuennighoffKyle LoLuca SoldainiJiasen LuTaira AndersonErin BransomKiana EhsaniHuong NgoYenSung ChenAjay PatelMark YatskarChris Callison-BurchAndrew HeadRose HendrixFavyen BastaniEli VanderBiltNathan LambertYvonne ChouArnavi ChhedaJenna SparksSam SkjonsbergMichael SchmitzAaron SarnatByron BischoffPete WalshChris NewellPiper WoltersTanmay GuptaKuo-Hao ZengJon BorchardtDirk GroeneveldJen DumasCrystal NamSophie LebrechtCaitlin WittlifCarissa SchoenickOscar MichelRanjay KrishnaLuca WeihsNoah A. SmithHannaneh HajishirziRoss GirshickAli FarhadiAniruddha Kembhavi
|links| http://arxiv.org/abs/2409.17146v1 |
|updated| 2024-09-25 17:59:51 UTC |
|summary| Todays most advanced multimodal models remain proprietary. The strongestopen-weight models rely heavily on synthetic data from proprietary VLMs toachieve good performance effectively distilling these closed models into openones. As a result the community is still missing foundational knowledge abouthow to build performant VLMs from scratch. We present Molmo a new family ofVLMs that are state-of-the-art in their class of openness. Our key innovationis a novel highly detailed image caption dataset collected entirely from humanannotators using speech-based descriptions. To enable a wide array of userinteractions we also introduce a diverse dataset mixture for fine-tuning thatincludes in-the-wild QA and innovative 2D pointing data. The success of ourapproach relies on careful choices for the model architecture details awell-tuned training pipeline and most critically the quality of our newlycollected datasets all of which will be released. The best-in-class 72B modelwithin the Molmo family not only outperforms others in the class of open weightand data models but also compares favorably against proprietary systems likeGPT-4o Claude 3.5 and Gemini 1.5 on both academic benchmarks and humanevaluation.  We will be releasing all of our model weights captioning and fine-tuningdata and source code in the near future. Select model weights inference codeand demo are available at https://molmo.allenai.org. |


| Item |Content|
| --- |---|
|idx| 2409.17145v1 |
|title| DreamWaltz-G: Expressive 3D Gaussian Avatars from Skeleton-Guided 2D Diffusion |
|authors| Yukun HuangJianan WangAiling ZengZheng-Jun ZhaLei ZhangXihui Liu
|links| http://arxiv.org/abs/2409.17145v1 |
|updated| 2024-09-25 17:59:45 UTC |
|summary| Leveraging pretrained 2D diffusion models and score distillation samplingSDS recent methods have shown promising results for text-to-3D avatargeneration. However generating high-quality 3D avatars capable of expressiveanimation remains challenging. In this work we present DreamWaltz-G a novellearning framework for animatable 3D avatar generation from text. The core ofthis framework lies in Skeleton-guided Score Distillation and Hybrid 3DGaussian Avatar representation. Specifically the proposed skeleton-guidedscore distillation integrates skeleton controls from 3D human templates into 2Ddiffusion models enhancing the consistency of SDS supervision in terms of viewand human pose. This facilitates the generation of high-quality avatarsmitigating issues such as multiple faces extra limbs and blurring. Theproposed hybrid 3D Gaussian avatar representation builds on the efficient 3DGaussians combining neural implicit fields and parameterized 3D meshes toenable real-time rendering stable SDS optimization and expressive animation.Extensive experiments demonstrate that DreamWaltz-G is highly effective ingenerating and animating 3D avatars outperforming existing methods in bothvisual quality and animation expressiveness. Our framework further supportsdiverse applications including human video reenactment and multi-subject scenecomposition. |


| Item |Content|
| --- |---|
|idx| 2409.17144v1 |
|title| Differential Privacy Regularization: Protecting Training Data Through Loss Function Regularization |
|authors| Francisco Aguilera-Mart√≠nezFernando Berzal
|links| http://arxiv.org/abs/2409.17144v1 |
|updated| 2024-09-25 17:59:32 UTC |
|summary| Training machine learning models based on neural networks requires largedatasets which may contain sensitive information. The models however shouldnot expose private information from these datasets. Differentially private SGDDP-SGD requires the modification of the standard stochastic gradient descentSGD algorithm for training new models. In this short paper a novelregularization strategy is proposed to achieve the same goal in a moreefficient manner. |


| Item |Content|
| --- |---|
|idx| 2409.17141v1 |
|title| FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression |
|authors| Fazal MittuYihuan BuAkshat GuptaAshok DevireddyAlp Eren OzdarendeliAnant SinghGopala Anumanchipalli
|links| http://arxiv.org/abs/2409.17141v1 |
|updated| 2024-09-25 17:58:35 UTC |
|summary| While the language modeling objective has been shown to be deeply connectedwith compression it is surprising that modern LLMs are not employed inpractical text compression systems. In this paper we provide an in-depthanalysis of neural network and transformer-based compression techniques toanswer this question. We compare traditional text compression systems withneural network and LLM-based text compression methods. Although LLM-basedsystems significantly outperform conventional compression methods they arehighly impractical. Specifically LLMZip a recent text compression systemusing Llama3-8B requires 9.5 days to compress just 10 MB of text although withhuge improvements in compression ratios. To overcome this we present FineZip -a novel LLM-based text compression system that combines ideas of onlinememorization and dynamic context to reduce the compression time immensely.FineZip can compress the above corpus in approximately 4 hours compared to 9.5days a 54 times improvement over LLMZip and comparable performance. FineZipoutperforms traditional algorithmic compression methods with a large marginimproving compression ratios by approximately 50. With this work we take thefirst step towards making lossless text compression with LLMs a reality. WhileFineZip presents a significant step in that direction LLMs are still not aviable solution for large-scale text compression. We hope our work paves theway for future research and innovation to solve this problem. |


| Item |Content|
| --- |---|
|idx| 2409.17139v1 |
|title| Learning with Dynamics: Autonomous Regulation of UAV Based Communication Networks with Dynamic UAV Crew |
|authors| Ran ZhangBowei LiLiyuan ZhangJiangXieMiao Wang
|links| http://arxiv.org/abs/2409.17139v1 |
|updated| 2024-09-25 17:57:04 UTC |
|summary| Unmanned Aerial Vehicle UAV based communication networks UCNs are a keycomponent in future mobile networking. To handle the dynamic environments inUCNs reinforcement learning RL has been a promising solution attributed toits strong capability of adaptive decision-making free of the environmentmodels. However most existing RL-based research focus on control strategydesign assuming a fixed set of UAVs. Few works have investigated how UCNsshould be adaptively regulated when the serving UAVs change dynamically. Thisarticle discusses RL-based strategy design for adaptive UCN regulation given adynamic UAV set addressing both reactive strategies in general UCNs andproactive strategies in solar-powered UCNs. An overview of the UCN and the RLframework is first provided. Potential research directions with key challengesand possible solutions are then elaborated. Some of our recent works arepresented as case studies to inspire innovative ways to handle dynamic UAV crewwith different RL algorithms. |


# cs.CV 

| Item |Content|
| --- |---|
|idx| 2409.17146v1 |
|title| Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models |
|authors| Matt DeitkeChristopher ClarkSangho LeeRohun TripathiYue YangJae Sung ParkMohammadreza SalehiNiklas MuennighoffKyle LoLuca SoldainiJiasen LuTaira AndersonErin BransomKiana EhsaniHuong NgoYenSung ChenAjay PatelMark YatskarChris Callison-BurchAndrew HeadRose HendrixFavyen BastaniEli VanderBiltNathan LambertYvonne ChouArnavi ChhedaJenna SparksSam SkjonsbergMichael SchmitzAaron SarnatByron BischoffPete WalshChris NewellPiper WoltersTanmay GuptaKuo-Hao ZengJon BorchardtDirk GroeneveldJen DumasCrystal NamSophie LebrechtCaitlin WittlifCarissa SchoenickOscar MichelRanjay KrishnaLuca WeihsNoah A. SmithHannaneh HajishirziRoss GirshickAli FarhadiAniruddha Kembhavi
|links| http://arxiv.org/abs/2409.17146v1 |
|updated| 2024-09-25 17:59:51 UTC |
|summary| Todays most advanced multimodal models remain proprietary. The strongestopen-weight models rely heavily on synthetic data from proprietary VLMs toachieve good performance effectively distilling these closed models into openones. As a result the community is still missing foundational knowledge abouthow to build performant VLMs from scratch. We present Molmo a new family ofVLMs that are state-of-the-art in their class of openness. Our key innovationis a novel highly detailed image caption dataset collected entirely from humanannotators using speech-based descriptions. To enable a wide array of userinteractions we also introduce a diverse dataset mixture for fine-tuning thatincludes in-the-wild QA and innovative 2D pointing data. The success of ourapproach relies on careful choices for the model architecture details awell-tuned training pipeline and most critically the quality of our newlycollected datasets all of which will be released. The best-in-class 72B modelwithin the Molmo family not only outperforms others in the class of open weightand data models but also compares favorably against proprietary systems likeGPT-4o Claude 3.5 and Gemini 1.5 on both academic benchmarks and humanevaluation.  We will be releasing all of our model weights captioning and fine-tuningdata and source code in the near future. Select model weights inference codeand demo are available at https://molmo.allenai.org. |


| Item |Content|
| --- |---|
|idx| 2409.17145v1 |
|title| DreamWaltz-G: Expressive 3D Gaussian Avatars from Skeleton-Guided 2D Diffusion |
|authors| Yukun HuangJianan WangAiling ZengZheng-Jun ZhaLei ZhangXihui Liu
|links| http://arxiv.org/abs/2409.17145v1 |
|updated| 2024-09-25 17:59:45 UTC |
|summary| Leveraging pretrained 2D diffusion models and score distillation samplingSDS recent methods have shown promising results for text-to-3D avatargeneration. However generating high-quality 3D avatars capable of expressiveanimation remains challenging. In this work we present DreamWaltz-G a novellearning framework for animatable 3D avatar generation from text. The core ofthis framework lies in Skeleton-guided Score Distillation and Hybrid 3DGaussian Avatar representation. Specifically the proposed skeleton-guidedscore distillation integrates skeleton controls from 3D human templates into 2Ddiffusion models enhancing the consistency of SDS supervision in terms of viewand human pose. This facilitates the generation of high-quality avatarsmitigating issues such as multiple faces extra limbs and blurring. Theproposed hybrid 3D Gaussian avatar representation builds on the efficient 3DGaussians combining neural implicit fields and parameterized 3D meshes toenable real-time rendering stable SDS optimization and expressive animation.Extensive experiments demonstrate that DreamWaltz-G is highly effective ingenerating and animating 3D avatars outperforming existing methods in bothvisual quality and animation expressiveness. Our framework further supportsdiverse applications including human video reenactment and multi-subject scenecomposition. |


| Item |Content|
| --- |---|
|idx| 2409.17143v1 |
|title| Attention Prompting on Image for Large Vision-Language Models |
|authors| Runpeng YuWeihao YuXinchao Wang
|links| http://arxiv.org/abs/2409.17143v1 |
|updated| 2024-09-25 17:59:13 UTC |
|summary| Compared with Large Language Models LLMs Large Vision-Language ModelsLVLMs can also accept images as input thus showcasing more interestingemergent capabilities and demonstrating impressive performance on variousvision-language tasks. Motivated by text prompting in LLMs visual promptinghas been explored to enhance LVLMs capabilities of perceiving visualinformation. However previous visual prompting techniques solely processvisual inputs without considering text queries limiting the models ability tofollow text instructions to complete tasks. To fill this gap in this work wepropose a new prompting technique named Attention Prompting on Image whichjust simply overlays a text-query-guided attention heatmap on the originalinput image and effectively enhances LVLM on various tasks. Specifically wegenerate an attention heatmap for the input image dependent on the text querywith an auxiliary model like CLIP. Then the heatmap simply multiplies the pixelvalues of the original image to obtain the actual input image for the LVLM.Extensive experiments on various vison-language benchmarks verify theeffectiveness of our technique. For example Attention Prompting on Imageimproves LLaVA-1.5 by 3.8 and 2.9 on MM-Vet and LLaVA-Wild benchmarksrespectively. |


| Item |Content|
| --- |---|
|idx| 2409.17137v1 |
|title| PACE: marrying generalization in PArameter-efficient fine-tuning with Consistency rEgularization |
|authors| Yao NiShan ZhangPiotr Koniusz
|links| http://arxiv.org/abs/2409.17137v1 |
|updated| 2024-09-25 17:56:00 UTC |
|summary| Parameter-Efficient Fine-Tuning PEFT effectively adapts pre-trained visiontransformers to downstream tasks. However the optimization for tasksperformance often comes at the cost of generalizability in fine-tuned models.To address this issue we theoretically connect smaller weight gradient normsduring training and larger datasets to the improved model generalization.Motivated by this connection we propose reducing gradient norms for enhancedgeneralization and aligning fine-tuned model with the pre-trained counterpartto retain knowledge from large-scale pre-training data. Yet naive alignmentdoes not guarantee gradient reduction and can potentially cause gradientexplosion complicating efforts to manage gradients. To address such issues wepropose PACE marrying generalization of PArameter-efficient fine-tuning withConsistency rEgularization. We perturb features learned from the adapter withthe multiplicative noise and ensure the fine-tuned model remains consistent forsame sample under different perturbations. Theoretical analysis shows that PACEnot only implicitly regularizes gradients for enhanced generalization but alsoimplicitly aligns the fine-tuned and pre-trained models to retain knowledge.Experimental evidence supports our theories. PACE outperforms existing PEFTmethods in four visual adaptation tasks: VTAB-1k FGVC few-shot learning anddomain adaptation. Code will be available athttps://github.com/MaxwellYaoNi/PACE |


| Item |Content|
| --- |---|
|idx| 2409.17134v1 |
|title| Streaming Neural Images |
|authors| Marcos V. CondeAndy BigosRadu Timofte
|links| http://arxiv.org/abs/2409.17134v1 |
|updated| 2024-09-25 17:51:20 UTC |
|summary| Implicit Neural Representations INRs are a novel paradigm for signalrepresentation that have attracted considerable interest for image compression.INRs offer unprecedented advantages in signal resolution and memory efficiencyenabling new possibilities for compression techniques. However the existinglimitations of INRs for image compression have not been sufficiently addressedin the literature. In this work we explore the critical yet overlookedlimiting factors of INRs such as computational cost unstable performance androbustness. Through extensive experiments and empirical analysis we provide adeeper and more nuanced understanding of implicit neural image compressionmethods such as Fourier Feature Networks and Siren. Our work also offersvaluable insights for future research in this area. |


# stat.ML 

| Item |Content|
| --- |---|
|idx| 2409.17107v1 |
|title| Non-asymptotic convergence analysis of the stochastic gradient Hamiltonian Monte Carlo algorithm with discontinuous stochastic gradient with applications to training of ReLU neural networks |
|authors| Luxu LiangAriel NeufeldYing Zhang
|links| http://arxiv.org/abs/2409.17107v1 |
|updated| 2024-09-25 17:21:09 UTC |
|summary| In this paper we provide a non-asymptotic analysis of the convergence of thestochastic gradient Hamiltonian Monte Carlo SGHMC algorithm to a targetmeasure in Wasserstein-1 and Wasserstein-2 distance. Crucially compared to theexisting literature on SGHMC we allow its stochastic gradient to bediscontinuous. This allows us to provide explicit upper bounds which can becontrolled to be arbitrarily small for the expected excess risk of non-convexstochastic optimization problems with discontinuous stochastic gradientsincluding among others the training of neural networks with ReLU activationfunction. To illustrate the applicability of our main results we considernumerical experiments on quantile estimation and on several optimizationproblems involving ReLU neural networks relevant in finance and artificialintelligence. |


| Item |Content|
| --- |---|
|idx| 2409.17085v1 |
|title| Parameter-efficient Bayesian Neural Networks for Uncertainty-aware Depth Estimation |
|authors| Richard D. PaulAlessio QuerciaVincent FortuinKatharina N√∂hHanno Scharr
|links| http://arxiv.org/abs/2409.17085v1 |
|updated| 2024-09-25 16:49:25 UTC |
|summary| State-of-the-art computer vision tasks like monocular depth estimationMDE rely heavily on large modern Transformer-based architectures. Howevertheir application in safety-critical domains demands reliable predictiveperformance and uncertainty quantification. While Bayesian neural networksprovide a conceptually simple approach to serve those requirements they sufferfrom the high dimensionality of the parameter space. Parameter-efficientfine-tuning PEFT methods in particular low-rank adaptations LoRA haveemerged as a popular strategy for adapting large-scale models to down-streamtasks by performing parameter inference on lower-dimensional subspaces. In thiswork we investigate the suitability of PEFT methods for subspace Bayesianinference in large-scale Transformer-based vision models. We show that indeedcombining BitFit DiffFit LoRA and CoLoRA a novel LoRA-inspired PEFT methodwith Bayesian inference enables more robust and reliable predictive performancein MDE. |


| Item |Content|
| --- |---|
|idx| 2409.16963v1 |
|title| Dimension reduction and the gradient flow of relative entropy |
|authors| Ben Weinkove
|links| http://arxiv.org/abs/2409.16963v1 |
|updated| 2024-09-25 14:23:04 UTC |
|summary| Dimension reduction widely used in science maps high-dimensional data intolow-dimensional space. We investigate a basic mathematical model underlying thetechniques of stochastic neighborhood embedding SNE and its popular variantt-SNE. Distances between points in high dimensions are used to define aprobability distribution on pairs of points measuring how similar the pointsare. The aim is to map these points to low dimensions in an optimal way so thatsimilar points are closer together. This is carried out by minimizing therelative entropy between two probability distributions.  We consider the gradient flow of the relative entropy and analyze itslong-time behavior. This is a self-contained mathematical problem about thebehavior of a system of nonlinear ordinary differential equations. We findoptimal bounds for the diameter of the evolving sets as time tends to infinity.In particular the diameter may blow up for the t-SNE version but remainsbounded for SNE. |


| Item |Content|
| --- |---|
|idx| 2409.16859v1 |
|title| Revisiting Extragradient-Type Methods -- Part 1: Generalizations and Sublinear Convergence Rates |
|authors| Quoc Tran-DinhNghia Nguyen-Trung
|links| http://arxiv.org/abs/2409.16859v1 |
|updated| 2024-09-25 12:14:05 UTC |
|summary| This paper presents a comprehensive analysis of the well-known extragradientEG method for solving both equations and inclusions. First we unify andgeneralize EG for nonlinear equations to a wider class of algorithmsencompassing various existing schemes and potentially new variants. Next weanalyze both sublinear best-iterate and last-iterate convergence ratesfor the entire class of algorithms and derive new convergence results for twowell-known instances. Second we extend our EG framework above to monotoneinclusions introducing a new class of algorithms and its correspondingconvergence results. Third we also unify and generalize Tsengsforward-backward-forward splitting FBFS method to a broader class ofalgorithms to solve nonlinear inclusions when a weak-Minty solution existsand establish its best-iterate convergence rate. Fourth to complete ourpicture we also investigate sublinear rates of two other common variants of EGusing our EG analysis framework developed here: the reflected forward-backwardsplitting and the golden ratio methods. Finally we conduct an extensivenumerical experiment to validate our theoretical findings. Our resultsdemonstrate that several new variants of our proposed algorithms outperformexisting schemes in the majority of examples. |


| Item |Content|
| --- |---|
|idx| 2409.16829v1 |
|title| Conditional Testing based on Localized Conformal p-values |
|authors| Xiaoyang WuLin LuZhaojun WangChangliang Zou
|links| http://arxiv.org/abs/2409.16829v1 |
|updated| 2024-09-25 11:30:14 UTC |
|summary| In this paper we address conditional testing problems through the conformalinference framework. We define the localized conformal p-values by invertingprediction intervals and prove their theoretical properties. These definedp-values are then applied to several conditional testing problems to illustratetheir practicality. Firstly we propose a conditional outlier detectionprocedure to test for outliers in the conditional distribution withfinite-sample false discovery rate FDR control. We also introduce a novelconditional label screening problem with the goal of screening multivariateresponse variables and propose a screening procedure to control the family-wiseerror rate FWER. Finally we consider the two-sample conditional distributiontest and define a weighted U-statistic through the aggregation of localizedp-values. Numerical simulations and real-data examples validate the superiorperformance of our proposed strategies. |


# cs.HC 

| Item |Content|
| --- |---|
|idx| 2409.17088v1 |
|title| Textoshop: Interactions Inspired by Drawing Software to Facilitate Text Editing |
|authors| Damien MassonYoung-Ho KimFanny Chevalier
|links| http://arxiv.org/abs/2409.17088v1 |
|updated| 2024-09-25 16:51:49 UTC |
|summary| We explore how interactions inspired by drawing software can help edit text.Making an analogy between visual and text editing we consider words as pixelssentences as regions and tones as colours. For instance direct manipulationsmove shorten expand and reorder text tools change number tense andgrammar colours map to tones explored along three dimensions in a tone pickerand layers help organize and version text. This analogy also leads to newworkflows such as boolean operations on text fragments to construct moreelaborated text. A study shows participants were more successful at editingtext and preferred using the proposed interface over existing solutions.Broadly our work highlights the potential of interaction analogies to rethinkexisting workflows while capitalizing on familiar features. |


| Item |Content|
| --- |---|
|idx| 2409.16978v1 |
|title| Towards User-Focused Research in Training Data Attribution for Human-Centered Explainable AI |
|authors| Elisa NguyenJohannes BertramEvgenii KortukovJean Y. SongSeong Joon Oh
|links| http://arxiv.org/abs/2409.16978v1 |
|updated| 2024-09-25 14:40:26 UTC |
|summary| While Explainable AI XAI aims to make AI understandable and useful tohumans it has been criticised for relying too much on formalism andsolutionism focusing more on mathematical soundness than user needs. Wepropose an alternative to this bottom-up approach inspired by design thinking:the XAI research community should adopt a top-down user-focused perspective toensure user relevance. We illustrate this with a relatively young subfield ofXAI Training Data Attribution TDA. With the surge in TDA research andgrowing competition the field risks repeating the same patterns ofsolutionism. We conducted a needfinding study with a diverse group of AIpractitioners to identify potential user needs related to TDA. Throughinterviews N10 and a systematic survey N31 we uncovered new TDA tasksthat are currently largely overlooked. We invite the TDA and XAI communities toconsider these novel tasks and improve the user relevance of their researchoutcomes. |


| Item |Content|
| --- |---|
|idx| 2409.16936v1 |
|title| Tactile Perception of Electroadhesion: Effect of DC versus AC Stimulation and Finger Moisture |
|authors| Easa AliAbbasiMuhammad MuzammilOmer SirinPhilippe Lef√®vre√òrjan Gr√∏ttem MartinsenCagatay Basdogan
|links| http://dx.doi.org/10.1109/TOH.2024.3441670 |
|updated| 2024-09-25 13:49:56 UTC |
|summary| Electroadhesion has emerged as a viable technique for displaying tactilefeedback on touch surfaces particularly capacitive touchscreens found insmartphones and tablets. This involves applying a voltage signal to theconductive layer of the touchscreen to generate tactile sensations on thefingerpads of users. In our investigation we explore the tactile perception ofelectroadhesion under DC and AC stimulations. Our tactile perceptionexperiments with 10 participants demonstrate a significantly lower voltagedetection threshold for AC signals compared to their DC counterparts. Thisdiscrepancy is elucidated by the underlying electro-mechanical interactionsbetween the finger and the voltage-induced touchscreen and considering theresponse of mechanoreceptors in the fingerpad to electrostatic forces generatedby electroadhesion. Additionally our study highlights the impact of moistureon electroadhesive tactile perception. Participants with moist fingersexhibited markedly higher threshold levels. Our electrical impedancemeasurements show a substantial reduction in impedance magnitude when sweat ispresent at the finger-touchscreen interface indicating increased conductivity.These findings not only contribute to our understanding of tactile perceptionunder electroadhesion but also shed light on the underlying physics. In thisregard the results of this study extend beyond mobile devices to encompassother applications of this technology including robotics automation spacemissions and textiles. |


| Item |Content|
| --- |---|
|idx| 2409.16923v1 |
|title| AI-assisted Gaze Detection for Proctoring Online Exams |
|authors| Yong-Siang ShihZach ZhaoChenhao NiuBruce IbergJames SharpnackMirza Basim Baig
|links| http://arxiv.org/abs/2409.16923v1 |
|updated| 2024-09-25 13:31:37 UTC |
|summary| For high-stakes online exams it is important to detect potential ruleviolations to ensure the security of the test. In this study we investigatethe task of detecting whether test takers are looking away from the screen assuch behavior could be an indication that the test taker is consulting externalresources. For asynchronous proctoring the exam videos are recorded andreviewed by the proctors. However when the length of the exam is long itcould be tedious for proctors to watch entire exam videos to determine theexact moments when test takers look away. We present an AI-assisted gazedetection system which allows proctors to navigate between different videoframes and discover video frames where the test taker is looking in similardirections. The system enables proctors to work more effectively to identifysuspicious moments in videos. An evaluation framework is proposed to evaluatethe system against human-only and ML-only proctoring and a user study isconducted to gather feedback from proctors aiming to demonstrate theeffectiveness of the system. |


| Item |Content|
| --- |---|
|idx| 2409.16920v1 |
|title| Cross-lingual Speech Emotion Recognition: Humans vs. Self-Supervised Models |
|authors| Zhichen HanTianqi GengHui FengJiahong YuanKorin RichmondYuanchao Li
|links| http://arxiv.org/abs/2409.16920v1 |
|updated| 2024-09-25 13:27:17 UTC |
|summary| Utilizing Self-Supervised Learning SSL models for Speech EmotionRecognition SER has proven effective yet limited research has exploredcross-lingual scenarios. This study presents a comparative analysis betweenhuman performance and SSL models beginning with a layer-wise analysis and anexploration of parameter-efficient fine-tuning strategies in monolingualcross-lingual and transfer learning contexts. We further compare the SERability of models and humans at both utterance- and segment-levels.Additionally we investigate the impact of dialect on cross-lingual SER throughhuman evaluation. Our findings reveal that models with appropriate knowledgetransfer can adapt to the target language and achieve performance comparableto native speakers. We also demonstrate the significant effect of dialect onSER for individuals without prior linguistic and paralinguistic background.Moreover both humans and models exhibit distinct behaviors across differentemotions. These results offer new insights into the cross-lingual SERcapabilities of SSL models underscoring both their similarities to anddifferences from human emotion perception. |


# cs.MA 

| Item |Content|
| --- |---|
|idx| 2409.16764v1 |
|title| Offline and Distributional Reinforcement Learning for Radio Resource Management |
|authors| Eslam EldeebHirley Alves
|links| http://arxiv.org/abs/2409.16764v1 |
|updated| 2024-09-25 09:22:23 UTC |
|summary| Reinforcement learning RL has proved to have a promising role in futureintelligent wireless networks. Online RL has been adopted for radio resourcemanagement RRM taking over traditional schemes. However due to its relianceon online interaction with the environment its role becomes limited inpractical real-world problems where online interaction is not feasible. Inaddition traditional RL stands short in front of the uncertainties and risksin real-world stochastic environments. In this manner we propose an offlineand distributional RL scheme for the RRM problem enabling offline trainingusing a static dataset without any interaction with the environment andconsidering the sources of uncertainties using the distributions of the return.Simulation results demonstrate that the proposed scheme outperformsconventional resource management models. In addition it is the only schemethat surpasses online RL and achieves a 16  gain over online RL. |


| Item |Content|
| --- |---|
|idx| 2409.16173v2 |
|title| Extending Stable and Popular Matching Algorithms from Bipartite to Arbitrary Instances |
|authors| Gergely Cs√°ji
|links| http://arxiv.org/abs/2409.16173v2 |
|updated| 2024-09-25 07:16:36 UTC |
|summary| We consider stable and popular matching problems in arbitrary graphs whichare referred to as stable roommates instances. We extend the 3/2-approximationalgorithm for the maximum size weakly stable matching problem to the roommatescase which solves a more than 20 year old open question of Irving and Manloveabout the approximability of maximum size weakly stable matchings in roommatesinstances with ties Irving and Manlove 2002 and has nice applications for theproblem of matching residents to hospitals in the presence of couples. We alsoextend the algorithm that finds a maximum size popular matching in bipartitegraphs in the case of strict preferences and the algorithm to find a popularmatching among maximum weight matchings. While previous attempts to extend theidea of promoting the agents or duplicating the edges from bipartite instancesto arbitrary ones failed these results show that with the help of a simpleobservation we can indeed bridge the gap and extend these algorithms |


| Item |Content|
| --- |---|
|idx| 2409.15831v1 |
|title| Introducing Anisotropic Fields for Enhanced Diversity in Crowd Simulation |
|authors| Yihao LiJunyu LiuXiaoyu GuanHanming HouTianyu Huang
|links| http://arxiv.org/abs/2409.15831v1 |
|updated| 2024-09-24 07:54:11 UTC |
|summary| Large crowds exhibit intricate behaviors and significant emergent propertiesyet existing crowd simulation systems often lack behavioral diversityresulting in homogeneous simulation outcomes. To address this limitation wepropose incorporating anisotropic fields AFs as a fundamental structure fordepicting the uncertainty in crowd movement. By leveraging AFs our method canrapidly generate crowd simulations with intricate behavioral patterns thatbetter reflect the inherent complexity of real crowds. The AFs are generatedeither through intuitive sketching or extracted from real crowd videosenabling flexible and efficient crowd simulation systems. We demonstrate theeffectiveness of our approach through several representative scenariosshowcasing a significant improvement in behavioral diversity compared toclassical methods. Our findings indicate that by incorporating AFs crowdsimulation systems can achieve a much higher similarity to real-world crowdsystems. Our code is publicly available athttps://github.com/tomblack2014/AF_Generation. |


| Item |Content|
| --- |---|
|idx| 2409.15105v1 |
|title| SPformer: A Transformer Based DRL Decision Making Method for Connected Automated Vehicles |
|authors| Ye HanLijun ZhangDejian MengXingyu HuYixia Lu
|links| http://arxiv.org/abs/2409.15105v1 |
|updated| 2024-09-23 15:16:35 UTC |
|summary| In mixed autonomy traffic environment every decision made by anautonomous-driving car may have a great impact on the transportation system.Because of the complex interaction between vehicles it is challenging to makedecisions that can ensure both high traffic efficiency and safety now andfuther. Connected automated vehicles CAVs have great potential to improve thequality of decision-making in this continuous highly dynamic and interactiveenvironment because of their stronger sensing and communicating ability. Formulti-vehicle collaborative decision-making algorithms based on deepreinforcement learning DRL we need to represent the interactions betweenvehicles to obtain interactive features. The representation in this aspectdirectly affects the learning efficiency and the quality of the learned policy.To this end we propose a CAV decision-making architecture based on transformerand reinforcement learning algorithms. A learnable policy token is used as thelearning medium of the multi-vehicle joint policy the states of all vehiclesin the area of interest can be adaptively noticed in order to extractinteractive features among agents. We also design an intuitive physicalpositional encodings the redundant location information of which optimizes theperformance of the network. Simulations show that our model can make good useof all the state information of vehicles in traffic scenario so as to obtainhigh-quality driving decisions that meet efficiency and safety objectives. Thecomparison shows that our method significantly improves existing DRL-basedmulti-vehicle cooperative decision-making algorithms. |


| Item |Content|
| --- |---|
|idx| 2409.15005v1 |
|title| Method of Equal Shares with Bounded Overspending |
|authors| Georgios PapasotiropoulosSeyedeh Zeinab PishbinOskar SkibskiPiotr SkowronTomasz WƒÖs
|links| http://arxiv.org/abs/2409.15005v1 |
|updated| 2024-09-23 13:30:25 UTC |
|summary| In participatory budgeting PB voters decide through voting which subset ofprojects to fund within a given budget. Proportionality in the context of PB iscrucial to ensure equal treatment of all groups of voters. However pureproportional rules can sometimes lead to suboptimal outcomes. We introduce theMethod of Equal Shares with Bounded Overspending BOS Equal Shares a robustvariant of Equal Shares that balances proportionality and efficiency. BOS EqualShares addresses inefficiencies inherent in strict proportionality guaranteesyet still provides good proportionality similar to the original Method of EqualShares. In the course of the analysis we also discuss a fractional variant ofthe method which allows for partial funding of projects. |


