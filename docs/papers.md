# cs.CL 

| Item |Content|
| --- |---|
|idx| 2408.08872v1 |
|title| xGen-MM (BLIP-3): A Family of Open Large Multimodal Models |
|authors| Le XueManli ShuAnas AwadallaJun WangAn YanSenthil PurushwalkamHonglu ZhouViraj PrabhuYutong DaiMichael S RyooShrikant KendreJieyu ZhangCan QinShu ZhangChia-Chih ChenNing YuJuntao TanTulika Manoj AwalgaonkarShelby HeineckeHuan WangYejin ChoiLudwig SchmidtZeyuan ChenSilvio SavareseJuan Carlos NieblesCaiming XiongRan Xu
|links| http://arxiv.org/abs/2408.08872v1 |
|updated| 2024-08-16 17:57:01 UTC |
|summary| This report introduces xGen-MM also known as BLIP-3 a framework fordeveloping Large Multimodal Models LMMs. The framework comprises meticulouslycurated datasets a training recipe model architectures and a resulting suiteof LMMs. xGen-MM short for xGen-MultiModal expands the Salesforce xGeninitiative on foundation AI models. Our models undergo rigorous evaluationacross a range of tasks including both single and multi-image benchmarks. Ourpre-trained base model exhibits strong in-context learning capabilities and theinstruction-tuned model demonstrates competitive performance among open-sourceLMMs with similar model sizes. In addition we introduce a safety-tuned modelwith DPO aiming to mitigate harmful behaviors such as hallucinations andimprove safety. We open-source our models curated large-scale datasets andour fine-tuning codebase to facilitate further advancements in LMM research.Associated resources will be available on our project page above. |


| Item |Content|
| --- |---|
|idx| 2408.08869v1 |
|title| PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars |
|authors| Sumanth Prabhu
|links| http://arxiv.org/abs/2408.08869v1 |
|updated| 2024-08-16 17:54:09 UTC |
|summary| Self-ensembling techniques with diverse reasoning paths such asSelf-Consistency have demonstrated remarkable gains in accuracy for LargeLanguage Models LLMs. However such techniques depend on the availability ofan accurate answer extraction process to aggregate across multiple outputs.Moreover they acquire higher inference cost in comparison to Greedy Decodingdue to generation of relatively higher number of output tokens. Research hasshown that the free form text outputs from Self-Consistency can be aggregatedreliably using LLMs to produce the final output. Additionally recentadvancements in LLM inference have demonstrated that usage of diverse exemplarsin prompts have the ability to induce diversity in the LLM outputs. Such proventechniques can be easily extended to self-ensembling based approaches toachieve enhanced results in text generation. In this paper we introduce PEDALPrompts based on Exemplar Diversity Aggregated using LLMs a hybridself-ensembling approach that combines the strengths of diverse exemplar basedprompts and LLM based aggregation to achieve improvement in overallperformance. On the publicly available SVAMP and ARC datasets our experimentsreveal that PEDAL can achieve better accuracy than Greedy Decoding basedstrategies with lower inference cost compared to Self Consistency basedapproaches. |


| Item |Content|
| --- |---|
|idx| 2408.08848v1 |
|title| PsychoLex: Unveiling the Psychological Mind of Large Language Models |
|authors| Mohammad Amin AbbasiFarnaz Sadat MirnezamiHassan Naderi
|links| http://arxiv.org/abs/2408.08848v1 |
|updated| 2024-08-16 17:19:23 UTC |
|summary| This paper explores the intersection of psychology and artificialintelligence through the development and evaluation of specialized LargeLanguage Models LLMs. We introduce PsychoLex a suite of resources designedto enhance LLMs proficiency in psychological tasks in both Persian andEnglish. Key contributions include the PsychoLexQA dataset for instructionalcontent and the PsychoLexEval dataset for rigorous evaluation of LLMs incomplex psychological scenarios. Additionally we present the PsychoLexLLaMAmodel optimized specifically for psychological applications demonstratingsuperior performance compared to general-purpose models. The findingsunderscore the potential of tailored LLMs for advancing psychological researchand applications while also highlighting areas for further refinement. Thisresearch offers a foundational step towards integrating LLMs into specializedpsychological domains with implications for future advancements in AI-drivenpsychological practice. |


| Item |Content|
| --- |---|
|idx| 2408.08841v1 |
|title| FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats |
|authors| Xuanliang ZhangDingzirui WangLongxu DouBaoxin WangDayong WuQingfu ZhuWanxiang Che
|links| http://arxiv.org/abs/2408.08841v1 |
|updated| 2024-08-16 17:00:11 UTC |
|summary| The table reasoning task aims to answer the question according to the giventable. Currently using Large Language Models LLMs is the predominant methodfor table reasoning. Most existing methods employ a fixed tabular format torepresent the table which could limit the performance. Given that eachinstance requires different capabilities and models possess varying abilitieswe assert that different instances and models suit different tabular formats.We prove the aforementioned claim through quantitative analysis of experimentalresults where different instances and models achieve different performancesusing various tabular formats. Building on this discussion we proposeFLEXTAF-Single and FLEXTAF-Vote to enhance table reasoning performance byemploying flexible tabular formats. Specifically i FLEXTAF-Single trains aclassifier to predict the most suitable tabular format based on the instanceand the LLM. ii FLEXTAF-Vote integrates the results across different formats.Our experiments on WikiTableQuestions and TabFact reveal significantimprovements with average gains of 2.3 and 4.8 compared to the bestperformance achieved using a fixed tabular format with greedy decoding andself-consistency decoding thereby validating the effectiveness of our methods. |


| Item |Content|
| --- |---|
|idx| 2408.08805v1 |
|title| CIKMar: A Dual-Encoder Approach to Prompt-Based Reranking in Educational Dialogue Systems |
|authors| Joanito Agili LopoMarina Indah PrasastiAlma Permatasari
|links| http://arxiv.org/abs/2408.08805v1 |
|updated| 2024-08-16 15:29:54 UTC |
|summary| In this study we introduce CIKMar an efficient approach to educationaldialogue systems powered by the Gemma Language model. By leveraging aDual-Encoder ranking system that incorporates both BERT and SBERT model wehave designed CIKMar to deliver highly relevant and accurate responses evenwith the constraints of a smaller language model size. Our evaluation revealsthat CIKMar achieves a robust recall and F1-score of 0.70 using BERTScoremetrics. However we have identified a significant challenge: the Dual-Encodertends to prioritize theoretical responses over practical ones. These findingsunderscore the potential of compact and efficient models like Gemma indemocratizing access to advanced educational AI systems ensuring effective andcontextually appropriate responses. |


# cs.AI 

| Item |Content|
| --- |---|
|idx| 2408.08872v1 |
|title| xGen-MM (BLIP-3): A Family of Open Large Multimodal Models |
|authors| Le XueManli ShuAnas AwadallaJun WangAn YanSenthil PurushwalkamHonglu ZhouViraj PrabhuYutong DaiMichael S RyooShrikant KendreJieyu ZhangCan QinShu ZhangChia-Chih ChenNing YuJuntao TanTulika Manoj AwalgaonkarShelby HeineckeHuan WangYejin ChoiLudwig SchmidtZeyuan ChenSilvio SavareseJuan Carlos NieblesCaiming XiongRan Xu
|links| http://arxiv.org/abs/2408.08872v1 |
|updated| 2024-08-16 17:57:01 UTC |
|summary| This report introduces xGen-MM also known as BLIP-3 a framework fordeveloping Large Multimodal Models LMMs. The framework comprises meticulouslycurated datasets a training recipe model architectures and a resulting suiteof LMMs. xGen-MM short for xGen-MultiModal expands the Salesforce xGeninitiative on foundation AI models. Our models undergo rigorous evaluationacross a range of tasks including both single and multi-image benchmarks. Ourpre-trained base model exhibits strong in-context learning capabilities and theinstruction-tuned model demonstrates competitive performance among open-sourceLMMs with similar model sizes. In addition we introduce a safety-tuned modelwith DPO aiming to mitigate harmful behaviors such as hallucinations andimprove safety. We open-source our models curated large-scale datasets andour fine-tuning codebase to facilitate further advancements in LMM research.Associated resources will be available on our project page above. |


| Item |Content|
| --- |---|
|idx| 2408.08852v1 |
|title| GeoTransformer: Enhancing Urban Forecasting with Geospatial Attention Mechanisms |
|authors| Yuhao JiaZile WuShengao YiYifei Sun
|links| http://arxiv.org/abs/2408.08852v1 |
|updated| 2024-08-16 17:26:42 UTC |
|summary| Recent advancements have focused on encoding urban spatial information intohigh-dimensional spaces with notable efforts dedicated to integratingsociodemographic data and satellite imagery. These efforts have establishedfoundational models in this field. However the effective utilization of thesespatial representations for urban forecasting applications remainsunder-explored. To address this gap we introduce GeoTransformer a novelstructure that synergizes the Transformer architecture with geospatialstatistics prior. GeoTransformer employs an innovative geospatial attentionmechanism to incorporate extensive urban information and spatial dependenciesinto a unified predictive model. Specifically we compute geospatial weightedattention scores between the target region and surrounding regions and leveragethe integrated urban information for predictions. Extensive experiments on GDPand ride-share demand prediction tasks demonstrate that GeoTransformersignificantly outperforms existing baseline models showcasing its potential toenhance urban forecasting tasks. |


| Item |Content|
| --- |---|
|idx| 2408.08823v1 |
|title| Optimal Symmetries in Binary Classification |
|authors| Vishal S. NgairangbamMichael Spannowsky
|links| http://arxiv.org/abs/2408.08823v1 |
|updated| 2024-08-16 16:15:18 UTC |
|summary| We explore the role of group symmetries in binary classification taskspresenting a novel framework that leverages the principles of Neyman-Pearsonoptimality. Contrary to the common intuition that larger symmetry groups leadto improved classification performance our findings show that selecting theappropriate group symmetries is crucial for optimising generalisation andsample efficiency. We develop a theoretical foundation for designing groupequivariant neural networks that align the choice of symmetries with theunderlying probability distributions of the data. Our approach provides aunified methodology for improving classification accuracy across a broad rangeof applications by carefully tailoring the symmetry group to the specificcharacteristics of the problem. Theoretical analysis and experimental resultsdemonstrate that optimal classification performance is not always associatedwith the largest equivariant groups possible in the domain even when thelikelihood ratio is invariant under one of its proper subgroups but ratherwith those subgroups themselves. This work offers insights and practicalguidelines for constructing more effective group equivariant architectures indiverse machine-learning contexts. |


| Item |Content|
| --- |---|
|idx| 2408.08821v1 |
|title| EasyRec: Simple yet Effective Language Models for Recommendation |
|authors| Xubin RenChao Huang
|links| http://arxiv.org/abs/2408.08821v1 |
|updated| 2024-08-16 16:09:59 UTC |
|summary| Deep neural networks have become a powerful technique for learningrepresentations from user-item interaction data in collaborative filtering CFfor recommender systems. However many existing methods heavily rely on uniqueuser and item IDs which limits their ability to perform well in practicalzero-shot learning scenarios where sufficient training data may be unavailable.Inspired by the success of language models LMs and their stronggeneralization capabilities a crucial question arises: How can we harness thepotential of language models to empower recommender systems and elevate itsgeneralization capabilities to new heights In this study we propose EasyRec -an effective and easy-to-use approach that seamlessly integrates text-basedsemantic understanding with collaborative signals. EasyRec employs atext-behavior alignment framework which combines contrastive learning withcollaborative language model tuning to ensure a strong alignment between thetext-enhanced semantic space and the collaborative behavior information.Extensive empirical evaluations across diverse real-world datasets demonstratethe superior performance of EasyRec compared to state-of-the-art alternativemodels particularly in the challenging text-based zero-shot recommendationscenarios. Furthermore the study highlights the potential of seamlesslyintegrating EasyRec as a plug-and-play component into text-enhancedcollaborative filtering frameworks thereby empowering existing recommendersystems to elevate their recommendation performance and adapt to the evolvinguser preferences in dynamic environments. For better result reproducibility ofour EasyRec framework the model implementation details source code anddatasets are available at the link: https://github.com/HKUDS/EasyRec. |


| Item |Content|
| --- |---|
|idx| 2408.08808v1 |
|title| Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge |
|authors| Ravi RajuSwayambhoo JainBo LiJonathan LiUrmish Thakkar
|links| http://arxiv.org/abs/2408.08808v1 |
|updated| 2024-08-16 15:41:43 UTC |
|summary| Large Language Models LLMs have revolutionized the landscape of machinelearning yet current benchmarks often fall short in capturing the diversebehavior of these models in real-world applications. A benchmarks usefulnessis determined by its ability to clearly differentiate between models of varyingcapabilities separability and closely align with human preferences. Existingframeworks like Alpaca-Eval 2.0 LCcitedubois2024lengthcontrolledalpacaevalsimpleway and Arena-Hard v0.1citeli2024crowdsourced are limited by their focus on general-purpose queriesand lack of diversity across domains such as law medicine and multilingualcontexts. In this paper we address these limitations by introducing a noveldata pipeline that curates diverse domain-specific evaluation sets tailoredfor LLM-as-a-Judge frameworks. Our approach leverages a combination of manualcuration semi-supervised learning to generate clusters and stratifiedsampling to ensure balanced representation across a wide range of domains andlanguages. The resulting evaluation set which includes 1573 samples across 14categories demonstrates high separability 84 across ten top-ranked modelsand agreement 84 with Chatbot Arena and 0.915 Spearman correlation. Theagreement values are 9 better than Arena Hard and 20 better than AlpacaEval2.0 LC while the Spearman coefficient is 0.7 more than the next bestbenchmark showcasing a significant improvement in the usefulness of thebenchmark. We further provide an open-source evaluation tool that enablesfine-grained analysis of model performance across user-defined categoriesoffering valuable insights for practitioners. This work contributes to theongoing effort to enhance the transparency diversity and effectiveness of LLMevaluation methodologies. |


# cs.LG 

| Item |Content|
| --- |---|
|idx| 2408.08873v1 |
|title| Accelerating Giant Impact Simulations with Machine Learning |
|authors| Caleb LammersMiles CranmerSam HaddenShirley HoNorman MurrayDaniel Tamayo
|links| http://arxiv.org/abs/2408.08873v1 |
|updated| 2024-08-16 17:59:46 UTC |
|summary| Constraining planet formation models based on the observed exoplanetpopulation requires generating large samples of synthetic planetary systemswhich can be computationally prohibitive. A significant bottleneck issimulating the giant impact phase during which planetary embryos evolvegravitationally and combine to form planets which may themselves experiencelater collisions. To accelerate giant impact simulations we present a machinelearning ML approach to predicting collisional outcomes in multiplanetsystems. Trained on more than 500000 N-body simulations of three-planetsystems we develop an ML model that can accurately predict which two planetswill experience a collision along with the state of the post-collisionplanets from a short integration of the systems initial conditions. Our modelgreatly improves on non-ML baselines that rely on metrics from dynamics theorywhich struggle to accurately predict which pair of planets will experience acollision. By combining with a model for predicting long-term stability wecreate an efficient ML-based giant impact emulator which can predict theoutcomes of giant impact simulations with a speedup of up to four orders ofmagnitude. We expect our model to enable analyses that would not otherwise becomputationally feasible. As such we release our full training code alongwith an easy-to-use API for our collision outcome model and giant impactemulator. |


| Item |Content|
| --- |---|
|idx| 2408.08869v1 |
|title| PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars |
|authors| Sumanth Prabhu
|links| http://arxiv.org/abs/2408.08869v1 |
|updated| 2024-08-16 17:54:09 UTC |
|summary| Self-ensembling techniques with diverse reasoning paths such asSelf-Consistency have demonstrated remarkable gains in accuracy for LargeLanguage Models LLMs. However such techniques depend on the availability ofan accurate answer extraction process to aggregate across multiple outputs.Moreover they acquire higher inference cost in comparison to Greedy Decodingdue to generation of relatively higher number of output tokens. Research hasshown that the free form text outputs from Self-Consistency can be aggregatedreliably using LLMs to produce the final output. Additionally recentadvancements in LLM inference have demonstrated that usage of diverse exemplarsin prompts have the ability to induce diversity in the LLM outputs. Such proventechniques can be easily extended to self-ensembling based approaches toachieve enhanced results in text generation. In this paper we introduce PEDALPrompts based on Exemplar Diversity Aggregated using LLMs a hybridself-ensembling approach that combines the strengths of diverse exemplar basedprompts and LLM based aggregation to achieve improvement in overallperformance. On the publicly available SVAMP and ARC datasets our experimentsreveal that PEDAL can achieve better accuracy than Greedy Decoding basedstrategies with lower inference cost compared to Self Consistency basedapproaches. |


| Item |Content|
| --- |---|
|idx| 2408.08868v1 |
|title| A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs |
|authors| H. Brendan McMahanZheng XuYanxiang Zhang
|links| http://arxiv.org/abs/2408.08868v1 |
|updated| 2024-08-16 17:52:22 UTC |
|summary| The state-of-the-art for training on-device language models for mobilekeyboard applications combines federated learning FL with differentialprivacy DP via the DP-Follow-the-Regularized-Leader DP-FTRL algorithm. Twovariants of DP-FTRL are used in practice tree aggregation and matrixfactorization. However tree aggregation suffers from significantly suboptimalprivacy/utility tradeoffs while matrix mechanisms require expensiveoptimization parameterized by hard-to-estimate-in-advance constants and highruntime memory costs.This paper extends the recently introduced Buffered LinearToeplitz BLT mechanism to multi-participation scenarios. Our BLT-DP-FTRLmaintains the ease-of-use advantages of tree aggregation while essentiallymatching matrix factorization in terms of utility and privacy. We evaluateBLT-DP-FTRL on the StackOverflow dataset serving as a re-producible simulationbenchmark and across four on-device language model tasks in a production FLsystem. Our empirical results highlight the advantages of the BLT mechanism andelevate the practicality and effectiveness of DP in real-world scenarios. |


| Item |Content|
| --- |---|
|idx| 2408.08862v1 |
|title| Visual Agents as Fast and Slow Thinkers |
|authors| Guangyan SunMingyu JinZhenting WangCheng-Long WangSiqi MaQifan WangYing Nian WuYongfeng ZhangDongfang Liu
|links| http://arxiv.org/abs/2408.08862v1 |
|updated| 2024-08-16 17:44:02 UTC |
|summary| Achieving human-level intelligence requires refining cognitive distinctionsbetween System 1 and System 2 thinking. While contemporary AI driven by largelanguage models demonstrates human-like traits it falls short of genuinecognition. Transitioning from structured benchmarks to real-world scenariospresents challenges for visual agents often leading to inaccurate and overlyconfident responses. To address the challenge we introduce FaST whichincorporates the Fast and Slow Thinking mechanism into visual agents. FaSTemploys a switch adapter to dynamically select between System 1/2 modestailoring the problem-solving approach to different task complexity. It tacklesuncertain and unseen objects by adjusting model confidence and integrating newcontextual data. With this novel design we advocate a flexible systemhierarchical reasoning capabilities and a transparent decision-makingpipeline all of which contribute to its ability to emulate human-likecognitive processes in visual intelligence. Empirical results demonstrate thatFaST outperforms various well-known baselines achieving 80.8 accuracy overVQAv2 for visual question answering and 48.7 GIoU score over ReasonSeg forreasoning segmentation demonstrate FaSTs superior performance. Extensivetesting validates the efficacy and robustness of FaSTs core componentsshowcasing its potential to advance the development of cognitive visual agentsin AI systems. |


| Item |Content|
| --- |---|
|idx| 2408.08859v1 |
|title| Stochastic Bandits Robust to Adversarial Attacks |
|authors| Xuchuang WangJinhang ZuoXutong LiuJohn C. S. LuiMohammad Hajiesmaili
|links| http://arxiv.org/abs/2408.08859v1 |
|updated| 2024-08-16 17:41:35 UTC |
|summary| This paper investigates stochastic multi-armed bandit algorithms that arerobust to adversarial attacks where an attacker can first observe thelearners action and then alter their reward observation. We study two casesof this model with or without the knowledge of an attack budget C definedas an upper bound of the summation of the difference between the actual andaltered rewards. For both cases we devise two types of algorithms with regretbounds having additive or multiplicative C dependence terms. For the knownattack budget case we prove our algorithms achieve the regret bound ofOK/Deltalog T  KC and tildeOsqrtKTC for the additive andmultiplicative C terms respectively where K is the number of arms T isthe time horizon Delta is the gap between the expected rewards of theoptimal arm and the second-best arm and tildeO hides the logarithmicfactors. For the unknown case we prove our algorithms achieve the regret boundof tildeOsqrtKT  KC2 and tildeOKCsqrtT for the additiveand multiplicative C terms respectively. In addition to these upper boundresults we provide several lower bounds showing the tightness of our boundsand the optimality of our algorithms. These results delineate an intrinsicseparation between the bandits with attacks and corruption models Lykouris etal. 2018. |


# cs.CV 

| Item |Content|
| --- |---|
|idx| 2408.08872v1 |
|title| xGen-MM (BLIP-3): A Family of Open Large Multimodal Models |
|authors| Le XueManli ShuAnas AwadallaJun WangAn YanSenthil PurushwalkamHonglu ZhouViraj PrabhuYutong DaiMichael S RyooShrikant KendreJieyu ZhangCan QinShu ZhangChia-Chih ChenNing YuJuntao TanTulika Manoj AwalgaonkarShelby HeineckeHuan WangYejin ChoiLudwig SchmidtZeyuan ChenSilvio SavareseJuan Carlos NieblesCaiming XiongRan Xu
|links| http://arxiv.org/abs/2408.08872v1 |
|updated| 2024-08-16 17:57:01 UTC |
|summary| This report introduces xGen-MM also known as BLIP-3 a framework fordeveloping Large Multimodal Models LMMs. The framework comprises meticulouslycurated datasets a training recipe model architectures and a resulting suiteof LMMs. xGen-MM short for xGen-MultiModal expands the Salesforce xGeninitiative on foundation AI models. Our models undergo rigorous evaluationacross a range of tasks including both single and multi-image benchmarks. Ourpre-trained base model exhibits strong in-context learning capabilities and theinstruction-tuned model demonstrates competitive performance among open-sourceLMMs with similar model sizes. In addition we introduce a safety-tuned modelwith DPO aiming to mitigate harmful behaviors such as hallucinations andimprove safety. We open-source our models curated large-scale datasets andour fine-tuning codebase to facilitate further advancements in LMM research.Associated resources will be available on our project page above. |


| Item |Content|
| --- |---|
|idx| 2408.08870v1 |
|title| SAM2-UNet: Segment Anything 2 Makes Strong Encoder for Natural and Medical Image Segmentation |
|authors| Xinyu XiongZihuang WuShuangyi TanWenxue LiFeilong TangYing ChenSiying LiJie MaGuanbin Li
|links| http://arxiv.org/abs/2408.08870v1 |
|updated| 2024-08-16 17:55:38 UTC |
|summary| Image segmentation plays an important role in vision understanding. Recentlythe emerging vision foundation models continuously achieved superiorperformance on various tasks. Following such success in this paper we provethat the Segment Anything Model 2 SAM2 can be a strong encoder for U-shapedsegmentation models. We propose a simple but effective framework termedSAM2-UNet for versatile image segmentation. Specifically SAM2-UNet adopts theHiera backbone of SAM2 as the encoder while the decoder uses the classicU-shaped design. Additionally adapters are inserted into the encoder to allowparameter-efficient fine-tuning. Preliminary experiments on various downstreamtasks such as camouflaged object detection salient object detection marineanimal segmentation mirror detection and polyp segmentation demonstrate thatour SAM2-UNet can simply beat existing specialized state-of-the-art methodswithout bells and whistles. Project page:urlhttps://github.com/WZH0120/SAM2-UNet. |


| Item |Content|
| --- |---|
|idx| 2408.08855v1 |
|title| DPA: Dual Prototypes Alignment for Unsupervised Adaptation of Vision-Language Models |
|authors| Eman AliSathira SilvaMuhammad Haris Khan
|links| http://arxiv.org/abs/2408.08855v1 |
|updated| 2024-08-16 17:30:27 UTC |
|summary| Vision-language models VLMs e.g. CLIP have shown remarkable potential inzero-shot image classification. However adapting these models to new domainsremains challenging especially in unsupervised settings where labelled data isunavailable. Recent research has proposed pseudo-labelling approaches to adaptCLIP in an unsupervised manner using unlabelled target data. Nonetheless thesemethods struggle due to noisy pseudo-labels resulting from the misalignmentbetween CLIPs visual and textual representations. This study introduces DPAan unsupervised domain adaptation method for VLMs. DPA introduces the conceptof dual prototypes acting as distinct classifiers along with the convexcombination of their outputs thereby leading to accurate pseudo-labelconstruction. Next it ranks pseudo-labels to facilitate robust self-trainingparticularly during early training. Finally it addresses visual-textualmisalignment by aligning textual prototypes with image prototypes to furtherimprove the adaptation performance. Experiments on 13 downstream vision tasksdemonstrate that DPA significantly outperforms zero-shot CLIP and thestate-of-the-art unsupervised adaptation baselines. |


| Item |Content|
| --- |---|
|idx| 2408.08847v1 |
|title| HistoGym: A Reinforcement Learning Environment for Histopathological Image Analysis |
|authors| Zhi-Bo LiuXiaobo PangJizhao WangShuai LiuChen Li
|links| http://arxiv.org/abs/2408.08847v1 |
|updated| 2024-08-16 17:19:07 UTC |
|summary| In pathological research education and clinical practice thedecision-making process based on pathological images is critically important.This significance extends to digital pathology image analysis: its adequacy isdemonstrated by the extensive information contained within tissue structureswhich is essential for accurate cancer classification and grading.Additionally its necessity is highlighted by the inherent requirement forinterpretability in the conclusions generated by algorithms. For humansdetermining tumor type and grade typically involves multi-scale analysis whichpresents a significant challenge for AI algorithms. Traditional patch-basedmethods are inadequate for modeling such complex structures as they fail tocapture the intricate multi-scale information inherent in whole slide images.Consequently there is a pressing need for advanced AI techniques capable ofefficiently and accurately replicating this complex analytical process. Toaddress this issue we introduce HistoGym an open-source reinforcementlearning environment for histopathological image analysis. Following OpenAI GymAPIs HistoGym aims to foster whole slide image diagnosis by mimicking thereal-life processes of doctors. Leveraging the pyramid feature of WSIs and theOpenSlide API HistoGym provides a unified framework for various clinicaltasks including tumor detection and classification. We detail the observationaction and reward specifications tailored for the histopathological imageanalysis domain and provide an open-source Python-based interface for bothclinicians and researchers. To accommodate different clinical demands we offervarious scenarios for different organs and cancers including both WSI-basedand selected region-based scenarios showcasing several noteworthy results. |


| Item |Content|
| --- |---|
|idx| 2408.08827v1 |
|title| RGBT Tracking via All-layer Multimodal Interactions with Progressive Fusion Mamba |
|authors| Andong LuWanyu WangChenglong LiJin TangBin Luo
|links| http://arxiv.org/abs/2408.08827v1 |
|updated| 2024-08-16 16:22:34 UTC |
|summary| Existing RGBT tracking methods often design various interaction models toperform cross-modal fusion of each layer but can not execute the featureinteractions among all layers which plays a critical role in robust multimodalrepresentation due to large computational burden. To address this issue thispaper presents a novel All-layer multimodal Interaction Network named AINetwhich performs efficient and effective feature interactions of all modalitiesand layers in a progressive fusion Mamba for robust RGBT tracking. Even thoughmodality features in different layers are known to contain different cues itis always challenging to build multimodal interactions in each layer due tostruggling in balancing interaction capabilities and efficiency. Meanwhileconsidering that the feature discrepancy between RGB and thermal modalitiesreflects their complementary information to some extent we design aDifference-based Fusion Mamba DFM to achieve enhanced fusion of differentmodalities with linear complexity. When interacting with features from alllayers a huge number of token sequences 3840 tokens in this work areinvolved and the computational burden is thus large. To handle this problem wedesign an Order-dynamic Fusion Mamba OFM to execute efficient and effectivefeature interactions of all layers by dynamically adjusting the scan order ofdifferent layers in Mamba. Extensive experiments on four public RGBT trackingdatasets show that AINet achieves leading performance against existingstate-of-the-art methods. |


# stat.ML 

| Item |Content|
| --- |---|
|idx| 2408.08845v1 |
|title| Shapley Marginal Surplus for Strong Models |
|authors| Daniel de MarchiMichael KosorokScott de Marchi
|links| http://arxiv.org/abs/2408.08845v1 |
|updated| 2024-08-16 17:06:07 UTC |
|summary| Shapley values have seen widespread use in machine learning as a way toexplain model predictions and estimate the importance of covariates. Accuratelyexplaining models is critical in real-world models to both aid in decisionmaking and to infer the properties of the true data-generating process DGP.In this paper we demonstrate that while model-based Shapley values might beaccurate explainers of model predictions machine learning models themselvesare often poor explainers of the DGP even if the model is highly accurate.Particularly in the presence of interrelated or noisy variables the output ofa highly predictive model may fail to account for these relationships. Thisimplies explanations of a trained models behavior may fail to providemeaningful insight into the DGP. In this paper we introduce a novel variableimportance algorithm Shapley Marginal Surplus for Strong Models that samplesthe space of possible models to come up with an inferential measure of featureimportance. We compare this method to other popular feature importance methodsboth Shapley-based and non-Shapley based and demonstrate significantoutperformance in inferential capabilities relative to other methods. |


| Item |Content|
| --- |---|
|idx| 2408.08823v1 |
|title| Optimal Symmetries in Binary Classification |
|authors| Vishal S. NgairangbamMichael Spannowsky
|links| http://arxiv.org/abs/2408.08823v1 |
|updated| 2024-08-16 16:15:18 UTC |
|summary| We explore the role of group symmetries in binary classification taskspresenting a novel framework that leverages the principles of Neyman-Pearsonoptimality. Contrary to the common intuition that larger symmetry groups leadto improved classification performance our findings show that selecting theappropriate group symmetries is crucial for optimising generalisation andsample efficiency. We develop a theoretical foundation for designing groupequivariant neural networks that align the choice of symmetries with theunderlying probability distributions of the data. Our approach provides aunified methodology for improving classification accuracy across a broad rangeof applications by carefully tailoring the symmetry group to the specificcharacteristics of the problem. Theoretical analysis and experimental resultsdemonstrate that optimal classification performance is not always associatedwith the largest equivariant groups possible in the domain even when thelikelihood ratio is invariant under one of its proper subgroups but ratherwith those subgroups themselves. This work offers insights and practicalguidelines for constructing more effective group equivariant architectures indiverse machine-learning contexts. |


| Item |Content|
| --- |---|
|idx| 2408.08690v1 |
|title| Explore-then-Commit Algorithms for Decentralized Two-Sided Matching Markets |
|authors| Tejas PagareAvishek Ghosh
|links| http://arxiv.org/abs/2408.08690v1 |
|updated| 2024-08-16 12:06:09 UTC |
|summary| Online learning in a decentralized two-sided matching markets where thedemand-side players compete to match with the supply-side arms hasreceived substantial interest because it abstracts out the complex interactionsin matching platforms e.g. UpWork TaskRabbit. However past works assumethat each arm knows their preference ranking over the players one-sidedlearning and each player aim to learn the preference over arms throughsuccessive interactions. Moreover several impractical assumptions on theproblem are usually made for theoretical tractability such as broadcastplayer-arm match Liu et al. 2020 2021 Kong  Li 2023 or serialdictatorship Sankararaman et al. 2021 Basu et al. 2021 Ghosh et al.2022. In this paper we study a decentralized two-sided matching marketwhere we do not assume that the preference ranking over players are known tothe arms apriori. Furthermore we do not have any structural assumptions on theproblem. We propose a multi-phase explore-then-commit type algorithm namelyepoch-based CA-ETC collision avoidance explore then commit textttCA-ETCin short for this problem that does not require any communication acrossagents players and arms and hence decentralized. We show that for the initialepoch length of T_circ and subsequent epoch-lengths of 2l/gammaT_circ for the l-th epoch with gamma in 01 as an input parameterto the algorithm textttCA-ETC yields a player optimal expected regret ofmathcalOleftT_circ fracK log TT_circ Delta21/gamma T_circ fracTT_circgammaright for the i-th player where Tis the learning horizon K is the number of arms and Delta is anappropriately defined problem gap. Furthermore we propose a blackboardcommunication based baseline achieving logarithmic regret in T. |


| Item |Content|
| --- |---|
|idx| 2408.08675v1 |
|title| Misclassification excess risk bounds for PAC-Bayesian classification via convexified loss |
|authors| The Tien Mai
|links| http://arxiv.org/abs/2408.08675v1 |
|updated| 2024-08-16 11:41:06 UTC |
|summary| PAC-Bayesian bounds have proven to be a valuable tool for derivinggeneralization bounds and for designing new learning algorithms in machinelearning. However it typically focus on providing generalization bounds withrespect to a chosen loss function. In classification tasks due to thenon-convex nature of the 0-1 loss a convex surrogate loss is often used andthus current PAC-Bayesian bounds are primarily specified for this convexsurrogate. This work shifts its focus to providing misclassification excessrisk bounds for PAC-Bayesian classification when using a convex surrogate loss.Our key ingredient here is to leverage PAC-Bayesian relative bounds inexpectation rather than relying on PAC-Bayesian bounds in probability. Wedemonstrate our approach in several important applications. |


| Item |Content|
| --- |---|
|idx| 2408.08664v1 |
|title| A new perspective on Bayesian Operational Modal Analysis |
|authors| Brandon J. O'ConnellMax D. ChampneysTimothy J. Rogers
|links| http://arxiv.org/abs/2408.08664v1 |
|updated| 2024-08-16 11:11:56 UTC |
|summary| In the field of operational modal analysis OMA obtained modal informationis frequently used to assess the current state of aerospace mechanicaloffshore and civil structures. However the stochasticity of operationalsystems and the lack of forcing information can lead to inconsistent results.Quantifying the uncertainty of the recovered modal parameters through OMA istherefore of significant value. In this article a new perspective on BayesianOMA is proposed: a Bayesian stochastic subspace identification SSI algorithm.Distinct from existing approaches to Bayesian OMA a hierarchical probabilisticmodel is embedded at the core of covariance-driven SSI. Through substitution ofcanonical correlation analysis with a Bayesian equivalent posteriordistributions over the modal properties are obtained. Two inference schemes arepresented for the proposed Bayesian formulation: Markov Chain Monte Carlo andvariational Bayes. Two case studies are then explored. The first is benchmarkstudy using data from a simulated multi degree-of-freedom linear system.Following application of Bayesian SSI it is shown that the same posterior istargeted and recovered by both inference schemes with good agreement betweenthe posterior mean and the conventional SSI result. The second study appliesthe variational form to data obtained from an in-service structure: The Z24bridge. The results of this study are presented at single model orders andthen using a stabilisation diagram. The recovered posterior uncertainty ispresented and compared to the classic SSI result. It is observed that theposterior distributions with mean values coinciding with the naturalfrequencies exhibit lower variance than values situated away from the naturalfrequencies. |


# cs.HC 

| Item |Content|
| --- |---|
|idx| 2408.08853v1 |
|title| CPS-TaskForge: Generating Collaborative Problem Solving Environments for Diverse Communication Tasks |
|authors| Nikita HaduongIrene WangBo-Ru LuPrithviraj AmmanabroluNoah A. Smith
|links| http://arxiv.org/abs/2408.08853v1 |
|updated| 2024-08-16 17:28:19 UTC |
|summary| Teams can outperform individuals could adding AI teammates further bolsterperformance of teams solving problems collaboratively Collaborative problemsolving CPS research commonly studies teams with two agents human-human orhuman-AI but team research literature finds that for complex tasks largerteams are more effective. Progress in studying collaboration with more than twoagents through textual records of team interactions is hindered by a majordata challenge: available CPS corpora are predominantly dyadic and adaptingpre-existing CPS tasks to more agents is non-trivial. We address this datachallenge by developing a CPS task generator CPS-TaskForge that can produceenvironments for studying CPS under a wide array of conditions and releasing aCPS task design checklist grounded in the theoretical PISA 2015 CPS frameworkto help facilitate the development of CPS corpora with more agents.CPS-TaskForge takes the form of a resource management tower defense game anddifferent CPS tasks can be studied by manipulating game design parameters. Weconduct a case study with groups of 3-4 humans to validate production ofdiverse natural language CPS communication in a game instance produced byCPS-TaskForge. We discuss opportunities for advancing research in CPS bothwith human-only and human-AI teams using different task configurations. Wewill release data and code. |


| Item |Content|
| --- |---|
|idx| 2408.08785v1 |
|title| A Transparency Paradox? Investigating the Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies on Passengers |
|authors| Daniel OmeizaRaunak BhattacharyyaMarina JirotkaNick HawesLars Kunze
|links| http://arxiv.org/abs/2408.08785v1 |
|updated| 2024-08-16 14:59:00 UTC |
|summary| Transparency in automated systems could be afforded through the provision ofintelligible explanations. While transparency is desirable might it lead tocatastrophic outcomes such as anxiety that could outweigh its benefits Itsquite unclear how the specificity of explanations level of transparencyinfluences recipients especially in autonomous driving AD. In this work weexamined the effects of transparency mediated through varying levels ofexplanation specificity in AD. We first extended a data-driven explainer modelby adding a rule-based option for explanation generation in AD and thenconducted a within-subject lab study with 39 participants in an immersivedriving simulator to study the effect of the resulting explanations.Specifically our investigation focused on: 1 how different types ofexplanations specific vs. abstract affect passengers perceived safetyanxiety and willingness to take control of the vehicle when the vehicleperception system makes erroneous predictions and 2 the relationship betweenpassengers behavioural cues and their feelings during the autonomous drives.Our findings showed that passengers felt safer with specific explanations whenthe vehicles perception system had minimal errors while abstract explanationsthat hid perception errors led to lower feelings of safety. Anxiety levelsincreased when specific explanations revealed perception system errors hightransparency. We found no significant link between passengers visual patternsand their anxiety levels. Our study suggests that passengers prefer clear andspecific explanations high transparency when they originate from autonomousvehicles AVs with optimal perceptual accuracy. |


| Item |Content|
| --- |---|
|idx| 2408.08652v1 |
|title| TextCAVs: Debugging vision models using text |
|authors| Angus NicolsonYarin GalJ. Alison Noble
|links| http://arxiv.org/abs/2408.08652v1 |
|updated| 2024-08-16 10:36:08 UTC |
|summary| Concept-based interpretability methods are a popular form of explanation fordeep learning models which provide explanations in the form of high-level humaninterpretable concepts. These methods typically find concept activation vectorsCAVs using a probe dataset of concept examples. This requires labelled datafor these concepts -- an expensive task in the medical domain. We introduceTextCAVs: a novel method which creates CAVs using vision-language models suchas CLIP allowing for explanations to be created solely using text descriptionsof the concept as opposed to image exemplars. This reduced cost in testingconcepts allows for many concepts to be tested and for users to interact withthe model testing new ideas as they are thought of rather than a delay causedby image collection and annotation. In early experimental results wedemonstrate that TextCAVs produces reasonable explanations for a chest x-raydataset MIMIC-CXR and natural images ImageNet and that these explanationscan be used to debug deep learning-based models. |


| Item |Content|
| --- |---|
|idx| 2408.08475v1 |
|title| Models Matter: Setting Accurate Privacy Expectations for Local and Central Differential Privacy |
|authors| Mary Anne SmartPriyanka NanayakkaraRachel CummingsGabriel KaptchukElissa Redmiles
|links| http://arxiv.org/abs/2408.08475v1 |
|updated| 2024-08-16 01:21:57 UTC |
|summary| Differential privacy is a popular privacy-enhancing technology that has beendeployed both in industry and government agencies. Unfortunately existingexplanations of differential privacy fail to set accurate privacy expectationsfor data subjects which depend on the choice of deployment model. We designand evaluate new explanations of differential privacy for the local and centralmodels drawing inspiration from prior work explaining other privacy-enhancingtechnologies. We find that consequences-focused explanations in the style ofprivacy nutrition labels that lay out the implications of differential privacyare a promising approach for setting accurate privacy expectations. Further wefind that while process-focused explanations are not enough to set accurateprivacy expectations combining consequences-focused explanations with a briefdescription of how differential privacy works leads to greater trust. |


| Item |Content|
| --- |---|
|idx| 2408.08438v1 |
|title| Voicing Uncertainty: How Speech, Text, and Visualizations Influence Decisions with Data Uncertainty |
|authors| Chase StokesChelsea SankerBridget CogleyVidya Setlur
|links| http://arxiv.org/abs/2408.08438v1 |
|updated| 2024-08-15 22:11:49 UTC |
|summary| Understanding and communicating data uncertainty is crucial for informeddecision-making across various domains including finance healthcare andpublic policy. This study investigates the impact of gender and acousticvariables on decision-making confidence and trust through a crowdsourcedexperiment. We compared visualization-only representations of uncertainty totext-forward and speech-forward bimodal representations including multiplesynthetic voices across gender. Speech-forward representations led to anincrease in risky decisions and text-forward representations led to lowerconfidence. Contrary to prior work speech-forward forecasts did not receivehigher ratings of trust. Higher normalized pitch led to a slight increase indecision confidence but other voice characteristics had minimal impact ondecisions and trust. An exploratory analysis of accented speech showedconsistent results with the main experiment and additionally indicated lowertrust ratings for information presented in Indian and Kenyan accents. Theresults underscore the importance of considering acoustic and contextualfactors in presentation of data uncertainty. |


# cs.MA 

| Item |Content|
| --- |---|
|idx| 2408.08861v1 |
|title| The computational power of a human society: a new model of social evolution |
|authors| David H. WolpertKyle Harper
|links| http://arxiv.org/abs/2408.08861v1 |
|updated| 2024-08-16 17:42:28 UTC |
|summary| Social evolutionary theory seeks to explain increases in the scale andcomplexity of human societies from origins to present. Over the course of thetwentieth century social evolutionary theory largely fell out of favor as away of investigating human history just as advances in complex systems scienceand computer science saw the emergence of powerful new conceptions of complexsystems and in particular new methods of measuring complexity. We propose thatthese advances in our understanding of complex systems and computer scienceshould be brought to bear on our investigations into human history. To thatend we present a new framework for modeling how human societies co-evolve withtheir biotic environments recognizing that both a society and its environmentare computers. This leads us to model the dynamics of each of those two systemsusing the same new kind of computational machine which we define here. Forsimplicity we construe a society as a set of interacting occupations andtechnologies. Similarly under such a model a biotic environment is a set ofinteracting distinct ecological and climatic processes. This provides novelways to characterize social complexity which we hope will cast new light onthe archaeological and historical records. Our framework also provides anatural way to formalize both the energetic thermodynamic costs required by asociety as it runs and the ways it can extract thermodynamic resources fromthe environment in order to pay for those costs -- and perhaps to grow with anyleft-over resources. |


| Item |Content|
| --- |---|
|idx| 2408.08571v1 |
|title| AgentSimulator: An Agent-based Approach for Data-driven Business Process Simulation |
|authors| Lukas KirchdorferRobert BlümelTimotheus KampikHan van der AaHeiner Stuckenschmidt
|links| http://arxiv.org/abs/2408.08571v1 |
|updated| 2024-08-16 07:19:11 UTC |
|summary| Business process simulation BPS is a versatile technique for estimatingprocess performance across various scenarios. Traditionally BPS approachesemploy a control-flow-first perspective by enriching a process model withsimulation parameters. Although such approaches can mimic the behavior ofcentrally orchestrated processes such as those supported by workflow systemscurrent control-flow-first approaches cannot faithfully capture the dynamics ofreal-world processes that involve distinct resource behavior and decentralizeddecision-making. Recognizing this issue this paper introduces AgentSimulatora resource-first BPS approach that discovers a multi-agent system from an eventlog modeling distinct resource behaviors and interaction patterns to simulatethe underlying process. Our experiments show that AgentSimulator achievesstate-of-the-art simulation accuracy with significantly lower computation timesthan existing approaches while providing high interpretability and adaptabilityto different types of process-execution scenarios. |


| Item |Content|
| --- |---|
|idx| 2408.08516v1 |
|title| Multilevel Graph Reinforcement Learning for Consistent Cognitive Decision-making in Heterogeneous Mixed Autonomy |
|authors| Xin GaoZhaoyang MaXueyuan LiXiaoqiang MengZirui Li
|links| http://arxiv.org/abs/2408.08516v1 |
|updated| 2024-08-16 04:14:06 UTC |
|summary| In the realm of heterogeneous mixed autonomy vehicles experience dynamicspatial correlations and nonlinear temporal interactions in a complexnon-Euclidean space. These complexities pose significant challenges totraditional decision-making frameworks. Addressing this we propose ahierarchical reinforcement learning framework integrated with multilevel graphrepresentations which effectively comprehends and models the spatiotemporalinteractions among vehicles navigating through uncertain traffic conditionswith varying decision-making systems. Rooted in multilevel graph representationtheory our approach encapsulates spatiotemporal relationships inherent innon-Euclidean spaces. A weighted graph represents spatiotemporal featuresbetween nodes addressing the degree imbalance inherent in dynamic graphs. Weintegrate asynchronous parallel hierarchical reinforcement learning with amultilevel graph representation and a multi-head attention mechanism whichenables connected autonomous vehicles CAVs to exhibit capabilities akin tohuman cognition facilitating consistent decision-making across variouscritical dimensions. The proposed decision-making strategy is validated inchallenging environments characterized by high density randomness anddynamism on highway roads. We assess the performance of our framework throughablation studies comparative analyses and spatiotemporal trajectoryevaluations. This study presents a quantitative analysis of decision-makingmechanisms mirroring human cognitive functions in the realm of heterogeneousmixed autonomy promoting the development of multi-dimensional decision-makingstrategies and a sophisticated distribution of attentional resources. |


| Item |Content|
| --- |---|
|idx| 2408.08497v1 |
|title| Data-driven Construction of Finite Abstractions for Interconnected Systems: A Compositional Approach |
|authors| Daniel AjeleyeMajid Zamani
|links| http://arxiv.org/abs/2408.08497v1 |
|updated| 2024-08-16 02:42:17 UTC |
|summary| Finite-state abstractions a.k.a. symbolic models present a promising avenuefor the formal verification and synthesis of controllers in continuous-spacecontrol systems. These abstractions provide simplified models that capture thefundamental behaviors of the original systems. However the creation of suchabstractions typically relies on the availability of precise knowledgeconcerning system dynamics which might not be available in many real-worldapplications. In this work we introduce an innovative data-driven andcompositional approach to generate finite abstractions for interconnectedsystems that consist of discrete-time control subsystems with unknown dynamics.These subsystems interact through an unknown static interconnection map. Ourmethodology for abstracting the interconnected system involves constructingabstractions for individual subsystems and incorporating an abstraction of theinterconnection map. |


| Item |Content|
| --- |---|
|idx| 2408.08192v1 |
|title| Stochastic Semi-Gradient Descent for Learning Mean Field Games with Population-Aware Function Approximation |
|authors| Chenyu ZhangXu ChenXuan Di
|links| http://arxiv.org/abs/2408.08192v1 |
|updated| 2024-08-15 14:51:50 UTC |
|summary| Mean field games MFGs model the interactions within a large-populationmulti-agent system using the population distribution. Traditional learningmethods for MFGs are based on fixed-point iteration FPI which calculatesbest responses and induced population distribution separately and sequentially.However FPI-type methods suffer from inefficiency and instability due tooscillations caused by the forward-backward procedure. This paper considers anonline learning method for MFGs where an agent updates its policy andpopulation estimates simultaneously and fully asynchronously resulting in asimple stochastic gradient descent SGD type method called SemiSGD. Not onlydoes SemiSGD exhibit numerical stability and efficiency but it also provides anovel perspective by treating the value function and population distribution asa unified parameter. We theoretically show that SemiSGD directs this unifiedparameter along a descent direction to the mean field equilibrium. Motivated bythis perspective we develop a linear function approximation LFA for both thevalue function and the population distribution resulting in the firstpopulation-aware LFA for MFGs on continuous state-action space. Finite-timeconvergence and approximation error analysis are provided for SemiSGD equippedwith population-aware LFA. |


