# cs.CL 

| Item |Content|
| --- |---|
|idx| 2402.13254v1 |
|title| CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples |
|authors| Jianrui ZhangMu CaiTengyang XieYong Jae Lee
|links| http://arxiv.org/abs/2402.13254v1 |
|updated| 2024-02-20 18:59:55 UTC |
|summary| We propose CounterCurate a framework to comprehensively improve thevisio-linguistic compositional reasoning capability for both contrastive andgenerative multimodal models. In particular we identify two under-exploredcritical problems: the neglect of the physically grounded reasoning countingand position understanding and the potential of using highly capable text andimage generation models for semantic counterfactual fine-tuning. Our workpioneers an approach that addresses these gaps. We first spotlight thenear-chance performance of multimodal models like CLIP and LLaVA in physicallygrounded compositional reasoning. We then apply simple data augmentation usinga grounded image generation model GLIGEN to generate finetuning dataresulting in significant performance improvements: 33 and 37 for CLIP andLLaVA respectively on our newly curated Flickr30k-Positions benchmark.Moreover we exploit the capabilities of high-performing text generation andimage generation models specifically GPT-4V and DALLE-3 to curate challengingsemantic counterfactuals thereby further enhancing compositional reasoningcapabilities on benchmarks such as SugarCrepe where CounterCurate outperformsGPT-4V. |


| Item |Content|
| --- |---|
|idx| 2402.13253v1 |
|title| BiMediX: Bilingual Medical Mixture of Experts LLM |
|authors| Sara PieriSahal Shaji MullappillyFahad Shahbaz KhanRao Muhammad AnwerSalman KhanTimothy BaldwinHisham Cholakkal
|links| http://arxiv.org/abs/2402.13253v1 |
|updated| 2024-02-20 18:59:26 UTC |
|summary| In this paper we introduce BiMediX the first bilingual medical mixture ofexperts LLM designed for seamless interaction in both English and Arabic. Ourmodel facilitates a wide range of medical interactions in English and Arabicincluding multi-turn chats to inquire about additional details such as patientsymptoms and medical history multiple-choice question answering andopen-ended question answering. We propose a semi-automated English-to-Arabictranslation pipeline with human refinement to ensure high-quality translations.We also introduce a comprehensive evaluation benchmark for Arabic medical LLMs.Furthermore we introduce BiMed1.3M an extensive Arabic-English bilingualinstruction set covering 1.3 Million diverse medical interactions resulting inover 632 million healthcare specialized tokens for instruction tuning. OurBiMed1.3M dataset includes 250k synthesized multi-turn doctor-patient chats andmaintains a 1:2 Arabic-to-English ratio. Our model outperforms state-of-the-artMed42 and Meditron by average absolute gains of 2.5 and 4.1 respectivelycomputed across multiple medical evaluation benchmarks in English whileoperating at 8-times faster inference. Moreover our BiMediX outperforms thegeneric Arabic-English bilingual LLM Jais-30B by average absolute gains of10 on our Arabic medical benchmark and 15 on bilingual evaluations acrossmultiple datasets. Our project page with source code and trained model isavailable at https://github.com/mbzuai-oryx/BiMediX . |


| Item |Content|
| --- |---|
|idx| 2402.13249v1 |
|title| TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization |
|authors| Liyan TangIgor ShalyminovAmy Wing-mei WongJon BurnskyJake W. VincentYu'an YangSiffi SinghSong FengHwanjun SongHang SuLijia SunYi ZhangSaab MansourKathleen McKeown
|links| http://arxiv.org/abs/2402.13249v1 |
|updated| 2024-02-20 18:58:49 UTC |
|summary| Single document news summarization has seen substantial progress onfaithfulness in recent years driven by research on the evaluation of factualconsistency or hallucinations. We ask whether these advances carry over toother text summarization domains. We propose a new evaluation benchmark ontopic-focused dialogue summarization generated by LLMs of varying sizes. Weprovide binary sentence-level human annotations of the factual consistency ofthese summaries along with detailed explanations of factually inconsistentsentences. Our analysis shows that existing LLMs hallucinate significantamounts of factual errors in the dialogue domain regardless of the modelssize. On the other hand when LLMs including GPT-4 serve as binary factualevaluators they perform poorly and can be outperformed by prevailingstate-of-the-art specialized factuality evaluation metrics. Finally weconducted an analysis of hallucination types with a curated error taxonomy. Wefind that there are diverse errors and error distributions in model-generatedsummaries and that non-LLM based metrics can capture all error types betterthan LLM-based evaluators. |


| Item |Content|
| --- |---|
|idx| 2402.13234v1 |
|title| Unlocking Insights: Semantic Search in Jupyter Notebooks |
|authors| Lan LiJinpeng Lv
|links| http://arxiv.org/abs/2402.13234v1 |
|updated| 2024-02-20 18:49:41 UTC |
|summary| Semantic search a process aimed at delivering highly relevant search resultsby comprehending the searchers intent and the contextual meaning of termswithin a searchable dataspace plays a pivotal role in information retrieval.In this paper we investigate the application of large language models toenhance semantic search capabilities specifically tailored for the domain ofJupyter Notebooks. Our objective is to retrieve generated outputs such asfigures or tables associated functions and methods and other pertinentinformation.  We demonstrate a semantic search framework that achieves a comprehensivesemantic understanding of the entire notebooks contents enabling it toeffectively handle various types of user queries. Key components of thisframework include:  1. A data preprocessor is designed to handle diverse types of cells withinJupyter Notebooks encompassing both markdown and code cells. 2. An innovativemethodology is devised to address token size limitations that arise withcode-type cells. We implement a finer-grained approach to data inputtransitioning from the cell level to the function level effectively resolvingthese issues. |


| Item |Content|
| --- |---|
|idx| 2402.13231v1 |
|title| Investigating Cultural Alignment of Large Language Models |
|authors| Badr AlKhamissiMuhammad ElNokrashyMai AlKhamissiMona Diab
|links| http://arxiv.org/abs/2402.13231v1 |
|updated| 2024-02-20 18:47:28 UTC |
|summary| The intricate relationship between language and culture has long been asubject of exploration within the realm of linguistic anthropology. LargeLanguage Models LLMs promoted as repositories of collective human knowledgeraise a pivotal question: do these models genuinely encapsulate the diverseknowledge adopted by different cultures Our study reveals that these modelsdemonstrate greater cultural alignment along two dimensions -- firstly whenprompted with the dominant language of a specific culture and secondly whenpretrained with a refined mixture of languages employed by that culture. Wequantify cultural alignment by simulating sociological surveys comparing modelresponses to those of actual survey participants as references. Specificallywe replicate a survey conducted in various regions of Egypt and the UnitedStates through prompting LLMs with different pretraining data mixtures in bothArabic and English with the personas of the real respondents and the surveyquestions. Further analysis reveals that misalignment becomes more pronouncedfor underrepresented personas and for culturally sensitive topics such asthose probing social values. Finally we introduce Anthropological Prompting anovel method leveraging anthropological reasoning to enhance culturalalignment. Our study emphasizes the necessity for a more balanced multilingualpretraining dataset to better represent the diversity of human experience andthe plurality of different cultures with many implications on the topic ofcross-lingual transfer. |


# cs.AI 

| Item |Content|
| --- |---|
|idx| 2402.13254v1 |
|title| CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples |
|authors| Jianrui ZhangMu CaiTengyang XieYong Jae Lee
|links| http://arxiv.org/abs/2402.13254v1 |
|updated| 2024-02-20 18:59:55 UTC |
|summary| We propose CounterCurate a framework to comprehensively improve thevisio-linguistic compositional reasoning capability for both contrastive andgenerative multimodal models. In particular we identify two under-exploredcritical problems: the neglect of the physically grounded reasoning countingand position understanding and the potential of using highly capable text andimage generation models for semantic counterfactual fine-tuning. Our workpioneers an approach that addresses these gaps. We first spotlight thenear-chance performance of multimodal models like CLIP and LLaVA in physicallygrounded compositional reasoning. We then apply simple data augmentation usinga grounded image generation model GLIGEN to generate finetuning dataresulting in significant performance improvements: 33 and 37 for CLIP andLLaVA respectively on our newly curated Flickr30k-Positions benchmark.Moreover we exploit the capabilities of high-performing text generation andimage generation models specifically GPT-4V and DALLE-3 to curate challengingsemantic counterfactuals thereby further enhancing compositional reasoningcapabilities on benchmarks such as SugarCrepe where CounterCurate outperformsGPT-4V. |


| Item |Content|
| --- |---|
|idx| 2402.13249v1 |
|title| TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization |
|authors| Liyan TangIgor ShalyminovAmy Wing-mei WongJon BurnskyJake W. VincentYu'an YangSiffi SinghSong FengHwanjun SongHang SuLijia SunYi ZhangSaab MansourKathleen McKeown
|links| http://arxiv.org/abs/2402.13249v1 |
|updated| 2024-02-20 18:58:49 UTC |
|summary| Single document news summarization has seen substantial progress onfaithfulness in recent years driven by research on the evaluation of factualconsistency or hallucinations. We ask whether these advances carry over toother text summarization domains. We propose a new evaluation benchmark ontopic-focused dialogue summarization generated by LLMs of varying sizes. Weprovide binary sentence-level human annotations of the factual consistency ofthese summaries along with detailed explanations of factually inconsistentsentences. Our analysis shows that existing LLMs hallucinate significantamounts of factual errors in the dialogue domain regardless of the modelssize. On the other hand when LLMs including GPT-4 serve as binary factualevaluators they perform poorly and can be outperformed by prevailingstate-of-the-art specialized factuality evaluation metrics. Finally weconducted an analysis of hallucination types with a curated error taxonomy. Wefind that there are diverse errors and error distributions in model-generatedsummaries and that non-LLM based metrics can capture all error types betterthan LLM-based evaluators. |


| Item |Content|
| --- |---|
|idx| 2402.13241v1 |
|title| Federated Causal Discovery from Heterogeneous Data |
|authors| Loka LiIgnavier NgGongxu LuoBiwei HuangGuangyi ChenTongliang LiuBin GuKun Zhang
|links| http://arxiv.org/abs/2402.13241v1 |
|updated| 2024-02-20 18:53:53 UTC |
|summary| Conventional causal discovery methods rely on centralized data which isinconsistent with the decentralized nature of data in many real-worldsituations. This discrepancy has motivated the development of federated causaldiscovery FCD approaches. However existing FCD methods may be limited bytheir potentially restrictive assumptions of identifiable functional causalmodels or homogeneous data distributions narrowing their applicability indiverse scenarios. In this paper we propose a novel FCD method attempting toaccommodate arbitrary causal models and heterogeneous data. We first utilize asurrogate variable corresponding to the client index to account for the dataheterogeneity across different clients. We then develop a federated conditionalindependence test FCIT for causal skeleton discovery and establish afederated independent change principle FICP to determine causal directions.These approaches involve constructing summary statistics as a proxy of the rawdata to protect data privacy. Owing to the nonparametric properties FCIT andFICP make no assumption about particular functional forms thereby facilitatingthe handling of arbitrary causal models. We conduct extensive experiments onsynthetic and real datasets to show the efficacy of our method. The code isavailable at urlhttps://github.com/lokali/FedCDH.git. |


| Item |Content|
| --- |---|
|idx| 2402.13228v1 |
|title| Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive |
|authors| Arka PalDeep KarkhanisSamuel DooleyManley RobertsSiddartha NaiduColin White
|links| http://arxiv.org/abs/2402.13228v1 |
|updated| 2024-02-20 18:42:34 UTC |
|summary| Direct Preference Optimisation DPO is effective at significantly improvingthe performance of large language models LLMs on downstream tasks such asreasoning summarisation and alignment. Using pairs of preferred anddispreferred data DPO models the textitrelative probability of picking oneresponse over another. In this work first we show theoretically that thestandard DPO loss can lead to a textitreduction of the models likelihood ofthe preferred examples as long as the relative probability between thepreferred and dispreferred classes increases. We then show empirically thatthis phenomenon occurs when fine-tuning LLMs on common datasets especiallydatasets in which the edit distance between pairs of completions is low. Usingthese insights we design DPO-Positive DPOP a new loss function and trainingprocedure which avoids this failure mode. Surprisingly we also find that DPOPsignificantly outperforms DPO across a wide variety of datasets and downstreamtasks including datasets with high edit distances between completions. Byfine-tuning with DPOP we create and release Smaug-34B and Smaug-72B whichachieve state-of-the-art open-source performance. Notably Smaug-72B is nearly2 better than any other open-source model on the HuggingFace Open LLMLeaderboard and becomes the first open-source LLM to surpass an averageaccuracy of 80. |


| Item |Content|
| --- |---|
|idx| 2402.13226v1 |
|title| NeRF Solves Undersampled MRI Reconstruction |
|authors| Tae Jun JangChang Min Hyun
|links| http://arxiv.org/abs/2402.13226v1 |
|updated| 2024-02-20 18:37:42 UTC |
|summary| This article presents a novel undersampled magnetic resonance imaging MRItechnique that leverages the concept of Neural Radiance Field NeRF. Withradial undersampling the corresponding imaging problem can be reformulatedinto an image modeling task from sparse-view rendered data therefore a highdimensional MR image is obtainable from undersampled k-space data by takingadvantage of implicit neural representation. A multi-layer perceptron which isdesigned to output an image intensity from a spatial coordinate learns the MRphysics-driven rendering relation between given measurement data and desiredimage. Effective undersampling strategies for high-quality neuralrepresentation are investigated. The proposed method serves two benefits: iThe learning is based fully on single undersampled k-space data not a bunchof measured data and target image sets. It can be used potentially fordiagnostic MR imaging such as fetal MRI where data acquisition is relativelyrare or limited against diversity of clinical images while undersampledreconstruction is highly demanded. ii A reconstructed MR image is ascan-specific representation highly adaptive to the given k-spacemeasurement. Numerous experiments validate the feasibility and capability ofthe proposed approach. |


# cs.LG 

| Item |Content|
| --- |---|
|idx| 2402.13254v1 |
|title| CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples |
|authors| Jianrui ZhangMu CaiTengyang XieYong Jae Lee
|links| http://arxiv.org/abs/2402.13254v1 |
|updated| 2024-02-20 18:59:55 UTC |
|summary| We propose CounterCurate a framework to comprehensively improve thevisio-linguistic compositional reasoning capability for both contrastive andgenerative multimodal models. In particular we identify two under-exploredcritical problems: the neglect of the physically grounded reasoning countingand position understanding and the potential of using highly capable text andimage generation models for semantic counterfactual fine-tuning. Our workpioneers an approach that addresses these gaps. We first spotlight thenear-chance performance of multimodal models like CLIP and LLaVA in physicallygrounded compositional reasoning. We then apply simple data augmentation usinga grounded image generation model GLIGEN to generate finetuning dataresulting in significant performance improvements: 33 and 37 for CLIP andLLaVA respectively on our newly curated Flickr30k-Positions benchmark.Moreover we exploit the capabilities of high-performing text generation andimage generation models specifically GPT-4V and DALLE-3 to curate challengingsemantic counterfactuals thereby further enhancing compositional reasoningcapabilities on benchmarks such as SugarCrepe where CounterCurate outperformsGPT-4V. |


| Item |Content|
| --- |---|
|idx| 2402.13251v1 |
|title| FlashTex: Fast Relightable Mesh Texturing with LightControlNet |
|authors| Kangle DengTimothy OmernickAlexander WeissDeva RamananJun-Yan ZhuTinghui ZhouManeesh Agrawala
|links| http://arxiv.org/abs/2402.13251v1 |
|updated| 2024-02-20 18:59:00 UTC |
|summary| Manually creating textures for 3D meshes is time-consuming even for expertvisual content creators. We propose a fast approach for automatically texturingan input 3D mesh based on a user-provided text prompt. Importantly ourapproach disentangles lighting from surface material/reflectance in theresulting texture so that the mesh can be properly relit and rendered in anylighting environment. We introduce LightControlNet a new text-to-image modelbased on the ControlNet architecture which allows the specification of thedesired lighting as a conditioning image to the model. Our text-to-texturepipeline then constructs the texture in two stages. The first stage produces asparse set of visually consistent reference views of the mesh usingLightControlNet. The second stage applies a texture optimization based on ScoreDistillation Sampling SDS that works with LightControlNet to increase thetexture quality while disentangling surface material from lighting. Ourpipeline is significantly faster than previous text-to-texture methods whileproducing high-quality and relightable textures. |


| Item |Content|
| --- |---|
|idx| 2402.13241v1 |
|title| Federated Causal Discovery from Heterogeneous Data |
|authors| Loka LiIgnavier NgGongxu LuoBiwei HuangGuangyi ChenTongliang LiuBin GuKun Zhang
|links| http://arxiv.org/abs/2402.13241v1 |
|updated| 2024-02-20 18:53:53 UTC |
|summary| Conventional causal discovery methods rely on centralized data which isinconsistent with the decentralized nature of data in many real-worldsituations. This discrepancy has motivated the development of federated causaldiscovery FCD approaches. However existing FCD methods may be limited bytheir potentially restrictive assumptions of identifiable functional causalmodels or homogeneous data distributions narrowing their applicability indiverse scenarios. In this paper we propose a novel FCD method attempting toaccommodate arbitrary causal models and heterogeneous data. We first utilize asurrogate variable corresponding to the client index to account for the dataheterogeneity across different clients. We then develop a federated conditionalindependence test FCIT for causal skeleton discovery and establish afederated independent change principle FICP to determine causal directions.These approaches involve constructing summary statistics as a proxy of the rawdata to protect data privacy. Owing to the nonparametric properties FCIT andFICP make no assumption about particular functional forms thereby facilitatingthe handling of arbitrary causal models. We conduct extensive experiments onsynthetic and real datasets to show the efficacy of our method. The code isavailable at urlhttps://github.com/lokali/FedCDH.git. |


| Item |Content|
| --- |---|
|idx| 2402.13233v1 |
|title| SMORE: Similarity-based Hyperdimensional Domain Adaptation for Multi-Sensor Time Series Classification |
|authors| Junyao WangMohammad Abdullah Al Faruque
|links| http://arxiv.org/abs/2402.13233v1 |
|updated| 2024-02-20 18:48:49 UTC |
|summary| Many real-world applications of the Internet of Things IoT employ machinelearning ML algorithms to analyze time series information collected byinterconnected sensors. However distribution shift a fundamental challenge indata-driven ML arises when a model is deployed on a data distributiondifferent from the training data and can substantially degrade modelperformance. Additionally increasingly sophisticated deep neural networksDNNs are required to capture intricate spatial and temporal dependencies inmulti-sensor time series data often exceeding the capabilities of todays edgedevices. In this paper we propose SMORE a novel resource-efficient domainadaptation DA algorithm for multi-sensor time series classificationleveraging the efficient and parallel operations of hyperdimensional computing.SMORE dynamically customizes test-time models with explicit consideration ofthe domain context of each sample to mitigate the negative impacts of domainshifts. Our evaluation on a variety of multi-sensor time series classificationtasks shows that SMORE achieves on average 1.98 higher accuracy thanstate-of-the-art SOTA DNN-based DA algorithms with 18.81x faster training and4.63x faster inference. |


| Item |Content|
| --- |---|
|idx| 2402.13228v1 |
|title| Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive |
|authors| Arka PalDeep KarkhanisSamuel DooleyManley RobertsSiddartha NaiduColin White
|links| http://arxiv.org/abs/2402.13228v1 |
|updated| 2024-02-20 18:42:34 UTC |
|summary| Direct Preference Optimisation DPO is effective at significantly improvingthe performance of large language models LLMs on downstream tasks such asreasoning summarisation and alignment. Using pairs of preferred anddispreferred data DPO models the textitrelative probability of picking oneresponse over another. In this work first we show theoretically that thestandard DPO loss can lead to a textitreduction of the models likelihood ofthe preferred examples as long as the relative probability between thepreferred and dispreferred classes increases. We then show empirically thatthis phenomenon occurs when fine-tuning LLMs on common datasets especiallydatasets in which the edit distance between pairs of completions is low. Usingthese insights we design DPO-Positive DPOP a new loss function and trainingprocedure which avoids this failure mode. Surprisingly we also find that DPOPsignificantly outperforms DPO across a wide variety of datasets and downstreamtasks including datasets with high edit distances between completions. Byfine-tuning with DPOP we create and release Smaug-34B and Smaug-72B whichachieve state-of-the-art open-source performance. Notably Smaug-72B is nearly2 better than any other open-source model on the HuggingFace Open LLMLeaderboard and becomes the first open-source LLM to surpass an averageaccuracy of 80. |


# cs.CV 

| Item |Content|
| --- |---|
|idx| 2402.13255v1 |
|title| How NeRFs and 3D Gaussian Splatting are Reshaping SLAM: a Survey |
|authors| Fabio TosiYoumin ZhangZiren GongErik SandströmStefano MattocciaMartin R. OswaldMatteo Poggi
|links| http://arxiv.org/abs/2402.13255v1 |
|updated| 2024-02-20 18:59:57 UTC |
|summary| Over the past two decades research in the field of Simultaneous Localizationand Mapping SLAM has undergone a significant evolution highlighting itscritical role in enabling autonomous exploration of unknown environments. Thisevolution ranges from hand-crafted methods through the era of deep learningto more recent developments focused on Neural Radiance Fields NeRFs and 3DGaussian Splatting 3DGS representations. Recognizing the growing body ofresearch and the absence of a comprehensive survey on the topic this paperaims to provide the first comprehensive overview of SLAM progress through thelens of the latest advancements in radiance fields. It sheds light on thebackground evolutionary path inherent strengths and limitations and servesas a fundamental reference to highlight the dynamic progress and specificchallenges. |


| Item |Content|
| --- |---|
|idx| 2402.13254v1 |
|title| CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples |
|authors| Jianrui ZhangMu CaiTengyang XieYong Jae Lee
|links| http://arxiv.org/abs/2402.13254v1 |
|updated| 2024-02-20 18:59:55 UTC |
|summary| We propose CounterCurate a framework to comprehensively improve thevisio-linguistic compositional reasoning capability for both contrastive andgenerative multimodal models. In particular we identify two under-exploredcritical problems: the neglect of the physically grounded reasoning countingand position understanding and the potential of using highly capable text andimage generation models for semantic counterfactual fine-tuning. Our workpioneers an approach that addresses these gaps. We first spotlight thenear-chance performance of multimodal models like CLIP and LLaVA in physicallygrounded compositional reasoning. We then apply simple data augmentation usinga grounded image generation model GLIGEN to generate finetuning dataresulting in significant performance improvements: 33 and 37 for CLIP andLLaVA respectively on our newly curated Flickr30k-Positions benchmark.Moreover we exploit the capabilities of high-performing text generation andimage generation models specifically GPT-4V and DALLE-3 to curate challengingsemantic counterfactuals thereby further enhancing compositional reasoningcapabilities on benchmarks such as SugarCrepe where CounterCurate outperformsGPT-4V. |


| Item |Content|
| --- |---|
|idx| 2402.13252v1 |
|title| Improving Robustness for Joint Optimization of Camera Poses and Decomposed Low-Rank Tensorial Radiance Fields |
|authors| Bo-Yu ChengWei-Chen ChiuYu-Lun Liu
|links| http://arxiv.org/abs/2402.13252v1 |
|updated| 2024-02-20 18:59:02 UTC |
|summary| In this paper we propose an algorithm that allows joint refinement of camerapose and scene geometry represented by decomposed low-rank tensor using only2D images as supervision. First we conduct a pilot study based on a 1D signaland relate our findings to 3D scenarios where the naive joint poseoptimization on voxel-based NeRFs can easily lead to sub-optimal solutions.Moreover based on the analysis of the frequency spectrum we propose to applyconvolutional Gaussian filters on 2D and 3D radiance fields for acoarse-to-fine training schedule that enables joint camera pose optimization.Leveraging the decomposition property in decomposed low-rank tensor our methodachieves an equivalent effect to brute-force 3D convolution with only incurringlittle computational overhead. To further improve the robustness and stabilityof joint optimization we also propose techniques of smoothed 2D supervisionrandomly scaled kernel parameters and edge-guided loss mask. Extensivequantitative and qualitative evaluations demonstrate that our proposedframework achieves superior performance in novel view synthesis as well asrapid convergence for optimization. |


| Item |Content|
| --- |---|
|idx| 2402.13251v1 |
|title| FlashTex: Fast Relightable Mesh Texturing with LightControlNet |
|authors| Kangle DengTimothy OmernickAlexander WeissDeva RamananJun-Yan ZhuTinghui ZhouManeesh Agrawala
|links| http://arxiv.org/abs/2402.13251v1 |
|updated| 2024-02-20 18:59:00 UTC |
|summary| Manually creating textures for 3D meshes is time-consuming even for expertvisual content creators. We propose a fast approach for automatically texturingan input 3D mesh based on a user-provided text prompt. Importantly ourapproach disentangles lighting from surface material/reflectance in theresulting texture so that the mesh can be properly relit and rendered in anylighting environment. We introduce LightControlNet a new text-to-image modelbased on the ControlNet architecture which allows the specification of thedesired lighting as a conditioning image to the model. Our text-to-texturepipeline then constructs the texture in two stages. The first stage produces asparse set of visually consistent reference views of the mesh usingLightControlNet. The second stage applies a texture optimization based on ScoreDistillation Sampling SDS that works with LightControlNet to increase thetexture quality while disentangling surface material from lighting. Ourpipeline is significantly faster than previous text-to-texture methods whileproducing high-quality and relightable textures. |


| Item |Content|
| --- |---|
|idx| 2402.13250v1 |
|title| Video ReCap: Recursive Captioning of Hour-Long Videos |
|authors| Md Mohaiminul IslamNgan HoXitong YangTushar NagarajanLorenzo TorresaniGedas Bertasius
|links| http://arxiv.org/abs/2402.13250v1 |
|updated| 2024-02-20 18:58:54 UTC |
|summary| Most video captioning models are designed to process short video clips of fewseconds and output text describing low-level visual concepts e.g. objectsscenes atomic actions. However most real-world videos last for minutes orhours and have a complex hierarchical structure spanning different temporalgranularities. We propose Video ReCap a recursive video captioning model thatcan process video inputs of dramatically different lengths from 1 second to 2hours and output video captions at multiple hierarchy levels. The recursivevideo-language architecture exploits the synergy between different videohierarchies and can process hour-long videos efficiently. We utilize acurriculum learning training scheme to learn the hierarchical structure ofvideos starting from clip-level captions describing atomic actions thenfocusing on segment-level descriptions and concluding with generatingsummaries for hour-long videos. Furthermore we introduce Ego4D-HCap dataset byaugmenting Ego4D with 8267 manually collected long-range video summaries. Ourrecursive model can flexibly generate captions at different hierarchy levelswhile also being useful for other complex video understanding tasks such asVideoQA on EgoSchema. Data code and models are available at:https://sites.google.com/view/vidrecap |


# stat.ML 

| Item |Content|
| --- |---|
|idx| 2402.13221v2 |
|title| CHILI: Chemically-Informed Large-scale Inorganic Nanomaterials Dataset for Advancing Graph Machine Learning |
|authors| Ulrik Friis-JensenFrederik L. JohansenAndy S. AnkerErik B. DamKirsten M. Ø. JensenRaghavendra Selvan
|links| http://arxiv.org/abs/2402.13221v2 |
|updated| 2024-02-21 08:07:13 UTC |
|summary| Advances in graph machine learning ML have been driven by applications inchemistry as graphs have remained the most expressive representations ofmolecules. While early graph ML methods focused primarily on small organicmolecules recently the scope of graph ML has expanded to include inorganicmaterials. Modelling the periodicity and symmetry of inorganic crystallinematerials poses unique challenges which existing graph ML methods are unableto address. Moving to inorganic nanomaterials increases complexity as the scaleof number of nodes within each graph can be broad 10 to 105. The bulk ofexisting graph ML focuses on characterising molecules and materials bypredicting target properties with graphs as input. However the most excitingapplications of graph ML will be in their generative capabilities which iscurrently not at par with other domains such as images or text.  We invite the graph ML community to address these open challenges bypresenting two new chemically-informed large-scale inorganic CHILInanomaterials datasets: A medium-scale dataset with overall 6M nodes 49Medges of mono-metallic oxide nanomaterials generated from 12 selected crystaltypes CHILI-3K and a large-scale dataset with overall 183M nodes 1.2Bedges of nanomaterials generated from experimentally determined crystalstructures CHILI-100K. We define 11 property prediction tasks and 6 structureprediction tasks which are of special interest for nanomaterial research. Webenchmark the performance of a wide array of baseline methods and use thesebenchmarking results to highlight areas which need future work. To the best ofour knowledge CHILI-3K and CHILI-100K are the first open-source nanomaterialdatasets of this scale -- both on the individual graph level and of the datasetas a whole -- and the only nanomaterials datasets with high structural andelemental diversity. |


| Item |Content|
| --- |---|
|idx| 2402.13187v1 |
|title| Testing Calibration in Subquadratic Time |
|authors| Lunjia HuKevin TianChutong Yang
|links| http://arxiv.org/abs/2402.13187v1 |
|updated| 2024-02-20 17:53:24 UTC |
|summary| In the recent literature on machine learning and decision making calibrationhas emerged as a desirable and widely-studied statistical property of theoutputs of binary prediction models. However the algorithmic aspects ofmeasuring model calibration have remained relatively less well-explored.Motivated by BGHN23 which proposed a rigorous framework for measuringdistances to calibration we initiate the algorithmic study of calibrationthrough the lens of property testing. We define the problem of calibrationtesting from samples where given n draws from a distribution mathcalD onpredictions binary outcomes our goal is to distinguish between the casewhere mathcalD is perfectly calibrated and the case where mathcalDis varepsilon-far from calibration.  We design an algorithm based on approximate linear programming which solvescalibration testing information-theoretically optimally up to constantfactors in time On1.5 logn. This improves upon state-of-the-artblack-box linear program solvers requiring Omeganomega time whereomega  2 is the exponent of matrix multiplication. We also developalgorithms for tolerant variants of our testing problem and give samplecomplexity lower bounds for alternative calibration distances to the oneconsidered in this work. Finally we present preliminary experiments showingthat the testing problem we define faithfully captures standard notions ofcalibration and that our algorithms scale to accommodate moderate samplesizes. |


| Item |Content|
| --- |---|
|idx| 2402.13182v1 |
|title| Order-Optimal Regret in Distributed Kernel Bandits using Uniform Sampling with Shared Randomness |
|authors| Nikola PavlovicSudeep SalgiaQing Zhao
|links| http://arxiv.org/abs/2402.13182v1 |
|updated| 2024-02-20 17:49:10 UTC |
|summary| We consider distributed kernel bandits where N agents aim tocollaboratively maximize an unknown reward function that lies in a reproducingkernel Hilbert space. Each agent sequentially queries the function to obtainnoisy observations at the query points. Agents can share information through acentral server with the objective of minimizing regret that is accumulatingover time T and aggregating over agents. We develop the first algorithm thatachieves the optimal regret order as defined by centralized learning with acommunication cost that is sublinear in both N and T. The key features ofthe proposed algorithm are the uniform exploration at the local agents andshared randomness with the central server. Working together with the sparseapproximation of the GP model these two key components make it possible topreserve the learning rate of the centralized setting at a diminishing rate ofcommunication. |


| Item |Content|
| --- |---|
|idx| 2402.13106v1 |
|title| On Generalization Bounds for Deep Compound Gaussian Neural Networks |
|authors| Carter LyonsRaghu G. RajMargaret Cheney
|links| http://arxiv.org/abs/2402.13106v1 |
|updated| 2024-02-20 16:01:39 UTC |
|summary| Algorithm unfolding or unrolling is the technique of constructing a deepneural network DNN from an iterative algorithm. Unrolled DNNs often providebetter interpretability and superior empirical performance over standard DNNsin signal estimation tasks. An important theoretical question which has onlyrecently received attention is the development of generalization error boundsfor unrolled DNNs. These bounds deliver theoretical and practical insights intothe performance of a DNN on empirical datasets that are distinct from butsampled from the probability density generating the DNN training data. In thispaper we develop novel generalization error bounds for a class of unrolledDNNs that are informed by a compound Gaussian prior. These compound Gaussiannetworks have been shown to outperform comparative standard and unfolded deepneural networks in compressive sensing and tomographic imaging problems. Thegeneralization error bound is formulated by bounding the Rademacher complexityof the class of compound Gaussian network estimates with Dudleys integral.Under realistic conditions we show that at worst the generalization errorscales mathcalOnsqrtlnn in the signal dimension andmathcalONetwork Size3/2 in network size. |


| Item |Content|
| --- |---|
|idx| 2402.13079v1 |
|title| Mode Estimation with Partial Feedback |
|authors| Charles ArnalVivien CabannesVianney Perchet
|links| http://arxiv.org/abs/2402.13079v1 |
|updated| 2024-02-20 15:24:21 UTC |
|summary| The combination of lightly supervised pre-training and online fine-tuning hasplayed a key role in recent AI developments. These new learning pipelines callfor new theoretical frameworks. In this paper we formalize core aspects ofweakly supervised and active learning with a simple problem: the estimation ofthe mode of a distribution using partial feedback. We show how entropy codingallows for optimal information acquisition from partial feedback developcoarse sufficient statistics for mode identification and adapt banditalgorithms to our new setting. Finally we combine those contributions into astatistically and computationally efficient solution to our problem. |


# cs.HC 

| Item |Content|
| --- |---|
|idx| 2402.13219v1 |
|title| Analyzing Operator States and the Impact of AI-Enhanced Decision Support in Control Rooms: A Human-in-the-Loop Specialized Reinforcement Learning Framework for Intervention Strategies |
|authors| Ammar N. AbbasChidera W. AmazuJoseph MietkiewiczHouda BriwaAndres Alonzo PerezGabriele BaldissoneMicaela DemichelaGeorgios G. ChasparisJohn D. KelleherMaria Chiara Leva
|links| http://arxiv.org/abs/2402.13219v1 |
|updated| 2024-02-20 18:31:27 UTC |
|summary| In complex industrial and chemical process control rooms effectivedecision-making is crucial for safety and efficiency. The experiments in thispaper evaluate the impact and applications of an AI-based decision supportsystem integrated into an improved human-machine interface using dynamicinfluence diagrams a hidden Markov model and deep reinforcement learning. Theenhanced support system aims to reduce operator workload improve situationalawareness and provide different intervention strategies to the operatoradapted to the current state of both the system and human performance. Such asystem can be particularly useful in cases of information overload when manyalarms and inputs are presented all within the same time window or for junioroperators during training. A comprehensive cross-data analysis was conductedinvolving 47 participants and a diverse range of data sources such assmartwatch metrics eye-tracking data process logs and responses fromquestionnaires. The results indicate interesting insights regarding theeffectiveness of the approach in aiding decision-making decreasing perceivedworkload and increasing situational awareness for the scenarios considered.Additionally the results provide valuable insights to compare differencesbetween styles of information gathering when using the system by individualparticipants. These findings are particularly relevant when predicting theoverall performance of the individual participant and their capacity tosuccessfully handle a plant upset and the alarms connected to it using processand human-machine interaction logs in real-time. These predictions enable thedevelopment of more effective intervention strategies. |


| Item |Content|
| --- |---|
|idx| 2402.13123v1 |
|title| Exploring AI-assisted Ideation and Prototyping for Choreography |
|authors| Yimeng LiuMisha Sra
|links| http://dx.doi.org/10.1145/3640544.3645227 |
|updated| 2024-02-20 16:36:15 UTC |
|summary| Choreography creation is a multimodal endeavor demanding cognitive abilitiesto develop creative ideas and technical expertise to convert choreographicideas into physical dance movements. Previous endeavors have sought to reducethe complexities in the choreography creation process in both dimensions. Amongthem non-AI-based systems have focused on reinforcing cognitive activities byhelping analyze and understand dance movements and augmenting physicalcapabilities by enhancing body expressivity. On the other hand AI-basedmethods have helped the creation of novel choreographic materials withgenerative AI algorithms. The choreography creation process is constrained bytime and requires a rich set of resources to stimulate novel ideas but theneed for iterative prototyping and reduced physical dependence have not beenadequately addressed by prior research. Recognizing these challenges and theresearch gap we present an innovative AI-based choreography-support system.Our goal is to facilitate rapid ideation by utilizing a generative AI modelthat can produce diverse and novel dance sequences. The system is designed tosupport iterative digital dance prototyping through an interactive web-baseduser interface that enables the editing and modification of generated motion.We evaluated our system by inviting six choreographers to analyze itslimitations and benefits and present the evaluation results along withpotential directions for future work. |


| Item |Content|
| --- |---|
|idx| 2402.13120v1 |
|title| Tactile Weight Rendering: A Review for Researchers and Developers |
|authors| Rubén Martín-RodríguezAlexandre L. RatschatLaura Marchal-CrespoYasemin Vardar
|links| http://arxiv.org/abs/2402.13120v1 |
|updated| 2024-02-20 16:27:07 UTC |
|summary| Haptic rendering of weight plays an essential role in naturalistic objectinteraction in virtual environments. While kinesthetic devices havetraditionally been used for this aim by applying forces on the limbs tactileinterfaces acting on the skin have recently offered potential solutions toenhance or substitute kinesthetic ones. Here we aim to provide an in-depthoverview and comparison of existing tactile weight rendering approaches. Wecategorized these approaches based on their type of stimulation into asymmetricvibration and skin stretch further divided according to the working mechanismof the devices. Then we compared these approaches using various criteriaincluding physical mechanical and perceptual characteristics of the reporteddevices and their potential applications. We found that asymmetric vibrationdevices have the smallest form factor while skin stretch devices relying onthe motion of flat surfaces belts or tactors present numerous mechanical andperceptual advantages for scenarios requiring more accurate weight rendering.Finally we discussed the selection of the proposed categorization of devicesand their application scopes together with the limitations and opportunitiesfor future research. We hope this study guides the development and use oftactile interfaces to achieve a more naturalistic object interaction andmanipulation in virtual environments. |


| Item |Content|
| --- |---|
|idx| 2402.13094v1 |
|title| Digital Comprehensibility Assessment of Simplified Texts among Persons with Intellectual Disabilities |
|authors| Andreas SäuberliFranz HolzknechtPatrick HallerSilvana DeilenLaura SchifflSilvia Hansen-SchirraSarah Ebling
|links| http://arxiv.org/abs/2402.13094v1 |
|updated| 2024-02-20 15:37:08 UTC |
|summary| Text simplification refers to the process of increasing the comprehensibilityof texts. Automatic text simplification models are most commonly evaluated byexperts or crowdworkers instead of the primary target groups of simplifiedtexts such as persons with intellectual disabilities. We conducted anevaluation study of text comprehensibility including participants with andwithout intellectual disabilities reading unsimplified automatically andmanually simplified German texts on a tablet computer. We explored fourdifferent approaches to measuring comprehensibility: multiple-choicecomprehension questions perceived difficulty ratings response time andreading speed. The results revealed significant variations in thesemeasurements depending on the reader group and whether the text had undergoneautomatic or manual simplification. For the target group of persons withintellectual disabilities comprehension questions emerged as the most reliablemeasure while analyzing reading speed provided valuable insights intoparticipants reading behavior. |


| Item |Content|
| --- |---|
|idx| 2402.13027v1 |
|title| Solving the decision-making analysis differential equation using eye fixation data in Unity software with Hermite Long-Short-Term Memory |
|authors| Kourosh ParandSaeed SetayeshiMir Mohsen PedramAli YoonesiAida Pakniyat
|links| http://arxiv.org/abs/2402.13027v1 |
|updated| 2024-02-20 14:09:28 UTC |
|summary| Decision-making is a fundamental component of our personal and professionallives. To analyze decision-making accuracy this study proposes a virtualenvironment designed as an industrial town to investigate the relationshipbetween eye movements and decision-making. Eye tracking provides a tool toexamine eye movements which contain information related to eye position headposition and gaze direction. The game is designed using Unity software withthe collected data being analyzed using a differential equation and the Hermiteneural network method. The game is used to identify the behaviors exhibited bybad and good individuals and differentiate between them before taking action.This paper investigates the accuracy of an individuals decision-making processby analyzing their eye movements and the correctness of the decisions made. |


# cs.MA 

| Item |Content|
| --- |---|
|idx| 2402.13219v1 |
|title| Analyzing Operator States and the Impact of AI-Enhanced Decision Support in Control Rooms: A Human-in-the-Loop Specialized Reinforcement Learning Framework for Intervention Strategies |
|authors| Ammar N. AbbasChidera W. AmazuJoseph MietkiewiczHouda BriwaAndres Alonzo PerezGabriele BaldissoneMicaela DemichelaGeorgios G. ChasparisJohn D. KelleherMaria Chiara Leva
|links| http://arxiv.org/abs/2402.13219v1 |
|updated| 2024-02-20 18:31:27 UTC |
|summary| In complex industrial and chemical process control rooms effectivedecision-making is crucial for safety and efficiency. The experiments in thispaper evaluate the impact and applications of an AI-based decision supportsystem integrated into an improved human-machine interface using dynamicinfluence diagrams a hidden Markov model and deep reinforcement learning. Theenhanced support system aims to reduce operator workload improve situationalawareness and provide different intervention strategies to the operatoradapted to the current state of both the system and human performance. Such asystem can be particularly useful in cases of information overload when manyalarms and inputs are presented all within the same time window or for junioroperators during training. A comprehensive cross-data analysis was conductedinvolving 47 participants and a diverse range of data sources such assmartwatch metrics eye-tracking data process logs and responses fromquestionnaires. The results indicate interesting insights regarding theeffectiveness of the approach in aiding decision-making decreasing perceivedworkload and increasing situational awareness for the scenarios considered.Additionally the results provide valuable insights to compare differencesbetween styles of information gathering when using the system by individualparticipants. These findings are particularly relevant when predicting theoverall performance of the individual participant and their capacity tosuccessfully handle a plant upset and the alarms connected to it using processand human-machine interaction logs in real-time. These predictions enable thedevelopment of more effective intervention strategies. |


| Item |Content|
| --- |---|
|idx| 2402.12327v1 |
|title| Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents |
|authors| Zengqing WuShuyuan ZhengQianying LiuXu HanBrian Inhyuk KwonMakoto OnizukaShaojie TangRun PengChuan Xiao
|links| http://arxiv.org/abs/2402.12327v1 |
|updated| 2024-02-19 18:00:53 UTC |
|summary| Recent advancements have shown that agents powered by large language modelsLLMs possess capabilities to simulate human behaviors and societal dynamics.However the potential for LLM agents to spontaneously establish collaborativerelationships in the absence of explicit instructions has not been studied. Toaddress this gap we conduct three case studies revealing that LLM agents arecapable of spontaneously forming collaborations even within competitivesettings. This finding not only demonstrates the capacity of LLM agents tomimic competition and cooperation in human societies but also validates apromising vision of computational social science. Specifically it suggeststhat LLM agents could be utilized to model human social interactions includingthose with spontaneous collaborations thus offering insights into socialphenomena. The source codes for this study are available athttps://github.com/wuzengqing001225/SABM_ShallWeTalk . |


| Item |Content|
| --- |---|
|idx| 2402.12326v1 |
|title| LLM Agents for Psychology: A Study on Gamified Assessments |
|authors| Qisen YangZekun WangHonghui ChenShenzhi WangYifan PuXin GaoWenhao HuangShiji SongGao Huang
|links| http://arxiv.org/abs/2402.12326v1 |
|updated| 2024-02-19 18:00:30 UTC |
|summary| Psychological measurement is essential for mental health self-understandingand personal development. Traditional methods such as self-report scales andpsychologist interviews often face challenges with engagement andaccessibility. While game-based and LLM-based tools have been explored toimprove user interest and automate assessment they struggle to balanceengagement with generalizability. In this work we propose PsychoGATPsychological Game AgenTs to achieve a generic gamification of psychologicalassessment. The main insight is that powerful LLMs can function both as adeptpsychologists and innovative game designers. By incorporating LLM agents intodesignated roles and carefully managing their interactions PsychoGAT cantransform any standardized scales into personalized and engaging interactivefiction games. To validate the proposed method we conduct psychometricevaluations to assess its effectiveness and employ human evaluators to examinethe generated content across various psychological constructs includingdepression cognitive distortions and personality traits. Results demonstratethat PsychoGAT serves as an effective assessment tool achieving statisticallysignificant excellence in psychometric metrics such as reliability convergentvalidity and discriminant validity. Moreover human evaluations confirmPsychoGATs enhancements in content coherence interactivity interestimmersion and satisfaction. |


| Item |Content|
| --- |---|
|idx| 2402.12086v1 |
|title| Navigating simplicity and complexity of social-ecological systems through a dialog between dynamical systems and agent-based models |
|authors| Sonja RadosavljevicUdita SangaMaja Schlüter
|links| http://arxiv.org/abs/2402.12086v1 |
|updated| 2024-02-19 12:07:27 UTC |
|summary| Social-ecological systems SES research aims to understand the nature ofsocial-ecological phenomena to find effective ways to foster or manageconditions under which desirable phenomena such as sustainable resource useoccur or to change conditions or reduce the negative consequences ofundesirable phenomena such as poverty traps. Challenges such as these areoften addressed using dynamical systems models DSM or agent-based modelsABM. Both modeling approaches have strengths and weaknesses. DSM are praisedfor their analytical tractability and efficient exploration of asymptoticdynamics and bifurcation which are enabled by reduced number and heterogeneityof system components. ABM allows representing heterogeneity agency learningand interactions of diverse agents within SES but this also comes at a pricesuch as inefficiency to explore asymptotic dynamics or bifurcations. In thispaper we combine DSM and ABM to leverage strengths of each modeling techniqueand gain deeper insights into dynamics of a system. We start with an ABM andresearch questions that the ABM was not able to answer. Using results of theABM analysis as inputs for DSM we create a DSM. Stability and bifurcationanalysis of the DSM gives partial answers to the research questions and directattention to where additional details are needed. This informs further ABManalysis prevents burdening the ABM with less important details and revealsnew insights about system dynamics. The iterative process and dialogue betweenthe ABM and DSM leads to more complete answers to research questions andsurpasses insights provided by each of the models separately. We illustrate theprocedure with the example of the emergence of poverty traps in an agriculturalsystem with endogenously driven innovation. |


| Item |Content|
| --- |---|
|idx| 2402.12416v1 |
|title| Aligning Individual and Collective Objectives in Multi-Agent Cooperation |
|authors| Yang LiWenhao ZhangJianhong WangShao ZhangYali DuYing WenWei Pan
|links| http://arxiv.org/abs/2402.12416v1 |
|updated| 2024-02-19 08:18:53 UTC |
|summary| In the field of multi-agent learning the challenge of mixed-motivecooperation is pronounced given the inherent contradictions between individualand collective goals. Current research in this domain primarily focuses onincorporating domain knowledge into rewards or introducing additionalmechanisms to foster cooperation. However many of these methods suffer fromthe drawbacks of manual design costs and the lack of a theoretical groundingconvergence procedure to the solution. To address this gap we approach themixed-motive game by modeling it as a differentiable game to study learningdynamics. We introduce a novel optimization method named Altruistic GradientAdjustment AgA that employs gradient adjustments to novelly align individualand collective objectives. Furthermore we provide theoretical proof that theselection of an appropriate alignment weight in AgA can accelerate convergencetowards the desired solutions while effectively avoiding the undesired ones.The visualization of learning dynamics effectively demonstrates that AgAsuccessfully achieves alignment between individual and collective objectives.Additionally through evaluations conducted on established mixed-motivebenchmarks such as the public good game Cleanup Harvest and our modifiedmixed-motive SMAC environment we validate AgAs capability to facilitatealtruistic and fair collaboration. |


